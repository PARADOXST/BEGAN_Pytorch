{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--lr_decay_every'], dest='lr_decay_every', nargs=None, const=None, default=3000, type=<type 'int'>, choices=None, help='decay lr how many iterations', metavar=None)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', required=True, help='cifar10 | lsun | imagenet | folder | lfw ')\n",
    "parser.add_argument('--dataroot', required=True, help='path to dataset')\n",
    "parser.add_argument('--workers', type=int, help='number of data loading workers', default=2)\n",
    "parser.add_argument('--batch_size', type=int, default=16, help='input batch size')\n",
    "parser.add_argument('--image_size', type=int, default=64, help='the height / width of the input image to network')\n",
    "parser.add_argument('--nz', type=int, default=64, help='size of the latent z vector')\n",
    "parser.add_argument('--niter', type=int, default=25, help='number of epochs to train for')\n",
    "parser.add_argument('--lr', type=float, default=0.0001, help='learning rate, default=0.0002')\n",
    "parser.add_argument('--beta1', type=float, default=0.4, help='beta1 for adam. default=0.5')\n",
    "parser.add_argument('--cuda', action='store_true', help='enables cuda')\n",
    "parser.add_argument('--netD', default='', help=\"path to netD (to continue training)\")\n",
    "parser.add_argument('--netG', default='', help=\"path to netG (to continue training)\")\n",
    "parser.add_argument('--base_dir', default='./train7/', help='directory to save image/model/data')\n",
    "parser.add_argument('--k_init', type=float, default=0.0, help='initial value of k')\n",
    "parser.add_argument('--gamma', type=float, default=0.4, help='diversity ratio')\n",
    "parser.add_argument('--numOfKernel', type=int, default=64, help='Number of Kernels in G\\'s Conv')\n",
    "parser.add_argument('--lr_decay', type=float, default=0.95, help='learning rate decay rate')\n",
    "parser.add_argument('--lr_decay_every', type=int, default=3000, help='decay lr how many iterations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(base_dir='./train7/', batch_size=16, beta1=0.4, cuda=True, dataroot='/home/ubuntu/data/work/', dataset='folder', gamma=0.4, image_size=64, k_init=0.0, lr=0.0001, lr_decay=0.95, lr_decay_every=3000, netD='', netG='', niter=25, numOfKernel=64, nz=64, workers=2)\n"
     ]
    }
   ],
   "source": [
    "opt = parser.parse_args(['--dataset', 'folder', '--dataroot', '/home/ubuntu/data/work/', '--cuda', '--niter', '25'])\n",
    "print(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(opt.base_dir)\n",
    "except OSError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if opt.manualSeed is None:\n",
    "#     opt.manualSeed = random.randint(1, 10000)\n",
    "# print(\"Random Seed: \", opt.manualSeed)\n",
    "# random.seed(opt.manualSeed)\n",
    "# torch.manual_seed(opt.manualSeed)\n",
    "# if opt.cuda:\n",
    "#     torch.cuda.manual_seed_all(opt.manualSeed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "if torch.cuda.is_available() and not opt.cuda:\n",
    "    print(\"WARNING: You have a CUDA device, so you should probably run with --cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = glob('/home/ubuntu/data/work/img_align_celeba/*')\n",
    "mini_batch = len(file_list) / opt.batch_size\n",
    "def get_permutation():\n",
    "    return np.random.permutation(len(file_list))\n",
    "def get_samples(index, i):\n",
    "    data = torch.FloatTensor(opt.batch_size, 3, opt.image_size, opt.image_size)\n",
    "    j = 0\n",
    "    for i in range(opt.batch_size*i, opt.batch_size*(i+1)):\n",
    "        data[j] = transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))(transforms.ToTensor()(Image.open(file_list[index[i]])))\n",
    "        j += 1\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngpu = 1\n",
    "nz = int(opt.nz)\n",
    "k = opt.k_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# custom weights initialization called on netG and netD\n",
    "def G_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.002)\n",
    "\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def D_weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class G_CNN(nn.Module):\n",
    "    def __init__(self, embedding_size, kernel_num):\n",
    "        super(G_CNN, self).__init__()\n",
    "        self.kernel_num = kernel_num\n",
    "        FC_start_size = 8 * 8 * self.kernel_num\n",
    "        self.start = nn.Linear(embedding_size, FC_start_size)\n",
    "        #all layers\n",
    "        self.main_arch = nn.Sequential(\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #last layer\n",
    "            #nn.Conv2d(in_channels=kernel_num, out_channels=3, kernel_size=3, padding=1)\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=kernel_num, out_channels=3, kernel_size=3, padding=1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        in_data = self.start(in_data.view(-1, 64))\n",
    "        in_data = in_data.view(-1, self.kernel_num, 8, 8)\n",
    "        output = self.main_arch(in_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netG = G_CNN(embedding_size=nz, kernel_num=opt.numOfKernel)\n",
    "netG.apply(G_weights_init)\n",
    "if opt.netG != '':\n",
    "    netG.load_state_dict(torch.load(opt.netG))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Discriminator\n",
    "class D_CNN(nn.Module):\n",
    "    def __init__(self, embedding_size, base_kernel_num):\n",
    "        super(D_CNN, self).__init__()\n",
    "        self.base_kernel_num = base_kernel_num\n",
    "        \n",
    "        #encoder w/o flatten and FC\n",
    "        self.encoder_wo_FC = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            #downsampling\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=2*base_kernel_num, kernel_size=1, padding=0, stride=1),\n",
    "            nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=2*base_kernel_num, out_channels=2*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=2*base_kernel_num, out_channels=2*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            #downsampling\n",
    "            nn.Conv2d(in_channels=2*base_kernel_num, out_channels=3*base_kernel_num, kernel_size=1, padding=0, stride=1),\n",
    "            nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=3*base_kernel_num, out_channels=3*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=3*base_kernel_num, out_channels=3*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            #downsampling\n",
    "            nn.Conv2d(in_channels=3*base_kernel_num, out_channels=4*base_kernel_num, kernel_size=1, padding=0, stride=1),\n",
    "            nn.AvgPool2d(kernel_size=2,stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=4*base_kernel_num, out_channels=4*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=4*base_kernel_num, out_channels=4*base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True)\n",
    "        )\n",
    "        FC_mid1_size = 8 * 8 * 4 * self.base_kernel_num\n",
    "        FC_mid2_size = 8 * 8 * self.base_kernel_num\n",
    "        self.FC1 = nn.Linear(FC_mid1_size, embedding_size)\n",
    "        self.FC2 = nn.Linear(embedding_size, FC_mid2_size)\n",
    "        self.decoder_wo_FC = nn.Sequential(\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #repeated units\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.UpsamplingNearest2d(scale_factor=2),\n",
    "            #last layer\n",
    "            #nn.Conv2d(in_channels=base_kernel_num, out_channels=3, kernel_size=3, padding=1)\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=base_kernel_num, kernel_size=3, padding=1),\n",
    "            nn.ELU(inplace=True),\n",
    "            nn.Conv2d(in_channels=base_kernel_num, out_channels=3, kernel_size=3, padding=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, in_data):\n",
    "        in_data = self.encoder_wo_FC(in_data)\n",
    "        \n",
    "        in_data = in_data.view(-1, 4*self.base_kernel_num * 8 * 8);\n",
    "        in_data = self.FC1(in_data)\n",
    "        in_data = self.FC2(in_data)\n",
    "        in_data = in_data.view(-1, self.base_kernel_num, 8, 8)\n",
    "        \n",
    "        output = self.decoder_wo_FC(in_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "netD = D_CNN(embedding_size=nz, base_kernel_num=opt.numOfKernel)\n",
    "netD.apply(D_weights_init)\n",
    "if opt.netD != '':\n",
    "    netD.load_state_dict(torch.load(opt.netD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "criterion_L1 = nn.L1Loss()\n",
    "\n",
    "input = torch.FloatTensor(opt.batch_size, 3, opt.image_size, opt.image_size)\n",
    "noise = torch.FloatTensor(opt.batch_size, nz)\n",
    "fixed_noise = torch.FloatTensor(opt.batch_size, nz, 1, 1).uniform_(-1, 1)\n",
    "\n",
    "if opt.cuda:\n",
    "    netD.cuda()\n",
    "    netG.cuda()\n",
    "    criterion_L1.cuda()\n",
    "    input = input.cuda()\n",
    "    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "input = Variable(input)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "np.save(opt.base_dir+'fixed_noise.npy', fixed_noise.data.cpu().numpy())\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=opt.lr, betas=(0.5, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=opt.lr, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def adjust_lr(optimizer, niter):\n",
    "    opt.lr = opt.lr * (0.95 ** (niter // opt.lr_decay_every))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = opt.lr\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][0/9765] Loss_D: 0.4499 Loss_G: 0.0472 Convergence: 0.5827 k= 0.000133 lr = 0.0001000\n",
      "[0/25][10/9765] Loss_D: 0.4492 Loss_G: 0.1245 Convergence: 0.5045 k= 0.001409 lr = 0.0001000\n",
      "[0/25][20/9765] Loss_D: 0.3714 Loss_G: 0.2301 Convergence: 0.4531 k= 0.001598 lr = 0.0001000\n",
      "[0/25][30/9765] Loss_D: 0.3718 Loss_G: 0.2300 Convergence: 0.4532 k= 0.000500 lr = 0.0001000\n",
      "[0/25][40/9765] Loss_D: 0.3659 Loss_G: 0.2953 Convergence: 0.5148 k= 0.000000 lr = 0.0001000\n",
      "[0/25][50/9765] Loss_D: 0.3563 Loss_G: 0.2666 Convergence: 0.4803 k= 0.000000 lr = 0.0001000\n",
      "[0/25][60/9765] Loss_D: 0.3488 Loss_G: 0.3471 Convergence: 0.5563 k= 0.000000 lr = 0.0001000\n",
      "[0/25][70/9765] Loss_D: 0.3797 Loss_G: 0.1578 Convergence: 0.3856 k= 0.000073 lr = 0.0001000\n",
      "[0/25][80/9765] Loss_D: 0.2946 Loss_G: 0.0998 Convergence: 0.3127 k= 0.000250 lr = 0.0001000\n",
      "[0/25][90/9765] Loss_D: 0.2789 Loss_G: 0.0559 Convergence: 0.3346 k= 0.000673 lr = 0.0001000\n",
      "[0/25][100/9765] Loss_D: 0.2594 Loss_G: 0.0556 Convergence: 0.3077 k= 0.001034 lr = 0.0001000\n",
      "[0/25][110/9765] Loss_D: 0.2841 Loss_G: 0.1286 Convergence: 0.2992 k= 0.001358 lr = 0.0001000\n",
      "[0/25][120/9765] Loss_D: 0.2260 Loss_G: 0.1010 Convergence: 0.2367 k= 0.001520 lr = 0.0001000\n",
      "[0/25][130/9765] Loss_D: 0.2552 Loss_G: 0.0787 Convergence: 0.2788 k= 0.001705 lr = 0.0001000\n",
      "[0/25][140/9765] Loss_D: 0.2394 Loss_G: 0.0971 Convergence: 0.2408 k= 0.001814 lr = 0.0001000\n",
      "[0/25][150/9765] Loss_D: 0.2438 Loss_G: 0.0774 Convergence: 0.2642 k= 0.002014 lr = 0.0001000\n",
      "[0/25][160/9765] Loss_D: 0.2440 Loss_G: 0.0887 Convergence: 0.2532 k= 0.002061 lr = 0.0001000\n",
      "[0/25][170/9765] Loss_D: 0.2400 Loss_G: 0.0930 Convergence: 0.2432 k= 0.002232 lr = 0.0001000\n",
      "[0/25][180/9765] Loss_D: 0.2388 Loss_G: 0.0850 Convergence: 0.2497 k= 0.002445 lr = 0.0001000\n",
      "[0/25][190/9765] Loss_D: 0.2529 Loss_G: 0.0832 Convergence: 0.2712 k= 0.002638 lr = 0.0001000\n",
      "[0/25][200/9765] Loss_D: 0.2553 Loss_G: 0.0651 Convergence: 0.2926 k= 0.002826 lr = 0.0001000\n",
      "[0/25][210/9765] Loss_D: 0.2338 Loss_G: 0.0753 Convergence: 0.2523 k= 0.002973 lr = 0.0001000\n",
      "[0/25][220/9765] Loss_D: 0.2250 Loss_G: 0.0668 Convergence: 0.2484 k= 0.003202 lr = 0.0001000\n",
      "[0/25][230/9765] Loss_D: 0.2388 Loss_G: 0.0680 Convergence: 0.2666 k= 0.003323 lr = 0.0001000\n",
      "[0/25][240/9765] Loss_D: 0.2224 Loss_G: 0.0628 Convergence: 0.2488 k= 0.003491 lr = 0.0001000\n",
      "[0/25][250/9765] Loss_D: 0.2063 Loss_G: 0.0679 Convergence: 0.2214 k= 0.003618 lr = 0.0001000\n",
      "[0/25][260/9765] Loss_D: 0.2122 Loss_G: 0.0655 Convergence: 0.2319 k= 0.003840 lr = 0.0001000\n",
      "[0/25][270/9765] Loss_D: 0.2300 Loss_G: 0.0661 Convergence: 0.2561 k= 0.004022 lr = 0.0001000\n",
      "[0/25][280/9765] Loss_D: 0.2272 Loss_G: 0.0596 Convergence: 0.2589 k= 0.004100 lr = 0.0001000\n",
      "[0/25][290/9765] Loss_D: 0.2123 Loss_G: 0.0560 Convergence: 0.2415 k= 0.004371 lr = 0.0001000\n",
      "[0/25][300/9765] Loss_D: 0.2085 Loss_G: 0.0519 Convergence: 0.2403 k= 0.004478 lr = 0.0001000\n",
      "[0/25][310/9765] Loss_D: 0.2166 Loss_G: 0.0728 Convergence: 0.2310 k= 0.004648 lr = 0.0001000\n",
      "[0/25][320/9765] Loss_D: 0.2102 Loss_G: 0.0941 Convergence: 0.2204 k= 0.004808 lr = 0.0001000\n",
      "[0/25][330/9765] Loss_D: 0.2125 Loss_G: 0.0840 Convergence: 0.2139 k= 0.004966 lr = 0.0001000\n",
      "[0/25][340/9765] Loss_D: 0.2067 Loss_G: 0.0759 Convergence: 0.2139 k= 0.005112 lr = 0.0001000\n",
      "[0/25][350/9765] Loss_D: 0.2157 Loss_G: 0.0696 Convergence: 0.2328 k= 0.005135 lr = 0.0001000\n",
      "[0/25][360/9765] Loss_D: 0.1932 Loss_G: 0.0818 Convergence: 0.1980 k= 0.005309 lr = 0.0001000\n",
      "[0/25][370/9765] Loss_D: 0.2265 Loss_G: 0.0648 Convergence: 0.2529 k= 0.005494 lr = 0.0001000\n",
      "[0/25][380/9765] Loss_D: 0.2142 Loss_G: 0.0607 Convergence: 0.2397 k= 0.005701 lr = 0.0001000\n",
      "[0/25][390/9765] Loss_D: 0.2120 Loss_G: 0.0557 Convergence: 0.2416 k= 0.005690 lr = 0.0001000\n",
      "[0/25][400/9765] Loss_D: 0.2047 Loss_G: 0.1125 Convergence: 0.2356 k= 0.005772 lr = 0.0001000\n",
      "[0/25][410/9765] Loss_D: 0.2041 Loss_G: 0.0694 Convergence: 0.2167 k= 0.005949 lr = 0.0001000\n",
      "[0/25][420/9765] Loss_D: 0.1975 Loss_G: 0.0735 Convergence: 0.2035 k= 0.006086 lr = 0.0001000\n",
      "[0/25][430/9765] Loss_D: 0.2042 Loss_G: 0.0624 Convergence: 0.2242 k= 0.006140 lr = 0.0001000\n",
      "[0/25][440/9765] Loss_D: 0.1943 Loss_G: 0.1124 Convergence: 0.2293 k= 0.006135 lr = 0.0001000\n",
      "[0/25][450/9765] Loss_D: 0.1974 Loss_G: 0.0879 Convergence: 0.2067 k= 0.006156 lr = 0.0001000\n",
      "[0/25][460/9765] Loss_D: 0.1908 Loss_G: 0.0790 Convergence: 0.1938 k= 0.006162 lr = 0.0001000\n",
      "[0/25][470/9765] Loss_D: 0.1882 Loss_G: 0.0621 Convergence: 0.2020 k= 0.006238 lr = 0.0001000\n",
      "[0/25][480/9765] Loss_D: 0.1843 Loss_G: 0.0744 Convergence: 0.1853 k= 0.006197 lr = 0.0001000\n",
      "[0/25][490/9765] Loss_D: 0.1929 Loss_G: 0.0906 Convergence: 0.2066 k= 0.006097 lr = 0.0001000\n",
      "[0/25][500/9765] Loss_D: 0.1865 Loss_G: 0.0947 Convergence: 0.2069 k= 0.006061 lr = 0.0001000\n",
      "[0/25][510/9765] Loss_D: 0.1824 Loss_G: 0.0861 Convergence: 0.1959 k= 0.005961 lr = 0.0001000\n",
      "[0/25][520/9765] Loss_D: 0.2069 Loss_G: 0.0900 Convergence: 0.2144 k= 0.005854 lr = 0.0001000\n",
      "[0/25][530/9765] Loss_D: 0.1815 Loss_G: 0.0715 Convergence: 0.1833 k= 0.005785 lr = 0.0001000\n",
      "[0/25][540/9765] Loss_D: 0.1929 Loss_G: 0.0977 Convergence: 0.2137 k= 0.005666 lr = 0.0001000\n",
      "[0/25][550/9765] Loss_D: 0.1816 Loss_G: 0.0872 Convergence: 0.1964 k= 0.005591 lr = 0.0001000\n",
      "[0/25][560/9765] Loss_D: 0.1841 Loss_G: 0.0740 Convergence: 0.1847 k= 0.005504 lr = 0.0001000\n",
      "[0/25][570/9765] Loss_D: 0.1954 Loss_G: 0.1165 Convergence: 0.2339 k= 0.005290 lr = 0.0001000\n",
      "[0/25][580/9765] Loss_D: 0.1883 Loss_G: 0.0699 Convergence: 0.1945 k= 0.005191 lr = 0.0001000\n",
      "[0/25][590/9765] Loss_D: 0.1936 Loss_G: 0.0881 Convergence: 0.2046 k= 0.005119 lr = 0.0001000\n",
      "[0/25][600/9765] Loss_D: 0.1919 Loss_G: 0.0805 Convergence: 0.1958 k= 0.004957 lr = 0.0001000\n",
      "[0/25][610/9765] Loss_D: 0.1819 Loss_G: 0.1024 Convergence: 0.2119 k= 0.004681 lr = 0.0001000\n",
      "[0/25][620/9765] Loss_D: 0.1778 Loss_G: 0.0997 Convergence: 0.2067 k= 0.004427 lr = 0.0001000\n",
      "[0/25][630/9765] Loss_D: 0.1877 Loss_G: 0.0918 Convergence: 0.2047 k= 0.004201 lr = 0.0001000\n",
      "[0/25][640/9765] Loss_D: 0.1819 Loss_G: 0.1024 Convergence: 0.2117 k= 0.004144 lr = 0.0001000\n",
      "[0/25][650/9765] Loss_D: 0.1887 Loss_G: 0.0905 Convergence: 0.2039 k= 0.004060 lr = 0.0001000\n",
      "[0/25][660/9765] Loss_D: 0.1948 Loss_G: 0.0700 Convergence: 0.2035 k= 0.003717 lr = 0.0001000\n",
      "[0/25][670/9765] Loss_D: 0.1867 Loss_G: 0.0988 Convergence: 0.2110 k= 0.003550 lr = 0.0001000\n",
      "[0/25][680/9765] Loss_D: 0.1859 Loss_G: 0.0736 Convergence: 0.1870 k= 0.003405 lr = 0.0001000\n",
      "[0/25][690/9765] Loss_D: 0.1939 Loss_G: 0.0926 Convergence: 0.2091 k= 0.003286 lr = 0.0001000\n",
      "[0/25][700/9765] Loss_D: 0.1879 Loss_G: 0.1078 Convergence: 0.2207 k= 0.003051 lr = 0.0001000\n",
      "[0/25][710/9765] Loss_D: 0.1920 Loss_G: 0.0782 Convergence: 0.1935 k= 0.002939 lr = 0.0001000\n",
      "[0/25][720/9765] Loss_D: 0.1818 Loss_G: 0.0895 Convergence: 0.1987 k= 0.002802 lr = 0.0001000\n",
      "[0/25][730/9765] Loss_D: 0.1926 Loss_G: 0.0849 Convergence: 0.2006 k= 0.002696 lr = 0.0001000\n",
      "[0/25][740/9765] Loss_D: 0.1825 Loss_G: 0.0945 Convergence: 0.2041 k= 0.002474 lr = 0.0001000\n",
      "[0/25][750/9765] Loss_D: 0.1756 Loss_G: 0.1010 Convergence: 0.2065 k= 0.002383 lr = 0.0001000\n",
      "[0/25][760/9765] Loss_D: 0.2112 Loss_G: 0.1701 Convergence: 0.2970 k= 0.002190 lr = 0.0001000\n",
      "[0/25][770/9765] Loss_D: 0.1680 Loss_G: 0.0758 Convergence: 0.1766 k= 0.002063 lr = 0.0001000\n",
      "[0/25][780/9765] Loss_D: 0.1942 Loss_G: 0.0776 Convergence: 0.1946 k= 0.002060 lr = 0.0001000\n",
      "[0/25][790/9765] Loss_D: 0.1895 Loss_G: 0.0820 Convergence: 0.1958 k= 0.001942 lr = 0.0001000\n",
      "[0/25][800/9765] Loss_D: 0.1756 Loss_G: 0.0643 Convergence: 0.1817 k= 0.001916 lr = 0.0001000\n",
      "[0/25][810/9765] Loss_D: 0.1682 Loss_G: 0.0634 Convergence: 0.1724 k= 0.001849 lr = 0.0001000\n",
      "[0/25][820/9765] Loss_D: 0.2024 Loss_G: 0.0703 Convergence: 0.2133 k= 0.001704 lr = 0.0001000\n",
      "[0/25][830/9765] Loss_D: 0.1845 Loss_G: 0.0963 Convergence: 0.2070 k= 0.001660 lr = 0.0001000\n",
      "[0/25][840/9765] Loss_D: 0.1659 Loss_G: 0.0886 Convergence: 0.1882 k= 0.001602 lr = 0.0001000\n",
      "[0/25][850/9765] Loss_D: 0.1644 Loss_G: 0.0581 Convergence: 0.1723 k= 0.001553 lr = 0.0001000\n",
      "[0/25][860/9765] Loss_D: 0.1680 Loss_G: 0.0714 Convergence: 0.1722 k= 0.001499 lr = 0.0001000\n",
      "[0/25][870/9765] Loss_D: 0.1696 Loss_G: 0.0622 Convergence: 0.1754 k= 0.001430 lr = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][880/9765] Loss_D: 0.1676 Loss_G: 0.0648 Convergence: 0.1699 k= 0.001379 lr = 0.0001000\n",
      "[0/25][890/9765] Loss_D: 0.1742 Loss_G: 0.0745 Convergence: 0.1790 k= 0.001313 lr = 0.0001000\n",
      "[0/25][900/9765] Loss_D: 0.1569 Loss_G: 0.0579 Convergence: 0.1618 k= 0.001369 lr = 0.0001000\n",
      "[0/25][910/9765] Loss_D: 0.1884 Loss_G: 0.1524 Convergence: 0.2655 k= 0.001277 lr = 0.0001000\n",
      "[0/25][920/9765] Loss_D: 0.1710 Loss_G: 0.0829 Convergence: 0.1855 k= 0.001172 lr = 0.0001000\n",
      "[0/25][930/9765] Loss_D: 0.1802 Loss_G: 0.1041 Convergence: 0.2122 k= 0.001117 lr = 0.0001000\n",
      "[0/25][940/9765] Loss_D: 0.1758 Loss_G: 0.0766 Convergence: 0.1822 k= 0.001134 lr = 0.0001000\n",
      "[0/25][950/9765] Loss_D: 0.1750 Loss_G: 0.1015 Convergence: 0.2065 k= 0.001028 lr = 0.0001000\n",
      "[0/25][960/9765] Loss_D: 0.1727 Loss_G: 0.0606 Convergence: 0.1812 k= 0.001042 lr = 0.0001000\n",
      "[0/25][970/9765] Loss_D: 0.1747 Loss_G: 0.0918 Convergence: 0.1967 k= 0.001050 lr = 0.0001000\n",
      "[0/25][980/9765] Loss_D: 0.1992 Loss_G: 0.1276 Convergence: 0.2472 k= 0.000856 lr = 0.0001000\n",
      "[0/25][990/9765] Loss_D: 0.1808 Loss_G: 0.0527 Convergence: 0.2005 k= 0.000912 lr = 0.0001000\n",
      "[0/25][1000/9765] Loss_D: 0.1719 Loss_G: 0.0688 Convergence: 0.1720 k= 0.000644 lr = 0.0001000\n",
      "[0/25][1010/9765] Loss_D: 0.1739 Loss_G: 0.0774 Convergence: 0.1818 k= 0.000593 lr = 0.0001000\n",
      "[0/25][1020/9765] Loss_D: 0.1744 Loss_G: 0.0684 Convergence: 0.1758 k= 0.000535 lr = 0.0001000\n",
      "[0/25][1030/9765] Loss_D: 0.1762 Loss_G: 0.0641 Convergence: 0.1827 k= 0.000482 lr = 0.0001000\n",
      "[0/25][1040/9765] Loss_D: 0.1985 Loss_G: 0.0568 Convergence: 0.2211 k= 0.000357 lr = 0.0001000\n",
      "[0/25][1050/9765] Loss_D: 0.1652 Loss_G: 0.0699 Convergence: 0.1690 k= 0.000202 lr = 0.0001000\n",
      "[0/25][1060/9765] Loss_D: 0.1784 Loss_G: 0.0484 Convergence: 0.2014 k= 0.000243 lr = 0.0001000\n",
      "[0/25][1070/9765] Loss_D: 0.1781 Loss_G: 0.0757 Convergence: 0.1826 k= 0.000035 lr = 0.0001000\n",
      "[0/25][1080/9765] Loss_D: 0.1683 Loss_G: 0.0619 Convergence: 0.1737 k= 0.000052 lr = 0.0001000\n",
      "[0/25][1090/9765] Loss_D: 0.1787 Loss_G: 0.0624 Convergence: 0.1878 k= 0.000099 lr = 0.0001000\n",
      "[0/25][1100/9765] Loss_D: 0.1665 Loss_G: 0.0482 Convergence: 0.1849 k= 0.000125 lr = 0.0001000\n",
      "[0/25][1110/9765] Loss_D: 0.1665 Loss_G: 0.0613 Convergence: 0.1719 k= 0.000200 lr = 0.0001000\n",
      "[0/25][1120/9765] Loss_D: 0.1644 Loss_G: 0.0563 Convergence: 0.1738 k= 0.000205 lr = 0.0001000\n",
      "[0/25][1130/9765] Loss_D: 0.1649 Loss_G: 0.0545 Convergence: 0.1763 k= 0.000206 lr = 0.0001000\n",
      "[0/25][1140/9765] Loss_D: 0.1522 Loss_G: 0.0563 Convergence: 0.1568 k= 0.000239 lr = 0.0001000\n",
      "[0/25][1150/9765] Loss_D: 0.1651 Loss_G: 0.0794 Convergence: 0.1785 k= 0.000183 lr = 0.0001000\n",
      "[0/25][1160/9765] Loss_D: 0.1651 Loss_G: 0.0509 Convergence: 0.1803 k= 0.000297 lr = 0.0001000\n",
      "[0/25][1170/9765] Loss_D: 0.1656 Loss_G: 0.0557 Convergence: 0.1761 k= 0.000339 lr = 0.0001000\n",
      "[0/25][1180/9765] Loss_D: 0.1736 Loss_G: 0.0739 Convergence: 0.1781 k= 0.000272 lr = 0.0001000\n",
      "[0/25][1190/9765] Loss_D: 0.1705 Loss_G: 0.0511 Convergence: 0.1876 k= 0.000149 lr = 0.0001000\n",
      "[0/25][1200/9765] Loss_D: 0.1820 Loss_G: 0.1652 Convergence: 0.2744 k= 0.000000 lr = 0.0001000\n",
      "[0/25][1210/9765] Loss_D: 0.1745 Loss_G: 0.0531 Convergence: 0.1912 k= 0.000109 lr = 0.0001000\n",
      "[0/25][1220/9765] Loss_D: 0.1667 Loss_G: 0.0658 Convergence: 0.1677 k= 0.000246 lr = 0.0001000\n",
      "[0/25][1230/9765] Loss_D: 0.1623 Loss_G: 0.1236 Convergence: 0.2210 k= 0.000256 lr = 0.0001000\n",
      "[0/25][1240/9765] Loss_D: 0.1713 Loss_G: 0.0546 Convergence: 0.1852 k= 0.000283 lr = 0.0001000\n",
      "[0/25][1250/9765] Loss_D: 0.1638 Loss_G: 0.0434 Convergence: 0.1859 k= 0.000355 lr = 0.0001000\n",
      "[0/25][1260/9765] Loss_D: 0.1551 Loss_G: 0.0770 Convergence: 0.1701 k= 0.000454 lr = 0.0001000\n",
      "[0/25][1270/9765] Loss_D: 0.1761 Loss_G: 0.0399 Convergence: 0.2066 k= 0.000641 lr = 0.0001000\n",
      "[0/25][1280/9765] Loss_D: 0.1575 Loss_G: 0.0386 Convergence: 0.1820 k= 0.000884 lr = 0.0001000\n",
      "[0/25][1290/9765] Loss_D: 0.1698 Loss_G: 0.0396 Convergence: 0.1982 k= 0.001062 lr = 0.0001000\n",
      "[0/25][1300/9765] Loss_D: 0.1707 Loss_G: 0.0430 Convergence: 0.1960 k= 0.001273 lr = 0.0001000\n",
      "[0/25][1310/9765] Loss_D: 0.1699 Loss_G: 0.0606 Convergence: 0.1773 k= 0.001508 lr = 0.0001000\n",
      "[0/25][1320/9765] Loss_D: 0.1586 Loss_G: 0.0501 Convergence: 0.1721 k= 0.001740 lr = 0.0001000\n",
      "[0/25][1330/9765] Loss_D: 0.1619 Loss_G: 0.0607 Convergence: 0.1660 k= 0.002002 lr = 0.0001000\n",
      "[0/25][1340/9765] Loss_D: 0.1725 Loss_G: 0.0367 Convergence: 0.2050 k= 0.002251 lr = 0.0001000\n",
      "[0/25][1350/9765] Loss_D: 0.1530 Loss_G: 0.0381 Convergence: 0.1762 k= 0.002462 lr = 0.0001000\n",
      "[0/25][1360/9765] Loss_D: 0.1581 Loss_G: 0.0534 Convergence: 0.1680 k= 0.002687 lr = 0.0001000\n",
      "[0/25][1370/9765] Loss_D: 0.1691 Loss_G: 0.0515 Convergence: 0.1854 k= 0.002921 lr = 0.0001000\n",
      "[0/25][1380/9765] Loss_D: 0.1656 Loss_G: 0.0340 Convergence: 0.1981 k= 0.003132 lr = 0.0001000\n",
      "[0/25][1390/9765] Loss_D: 0.1638 Loss_G: 0.0740 Convergence: 0.1724 k= 0.003347 lr = 0.0001000\n",
      "[0/25][1400/9765] Loss_D: 0.1693 Loss_G: 0.0436 Convergence: 0.1937 k= 0.003590 lr = 0.0001000\n",
      "[0/25][1410/9765] Loss_D: 0.1513 Loss_G: 0.0398 Convergence: 0.1722 k= 0.003768 lr = 0.0001000\n",
      "[0/25][1420/9765] Loss_D: 0.1641 Loss_G: 0.0420 Convergence: 0.1879 k= 0.004013 lr = 0.0001000\n",
      "[0/25][1430/9765] Loss_D: 0.1666 Loss_G: 0.0383 Convergence: 0.1952 k= 0.004264 lr = 0.0001000\n",
      "[0/25][1440/9765] Loss_D: 0.1613 Loss_G: 0.0699 Convergence: 0.1668 k= 0.004445 lr = 0.0001000\n",
      "[0/25][1450/9765] Loss_D: 0.1622 Loss_G: 0.0332 Convergence: 0.1941 k= 0.004708 lr = 0.0001000\n",
      "[0/25][1460/9765] Loss_D: 0.1709 Loss_G: 0.0389 Convergence: 0.2007 k= 0.004837 lr = 0.0001000\n",
      "[0/25][1470/9765] Loss_D: 0.1631 Loss_G: 0.0500 Convergence: 0.1786 k= 0.005082 lr = 0.0001000\n",
      "[0/25][1480/9765] Loss_D: 0.1613 Loss_G: 0.0365 Convergence: 0.1896 k= 0.005337 lr = 0.0001000\n",
      "[0/25][1490/9765] Loss_D: 0.1669 Loss_G: 0.0484 Convergence: 0.1855 k= 0.005548 lr = 0.0001000\n",
      "[0/25][1500/9765] Loss_D: 0.1585 Loss_G: 0.0399 Convergence: 0.1823 k= 0.005732 lr = 0.0001000\n",
      "[0/25][1510/9765] Loss_D: 0.1647 Loss_G: 0.0416 Convergence: 0.1892 k= 0.005995 lr = 0.0001000\n",
      "[0/25][1520/9765] Loss_D: 0.1711 Loss_G: 0.0523 Convergence: 0.1877 k= 0.006138 lr = 0.0001000\n",
      "[0/25][1530/9765] Loss_D: 0.1630 Loss_G: 0.0458 Convergence: 0.1829 k= 0.006293 lr = 0.0001000\n",
      "[0/25][1540/9765] Loss_D: 0.1810 Loss_G: 0.0432 Convergence: 0.2107 k= 0.006482 lr = 0.0001000\n",
      "[0/25][1550/9765] Loss_D: 0.1607 Loss_G: 0.0396 Convergence: 0.1860 k= 0.006659 lr = 0.0001000\n",
      "[0/25][1560/9765] Loss_D: 0.1744 Loss_G: 0.0533 Convergence: 0.1915 k= 0.006772 lr = 0.0001000\n",
      "[0/25][1570/9765] Loss_D: 0.1668 Loss_G: 0.0571 Convergence: 0.1767 k= 0.006926 lr = 0.0001000\n",
      "[0/25][1580/9765] Loss_D: 0.1510 Loss_G: 0.0458 Convergence: 0.1661 k= 0.007048 lr = 0.0001000\n",
      "[0/25][1590/9765] Loss_D: 0.1790 Loss_G: 0.0455 Convergence: 0.2057 k= 0.007219 lr = 0.0001000\n",
      "[0/25][1600/9765] Loss_D: 0.1596 Loss_G: 0.0619 Convergence: 0.1621 k= 0.007354 lr = 0.0001000\n",
      "[0/25][1610/9765] Loss_D: 0.1816 Loss_G: 0.0453 Convergence: 0.2097 k= 0.007544 lr = 0.0001000\n",
      "[0/25][1620/9765] Loss_D: 0.1505 Loss_G: 0.0605 Convergence: 0.1510 k= 0.007706 lr = 0.0001000\n",
      "[0/25][1630/9765] Loss_D: 0.1589 Loss_G: 0.0389 Convergence: 0.1841 k= 0.007860 lr = 0.0001000\n",
      "[0/25][1640/9765] Loss_D: 0.1709 Loss_G: 0.0456 Convergence: 0.1942 k= 0.008073 lr = 0.0001000\n",
      "[0/25][1650/9765] Loss_D: 0.1648 Loss_G: 0.0446 Convergence: 0.1866 k= 0.008247 lr = 0.0001000\n",
      "[0/25][1660/9765] Loss_D: 0.1563 Loss_G: 0.0575 Convergence: 0.1619 k= 0.008362 lr = 0.0001000\n",
      "[0/25][1670/9765] Loss_D: 0.1526 Loss_G: 0.0535 Convergence: 0.1606 k= 0.008548 lr = 0.0001000\n",
      "[0/25][1680/9765] Loss_D: 0.1588 Loss_G: 0.0447 Convergence: 0.1781 k= 0.008728 lr = 0.0001000\n",
      "[0/25][1690/9765] Loss_D: 0.1631 Loss_G: 0.0863 Convergence: 0.1845 k= 0.008841 lr = 0.0001000\n",
      "[0/25][1700/9765] Loss_D: 0.1639 Loss_G: 0.0403 Convergence: 0.1897 k= 0.009054 lr = 0.0001000\n",
      "[0/25][1710/9765] Loss_D: 0.1706 Loss_G: 0.0389 Convergence: 0.2005 k= 0.009238 lr = 0.0001000\n",
      "[0/25][1720/9765] Loss_D: 0.1648 Loss_G: 0.0496 Convergence: 0.1819 k= 0.009411 lr = 0.0001000\n",
      "[0/25][1730/9765] Loss_D: 0.1542 Loss_G: 0.0596 Convergence: 0.1570 k= 0.009517 lr = 0.0001000\n",
      "[0/25][1740/9765] Loss_D: 0.1640 Loss_G: 0.0424 Convergence: 0.1878 k= 0.009686 lr = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][1750/9765] Loss_D: 0.1790 Loss_G: 0.0448 Convergence: 0.2064 k= 0.009877 lr = 0.0001000\n",
      "[0/25][1760/9765] Loss_D: 0.1633 Loss_G: 0.0642 Convergence: 0.1653 k= 0.009951 lr = 0.0001000\n",
      "[0/25][1770/9765] Loss_D: 0.1539 Loss_G: 0.0678 Convergence: 0.1604 k= 0.010049 lr = 0.0001000\n",
      "[0/25][1780/9765] Loss_D: 0.1535 Loss_G: 0.0515 Convergence: 0.1642 k= 0.010215 lr = 0.0001000\n",
      "[0/25][1790/9765] Loss_D: 0.1543 Loss_G: 0.0435 Convergence: 0.1733 k= 0.010382 lr = 0.0001000\n",
      "[0/25][1800/9765] Loss_D: 0.1497 Loss_G: 0.0488 Convergence: 0.1614 k= 0.010496 lr = 0.0001000\n",
      "[0/25][1810/9765] Loss_D: 0.1773 Loss_G: 0.0551 Convergence: 0.1940 k= 0.010597 lr = 0.0001000\n",
      "[0/25][1820/9765] Loss_D: 0.1655 Loss_G: 0.0467 Convergence: 0.1857 k= 0.010696 lr = 0.0001000\n",
      "[0/25][1830/9765] Loss_D: 0.1600 Loss_G: 0.0475 Convergence: 0.1772 k= 0.010846 lr = 0.0001000\n",
      "[0/25][1840/9765] Loss_D: 0.1577 Loss_G: 0.0590 Convergence: 0.1625 k= 0.010922 lr = 0.0001000\n",
      "[0/25][1850/9765] Loss_D: 0.1722 Loss_G: 0.0909 Convergence: 0.1946 k= 0.010967 lr = 0.0001000\n",
      "[0/25][1860/9765] Loss_D: 0.1614 Loss_G: 0.0587 Convergence: 0.1682 k= 0.010993 lr = 0.0001000\n",
      "[0/25][1870/9765] Loss_D: 0.1619 Loss_G: 0.0593 Convergence: 0.1682 k= 0.011023 lr = 0.0001000\n",
      "[0/25][1880/9765] Loss_D: 0.1515 Loss_G: 0.0464 Convergence: 0.1664 k= 0.011112 lr = 0.0001000\n",
      "[0/25][1890/9765] Loss_D: 0.1512 Loss_G: 0.0508 Convergence: 0.1618 k= 0.011236 lr = 0.0001000\n",
      "[0/25][1900/9765] Loss_D: 0.1558 Loss_G: 0.0532 Convergence: 0.1656 k= 0.011313 lr = 0.0001000\n",
      "[0/25][1910/9765] Loss_D: 0.1620 Loss_G: 0.0435 Convergence: 0.1842 k= 0.011448 lr = 0.0001000\n",
      "[0/25][1920/9765] Loss_D: 0.1634 Loss_G: 0.0535 Convergence: 0.1761 k= 0.011593 lr = 0.0001000\n",
      "[0/25][1930/9765] Loss_D: 0.1678 Loss_G: 0.0789 Convergence: 0.1800 k= 0.011717 lr = 0.0001000\n",
      "[0/25][1940/9765] Loss_D: 0.1676 Loss_G: 0.0676 Convergence: 0.1686 k= 0.011872 lr = 0.0001000\n",
      "[0/25][1950/9765] Loss_D: 0.1656 Loss_G: 0.0486 Convergence: 0.1843 k= 0.011907 lr = 0.0001000\n",
      "[0/25][1960/9765] Loss_D: 0.1513 Loss_G: 0.0634 Convergence: 0.1547 k= 0.011873 lr = 0.0001000\n",
      "[0/25][1970/9765] Loss_D: 0.1662 Loss_G: 0.0602 Convergence: 0.1735 k= 0.011907 lr = 0.0001000\n",
      "[0/25][1980/9765] Loss_D: 0.1442 Loss_G: 0.0470 Convergence: 0.1558 k= 0.011939 lr = 0.0001000\n",
      "[0/25][1990/9765] Loss_D: 0.1455 Loss_G: 0.0510 Convergence: 0.1536 k= 0.012044 lr = 0.0001000\n",
      "[0/25][2000/9765] Loss_D: 0.1729 Loss_G: 0.0502 Convergence: 0.1928 k= 0.012167 lr = 0.0001000\n",
      "[0/25][2010/9765] Loss_D: 0.1470 Loss_G: 0.0817 Convergence: 0.1703 k= 0.012221 lr = 0.0001000\n",
      "[0/25][2020/9765] Loss_D: 0.1554 Loss_G: 0.0498 Convergence: 0.1688 k= 0.012304 lr = 0.0001000\n",
      "[0/25][2030/9765] Loss_D: 0.1528 Loss_G: 0.0439 Convergence: 0.1708 k= 0.012481 lr = 0.0001000\n",
      "[0/25][2040/9765] Loss_D: 0.1705 Loss_G: 0.0516 Convergence: 0.1878 k= 0.012581 lr = 0.0001000\n",
      "[0/25][2050/9765] Loss_D: 0.1715 Loss_G: 0.0531 Convergence: 0.1878 k= 0.012726 lr = 0.0001000\n",
      "[0/25][2060/9765] Loss_D: 0.1543 Loss_G: 0.0439 Convergence: 0.1731 k= 0.012855 lr = 0.0001000\n",
      "[0/25][2070/9765] Loss_D: 0.1496 Loss_G: 0.0491 Convergence: 0.1611 k= 0.013001 lr = 0.0001000\n",
      "[0/25][2080/9765] Loss_D: 0.1599 Loss_G: 0.0495 Convergence: 0.1753 k= 0.013145 lr = 0.0001000\n",
      "[0/25][2090/9765] Loss_D: 0.1401 Loss_G: 0.0541 Convergence: 0.1433 k= 0.013212 lr = 0.0001000\n",
      "[0/25][2100/9765] Loss_D: 0.1521 Loss_G: 0.0517 Convergence: 0.1621 k= 0.013279 lr = 0.0001000\n",
      "[0/25][2110/9765] Loss_D: 0.1533 Loss_G: 0.0638 Convergence: 0.1564 k= 0.013347 lr = 0.0001000\n",
      "[0/25][2120/9765] Loss_D: 0.1499 Loss_G: 0.0454 Convergence: 0.1652 k= 0.013504 lr = 0.0001000\n",
      "[0/25][2130/9765] Loss_D: 0.1516 Loss_G: 0.0521 Convergence: 0.1612 k= 0.013617 lr = 0.0001000\n",
      "[0/25][2140/9765] Loss_D: 0.1746 Loss_G: 0.0471 Convergence: 0.1983 k= 0.013718 lr = 0.0001000\n",
      "[0/25][2150/9765] Loss_D: 0.1505 Loss_G: 0.0458 Convergence: 0.1660 k= 0.013821 lr = 0.0001000\n",
      "[0/25][2160/9765] Loss_D: 0.1598 Loss_G: 0.0625 Convergence: 0.1621 k= 0.013901 lr = 0.0001000\n",
      "[0/25][2170/9765] Loss_D: 0.1466 Loss_G: 0.0544 Convergence: 0.1521 k= 0.013939 lr = 0.0001000\n",
      "[0/25][2180/9765] Loss_D: 0.1460 Loss_G: 0.0416 Convergence: 0.1636 k= 0.014029 lr = 0.0001000\n",
      "[0/25][2190/9765] Loss_D: 0.1661 Loss_G: 0.0439 Convergence: 0.1896 k= 0.014132 lr = 0.0001000\n",
      "[0/25][2200/9765] Loss_D: 0.1437 Loss_G: 0.0487 Convergence: 0.1534 k= 0.014225 lr = 0.0001000\n",
      "[0/25][2210/9765] Loss_D: 0.1494 Loss_G: 0.0482 Convergence: 0.1617 k= 0.014315 lr = 0.0001000\n",
      "[0/25][2220/9765] Loss_D: 0.1589 Loss_G: 0.0466 Convergence: 0.1766 k= 0.014458 lr = 0.0001000\n",
      "[0/25][2230/9765] Loss_D: 0.1557 Loss_G: 0.0491 Convergence: 0.1700 k= 0.014536 lr = 0.0001000\n",
      "[0/25][2240/9765] Loss_D: 0.1510 Loss_G: 0.0645 Convergence: 0.1557 k= 0.014579 lr = 0.0001000\n",
      "[0/25][2250/9765] Loss_D: 0.1671 Loss_G: 0.0563 Convergence: 0.1788 k= 0.014672 lr = 0.0001000\n",
      "[0/25][2260/9765] Loss_D: 0.1562 Loss_G: 0.0455 Convergence: 0.1743 k= 0.014792 lr = 0.0001000\n",
      "[0/25][2270/9765] Loss_D: 0.1519 Loss_G: 0.0436 Convergence: 0.1701 k= 0.014950 lr = 0.0001000\n",
      "[0/25][2280/9765] Loss_D: 0.1658 Loss_G: 0.0570 Convergence: 0.1762 k= 0.015039 lr = 0.0001000\n",
      "[0/25][2290/9765] Loss_D: 0.1683 Loss_G: 0.0431 Convergence: 0.1939 k= 0.015144 lr = 0.0001000\n",
      "[0/25][2300/9765] Loss_D: 0.1503 Loss_G: 0.0452 Convergence: 0.1669 k= 0.015214 lr = 0.0001000\n",
      "[0/25][2310/9765] Loss_D: 0.1718 Loss_G: 0.0601 Convergence: 0.1816 k= 0.015292 lr = 0.0001000\n",
      "[0/25][2320/9765] Loss_D: 0.1386 Loss_G: 0.0399 Convergence: 0.1549 k= 0.015389 lr = 0.0001000\n",
      "[0/25][2330/9765] Loss_D: 0.1564 Loss_G: 0.0589 Convergence: 0.1615 k= 0.015489 lr = 0.0001000\n",
      "[0/25][2340/9765] Loss_D: 0.1609 Loss_G: 0.0443 Convergence: 0.1817 k= 0.015637 lr = 0.0001000\n",
      "[0/25][2350/9765] Loss_D: 0.1563 Loss_G: 0.0436 Convergence: 0.1763 k= 0.015773 lr = 0.0001000\n",
      "[0/25][2360/9765] Loss_D: 0.1600 Loss_G: 0.0429 Convergence: 0.1821 k= 0.015849 lr = 0.0001000\n",
      "[0/25][2370/9765] Loss_D: 0.1395 Loss_G: 0.0515 Convergence: 0.1449 k= 0.015928 lr = 0.0001000\n",
      "[0/25][2380/9765] Loss_D: 0.1617 Loss_G: 0.0543 Convergence: 0.1733 k= 0.016019 lr = 0.0001000\n",
      "[0/25][2390/9765] Loss_D: 0.1313 Loss_G: 0.0351 Convergence: 0.1497 k= 0.016127 lr = 0.0001000\n",
      "[0/25][2400/9765] Loss_D: 0.1420 Loss_G: 0.0402 Convergence: 0.1596 k= 0.016280 lr = 0.0001000\n",
      "[0/25][2410/9765] Loss_D: 0.1532 Loss_G: 0.0490 Convergence: 0.1668 k= 0.016421 lr = 0.0001000\n",
      "[0/25][2420/9765] Loss_D: 0.1522 Loss_G: 0.0608 Convergence: 0.1535 k= 0.016460 lr = 0.0001000\n",
      "[0/25][2430/9765] Loss_D: 0.1469 Loss_G: 0.0644 Convergence: 0.1532 k= 0.016454 lr = 0.0001000\n",
      "[0/25][2440/9765] Loss_D: 0.1569 Loss_G: 0.0514 Convergence: 0.1697 k= 0.016501 lr = 0.0001000\n",
      "[0/25][2450/9765] Loss_D: 0.1480 Loss_G: 0.0508 Convergence: 0.1576 k= 0.016601 lr = 0.0001000\n",
      "[0/25][2460/9765] Loss_D: 0.1548 Loss_G: 0.0555 Convergence: 0.1628 k= 0.016603 lr = 0.0001000\n",
      "[0/25][2470/9765] Loss_D: 0.1636 Loss_G: 0.0465 Convergence: 0.1834 k= 0.016717 lr = 0.0001000\n",
      "[0/25][2480/9765] Loss_D: 0.1528 Loss_G: 0.0484 Convergence: 0.1667 k= 0.016780 lr = 0.0001000\n",
      "[0/25][2490/9765] Loss_D: 0.1572 Loss_G: 0.0625 Convergence: 0.1595 k= 0.016817 lr = 0.0001000\n",
      "[0/25][2500/9765] Loss_D: 0.1486 Loss_G: 0.0503 Convergence: 0.1591 k= 0.016905 lr = 0.0001000\n",
      "[0/25][2510/9765] Loss_D: 0.1549 Loss_G: 0.0507 Convergence: 0.1673 k= 0.017003 lr = 0.0001000\n",
      "[0/25][2520/9765] Loss_D: 0.1518 Loss_G: 0.0473 Convergence: 0.1664 k= 0.017073 lr = 0.0001000\n",
      "[0/25][2530/9765] Loss_D: 0.1596 Loss_G: 0.0550 Convergence: 0.1701 k= 0.017093 lr = 0.0001000\n",
      "[0/25][2540/9765] Loss_D: 0.1468 Loss_G: 0.0700 Convergence: 0.1585 k= 0.017152 lr = 0.0001000\n",
      "[0/25][2550/9765] Loss_D: 0.1417 Loss_G: 0.0578 Convergence: 0.1434 k= 0.017190 lr = 0.0001000\n",
      "[0/25][2560/9765] Loss_D: 0.1411 Loss_G: 0.0380 Convergence: 0.1608 k= 0.017232 lr = 0.0001000\n",
      "[0/25][2570/9765] Loss_D: 0.1559 Loss_G: 0.0416 Convergence: 0.1783 k= 0.017337 lr = 0.0001000\n",
      "[0/25][2580/9765] Loss_D: 0.1388 Loss_G: 0.0521 Convergence: 0.1435 k= 0.017371 lr = 0.0001000\n",
      "[0/25][2590/9765] Loss_D: 0.1533 Loss_G: 0.0648 Convergence: 0.1572 k= 0.017444 lr = 0.0001000\n",
      "[0/25][2600/9765] Loss_D: 0.1463 Loss_G: 0.0442 Convergence: 0.1617 k= 0.017540 lr = 0.0001000\n",
      "[0/25][2610/9765] Loss_D: 0.1488 Loss_G: 0.0478 Convergence: 0.1619 k= 0.017570 lr = 0.0001000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][2620/9765] Loss_D: 0.1443 Loss_G: 0.0497 Convergence: 0.1534 k= 0.017605 lr = 0.0001000\n",
      "[0/25][2630/9765] Loss_D: 0.1425 Loss_G: 0.0523 Convergence: 0.1487 k= 0.017726 lr = 0.0001000\n",
      "[0/25][2640/9765] Loss_D: 0.1569 Loss_G: 0.0607 Convergence: 0.1602 k= 0.017745 lr = 0.0001000\n",
      "[0/25][2650/9765] Loss_D: 0.1501 Loss_G: 0.0446 Convergence: 0.1673 k= 0.017721 lr = 0.0001000\n",
      "[0/25][2660/9765] Loss_D: 0.1570 Loss_G: 0.0735 Convergence: 0.1684 k= 0.017695 lr = 0.0001000\n",
      "[0/25][2670/9765] Loss_D: 0.1473 Loss_G: 0.0499 Convergence: 0.1577 k= 0.017706 lr = 0.0001000\n",
      "[0/25][2680/9765] Loss_D: 0.1572 Loss_G: 0.0520 Convergence: 0.1694 k= 0.017781 lr = 0.0001000\n",
      "[0/25][2690/9765] Loss_D: 0.1471 Loss_G: 0.0527 Convergence: 0.1547 k= 0.017830 lr = 0.0001000\n",
      "[0/25][2700/9765] Loss_D: 0.1448 Loss_G: 0.0417 Convergence: 0.1623 k= 0.017892 lr = 0.0001000\n",
      "[0/25][2710/9765] Loss_D: 0.1548 Loss_G: 0.0551 Convergence: 0.1628 k= 0.017954 lr = 0.0001000\n",
      "[0/25][2720/9765] Loss_D: 0.1502 Loss_G: 0.0612 Convergence: 0.1518 k= 0.018024 lr = 0.0001000\n",
      "[0/25][2730/9765] Loss_D: 0.1358 Loss_G: 0.0654 Convergence: 0.1475 k= 0.018002 lr = 0.0001000\n",
      "[0/25][2740/9765] Loss_D: 0.1383 Loss_G: 0.0585 Convergence: 0.1422 k= 0.017977 lr = 0.0001000\n",
      "[0/25][2750/9765] Loss_D: 0.1681 Loss_G: 0.0506 Convergence: 0.1861 k= 0.018028 lr = 0.0001000\n",
      "[0/25][2760/9765] Loss_D: 0.1447 Loss_G: 0.0539 Convergence: 0.1500 k= 0.017989 lr = 0.0001000\n",
      "[0/25][2770/9765] Loss_D: 0.1547 Loss_G: 0.0579 Convergence: 0.1599 k= 0.018019 lr = 0.0001000\n",
      "[0/25][2780/9765] Loss_D: 0.1578 Loss_G: 0.0675 Convergence: 0.1628 k= 0.018078 lr = 0.0001000\n",
      "[0/25][2790/9765] Loss_D: 0.1398 Loss_G: 0.0536 Convergence: 0.1434 k= 0.018161 lr = 0.0001000\n",
      "[0/25][2800/9765] Loss_D: 0.1375 Loss_G: 0.0508 Convergence: 0.1435 k= 0.018209 lr = 0.0001000\n",
      "[0/25][2810/9765] Loss_D: 0.1468 Loss_G: 0.0663 Convergence: 0.1552 k= 0.018182 lr = 0.0001000\n",
      "[0/25][2820/9765] Loss_D: 0.1482 Loss_G: 0.0661 Convergence: 0.1556 k= 0.018153 lr = 0.0001000\n",
      "[0/25][2830/9765] Loss_D: 0.1405 Loss_G: 0.0618 Convergence: 0.1467 k= 0.018187 lr = 0.0001000\n",
      "[0/25][2840/9765] Loss_D: 0.1433 Loss_G: 0.0521 Convergence: 0.1498 k= 0.018099 lr = 0.0001000\n",
      "[0/25][2850/9765] Loss_D: 0.1425 Loss_G: 0.0546 Convergence: 0.1467 k= 0.018060 lr = 0.0001000\n",
      "[0/25][2860/9765] Loss_D: 0.1405 Loss_G: 0.0487 Convergence: 0.1492 k= 0.018103 lr = 0.0001000\n",
      "[0/25][2870/9765] Loss_D: 0.1489 Loss_G: 0.0575 Convergence: 0.1522 k= 0.018127 lr = 0.0001000\n",
      "[0/25][2880/9765] Loss_D: 0.1500 Loss_G: 0.0557 Convergence: 0.1554 k= 0.018206 lr = 0.0001000\n",
      "[0/25][2890/9765] Loss_D: 0.1422 Loss_G: 0.0574 Convergence: 0.1434 k= 0.018193 lr = 0.0001000\n",
      "[0/25][2900/9765] Loss_D: 0.1395 Loss_G: 0.0443 Convergence: 0.1527 k= 0.018235 lr = 0.0001000\n",
      "[0/25][2910/9765] Loss_D: 0.1497 Loss_G: 0.0582 Convergence: 0.1531 k= 0.018206 lr = 0.0001000\n",
      "[0/25][2920/9765] Loss_D: 0.1346 Loss_G: 0.0549 Convergence: 0.1363 k= 0.018265 lr = 0.0001000\n",
      "[0/25][2930/9765] Loss_D: 0.1481 Loss_G: 0.0505 Convergence: 0.1584 k= 0.018272 lr = 0.0001000\n",
      "[0/25][2940/9765] Loss_D: 0.1506 Loss_G: 0.0641 Convergence: 0.1550 k= 0.018301 lr = 0.0001000\n",
      "[0/25][2950/9765] Loss_D: 0.1374 Loss_G: 0.0514 Convergence: 0.1424 k= 0.018346 lr = 0.0001000\n",
      "[0/25][2960/9765] Loss_D: 0.1543 Loss_G: 0.0626 Convergence: 0.1557 k= 0.018349 lr = 0.0001000\n",
      "[0/25][2970/9765] Loss_D: 0.1509 Loss_G: 0.0512 Convergence: 0.1614 k= 0.018434 lr = 0.0001000\n",
      "[0/25][2980/9765] Loss_D: 0.1618 Loss_G: 0.0453 Convergence: 0.1824 k= 0.018509 lr = 0.0001000\n",
      "[0/25][2990/9765] Loss_D: 0.1495 Loss_G: 0.0403 Convergence: 0.1701 k= 0.018568 lr = 0.0001000\n",
      "[0/25][3000/9765] Loss_D: 0.1444 Loss_G: 0.0622 Convergence: 0.1495 k= 0.018587 lr = 0.0000950\n",
      "[0/25][3010/9765] Loss_D: 0.1556 Loss_G: 0.0729 Convergence: 0.1670 k= 0.018545 lr = 0.0000950\n",
      "[0/25][3020/9765] Loss_D: 0.1414 Loss_G: 0.0539 Convergence: 0.1453 k= 0.018540 lr = 0.0000950\n",
      "[0/25][3030/9765] Loss_D: 0.1423 Loss_G: 0.0491 Convergence: 0.1515 k= 0.018587 lr = 0.0000950\n",
      "[0/25][3040/9765] Loss_D: 0.1407 Loss_G: 0.0512 Convergence: 0.1477 k= 0.018617 lr = 0.0000950\n",
      "[0/25][3050/9765] Loss_D: 0.1554 Loss_G: 0.0977 Convergence: 0.1917 k= 0.018493 lr = 0.0000950\n",
      "[0/25][3060/9765] Loss_D: 0.1454 Loss_G: 0.0585 Convergence: 0.1468 k= 0.018473 lr = 0.0000950\n",
      "[0/25][3070/9765] Loss_D: 0.1512 Loss_G: 0.0500 Convergence: 0.1629 k= 0.018494 lr = 0.0000950\n",
      "[0/25][3080/9765] Loss_D: 0.1404 Loss_G: 0.0511 Convergence: 0.1467 k= 0.018547 lr = 0.0000950\n",
      "[0/25][3090/9765] Loss_D: 0.1386 Loss_G: 0.0519 Convergence: 0.1437 k= 0.018590 lr = 0.0000950\n",
      "[0/25][3100/9765] Loss_D: 0.1567 Loss_G: 0.0572 Convergence: 0.1638 k= 0.018576 lr = 0.0000950\n",
      "[0/25][3110/9765] Loss_D: 0.1577 Loss_G: 0.0608 Convergence: 0.1615 k= 0.018552 lr = 0.0000950\n",
      "[0/25][3120/9765] Loss_D: 0.1378 Loss_G: 0.0481 Convergence: 0.1462 k= 0.018592 lr = 0.0000950\n",
      "[0/25][3130/9765] Loss_D: 0.1625 Loss_G: 0.0804 Convergence: 0.1785 k= 0.018598 lr = 0.0000950\n",
      "[0/25][3140/9765] Loss_D: 0.1437 Loss_G: 0.0535 Convergence: 0.1490 k= 0.018670 lr = 0.0000950\n",
      "[0/25][3150/9765] Loss_D: 0.1469 Loss_G: 0.0673 Convergence: 0.1561 k= 0.018655 lr = 0.0000950\n",
      "[0/25][3160/9765] Loss_D: 0.1430 Loss_G: 0.0582 Convergence: 0.1445 k= 0.018685 lr = 0.0000950\n",
      "[0/25][3170/9765] Loss_D: 0.1502 Loss_G: 0.0554 Convergence: 0.1566 k= 0.018689 lr = 0.0000950\n",
      "[0/25][3180/9765] Loss_D: 0.1353 Loss_G: 0.0478 Convergence: 0.1432 k= 0.018729 lr = 0.0000950\n",
      "[0/25][3190/9765] Loss_D: 0.1403 Loss_G: 0.0455 Convergence: 0.1521 k= 0.018776 lr = 0.0000950\n",
      "[0/25][3200/9765] Loss_D: 0.1596 Loss_G: 0.0557 Convergence: 0.1692 k= 0.018848 lr = 0.0000950\n",
      "[0/25][3210/9765] Loss_D: 0.1454 Loss_G: 0.0467 Convergence: 0.1580 k= 0.018887 lr = 0.0000950\n",
      "[0/25][3220/9765] Loss_D: 0.1507 Loss_G: 0.0734 Convergence: 0.1644 k= 0.018880 lr = 0.0000950\n",
      "[0/25][3230/9765] Loss_D: 0.1546 Loss_G: 0.0669 Convergence: 0.1603 k= 0.018858 lr = 0.0000950\n",
      "[0/25][3240/9765] Loss_D: 0.1407 Loss_G: 0.0774 Convergence: 0.1623 k= 0.018865 lr = 0.0000950\n",
      "[0/25][3250/9765] Loss_D: 0.1399 Loss_G: 0.0478 Convergence: 0.1492 k= 0.018918 lr = 0.0000950\n",
      "[0/25][3260/9765] Loss_D: 0.1478 Loss_G: 0.0832 Convergence: 0.1724 k= 0.018949 lr = 0.0000950\n",
      "[0/25][3270/9765] Loss_D: 0.1475 Loss_G: 0.0560 Convergence: 0.1522 k= 0.018995 lr = 0.0000950\n",
      "[0/25][3280/9765] Loss_D: 0.1456 Loss_G: 0.0540 Convergence: 0.1509 k= 0.019063 lr = 0.0000950\n",
      "[0/25][3290/9765] Loss_D: 0.1474 Loss_G: 0.0431 Convergence: 0.1643 k= 0.019149 lr = 0.0000950\n",
      "[0/25][3300/9765] Loss_D: 0.1389 Loss_G: 0.0557 Convergence: 0.1400 k= 0.019218 lr = 0.0000950\n",
      "[0/25][3310/9765] Loss_D: 0.1453 Loss_G: 0.0526 Convergence: 0.1520 k= 0.019287 lr = 0.0000950\n",
      "[0/25][3320/9765] Loss_D: 0.1629 Loss_G: 0.0621 Convergence: 0.1674 k= 0.019304 lr = 0.0000950\n",
      "[0/25][3330/9765] Loss_D: 0.1458 Loss_G: 0.0455 Convergence: 0.1598 k= 0.019389 lr = 0.0000950\n",
      "[0/25][3340/9765] Loss_D: 0.1503 Loss_G: 0.0591 Convergence: 0.1526 k= 0.019422 lr = 0.0000950\n",
      "[0/25][3350/9765] Loss_D: 0.1525 Loss_G: 0.0485 Convergence: 0.1663 k= 0.019498 lr = 0.0000950\n",
      "[0/25][3360/9765] Loss_D: 0.1329 Loss_G: 0.0454 Convergence: 0.1419 k= 0.019588 lr = 0.0000950\n",
      "[0/25][3370/9765] Loss_D: 0.1445 Loss_G: 0.0461 Convergence: 0.1575 k= 0.019675 lr = 0.0000950\n",
      "[0/25][3380/9765] Loss_D: 0.1654 Loss_G: 0.0657 Convergence: 0.1672 k= 0.019713 lr = 0.0000950\n",
      "[0/25][3390/9765] Loss_D: 0.1467 Loss_G: 0.0513 Convergence: 0.1554 k= 0.019770 lr = 0.0000950\n",
      "[0/25][3400/9765] Loss_D: 0.1558 Loss_G: 0.0552 Convergence: 0.1641 k= 0.019829 lr = 0.0000950\n",
      "[0/25][3410/9765] Loss_D: 0.1345 Loss_G: 0.0453 Convergence: 0.1445 k= 0.019915 lr = 0.0000950\n",
      "[0/25][3420/9765] Loss_D: 0.1508 Loss_G: 0.0433 Convergence: 0.1691 k= 0.020032 lr = 0.0000950\n",
      "[0/25][3430/9765] Loss_D: 0.1540 Loss_G: 0.0427 Convergence: 0.1746 k= 0.020131 lr = 0.0000950\n",
      "[0/25][3440/9765] Loss_D: 0.1480 Loss_G: 0.0493 Convergence: 0.1595 k= 0.020161 lr = 0.0000950\n",
      "[0/25][3450/9765] Loss_D: 0.1396 Loss_G: 0.0515 Convergence: 0.1454 k= 0.020221 lr = 0.0000950\n",
      "[0/25][3460/9765] Loss_D: 0.1417 Loss_G: 0.0427 Convergence: 0.1572 k= 0.020318 lr = 0.0000950\n",
      "[0/25][3470/9765] Loss_D: 0.1340 Loss_G: 0.0523 Convergence: 0.1367 k= 0.020424 lr = 0.0000950\n",
      "[0/25][3480/9765] Loss_D: 0.1456 Loss_G: 0.0625 Convergence: 0.1505 k= 0.020420 lr = 0.0000950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][3490/9765] Loss_D: 0.1539 Loss_G: 0.0435 Convergence: 0.1734 k= 0.020513 lr = 0.0000950\n",
      "[0/25][3500/9765] Loss_D: 0.1392 Loss_G: 0.0682 Convergence: 0.1522 k= 0.020609 lr = 0.0000950\n",
      "[0/25][3510/9765] Loss_D: 0.1374 Loss_G: 0.0574 Convergence: 0.1404 k= 0.020674 lr = 0.0000950\n",
      "[0/25][3520/9765] Loss_D: 0.1393 Loss_G: 0.0448 Convergence: 0.1518 k= 0.020672 lr = 0.0000950\n",
      "[0/25][3530/9765] Loss_D: 0.1599 Loss_G: 0.0619 Convergence: 0.1633 k= 0.020767 lr = 0.0000950\n",
      "[0/25][3540/9765] Loss_D: 0.1396 Loss_G: 0.0435 Convergence: 0.1533 k= 0.020849 lr = 0.0000950\n",
      "[0/25][3550/9765] Loss_D: 0.1433 Loss_G: 0.0424 Convergence: 0.1597 k= 0.020896 lr = 0.0000950\n",
      "[0/25][3560/9765] Loss_D: 0.1435 Loss_G: 0.0524 Convergence: 0.1498 k= 0.021002 lr = 0.0000950\n",
      "[0/25][3570/9765] Loss_D: 0.1403 Loss_G: 0.0438 Convergence: 0.1542 k= 0.021071 lr = 0.0000950\n",
      "[0/25][3580/9765] Loss_D: 0.1478 Loss_G: 0.0569 Convergence: 0.1514 k= 0.021062 lr = 0.0000950\n",
      "[0/25][3590/9765] Loss_D: 0.1509 Loss_G: 0.0502 Convergence: 0.1624 k= 0.021139 lr = 0.0000950\n",
      "[0/25][3600/9765] Loss_D: 0.1482 Loss_G: 0.0490 Convergence: 0.1603 k= 0.021216 lr = 0.0000950\n",
      "[0/25][3610/9765] Loss_D: 0.1389 Loss_G: 0.0527 Convergence: 0.1432 k= 0.021212 lr = 0.0000950\n",
      "[0/25][3620/9765] Loss_D: 0.1378 Loss_G: 0.0490 Convergence: 0.1455 k= 0.021206 lr = 0.0000950\n",
      "[0/25][3630/9765] Loss_D: 0.1378 Loss_G: 0.0610 Convergence: 0.1443 k= 0.021262 lr = 0.0000950\n",
      "[0/25][3640/9765] Loss_D: 0.1481 Loss_G: 0.0476 Convergence: 0.1611 k= 0.021311 lr = 0.0000950\n",
      "[0/25][3650/9765] Loss_D: 0.1438 Loss_G: 0.0701 Convergence: 0.1569 k= 0.021388 lr = 0.0000950\n",
      "[0/25][3660/9765] Loss_D: 0.1447 Loss_G: 0.0472 Convergence: 0.1567 k= 0.021478 lr = 0.0000950\n",
      "[0/25][3670/9765] Loss_D: 0.1513 Loss_G: 0.0488 Convergence: 0.1645 k= 0.021520 lr = 0.0000950\n",
      "[0/25][3680/9765] Loss_D: 0.1419 Loss_G: 0.0437 Convergence: 0.1564 k= 0.021628 lr = 0.0000950\n",
      "[0/25][3690/9765] Loss_D: 0.1511 Loss_G: 0.0782 Convergence: 0.1695 k= 0.021698 lr = 0.0000950\n",
      "[0/25][3700/9765] Loss_D: 0.1390 Loss_G: 0.0606 Convergence: 0.1445 k= 0.021675 lr = 0.0000950\n",
      "[0/25][3710/9765] Loss_D: 0.1352 Loss_G: 0.0530 Convergence: 0.1382 k= 0.021772 lr = 0.0000950\n",
      "[0/25][3720/9765] Loss_D: 0.1472 Loss_G: 0.0561 Convergence: 0.1512 k= 0.021867 lr = 0.0000950\n",
      "[0/25][3730/9765] Loss_D: 0.1415 Loss_G: 0.0530 Convergence: 0.1465 k= 0.021950 lr = 0.0000950\n",
      "[0/25][3740/9765] Loss_D: 0.1411 Loss_G: 0.0518 Convergence: 0.1473 k= 0.022052 lr = 0.0000950\n",
      "[0/25][3750/9765] Loss_D: 0.1477 Loss_G: 0.0641 Convergence: 0.1533 k= 0.022096 lr = 0.0000950\n",
      "[0/25][3760/9765] Loss_D: 0.1530 Loss_G: 0.0442 Convergence: 0.1719 k= 0.022160 lr = 0.0000950\n",
      "[0/25][3770/9765] Loss_D: 0.1441 Loss_G: 0.0464 Convergence: 0.1569 k= 0.022219 lr = 0.0000950\n",
      "[0/25][3780/9765] Loss_D: 0.1352 Loss_G: 0.0451 Convergence: 0.1457 k= 0.022342 lr = 0.0000950\n",
      "[0/25][3790/9765] Loss_D: 0.1390 Loss_G: 0.0473 Convergence: 0.1487 k= 0.022405 lr = 0.0000950\n",
      "[0/25][3800/9765] Loss_D: 0.1351 Loss_G: 0.0410 Convergence: 0.1493 k= 0.022477 lr = 0.0000950\n",
      "[0/25][3810/9765] Loss_D: 0.1480 Loss_G: 0.0540 Convergence: 0.1549 k= 0.022578 lr = 0.0000950\n",
      "[0/25][3820/9765] Loss_D: 0.1456 Loss_G: 0.0446 Convergence: 0.1605 k= 0.022702 lr = 0.0000950\n",
      "[0/25][3830/9765] Loss_D: 0.1476 Loss_G: 0.0616 Convergence: 0.1510 k= 0.022750 lr = 0.0000950\n",
      "[0/25][3840/9765] Loss_D: 0.1304 Loss_G: 0.0435 Convergence: 0.1404 k= 0.022833 lr = 0.0000950\n",
      "[0/25][3850/9765] Loss_D: 0.1460 Loss_G: 0.0410 Convergence: 0.1649 k= 0.022986 lr = 0.0000950\n",
      "[0/25][3860/9765] Loss_D: 0.1417 Loss_G: 0.0422 Convergence: 0.1575 k= 0.023106 lr = 0.0000950\n",
      "[0/25][3870/9765] Loss_D: 0.1337 Loss_G: 0.0531 Convergence: 0.1358 k= 0.023173 lr = 0.0000950\n",
      "[0/25][3880/9765] Loss_D: 0.1426 Loss_G: 0.0554 Convergence: 0.1457 k= 0.023251 lr = 0.0000950\n",
      "[0/25][3890/9765] Loss_D: 0.1374 Loss_G: 0.0462 Convergence: 0.1478 k= 0.023305 lr = 0.0000950\n",
      "[0/25][3900/9765] Loss_D: 0.1337 Loss_G: 0.0409 Convergence: 0.1476 k= 0.023390 lr = 0.0000950\n",
      "[0/25][3910/9765] Loss_D: 0.1442 Loss_G: 0.0406 Convergence: 0.1627 k= 0.023465 lr = 0.0000950\n",
      "[0/25][3920/9765] Loss_D: 0.1388 Loss_G: 0.0439 Convergence: 0.1520 k= 0.023590 lr = 0.0000950\n",
      "[0/25][3930/9765] Loss_D: 0.1488 Loss_G: 0.0418 Convergence: 0.1678 k= 0.023715 lr = 0.0000950\n",
      "[0/25][3940/9765] Loss_D: 0.1418 Loss_G: 0.0440 Convergence: 0.1559 k= 0.023803 lr = 0.0000950\n",
      "[0/25][3950/9765] Loss_D: 0.1450 Loss_G: 0.0589 Convergence: 0.1465 k= 0.023872 lr = 0.0000950\n",
      "[0/25][3960/9765] Loss_D: 0.1537 Loss_G: 0.0773 Convergence: 0.1704 k= 0.023916 lr = 0.0000950\n",
      "[0/25][3970/9765] Loss_D: 0.1403 Loss_G: 0.0565 Convergence: 0.1415 k= 0.024007 lr = 0.0000950\n",
      "[0/25][3980/9765] Loss_D: 0.1434 Loss_G: 0.0451 Convergence: 0.1574 k= 0.024094 lr = 0.0000950\n",
      "[0/25][3990/9765] Loss_D: 0.1386 Loss_G: 0.0563 Convergence: 0.1401 k= 0.024154 lr = 0.0000950\n",
      "[0/25][4000/9765] Loss_D: 0.1374 Loss_G: 0.0427 Convergence: 0.1510 k= 0.024256 lr = 0.0000950\n",
      "[0/25][4010/9765] Loss_D: 0.1659 Loss_G: 0.0577 Convergence: 0.1763 k= 0.024346 lr = 0.0000950\n",
      "[0/25][4020/9765] Loss_D: 0.1456 Loss_G: 0.0514 Convergence: 0.1540 k= 0.024408 lr = 0.0000950\n",
      "[0/25][4030/9765] Loss_D: 0.1519 Loss_G: 0.0464 Convergence: 0.1686 k= 0.024481 lr = 0.0000950\n",
      "[0/25][4040/9765] Loss_D: 0.1480 Loss_G: 0.0552 Convergence: 0.1535 k= 0.024579 lr = 0.0000950\n",
      "[0/25][4050/9765] Loss_D: 0.1531 Loss_G: 0.0718 Convergence: 0.1644 k= 0.024623 lr = 0.0000950\n",
      "[0/25][4060/9765] Loss_D: 0.1547 Loss_G: 0.0513 Convergence: 0.1672 k= 0.024661 lr = 0.0000950\n",
      "[0/25][4070/9765] Loss_D: 0.1399 Loss_G: 0.0466 Convergence: 0.1508 k= 0.024740 lr = 0.0000950\n",
      "[0/25][4080/9765] Loss_D: 0.1456 Loss_G: 0.0558 Convergence: 0.1499 k= 0.024824 lr = 0.0000950\n",
      "[0/25][4090/9765] Loss_D: 0.1260 Loss_G: 0.0392 Convergence: 0.1389 k= 0.024920 lr = 0.0000950\n",
      "[0/25][4100/9765] Loss_D: 0.1419 Loss_G: 0.0570 Convergence: 0.1440 k= 0.024935 lr = 0.0000950\n",
      "[0/25][4110/9765] Loss_D: 0.1541 Loss_G: 0.0479 Convergence: 0.1697 k= 0.025030 lr = 0.0000950\n",
      "[0/25][4120/9765] Loss_D: 0.1340 Loss_G: 0.0525 Convergence: 0.1369 k= 0.025080 lr = 0.0000950\n",
      "[0/25][4130/9765] Loss_D: 0.1511 Loss_G: 0.0383 Convergence: 0.1753 k= 0.025111 lr = 0.0000950\n",
      "[0/25][4140/9765] Loss_D: 0.1402 Loss_G: 0.0466 Convergence: 0.1512 k= 0.025198 lr = 0.0000950\n",
      "[0/25][4150/9765] Loss_D: 0.1449 Loss_G: 0.0459 Convergence: 0.1583 k= 0.025299 lr = 0.0000950\n",
      "[0/25][4160/9765] Loss_D: 0.1379 Loss_G: 0.0496 Convergence: 0.1451 k= 0.025396 lr = 0.0000950\n",
      "[0/25][4170/9765] Loss_D: 0.1405 Loss_G: 0.0422 Convergence: 0.1559 k= 0.025523 lr = 0.0000950\n",
      "[0/25][4180/9765] Loss_D: 0.1434 Loss_G: 0.0524 Convergence: 0.1505 k= 0.025585 lr = 0.0000950\n",
      "[0/25][4190/9765] Loss_D: 0.1351 Loss_G: 0.0542 Convergence: 0.1366 k= 0.025686 lr = 0.0000950\n",
      "[0/25][4200/9765] Loss_D: 0.1519 Loss_G: 0.0477 Convergence: 0.1666 k= 0.025751 lr = 0.0000950\n",
      "[0/25][4210/9765] Loss_D: 0.1437 Loss_G: 0.0465 Convergence: 0.1567 k= 0.025824 lr = 0.0000950\n",
      "[0/25][4220/9765] Loss_D: 0.1425 Loss_G: 0.0532 Convergence: 0.1484 k= 0.025897 lr = 0.0000950\n",
      "[0/25][4230/9765] Loss_D: 0.1349 Loss_G: 0.0542 Convergence: 0.1370 k= 0.025964 lr = 0.0000950\n",
      "[0/25][4240/9765] Loss_D: 0.1403 Loss_G: 0.0471 Convergence: 0.1511 k= 0.026039 lr = 0.0000950\n",
      "[0/25][4250/9765] Loss_D: 0.1338 Loss_G: 0.0504 Convergence: 0.1388 k= 0.026152 lr = 0.0000950\n",
      "[0/25][4260/9765] Loss_D: 0.1452 Loss_G: 0.0448 Convergence: 0.1601 k= 0.026232 lr = 0.0000950\n",
      "[0/25][4270/9765] Loss_D: 0.1314 Loss_G: 0.0431 Convergence: 0.1427 k= 0.026280 lr = 0.0000950\n",
      "[0/25][4280/9765] Loss_D: 0.1394 Loss_G: 0.0424 Convergence: 0.1546 k= 0.026374 lr = 0.0000950\n",
      "[0/25][4290/9765] Loss_D: 0.1546 Loss_G: 0.0615 Convergence: 0.1569 k= 0.026444 lr = 0.0000950\n",
      "[0/25][4300/9765] Loss_D: 0.1396 Loss_G: 0.0418 Convergence: 0.1556 k= 0.026498 lr = 0.0000950\n",
      "[0/25][4310/9765] Loss_D: 0.1450 Loss_G: 0.0556 Convergence: 0.1490 k= 0.026588 lr = 0.0000950\n",
      "[0/25][4320/9765] Loss_D: 0.1321 Loss_G: 0.0644 Convergence: 0.1447 k= 0.026586 lr = 0.0000950\n",
      "[0/25][4330/9765] Loss_D: 0.1496 Loss_G: 0.0508 Convergence: 0.1606 k= 0.026637 lr = 0.0000950\n",
      "[0/25][4340/9765] Loss_D: 0.1437 Loss_G: 0.0441 Convergence: 0.1590 k= 0.026715 lr = 0.0000950\n",
      "[0/25][4350/9765] Loss_D: 0.1444 Loss_G: 0.0490 Convergence: 0.1548 k= 0.026795 lr = 0.0000950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][4360/9765] Loss_D: 0.1320 Loss_G: 0.0448 Convergence: 0.1421 k= 0.026880 lr = 0.0000950\n",
      "[0/25][4370/9765] Loss_D: 0.1411 Loss_G: 0.0555 Convergence: 0.1438 k= 0.026966 lr = 0.0000950\n",
      "[0/25][4380/9765] Loss_D: 0.1443 Loss_G: 0.0586 Convergence: 0.1459 k= 0.027013 lr = 0.0000950\n",
      "[0/25][4390/9765] Loss_D: 0.1403 Loss_G: 0.0453 Convergence: 0.1530 k= 0.027111 lr = 0.0000950\n",
      "[0/25][4400/9765] Loss_D: 0.1366 Loss_G: 0.0389 Convergence: 0.1537 k= 0.027226 lr = 0.0000950\n",
      "[0/25][4410/9765] Loss_D: 0.1357 Loss_G: 0.0697 Convergence: 0.1521 k= 0.027288 lr = 0.0000950\n",
      "[0/25][4420/9765] Loss_D: 0.1460 Loss_G: 0.0394 Convergence: 0.1668 k= 0.027397 lr = 0.0000950\n",
      "[0/25][4430/9765] Loss_D: 0.1345 Loss_G: 0.0523 Convergence: 0.1377 k= 0.027489 lr = 0.0000950\n",
      "[0/25][4440/9765] Loss_D: 0.1322 Loss_G: 0.0568 Convergence: 0.1369 k= 0.027513 lr = 0.0000950\n",
      "[0/25][4450/9765] Loss_D: 0.1433 Loss_G: 0.0585 Convergence: 0.1452 k= 0.027608 lr = 0.0000950\n",
      "[0/25][4460/9765] Loss_D: 0.1448 Loss_G: 0.0396 Convergence: 0.1650 k= 0.027724 lr = 0.0000950\n",
      "[0/25][4470/9765] Loss_D: 0.1426 Loss_G: 0.0404 Convergence: 0.1609 k= 0.027831 lr = 0.0000950\n",
      "[0/25][4480/9765] Loss_D: 0.1316 Loss_G: 0.0440 Convergence: 0.1418 k= 0.027957 lr = 0.0000950\n",
      "[0/25][4490/9765] Loss_D: 0.1432 Loss_G: 0.0420 Convergence: 0.1604 k= 0.028039 lr = 0.0000950\n",
      "[0/25][4500/9765] Loss_D: 0.1343 Loss_G: 0.0645 Convergence: 0.1459 k= 0.028100 lr = 0.0000950\n",
      "[0/25][4510/9765] Loss_D: 0.1330 Loss_G: 0.0427 Convergence: 0.1456 k= 0.028190 lr = 0.0000950\n",
      "[0/25][4520/9765] Loss_D: 0.1409 Loss_G: 0.0460 Convergence: 0.1528 k= 0.028282 lr = 0.0000950\n",
      "[0/25][4530/9765] Loss_D: 0.1459 Loss_G: 0.0459 Convergence: 0.1602 k= 0.028333 lr = 0.0000950\n",
      "[0/25][4540/9765] Loss_D: 0.1426 Loss_G: 0.0539 Convergence: 0.1475 k= 0.028383 lr = 0.0000950\n",
      "[0/25][4550/9765] Loss_D: 0.1377 Loss_G: 0.0463 Convergence: 0.1483 k= 0.028426 lr = 0.0000950\n",
      "[0/25][4560/9765] Loss_D: 0.1453 Loss_G: 0.0459 Convergence: 0.1592 k= 0.028518 lr = 0.0000950\n",
      "[0/25][4570/9765] Loss_D: 0.1443 Loss_G: 0.0444 Convergence: 0.1594 k= 0.028592 lr = 0.0000950\n",
      "[0/25][4580/9765] Loss_D: 0.1390 Loss_G: 0.0491 Convergence: 0.1472 k= 0.028683 lr = 0.0000950\n",
      "[0/25][4590/9765] Loss_D: 0.1477 Loss_G: 0.0424 Convergence: 0.1665 k= 0.028784 lr = 0.0000950\n",
      "[0/25][4600/9765] Loss_D: 0.1327 Loss_G: 0.0429 Convergence: 0.1451 k= 0.028876 lr = 0.0000950\n",
      "[0/25][4610/9765] Loss_D: 0.1316 Loss_G: 0.0478 Convergence: 0.1384 k= 0.028961 lr = 0.0000950\n",
      "[0/25][4620/9765] Loss_D: 0.1405 Loss_G: 0.0527 Convergence: 0.1459 k= 0.029034 lr = 0.0000950\n",
      "[0/25][4630/9765] Loss_D: 0.1353 Loss_G: 0.0480 Convergence: 0.1433 k= 0.029105 lr = 0.0000950\n",
      "[0/25][4640/9765] Loss_D: 0.1596 Loss_G: 0.0704 Convergence: 0.1671 k= 0.029140 lr = 0.0000950\n",
      "[0/25][4650/9765] Loss_D: 0.1461 Loss_G: 0.0456 Convergence: 0.1611 k= 0.029181 lr = 0.0000950\n",
      "[0/25][4660/9765] Loss_D: 0.1354 Loss_G: 0.0578 Convergence: 0.1397 k= 0.029261 lr = 0.0000950\n",
      "[0/25][4670/9765] Loss_D: 0.1383 Loss_G: 0.0437 Convergence: 0.1521 k= 0.029348 lr = 0.0000950\n",
      "[0/25][4680/9765] Loss_D: 0.1480 Loss_G: 0.0476 Convergence: 0.1618 k= 0.029406 lr = 0.0000950\n",
      "[0/25][4690/9765] Loss_D: 0.1451 Loss_G: 0.0429 Convergence: 0.1622 k= 0.029467 lr = 0.0000950\n",
      "[0/25][4700/9765] Loss_D: 0.1458 Loss_G: 0.0466 Convergence: 0.1595 k= 0.029553 lr = 0.0000950\n",
      "[0/25][4710/9765] Loss_D: 0.1403 Loss_G: 0.0481 Convergence: 0.1505 k= 0.029615 lr = 0.0000950\n",
      "[0/25][4720/9765] Loss_D: 0.1360 Loss_G: 0.0498 Convergence: 0.1426 k= 0.029653 lr = 0.0000950\n",
      "[0/25][4730/9765] Loss_D: 0.1269 Loss_G: 0.0448 Convergence: 0.1346 k= 0.029723 lr = 0.0000950\n",
      "[0/25][4740/9765] Loss_D: 0.1257 Loss_G: 0.0563 Convergence: 0.1325 k= 0.029796 lr = 0.0000950\n",
      "[0/25][4750/9765] Loss_D: 0.1381 Loss_G: 0.0622 Convergence: 0.1461 k= 0.029820 lr = 0.0000950\n",
      "[0/25][4760/9765] Loss_D: 0.1420 Loss_G: 0.0486 Convergence: 0.1521 k= 0.029836 lr = 0.0000950\n",
      "[0/25][4770/9765] Loss_D: 0.1372 Loss_G: 0.0429 Convergence: 0.1510 k= 0.029956 lr = 0.0000950\n",
      "[0/25][4780/9765] Loss_D: 0.1500 Loss_G: 0.0519 Convergence: 0.1600 k= 0.030006 lr = 0.0000950\n",
      "[0/25][4790/9765] Loss_D: 0.1383 Loss_G: 0.0484 Convergence: 0.1472 k= 0.030072 lr = 0.0000950\n",
      "[0/25][4800/9765] Loss_D: 0.1485 Loss_G: 0.0519 Convergence: 0.1579 k= 0.030158 lr = 0.0000950\n",
      "[0/25][4810/9765] Loss_D: 0.1319 Loss_G: 0.0442 Convergence: 0.1421 k= 0.030241 lr = 0.0000950\n",
      "[0/25][4820/9765] Loss_D: 0.1383 Loss_G: 0.0803 Convergence: 0.1642 k= 0.030279 lr = 0.0000950\n",
      "[0/25][4830/9765] Loss_D: 0.1504 Loss_G: 0.0501 Convergence: 0.1632 k= 0.030345 lr = 0.0000950\n",
      "[0/25][4840/9765] Loss_D: 0.1395 Loss_G: 0.0383 Convergence: 0.1589 k= 0.030447 lr = 0.0000950\n",
      "[0/25][4850/9765] Loss_D: 0.1370 Loss_G: 0.0466 Convergence: 0.1473 k= 0.030507 lr = 0.0000950\n",
      "[0/25][4860/9765] Loss_D: 0.1440 Loss_G: 0.0453 Convergence: 0.1590 k= 0.030578 lr = 0.0000950\n",
      "[0/25][4870/9765] Loss_D: 0.1295 Loss_G: 0.0450 Convergence: 0.1383 k= 0.030633 lr = 0.0000950\n",
      "[0/25][4880/9765] Loss_D: 0.1314 Loss_G: 0.0471 Convergence: 0.1387 k= 0.030728 lr = 0.0000950\n",
      "[0/25][4890/9765] Loss_D: 0.1385 Loss_G: 0.0492 Convergence: 0.1471 k= 0.030780 lr = 0.0000950\n",
      "[0/25][4900/9765] Loss_D: 0.1367 Loss_G: 0.0456 Convergence: 0.1478 k= 0.030814 lr = 0.0000950\n",
      "[0/25][4910/9765] Loss_D: 0.1560 Loss_G: 0.0607 Convergence: 0.1596 k= 0.030887 lr = 0.0000950\n",
      "[0/25][4920/9765] Loss_D: 0.1431 Loss_G: 0.0496 Convergence: 0.1529 k= 0.030914 lr = 0.0000950\n",
      "[0/25][4930/9765] Loss_D: 0.1273 Loss_G: 0.0471 Convergence: 0.1331 k= 0.030929 lr = 0.0000950\n",
      "[0/25][4940/9765] Loss_D: 0.1301 Loss_G: 0.0475 Convergence: 0.1367 k= 0.030973 lr = 0.0000950\n",
      "[0/25][4950/9765] Loss_D: 0.1437 Loss_G: 0.0435 Convergence: 0.1593 k= 0.031057 lr = 0.0000950\n",
      "[0/25][4960/9765] Loss_D: 0.1283 Loss_G: 0.0490 Convergence: 0.1326 k= 0.031077 lr = 0.0000950\n",
      "[0/25][4970/9765] Loss_D: 0.1407 Loss_G: 0.0549 Convergence: 0.1449 k= 0.031084 lr = 0.0000950\n",
      "[0/25][4980/9765] Loss_D: 0.1476 Loss_G: 0.0491 Convergence: 0.1600 k= 0.031161 lr = 0.0000950\n",
      "[0/25][4990/9765] Loss_D: 0.1329 Loss_G: 0.0535 Convergence: 0.1346 k= 0.031208 lr = 0.0000950\n",
      "[0/25][5000/9765] Loss_D: 0.1300 Loss_G: 0.0542 Convergence: 0.1330 k= 0.031290 lr = 0.0000950\n",
      "[0/25][5010/9765] Loss_D: 0.1436 Loss_G: 0.0536 Convergence: 0.1496 k= 0.031358 lr = 0.0000950\n",
      "[0/25][5020/9765] Loss_D: 0.1344 Loss_G: 0.0427 Convergence: 0.1481 k= 0.031444 lr = 0.0000950\n",
      "[0/25][5030/9765] Loss_D: 0.1333 Loss_G: 0.0484 Convergence: 0.1400 k= 0.031531 lr = 0.0000950\n",
      "[0/25][5040/9765] Loss_D: 0.1440 Loss_G: 0.0457 Convergence: 0.1577 k= 0.031638 lr = 0.0000950\n",
      "[0/25][5050/9765] Loss_D: 0.1416 Loss_G: 0.0664 Convergence: 0.1523 k= 0.031669 lr = 0.0000950\n",
      "[0/25][5060/9765] Loss_D: 0.1256 Loss_G: 0.0461 Convergence: 0.1318 k= 0.031725 lr = 0.0000950\n",
      "[0/25][5070/9765] Loss_D: 0.1419 Loss_G: 0.0405 Convergence: 0.1600 k= 0.031759 lr = 0.0000950\n",
      "[0/25][5080/9765] Loss_D: 0.1360 Loss_G: 0.0448 Convergence: 0.1477 k= 0.031830 lr = 0.0000950\n",
      "[0/25][5090/9765] Loss_D: 0.1376 Loss_G: 0.0473 Convergence: 0.1480 k= 0.031899 lr = 0.0000950\n",
      "[0/25][5100/9765] Loss_D: 0.1382 Loss_G: 0.0435 Convergence: 0.1527 k= 0.031971 lr = 0.0000950\n",
      "[0/25][5110/9765] Loss_D: 0.1315 Loss_G: 0.0504 Convergence: 0.1361 k= 0.032020 lr = 0.0000950\n",
      "[0/25][5120/9765] Loss_D: 0.1425 Loss_G: 0.0429 Convergence: 0.1590 k= 0.032066 lr = 0.0000950\n",
      "[0/25][5130/9765] Loss_D: 0.1396 Loss_G: 0.0514 Convergence: 0.1458 k= 0.032146 lr = 0.0000950\n",
      "[0/25][5140/9765] Loss_D: 0.1274 Loss_G: 0.0589 Convergence: 0.1364 k= 0.032163 lr = 0.0000950\n",
      "[0/25][5150/9765] Loss_D: 0.1471 Loss_G: 0.0493 Convergence: 0.1589 k= 0.032222 lr = 0.0000950\n",
      "[0/25][5160/9765] Loss_D: 0.1437 Loss_G: 0.0456 Convergence: 0.1578 k= 0.032279 lr = 0.0000950\n",
      "[0/25][5170/9765] Loss_D: 0.1381 Loss_G: 0.0436 Convergence: 0.1516 k= 0.032343 lr = 0.0000950\n",
      "[0/25][5180/9765] Loss_D: 0.1250 Loss_G: 0.0494 Convergence: 0.1276 k= 0.032444 lr = 0.0000950\n",
      "[0/25][5190/9765] Loss_D: 0.1414 Loss_G: 0.0544 Convergence: 0.1457 k= 0.032473 lr = 0.0000950\n",
      "[0/25][5200/9765] Loss_D: 0.1392 Loss_G: 0.0438 Convergence: 0.1535 k= 0.032488 lr = 0.0000950\n",
      "[0/25][5210/9765] Loss_D: 0.1318 Loss_G: 0.0526 Convergence: 0.1341 k= 0.032552 lr = 0.0000950\n",
      "[0/25][5220/9765] Loss_D: 0.1547 Loss_G: 0.0614 Convergence: 0.1580 k= 0.032567 lr = 0.0000950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][5230/9765] Loss_D: 0.1427 Loss_G: 0.0454 Convergence: 0.1565 k= 0.032627 lr = 0.0000950\n",
      "[0/25][5240/9765] Loss_D: 0.1370 Loss_G: 0.0523 Convergence: 0.1420 k= 0.032677 lr = 0.0000950\n",
      "[0/25][5250/9765] Loss_D: 0.1484 Loss_G: 0.0516 Convergence: 0.1589 k= 0.032718 lr = 0.0000950\n",
      "[0/25][5260/9765] Loss_D: 0.1313 Loss_G: 0.0427 Convergence: 0.1430 k= 0.032797 lr = 0.0000950\n",
      "[0/25][5270/9765] Loss_D: 0.1394 Loss_G: 0.0491 Convergence: 0.1480 k= 0.032876 lr = 0.0000950\n",
      "[0/25][5280/9765] Loss_D: 0.1445 Loss_G: 0.0506 Convergence: 0.1537 k= 0.032980 lr = 0.0000950\n",
      "[0/25][5290/9765] Loss_D: 0.1259 Loss_G: 0.0594 Convergence: 0.1360 k= 0.033016 lr = 0.0000950\n",
      "[0/25][5300/9765] Loss_D: 0.1455 Loss_G: 0.0547 Convergence: 0.1516 k= 0.033054 lr = 0.0000950\n",
      "[0/25][5310/9765] Loss_D: 0.1450 Loss_G: 0.0473 Convergence: 0.1581 k= 0.033111 lr = 0.0000950\n",
      "[0/25][5320/9765] Loss_D: 0.1256 Loss_G: 0.0477 Convergence: 0.1302 k= 0.033183 lr = 0.0000950\n",
      "[0/25][5330/9765] Loss_D: 0.1395 Loss_G: 0.0447 Convergence: 0.1528 k= 0.033269 lr = 0.0000950\n",
      "[0/25][5340/9765] Loss_D: 0.1367 Loss_G: 0.0456 Convergence: 0.1479 k= 0.033346 lr = 0.0000950\n",
      "[0/25][5350/9765] Loss_D: 0.1314 Loss_G: 0.0471 Convergence: 0.1395 k= 0.033435 lr = 0.0000950\n",
      "[0/25][5360/9765] Loss_D: 0.1334 Loss_G: 0.0455 Convergence: 0.1438 k= 0.033491 lr = 0.0000950\n",
      "[0/25][5370/9765] Loss_D: 0.1372 Loss_G: 0.0463 Convergence: 0.1479 k= 0.033536 lr = 0.0000950\n",
      "[0/25][5380/9765] Loss_D: 0.1328 Loss_G: 0.0457 Convergence: 0.1428 k= 0.033632 lr = 0.0000950\n",
      "[0/25][5390/9765] Loss_D: 0.1468 Loss_G: 0.0483 Convergence: 0.1591 k= 0.033730 lr = 0.0000950\n",
      "[0/25][5400/9765] Loss_D: 0.1430 Loss_G: 0.0485 Convergence: 0.1543 k= 0.033800 lr = 0.0000950\n",
      "[0/25][5410/9765] Loss_D: 0.1420 Loss_G: 0.0494 Convergence: 0.1517 k= 0.033848 lr = 0.0000950\n",
      "[0/25][5420/9765] Loss_D: 0.1348 Loss_G: 0.0441 Convergence: 0.1467 k= 0.033940 lr = 0.0000950\n",
      "[0/25][5430/9765] Loss_D: 0.1352 Loss_G: 0.0498 Convergence: 0.1421 k= 0.033985 lr = 0.0000950\n",
      "[0/25][5440/9765] Loss_D: 0.1386 Loss_G: 0.0506 Convergence: 0.1458 k= 0.033991 lr = 0.0000950\n",
      "[0/25][5450/9765] Loss_D: 0.1368 Loss_G: 0.0475 Convergence: 0.1461 k= 0.034045 lr = 0.0000950\n",
      "[0/25][5460/9765] Loss_D: 0.1331 Loss_G: 0.0620 Convergence: 0.1427 k= 0.034138 lr = 0.0000950\n",
      "[0/25][5470/9765] Loss_D: 0.1372 Loss_G: 0.0461 Convergence: 0.1496 k= 0.034162 lr = 0.0000950\n",
      "[0/25][5480/9765] Loss_D: 0.1348 Loss_G: 0.0565 Convergence: 0.1386 k= 0.034202 lr = 0.0000950\n",
      "[0/25][5490/9765] Loss_D: 0.1355 Loss_G: 0.0480 Convergence: 0.1440 k= 0.034263 lr = 0.0000950\n",
      "[0/25][5500/9765] Loss_D: 0.1457 Loss_G: 0.0491 Convergence: 0.1573 k= 0.034230 lr = 0.0000950\n",
      "[0/25][5510/9765] Loss_D: 0.1506 Loss_G: 0.0643 Convergence: 0.1558 k= 0.034271 lr = 0.0000950\n",
      "[0/25][5520/9765] Loss_D: 0.1383 Loss_G: 0.0563 Convergence: 0.1403 k= 0.034287 lr = 0.0000950\n",
      "[0/25][5530/9765] Loss_D: 0.1426 Loss_G: 0.0500 Convergence: 0.1518 k= 0.034319 lr = 0.0000950\n",
      "[0/25][5540/9765] Loss_D: 0.1340 Loss_G: 0.0515 Convergence: 0.1389 k= 0.034333 lr = 0.0000950\n",
      "[0/25][5550/9765] Loss_D: 0.1387 Loss_G: 0.0541 Convergence: 0.1421 k= 0.034346 lr = 0.0000950\n",
      "[0/25][5560/9765] Loss_D: 0.1383 Loss_G: 0.0532 Convergence: 0.1429 k= 0.034376 lr = 0.0000950\n",
      "[0/25][5570/9765] Loss_D: 0.1541 Loss_G: 0.0467 Convergence: 0.1713 k= 0.034441 lr = 0.0000950\n",
      "[0/25][5580/9765] Loss_D: 0.1420 Loss_G: 0.0563 Convergence: 0.1462 k= 0.034350 lr = 0.0000950\n",
      "[0/25][5590/9765] Loss_D: 0.1231 Loss_G: 0.0477 Convergence: 0.1268 k= 0.034400 lr = 0.0000950\n",
      "[0/25][5600/9765] Loss_D: 0.1432 Loss_G: 0.0609 Convergence: 0.1477 k= 0.034457 lr = 0.0000950\n",
      "[0/25][5610/9765] Loss_D: 0.1315 Loss_G: 0.0512 Convergence: 0.1354 k= 0.034494 lr = 0.0000950\n",
      "[0/25][5620/9765] Loss_D: 0.1286 Loss_G: 0.0530 Convergence: 0.1313 k= 0.034496 lr = 0.0000950\n",
      "[0/25][5630/9765] Loss_D: 0.1341 Loss_G: 0.0516 Convergence: 0.1389 k= 0.034525 lr = 0.0000950\n",
      "[0/25][5640/9765] Loss_D: 0.1248 Loss_G: 0.0612 Convergence: 0.1370 k= 0.034530 lr = 0.0000950\n",
      "[0/25][5650/9765] Loss_D: 0.1307 Loss_G: 0.0550 Convergence: 0.1344 k= 0.034535 lr = 0.0000950\n",
      "[0/25][5660/9765] Loss_D: 0.1304 Loss_G: 0.0615 Convergence: 0.1408 k= 0.034523 lr = 0.0000950\n",
      "[0/25][5670/9765] Loss_D: 0.1297 Loss_G: 0.0465 Convergence: 0.1376 k= 0.034525 lr = 0.0000950\n",
      "[0/25][5680/9765] Loss_D: 0.1242 Loss_G: 0.0461 Convergence: 0.1305 k= 0.034501 lr = 0.0000950\n",
      "[0/25][5690/9765] Loss_D: 0.1318 Loss_G: 0.0926 Convergence: 0.1728 k= 0.034457 lr = 0.0000950\n",
      "[0/25][5700/9765] Loss_D: 0.1379 Loss_G: 0.0565 Convergence: 0.1403 k= 0.034456 lr = 0.0000950\n",
      "[0/25][5710/9765] Loss_D: 0.1272 Loss_G: 0.0469 Convergence: 0.1333 k= 0.034452 lr = 0.0000950\n",
      "[0/25][5720/9765] Loss_D: 0.1302 Loss_G: 0.0421 Convergence: 0.1426 k= 0.034468 lr = 0.0000950\n",
      "[0/25][5730/9765] Loss_D: 0.1195 Loss_G: 0.0513 Convergence: 0.1240 k= 0.034386 lr = 0.0000950\n",
      "[0/25][5740/9765] Loss_D: 0.1415 Loss_G: 0.0540 Convergence: 0.1468 k= 0.034400 lr = 0.0000950\n",
      "[0/25][5750/9765] Loss_D: 0.1374 Loss_G: 0.0477 Convergence: 0.1471 k= 0.034384 lr = 0.0000950\n",
      "[0/25][5760/9765] Loss_D: 0.1352 Loss_G: 0.0488 Convergence: 0.1431 k= 0.034408 lr = 0.0000950\n",
      "[0/25][5770/9765] Loss_D: 0.1290 Loss_G: 0.0492 Convergence: 0.1341 k= 0.034446 lr = 0.0000950\n",
      "[0/25][5780/9765] Loss_D: 0.1358 Loss_G: 0.0542 Convergence: 0.1381 k= 0.034496 lr = 0.0000950\n",
      "[0/25][5790/9765] Loss_D: 0.1174 Loss_G: 0.0438 Convergence: 0.1225 k= 0.034554 lr = 0.0000950\n",
      "[0/25][5800/9765] Loss_D: 0.1281 Loss_G: 0.0573 Convergence: 0.1350 k= 0.034564 lr = 0.0000950\n",
      "[0/25][5810/9765] Loss_D: 0.1300 Loss_G: 0.0632 Convergence: 0.1422 k= 0.034584 lr = 0.0000950\n",
      "[0/25][5820/9765] Loss_D: 0.1156 Loss_G: 0.0626 Convergence: 0.1329 k= 0.034521 lr = 0.0000950\n",
      "[0/25][5830/9765] Loss_D: 0.1324 Loss_G: 0.0579 Convergence: 0.1382 k= 0.034544 lr = 0.0000950\n",
      "[0/25][5840/9765] Loss_D: 0.1340 Loss_G: 0.0539 Convergence: 0.1365 k= 0.034530 lr = 0.0000950\n",
      "[0/25][5850/9765] Loss_D: 0.1315 Loss_G: 0.0486 Convergence: 0.1375 k= 0.034518 lr = 0.0000950\n",
      "[0/25][5860/9765] Loss_D: 0.1262 Loss_G: 0.0398 Convergence: 0.1391 k= 0.034550 lr = 0.0000950\n",
      "[0/25][5870/9765] Loss_D: 0.1240 Loss_G: 0.0473 Convergence: 0.1289 k= 0.034577 lr = 0.0000950\n",
      "[0/25][5880/9765] Loss_D: 0.1295 Loss_G: 0.0482 Convergence: 0.1354 k= 0.034582 lr = 0.0000950\n",
      "[0/25][5890/9765] Loss_D: 0.1306 Loss_G: 0.0411 Convergence: 0.1440 k= 0.034597 lr = 0.0000950\n",
      "[0/25][5900/9765] Loss_D: 0.1248 Loss_G: 0.0436 Convergence: 0.1331 k= 0.034627 lr = 0.0000950\n",
      "[0/25][5910/9765] Loss_D: 0.1399 Loss_G: 0.0480 Convergence: 0.1500 k= 0.034658 lr = 0.0000950\n",
      "[0/25][5920/9765] Loss_D: 0.1225 Loss_G: 0.0582 Convergence: 0.1325 k= 0.034659 lr = 0.0000950\n",
      "[0/25][5930/9765] Loss_D: 0.1222 Loss_G: 0.0517 Convergence: 0.1262 k= 0.034652 lr = 0.0000950\n",
      "[0/25][5940/9765] Loss_D: 0.1345 Loss_G: 0.0461 Convergence: 0.1443 k= 0.034685 lr = 0.0000950\n",
      "[0/25][5950/9765] Loss_D: 0.1241 Loss_G: 0.0556 Convergence: 0.1310 k= 0.034723 lr = 0.0000950\n",
      "[0/25][5960/9765] Loss_D: 0.1233 Loss_G: 0.0492 Convergence: 0.1256 k= 0.034743 lr = 0.0000950\n",
      "[0/25][5970/9765] Loss_D: 0.1352 Loss_G: 0.0466 Convergence: 0.1450 k= 0.034798 lr = 0.0000950\n",
      "[0/25][5980/9765] Loss_D: 0.1199 Loss_G: 0.0431 Convergence: 0.1272 k= 0.034849 lr = 0.0000950\n",
      "[0/25][5990/9765] Loss_D: 0.1314 Loss_G: 0.0446 Convergence: 0.1415 k= 0.034900 lr = 0.0000950\n",
      "[0/25][6000/9765] Loss_D: 0.1339 Loss_G: 0.0622 Convergence: 0.1438 k= 0.034879 lr = 0.0000902\n",
      "[0/25][6010/9765] Loss_D: 0.1229 Loss_G: 0.0446 Convergence: 0.1297 k= 0.034908 lr = 0.0000902\n",
      "[0/25][6020/9765] Loss_D: 0.1268 Loss_G: 0.0410 Convergence: 0.1388 k= 0.034899 lr = 0.0000902\n",
      "[0/25][6030/9765] Loss_D: 0.1239 Loss_G: 0.0439 Convergence: 0.1318 k= 0.034961 lr = 0.0000902\n",
      "[0/25][6040/9765] Loss_D: 0.1252 Loss_G: 0.0418 Convergence: 0.1356 k= 0.035033 lr = 0.0000902\n",
      "[0/25][6050/9765] Loss_D: 0.1300 Loss_G: 0.0424 Convergence: 0.1419 k= 0.035047 lr = 0.0000902\n",
      "[0/25][6060/9765] Loss_D: 0.1245 Loss_G: 0.0501 Convergence: 0.1259 k= 0.035117 lr = 0.0000902\n",
      "[0/25][6070/9765] Loss_D: 0.1347 Loss_G: 0.0449 Convergence: 0.1458 k= 0.035162 lr = 0.0000902\n",
      "[0/25][6080/9765] Loss_D: 0.1308 Loss_G: 0.0509 Convergence: 0.1345 k= 0.035247 lr = 0.0000902\n",
      "[0/25][6090/9765] Loss_D: 0.1491 Loss_G: 0.0474 Convergence: 0.1642 k= 0.035261 lr = 0.0000902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][6100/9765] Loss_D: 0.1344 Loss_G: 0.0555 Convergence: 0.1373 k= 0.035308 lr = 0.0000902\n",
      "[0/25][6110/9765] Loss_D: 0.1279 Loss_G: 0.0591 Convergence: 0.1368 k= 0.035346 lr = 0.0000902\n",
      "[0/25][6120/9765] Loss_D: 0.1352 Loss_G: 0.0563 Convergence: 0.1384 k= 0.035385 lr = 0.0000902\n",
      "[0/25][6130/9765] Loss_D: 0.1306 Loss_G: 0.0500 Convergence: 0.1350 k= 0.035427 lr = 0.0000902\n",
      "[0/25][6140/9765] Loss_D: 0.1081 Loss_G: 0.0385 Convergence: 0.1146 k= 0.035503 lr = 0.0000902\n",
      "[0/25][6150/9765] Loss_D: 0.1317 Loss_G: 0.0615 Convergence: 0.1413 k= 0.035544 lr = 0.0000902\n",
      "[0/25][6160/9765] Loss_D: 0.1203 Loss_G: 0.0417 Convergence: 0.1292 k= 0.035568 lr = 0.0000902\n",
      "[0/25][6170/9765] Loss_D: 0.1236 Loss_G: 0.0539 Convergence: 0.1289 k= 0.035616 lr = 0.0000902\n",
      "[0/25][6180/9765] Loss_D: 0.1300 Loss_G: 0.0420 Convergence: 0.1419 k= 0.035689 lr = 0.0000902\n",
      "[0/25][6190/9765] Loss_D: 0.1335 Loss_G: 0.0418 Convergence: 0.1475 k= 0.035774 lr = 0.0000902\n",
      "[0/25][6200/9765] Loss_D: 0.1279 Loss_G: 0.0429 Convergence: 0.1384 k= 0.035826 lr = 0.0000902\n",
      "[0/25][6210/9765] Loss_D: 0.1259 Loss_G: 0.0424 Convergence: 0.1364 k= 0.035857 lr = 0.0000902\n",
      "[0/25][6220/9765] Loss_D: 0.1227 Loss_G: 0.0368 Convergence: 0.1373 k= 0.035899 lr = 0.0000902\n",
      "[0/25][6230/9765] Loss_D: 0.1346 Loss_G: 0.0458 Convergence: 0.1449 k= 0.035963 lr = 0.0000902\n",
      "[0/25][6240/9765] Loss_D: 0.1293 Loss_G: 0.0466 Convergence: 0.1364 k= 0.035970 lr = 0.0000902\n",
      "[0/25][6250/9765] Loss_D: 0.1292 Loss_G: 0.0480 Convergence: 0.1352 k= 0.035984 lr = 0.0000902\n",
      "[0/25][6260/9765] Loss_D: 0.1258 Loss_G: 0.0429 Convergence: 0.1352 k= 0.036019 lr = 0.0000902\n",
      "[0/25][6270/9765] Loss_D: 0.1213 Loss_G: 0.0446 Convergence: 0.1280 k= 0.036109 lr = 0.0000902\n",
      "[0/25][6280/9765] Loss_D: 0.1239 Loss_G: 0.0426 Convergence: 0.1333 k= 0.036133 lr = 0.0000902\n",
      "[0/25][6290/9765] Loss_D: 0.1273 Loss_G: 0.0535 Convergence: 0.1308 k= 0.036188 lr = 0.0000902\n",
      "[0/25][6300/9765] Loss_D: 0.1213 Loss_G: 0.0405 Convergence: 0.1314 k= 0.036240 lr = 0.0000902\n",
      "[0/25][6310/9765] Loss_D: 0.1331 Loss_G: 0.0591 Convergence: 0.1399 k= 0.036280 lr = 0.0000902\n",
      "[0/25][6320/9765] Loss_D: 0.1108 Loss_G: 0.0386 Convergence: 0.1182 k= 0.036363 lr = 0.0000902\n",
      "[0/25][6330/9765] Loss_D: 0.1148 Loss_G: 0.0524 Convergence: 0.1221 k= 0.036424 lr = 0.0000902\n",
      "[0/25][6340/9765] Loss_D: 0.1287 Loss_G: 0.0518 Convergence: 0.1308 k= 0.036458 lr = 0.0000902\n",
      "[0/25][6350/9765] Loss_D: 0.1161 Loss_G: 0.0381 Convergence: 0.1269 k= 0.036523 lr = 0.0000902\n",
      "[0/25][6360/9765] Loss_D: 0.1125 Loss_G: 0.0371 Convergence: 0.1226 k= 0.036580 lr = 0.0000902\n",
      "[0/25][6370/9765] Loss_D: 0.1319 Loss_G: 0.0384 Convergence: 0.1487 k= 0.036663 lr = 0.0000902\n",
      "[0/25][6380/9765] Loss_D: 0.1231 Loss_G: 0.0434 Convergence: 0.1310 k= 0.036743 lr = 0.0000902\n",
      "[0/25][6390/9765] Loss_D: 0.1331 Loss_G: 0.0466 Convergence: 0.1422 k= 0.036799 lr = 0.0000902\n",
      "[0/25][6400/9765] Loss_D: 0.1241 Loss_G: 0.0392 Convergence: 0.1365 k= 0.036886 lr = 0.0000902\n",
      "[0/25][6410/9765] Loss_D: 0.1169 Loss_G: 0.0464 Convergence: 0.1193 k= 0.036960 lr = 0.0000902\n",
      "[0/25][6420/9765] Loss_D: 0.1169 Loss_G: 0.0393 Convergence: 0.1264 k= 0.037053 lr = 0.0000902\n",
      "[0/25][6430/9765] Loss_D: 0.1303 Loss_G: 0.0446 Convergence: 0.1399 k= 0.037146 lr = 0.0000902\n",
      "[0/25][6440/9765] Loss_D: 0.1443 Loss_G: 0.0462 Convergence: 0.1588 k= 0.037147 lr = 0.0000902\n",
      "[0/25][6450/9765] Loss_D: 0.1330 Loss_G: 0.0757 Convergence: 0.1568 k= 0.037050 lr = 0.0000902\n",
      "[0/25][6460/9765] Loss_D: 0.1264 Loss_G: 0.0381 Convergence: 0.1407 k= 0.036973 lr = 0.0000902\n",
      "[0/25][6470/9765] Loss_D: 0.1282 Loss_G: 0.0547 Convergence: 0.1326 k= 0.037020 lr = 0.0000902\n",
      "[0/25][6480/9765] Loss_D: 0.1259 Loss_G: 0.0484 Convergence: 0.1299 k= 0.037087 lr = 0.0000902\n",
      "[0/25][6490/9765] Loss_D: 0.1372 Loss_G: 0.0482 Convergence: 0.1461 k= 0.037152 lr = 0.0000902\n",
      "[0/25][6500/9765] Loss_D: 0.1267 Loss_G: 0.0379 Convergence: 0.1416 k= 0.037251 lr = 0.0000902\n",
      "[0/25][6510/9765] Loss_D: 0.1332 Loss_G: 0.0409 Convergence: 0.1477 k= 0.037335 lr = 0.0000902\n",
      "[0/25][6520/9765] Loss_D: 0.1210 Loss_G: 0.0416 Convergence: 0.1301 k= 0.037404 lr = 0.0000902\n",
      "[0/25][6530/9765] Loss_D: 0.1244 Loss_G: 0.0607 Convergence: 0.1362 k= 0.037454 lr = 0.0000902\n",
      "[0/25][6540/9765] Loss_D: 0.1347 Loss_G: 0.0452 Convergence: 0.1460 k= 0.037460 lr = 0.0000902\n",
      "[0/25][6550/9765] Loss_D: 0.1175 Loss_G: 0.0377 Convergence: 0.1297 k= 0.037482 lr = 0.0000902\n",
      "[0/25][6560/9765] Loss_D: 0.1205 Loss_G: 0.0362 Convergence: 0.1349 k= 0.037553 lr = 0.0000902\n",
      "[0/25][6570/9765] Loss_D: 0.1348 Loss_G: 0.0497 Convergence: 0.1415 k= 0.037608 lr = 0.0000902\n",
      "[0/25][6580/9765] Loss_D: 0.1327 Loss_G: 0.0442 Convergence: 0.1445 k= 0.037667 lr = 0.0000902\n",
      "[0/25][6590/9765] Loss_D: 0.1356 Loss_G: 0.0502 Convergence: 0.1419 k= 0.037697 lr = 0.0000902\n",
      "[0/25][6600/9765] Loss_D: 0.1194 Loss_G: 0.0532 Convergence: 0.1257 k= 0.037734 lr = 0.0000902\n",
      "[0/25][6610/9765] Loss_D: 0.1233 Loss_G: 0.0369 Convergence: 0.1385 k= 0.037757 lr = 0.0000902\n",
      "[0/25][6620/9765] Loss_D: 0.1231 Loss_G: 0.0419 Convergence: 0.1329 k= 0.037834 lr = 0.0000902\n",
      "[0/25][6630/9765] Loss_D: 0.1218 Loss_G: 0.0382 Convergence: 0.1342 k= 0.037922 lr = 0.0000902\n",
      "[0/25][6640/9765] Loss_D: 0.1228 Loss_G: 0.0412 Convergence: 0.1326 k= 0.038005 lr = 0.0000902\n",
      "[0/25][6650/9765] Loss_D: 0.1334 Loss_G: 0.0568 Convergence: 0.1376 k= 0.038084 lr = 0.0000902\n",
      "[0/25][6660/9765] Loss_D: 0.1369 Loss_G: 0.0531 Convergence: 0.1413 k= 0.038045 lr = 0.0000902\n",
      "[0/25][6670/9765] Loss_D: 0.1200 Loss_G: 0.0441 Convergence: 0.1262 k= 0.038083 lr = 0.0000902\n",
      "[0/25][6680/9765] Loss_D: 0.1206 Loss_G: 0.0474 Convergence: 0.1239 k= 0.038104 lr = 0.0000902\n",
      "[0/25][6690/9765] Loss_D: 0.1264 Loss_G: 0.0423 Convergence: 0.1366 k= 0.038201 lr = 0.0000902\n",
      "[0/25][6700/9765] Loss_D: 0.1133 Loss_G: 0.0495 Convergence: 0.1183 k= 0.038262 lr = 0.0000902\n",
      "[0/25][6710/9765] Loss_D: 0.1261 Loss_G: 0.0522 Convergence: 0.1286 k= 0.038343 lr = 0.0000902\n",
      "[0/25][6720/9765] Loss_D: 0.1356 Loss_G: 0.0434 Convergence: 0.1494 k= 0.038424 lr = 0.0000902\n",
      "[0/25][6730/9765] Loss_D: 0.1279 Loss_G: 0.0422 Convergence: 0.1393 k= 0.038488 lr = 0.0000902\n",
      "[0/25][6740/9765] Loss_D: 0.1317 Loss_G: 0.0560 Convergence: 0.1358 k= 0.038539 lr = 0.0000902\n",
      "[0/25][6750/9765] Loss_D: 0.1187 Loss_G: 0.0377 Convergence: 0.1315 k= 0.038584 lr = 0.0000902\n",
      "[0/25][6760/9765] Loss_D: 0.1167 Loss_G: 0.0590 Convergence: 0.1300 k= 0.038589 lr = 0.0000902\n",
      "[0/25][6770/9765] Loss_D: 0.1151 Loss_G: 0.0549 Convergence: 0.1250 k= 0.038636 lr = 0.0000902\n",
      "[0/25][6780/9765] Loss_D: 0.1189 Loss_G: 0.0335 Convergence: 0.1351 k= 0.038672 lr = 0.0000902\n",
      "[0/25][6790/9765] Loss_D: 0.1353 Loss_G: 0.0598 Convergence: 0.1420 k= 0.038743 lr = 0.0000902\n",
      "[0/25][6800/9765] Loss_D: 0.1343 Loss_G: 0.0550 Convergence: 0.1365 k= 0.038751 lr = 0.0000902\n",
      "[0/25][6810/9765] Loss_D: 0.1253 Loss_G: 0.0407 Convergence: 0.1368 k= 0.038780 lr = 0.0000902\n",
      "[0/25][6820/9765] Loss_D: 0.1292 Loss_G: 0.0397 Convergence: 0.1438 k= 0.038847 lr = 0.0000902\n",
      "[0/25][6830/9765] Loss_D: 0.1167 Loss_G: 0.0346 Convergence: 0.1312 k= 0.038905 lr = 0.0000902\n",
      "[0/25][6840/9765] Loss_D: 0.1144 Loss_G: 0.0412 Convergence: 0.1213 k= 0.038994 lr = 0.0000902\n",
      "[0/25][6850/9765] Loss_D: 0.1272 Loss_G: 0.0652 Convergence: 0.1425 k= 0.039046 lr = 0.0000902\n",
      "[0/25][6860/9765] Loss_D: 0.1268 Loss_G: 0.0515 Convergence: 0.1288 k= 0.039093 lr = 0.0000902\n",
      "[0/25][6870/9765] Loss_D: 0.1298 Loss_G: 0.0448 Convergence: 0.1399 k= 0.039124 lr = 0.0000902\n",
      "[0/25][6880/9765] Loss_D: 0.1274 Loss_G: 0.0565 Convergence: 0.1341 k= 0.039105 lr = 0.0000902\n",
      "[0/25][6890/9765] Loss_D: 0.1129 Loss_G: 0.0329 Convergence: 0.1274 k= 0.039185 lr = 0.0000902\n",
      "[0/25][6900/9765] Loss_D: 0.1381 Loss_G: 0.0424 Convergence: 0.1536 k= 0.039233 lr = 0.0000902\n",
      "[0/25][6910/9765] Loss_D: 0.1176 Loss_G: 0.0379 Convergence: 0.1292 k= 0.039264 lr = 0.0000902\n",
      "[0/25][6920/9765] Loss_D: 0.1201 Loss_G: 0.0370 Convergence: 0.1337 k= 0.039353 lr = 0.0000902\n",
      "[0/25][6930/9765] Loss_D: 0.1272 Loss_G: 0.0346 Convergence: 0.1458 k= 0.039450 lr = 0.0000902\n",
      "[0/25][6940/9765] Loss_D: 0.1215 Loss_G: 0.0382 Convergence: 0.1343 k= 0.039542 lr = 0.0000902\n",
      "[0/25][6950/9765] Loss_D: 0.1127 Loss_G: 0.0390 Convergence: 0.1211 k= 0.039636 lr = 0.0000902\n",
      "[0/25][6960/9765] Loss_D: 0.1131 Loss_G: 0.0351 Convergence: 0.1256 k= 0.039738 lr = 0.0000902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][6970/9765] Loss_D: 0.1199 Loss_G: 0.0355 Convergence: 0.1348 k= 0.039784 lr = 0.0000902\n",
      "[0/25][6980/9765] Loss_D: 0.1190 Loss_G: 0.0364 Convergence: 0.1326 k= 0.039844 lr = 0.0000902\n",
      "[0/25][6990/9765] Loss_D: 0.1137 Loss_G: 0.0380 Convergence: 0.1236 k= 0.039898 lr = 0.0000902\n",
      "[0/25][7000/9765] Loss_D: 0.1154 Loss_G: 0.0438 Convergence: 0.1195 k= 0.039964 lr = 0.0000902\n",
      "[0/25][7010/9765] Loss_D: 0.1444 Loss_G: 0.0439 Convergence: 0.1614 k= 0.040045 lr = 0.0000902\n",
      "[0/25][7020/9765] Loss_D: 0.1315 Loss_G: 0.0454 Convergence: 0.1409 k= 0.040108 lr = 0.0000902\n",
      "[0/25][7030/9765] Loss_D: 0.1146 Loss_G: 0.0382 Convergence: 0.1249 k= 0.040200 lr = 0.0000902\n",
      "[0/25][7040/9765] Loss_D: 0.1279 Loss_G: 0.0537 Convergence: 0.1313 k= 0.040266 lr = 0.0000902\n",
      "[0/25][7050/9765] Loss_D: 0.1232 Loss_G: 0.0567 Convergence: 0.1314 k= 0.040342 lr = 0.0000902\n",
      "[0/25][7060/9765] Loss_D: 0.1238 Loss_G: 0.0319 Convergence: 0.1440 k= 0.040450 lr = 0.0000902\n",
      "[0/25][7070/9765] Loss_D: 0.1211 Loss_G: 0.0550 Convergence: 0.1284 k= 0.040512 lr = 0.0000902\n",
      "[0/25][7080/9765] Loss_D: 0.1155 Loss_G: 0.0458 Convergence: 0.1180 k= 0.040566 lr = 0.0000902\n",
      "[0/25][7090/9765] Loss_D: 0.1194 Loss_G: 0.0376 Convergence: 0.1319 k= 0.040652 lr = 0.0000902\n",
      "[0/25][7100/9765] Loss_D: 0.1265 Loss_G: 0.0339 Convergence: 0.1457 k= 0.040785 lr = 0.0000902\n",
      "[0/25][7110/9765] Loss_D: 0.1311 Loss_G: 0.0421 Convergence: 0.1438 k= 0.040856 lr = 0.0000902\n",
      "[0/25][7120/9765] Loss_D: 0.1199 Loss_G: 0.0522 Convergence: 0.1253 k= 0.040913 lr = 0.0000902\n",
      "[0/25][7130/9765] Loss_D: 0.1267 Loss_G: 0.0448 Convergence: 0.1356 k= 0.040948 lr = 0.0000902\n",
      "[0/25][7140/9765] Loss_D: 0.1154 Loss_G: 0.0372 Convergence: 0.1272 k= 0.041008 lr = 0.0000902\n",
      "[0/25][7150/9765] Loss_D: 0.1218 Loss_G: 0.0501 Convergence: 0.1242 k= 0.040993 lr = 0.0000902\n",
      "[0/25][7160/9765] Loss_D: 0.1214 Loss_G: 0.0401 Convergence: 0.1325 k= 0.041066 lr = 0.0000902\n",
      "[0/25][7170/9765] Loss_D: 0.1268 Loss_G: 0.0451 Convergence: 0.1351 k= 0.041129 lr = 0.0000902\n",
      "[0/25][7180/9765] Loss_D: 0.1280 Loss_G: 0.0402 Convergence: 0.1419 k= 0.041184 lr = 0.0000902\n",
      "[0/25][7190/9765] Loss_D: 0.1297 Loss_G: 0.0390 Convergence: 0.1447 k= 0.041262 lr = 0.0000902\n",
      "[0/25][7200/9765] Loss_D: 0.1306 Loss_G: 0.0517 Convergence: 0.1336 k= 0.041334 lr = 0.0000902\n",
      "[0/25][7210/9765] Loss_D: 0.1190 Loss_G: 0.0370 Convergence: 0.1321 k= 0.041406 lr = 0.0000902\n",
      "[0/25][7220/9765] Loss_D: 0.1173 Loss_G: 0.0481 Convergence: 0.1194 k= 0.041471 lr = 0.0000902\n",
      "[0/25][7230/9765] Loss_D: 0.1123 Loss_G: 0.0360 Convergence: 0.1234 k= 0.041548 lr = 0.0000902\n",
      "[0/25][7240/9765] Loss_D: 0.1207 Loss_G: 0.0522 Convergence: 0.1256 k= 0.041578 lr = 0.0000902\n",
      "[0/25][7250/9765] Loss_D: 0.1193 Loss_G: 0.0420 Convergence: 0.1275 k= 0.041667 lr = 0.0000902\n",
      "[0/25][7260/9765] Loss_D: 0.1179 Loss_G: 0.0408 Convergence: 0.1271 k= 0.041743 lr = 0.0000902\n",
      "[0/25][7270/9765] Loss_D: 0.1297 Loss_G: 0.0557 Convergence: 0.1347 k= 0.041772 lr = 0.0000902\n",
      "[0/25][7280/9765] Loss_D: 0.1304 Loss_G: 0.0462 Convergence: 0.1384 k= 0.041828 lr = 0.0000902\n",
      "[0/25][7290/9765] Loss_D: 0.1208 Loss_G: 0.0427 Convergence: 0.1294 k= 0.041900 lr = 0.0000902\n",
      "[0/25][7300/9765] Loss_D: 0.1251 Loss_G: 0.0387 Convergence: 0.1396 k= 0.041953 lr = 0.0000902\n",
      "[0/25][7310/9765] Loss_D: 0.1245 Loss_G: 0.0378 Convergence: 0.1392 k= 0.042031 lr = 0.0000902\n",
      "[0/25][7320/9765] Loss_D: 0.1161 Loss_G: 0.0549 Convergence: 0.1255 k= 0.042068 lr = 0.0000902\n",
      "[0/25][7330/9765] Loss_D: 0.1267 Loss_G: 0.0519 Convergence: 0.1288 k= 0.042146 lr = 0.0000902\n",
      "[0/25][7340/9765] Loss_D: 0.1287 Loss_G: 0.0406 Convergence: 0.1420 k= 0.042243 lr = 0.0000902\n",
      "[0/25][7350/9765] Loss_D: 0.1243 Loss_G: 0.0464 Convergence: 0.1304 k= 0.042274 lr = 0.0000902\n",
      "[0/25][7360/9765] Loss_D: 0.1246 Loss_G: 0.0447 Convergence: 0.1323 k= 0.042343 lr = 0.0000902\n",
      "[0/25][7370/9765] Loss_D: 0.1289 Loss_G: 0.0416 Convergence: 0.1421 k= 0.042398 lr = 0.0000902\n",
      "[0/25][7380/9765] Loss_D: 0.1227 Loss_G: 0.0417 Convergence: 0.1327 k= 0.042465 lr = 0.0000902\n",
      "[0/25][7390/9765] Loss_D: 0.1226 Loss_G: 0.0457 Convergence: 0.1283 k= 0.042490 lr = 0.0000902\n",
      "[0/25][7400/9765] Loss_D: 0.1244 Loss_G: 0.0435 Convergence: 0.1334 k= 0.042573 lr = 0.0000902\n",
      "[0/25][7410/9765] Loss_D: 0.1346 Loss_G: 0.0425 Convergence: 0.1494 k= 0.042604 lr = 0.0000902\n",
      "[0/25][7420/9765] Loss_D: 0.1294 Loss_G: 0.0562 Convergence: 0.1350 k= 0.042591 lr = 0.0000902\n",
      "[0/25][7430/9765] Loss_D: 0.1144 Loss_G: 0.0410 Convergence: 0.1220 k= 0.042656 lr = 0.0000902\n",
      "[0/25][7440/9765] Loss_D: 0.1138 Loss_G: 0.0414 Convergence: 0.1206 k= 0.042714 lr = 0.0000902\n",
      "[0/25][7450/9765] Loss_D: 0.1269 Loss_G: 0.0430 Convergence: 0.1368 k= 0.042799 lr = 0.0000902\n",
      "[0/25][7460/9765] Loss_D: 0.1318 Loss_G: 0.0442 Convergence: 0.1432 k= 0.042841 lr = 0.0000902\n",
      "[0/25][7470/9765] Loss_D: 0.1239 Loss_G: 0.0410 Convergence: 0.1353 k= 0.042853 lr = 0.0000902\n",
      "[0/25][7480/9765] Loss_D: 0.1250 Loss_G: 0.0380 Convergence: 0.1400 k= 0.042931 lr = 0.0000902\n",
      "[0/25][7490/9765] Loss_D: 0.1199 Loss_G: 0.0425 Convergence: 0.1277 k= 0.042978 lr = 0.0000902\n",
      "[0/25][7500/9765] Loss_D: 0.1159 Loss_G: 0.0383 Convergence: 0.1267 k= 0.043074 lr = 0.0000902\n",
      "[0/25][7510/9765] Loss_D: 0.1191 Loss_G: 0.0402 Convergence: 0.1294 k= 0.043130 lr = 0.0000902\n",
      "[0/25][7520/9765] Loss_D: 0.1307 Loss_G: 0.0420 Convergence: 0.1437 k= 0.043182 lr = 0.0000902\n",
      "[0/25][7530/9765] Loss_D: 0.1385 Loss_G: 0.0578 Convergence: 0.1420 k= 0.043241 lr = 0.0000902\n",
      "[0/25][7540/9765] Loss_D: 0.1398 Loss_G: 0.0413 Convergence: 0.1571 k= 0.043314 lr = 0.0000902\n",
      "[0/25][7550/9765] Loss_D: 0.1327 Loss_G: 0.0409 Convergence: 0.1474 k= 0.043398 lr = 0.0000902\n",
      "[0/25][7560/9765] Loss_D: 0.1377 Loss_G: 0.0502 Convergence: 0.1448 k= 0.043468 lr = 0.0000902\n",
      "[0/25][7570/9765] Loss_D: 0.1184 Loss_G: 0.0376 Convergence: 0.1303 k= 0.043569 lr = 0.0000902\n",
      "[0/25][7580/9765] Loss_D: 0.1211 Loss_G: 0.0483 Convergence: 0.1246 k= 0.043605 lr = 0.0000902\n",
      "[0/25][7590/9765] Loss_D: 0.1297 Loss_G: 0.0422 Convergence: 0.1423 k= 0.043620 lr = 0.0000902\n",
      "[0/25][7600/9765] Loss_D: 0.1225 Loss_G: 0.0345 Convergence: 0.1397 k= 0.043690 lr = 0.0000902\n",
      "[0/25][7610/9765] Loss_D: 0.1323 Loss_G: 0.0468 Convergence: 0.1421 k= 0.043736 lr = 0.0000902\n",
      "[0/25][7620/9765] Loss_D: 0.1232 Loss_G: 0.0510 Convergence: 0.1261 k= 0.043785 lr = 0.0000902\n",
      "[0/25][7630/9765] Loss_D: 0.1132 Loss_G: 0.0431 Convergence: 0.1176 k= 0.043816 lr = 0.0000902\n",
      "[0/25][7640/9765] Loss_D: 0.1176 Loss_G: 0.0392 Convergence: 0.1281 k= 0.043888 lr = 0.0000902\n",
      "[0/25][7650/9765] Loss_D: 0.1261 Loss_G: 0.0418 Convergence: 0.1367 k= 0.043948 lr = 0.0000902\n",
      "[0/25][7660/9765] Loss_D: 0.1214 Loss_G: 0.0433 Convergence: 0.1287 k= 0.043979 lr = 0.0000902\n",
      "[0/25][7670/9765] Loss_D: 0.1239 Loss_G: 0.0531 Convergence: 0.1286 k= 0.043979 lr = 0.0000902\n",
      "[0/25][7680/9765] Loss_D: 0.1204 Loss_G: 0.0406 Convergence: 0.1311 k= 0.044024 lr = 0.0000902\n",
      "[0/25][7690/9765] Loss_D: 0.1183 Loss_G: 0.0380 Convergence: 0.1304 k= 0.044092 lr = 0.0000902\n",
      "[0/25][7700/9765] Loss_D: 0.1194 Loss_G: 0.0374 Convergence: 0.1326 k= 0.044173 lr = 0.0000902\n",
      "[0/25][7710/9765] Loss_D: 0.1226 Loss_G: 0.0579 Convergence: 0.1324 k= 0.044235 lr = 0.0000902\n",
      "[0/25][7720/9765] Loss_D: 0.1256 Loss_G: 0.0425 Convergence: 0.1360 k= 0.044300 lr = 0.0000902\n",
      "[0/25][7730/9765] Loss_D: 0.1211 Loss_G: 0.0378 Convergence: 0.1347 k= 0.044303 lr = 0.0000902\n",
      "[0/25][7740/9765] Loss_D: 0.1247 Loss_G: 0.0418 Convergence: 0.1359 k= 0.044362 lr = 0.0000902\n",
      "[0/25][7750/9765] Loss_D: 0.1367 Loss_G: 0.0563 Convergence: 0.1399 k= 0.044389 lr = 0.0000902\n",
      "[0/25][7760/9765] Loss_D: 0.1349 Loss_G: 0.0441 Convergence: 0.1476 k= 0.044410 lr = 0.0000902\n",
      "[0/25][7770/9765] Loss_D: 0.1160 Loss_G: 0.0386 Convergence: 0.1262 k= 0.044477 lr = 0.0000902\n",
      "[0/25][7780/9765] Loss_D: 0.1170 Loss_G: 0.0566 Convergence: 0.1281 k= 0.044482 lr = 0.0000902\n",
      "[0/25][7790/9765] Loss_D: 0.1178 Loss_G: 0.0641 Convergence: 0.1362 k= 0.044526 lr = 0.0000902\n",
      "[0/25][7800/9765] Loss_D: 0.1220 Loss_G: 0.0526 Convergence: 0.1268 k= 0.044570 lr = 0.0000902\n",
      "[0/25][7810/9765] Loss_D: 0.1190 Loss_G: 0.0468 Convergence: 0.1221 k= 0.044642 lr = 0.0000902\n",
      "[0/25][7820/9765] Loss_D: 0.1179 Loss_G: 0.0445 Convergence: 0.1232 k= 0.044656 lr = 0.0000902\n",
      "[0/25][7830/9765] Loss_D: 0.1239 Loss_G: 0.0472 Convergence: 0.1296 k= 0.044708 lr = 0.0000902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][7840/9765] Loss_D: 0.1197 Loss_G: 0.0500 Convergence: 0.1229 k= 0.044764 lr = 0.0000902\n",
      "[0/25][7850/9765] Loss_D: 0.1214 Loss_G: 0.0465 Convergence: 0.1257 k= 0.044831 lr = 0.0000902\n",
      "[0/25][7860/9765] Loss_D: 0.1155 Loss_G: 0.0373 Convergence: 0.1268 k= 0.044907 lr = 0.0000902\n",
      "[0/25][7870/9765] Loss_D: 0.1394 Loss_G: 0.0516 Convergence: 0.1464 k= 0.044945 lr = 0.0000902\n",
      "[0/25][7880/9765] Loss_D: 0.1156 Loss_G: 0.0365 Convergence: 0.1285 k= 0.045017 lr = 0.0000902\n",
      "[0/25][7890/9765] Loss_D: 0.1201 Loss_G: 0.0364 Convergence: 0.1349 k= 0.045075 lr = 0.0000902\n",
      "[0/25][7900/9765] Loss_D: 0.1226 Loss_G: 0.0458 Convergence: 0.1286 k= 0.045138 lr = 0.0000902\n",
      "[0/25][7910/9765] Loss_D: 0.1200 Loss_G: 0.0455 Convergence: 0.1256 k= 0.045175 lr = 0.0000902\n",
      "[0/25][7920/9765] Loss_D: 0.1257 Loss_G: 0.0398 Convergence: 0.1392 k= 0.045237 lr = 0.0000902\n",
      "[0/25][7930/9765] Loss_D: 0.1260 Loss_G: 0.0340 Convergence: 0.1452 k= 0.045320 lr = 0.0000902\n",
      "[0/25][7940/9765] Loss_D: 0.1217 Loss_G: 0.0451 Convergence: 0.1274 k= 0.045414 lr = 0.0000902\n",
      "[0/25][7950/9765] Loss_D: 0.1224 Loss_G: 0.0414 Convergence: 0.1325 k= 0.045497 lr = 0.0000902\n",
      "[0/25][7960/9765] Loss_D: 0.1226 Loss_G: 0.0608 Convergence: 0.1355 k= 0.045542 lr = 0.0000902\n",
      "[0/25][7970/9765] Loss_D: 0.1267 Loss_G: 0.0496 Convergence: 0.1302 k= 0.045568 lr = 0.0000902\n",
      "[0/25][7980/9765] Loss_D: 0.1135 Loss_G: 0.0422 Convergence: 0.1191 k= 0.045630 lr = 0.0000902\n",
      "[0/25][7990/9765] Loss_D: 0.1186 Loss_G: 0.0376 Convergence: 0.1312 k= 0.045707 lr = 0.0000902\n",
      "[0/25][8000/9765] Loss_D: 0.1297 Loss_G: 0.0401 Convergence: 0.1438 k= 0.045793 lr = 0.0000902\n",
      "[0/25][8010/9765] Loss_D: 0.1168 Loss_G: 0.0360 Convergence: 0.1303 k= 0.045870 lr = 0.0000902\n",
      "[0/25][8020/9765] Loss_D: 0.1201 Loss_G: 0.0575 Convergence: 0.1312 k= 0.045863 lr = 0.0000902\n",
      "[0/25][8030/9765] Loss_D: 0.1332 Loss_G: 0.0617 Convergence: 0.1427 k= 0.045909 lr = 0.0000902\n",
      "[0/25][8040/9765] Loss_D: 0.1364 Loss_G: 0.0491 Convergence: 0.1443 k= 0.045856 lr = 0.0000902\n",
      "[0/25][8050/9765] Loss_D: 0.1198 Loss_G: 0.0475 Convergence: 0.1231 k= 0.045883 lr = 0.0000902\n",
      "[0/25][8060/9765] Loss_D: 0.1115 Loss_G: 0.0380 Convergence: 0.1211 k= 0.045941 lr = 0.0000902\n",
      "[0/25][8070/9765] Loss_D: 0.1306 Loss_G: 0.0509 Convergence: 0.1344 k= 0.046001 lr = 0.0000902\n",
      "[0/25][8080/9765] Loss_D: 0.1266 Loss_G: 0.0414 Convergence: 0.1383 k= 0.046072 lr = 0.0000902\n",
      "[0/25][8090/9765] Loss_D: 0.1177 Loss_G: 0.0369 Convergence: 0.1308 k= 0.046142 lr = 0.0000902\n",
      "[0/25][8100/9765] Loss_D: 0.1127 Loss_G: 0.0465 Convergence: 0.1151 k= 0.046203 lr = 0.0000902\n",
      "[0/25][8110/9765] Loss_D: 0.1209 Loss_G: 0.0432 Convergence: 0.1294 k= 0.046223 lr = 0.0000902\n",
      "[0/25][8120/9765] Loss_D: 0.1160 Loss_G: 0.0444 Convergence: 0.1210 k= 0.046274 lr = 0.0000902\n",
      "[0/25][8130/9765] Loss_D: 0.1152 Loss_G: 0.0477 Convergence: 0.1180 k= 0.046334 lr = 0.0000902\n",
      "[0/25][8140/9765] Loss_D: 0.1169 Loss_G: 0.0533 Convergence: 0.1245 k= 0.046358 lr = 0.0000902\n",
      "[0/25][8150/9765] Loss_D: 0.1163 Loss_G: 0.0393 Convergence: 0.1263 k= 0.046385 lr = 0.0000902\n",
      "[0/25][8160/9765] Loss_D: 0.1282 Loss_G: 0.0525 Convergence: 0.1307 k= 0.046399 lr = 0.0000902\n",
      "[0/25][8170/9765] Loss_D: 0.1236 Loss_G: 0.0569 Convergence: 0.1323 k= 0.046340 lr = 0.0000902\n",
      "[0/25][8180/9765] Loss_D: 0.1320 Loss_G: 0.0563 Convergence: 0.1371 k= 0.046304 lr = 0.0000902\n",
      "[0/25][8190/9765] Loss_D: 0.1274 Loss_G: 0.0411 Convergence: 0.1396 k= 0.046347 lr = 0.0000902\n",
      "[0/25][8200/9765] Loss_D: 0.1199 Loss_G: 0.0401 Convergence: 0.1300 k= 0.046399 lr = 0.0000902\n",
      "[0/25][8210/9765] Loss_D: 0.1269 Loss_G: 0.0434 Convergence: 0.1378 k= 0.046429 lr = 0.0000902\n",
      "[0/25][8220/9765] Loss_D: 0.1201 Loss_G: 0.0450 Convergence: 0.1261 k= 0.046429 lr = 0.0000902\n",
      "[0/25][8230/9765] Loss_D: 0.1417 Loss_G: 0.0473 Convergence: 0.1541 k= 0.046425 lr = 0.0000902\n",
      "[0/25][8240/9765] Loss_D: 0.1232 Loss_G: 0.0503 Convergence: 0.1253 k= 0.046471 lr = 0.0000902\n",
      "[0/25][8250/9765] Loss_D: 0.1208 Loss_G: 0.0392 Convergence: 0.1330 k= 0.046548 lr = 0.0000902\n",
      "[0/25][8260/9765] Loss_D: 0.1139 Loss_G: 0.0355 Convergence: 0.1262 k= 0.046603 lr = 0.0000902\n",
      "[0/25][8270/9765] Loss_D: 0.1174 Loss_G: 0.0460 Convergence: 0.1208 k= 0.046674 lr = 0.0000902\n",
      "[0/25][8280/9765] Loss_D: 0.1209 Loss_G: 0.0443 Convergence: 0.1277 k= 0.046721 lr = 0.0000902\n",
      "[0/25][8290/9765] Loss_D: 0.1203 Loss_G: 0.0384 Convergence: 0.1327 k= 0.046802 lr = 0.0000902\n",
      "[0/25][8300/9765] Loss_D: 0.1166 Loss_G: 0.0511 Convergence: 0.1223 k= 0.046787 lr = 0.0000902\n",
      "[0/25][8310/9765] Loss_D: 0.1240 Loss_G: 0.0530 Convergence: 0.1287 k= 0.046798 lr = 0.0000902\n",
      "[0/25][8320/9765] Loss_D: 0.1244 Loss_G: 0.0490 Convergence: 0.1280 k= 0.046854 lr = 0.0000902\n",
      "[0/25][8330/9765] Loss_D: 0.1248 Loss_G: 0.0437 Convergence: 0.1335 k= 0.046908 lr = 0.0000902\n",
      "[0/25][8340/9765] Loss_D: 0.1273 Loss_G: 0.0616 Convergence: 0.1392 k= 0.046936 lr = 0.0000902\n",
      "[0/25][8350/9765] Loss_D: 0.1300 Loss_G: 0.0633 Convergence: 0.1423 k= 0.046969 lr = 0.0000902\n",
      "[0/25][8360/9765] Loss_D: 0.1239 Loss_G: 0.0394 Convergence: 0.1366 k= 0.046996 lr = 0.0000902\n",
      "[0/25][8370/9765] Loss_D: 0.1164 Loss_G: 0.0420 Convergence: 0.1235 k= 0.047053 lr = 0.0000902\n",
      "[0/25][8380/9765] Loss_D: 0.1176 Loss_G: 0.0484 Convergence: 0.1203 k= 0.047082 lr = 0.0000902\n",
      "[0/25][8390/9765] Loss_D: 0.1252 Loss_G: 0.0522 Convergence: 0.1288 k= 0.047116 lr = 0.0000902\n",
      "[0/25][8400/9765] Loss_D: 0.1203 Loss_G: 0.0417 Convergence: 0.1299 k= 0.047121 lr = 0.0000902\n",
      "[0/25][8410/9765] Loss_D: 0.1235 Loss_G: 0.0361 Convergence: 0.1391 k= 0.047189 lr = 0.0000902\n",
      "[0/25][8420/9765] Loss_D: 0.1161 Loss_G: 0.0573 Convergence: 0.1281 k= 0.047221 lr = 0.0000902\n",
      "[0/25][8430/9765] Loss_D: 0.1234 Loss_G: 0.0441 Convergence: 0.1321 k= 0.047240 lr = 0.0000902\n",
      "[0/25][8440/9765] Loss_D: 0.1289 Loss_G: 0.0477 Convergence: 0.1358 k= 0.047254 lr = 0.0000902\n",
      "[0/25][8450/9765] Loss_D: 0.1174 Loss_G: 0.0425 Convergence: 0.1252 k= 0.047289 lr = 0.0000902\n",
      "[0/25][8460/9765] Loss_D: 0.1295 Loss_G: 0.0363 Convergence: 0.1475 k= 0.047353 lr = 0.0000902\n",
      "[0/25][8470/9765] Loss_D: 0.1141 Loss_G: 0.0498 Convergence: 0.1195 k= 0.047396 lr = 0.0000902\n",
      "[0/25][8480/9765] Loss_D: 0.1278 Loss_G: 0.0512 Convergence: 0.1313 k= 0.047326 lr = 0.0000902\n",
      "[0/25][8490/9765] Loss_D: 0.1313 Loss_G: 0.0502 Convergence: 0.1368 k= 0.047339 lr = 0.0000902\n",
      "[0/25][8500/9765] Loss_D: 0.1323 Loss_G: 0.0443 Convergence: 0.1433 k= 0.047383 lr = 0.0000902\n",
      "[0/25][8510/9765] Loss_D: 0.1163 Loss_G: 0.0443 Convergence: 0.1216 k= 0.047430 lr = 0.0000902\n",
      "[0/25][8520/9765] Loss_D: 0.1274 Loss_G: 0.0403 Convergence: 0.1415 k= 0.047478 lr = 0.0000902\n",
      "[0/25][8530/9765] Loss_D: 0.1161 Loss_G: 0.0471 Convergence: 0.1181 k= 0.047503 lr = 0.0000902\n",
      "[0/25][8540/9765] Loss_D: 0.1233 Loss_G: 0.0560 Convergence: 0.1316 k= 0.047533 lr = 0.0000902\n",
      "[0/25][8550/9765] Loss_D: 0.1253 Loss_G: 0.0394 Convergence: 0.1387 k= 0.047580 lr = 0.0000902\n",
      "[0/25][8560/9765] Loss_D: 0.1252 Loss_G: 0.0429 Convergence: 0.1350 k= 0.047634 lr = 0.0000902\n",
      "[0/25][8570/9765] Loss_D: 0.1200 Loss_G: 0.0450 Convergence: 0.1256 k= 0.047674 lr = 0.0000902\n",
      "[0/25][8580/9765] Loss_D: 0.1228 Loss_G: 0.0387 Convergence: 0.1360 k= 0.047741 lr = 0.0000902\n",
      "[0/25][8590/9765] Loss_D: 0.1331 Loss_G: 0.0627 Convergence: 0.1438 k= 0.047795 lr = 0.0000902\n",
      "[0/25][8600/9765] Loss_D: 0.1271 Loss_G: 0.0499 Convergence: 0.1307 k= 0.047803 lr = 0.0000902\n",
      "[0/25][8610/9765] Loss_D: 0.1129 Loss_G: 0.0431 Convergence: 0.1175 k= 0.047798 lr = 0.0000902\n",
      "[0/25][8620/9765] Loss_D: 0.1188 Loss_G: 0.0474 Convergence: 0.1219 k= 0.047808 lr = 0.0000902\n",
      "[0/25][8630/9765] Loss_D: 0.1140 Loss_G: 0.0456 Convergence: 0.1173 k= 0.047824 lr = 0.0000902\n",
      "[0/25][8640/9765] Loss_D: 0.1192 Loss_G: 0.0557 Convergence: 0.1284 k= 0.047872 lr = 0.0000902\n",
      "[0/25][8650/9765] Loss_D: 0.1111 Loss_G: 0.0419 Convergence: 0.1162 k= 0.047907 lr = 0.0000902\n",
      "[0/25][8660/9765] Loss_D: 0.1089 Loss_G: 0.0381 Convergence: 0.1168 k= 0.047955 lr = 0.0000902\n",
      "[0/25][8670/9765] Loss_D: 0.1322 Loss_G: 0.0441 Convergence: 0.1448 k= 0.047978 lr = 0.0000902\n",
      "[0/25][8680/9765] Loss_D: 0.1188 Loss_G: 0.0375 Convergence: 0.1318 k= 0.048016 lr = 0.0000902\n",
      "[0/25][8690/9765] Loss_D: 0.1259 Loss_G: 0.0452 Convergence: 0.1336 k= 0.048080 lr = 0.0000902\n",
      "[0/25][8700/9765] Loss_D: 0.1352 Loss_G: 0.0480 Convergence: 0.1444 k= 0.048141 lr = 0.0000902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][8710/9765] Loss_D: 0.1278 Loss_G: 0.0446 Convergence: 0.1384 k= 0.048031 lr = 0.0000902\n",
      "[0/25][8720/9765] Loss_D: 0.1207 Loss_G: 0.0493 Convergence: 0.1230 k= 0.048007 lr = 0.0000902\n",
      "[0/25][8730/9765] Loss_D: 0.1291 Loss_G: 0.0522 Convergence: 0.1313 k= 0.048048 lr = 0.0000902\n",
      "[0/25][8740/9765] Loss_D: 0.1179 Loss_G: 0.0468 Convergence: 0.1209 k= 0.048104 lr = 0.0000902\n",
      "[0/25][8750/9765] Loss_D: 0.1277 Loss_G: 0.0499 Convergence: 0.1320 k= 0.048136 lr = 0.0000902\n",
      "[0/25][8760/9765] Loss_D: 0.1221 Loss_G: 0.0409 Convergence: 0.1332 k= 0.048187 lr = 0.0000902\n",
      "[0/25][8770/9765] Loss_D: 0.1193 Loss_G: 0.0438 Convergence: 0.1256 k= 0.048260 lr = 0.0000902\n",
      "[0/25][8780/9765] Loss_D: 0.1142 Loss_G: 0.0413 Convergence: 0.1218 k= 0.048309 lr = 0.0000902\n",
      "[0/25][8790/9765] Loss_D: 0.1187 Loss_G: 0.0475 Convergence: 0.1217 k= 0.048367 lr = 0.0000902\n",
      "[0/25][8800/9765] Loss_D: 0.1110 Loss_G: 0.0409 Convergence: 0.1168 k= 0.048416 lr = 0.0000902\n",
      "[0/25][8810/9765] Loss_D: 0.1173 Loss_G: 0.0411 Convergence: 0.1258 k= 0.048488 lr = 0.0000902\n",
      "[0/25][8820/9765] Loss_D: 0.1165 Loss_G: 0.0471 Convergence: 0.1192 k= 0.048553 lr = 0.0000902\n",
      "[0/25][8830/9765] Loss_D: 0.1321 Loss_G: 0.0438 Convergence: 0.1448 k= 0.048592 lr = 0.0000902\n",
      "[0/25][8840/9765] Loss_D: 0.1161 Loss_G: 0.0406 Convergence: 0.1250 k= 0.048656 lr = 0.0000902\n",
      "[0/25][8850/9765] Loss_D: 0.1228 Loss_G: 0.0431 Convergence: 0.1313 k= 0.048714 lr = 0.0000902\n",
      "[0/25][8860/9765] Loss_D: 0.1206 Loss_G: 0.0457 Convergence: 0.1258 k= 0.048754 lr = 0.0000902\n",
      "[0/25][8870/9765] Loss_D: 0.1181 Loss_G: 0.0431 Convergence: 0.1248 k= 0.048799 lr = 0.0000902\n",
      "[0/25][8880/9765] Loss_D: 0.1292 Loss_G: 0.0524 Convergence: 0.1318 k= 0.048839 lr = 0.0000902\n",
      "[0/25][8890/9765] Loss_D: 0.1149 Loss_G: 0.0507 Convergence: 0.1209 k= 0.048866 lr = 0.0000902\n",
      "[0/25][8900/9765] Loss_D: 0.1171 Loss_G: 0.0394 Convergence: 0.1275 k= 0.048913 lr = 0.0000902\n",
      "[0/25][8910/9765] Loss_D: 0.1161 Loss_G: 0.0464 Convergence: 0.1189 k= 0.048950 lr = 0.0000902\n",
      "[0/25][8920/9765] Loss_D: 0.1184 Loss_G: 0.0460 Convergence: 0.1227 k= 0.049001 lr = 0.0000902\n",
      "[0/25][8930/9765] Loss_D: 0.1258 Loss_G: 0.0431 Convergence: 0.1360 k= 0.049047 lr = 0.0000902\n",
      "[0/25][8940/9765] Loss_D: 0.1255 Loss_G: 0.0403 Convergence: 0.1384 k= 0.049111 lr = 0.0000902\n",
      "[0/25][8950/9765] Loss_D: 0.1148 Loss_G: 0.0487 Convergence: 0.1189 k= 0.049171 lr = 0.0000902\n",
      "[0/25][8960/9765] Loss_D: 0.1365 Loss_G: 0.0495 Convergence: 0.1441 k= 0.049232 lr = 0.0000902\n",
      "[0/25][8970/9765] Loss_D: 0.1122 Loss_G: 0.0404 Convergence: 0.1191 k= 0.049288 lr = 0.0000902\n",
      "[0/25][8980/9765] Loss_D: 0.1194 Loss_G: 0.0433 Convergence: 0.1262 k= 0.049333 lr = 0.0000902\n",
      "[0/25][8990/9765] Loss_D: 0.1127 Loss_G: 0.0527 Convergence: 0.1219 k= 0.049304 lr = 0.0000902\n",
      "[0/25][9000/9765] Loss_D: 0.1122 Loss_G: 0.0748 Convergence: 0.1433 k= 0.049329 lr = 0.0000857\n",
      "[0/25][9010/9765] Loss_D: 0.1258 Loss_G: 0.0481 Convergence: 0.1312 k= 0.049381 lr = 0.0000857\n",
      "[0/25][9020/9765] Loss_D: 0.1157 Loss_G: 0.0479 Convergence: 0.1186 k= 0.049434 lr = 0.0000857\n",
      "[0/25][9030/9765] Loss_D: 0.1157 Loss_G: 0.0429 Convergence: 0.1224 k= 0.049500 lr = 0.0000857\n",
      "[0/25][9040/9765] Loss_D: 0.1211 Loss_G: 0.0402 Convergence: 0.1319 k= 0.049525 lr = 0.0000857\n",
      "[0/25][9050/9765] Loss_D: 0.1294 Loss_G: 0.0486 Convergence: 0.1353 k= 0.049558 lr = 0.0000857\n",
      "[0/25][9060/9765] Loss_D: 0.1170 Loss_G: 0.0538 Convergence: 0.1251 k= 0.049613 lr = 0.0000857\n",
      "[0/25][9070/9765] Loss_D: 0.1163 Loss_G: 0.0496 Convergence: 0.1207 k= 0.049639 lr = 0.0000857\n",
      "[0/25][9080/9765] Loss_D: 0.1125 Loss_G: 0.0389 Convergence: 0.1218 k= 0.049668 lr = 0.0000857\n",
      "[0/25][9090/9765] Loss_D: 0.1245 Loss_G: 0.0415 Convergence: 0.1366 k= 0.049699 lr = 0.0000857\n",
      "[0/25][9100/9765] Loss_D: 0.1237 Loss_G: 0.0500 Convergence: 0.1267 k= 0.049684 lr = 0.0000857\n",
      "[0/25][9110/9765] Loss_D: 0.1238 Loss_G: 0.0430 Convergence: 0.1334 k= 0.049723 lr = 0.0000857\n",
      "[0/25][9120/9765] Loss_D: 0.1215 Loss_G: 0.0449 Convergence: 0.1278 k= 0.049775 lr = 0.0000857\n",
      "[0/25][9130/9765] Loss_D: 0.1181 Loss_G: 0.0416 Convergence: 0.1267 k= 0.049832 lr = 0.0000857\n",
      "[0/25][9140/9765] Loss_D: 0.1112 Loss_G: 0.0454 Convergence: 0.1134 k= 0.049864 lr = 0.0000857\n",
      "[0/25][9150/9765] Loss_D: 0.1289 Loss_G: 0.0479 Convergence: 0.1364 k= 0.049864 lr = 0.0000857\n",
      "[0/25][9160/9765] Loss_D: 0.1202 Loss_G: 0.0427 Convergence: 0.1284 k= 0.049898 lr = 0.0000857\n",
      "[0/25][9170/9765] Loss_D: 0.1265 Loss_G: 0.0406 Convergence: 0.1392 k= 0.049962 lr = 0.0000857\n",
      "[0/25][9180/9765] Loss_D: 0.1193 Loss_G: 0.0503 Convergence: 0.1230 k= 0.049985 lr = 0.0000857\n",
      "[0/25][9190/9765] Loss_D: 0.1215 Loss_G: 0.0422 Convergence: 0.1309 k= 0.050008 lr = 0.0000857\n",
      "[0/25][9200/9765] Loss_D: 0.1225 Loss_G: 0.0516 Convergence: 0.1264 k= 0.050048 lr = 0.0000857\n",
      "[0/25][9210/9765] Loss_D: 0.1162 Loss_G: 0.0394 Convergence: 0.1265 k= 0.050066 lr = 0.0000857\n",
      "[0/25][9220/9765] Loss_D: 0.1164 Loss_G: 0.0632 Convergence: 0.1343 k= 0.050099 lr = 0.0000857\n",
      "[0/25][9230/9765] Loss_D: 0.1168 Loss_G: 0.0387 Convergence: 0.1273 k= 0.050098 lr = 0.0000857\n",
      "[0/25][9240/9765] Loss_D: 0.1197 Loss_G: 0.0407 Convergence: 0.1295 k= 0.050166 lr = 0.0000857\n",
      "[0/25][9250/9765] Loss_D: 0.1182 Loss_G: 0.0450 Convergence: 0.1233 k= 0.050225 lr = 0.0000857\n",
      "[0/25][9260/9765] Loss_D: 0.1164 Loss_G: 0.0543 Convergence: 0.1254 k= 0.050277 lr = 0.0000857\n",
      "[0/25][9270/9765] Loss_D: 0.1146 Loss_G: 0.0445 Convergence: 0.1188 k= 0.050312 lr = 0.0000857\n",
      "[0/25][9280/9765] Loss_D: 0.1169 Loss_G: 0.0455 Convergence: 0.1210 k= 0.050375 lr = 0.0000857\n",
      "[0/25][9290/9765] Loss_D: 0.1155 Loss_G: 0.0378 Convergence: 0.1265 k= 0.050424 lr = 0.0000857\n",
      "[0/25][9300/9765] Loss_D: 0.1233 Loss_G: 0.0489 Convergence: 0.1263 k= 0.050489 lr = 0.0000857\n",
      "[0/25][9310/9765] Loss_D: 0.1229 Loss_G: 0.0469 Convergence: 0.1276 k= 0.050547 lr = 0.0000857\n",
      "[0/25][9320/9765] Loss_D: 0.1113 Loss_G: 0.0323 Convergence: 0.1261 k= 0.050612 lr = 0.0000857\n",
      "[0/25][9330/9765] Loss_D: 0.1133 Loss_G: 0.0393 Convergence: 0.1227 k= 0.050652 lr = 0.0000857\n",
      "[0/25][9340/9765] Loss_D: 0.1214 Loss_G: 0.0435 Convergence: 0.1293 k= 0.050676 lr = 0.0000857\n",
      "[0/25][9350/9765] Loss_D: 0.1202 Loss_G: 0.0513 Convergence: 0.1247 k= 0.050703 lr = 0.0000857\n",
      "[0/25][9360/9765] Loss_D: 0.1269 Loss_G: 0.0636 Convergence: 0.1410 k= 0.050749 lr = 0.0000857\n",
      "[0/25][9370/9765] Loss_D: 0.1159 Loss_G: 0.0410 Convergence: 0.1243 k= 0.050778 lr = 0.0000857\n",
      "[0/25][9380/9765] Loss_D: 0.1115 Loss_G: 0.0385 Convergence: 0.1208 k= 0.050839 lr = 0.0000857\n",
      "[0/25][9390/9765] Loss_D: 0.1298 Loss_G: 0.0413 Convergence: 0.1432 k= 0.050883 lr = 0.0000857\n",
      "[0/25][9400/9765] Loss_D: 0.1135 Loss_G: 0.0469 Convergence: 0.1163 k= 0.050951 lr = 0.0000857\n",
      "[0/25][9410/9765] Loss_D: 0.1175 Loss_G: 0.0373 Convergence: 0.1301 k= 0.051008 lr = 0.0000857\n",
      "[0/25][9420/9765] Loss_D: 0.1261 Loss_G: 0.0433 Convergence: 0.1362 k= 0.051071 lr = 0.0000857\n",
      "[0/25][9430/9765] Loss_D: 0.1303 Loss_G: 0.0463 Convergence: 0.1399 k= 0.051103 lr = 0.0000857\n",
      "[0/25][9440/9765] Loss_D: 0.1182 Loss_G: 0.0431 Convergence: 0.1256 k= 0.051096 lr = 0.0000857\n",
      "[0/25][9450/9765] Loss_D: 0.1203 Loss_G: 0.0604 Convergence: 0.1339 k= 0.051132 lr = 0.0000857\n",
      "[0/25][9460/9765] Loss_D: 0.1249 Loss_G: 0.0510 Convergence: 0.1273 k= 0.051155 lr = 0.0000857\n",
      "[0/25][9470/9765] Loss_D: 0.1182 Loss_G: 0.0487 Convergence: 0.1208 k= 0.051209 lr = 0.0000857\n",
      "[0/25][9480/9765] Loss_D: 0.1311 Loss_G: 0.0469 Convergence: 0.1403 k= 0.051205 lr = 0.0000857\n",
      "[0/25][9490/9765] Loss_D: 0.1165 Loss_G: 0.0600 Convergence: 0.1311 k= 0.051203 lr = 0.0000857\n",
      "[0/25][9500/9765] Loss_D: 0.1234 Loss_G: 0.0433 Convergence: 0.1321 k= 0.051231 lr = 0.0000857\n",
      "[0/25][9510/9765] Loss_D: 0.1115 Loss_G: 0.0561 Convergence: 0.1243 k= 0.051264 lr = 0.0000857\n",
      "[0/25][9520/9765] Loss_D: 0.1079 Loss_G: 0.0411 Convergence: 0.1129 k= 0.051300 lr = 0.0000857\n",
      "[0/25][9530/9765] Loss_D: 0.1135 Loss_G: 0.0424 Convergence: 0.1195 k= 0.051362 lr = 0.0000857\n",
      "[0/25][9540/9765] Loss_D: 0.1332 Loss_G: 0.0450 Convergence: 0.1457 k= 0.051387 lr = 0.0000857\n",
      "[0/25][9550/9765] Loss_D: 0.1275 Loss_G: 0.0534 Convergence: 0.1318 k= 0.051401 lr = 0.0000857\n",
      "[0/25][9560/9765] Loss_D: 0.1284 Loss_G: 0.0417 Convergence: 0.1407 k= 0.051446 lr = 0.0000857\n",
      "[0/25][9570/9765] Loss_D: 0.1131 Loss_G: 0.0400 Convergence: 0.1214 k= 0.051488 lr = 0.0000857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/25][9580/9765] Loss_D: 0.1185 Loss_G: 0.0505 Convergence: 0.1232 k= 0.051471 lr = 0.0000857\n",
      "[0/25][9590/9765] Loss_D: 0.1365 Loss_G: 0.0441 Convergence: 0.1505 k= 0.051507 lr = 0.0000857\n",
      "[0/25][9600/9765] Loss_D: 0.1279 Loss_G: 0.0448 Convergence: 0.1371 k= 0.051532 lr = 0.0000857\n",
      "[0/25][9610/9765] Loss_D: 0.1147 Loss_G: 0.0460 Convergence: 0.1175 k= 0.051569 lr = 0.0000857\n",
      "[0/25][9620/9765] Loss_D: 0.1209 Loss_G: 0.0466 Convergence: 0.1254 k= 0.051617 lr = 0.0000857\n",
      "[0/25][9630/9765] Loss_D: 0.1160 Loss_G: 0.0396 Convergence: 0.1253 k= 0.051678 lr = 0.0000857\n",
      "[0/25][9640/9765] Loss_D: 0.1211 Loss_G: 0.0444 Convergence: 0.1281 k= 0.051726 lr = 0.0000857\n",
      "[0/25][9650/9765] Loss_D: 0.1180 Loss_G: 0.0398 Convergence: 0.1286 k= 0.051763 lr = 0.0000857\n",
      "[0/25][9660/9765] Loss_D: 0.1246 Loss_G: 0.0378 Convergence: 0.1396 k= 0.051822 lr = 0.0000857\n",
      "[0/25][9670/9765] Loss_D: 0.1157 Loss_G: 0.0627 Convergence: 0.1335 k= 0.051837 lr = 0.0000857\n",
      "[0/25][9680/9765] Loss_D: 0.1230 Loss_G: 0.0626 Convergence: 0.1379 k= 0.051804 lr = 0.0000857\n",
      "[0/25][9690/9765] Loss_D: 0.1369 Loss_G: 0.0454 Convergence: 0.1488 k= 0.051819 lr = 0.0000857\n",
      "[0/25][9700/9765] Loss_D: 0.1185 Loss_G: 0.0433 Convergence: 0.1257 k= 0.051828 lr = 0.0000857\n",
      "[0/25][9710/9765] Loss_D: 0.1135 Loss_G: 0.0381 Convergence: 0.1240 k= 0.051830 lr = 0.0000857\n",
      "[0/25][9720/9765] Loss_D: 0.1212 Loss_G: 0.0388 Convergence: 0.1339 k= 0.051882 lr = 0.0000857\n",
      "[0/25][9730/9765] Loss_D: 0.1190 Loss_G: 0.0419 Convergence: 0.1281 k= 0.051924 lr = 0.0000857\n",
      "[0/25][9740/9765] Loss_D: 0.1201 Loss_G: 0.0398 Convergence: 0.1318 k= 0.051978 lr = 0.0000857\n",
      "[0/25][9750/9765] Loss_D: 0.1233 Loss_G: 0.0531 Convergence: 0.1283 k= 0.052015 lr = 0.0000857\n",
      "[0/25][9760/9765] Loss_D: 0.1163 Loss_G: 0.0383 Convergence: 0.1275 k= 0.052094 lr = 0.0000857\n",
      "[1/25][0/9765] Loss_D: 0.1100 Loss_G: 0.0387 Convergence: 0.1183 k= 0.052108 lr = 0.0000857\n",
      "[1/25][10/9765] Loss_D: 0.1158 Loss_G: 0.0400 Convergence: 0.1253 k= 0.052168 lr = 0.0000857\n",
      "[1/25][20/9765] Loss_D: 0.1143 Loss_G: 0.0420 Convergence: 0.1210 k= 0.052202 lr = 0.0000857\n",
      "[1/25][30/9765] Loss_D: 0.1202 Loss_G: 0.0534 Convergence: 0.1269 k= 0.052202 lr = 0.0000857\n",
      "[1/25][40/9765] Loss_D: 0.1176 Loss_G: 0.0497 Convergence: 0.1217 k= 0.052160 lr = 0.0000857\n",
      "[1/25][50/9765] Loss_D: 0.1159 Loss_G: 0.0453 Convergence: 0.1200 k= 0.052179 lr = 0.0000857\n",
      "[1/25][60/9765] Loss_D: 0.1197 Loss_G: 0.0424 Convergence: 0.1282 k= 0.052173 lr = 0.0000857\n",
      "[1/25][70/9765] Loss_D: 0.1212 Loss_G: 0.0403 Convergence: 0.1321 k= 0.052232 lr = 0.0000857\n",
      "[1/25][80/9765] Loss_D: 0.1172 Loss_G: 0.0492 Convergence: 0.1209 k= 0.052290 lr = 0.0000857\n",
      "[1/25][90/9765] Loss_D: 0.1097 Loss_G: 0.0387 Convergence: 0.1177 k= 0.052338 lr = 0.0000857\n",
      "[1/25][100/9765] Loss_D: 0.1152 Loss_G: 0.0413 Convergence: 0.1233 k= 0.052367 lr = 0.0000857\n",
      "[1/25][110/9765] Loss_D: 0.1280 Loss_G: 0.0406 Convergence: 0.1415 k= 0.052408 lr = 0.0000857\n",
      "[1/25][120/9765] Loss_D: 0.1102 Loss_G: 0.0436 Convergence: 0.1143 k= 0.052417 lr = 0.0000857\n",
      "[1/25][130/9765] Loss_D: 0.1124 Loss_G: 0.0424 Convergence: 0.1179 k= 0.052456 lr = 0.0000857\n",
      "[1/25][140/9765] Loss_D: 0.1200 Loss_G: 0.0419 Convergence: 0.1290 k= 0.052502 lr = 0.0000857\n",
      "[1/25][150/9765] Loss_D: 0.1162 Loss_G: 0.0412 Convergence: 0.1247 k= 0.052539 lr = 0.0000857\n",
      "[1/25][160/9765] Loss_D: 0.1159 Loss_G: 0.0408 Convergence: 0.1251 k= 0.052561 lr = 0.0000857\n",
      "[1/25][170/9765] Loss_D: 0.1141 Loss_G: 0.0374 Convergence: 0.1255 k= 0.052610 lr = 0.0000857\n",
      "[1/25][180/9765] Loss_D: 0.1163 Loss_G: 0.0381 Convergence: 0.1282 k= 0.052617 lr = 0.0000857\n",
      "[1/25][190/9765] Loss_D: 0.1130 Loss_G: 0.0598 Convergence: 0.1291 k= 0.052637 lr = 0.0000857\n",
      "[1/25][200/9765] Loss_D: 0.1129 Loss_G: 0.0408 Convergence: 0.1205 k= 0.052618 lr = 0.0000857\n",
      "[1/25][210/9765] Loss_D: 0.1126 Loss_G: 0.0403 Convergence: 0.1206 k= 0.052660 lr = 0.0000857\n",
      "[1/25][220/9765] Loss_D: 0.1213 Loss_G: 0.0539 Convergence: 0.1278 k= 0.052706 lr = 0.0000857\n",
      "[1/25][230/9765] Loss_D: 0.1247 Loss_G: 0.0538 Convergence: 0.1303 k= 0.052669 lr = 0.0000857\n",
      "[1/25][240/9765] Loss_D: 0.1129 Loss_G: 0.0413 Convergence: 0.1204 k= 0.052681 lr = 0.0000857\n",
      "[1/25][250/9765] Loss_D: 0.1225 Loss_G: 0.0558 Convergence: 0.1308 k= 0.052714 lr = 0.0000857\n",
      "[1/25][260/9765] Loss_D: 0.1106 Loss_G: 0.0382 Convergence: 0.1200 k= 0.052751 lr = 0.0000857\n",
      "[1/25][270/9765] Loss_D: 0.1253 Loss_G: 0.0557 Convergence: 0.1323 k= 0.052760 lr = 0.0000857\n",
      "[1/25][280/9765] Loss_D: 0.1167 Loss_G: 0.0409 Convergence: 0.1255 k= 0.052809 lr = 0.0000857\n",
      "[1/25][290/9765] Loss_D: 0.1201 Loss_G: 0.0389 Convergence: 0.1319 k= 0.052871 lr = 0.0000857\n",
      "[1/25][300/9765] Loss_D: 0.1216 Loss_G: 0.0465 Convergence: 0.1268 k= 0.052918 lr = 0.0000857\n",
      "[1/25][310/9765] Loss_D: 0.1279 Loss_G: 0.0546 Convergence: 0.1326 k= 0.052935 lr = 0.0000857\n",
      "[1/25][320/9765] Loss_D: 0.1265 Loss_G: 0.0491 Convergence: 0.1317 k= 0.052966 lr = 0.0000857\n",
      "[1/25][330/9765] Loss_D: 0.1232 Loss_G: 0.0576 Convergence: 0.1330 k= 0.052970 lr = 0.0000857\n",
      "[1/25][340/9765] Loss_D: 0.1207 Loss_G: 0.0591 Convergence: 0.1333 k= 0.052934 lr = 0.0000857\n",
      "[1/25][350/9765] Loss_D: 0.1196 Loss_G: 0.0415 Convergence: 0.1298 k= 0.052928 lr = 0.0000857\n",
      "[1/25][360/9765] Loss_D: 0.1232 Loss_G: 0.0470 Convergence: 0.1287 k= 0.052958 lr = 0.0000857\n",
      "[1/25][370/9765] Loss_D: 0.1184 Loss_G: 0.0470 Convergence: 0.1227 k= 0.052980 lr = 0.0000857\n",
      "[1/25][380/9765] Loss_D: 0.1257 Loss_G: 0.0592 Convergence: 0.1368 k= 0.052933 lr = 0.0000857\n",
      "[1/25][390/9765] Loss_D: 0.1199 Loss_G: 0.0519 Convergence: 0.1253 k= 0.052932 lr = 0.0000857\n",
      "[1/25][400/9765] Loss_D: 0.1164 Loss_G: 0.0485 Convergence: 0.1198 k= 0.052963 lr = 0.0000857\n",
      "[1/25][410/9765] Loss_D: 0.1150 Loss_G: 0.0393 Convergence: 0.1245 k= 0.053012 lr = 0.0000857\n",
      "[1/25][420/9765] Loss_D: 0.1167 Loss_G: 0.0438 Convergence: 0.1227 k= 0.053032 lr = 0.0000857\n",
      "[1/25][430/9765] Loss_D: 0.1235 Loss_G: 0.0488 Convergence: 0.1280 k= 0.053044 lr = 0.0000857\n",
      "[1/25][440/9765] Loss_D: 0.1190 Loss_G: 0.0417 Convergence: 0.1279 k= 0.053118 lr = 0.0000857\n",
      "[1/25][450/9765] Loss_D: 0.1153 Loss_G: 0.0467 Convergence: 0.1179 k= 0.053152 lr = 0.0000857\n",
      "[1/25][460/9765] Loss_D: 0.1259 Loss_G: 0.0450 Convergence: 0.1345 k= 0.053195 lr = 0.0000857\n",
      "[1/25][470/9765] Loss_D: 0.1216 Loss_G: 0.0445 Convergence: 0.1295 k= 0.053218 lr = 0.0000857\n",
      "[1/25][480/9765] Loss_D: 0.1226 Loss_G: 0.0492 Convergence: 0.1262 k= 0.053219 lr = 0.0000857\n",
      "[1/25][490/9765] Loss_D: 0.1233 Loss_G: 0.0398 Convergence: 0.1357 k= 0.053229 lr = 0.0000857\n",
      "[1/25][500/9765] Loss_D: 0.1068 Loss_G: 0.0452 Convergence: 0.1106 k= 0.053290 lr = 0.0000857\n",
      "[1/25][510/9765] Loss_D: 0.1299 Loss_G: 0.0436 Convergence: 0.1411 k= 0.053354 lr = 0.0000857\n",
      "[1/25][520/9765] Loss_D: 0.1400 Loss_G: 0.0449 Convergence: 0.1544 k= 0.053408 lr = 0.0000857\n",
      "[1/25][530/9765] Loss_D: 0.1112 Loss_G: 0.0345 Convergence: 0.1239 k= 0.053470 lr = 0.0000857\n",
      "[1/25][540/9765] Loss_D: 0.1163 Loss_G: 0.0459 Convergence: 0.1205 k= 0.053463 lr = 0.0000857\n",
      "[1/25][550/9765] Loss_D: 0.1094 Loss_G: 0.0392 Convergence: 0.1178 k= 0.053488 lr = 0.0000857\n",
      "[1/25][560/9765] Loss_D: 0.1244 Loss_G: 0.0454 Convergence: 0.1318 k= 0.053510 lr = 0.0000857\n",
      "[1/25][570/9765] Loss_D: 0.1140 Loss_G: 0.0516 Convergence: 0.1212 k= 0.053536 lr = 0.0000857\n",
      "[1/25][580/9765] Loss_D: 0.1191 Loss_G: 0.0562 Convergence: 0.1294 k= 0.053570 lr = 0.0000857\n",
      "[1/25][590/9765] Loss_D: 0.1157 Loss_G: 0.0467 Convergence: 0.1187 k= 0.053583 lr = 0.0000857\n",
      "[1/25][600/9765] Loss_D: 0.1219 Loss_G: 0.0412 Convergence: 0.1323 k= 0.053626 lr = 0.0000857\n",
      "[1/25][610/9765] Loss_D: 0.1208 Loss_G: 0.0377 Convergence: 0.1346 k= 0.053679 lr = 0.0000857\n",
      "[1/25][620/9765] Loss_D: 0.1082 Loss_G: 0.0433 Convergence: 0.1112 k= 0.053728 lr = 0.0000857\n",
      "[1/25][630/9765] Loss_D: 0.1155 Loss_G: 0.0449 Convergence: 0.1195 k= 0.053779 lr = 0.0000857\n",
      "[1/25][640/9765] Loss_D: 0.1207 Loss_G: 0.0387 Convergence: 0.1329 k= 0.053817 lr = 0.0000857\n",
      "[1/25][650/9765] Loss_D: 0.1172 Loss_G: 0.0426 Convergence: 0.1246 k= 0.053837 lr = 0.0000857\n",
      "[1/25][660/9765] Loss_D: 0.1144 Loss_G: 0.0370 Convergence: 0.1259 k= 0.053885 lr = 0.0000857\n",
      "[1/25][670/9765] Loss_D: 0.1133 Loss_G: 0.0463 Convergence: 0.1157 k= 0.053913 lr = 0.0000857\n",
      "[1/25][680/9765] Loss_D: 0.1232 Loss_G: 0.0436 Convergence: 0.1328 k= 0.053939 lr = 0.0000857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][690/9765] Loss_D: 0.1164 Loss_G: 0.0463 Convergence: 0.1196 k= 0.053956 lr = 0.0000857\n",
      "[1/25][700/9765] Loss_D: 0.1173 Loss_G: 0.0531 Convergence: 0.1254 k= 0.053935 lr = 0.0000857\n",
      "[1/25][710/9765] Loss_D: 0.1116 Loss_G: 0.0436 Convergence: 0.1160 k= 0.053925 lr = 0.0000857\n",
      "[1/25][720/9765] Loss_D: 0.1083 Loss_G: 0.0473 Convergence: 0.1136 k= 0.053955 lr = 0.0000857\n",
      "[1/25][730/9765] Loss_D: 0.1227 Loss_G: 0.0496 Convergence: 0.1259 k= 0.053966 lr = 0.0000857\n",
      "[1/25][740/9765] Loss_D: 0.1152 Loss_G: 0.0389 Convergence: 0.1252 k= 0.053993 lr = 0.0000857\n",
      "[1/25][750/9765] Loss_D: 0.1302 Loss_G: 0.0459 Convergence: 0.1392 k= 0.054038 lr = 0.0000857\n",
      "[1/25][760/9765] Loss_D: 0.1086 Loss_G: 0.0413 Convergence: 0.1142 k= 0.054064 lr = 0.0000857\n",
      "[1/25][770/9765] Loss_D: 0.1156 Loss_G: 0.0440 Convergence: 0.1218 k= 0.054044 lr = 0.0000857\n",
      "[1/25][780/9765] Loss_D: 0.1130 Loss_G: 0.0410 Convergence: 0.1206 k= 0.054056 lr = 0.0000857\n",
      "[1/25][790/9765] Loss_D: 0.1095 Loss_G: 0.0420 Convergence: 0.1145 k= 0.054061 lr = 0.0000857\n",
      "[1/25][800/9765] Loss_D: 0.1055 Loss_G: 0.0407 Convergence: 0.1105 k= 0.054074 lr = 0.0000857\n",
      "[1/25][810/9765] Loss_D: 0.1201 Loss_G: 0.0502 Convergence: 0.1238 k= 0.054112 lr = 0.0000857\n",
      "[1/25][820/9765] Loss_D: 0.1118 Loss_G: 0.0423 Convergence: 0.1172 k= 0.054151 lr = 0.0000857\n",
      "[1/25][830/9765] Loss_D: 0.1172 Loss_G: 0.0433 Convergence: 0.1239 k= 0.054190 lr = 0.0000857\n",
      "[1/25][840/9765] Loss_D: 0.1144 Loss_G: 0.0470 Convergence: 0.1169 k= 0.054232 lr = 0.0000857\n",
      "[1/25][850/9765] Loss_D: 0.1287 Loss_G: 0.0456 Convergence: 0.1385 k= 0.054286 lr = 0.0000857\n",
      "[1/25][860/9765] Loss_D: 0.1129 Loss_G: 0.0353 Convergence: 0.1262 k= 0.054347 lr = 0.0000857\n",
      "[1/25][870/9765] Loss_D: 0.1115 Loss_G: 0.0448 Convergence: 0.1146 k= 0.054379 lr = 0.0000857\n",
      "[1/25][880/9765] Loss_D: 0.1213 Loss_G: 0.0430 Convergence: 0.1300 k= 0.054423 lr = 0.0000857\n",
      "[1/25][890/9765] Loss_D: 0.1138 Loss_G: 0.0456 Convergence: 0.1172 k= 0.054463 lr = 0.0000857\n",
      "[1/25][900/9765] Loss_D: 0.1168 Loss_G: 0.0520 Convergence: 0.1237 k= 0.054424 lr = 0.0000857\n",
      "[1/25][910/9765] Loss_D: 0.1319 Loss_G: 0.0516 Convergence: 0.1390 k= 0.054342 lr = 0.0000857\n",
      "[1/25][920/9765] Loss_D: 0.1205 Loss_G: 0.0471 Convergence: 0.1246 k= 0.054355 lr = 0.0000857\n",
      "[1/25][930/9765] Loss_D: 0.1238 Loss_G: 0.0460 Convergence: 0.1308 k= 0.054364 lr = 0.0000857\n",
      "[1/25][940/9765] Loss_D: 0.1179 Loss_G: 0.0455 Convergence: 0.1226 k= 0.054391 lr = 0.0000857\n",
      "[1/25][950/9765] Loss_D: 0.1224 Loss_G: 0.0527 Convergence: 0.1276 k= 0.054399 lr = 0.0000857\n",
      "[1/25][960/9765] Loss_D: 0.1152 Loss_G: 0.0427 Convergence: 0.1220 k= 0.054398 lr = 0.0000857\n",
      "[1/25][970/9765] Loss_D: 0.1135 Loss_G: 0.0445 Convergence: 0.1172 k= 0.054426 lr = 0.0000857\n",
      "[1/25][980/9765] Loss_D: 0.1252 Loss_G: 0.0475 Convergence: 0.1320 k= 0.054428 lr = 0.0000857\n",
      "[1/25][990/9765] Loss_D: 0.1090 Loss_G: 0.0371 Convergence: 0.1188 k= 0.054477 lr = 0.0000857\n",
      "[1/25][1000/9765] Loss_D: 0.1350 Loss_G: 0.0527 Convergence: 0.1393 k= 0.054515 lr = 0.0000857\n",
      "[1/25][1010/9765] Loss_D: 0.1123 Loss_G: 0.0471 Convergence: 0.1160 k= 0.054436 lr = 0.0000857\n",
      "[1/25][1020/9765] Loss_D: 0.1252 Loss_G: 0.0566 Convergence: 0.1333 k= 0.054460 lr = 0.0000857\n",
      "[1/25][1030/9765] Loss_D: 0.1299 Loss_G: 0.0445 Convergence: 0.1412 k= 0.054474 lr = 0.0000857\n",
      "[1/25][1040/9765] Loss_D: 0.1182 Loss_G: 0.0413 Convergence: 0.1280 k= 0.054493 lr = 0.0000857\n",
      "[1/25][1050/9765] Loss_D: 0.1089 Loss_G: 0.0433 Convergence: 0.1121 k= 0.054533 lr = 0.0000857\n",
      "[1/25][1060/9765] Loss_D: 0.1238 Loss_G: 0.0418 Convergence: 0.1348 k= 0.054539 lr = 0.0000857\n",
      "[1/25][1070/9765] Loss_D: 0.1048 Loss_G: 0.0502 Convergence: 0.1144 k= 0.054566 lr = 0.0000857\n",
      "[1/25][1080/9765] Loss_D: 0.1212 Loss_G: 0.0456 Convergence: 0.1277 k= 0.054602 lr = 0.0000857\n",
      "[1/25][1090/9765] Loss_D: 0.1125 Loss_G: 0.0430 Convergence: 0.1175 k= 0.054642 lr = 0.0000857\n",
      "[1/25][1100/9765] Loss_D: 0.1092 Loss_G: 0.0416 Convergence: 0.1144 k= 0.054684 lr = 0.0000857\n",
      "[1/25][1110/9765] Loss_D: 0.1223 Loss_G: 0.0546 Convergence: 0.1296 k= 0.054683 lr = 0.0000857\n",
      "[1/25][1120/9765] Loss_D: 0.1136 Loss_G: 0.0438 Convergence: 0.1189 k= 0.054678 lr = 0.0000857\n",
      "[1/25][1130/9765] Loss_D: 0.1173 Loss_G: 0.0602 Convergence: 0.1324 k= 0.054626 lr = 0.0000857\n",
      "[1/25][1140/9765] Loss_D: 0.1415 Loss_G: 0.0454 Convergence: 0.1571 k= 0.054600 lr = 0.0000857\n",
      "[1/25][1150/9765] Loss_D: 0.1042 Loss_G: 0.0400 Convergence: 0.1094 k= 0.054646 lr = 0.0000857\n",
      "[1/25][1160/9765] Loss_D: 0.1186 Loss_G: 0.0428 Convergence: 0.1271 k= 0.054688 lr = 0.0000857\n",
      "[1/25][1170/9765] Loss_D: 0.1126 Loss_G: 0.0395 Convergence: 0.1210 k= 0.054737 lr = 0.0000857\n",
      "[1/25][1180/9765] Loss_D: 0.1173 Loss_G: 0.0398 Convergence: 0.1278 k= 0.054760 lr = 0.0000857\n",
      "[1/25][1190/9765] Loss_D: 0.1160 Loss_G: 0.0407 Convergence: 0.1248 k= 0.054797 lr = 0.0000857\n",
      "[1/25][1200/9765] Loss_D: 0.1190 Loss_G: 0.0407 Convergence: 0.1293 k= 0.054811 lr = 0.0000857\n",
      "[1/25][1210/9765] Loss_D: 0.1174 Loss_G: 0.0475 Convergence: 0.1203 k= 0.054796 lr = 0.0000857\n",
      "[1/25][1220/9765] Loss_D: 0.1090 Loss_G: 0.0407 Convergence: 0.1145 k= 0.054836 lr = 0.0000857\n",
      "[1/25][1230/9765] Loss_D: 0.1260 Loss_G: 0.0452 Convergence: 0.1346 k= 0.054884 lr = 0.0000857\n",
      "[1/25][1240/9765] Loss_D: 0.1289 Loss_G: 0.0426 Convergence: 0.1412 k= 0.054930 lr = 0.0000857\n",
      "[1/25][1250/9765] Loss_D: 0.1230 Loss_G: 0.0443 Convergence: 0.1311 k= 0.054962 lr = 0.0000857\n",
      "[1/25][1260/9765] Loss_D: 0.1191 Loss_G: 0.0443 Convergence: 0.1255 k= 0.054996 lr = 0.0000857\n",
      "[1/25][1270/9765] Loss_D: 0.1018 Loss_G: 0.0530 Convergence: 0.1154 k= 0.054993 lr = 0.0000857\n",
      "[1/25][1280/9765] Loss_D: 0.1326 Loss_G: 0.0475 Convergence: 0.1421 k= 0.055013 lr = 0.0000857\n",
      "[1/25][1290/9765] Loss_D: 0.1220 Loss_G: 0.0398 Convergence: 0.1343 k= 0.055049 lr = 0.0000857\n",
      "[1/25][1300/9765] Loss_D: 0.1286 Loss_G: 0.0512 Convergence: 0.1344 k= 0.055012 lr = 0.0000857\n",
      "[1/25][1310/9765] Loss_D: 0.1259 Loss_G: 0.0443 Convergence: 0.1351 k= 0.055009 lr = 0.0000857\n",
      "[1/25][1320/9765] Loss_D: 0.1250 Loss_G: 0.0403 Convergence: 0.1382 k= 0.055043 lr = 0.0000857\n",
      "[1/25][1330/9765] Loss_D: 0.1204 Loss_G: 0.0417 Convergence: 0.1304 k= 0.055095 lr = 0.0000857\n",
      "[1/25][1340/9765] Loss_D: 0.1139 Loss_G: 0.0454 Convergence: 0.1174 k= 0.055111 lr = 0.0000857\n",
      "[1/25][1350/9765] Loss_D: 0.1133 Loss_G: 0.0491 Convergence: 0.1187 k= 0.055101 lr = 0.0000857\n",
      "[1/25][1360/9765] Loss_D: 0.1106 Loss_G: 0.0482 Convergence: 0.1163 k= 0.055087 lr = 0.0000857\n",
      "[1/25][1370/9765] Loss_D: 0.1099 Loss_G: 0.0385 Convergence: 0.1183 k= 0.055092 lr = 0.0000857\n",
      "[1/25][1380/9765] Loss_D: 0.1189 Loss_G: 0.0437 Convergence: 0.1266 k= 0.055048 lr = 0.0000857\n",
      "[1/25][1390/9765] Loss_D: 0.1192 Loss_G: 0.0427 Convergence: 0.1277 k= 0.055043 lr = 0.0000857\n",
      "[1/25][1400/9765] Loss_D: 0.1233 Loss_G: 0.0484 Convergence: 0.1273 k= 0.055078 lr = 0.0000857\n",
      "[1/25][1410/9765] Loss_D: 0.1147 Loss_G: 0.0428 Convergence: 0.1212 k= 0.055093 lr = 0.0000857\n",
      "[1/25][1420/9765] Loss_D: 0.1147 Loss_G: 0.0413 Convergence: 0.1230 k= 0.055137 lr = 0.0000857\n",
      "[1/25][1430/9765] Loss_D: 0.1075 Loss_G: 0.0403 Convergence: 0.1134 k= 0.055182 lr = 0.0000857\n",
      "[1/25][1440/9765] Loss_D: 0.1203 Loss_G: 0.0433 Convergence: 0.1285 k= 0.055205 lr = 0.0000857\n",
      "[1/25][1450/9765] Loss_D: 0.1093 Loss_G: 0.0483 Convergence: 0.1154 k= 0.055228 lr = 0.0000857\n",
      "[1/25][1460/9765] Loss_D: 0.1149 Loss_G: 0.0446 Convergence: 0.1196 k= 0.055246 lr = 0.0000857\n",
      "[1/25][1470/9765] Loss_D: 0.1179 Loss_G: 0.0424 Convergence: 0.1261 k= 0.055292 lr = 0.0000857\n",
      "[1/25][1480/9765] Loss_D: 0.1154 Loss_G: 0.0403 Convergence: 0.1248 k= 0.055345 lr = 0.0000857\n",
      "[1/25][1490/9765] Loss_D: 0.1192 Loss_G: 0.0448 Convergence: 0.1261 k= 0.055367 lr = 0.0000857\n",
      "[1/25][1500/9765] Loss_D: 0.1184 Loss_G: 0.0466 Convergence: 0.1223 k= 0.055389 lr = 0.0000857\n",
      "[1/25][1510/9765] Loss_D: 0.1252 Loss_G: 0.0431 Convergence: 0.1354 k= 0.055426 lr = 0.0000857\n",
      "[1/25][1520/9765] Loss_D: 0.1100 Loss_G: 0.0473 Convergence: 0.1148 k= 0.055424 lr = 0.0000857\n",
      "[1/25][1530/9765] Loss_D: 0.1304 Loss_G: 0.0456 Convergence: 0.1417 k= 0.055401 lr = 0.0000857\n",
      "[1/25][1540/9765] Loss_D: 0.1049 Loss_G: 0.0468 Convergence: 0.1111 k= 0.055432 lr = 0.0000857\n",
      "[1/25][1550/9765] Loss_D: 0.1259 Loss_G: 0.0432 Convergence: 0.1369 k= 0.055457 lr = 0.0000857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][1560/9765] Loss_D: 0.1091 Loss_G: 0.0477 Convergence: 0.1147 k= 0.055480 lr = 0.0000857\n",
      "[1/25][1570/9765] Loss_D: 0.1195 Loss_G: 0.0637 Convergence: 0.1369 k= 0.055448 lr = 0.0000857\n",
      "[1/25][1580/9765] Loss_D: 0.1169 Loss_G: 0.0468 Convergence: 0.1201 k= 0.055464 lr = 0.0000857\n",
      "[1/25][1590/9765] Loss_D: 0.1273 Loss_G: 0.0542 Convergence: 0.1326 k= 0.055424 lr = 0.0000857\n",
      "[1/25][1600/9765] Loss_D: 0.1150 Loss_G: 0.0496 Convergence: 0.1199 k= 0.055426 lr = 0.0000857\n",
      "[1/25][1610/9765] Loss_D: 0.1223 Loss_G: 0.0609 Convergence: 0.1356 k= 0.055429 lr = 0.0000857\n",
      "[1/25][1620/9765] Loss_D: 0.1192 Loss_G: 0.0485 Convergence: 0.1223 k= 0.055420 lr = 0.0000857\n",
      "[1/25][1630/9765] Loss_D: 0.1102 Loss_G: 0.0391 Convergence: 0.1186 k= 0.055453 lr = 0.0000857\n",
      "[1/25][1640/9765] Loss_D: 0.1267 Loss_G: 0.0476 Convergence: 0.1335 k= 0.055429 lr = 0.0000857\n",
      "[1/25][1650/9765] Loss_D: 0.1163 Loss_G: 0.0427 Convergence: 0.1233 k= 0.055448 lr = 0.0000857\n",
      "[1/25][1660/9765] Loss_D: 0.1053 Loss_G: 0.0442 Convergence: 0.1089 k= 0.055485 lr = 0.0000857\n",
      "[1/25][1670/9765] Loss_D: 0.1181 Loss_G: 0.0415 Convergence: 0.1271 k= 0.055511 lr = 0.0000857\n",
      "[1/25][1680/9765] Loss_D: 0.1232 Loss_G: 0.0405 Convergence: 0.1350 k= 0.055556 lr = 0.0000857\n",
      "[1/25][1690/9765] Loss_D: 0.1259 Loss_G: 0.0451 Convergence: 0.1346 k= 0.055589 lr = 0.0000857\n",
      "[1/25][1700/9765] Loss_D: 0.1270 Loss_G: 0.0612 Convergence: 0.1389 k= 0.055604 lr = 0.0000857\n",
      "[1/25][1710/9765] Loss_D: 0.1093 Loss_G: 0.0412 Convergence: 0.1149 k= 0.055623 lr = 0.0000857\n",
      "[1/25][1720/9765] Loss_D: 0.1164 Loss_G: 0.0501 Convergence: 0.1212 k= 0.055666 lr = 0.0000857\n",
      "[1/25][1730/9765] Loss_D: 0.1304 Loss_G: 0.0464 Convergence: 0.1396 k= 0.055685 lr = 0.0000857\n",
      "[1/25][1740/9765] Loss_D: 0.1124 Loss_G: 0.0442 Convergence: 0.1166 k= 0.055712 lr = 0.0000857\n",
      "[1/25][1750/9765] Loss_D: 0.1148 Loss_G: 0.0380 Convergence: 0.1264 k= 0.055758 lr = 0.0000857\n",
      "[1/25][1760/9765] Loss_D: 0.1096 Loss_G: 0.0387 Convergence: 0.1185 k= 0.055789 lr = 0.0000857\n",
      "[1/25][1770/9765] Loss_D: 0.1093 Loss_G: 0.0466 Convergence: 0.1137 k= 0.055817 lr = 0.0000857\n",
      "[1/25][1780/9765] Loss_D: 0.1230 Loss_G: 0.0479 Convergence: 0.1275 k= 0.055844 lr = 0.0000857\n",
      "[1/25][1790/9765] Loss_D: 0.1186 Loss_G: 0.0412 Convergence: 0.1280 k= 0.055851 lr = 0.0000857\n",
      "[1/25][1800/9765] Loss_D: 0.1290 Loss_G: 0.0541 Convergence: 0.1331 k= 0.055829 lr = 0.0000857\n",
      "[1/25][1810/9765] Loss_D: 0.1139 Loss_G: 0.0443 Convergence: 0.1189 k= 0.055817 lr = 0.0000857\n",
      "[1/25][1820/9765] Loss_D: 0.1118 Loss_G: 0.0455 Convergence: 0.1152 k= 0.055827 lr = 0.0000857\n",
      "[1/25][1830/9765] Loss_D: 0.1206 Loss_G: 0.0456 Convergence: 0.1265 k= 0.055869 lr = 0.0000857\n",
      "[1/25][1840/9765] Loss_D: 0.1089 Loss_G: 0.0419 Convergence: 0.1141 k= 0.055876 lr = 0.0000857\n",
      "[1/25][1850/9765] Loss_D: 0.1145 Loss_G: 0.0419 Convergence: 0.1215 k= 0.055929 lr = 0.0000857\n",
      "[1/25][1860/9765] Loss_D: 0.1156 Loss_G: 0.0472 Convergence: 0.1180 k= 0.055946 lr = 0.0000857\n",
      "[1/25][1870/9765] Loss_D: 0.1292 Loss_G: 0.0396 Convergence: 0.1450 k= 0.055972 lr = 0.0000857\n",
      "[1/25][1880/9765] Loss_D: 0.1129 Loss_G: 0.0499 Convergence: 0.1193 k= 0.055963 lr = 0.0000857\n",
      "[1/25][1890/9765] Loss_D: 0.1113 Loss_G: 0.0438 Convergence: 0.1153 k= 0.056007 lr = 0.0000857\n",
      "[1/25][1900/9765] Loss_D: 0.1122 Loss_G: 0.0483 Convergence: 0.1169 k= 0.056025 lr = 0.0000857\n",
      "[1/25][1910/9765] Loss_D: 0.1161 Loss_G: 0.0444 Convergence: 0.1213 k= 0.056026 lr = 0.0000857\n",
      "[1/25][1920/9765] Loss_D: 0.1138 Loss_G: 0.0443 Convergence: 0.1183 k= 0.056065 lr = 0.0000857\n",
      "[1/25][1930/9765] Loss_D: 0.1129 Loss_G: 0.0513 Convergence: 0.1204 k= 0.056079 lr = 0.0000857\n",
      "[1/25][1940/9765] Loss_D: 0.1355 Loss_G: 0.0535 Convergence: 0.1393 k= 0.056110 lr = 0.0000857\n",
      "[1/25][1950/9765] Loss_D: 0.1100 Loss_G: 0.0445 Convergence: 0.1131 k= 0.056095 lr = 0.0000857\n",
      "[1/25][1960/9765] Loss_D: 0.1158 Loss_G: 0.0422 Convergence: 0.1233 k= 0.056105 lr = 0.0000857\n",
      "[1/25][1970/9765] Loss_D: 0.1061 Loss_G: 0.0422 Convergence: 0.1099 k= 0.056128 lr = 0.0000857\n",
      "[1/25][1980/9765] Loss_D: 0.1051 Loss_G: 0.0379 Convergence: 0.1131 k= 0.056113 lr = 0.0000857\n",
      "[1/25][1990/9765] Loss_D: 0.1161 Loss_G: 0.0431 Convergence: 0.1231 k= 0.056068 lr = 0.0000857\n",
      "[1/25][2000/9765] Loss_D: 0.1219 Loss_G: 0.0420 Convergence: 0.1320 k= 0.056091 lr = 0.0000857\n",
      "[1/25][2010/9765] Loss_D: 0.1246 Loss_G: 0.0464 Convergence: 0.1312 k= 0.056121 lr = 0.0000857\n",
      "[1/25][2020/9765] Loss_D: 0.1105 Loss_G: 0.0397 Convergence: 0.1183 k= 0.056163 lr = 0.0000857\n",
      "[1/25][2030/9765] Loss_D: 0.1146 Loss_G: 0.0424 Convergence: 0.1211 k= 0.056183 lr = 0.0000857\n",
      "[1/25][2040/9765] Loss_D: 0.1175 Loss_G: 0.0433 Convergence: 0.1247 k= 0.056211 lr = 0.0000857\n",
      "[1/25][2050/9765] Loss_D: 0.1255 Loss_G: 0.0469 Convergence: 0.1321 k= 0.056239 lr = 0.0000857\n",
      "[1/25][2060/9765] Loss_D: 0.1107 Loss_G: 0.0420 Convergence: 0.1166 k= 0.056255 lr = 0.0000857\n",
      "[1/25][2070/9765] Loss_D: 0.1139 Loss_G: 0.0457 Convergence: 0.1172 k= 0.056294 lr = 0.0000857\n",
      "[1/25][2080/9765] Loss_D: 0.1229 Loss_G: 0.0441 Convergence: 0.1315 k= 0.056299 lr = 0.0000857\n",
      "[1/25][2090/9765] Loss_D: 0.1236 Loss_G: 0.0637 Convergence: 0.1394 k= 0.056319 lr = 0.0000857\n",
      "[1/25][2100/9765] Loss_D: 0.1222 Loss_G: 0.0435 Convergence: 0.1306 k= 0.056358 lr = 0.0000857\n",
      "[1/25][2110/9765] Loss_D: 0.1253 Loss_G: 0.0397 Convergence: 0.1405 k= 0.056359 lr = 0.0000857\n",
      "[1/25][2120/9765] Loss_D: 0.1162 Loss_G: 0.0396 Convergence: 0.1268 k= 0.056394 lr = 0.0000857\n",
      "[1/25][2130/9765] Loss_D: 0.1215 Loss_G: 0.0684 Convergence: 0.1435 k= 0.056338 lr = 0.0000857\n",
      "[1/25][2140/9765] Loss_D: 0.1063 Loss_G: 0.0417 Convergence: 0.1107 k= 0.056295 lr = 0.0000857\n",
      "[1/25][2150/9765] Loss_D: 0.1231 Loss_G: 0.0462 Convergence: 0.1294 k= 0.056335 lr = 0.0000857\n",
      "[1/25][2160/9765] Loss_D: 0.1169 Loss_G: 0.0424 Convergence: 0.1244 k= 0.056381 lr = 0.0000857\n",
      "[1/25][2170/9765] Loss_D: 0.1171 Loss_G: 0.0460 Convergence: 0.1215 k= 0.056423 lr = 0.0000857\n",
      "[1/25][2180/9765] Loss_D: 0.1209 Loss_G: 0.0406 Convergence: 0.1330 k= 0.056435 lr = 0.0000857\n",
      "[1/25][2190/9765] Loss_D: 0.1288 Loss_G: 0.0499 Convergence: 0.1337 k= 0.056439 lr = 0.0000857\n",
      "[1/25][2200/9765] Loss_D: 0.1119 Loss_G: 0.0425 Convergence: 0.1177 k= 0.056459 lr = 0.0000857\n",
      "[1/25][2210/9765] Loss_D: 0.1067 Loss_G: 0.0418 Convergence: 0.1111 k= 0.056477 lr = 0.0000857\n",
      "[1/25][2220/9765] Loss_D: 0.1076 Loss_G: 0.0456 Convergence: 0.1117 k= 0.056467 lr = 0.0000857\n",
      "[1/25][2230/9765] Loss_D: 0.1200 Loss_G: 0.0497 Convergence: 0.1232 k= 0.056443 lr = 0.0000857\n",
      "[1/25][2240/9765] Loss_D: 0.1217 Loss_G: 0.0544 Convergence: 0.1289 k= 0.056445 lr = 0.0000815\n",
      "[1/25][2250/9765] Loss_D: 0.1147 Loss_G: 0.0450 Convergence: 0.1195 k= 0.056459 lr = 0.0000815\n",
      "[1/25][2260/9765] Loss_D: 0.1174 Loss_G: 0.0498 Convergence: 0.1218 k= 0.056438 lr = 0.0000815\n",
      "[1/25][2270/9765] Loss_D: 0.1130 Loss_G: 0.0395 Convergence: 0.1221 k= 0.056468 lr = 0.0000815\n",
      "[1/25][2280/9765] Loss_D: 0.1125 Loss_G: 0.0435 Convergence: 0.1172 k= 0.056496 lr = 0.0000815\n",
      "[1/25][2290/9765] Loss_D: 0.1131 Loss_G: 0.0424 Convergence: 0.1194 k= 0.056527 lr = 0.0000815\n",
      "[1/25][2300/9765] Loss_D: 0.1105 Loss_G: 0.0376 Convergence: 0.1199 k= 0.056568 lr = 0.0000815\n",
      "[1/25][2310/9765] Loss_D: 0.1303 Loss_G: 0.0561 Convergence: 0.1359 k= 0.056532 lr = 0.0000815\n",
      "[1/25][2320/9765] Loss_D: 0.1182 Loss_G: 0.0482 Convergence: 0.1207 k= 0.056547 lr = 0.0000815\n",
      "[1/25][2330/9765] Loss_D: 0.1202 Loss_G: 0.0451 Convergence: 0.1268 k= 0.056547 lr = 0.0000815\n",
      "[1/25][2340/9765] Loss_D: 0.1107 Loss_G: 0.0451 Convergence: 0.1144 k= 0.056534 lr = 0.0000815\n",
      "[1/25][2350/9765] Loss_D: 0.1141 Loss_G: 0.0429 Convergence: 0.1201 k= 0.056568 lr = 0.0000815\n",
      "[1/25][2360/9765] Loss_D: 0.1120 Loss_G: 0.0429 Convergence: 0.1178 k= 0.056593 lr = 0.0000815\n",
      "[1/25][2370/9765] Loss_D: 0.1228 Loss_G: 0.0512 Convergence: 0.1265 k= 0.056591 lr = 0.0000815\n",
      "[1/25][2380/9765] Loss_D: 0.1171 Loss_G: 0.0391 Convergence: 0.1285 k= 0.056621 lr = 0.0000815\n",
      "[1/25][2390/9765] Loss_D: 0.1184 Loss_G: 0.0439 Convergence: 0.1256 k= 0.056619 lr = 0.0000815\n",
      "[1/25][2400/9765] Loss_D: 0.1159 Loss_G: 0.0409 Convergence: 0.1245 k= 0.056655 lr = 0.0000815\n",
      "[1/25][2410/9765] Loss_D: 0.1126 Loss_G: 0.0512 Convergence: 0.1203 k= 0.056656 lr = 0.0000815\n",
      "[1/25][2420/9765] Loss_D: 0.1200 Loss_G: 0.0429 Convergence: 0.1289 k= 0.056666 lr = 0.0000815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][2430/9765] Loss_D: 0.1136 Loss_G: 0.0456 Convergence: 0.1173 k= 0.056673 lr = 0.0000815\n",
      "[1/25][2440/9765] Loss_D: 0.1205 Loss_G: 0.0451 Convergence: 0.1271 k= 0.056648 lr = 0.0000815\n",
      "[1/25][2450/9765] Loss_D: 0.1202 Loss_G: 0.0603 Convergence: 0.1337 k= 0.056661 lr = 0.0000815\n",
      "[1/25][2460/9765] Loss_D: 0.1227 Loss_G: 0.0444 Convergence: 0.1307 k= 0.056642 lr = 0.0000815\n",
      "[1/25][2470/9765] Loss_D: 0.1096 Loss_G: 0.0420 Convergence: 0.1151 k= 0.056659 lr = 0.0000815\n",
      "[1/25][2480/9765] Loss_D: 0.1143 Loss_G: 0.0453 Convergence: 0.1186 k= 0.056690 lr = 0.0000815\n",
      "[1/25][2490/9765] Loss_D: 0.1138 Loss_G: 0.0487 Convergence: 0.1189 k= 0.056668 lr = 0.0000815\n",
      "[1/25][2500/9765] Loss_D: 0.1157 Loss_G: 0.0422 Convergence: 0.1230 k= 0.056680 lr = 0.0000815\n",
      "[1/25][2510/9765] Loss_D: 0.1082 Loss_G: 0.0493 Convergence: 0.1158 k= 0.056678 lr = 0.0000815\n",
      "[1/25][2520/9765] Loss_D: 0.1269 Loss_G: 0.0417 Convergence: 0.1390 k= 0.056683 lr = 0.0000815\n",
      "[1/25][2530/9765] Loss_D: 0.1163 Loss_G: 0.0540 Convergence: 0.1255 k= 0.056681 lr = 0.0000815\n",
      "[1/25][2540/9765] Loss_D: 0.1195 Loss_G: 0.0465 Convergence: 0.1240 k= 0.056690 lr = 0.0000815\n",
      "[1/25][2550/9765] Loss_D: 0.1173 Loss_G: 0.0529 Convergence: 0.1249 k= 0.056709 lr = 0.0000815\n",
      "[1/25][2560/9765] Loss_D: 0.1125 Loss_G: 0.0479 Convergence: 0.1169 k= 0.056704 lr = 0.0000815\n",
      "[1/25][2570/9765] Loss_D: 0.1159 Loss_G: 0.0494 Convergence: 0.1206 k= 0.056727 lr = 0.0000815\n",
      "[1/25][2580/9765] Loss_D: 0.1121 Loss_G: 0.0478 Convergence: 0.1166 k= 0.056729 lr = 0.0000815\n",
      "[1/25][2590/9765] Loss_D: 0.1136 Loss_G: 0.0498 Convergence: 0.1195 k= 0.056744 lr = 0.0000815\n",
      "[1/25][2600/9765] Loss_D: 0.1166 Loss_G: 0.0438 Convergence: 0.1229 k= 0.056790 lr = 0.0000815\n",
      "[1/25][2610/9765] Loss_D: 0.1191 Loss_G: 0.0456 Convergence: 0.1252 k= 0.056793 lr = 0.0000815\n",
      "[1/25][2620/9765] Loss_D: 0.1114 Loss_G: 0.0442 Convergence: 0.1152 k= 0.056807 lr = 0.0000815\n",
      "[1/25][2630/9765] Loss_D: 0.1214 Loss_G: 0.0512 Convergence: 0.1257 k= 0.056788 lr = 0.0000815\n",
      "[1/25][2640/9765] Loss_D: 0.1110 Loss_G: 0.0366 Convergence: 0.1221 k= 0.056825 lr = 0.0000815\n",
      "[1/25][2650/9765] Loss_D: 0.1057 Loss_G: 0.0457 Convergence: 0.1107 k= 0.056851 lr = 0.0000815\n",
      "[1/25][2660/9765] Loss_D: 0.1171 Loss_G: 0.0454 Convergence: 0.1230 k= 0.056862 lr = 0.0000815\n",
      "[1/25][2670/9765] Loss_D: 0.1240 Loss_G: 0.0468 Convergence: 0.1302 k= 0.056865 lr = 0.0000815\n",
      "[1/25][2680/9765] Loss_D: 0.1191 Loss_G: 0.0411 Convergence: 0.1293 k= 0.056839 lr = 0.0000815\n",
      "[1/25][2690/9765] Loss_D: 0.1033 Loss_G: 0.0423 Convergence: 0.1056 k= 0.056856 lr = 0.0000815\n",
      "[1/25][2700/9765] Loss_D: 0.1203 Loss_G: 0.0517 Convergence: 0.1252 k= 0.056834 lr = 0.0000815\n",
      "[1/25][2710/9765] Loss_D: 0.1236 Loss_G: 0.0579 Convergence: 0.1345 k= 0.056735 lr = 0.0000815\n",
      "[1/25][2720/9765] Loss_D: 0.1125 Loss_G: 0.0426 Convergence: 0.1186 k= 0.056684 lr = 0.0000815\n",
      "[1/25][2730/9765] Loss_D: 0.1198 Loss_G: 0.0448 Convergence: 0.1262 k= 0.056715 lr = 0.0000815\n",
      "[1/25][2740/9765] Loss_D: 0.1164 Loss_G: 0.0450 Convergence: 0.1221 k= 0.056717 lr = 0.0000815\n",
      "[1/25][2750/9765] Loss_D: 0.1151 Loss_G: 0.0544 Convergence: 0.1250 k= 0.056740 lr = 0.0000815\n",
      "[1/25][2760/9765] Loss_D: 0.1246 Loss_G: 0.0469 Convergence: 0.1314 k= 0.056750 lr = 0.0000815\n",
      "[1/25][2770/9765] Loss_D: 0.1178 Loss_G: 0.0465 Convergence: 0.1217 k= 0.056781 lr = 0.0000815\n",
      "[1/25][2780/9765] Loss_D: 0.1173 Loss_G: 0.0424 Convergence: 0.1257 k= 0.056794 lr = 0.0000815\n",
      "[1/25][2790/9765] Loss_D: 0.1299 Loss_G: 0.0480 Convergence: 0.1369 k= 0.056782 lr = 0.0000815\n",
      "[1/25][2800/9765] Loss_D: 0.1076 Loss_G: 0.0561 Convergence: 0.1220 k= 0.056808 lr = 0.0000815\n",
      "[1/25][2810/9765] Loss_D: 0.1153 Loss_G: 0.0382 Convergence: 0.1266 k= 0.056832 lr = 0.0000815\n",
      "[1/25][2820/9765] Loss_D: 0.1094 Loss_G: 0.0561 Convergence: 0.1234 k= 0.056801 lr = 0.0000815\n",
      "[1/25][2830/9765] Loss_D: 0.1123 Loss_G: 0.0435 Convergence: 0.1171 k= 0.056818 lr = 0.0000815\n",
      "[1/25][2840/9765] Loss_D: 0.1150 Loss_G: 0.0407 Convergence: 0.1236 k= 0.056862 lr = 0.0000815\n",
      "[1/25][2850/9765] Loss_D: 0.1166 Loss_G: 0.0477 Convergence: 0.1192 k= 0.056855 lr = 0.0000815\n",
      "[1/25][2860/9765] Loss_D: 0.1072 Loss_G: 0.0426 Convergence: 0.1108 k= 0.056872 lr = 0.0000815\n",
      "[1/25][2870/9765] Loss_D: 0.1080 Loss_G: 0.0462 Convergence: 0.1125 k= 0.056902 lr = 0.0000815\n",
      "[1/25][2880/9765] Loss_D: 0.1103 Loss_G: 0.0497 Convergence: 0.1177 k= 0.056909 lr = 0.0000815\n",
      "[1/25][2890/9765] Loss_D: 0.1098 Loss_G: 0.0408 Convergence: 0.1160 k= 0.056953 lr = 0.0000815\n",
      "[1/25][2900/9765] Loss_D: 0.1172 Loss_G: 0.0394 Convergence: 0.1284 k= 0.056957 lr = 0.0000815\n",
      "[1/25][2910/9765] Loss_D: 0.1152 Loss_G: 0.0442 Convergence: 0.1201 k= 0.056969 lr = 0.0000815\n",
      "[1/25][2920/9765] Loss_D: 0.1080 Loss_G: 0.0520 Convergence: 0.1184 k= 0.056973 lr = 0.0000815\n",
      "[1/25][2930/9765] Loss_D: 0.1023 Loss_G: 0.0420 Convergence: 0.1049 k= 0.057004 lr = 0.0000815\n",
      "[1/25][2940/9765] Loss_D: 0.1163 Loss_G: 0.0393 Convergence: 0.1265 k= 0.057028 lr = 0.0000815\n",
      "[1/25][2950/9765] Loss_D: 0.1080 Loss_G: 0.0409 Convergence: 0.1134 k= 0.057065 lr = 0.0000815\n",
      "[1/25][2960/9765] Loss_D: 0.1113 Loss_G: 0.0465 Convergence: 0.1147 k= 0.057090 lr = 0.0000815\n",
      "[1/25][2970/9765] Loss_D: 0.1130 Loss_G: 0.0455 Convergence: 0.1166 k= 0.057123 lr = 0.0000815\n",
      "[1/25][2980/9765] Loss_D: 0.1200 Loss_G: 0.0525 Convergence: 0.1258 k= 0.057147 lr = 0.0000815\n",
      "[1/25][2990/9765] Loss_D: 0.1194 Loss_G: 0.0429 Convergence: 0.1299 k= 0.057114 lr = 0.0000815\n",
      "[1/25][3000/9765] Loss_D: 0.1217 Loss_G: 0.0476 Convergence: 0.1262 k= 0.057124 lr = 0.0000815\n",
      "[1/25][3010/9765] Loss_D: 0.1123 Loss_G: 0.0416 Convergence: 0.1187 k= 0.057163 lr = 0.0000815\n",
      "[1/25][3020/9765] Loss_D: 0.1103 Loss_G: 0.0589 Convergence: 0.1269 k= 0.057131 lr = 0.0000815\n",
      "[1/25][3030/9765] Loss_D: 0.1005 Loss_G: 0.0424 Convergence: 0.1043 k= 0.057116 lr = 0.0000815\n",
      "[1/25][3040/9765] Loss_D: 0.1199 Loss_G: 0.0420 Convergence: 0.1295 k= 0.057129 lr = 0.0000815\n",
      "[1/25][3050/9765] Loss_D: 0.1206 Loss_G: 0.0423 Convergence: 0.1300 k= 0.057155 lr = 0.0000815\n",
      "[1/25][3060/9765] Loss_D: 0.1179 Loss_G: 0.0429 Convergence: 0.1255 k= 0.057176 lr = 0.0000815\n",
      "[1/25][3070/9765] Loss_D: 0.1142 Loss_G: 0.0445 Convergence: 0.1193 k= 0.057174 lr = 0.0000815\n",
      "[1/25][3080/9765] Loss_D: 0.1099 Loss_G: 0.0426 Convergence: 0.1155 k= 0.057158 lr = 0.0000815\n",
      "[1/25][3090/9765] Loss_D: 0.1158 Loss_G: 0.0398 Convergence: 0.1261 k= 0.057179 lr = 0.0000815\n",
      "[1/25][3100/9765] Loss_D: 0.1115 Loss_G: 0.0517 Convergence: 0.1201 k= 0.057183 lr = 0.0000815\n",
      "[1/25][3110/9765] Loss_D: 0.1058 Loss_G: 0.0429 Convergence: 0.1084 k= 0.057215 lr = 0.0000815\n",
      "[1/25][3120/9765] Loss_D: 0.1252 Loss_G: 0.0409 Convergence: 0.1380 k= 0.057259 lr = 0.0000815\n",
      "[1/25][3130/9765] Loss_D: 0.1163 Loss_G: 0.0408 Convergence: 0.1256 k= 0.057273 lr = 0.0000815\n",
      "[1/25][3140/9765] Loss_D: 0.1226 Loss_G: 0.0475 Convergence: 0.1278 k= 0.057299 lr = 0.0000815\n",
      "[1/25][3150/9765] Loss_D: 0.1118 Loss_G: 0.0435 Convergence: 0.1168 k= 0.057258 lr = 0.0000815\n",
      "[1/25][3160/9765] Loss_D: 0.1138 Loss_G: 0.0473 Convergence: 0.1171 k= 0.057272 lr = 0.0000815\n",
      "[1/25][3170/9765] Loss_D: 0.1086 Loss_G: 0.0493 Convergence: 0.1161 k= 0.057276 lr = 0.0000815\n",
      "[1/25][3180/9765] Loss_D: 0.1146 Loss_G: 0.0688 Convergence: 0.1395 k= 0.057226 lr = 0.0000815\n",
      "[1/25][3190/9765] Loss_D: 0.1142 Loss_G: 0.0469 Convergence: 0.1170 k= 0.057204 lr = 0.0000815\n",
      "[1/25][3200/9765] Loss_D: 0.1161 Loss_G: 0.0443 Convergence: 0.1215 k= 0.057213 lr = 0.0000815\n",
      "[1/25][3210/9765] Loss_D: 0.1050 Loss_G: 0.0432 Convergence: 0.1076 k= 0.057229 lr = 0.0000815\n",
      "[1/25][3220/9765] Loss_D: 0.1123 Loss_G: 0.0446 Convergence: 0.1159 k= 0.057251 lr = 0.0000815\n",
      "[1/25][3230/9765] Loss_D: 0.1143 Loss_G: 0.0501 Convergence: 0.1207 k= 0.057255 lr = 0.0000815\n",
      "[1/25][3240/9765] Loss_D: 0.1207 Loss_G: 0.0412 Convergence: 0.1313 k= 0.057250 lr = 0.0000815\n",
      "[1/25][3250/9765] Loss_D: 0.1165 Loss_G: 0.0509 Convergence: 0.1222 k= 0.057258 lr = 0.0000815\n",
      "[1/25][3260/9765] Loss_D: 0.1108 Loss_G: 0.0421 Convergence: 0.1170 k= 0.057249 lr = 0.0000815\n",
      "[1/25][3270/9765] Loss_D: 0.1114 Loss_G: 0.0515 Convergence: 0.1198 k= 0.057246 lr = 0.0000815\n",
      "[1/25][3280/9765] Loss_D: 0.1107 Loss_G: 0.0415 Convergence: 0.1172 k= 0.057236 lr = 0.0000815\n",
      "[1/25][3290/9765] Loss_D: 0.1249 Loss_G: 0.0448 Convergence: 0.1334 k= 0.057213 lr = 0.0000815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][3300/9765] Loss_D: 0.1126 Loss_G: 0.0540 Convergence: 0.1229 k= 0.057191 lr = 0.0000815\n",
      "[1/25][3310/9765] Loss_D: 0.1221 Loss_G: 0.0445 Convergence: 0.1296 k= 0.057208 lr = 0.0000815\n",
      "[1/25][3320/9765] Loss_D: 0.1131 Loss_G: 0.0489 Convergence: 0.1184 k= 0.057203 lr = 0.0000815\n",
      "[1/25][3330/9765] Loss_D: 0.1159 Loss_G: 0.0548 Convergence: 0.1259 k= 0.057210 lr = 0.0000815\n",
      "[1/25][3340/9765] Loss_D: 0.1180 Loss_G: 0.0415 Convergence: 0.1270 k= 0.057232 lr = 0.0000815\n",
      "[1/25][3350/9765] Loss_D: 0.1128 Loss_G: 0.0475 Convergence: 0.1170 k= 0.057229 lr = 0.0000815\n",
      "[1/25][3360/9765] Loss_D: 0.1204 Loss_G: 0.0474 Convergence: 0.1258 k= 0.057210 lr = 0.0000815\n",
      "[1/25][3370/9765] Loss_D: 0.1198 Loss_G: 0.0520 Convergence: 0.1256 k= 0.057146 lr = 0.0000815\n",
      "[1/25][3380/9765] Loss_D: 0.1154 Loss_G: 0.0439 Convergence: 0.1213 k= 0.057149 lr = 0.0000815\n",
      "[1/25][3390/9765] Loss_D: 0.1126 Loss_G: 0.0464 Convergence: 0.1157 k= 0.057142 lr = 0.0000815\n",
      "[1/25][3400/9765] Loss_D: 0.1186 Loss_G: 0.0501 Convergence: 0.1227 k= 0.057134 lr = 0.0000815\n",
      "[1/25][3410/9765] Loss_D: 0.1034 Loss_G: 0.0396 Convergence: 0.1090 k= 0.057151 lr = 0.0000815\n",
      "[1/25][3420/9765] Loss_D: 0.1148 Loss_G: 0.0468 Convergence: 0.1174 k= 0.057166 lr = 0.0000815\n",
      "[1/25][3430/9765] Loss_D: 0.1209 Loss_G: 0.0528 Convergence: 0.1270 k= 0.057152 lr = 0.0000815\n",
      "[1/25][3440/9765] Loss_D: 0.1060 Loss_G: 0.0457 Convergence: 0.1108 k= 0.057140 lr = 0.0000815\n",
      "[1/25][3450/9765] Loss_D: 0.1302 Loss_G: 0.0588 Convergence: 0.1385 k= 0.057126 lr = 0.0000815\n",
      "[1/25][3460/9765] Loss_D: 0.1218 Loss_G: 0.0521 Convergence: 0.1266 k= 0.057140 lr = 0.0000815\n",
      "[1/25][3470/9765] Loss_D: 0.1190 Loss_G: 0.0451 Convergence: 0.1248 k= 0.057163 lr = 0.0000815\n",
      "[1/25][3480/9765] Loss_D: 0.1189 Loss_G: 0.0450 Convergence: 0.1249 k= 0.057167 lr = 0.0000815\n",
      "[1/25][3490/9765] Loss_D: 0.1090 Loss_G: 0.0400 Convergence: 0.1162 k= 0.057169 lr = 0.0000815\n",
      "[1/25][3500/9765] Loss_D: 0.1255 Loss_G: 0.0494 Convergence: 0.1303 k= 0.057160 lr = 0.0000815\n",
      "[1/25][3510/9765] Loss_D: 0.1123 Loss_G: 0.0432 Convergence: 0.1172 k= 0.057158 lr = 0.0000815\n",
      "[1/25][3520/9765] Loss_D: 0.1100 Loss_G: 0.0398 Convergence: 0.1174 k= 0.057193 lr = 0.0000815\n",
      "[1/25][3530/9765] Loss_D: 0.1201 Loss_G: 0.0470 Convergence: 0.1256 k= 0.057180 lr = 0.0000815\n",
      "[1/25][3540/9765] Loss_D: 0.1289 Loss_G: 0.0470 Convergence: 0.1370 k= 0.057193 lr = 0.0000815\n",
      "[1/25][3550/9765] Loss_D: 0.1159 Loss_G: 0.0459 Convergence: 0.1205 k= 0.057193 lr = 0.0000815\n",
      "[1/25][3560/9765] Loss_D: 0.1141 Loss_G: 0.0456 Convergence: 0.1176 k= 0.057210 lr = 0.0000815\n",
      "[1/25][3570/9765] Loss_D: 0.1065 Loss_G: 0.0459 Convergence: 0.1115 k= 0.057230 lr = 0.0000815\n",
      "[1/25][3580/9765] Loss_D: 0.1163 Loss_G: 0.0452 Convergence: 0.1211 k= 0.057251 lr = 0.0000815\n",
      "[1/25][3590/9765] Loss_D: 0.1179 Loss_G: 0.0478 Convergence: 0.1209 k= 0.057269 lr = 0.0000815\n",
      "[1/25][3600/9765] Loss_D: 0.1279 Loss_G: 0.0551 Convergence: 0.1336 k= 0.057242 lr = 0.0000815\n",
      "[1/25][3610/9765] Loss_D: 0.1114 Loss_G: 0.0391 Convergence: 0.1205 k= 0.057179 lr = 0.0000815\n",
      "[1/25][3620/9765] Loss_D: 0.1109 Loss_G: 0.0445 Convergence: 0.1148 k= 0.057183 lr = 0.0000815\n",
      "[1/25][3630/9765] Loss_D: 0.1119 Loss_G: 0.0442 Convergence: 0.1162 k= 0.057204 lr = 0.0000815\n",
      "[1/25][3640/9765] Loss_D: 0.1000 Loss_G: 0.0473 Convergence: 0.1088 k= 0.057215 lr = 0.0000815\n",
      "[1/25][3650/9765] Loss_D: 0.1211 Loss_G: 0.0527 Convergence: 0.1270 k= 0.057240 lr = 0.0000815\n",
      "[1/25][3660/9765] Loss_D: 0.1174 Loss_G: 0.0458 Convergence: 0.1220 k= 0.057254 lr = 0.0000815\n",
      "[1/25][3670/9765] Loss_D: 0.1173 Loss_G: 0.0548 Convergence: 0.1267 k= 0.057224 lr = 0.0000815\n",
      "[1/25][3680/9765] Loss_D: 0.1058 Loss_G: 0.0439 Convergence: 0.1090 k= 0.057222 lr = 0.0000815\n",
      "[1/25][3690/9765] Loss_D: 0.1117 Loss_G: 0.0466 Convergence: 0.1152 k= 0.057205 lr = 0.0000815\n",
      "[1/25][3700/9765] Loss_D: 0.1264 Loss_G: 0.0511 Convergence: 0.1294 k= 0.057185 lr = 0.0000815\n",
      "[1/25][3710/9765] Loss_D: 0.1079 Loss_G: 0.0433 Convergence: 0.1113 k= 0.057197 lr = 0.0000815\n",
      "[1/25][3720/9765] Loss_D: 0.1074 Loss_G: 0.0437 Convergence: 0.1101 k= 0.057169 lr = 0.0000815\n",
      "[1/25][3730/9765] Loss_D: 0.1239 Loss_G: 0.0521 Convergence: 0.1279 k= 0.057179 lr = 0.0000815\n",
      "[1/25][3740/9765] Loss_D: 0.1193 Loss_G: 0.0444 Convergence: 0.1263 k= 0.057131 lr = 0.0000815\n",
      "[1/25][3750/9765] Loss_D: 0.1152 Loss_G: 0.0427 Convergence: 0.1219 k= 0.057163 lr = 0.0000815\n",
      "[1/25][3760/9765] Loss_D: 0.1076 Loss_G: 0.0421 Convergence: 0.1120 k= 0.057164 lr = 0.0000815\n",
      "[1/25][3770/9765] Loss_D: 0.1123 Loss_G: 0.0528 Convergence: 0.1223 k= 0.057099 lr = 0.0000815\n",
      "[1/25][3780/9765] Loss_D: 0.1143 Loss_G: 0.0484 Convergence: 0.1184 k= 0.057080 lr = 0.0000815\n",
      "[1/25][3790/9765] Loss_D: 0.1061 Loss_G: 0.0431 Convergence: 0.1089 k= 0.057080 lr = 0.0000815\n",
      "[1/25][3800/9765] Loss_D: 0.1069 Loss_G: 0.0451 Convergence: 0.1105 k= 0.057102 lr = 0.0000815\n",
      "[1/25][3810/9765] Loss_D: 0.1147 Loss_G: 0.0408 Convergence: 0.1232 k= 0.057122 lr = 0.0000815\n",
      "[1/25][3820/9765] Loss_D: 0.1109 Loss_G: 0.0534 Convergence: 0.1218 k= 0.057127 lr = 0.0000815\n",
      "[1/25][3830/9765] Loss_D: 0.1237 Loss_G: 0.0527 Convergence: 0.1284 k= 0.057131 lr = 0.0000815\n",
      "[1/25][3840/9765] Loss_D: 0.1148 Loss_G: 0.0572 Convergence: 0.1277 k= 0.057117 lr = 0.0000815\n",
      "[1/25][3850/9765] Loss_D: 0.1146 Loss_G: 0.0476 Convergence: 0.1179 k= 0.057064 lr = 0.0000815\n",
      "[1/25][3860/9765] Loss_D: 0.1132 Loss_G: 0.0474 Convergence: 0.1168 k= 0.057058 lr = 0.0000815\n",
      "[1/25][3870/9765] Loss_D: 0.1126 Loss_G: 0.0486 Convergence: 0.1175 k= 0.057075 lr = 0.0000815\n",
      "[1/25][3880/9765] Loss_D: 0.1081 Loss_G: 0.0452 Convergence: 0.1117 k= 0.057086 lr = 0.0000815\n",
      "[1/25][3890/9765] Loss_D: 0.1110 Loss_G: 0.0400 Convergence: 0.1189 k= 0.057091 lr = 0.0000815\n",
      "[1/25][3900/9765] Loss_D: 0.1115 Loss_G: 0.0467 Convergence: 0.1151 k= 0.057061 lr = 0.0000815\n",
      "[1/25][3910/9765] Loss_D: 0.1205 Loss_G: 0.0455 Convergence: 0.1268 k= 0.057089 lr = 0.0000815\n",
      "[1/25][3920/9765] Loss_D: 0.1076 Loss_G: 0.0499 Convergence: 0.1161 k= 0.057086 lr = 0.0000815\n",
      "[1/25][3930/9765] Loss_D: 0.1202 Loss_G: 0.0440 Convergence: 0.1275 k= 0.057105 lr = 0.0000815\n",
      "[1/25][3940/9765] Loss_D: 0.1081 Loss_G: 0.0451 Convergence: 0.1113 k= 0.057106 lr = 0.0000815\n",
      "[1/25][3950/9765] Loss_D: 0.1165 Loss_G: 0.0537 Convergence: 0.1250 k= 0.057117 lr = 0.0000815\n",
      "[1/25][3960/9765] Loss_D: 0.1120 Loss_G: 0.0440 Convergence: 0.1165 k= 0.057130 lr = 0.0000815\n",
      "[1/25][3970/9765] Loss_D: 0.1099 Loss_G: 0.0481 Convergence: 0.1154 k= 0.057130 lr = 0.0000815\n",
      "[1/25][3980/9765] Loss_D: 0.1143 Loss_G: 0.0454 Convergence: 0.1186 k= 0.057137 lr = 0.0000815\n",
      "[1/25][3990/9765] Loss_D: 0.1176 Loss_G: 0.0452 Convergence: 0.1224 k= 0.057165 lr = 0.0000815\n",
      "[1/25][4000/9765] Loss_D: 0.1204 Loss_G: 0.0462 Convergence: 0.1265 k= 0.057152 lr = 0.0000815\n",
      "[1/25][4010/9765] Loss_D: 0.1032 Loss_G: 0.0442 Convergence: 0.1077 k= 0.057153 lr = 0.0000815\n",
      "[1/25][4020/9765] Loss_D: 0.1205 Loss_G: 0.0469 Convergence: 0.1255 k= 0.057132 lr = 0.0000815\n",
      "[1/25][4030/9765] Loss_D: 0.1157 Loss_G: 0.0475 Convergence: 0.1186 k= 0.057141 lr = 0.0000815\n",
      "[1/25][4040/9765] Loss_D: 0.1255 Loss_G: 0.0447 Convergence: 0.1348 k= 0.057144 lr = 0.0000815\n",
      "[1/25][4050/9765] Loss_D: 0.1056 Loss_G: 0.0495 Convergence: 0.1145 k= 0.057130 lr = 0.0000815\n",
      "[1/25][4060/9765] Loss_D: 0.1116 Loss_G: 0.0422 Convergence: 0.1177 k= 0.057125 lr = 0.0000815\n",
      "[1/25][4070/9765] Loss_D: 0.1092 Loss_G: 0.0386 Convergence: 0.1176 k= 0.057153 lr = 0.0000815\n",
      "[1/25][4080/9765] Loss_D: 0.1132 Loss_G: 0.0435 Convergence: 0.1184 k= 0.057175 lr = 0.0000815\n",
      "[1/25][4090/9765] Loss_D: 0.1332 Loss_G: 0.0493 Convergence: 0.1424 k= 0.057128 lr = 0.0000815\n",
      "[1/25][4100/9765] Loss_D: 0.1098 Loss_G: 0.0427 Convergence: 0.1143 k= 0.057119 lr = 0.0000815\n",
      "[1/25][4110/9765] Loss_D: 0.1172 Loss_G: 0.0480 Convergence: 0.1204 k= 0.057099 lr = 0.0000815\n",
      "[1/25][4120/9765] Loss_D: 0.1211 Loss_G: 0.0495 Convergence: 0.1235 k= 0.057126 lr = 0.0000815\n",
      "[1/25][4130/9765] Loss_D: 0.1158 Loss_G: 0.0480 Convergence: 0.1191 k= 0.057139 lr = 0.0000815\n",
      "[1/25][4140/9765] Loss_D: 0.1090 Loss_G: 0.0578 Convergence: 0.1250 k= 0.057057 lr = 0.0000815\n",
      "[1/25][4150/9765] Loss_D: 0.1068 Loss_G: 0.0458 Convergence: 0.1114 k= 0.057016 lr = 0.0000815\n",
      "[1/25][4160/9765] Loss_D: 0.1093 Loss_G: 0.0527 Convergence: 0.1197 k= 0.057027 lr = 0.0000815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][4170/9765] Loss_D: 0.1183 Loss_G: 0.0443 Convergence: 0.1248 k= 0.057055 lr = 0.0000815\n",
      "[1/25][4180/9765] Loss_D: 0.1228 Loss_G: 0.0499 Convergence: 0.1255 k= 0.057056 lr = 0.0000815\n",
      "[1/25][4190/9765] Loss_D: 0.1176 Loss_G: 0.0477 Convergence: 0.1201 k= 0.057066 lr = 0.0000815\n",
      "[1/25][4200/9765] Loss_D: 0.1146 Loss_G: 0.0408 Convergence: 0.1232 k= 0.057062 lr = 0.0000815\n",
      "[1/25][4210/9765] Loss_D: 0.1118 Loss_G: 0.0459 Convergence: 0.1145 k= 0.057082 lr = 0.0000815\n",
      "[1/25][4220/9765] Loss_D: 0.1232 Loss_G: 0.0641 Convergence: 0.1398 k= 0.057070 lr = 0.0000815\n",
      "[1/25][4230/9765] Loss_D: 0.1205 Loss_G: 0.0491 Convergence: 0.1234 k= 0.057037 lr = 0.0000815\n",
      "[1/25][4240/9765] Loss_D: 0.1157 Loss_G: 0.0442 Convergence: 0.1214 k= 0.057060 lr = 0.0000815\n",
      "[1/25][4250/9765] Loss_D: 0.1086 Loss_G: 0.0408 Convergence: 0.1150 k= 0.057071 lr = 0.0000815\n",
      "[1/25][4260/9765] Loss_D: 0.1081 Loss_G: 0.0463 Convergence: 0.1128 k= 0.057070 lr = 0.0000815\n",
      "[1/25][4270/9765] Loss_D: 0.1232 Loss_G: 0.0484 Convergence: 0.1277 k= 0.057070 lr = 0.0000815\n",
      "[1/25][4280/9765] Loss_D: 0.1172 Loss_G: 0.0447 Convergence: 0.1232 k= 0.057063 lr = 0.0000815\n",
      "[1/25][4290/9765] Loss_D: 0.1153 Loss_G: 0.0503 Convergence: 0.1213 k= 0.057045 lr = 0.0000815\n",
      "[1/25][4300/9765] Loss_D: 0.1040 Loss_G: 0.0418 Convergence: 0.1070 k= 0.057007 lr = 0.0000815\n",
      "[1/25][4310/9765] Loss_D: 0.1105 Loss_G: 0.0443 Convergence: 0.1136 k= 0.057041 lr = 0.0000815\n",
      "[1/25][4320/9765] Loss_D: 0.1143 Loss_G: 0.0507 Convergence: 0.1207 k= 0.057046 lr = 0.0000815\n",
      "[1/25][4330/9765] Loss_D: 0.1173 Loss_G: 0.0474 Convergence: 0.1208 k= 0.057057 lr = 0.0000815\n",
      "[1/25][4340/9765] Loss_D: 0.1213 Loss_G: 0.0501 Convergence: 0.1245 k= 0.057059 lr = 0.0000815\n",
      "[1/25][4350/9765] Loss_D: 0.1052 Loss_G: 0.0444 Convergence: 0.1089 k= 0.057073 lr = 0.0000815\n",
      "[1/25][4360/9765] Loss_D: 0.1119 Loss_G: 0.0456 Convergence: 0.1151 k= 0.057062 lr = 0.0000815\n",
      "[1/25][4370/9765] Loss_D: 0.1000 Loss_G: 0.0433 Convergence: 0.1050 k= 0.057059 lr = 0.0000815\n",
      "[1/25][4380/9765] Loss_D: 0.1212 Loss_G: 0.0548 Convergence: 0.1292 k= 0.057048 lr = 0.0000815\n",
      "[1/25][4390/9765] Loss_D: 0.1185 Loss_G: 0.0534 Convergence: 0.1259 k= 0.057047 lr = 0.0000815\n",
      "[1/25][4400/9765] Loss_D: 0.1072 Loss_G: 0.0395 Convergence: 0.1141 k= 0.057055 lr = 0.0000815\n",
      "[1/25][4410/9765] Loss_D: 0.1135 Loss_G: 0.0527 Convergence: 0.1225 k= 0.057058 lr = 0.0000815\n",
      "[1/25][4420/9765] Loss_D: 0.1110 Loss_G: 0.0482 Convergence: 0.1163 k= 0.057075 lr = 0.0000815\n",
      "[1/25][4430/9765] Loss_D: 0.1179 Loss_G: 0.0464 Convergence: 0.1223 k= 0.057088 lr = 0.0000815\n",
      "[1/25][4440/9765] Loss_D: 0.1203 Loss_G: 0.0511 Convergence: 0.1253 k= 0.057092 lr = 0.0000815\n",
      "[1/25][4450/9765] Loss_D: 0.1179 Loss_G: 0.0413 Convergence: 0.1278 k= 0.057080 lr = 0.0000815\n",
      "[1/25][4460/9765] Loss_D: 0.0970 Loss_G: 0.0401 Convergence: 0.0998 k= 0.057093 lr = 0.0000815\n",
      "[1/25][4470/9765] Loss_D: 0.1139 Loss_G: 0.0451 Convergence: 0.1181 k= 0.057135 lr = 0.0000815\n",
      "[1/25][4480/9765] Loss_D: 0.1172 Loss_G: 0.0472 Convergence: 0.1207 k= 0.057122 lr = 0.0000815\n",
      "[1/25][4490/9765] Loss_D: 0.1215 Loss_G: 0.0579 Convergence: 0.1322 k= 0.057101 lr = 0.0000815\n",
      "[1/25][4500/9765] Loss_D: 0.1152 Loss_G: 0.0401 Convergence: 0.1248 k= 0.057100 lr = 0.0000815\n",
      "[1/25][4510/9765] Loss_D: 0.1119 Loss_G: 0.0443 Convergence: 0.1155 k= 0.057108 lr = 0.0000815\n",
      "[1/25][4520/9765] Loss_D: 0.1163 Loss_G: 0.0538 Convergence: 0.1251 k= 0.057105 lr = 0.0000815\n",
      "[1/25][4530/9765] Loss_D: 0.1221 Loss_G: 0.0480 Convergence: 0.1264 k= 0.057096 lr = 0.0000815\n",
      "[1/25][4540/9765] Loss_D: 0.1116 Loss_G: 0.0443 Convergence: 0.1158 k= 0.057065 lr = 0.0000815\n",
      "[1/25][4550/9765] Loss_D: 0.1043 Loss_G: 0.0452 Convergence: 0.1093 k= 0.057030 lr = 0.0000815\n",
      "[1/25][4560/9765] Loss_D: 0.1062 Loss_G: 0.0423 Convergence: 0.1100 k= 0.057053 lr = 0.0000815\n",
      "[1/25][4570/9765] Loss_D: 0.1217 Loss_G: 0.0574 Convergence: 0.1325 k= 0.057019 lr = 0.0000815\n",
      "[1/25][4580/9765] Loss_D: 0.1200 Loss_G: 0.0433 Convergence: 0.1283 k= 0.057004 lr = 0.0000815\n",
      "[1/25][4590/9765] Loss_D: 0.1101 Loss_G: 0.0476 Convergence: 0.1157 k= 0.056984 lr = 0.0000815\n",
      "[1/25][4600/9765] Loss_D: 0.1195 Loss_G: 0.0517 Convergence: 0.1249 k= 0.056974 lr = 0.0000815\n",
      "[1/25][4610/9765] Loss_D: 0.1224 Loss_G: 0.0458 Convergence: 0.1290 k= 0.056982 lr = 0.0000815\n",
      "[1/25][4620/9765] Loss_D: 0.1249 Loss_G: 0.0573 Convergence: 0.1337 k= 0.057003 lr = 0.0000815\n",
      "[1/25][4630/9765] Loss_D: 0.1082 Loss_G: 0.0396 Convergence: 0.1150 k= 0.056984 lr = 0.0000815\n",
      "[1/25][4640/9765] Loss_D: 0.1046 Loss_G: 0.0413 Convergence: 0.1083 k= 0.057007 lr = 0.0000815\n",
      "[1/25][4650/9765] Loss_D: 0.1067 Loss_G: 0.0506 Convergence: 0.1162 k= 0.056987 lr = 0.0000815\n",
      "[1/25][4660/9765] Loss_D: 0.1194 Loss_G: 0.0492 Convergence: 0.1224 k= 0.056993 lr = 0.0000815\n",
      "[1/25][4670/9765] Loss_D: 0.1142 Loss_G: 0.0425 Convergence: 0.1209 k= 0.057022 lr = 0.0000815\n",
      "[1/25][4680/9765] Loss_D: 0.1071 Loss_G: 0.0472 Convergence: 0.1130 k= 0.057044 lr = 0.0000815\n",
      "[1/25][4690/9765] Loss_D: 0.1092 Loss_G: 0.0456 Convergence: 0.1127 k= 0.057034 lr = 0.0000815\n",
      "[1/25][4700/9765] Loss_D: 0.1125 Loss_G: 0.0446 Convergence: 0.1163 k= 0.057022 lr = 0.0000815\n",
      "[1/25][4710/9765] Loss_D: 0.1226 Loss_G: 0.0505 Convergence: 0.1257 k= 0.056992 lr = 0.0000815\n",
      "[1/25][4720/9765] Loss_D: 0.1172 Loss_G: 0.0427 Convergence: 0.1251 k= 0.056954 lr = 0.0000815\n",
      "[1/25][4730/9765] Loss_D: 0.1160 Loss_G: 0.0515 Convergence: 0.1225 k= 0.056947 lr = 0.0000815\n",
      "[1/25][4740/9765] Loss_D: 0.1230 Loss_G: 0.0548 Convergence: 0.1302 k= 0.056975 lr = 0.0000815\n",
      "[1/25][4750/9765] Loss_D: 0.1185 Loss_G: 0.0476 Convergence: 0.1222 k= 0.056927 lr = 0.0000815\n",
      "[1/25][4760/9765] Loss_D: 0.1248 Loss_G: 0.0490 Convergence: 0.1304 k= 0.056923 lr = 0.0000815\n",
      "[1/25][4770/9765] Loss_D: 0.1147 Loss_G: 0.0474 Convergence: 0.1176 k= 0.056904 lr = 0.0000815\n",
      "[1/25][4780/9765] Loss_D: 0.1122 Loss_G: 0.0461 Convergence: 0.1147 k= 0.056952 lr = 0.0000815\n",
      "[1/25][4790/9765] Loss_D: 0.1057 Loss_G: 0.0401 Convergence: 0.1115 k= 0.056976 lr = 0.0000815\n",
      "[1/25][4800/9765] Loss_D: 0.1095 Loss_G: 0.0442 Convergence: 0.1129 k= 0.057000 lr = 0.0000815\n",
      "[1/25][4810/9765] Loss_D: 0.1197 Loss_G: 0.0454 Convergence: 0.1255 k= 0.056989 lr = 0.0000815\n",
      "[1/25][4820/9765] Loss_D: 0.1110 Loss_G: 0.0448 Convergence: 0.1145 k= 0.057004 lr = 0.0000815\n",
      "[1/25][4830/9765] Loss_D: 0.1020 Loss_G: 0.0456 Convergence: 0.1085 k= 0.056966 lr = 0.0000815\n",
      "[1/25][4840/9765] Loss_D: 0.1108 Loss_G: 0.0448 Convergence: 0.1138 k= 0.056990 lr = 0.0000815\n",
      "[1/25][4850/9765] Loss_D: 0.1090 Loss_G: 0.0398 Convergence: 0.1158 k= 0.057029 lr = 0.0000815\n",
      "[1/25][4860/9765] Loss_D: 0.1163 Loss_G: 0.0464 Convergence: 0.1201 k= 0.057024 lr = 0.0000815\n",
      "[1/25][4870/9765] Loss_D: 0.1093 Loss_G: 0.0483 Convergence: 0.1154 k= 0.057003 lr = 0.0000815\n",
      "[1/25][4880/9765] Loss_D: 0.1104 Loss_G: 0.0442 Convergence: 0.1136 k= 0.057032 lr = 0.0000815\n",
      "[1/25][4890/9765] Loss_D: 0.1185 Loss_G: 0.0448 Convergence: 0.1247 k= 0.057027 lr = 0.0000815\n",
      "[1/25][4900/9765] Loss_D: 0.1094 Loss_G: 0.0463 Convergence: 0.1134 k= 0.057030 lr = 0.0000815\n",
      "[1/25][4910/9765] Loss_D: 0.1168 Loss_G: 0.0484 Convergence: 0.1203 k= 0.057022 lr = 0.0000815\n",
      "[1/25][4920/9765] Loss_D: 0.1077 Loss_G: 0.0438 Convergence: 0.1102 k= 0.057034 lr = 0.0000815\n",
      "[1/25][4930/9765] Loss_D: 0.1132 Loss_G: 0.0413 Convergence: 0.1206 k= 0.057063 lr = 0.0000815\n",
      "[1/25][4940/9765] Loss_D: 0.1111 Loss_G: 0.0451 Convergence: 0.1142 k= 0.057077 lr = 0.0000815\n",
      "[1/25][4950/9765] Loss_D: 0.1298 Loss_G: 0.0479 Convergence: 0.1375 k= 0.057045 lr = 0.0000815\n",
      "[1/25][4960/9765] Loss_D: 0.1142 Loss_G: 0.0447 Convergence: 0.1186 k= 0.057023 lr = 0.0000815\n",
      "[1/25][4970/9765] Loss_D: 0.1168 Loss_G: 0.0458 Convergence: 0.1216 k= 0.057016 lr = 0.0000815\n",
      "[1/25][4980/9765] Loss_D: 0.1105 Loss_G: 0.0485 Convergence: 0.1163 k= 0.057001 lr = 0.0000815\n",
      "[1/25][4990/9765] Loss_D: 0.1123 Loss_G: 0.0450 Convergence: 0.1154 k= 0.056994 lr = 0.0000815\n",
      "[1/25][5000/9765] Loss_D: 0.1173 Loss_G: 0.0513 Convergence: 0.1231 k= 0.056986 lr = 0.0000815\n",
      "[1/25][5010/9765] Loss_D: 0.1044 Loss_G: 0.0447 Convergence: 0.1087 k= 0.056964 lr = 0.0000815\n",
      "[1/25][5020/9765] Loss_D: 0.1111 Loss_G: 0.0422 Convergence: 0.1169 k= 0.056977 lr = 0.0000815\n",
      "[1/25][5030/9765] Loss_D: 0.1119 Loss_G: 0.0440 Convergence: 0.1166 k= 0.056965 lr = 0.0000815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][5040/9765] Loss_D: 0.1058 Loss_G: 0.0543 Convergence: 0.1192 k= 0.056968 lr = 0.0000815\n",
      "[1/25][5050/9765] Loss_D: 0.1152 Loss_G: 0.0504 Convergence: 0.1209 k= 0.056951 lr = 0.0000815\n",
      "[1/25][5060/9765] Loss_D: 0.1205 Loss_G: 0.0473 Convergence: 0.1251 k= 0.056954 lr = 0.0000815\n",
      "[1/25][5070/9765] Loss_D: 0.1151 Loss_G: 0.0448 Convergence: 0.1200 k= 0.056960 lr = 0.0000815\n",
      "[1/25][5080/9765] Loss_D: 0.1242 Loss_G: 0.0502 Convergence: 0.1279 k= 0.056880 lr = 0.0000815\n",
      "[1/25][5090/9765] Loss_D: 0.1096 Loss_G: 0.0529 Convergence: 0.1202 k= 0.056842 lr = 0.0000815\n",
      "[1/25][5100/9765] Loss_D: 0.1149 Loss_G: 0.0507 Convergence: 0.1213 k= 0.056763 lr = 0.0000815\n",
      "[1/25][5110/9765] Loss_D: 0.1165 Loss_G: 0.0505 Convergence: 0.1218 k= 0.056781 lr = 0.0000815\n",
      "[1/25][5120/9765] Loss_D: 0.1186 Loss_G: 0.0525 Convergence: 0.1251 k= 0.056767 lr = 0.0000815\n",
      "[1/25][5130/9765] Loss_D: 0.1244 Loss_G: 0.0529 Convergence: 0.1289 k= 0.056783 lr = 0.0000815\n",
      "[1/25][5140/9765] Loss_D: 0.1244 Loss_G: 0.0520 Convergence: 0.1284 k= 0.056761 lr = 0.0000815\n",
      "[1/25][5150/9765] Loss_D: 0.1232 Loss_G: 0.0488 Convergence: 0.1274 k= 0.056753 lr = 0.0000815\n",
      "[1/25][5160/9765] Loss_D: 0.1149 Loss_G: 0.0562 Convergence: 0.1267 k= 0.056746 lr = 0.0000815\n",
      "[1/25][5170/9765] Loss_D: 0.1167 Loss_G: 0.0456 Convergence: 0.1215 k= 0.056727 lr = 0.0000815\n",
      "[1/25][5180/9765] Loss_D: 0.1083 Loss_G: 0.0468 Convergence: 0.1134 k= 0.056720 lr = 0.0000815\n",
      "[1/25][5190/9765] Loss_D: 0.1129 Loss_G: 0.0542 Convergence: 0.1237 k= 0.056677 lr = 0.0000815\n",
      "[1/25][5200/9765] Loss_D: 0.1123 Loss_G: 0.0477 Convergence: 0.1164 k= 0.056710 lr = 0.0000815\n",
      "[1/25][5210/9765] Loss_D: 0.1089 Loss_G: 0.0442 Convergence: 0.1117 k= 0.056739 lr = 0.0000815\n",
      "[1/25][5220/9765] Loss_D: 0.1007 Loss_G: 0.0490 Convergence: 0.1109 k= 0.056745 lr = 0.0000815\n",
      "[1/25][5230/9765] Loss_D: 0.1179 Loss_G: 0.0435 Convergence: 0.1246 k= 0.056761 lr = 0.0000815\n",
      "[1/25][5240/9765] Loss_D: 0.1265 Loss_G: 0.0464 Convergence: 0.1352 k= 0.056736 lr = 0.0000774\n",
      "[1/25][5250/9765] Loss_D: 0.1069 Loss_G: 0.0384 Convergence: 0.1143 k= 0.056757 lr = 0.0000774\n",
      "[1/25][5260/9765] Loss_D: 0.1109 Loss_G: 0.0566 Convergence: 0.1245 k= 0.056755 lr = 0.0000774\n",
      "[1/25][5270/9765] Loss_D: 0.1110 Loss_G: 0.0403 Convergence: 0.1187 k= 0.056778 lr = 0.0000774\n",
      "[1/25][5280/9765] Loss_D: 0.1232 Loss_G: 0.0594 Convergence: 0.1349 k= 0.056756 lr = 0.0000774\n",
      "[1/25][5290/9765] Loss_D: 0.1262 Loss_G: 0.0479 Convergence: 0.1326 k= 0.056708 lr = 0.0000774\n",
      "[1/25][5300/9765] Loss_D: 0.1235 Loss_G: 0.0520 Convergence: 0.1274 k= 0.056715 lr = 0.0000774\n",
      "[1/25][5310/9765] Loss_D: 0.1094 Loss_G: 0.0397 Convergence: 0.1166 k= 0.056711 lr = 0.0000774\n",
      "[1/25][5320/9765] Loss_D: 0.1114 Loss_G: 0.0426 Convergence: 0.1175 k= 0.056706 lr = 0.0000774\n",
      "[1/25][5330/9765] Loss_D: 0.1183 Loss_G: 0.0481 Convergence: 0.1207 k= 0.056716 lr = 0.0000774\n",
      "[1/25][5340/9765] Loss_D: 0.1072 Loss_G: 0.0468 Convergence: 0.1126 k= 0.056739 lr = 0.0000774\n",
      "[1/25][5350/9765] Loss_D: 0.1212 Loss_G: 0.0410 Convergence: 0.1322 k= 0.056745 lr = 0.0000774\n",
      "[1/25][5360/9765] Loss_D: 0.1156 Loss_G: 0.0406 Convergence: 0.1245 k= 0.056755 lr = 0.0000774\n",
      "[1/25][5370/9765] Loss_D: 0.1091 Loss_G: 0.0457 Convergence: 0.1129 k= 0.056747 lr = 0.0000774\n",
      "[1/25][5380/9765] Loss_D: 0.1035 Loss_G: 0.0407 Convergence: 0.1076 k= 0.056761 lr = 0.0000774\n",
      "[1/25][5390/9765] Loss_D: 0.1078 Loss_G: 0.0406 Convergence: 0.1137 k= 0.056772 lr = 0.0000774\n",
      "[1/25][5400/9765] Loss_D: 0.1221 Loss_G: 0.0445 Convergence: 0.1297 k= 0.056762 lr = 0.0000774\n",
      "[1/25][5410/9765] Loss_D: 0.1163 Loss_G: 0.0506 Convergence: 0.1218 k= 0.056772 lr = 0.0000774\n",
      "[1/25][5420/9765] Loss_D: 0.1117 Loss_G: 0.0539 Convergence: 0.1225 k= 0.056726 lr = 0.0000774\n",
      "[1/25][5430/9765] Loss_D: 0.1045 Loss_G: 0.0411 Convergence: 0.1091 k= 0.056716 lr = 0.0000774\n",
      "[1/25][5440/9765] Loss_D: 0.1133 Loss_G: 0.0552 Convergence: 0.1249 k= 0.056718 lr = 0.0000774\n",
      "[1/25][5450/9765] Loss_D: 0.1073 Loss_G: 0.0387 Convergence: 0.1150 k= 0.056720 lr = 0.0000774\n",
      "[1/25][5460/9765] Loss_D: 0.1177 Loss_G: 0.0407 Convergence: 0.1274 k= 0.056741 lr = 0.0000774\n",
      "[1/25][5470/9765] Loss_D: 0.1109 Loss_G: 0.0495 Convergence: 0.1178 k= 0.056703 lr = 0.0000774\n",
      "[1/25][5480/9765] Loss_D: 0.1133 Loss_G: 0.0482 Convergence: 0.1177 k= 0.056689 lr = 0.0000774\n",
      "[1/25][5490/9765] Loss_D: 0.1137 Loss_G: 0.0484 Convergence: 0.1182 k= 0.056717 lr = 0.0000774\n",
      "[1/25][5500/9765] Loss_D: 0.1056 Loss_G: 0.0405 Convergence: 0.1108 k= 0.056714 lr = 0.0000774\n",
      "[1/25][5510/9765] Loss_D: 0.1093 Loss_G: 0.0473 Convergence: 0.1146 k= 0.056692 lr = 0.0000774\n",
      "[1/25][5520/9765] Loss_D: 0.1070 Loss_G: 0.0486 Convergence: 0.1141 k= 0.056684 lr = 0.0000774\n",
      "[1/25][5530/9765] Loss_D: 0.1230 Loss_G: 0.0438 Convergence: 0.1324 k= 0.056688 lr = 0.0000774\n",
      "[1/25][5540/9765] Loss_D: 0.1052 Loss_G: 0.0436 Convergence: 0.1080 k= 0.056674 lr = 0.0000774\n",
      "[1/25][5550/9765] Loss_D: 0.1163 Loss_G: 0.0546 Convergence: 0.1263 k= 0.056621 lr = 0.0000774\n",
      "[1/25][5560/9765] Loss_D: 0.1140 Loss_G: 0.0501 Convergence: 0.1200 k= 0.056594 lr = 0.0000774\n",
      "[1/25][5570/9765] Loss_D: 0.1170 Loss_G: 0.0557 Convergence: 0.1274 k= 0.056587 lr = 0.0000774\n",
      "[1/25][5580/9765] Loss_D: 0.1145 Loss_G: 0.0441 Convergence: 0.1194 k= 0.056585 lr = 0.0000774\n",
      "[1/25][5590/9765] Loss_D: 0.1185 Loss_G: 0.0492 Convergence: 0.1217 k= 0.056615 lr = 0.0000774\n",
      "[1/25][5600/9765] Loss_D: 0.1117 Loss_G: 0.0560 Convergence: 0.1248 k= 0.056594 lr = 0.0000774\n",
      "[1/25][5610/9765] Loss_D: 0.1251 Loss_G: 0.0474 Convergence: 0.1322 k= 0.056556 lr = 0.0000774\n",
      "[1/25][5620/9765] Loss_D: 0.1017 Loss_G: 0.0456 Convergence: 0.1080 k= 0.056565 lr = 0.0000774\n",
      "[1/25][5630/9765] Loss_D: 0.1068 Loss_G: 0.0430 Convergence: 0.1107 k= 0.056569 lr = 0.0000774\n",
      "[1/25][5640/9765] Loss_D: 0.1050 Loss_G: 0.0499 Convergence: 0.1143 k= 0.056576 lr = 0.0000774\n",
      "[1/25][5650/9765] Loss_D: 0.1140 Loss_G: 0.0462 Convergence: 0.1167 k= 0.056598 lr = 0.0000774\n",
      "[1/25][5660/9765] Loss_D: 0.1143 Loss_G: 0.0440 Convergence: 0.1194 k= 0.056616 lr = 0.0000774\n",
      "[1/25][5670/9765] Loss_D: 0.1241 Loss_G: 0.0691 Convergence: 0.1456 k= 0.056553 lr = 0.0000774\n",
      "[1/25][5680/9765] Loss_D: 0.1116 Loss_G: 0.0477 Convergence: 0.1161 k= 0.056494 lr = 0.0000774\n",
      "[1/25][5690/9765] Loss_D: 0.1167 Loss_G: 0.0472 Convergence: 0.1196 k= 0.056501 lr = 0.0000774\n",
      "[1/25][5700/9765] Loss_D: 0.1190 Loss_G: 0.0456 Convergence: 0.1246 k= 0.056531 lr = 0.0000774\n",
      "[1/25][5710/9765] Loss_D: 0.1168 Loss_G: 0.0579 Convergence: 0.1295 k= 0.056489 lr = 0.0000774\n",
      "[1/25][5720/9765] Loss_D: 0.1092 Loss_G: 0.0454 Convergence: 0.1124 k= 0.056479 lr = 0.0000774\n",
      "[1/25][5730/9765] Loss_D: 0.1157 Loss_G: 0.0449 Convergence: 0.1205 k= 0.056494 lr = 0.0000774\n",
      "[1/25][5740/9765] Loss_D: 0.1141 Loss_G: 0.0388 Convergence: 0.1242 k= 0.056514 lr = 0.0000774\n",
      "[1/25][5750/9765] Loss_D: 0.1182 Loss_G: 0.0482 Convergence: 0.1211 k= 0.056463 lr = 0.0000774\n",
      "[1/25][5760/9765] Loss_D: 0.1078 Loss_G: 0.0393 Convergence: 0.1149 k= 0.056477 lr = 0.0000774\n",
      "[1/25][5770/9765] Loss_D: 0.1063 Loss_G: 0.0513 Convergence: 0.1166 k= 0.056515 lr = 0.0000774\n",
      "[1/25][5780/9765] Loss_D: 0.1106 Loss_G: 0.0613 Convergence: 0.1293 k= 0.056476 lr = 0.0000774\n",
      "[1/25][5790/9765] Loss_D: 0.1029 Loss_G: 0.0492 Convergence: 0.1127 k= 0.056427 lr = 0.0000774\n",
      "[1/25][5800/9765] Loss_D: 0.1047 Loss_G: 0.0496 Convergence: 0.1139 k= 0.056402 lr = 0.0000774\n",
      "[1/25][5810/9765] Loss_D: 0.1113 Loss_G: 0.0440 Convergence: 0.1156 k= 0.056413 lr = 0.0000774\n",
      "[1/25][5820/9765] Loss_D: 0.1066 Loss_G: 0.0439 Convergence: 0.1094 k= 0.056374 lr = 0.0000774\n",
      "[1/25][5830/9765] Loss_D: 0.1023 Loss_G: 0.0523 Convergence: 0.1152 k= 0.056398 lr = 0.0000774\n",
      "[1/25][5840/9765] Loss_D: 0.1087 Loss_G: 0.0483 Convergence: 0.1149 k= 0.056401 lr = 0.0000774\n",
      "[1/25][5850/9765] Loss_D: 0.1052 Loss_G: 0.0409 Convergence: 0.1098 k= 0.056425 lr = 0.0000774\n",
      "[1/25][5860/9765] Loss_D: 0.1206 Loss_G: 0.0466 Convergence: 0.1255 k= 0.056426 lr = 0.0000774\n",
      "[1/25][5870/9765] Loss_D: 0.1122 Loss_G: 0.0525 Convergence: 0.1218 k= 0.056356 lr = 0.0000774\n",
      "[1/25][5880/9765] Loss_D: 0.1096 Loss_G: 0.0463 Convergence: 0.1136 k= 0.056323 lr = 0.0000774\n",
      "[1/25][5890/9765] Loss_D: 0.1158 Loss_G: 0.0457 Convergence: 0.1197 k= 0.056310 lr = 0.0000774\n",
      "[1/25][5900/9765] Loss_D: 0.1097 Loss_G: 0.0409 Convergence: 0.1160 k= 0.056324 lr = 0.0000774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][5910/9765] Loss_D: 0.1126 Loss_G: 0.0478 Convergence: 0.1167 k= 0.056316 lr = 0.0000774\n",
      "[1/25][5920/9765] Loss_D: 0.1179 Loss_G: 0.0523 Convergence: 0.1245 k= 0.056304 lr = 0.0000774\n",
      "[1/25][5930/9765] Loss_D: 0.1235 Loss_G: 0.0498 Convergence: 0.1273 k= 0.056270 lr = 0.0000774\n",
      "[1/25][5940/9765] Loss_D: 0.1088 Loss_G: 0.0443 Convergence: 0.1116 k= 0.056268 lr = 0.0000774\n",
      "[1/25][5950/9765] Loss_D: 0.1063 Loss_G: 0.0471 Convergence: 0.1125 k= 0.056246 lr = 0.0000774\n",
      "[1/25][5960/9765] Loss_D: 0.1175 Loss_G: 0.0427 Convergence: 0.1250 k= 0.056239 lr = 0.0000774\n",
      "[1/25][5970/9765] Loss_D: 0.1036 Loss_G: 0.0500 Convergence: 0.1137 k= 0.056225 lr = 0.0000774\n",
      "[1/25][5980/9765] Loss_D: 0.1202 Loss_G: 0.0443 Convergence: 0.1270 k= 0.056236 lr = 0.0000774\n",
      "[1/25][5990/9765] Loss_D: 0.1174 Loss_G: 0.0475 Convergence: 0.1204 k= 0.056238 lr = 0.0000774\n",
      "[1/25][6000/9765] Loss_D: 0.1174 Loss_G: 0.0469 Convergence: 0.1216 k= 0.056231 lr = 0.0000774\n",
      "[1/25][6010/9765] Loss_D: 0.1168 Loss_G: 0.0473 Convergence: 0.1197 k= 0.056221 lr = 0.0000774\n",
      "[1/25][6020/9765] Loss_D: 0.1100 Loss_G: 0.0416 Convergence: 0.1158 k= 0.056232 lr = 0.0000774\n",
      "[1/25][6030/9765] Loss_D: 0.1048 Loss_G: 0.0455 Convergence: 0.1101 k= 0.056175 lr = 0.0000774\n",
      "[1/25][6040/9765] Loss_D: 0.1193 Loss_G: 0.0585 Convergence: 0.1318 k= 0.056116 lr = 0.0000774\n",
      "[1/25][6050/9765] Loss_D: 0.1108 Loss_G: 0.0444 Convergence: 0.1136 k= 0.056119 lr = 0.0000774\n",
      "[1/25][6060/9765] Loss_D: 0.1125 Loss_G: 0.0539 Convergence: 0.1232 k= 0.056126 lr = 0.0000774\n",
      "[1/25][6070/9765] Loss_D: 0.1083 Loss_G: 0.0441 Convergence: 0.1113 k= 0.056152 lr = 0.0000774\n",
      "[1/25][6080/9765] Loss_D: 0.1090 Loss_G: 0.0429 Convergence: 0.1136 k= 0.056135 lr = 0.0000774\n",
      "[1/25][6090/9765] Loss_D: 0.1200 Loss_G: 0.0483 Convergence: 0.1234 k= 0.056115 lr = 0.0000774\n",
      "[1/25][6100/9765] Loss_D: 0.1079 Loss_G: 0.0424 Convergence: 0.1127 k= 0.056115 lr = 0.0000774\n",
      "[1/25][6110/9765] Loss_D: 0.1183 Loss_G: 0.0596 Convergence: 0.1323 k= 0.056061 lr = 0.0000774\n",
      "[1/25][6120/9765] Loss_D: 0.1127 Loss_G: 0.0419 Convergence: 0.1192 k= 0.056045 lr = 0.0000774\n",
      "[1/25][6130/9765] Loss_D: 0.1082 Loss_G: 0.0453 Convergence: 0.1118 k= 0.056048 lr = 0.0000774\n",
      "[1/25][6140/9765] Loss_D: 0.1097 Loss_G: 0.0538 Convergence: 0.1212 k= 0.056029 lr = 0.0000774\n",
      "[1/25][6150/9765] Loss_D: 0.1125 Loss_G: 0.0521 Convergence: 0.1211 k= 0.056013 lr = 0.0000774\n",
      "[1/25][6160/9765] Loss_D: 0.1173 Loss_G: 0.0433 Convergence: 0.1246 k= 0.056001 lr = 0.0000774\n",
      "[1/25][6170/9765] Loss_D: 0.1104 Loss_G: 0.0623 Convergence: 0.1304 k= 0.055975 lr = 0.0000774\n",
      "[1/25][6180/9765] Loss_D: 0.1019 Loss_G: 0.0563 Convergence: 0.1190 k= 0.055912 lr = 0.0000774\n",
      "[1/25][6190/9765] Loss_D: 0.1177 Loss_G: 0.0550 Convergence: 0.1273 k= 0.055876 lr = 0.0000774\n",
      "[1/25][6200/9765] Loss_D: 0.1103 Loss_G: 0.0440 Convergence: 0.1138 k= 0.055855 lr = 0.0000774\n",
      "[1/25][6210/9765] Loss_D: 0.1063 Loss_G: 0.0506 Convergence: 0.1158 k= 0.055866 lr = 0.0000774\n",
      "[1/25][6220/9765] Loss_D: 0.1241 Loss_G: 0.0441 Convergence: 0.1336 k= 0.055826 lr = 0.0000774\n",
      "[1/25][6230/9765] Loss_D: 0.1205 Loss_G: 0.0463 Convergence: 0.1258 k= 0.055802 lr = 0.0000774\n",
      "[1/25][6240/9765] Loss_D: 0.1074 Loss_G: 0.0402 Convergence: 0.1136 k= 0.055794 lr = 0.0000774\n",
      "[1/25][6250/9765] Loss_D: 0.1197 Loss_G: 0.0480 Convergence: 0.1231 k= 0.055735 lr = 0.0000774\n",
      "[1/25][6260/9765] Loss_D: 0.1131 Loss_G: 0.0546 Convergence: 0.1244 k= 0.055632 lr = 0.0000774\n",
      "[1/25][6270/9765] Loss_D: 0.1197 Loss_G: 0.0458 Convergence: 0.1255 k= 0.055653 lr = 0.0000774\n",
      "[1/25][6280/9765] Loss_D: 0.1116 Loss_G: 0.0413 Convergence: 0.1182 k= 0.055629 lr = 0.0000774\n",
      "[1/25][6290/9765] Loss_D: 0.1246 Loss_G: 0.0472 Convergence: 0.1310 k= 0.055641 lr = 0.0000774\n",
      "[1/25][6300/9765] Loss_D: 0.1106 Loss_G: 0.0579 Convergence: 0.1259 k= 0.055619 lr = 0.0000774\n",
      "[1/25][6310/9765] Loss_D: 0.1063 Loss_G: 0.0448 Convergence: 0.1101 k= 0.055617 lr = 0.0000774\n",
      "[1/25][6320/9765] Loss_D: 0.1109 Loss_G: 0.0502 Convergence: 0.1182 k= 0.055591 lr = 0.0000774\n",
      "[1/25][6330/9765] Loss_D: 0.1121 Loss_G: 0.0512 Convergence: 0.1199 k= 0.055567 lr = 0.0000774\n",
      "[1/25][6340/9765] Loss_D: 0.1065 Loss_G: 0.0459 Convergence: 0.1112 k= 0.055556 lr = 0.0000774\n",
      "[1/25][6350/9765] Loss_D: 0.1070 Loss_G: 0.0420 Convergence: 0.1110 k= 0.055572 lr = 0.0000774\n",
      "[1/25][6360/9765] Loss_D: 0.1062 Loss_G: 0.0528 Convergence: 0.1181 k= 0.055559 lr = 0.0000774\n",
      "[1/25][6370/9765] Loss_D: 0.1062 Loss_G: 0.0502 Convergence: 0.1153 k= 0.055560 lr = 0.0000774\n",
      "[1/25][6380/9765] Loss_D: 0.1182 Loss_G: 0.0499 Convergence: 0.1224 k= 0.055537 lr = 0.0000774\n",
      "[1/25][6390/9765] Loss_D: 0.1038 Loss_G: 0.0547 Convergence: 0.1188 k= 0.055488 lr = 0.0000774\n",
      "[1/25][6400/9765] Loss_D: 0.1073 Loss_G: 0.0452 Convergence: 0.1110 k= 0.055436 lr = 0.0000774\n",
      "[1/25][6410/9765] Loss_D: 0.1148 Loss_G: 0.0421 Convergence: 0.1221 k= 0.055449 lr = 0.0000774\n",
      "[1/25][6420/9765] Loss_D: 0.1027 Loss_G: 0.0503 Convergence: 0.1131 k= 0.055439 lr = 0.0000774\n",
      "[1/25][6430/9765] Loss_D: 0.1251 Loss_G: 0.0476 Convergence: 0.1308 k= 0.055412 lr = 0.0000774\n",
      "[1/25][6440/9765] Loss_D: 0.1152 Loss_G: 0.0536 Convergence: 0.1243 k= 0.055381 lr = 0.0000774\n",
      "[1/25][6450/9765] Loss_D: 0.1181 Loss_G: 0.0454 Convergence: 0.1234 k= 0.055352 lr = 0.0000774\n",
      "[1/25][6460/9765] Loss_D: 0.1149 Loss_G: 0.0445 Convergence: 0.1194 k= 0.055381 lr = 0.0000774\n",
      "[1/25][6470/9765] Loss_D: 0.1154 Loss_G: 0.0474 Convergence: 0.1184 k= 0.055354 lr = 0.0000774\n",
      "[1/25][6480/9765] Loss_D: 0.1175 Loss_G: 0.0554 Convergence: 0.1274 k= 0.055321 lr = 0.0000774\n",
      "[1/25][6490/9765] Loss_D: 0.1134 Loss_G: 0.0456 Convergence: 0.1167 k= 0.055307 lr = 0.0000774\n",
      "[1/25][6500/9765] Loss_D: 0.1164 Loss_G: 0.0502 Convergence: 0.1216 k= 0.055316 lr = 0.0000774\n",
      "[1/25][6510/9765] Loss_D: 0.1081 Loss_G: 0.0464 Convergence: 0.1127 k= 0.055305 lr = 0.0000774\n",
      "[1/25][6520/9765] Loss_D: 0.1122 Loss_G: 0.0417 Convergence: 0.1187 k= 0.055326 lr = 0.0000774\n",
      "[1/25][6530/9765] Loss_D: 0.1258 Loss_G: 0.0520 Convergence: 0.1290 k= 0.055293 lr = 0.0000774\n",
      "[1/25][6540/9765] Loss_D: 0.1199 Loss_G: 0.0449 Convergence: 0.1266 k= 0.055280 lr = 0.0000774\n",
      "[1/25][6550/9765] Loss_D: 0.1176 Loss_G: 0.0452 Convergence: 0.1230 k= 0.055266 lr = 0.0000774\n",
      "[1/25][6560/9765] Loss_D: 0.1164 Loss_G: 0.0466 Convergence: 0.1198 k= 0.055260 lr = 0.0000774\n",
      "[1/25][6570/9765] Loss_D: 0.1075 Loss_G: 0.0541 Convergence: 0.1201 k= 0.055249 lr = 0.0000774\n",
      "[1/25][6580/9765] Loss_D: 0.0988 Loss_G: 0.0478 Convergence: 0.1088 k= 0.055197 lr = 0.0000774\n",
      "[1/25][6590/9765] Loss_D: 0.1058 Loss_G: 0.0430 Convergence: 0.1083 k= 0.055181 lr = 0.0000774\n",
      "[1/25][6600/9765] Loss_D: 0.1176 Loss_G: 0.0505 Convergence: 0.1227 k= 0.055160 lr = 0.0000774\n",
      "[1/25][6610/9765] Loss_D: 0.1116 Loss_G: 0.0447 Convergence: 0.1152 k= 0.055139 lr = 0.0000774\n",
      "[1/25][6620/9765] Loss_D: 0.1073 Loss_G: 0.0461 Convergence: 0.1120 k= 0.055111 lr = 0.0000774\n",
      "[1/25][6630/9765] Loss_D: 0.1006 Loss_G: 0.0433 Convergence: 0.1052 k= 0.055099 lr = 0.0000774\n",
      "[1/25][6640/9765] Loss_D: 0.1165 Loss_G: 0.0484 Convergence: 0.1198 k= 0.055094 lr = 0.0000774\n",
      "[1/25][6650/9765] Loss_D: 0.1066 Loss_G: 0.0413 Convergence: 0.1110 k= 0.055098 lr = 0.0000774\n",
      "[1/25][6660/9765] Loss_D: 0.1118 Loss_G: 0.0480 Convergence: 0.1165 k= 0.055100 lr = 0.0000774\n",
      "[1/25][6670/9765] Loss_D: 0.1078 Loss_G: 0.0462 Convergence: 0.1123 k= 0.055104 lr = 0.0000774\n",
      "[1/25][6680/9765] Loss_D: 0.1024 Loss_G: 0.0484 Convergence: 0.1113 k= 0.055079 lr = 0.0000774\n",
      "[1/25][6690/9765] Loss_D: 0.1144 Loss_G: 0.0478 Convergence: 0.1181 k= 0.055040 lr = 0.0000774\n",
      "[1/25][6700/9765] Loss_D: 0.1097 Loss_G: 0.0479 Convergence: 0.1153 k= 0.054982 lr = 0.0000774\n",
      "[1/25][6710/9765] Loss_D: 0.1266 Loss_G: 0.0505 Convergence: 0.1302 k= 0.054953 lr = 0.0000774\n",
      "[1/25][6720/9765] Loss_D: 0.1208 Loss_G: 0.0523 Convergence: 0.1261 k= 0.054947 lr = 0.0000774\n",
      "[1/25][6730/9765] Loss_D: 0.1120 Loss_G: 0.0427 Convergence: 0.1179 k= 0.054913 lr = 0.0000774\n",
      "[1/25][6740/9765] Loss_D: 0.1145 Loss_G: 0.0448 Convergence: 0.1185 k= 0.054906 lr = 0.0000774\n",
      "[1/25][6750/9765] Loss_D: 0.1116 Loss_G: 0.0448 Convergence: 0.1144 k= 0.054921 lr = 0.0000774\n",
      "[1/25][6760/9765] Loss_D: 0.1137 Loss_G: 0.0515 Convergence: 0.1214 k= 0.054886 lr = 0.0000774\n",
      "[1/25][6770/9765] Loss_D: 0.1112 Loss_G: 0.0424 Convergence: 0.1161 k= 0.054895 lr = 0.0000774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][6780/9765] Loss_D: 0.1215 Loss_G: 0.0543 Convergence: 0.1287 k= 0.054851 lr = 0.0000774\n",
      "[1/25][6790/9765] Loss_D: 0.1212 Loss_G: 0.0395 Convergence: 0.1338 k= 0.054831 lr = 0.0000774\n",
      "[1/25][6800/9765] Loss_D: 0.1045 Loss_G: 0.0519 Convergence: 0.1161 k= 0.054801 lr = 0.0000774\n",
      "[1/25][6810/9765] Loss_D: 0.1173 Loss_G: 0.0617 Convergence: 0.1335 k= 0.054765 lr = 0.0000774\n",
      "[1/25][6820/9765] Loss_D: 0.1161 Loss_G: 0.0451 Convergence: 0.1206 k= 0.054713 lr = 0.0000774\n",
      "[1/25][6830/9765] Loss_D: 0.1177 Loss_G: 0.0631 Convergence: 0.1353 k= 0.054701 lr = 0.0000774\n",
      "[1/25][6840/9765] Loss_D: 0.1272 Loss_G: 0.0576 Convergence: 0.1354 k= 0.054671 lr = 0.0000774\n",
      "[1/25][6850/9765] Loss_D: 0.1168 Loss_G: 0.0419 Convergence: 0.1249 k= 0.054697 lr = 0.0000774\n",
      "[1/25][6860/9765] Loss_D: 0.1108 Loss_G: 0.0490 Convergence: 0.1170 k= 0.054677 lr = 0.0000774\n",
      "[1/25][6870/9765] Loss_D: 0.1140 Loss_G: 0.0494 Convergence: 0.1193 k= 0.054608 lr = 0.0000774\n",
      "[1/25][6880/9765] Loss_D: 0.1130 Loss_G: 0.0713 Convergence: 0.1408 k= 0.054528 lr = 0.0000774\n",
      "[1/25][6890/9765] Loss_D: 0.1145 Loss_G: 0.0506 Convergence: 0.1208 k= 0.054504 lr = 0.0000774\n",
      "[1/25][6900/9765] Loss_D: 0.1117 Loss_G: 0.0423 Convergence: 0.1173 k= 0.054500 lr = 0.0000774\n",
      "[1/25][6910/9765] Loss_D: 0.1298 Loss_G: 0.0438 Convergence: 0.1413 k= 0.054502 lr = 0.0000774\n",
      "[1/25][6920/9765] Loss_D: 0.1140 Loss_G: 0.0447 Convergence: 0.1180 k= 0.054505 lr = 0.0000774\n",
      "[1/25][6930/9765] Loss_D: 0.1282 Loss_G: 0.0564 Convergence: 0.1349 k= 0.054491 lr = 0.0000774\n",
      "[1/25][6940/9765] Loss_D: 0.1123 Loss_G: 0.0457 Convergence: 0.1149 k= 0.054496 lr = 0.0000774\n",
      "[1/25][6950/9765] Loss_D: 0.1222 Loss_G: 0.0477 Convergence: 0.1266 k= 0.054508 lr = 0.0000774\n",
      "[1/25][6960/9765] Loss_D: 0.1193 Loss_G: 0.0513 Convergence: 0.1244 k= 0.054495 lr = 0.0000774\n",
      "[1/25][6970/9765] Loss_D: 0.1118 Loss_G: 0.0478 Convergence: 0.1164 k= 0.054472 lr = 0.0000774\n",
      "[1/25][6980/9765] Loss_D: 0.1153 Loss_G: 0.0474 Convergence: 0.1182 k= 0.054442 lr = 0.0000774\n",
      "[1/25][6990/9765] Loss_D: 0.1190 Loss_G: 0.0532 Convergence: 0.1260 k= 0.054434 lr = 0.0000774\n",
      "[1/25][7000/9765] Loss_D: 0.1107 Loss_G: 0.0476 Convergence: 0.1156 k= 0.054420 lr = 0.0000774\n",
      "[1/25][7010/9765] Loss_D: 0.1174 Loss_G: 0.0462 Convergence: 0.1222 k= 0.054352 lr = 0.0000774\n",
      "[1/25][7020/9765] Loss_D: 0.1097 Loss_G: 0.0489 Convergence: 0.1164 k= 0.054351 lr = 0.0000774\n",
      "[1/25][7030/9765] Loss_D: 0.1052 Loss_G: 0.0491 Convergence: 0.1137 k= 0.054295 lr = 0.0000774\n",
      "[1/25][7040/9765] Loss_D: 0.1153 Loss_G: 0.0419 Convergence: 0.1227 k= 0.054300 lr = 0.0000774\n",
      "[1/25][7050/9765] Loss_D: 0.1101 Loss_G: 0.0423 Convergence: 0.1152 k= 0.054293 lr = 0.0000774\n",
      "[1/25][7060/9765] Loss_D: 0.1159 Loss_G: 0.0512 Convergence: 0.1223 k= 0.054287 lr = 0.0000774\n",
      "[1/25][7070/9765] Loss_D: 0.1163 Loss_G: 0.0569 Convergence: 0.1281 k= 0.054287 lr = 0.0000774\n",
      "[1/25][7080/9765] Loss_D: 0.1084 Loss_G: 0.0430 Convergence: 0.1124 k= 0.054268 lr = 0.0000774\n",
      "[1/25][7090/9765] Loss_D: 0.1214 Loss_G: 0.0414 Convergence: 0.1321 k= 0.054264 lr = 0.0000774\n",
      "[1/25][7100/9765] Loss_D: 0.1108 Loss_G: 0.0443 Convergence: 0.1145 k= 0.054278 lr = 0.0000774\n",
      "[1/25][7110/9765] Loss_D: 0.1161 Loss_G: 0.0442 Convergence: 0.1212 k= 0.054283 lr = 0.0000774\n",
      "[1/25][7120/9765] Loss_D: 0.1114 Loss_G: 0.0512 Convergence: 0.1196 k= 0.054239 lr = 0.0000774\n",
      "[1/25][7130/9765] Loss_D: 0.1176 Loss_G: 0.0490 Convergence: 0.1213 k= 0.054221 lr = 0.0000774\n",
      "[1/25][7140/9765] Loss_D: 0.1156 Loss_G: 0.0525 Convergence: 0.1234 k= 0.054187 lr = 0.0000774\n",
      "[1/25][7150/9765] Loss_D: 0.1230 Loss_G: 0.0556 Convergence: 0.1309 k= 0.054176 lr = 0.0000774\n",
      "[1/25][7160/9765] Loss_D: 0.1145 Loss_G: 0.0465 Convergence: 0.1175 k= 0.054132 lr = 0.0000774\n",
      "[1/25][7170/9765] Loss_D: 0.1166 Loss_G: 0.0488 Convergence: 0.1202 k= 0.054141 lr = 0.0000774\n",
      "[1/25][7180/9765] Loss_D: 0.1173 Loss_G: 0.0538 Convergence: 0.1258 k= 0.054094 lr = 0.0000774\n",
      "[1/25][7190/9765] Loss_D: 0.1176 Loss_G: 0.0391 Convergence: 0.1285 k= 0.054078 lr = 0.0000774\n",
      "[1/25][7200/9765] Loss_D: 0.1044 Loss_G: 0.0412 Convergence: 0.1084 k= 0.054082 lr = 0.0000774\n",
      "[1/25][7210/9765] Loss_D: 0.1087 Loss_G: 0.0390 Convergence: 0.1164 k= 0.054083 lr = 0.0000774\n",
      "[1/25][7220/9765] Loss_D: 0.1235 Loss_G: 0.0428 Convergence: 0.1335 k= 0.054062 lr = 0.0000774\n",
      "[1/25][7230/9765] Loss_D: 0.1229 Loss_G: 0.0570 Convergence: 0.1325 k= 0.054009 lr = 0.0000774\n",
      "[1/25][7240/9765] Loss_D: 0.1188 Loss_G: 0.0464 Convergence: 0.1243 k= 0.053951 lr = 0.0000774\n",
      "[1/25][7250/9765] Loss_D: 0.1088 Loss_G: 0.0395 Convergence: 0.1163 k= 0.053966 lr = 0.0000774\n",
      "[1/25][7260/9765] Loss_D: 0.1169 Loss_G: 0.0456 Convergence: 0.1212 k= 0.053924 lr = 0.0000774\n",
      "[1/25][7270/9765] Loss_D: 0.1211 Loss_G: 0.0456 Convergence: 0.1272 k= 0.053924 lr = 0.0000774\n",
      "[1/25][7280/9765] Loss_D: 0.1058 Loss_G: 0.0476 Convergence: 0.1124 k= 0.053876 lr = 0.0000774\n",
      "[1/25][7290/9765] Loss_D: 0.1118 Loss_G: 0.0449 Convergence: 0.1149 k= 0.053837 lr = 0.0000774\n",
      "[1/25][7300/9765] Loss_D: 0.1052 Loss_G: 0.0445 Convergence: 0.1092 k= 0.053851 lr = 0.0000774\n",
      "[1/25][7310/9765] Loss_D: 0.1156 Loss_G: 0.0496 Convergence: 0.1202 k= 0.053864 lr = 0.0000774\n",
      "[1/25][7320/9765] Loss_D: 0.1122 Loss_G: 0.0431 Convergence: 0.1172 k= 0.053865 lr = 0.0000774\n",
      "[1/25][7330/9765] Loss_D: 0.1116 Loss_G: 0.0478 Convergence: 0.1162 k= 0.053820 lr = 0.0000774\n",
      "[1/25][7340/9765] Loss_D: 0.1084 Loss_G: 0.0468 Convergence: 0.1131 k= 0.053806 lr = 0.0000774\n",
      "[1/25][7350/9765] Loss_D: 0.1119 Loss_G: 0.0444 Convergence: 0.1158 k= 0.053823 lr = 0.0000774\n",
      "[1/25][7360/9765] Loss_D: 0.1115 Loss_G: 0.0505 Convergence: 0.1187 k= 0.053813 lr = 0.0000774\n",
      "[1/25][7370/9765] Loss_D: 0.1137 Loss_G: 0.0481 Convergence: 0.1180 k= 0.053800 lr = 0.0000774\n",
      "[1/25][7380/9765] Loss_D: 0.1238 Loss_G: 0.0478 Convergence: 0.1288 k= 0.053777 lr = 0.0000774\n",
      "[1/25][7390/9765] Loss_D: 0.1020 Loss_G: 0.0470 Convergence: 0.1096 k= 0.053756 lr = 0.0000774\n",
      "[1/25][7400/9765] Loss_D: 0.1141 Loss_G: 0.0484 Convergence: 0.1184 k= 0.053704 lr = 0.0000774\n",
      "[1/25][7410/9765] Loss_D: 0.1176 Loss_G: 0.0509 Convergence: 0.1229 k= 0.053682 lr = 0.0000774\n",
      "[1/25][7420/9765] Loss_D: 0.1022 Loss_G: 0.0488 Convergence: 0.1114 k= 0.053666 lr = 0.0000774\n",
      "[1/25][7430/9765] Loss_D: 0.1083 Loss_G: 0.0443 Convergence: 0.1107 k= 0.053666 lr = 0.0000774\n",
      "[1/25][7440/9765] Loss_D: 0.1172 Loss_G: 0.0538 Convergence: 0.1257 k= 0.053642 lr = 0.0000774\n",
      "[1/25][7450/9765] Loss_D: 0.1106 Loss_G: 0.0480 Convergence: 0.1158 k= 0.053601 lr = 0.0000774\n",
      "[1/25][7460/9765] Loss_D: 0.1080 Loss_G: 0.0507 Convergence: 0.1169 k= 0.053553 lr = 0.0000774\n",
      "[1/25][7470/9765] Loss_D: 0.1138 Loss_G: 0.0477 Convergence: 0.1174 k= 0.053537 lr = 0.0000774\n",
      "[1/25][7480/9765] Loss_D: 0.1196 Loss_G: 0.0545 Convergence: 0.1277 k= 0.053481 lr = 0.0000774\n",
      "[1/25][7490/9765] Loss_D: 0.1182 Loss_G: 0.0490 Convergence: 0.1213 k= 0.053474 lr = 0.0000774\n",
      "[1/25][7500/9765] Loss_D: 0.1143 Loss_G: 0.0593 Convergence: 0.1294 k= 0.053417 lr = 0.0000774\n",
      "[1/25][7510/9765] Loss_D: 0.1081 Loss_G: 0.0425 Convergence: 0.1121 k= 0.053394 lr = 0.0000774\n",
      "[1/25][7520/9765] Loss_D: 0.1197 Loss_G: 0.0485 Convergence: 0.1225 k= 0.053408 lr = 0.0000774\n",
      "[1/25][7530/9765] Loss_D: 0.1145 Loss_G: 0.0503 Convergence: 0.1206 k= 0.053338 lr = 0.0000774\n",
      "[1/25][7540/9765] Loss_D: 0.1111 Loss_G: 0.0441 Convergence: 0.1149 k= 0.053321 lr = 0.0000774\n",
      "[1/25][7550/9765] Loss_D: 0.1108 Loss_G: 0.0475 Convergence: 0.1155 k= 0.053314 lr = 0.0000774\n",
      "[1/25][7560/9765] Loss_D: 0.1106 Loss_G: 0.0476 Convergence: 0.1156 k= 0.053264 lr = 0.0000774\n",
      "[1/25][7570/9765] Loss_D: 0.1034 Loss_G: 0.0514 Convergence: 0.1152 k= 0.053230 lr = 0.0000774\n",
      "[1/25][7580/9765] Loss_D: 0.1087 Loss_G: 0.0413 Convergence: 0.1149 k= 0.053165 lr = 0.0000774\n",
      "[1/25][7590/9765] Loss_D: 0.1183 Loss_G: 0.0455 Convergence: 0.1234 k= 0.053182 lr = 0.0000774\n",
      "[1/25][7600/9765] Loss_D: 0.1175 Loss_G: 0.0531 Convergence: 0.1252 k= 0.053166 lr = 0.0000774\n",
      "[1/25][7610/9765] Loss_D: 0.1046 Loss_G: 0.0484 Convergence: 0.1127 k= 0.053134 lr = 0.0000774\n",
      "[1/25][7620/9765] Loss_D: 0.1148 Loss_G: 0.0489 Convergence: 0.1194 k= 0.053061 lr = 0.0000774\n",
      "[1/25][7630/9765] Loss_D: 0.1118 Loss_G: 0.0527 Convergence: 0.1211 k= 0.053043 lr = 0.0000774\n",
      "[1/25][7640/9765] Loss_D: 0.1054 Loss_G: 0.0460 Convergence: 0.1106 k= 0.053057 lr = 0.0000774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][7650/9765] Loss_D: 0.1281 Loss_G: 0.0462 Convergence: 0.1368 k= 0.053053 lr = 0.0000774\n",
      "[1/25][7660/9765] Loss_D: 0.1127 Loss_G: 0.0498 Convergence: 0.1189 k= 0.053045 lr = 0.0000774\n",
      "[1/25][7670/9765] Loss_D: 0.1154 Loss_G: 0.0536 Convergence: 0.1243 k= 0.053028 lr = 0.0000774\n",
      "[1/25][7680/9765] Loss_D: 0.1037 Loss_G: 0.0508 Convergence: 0.1144 k= 0.053025 lr = 0.0000774\n",
      "[1/25][7690/9765] Loss_D: 0.1164 Loss_G: 0.0454 Convergence: 0.1209 k= 0.053016 lr = 0.0000774\n",
      "[1/25][7700/9765] Loss_D: 0.1227 Loss_G: 0.0533 Convergence: 0.1286 k= 0.052969 lr = 0.0000774\n",
      "[1/25][7710/9765] Loss_D: 0.1146 Loss_G: 0.0416 Convergence: 0.1225 k= 0.052934 lr = 0.0000774\n",
      "[1/25][7720/9765] Loss_D: 0.1016 Loss_G: 0.0411 Convergence: 0.1045 k= 0.052914 lr = 0.0000774\n",
      "[1/25][7730/9765] Loss_D: 0.1135 Loss_G: 0.0443 Convergence: 0.1179 k= 0.052907 lr = 0.0000774\n",
      "[1/25][7740/9765] Loss_D: 0.1148 Loss_G: 0.0664 Convergence: 0.1368 k= 0.052881 lr = 0.0000774\n",
      "[1/25][7750/9765] Loss_D: 0.1057 Loss_G: 0.0425 Convergence: 0.1087 k= 0.052810 lr = 0.0000774\n",
      "[1/25][7760/9765] Loss_D: 0.1072 Loss_G: 0.0453 Convergence: 0.1109 k= 0.052810 lr = 0.0000774\n",
      "[1/25][7770/9765] Loss_D: 0.1203 Loss_G: 0.0499 Convergence: 0.1235 k= 0.052798 lr = 0.0000774\n",
      "[1/25][7780/9765] Loss_D: 0.1145 Loss_G: 0.0520 Convergence: 0.1220 k= 0.052803 lr = 0.0000774\n",
      "[1/25][7790/9765] Loss_D: 0.1116 Loss_G: 0.0509 Convergence: 0.1192 k= 0.052795 lr = 0.0000774\n",
      "[1/25][7800/9765] Loss_D: 0.1087 Loss_G: 0.0454 Convergence: 0.1120 k= 0.052781 lr = 0.0000774\n",
      "[1/25][7810/9765] Loss_D: 0.1179 Loss_G: 0.0477 Convergence: 0.1205 k= 0.052762 lr = 0.0000774\n",
      "[1/25][7820/9765] Loss_D: 0.1204 Loss_G: 0.0663 Convergence: 0.1404 k= 0.052651 lr = 0.0000774\n",
      "[1/25][7830/9765] Loss_D: 0.1098 Loss_G: 0.0366 Convergence: 0.1195 k= 0.052622 lr = 0.0000774\n",
      "[1/25][7840/9765] Loss_D: 0.1057 Loss_G: 0.0502 Convergence: 0.1149 k= 0.052666 lr = 0.0000774\n",
      "[1/25][7850/9765] Loss_D: 0.1022 Loss_G: 0.0471 Convergence: 0.1097 k= 0.052651 lr = 0.0000774\n",
      "[1/25][7860/9765] Loss_D: 0.1072 Loss_G: 0.0429 Convergence: 0.1102 k= 0.052660 lr = 0.0000774\n",
      "[1/25][7870/9765] Loss_D: 0.1055 Loss_G: 0.0423 Convergence: 0.1092 k= 0.052643 lr = 0.0000774\n",
      "[1/25][7880/9765] Loss_D: 0.1199 Loss_G: 0.0509 Convergence: 0.1243 k= 0.052627 lr = 0.0000774\n",
      "[1/25][7890/9765] Loss_D: 0.1137 Loss_G: 0.0578 Convergence: 0.1276 k= 0.052609 lr = 0.0000774\n",
      "[1/25][7900/9765] Loss_D: 0.0982 Loss_G: 0.0472 Convergence: 0.1078 k= 0.052578 lr = 0.0000774\n",
      "[1/25][7910/9765] Loss_D: 0.1139 Loss_G: 0.0475 Convergence: 0.1172 k= 0.052577 lr = 0.0000774\n",
      "[1/25][7920/9765] Loss_D: 0.1098 Loss_G: 0.0419 Convergence: 0.1153 k= 0.052562 lr = 0.0000774\n",
      "[1/25][7930/9765] Loss_D: 0.1097 Loss_G: 0.0452 Convergence: 0.1127 k= 0.052530 lr = 0.0000774\n",
      "[1/25][7940/9765] Loss_D: 0.1114 Loss_G: 0.0464 Convergence: 0.1146 k= 0.052490 lr = 0.0000774\n",
      "[1/25][7950/9765] Loss_D: 0.1199 Loss_G: 0.0459 Convergence: 0.1251 k= 0.052479 lr = 0.0000774\n",
      "[1/25][7960/9765] Loss_D: 0.1079 Loss_G: 0.0427 Convergence: 0.1113 k= 0.052498 lr = 0.0000774\n",
      "[1/25][7970/9765] Loss_D: 0.1219 Loss_G: 0.0636 Convergence: 0.1384 k= 0.052463 lr = 0.0000774\n",
      "[1/25][7980/9765] Loss_D: 0.1103 Loss_G: 0.0424 Convergence: 0.1153 k= 0.052414 lr = 0.0000774\n",
      "[1/25][7990/9765] Loss_D: 0.1160 Loss_G: 0.0473 Convergence: 0.1187 k= 0.052420 lr = 0.0000774\n",
      "[1/25][8000/9765] Loss_D: 0.1140 Loss_G: 0.0598 Convergence: 0.1298 k= 0.052363 lr = 0.0000774\n",
      "[1/25][8010/9765] Loss_D: 0.1055 Loss_G: 0.0395 Convergence: 0.1112 k= 0.052361 lr = 0.0000774\n",
      "[1/25][8020/9765] Loss_D: 0.1092 Loss_G: 0.0422 Convergence: 0.1149 k= 0.052340 lr = 0.0000774\n",
      "[1/25][8030/9765] Loss_D: 0.1302 Loss_G: 0.0461 Convergence: 0.1400 k= 0.052322 lr = 0.0000774\n",
      "[1/25][8040/9765] Loss_D: 0.1051 Loss_G: 0.0501 Convergence: 0.1146 k= 0.052289 lr = 0.0000774\n",
      "[1/25][8050/9765] Loss_D: 0.1056 Loss_G: 0.0494 Convergence: 0.1141 k= 0.052273 lr = 0.0000774\n",
      "[1/25][8060/9765] Loss_D: 0.1129 Loss_G: 0.0444 Convergence: 0.1170 k= 0.052276 lr = 0.0000774\n",
      "[1/25][8070/9765] Loss_D: 0.1018 Loss_G: 0.0392 Convergence: 0.1062 k= 0.052263 lr = 0.0000774\n",
      "[1/25][8080/9765] Loss_D: 0.1162 Loss_G: 0.0416 Convergence: 0.1242 k= 0.052268 lr = 0.0000774\n",
      "[1/25][8090/9765] Loss_D: 0.1079 Loss_G: 0.0495 Convergence: 0.1158 k= 0.052235 lr = 0.0000774\n",
      "[1/25][8100/9765] Loss_D: 0.1236 Loss_G: 0.0546 Convergence: 0.1300 k= 0.052253 lr = 0.0000774\n",
      "[1/25][8110/9765] Loss_D: 0.1101 Loss_G: 0.0435 Convergence: 0.1140 k= 0.052219 lr = 0.0000774\n",
      "[1/25][8120/9765] Loss_D: 0.1208 Loss_G: 0.0572 Convergence: 0.1313 k= 0.052154 lr = 0.0000774\n",
      "[1/25][8130/9765] Loss_D: 0.1073 Loss_G: 0.0505 Convergence: 0.1166 k= 0.052127 lr = 0.0000774\n",
      "[1/25][8140/9765] Loss_D: 0.1131 Loss_G: 0.0516 Convergence: 0.1208 k= 0.052111 lr = 0.0000774\n",
      "[1/25][8150/9765] Loss_D: 0.1138 Loss_G: 0.0416 Convergence: 0.1208 k= 0.052083 lr = 0.0000774\n",
      "[1/25][8160/9765] Loss_D: 0.1082 Loss_G: 0.0478 Convergence: 0.1140 k= 0.052049 lr = 0.0000774\n",
      "[1/25][8170/9765] Loss_D: 0.1058 Loss_G: 0.0497 Convergence: 0.1146 k= 0.052026 lr = 0.0000774\n",
      "[1/25][8180/9765] Loss_D: 0.1001 Loss_G: 0.0426 Convergence: 0.1039 k= 0.052048 lr = 0.0000774\n",
      "[1/25][8190/9765] Loss_D: 0.1100 Loss_G: 0.0453 Convergence: 0.1126 k= 0.052038 lr = 0.0000774\n",
      "[1/25][8200/9765] Loss_D: 0.1135 Loss_G: 0.0494 Convergence: 0.1191 k= 0.052029 lr = 0.0000774\n",
      "[1/25][8210/9765] Loss_D: 0.1185 Loss_G: 0.0471 Convergence: 0.1227 k= 0.051978 lr = 0.0000774\n",
      "[1/25][8220/9765] Loss_D: 0.1115 Loss_G: 0.0461 Convergence: 0.1143 k= 0.051966 lr = 0.0000774\n",
      "[1/25][8230/9765] Loss_D: 0.1107 Loss_G: 0.0424 Convergence: 0.1165 k= 0.051950 lr = 0.0000774\n",
      "[1/25][8240/9765] Loss_D: 0.1107 Loss_G: 0.0525 Convergence: 0.1204 k= 0.051879 lr = 0.0000735\n",
      "[1/25][8250/9765] Loss_D: 0.1118 Loss_G: 0.0451 Convergence: 0.1146 k= 0.051878 lr = 0.0000735\n",
      "[1/25][8260/9765] Loss_D: 0.1075 Loss_G: 0.0502 Convergence: 0.1164 k= 0.051850 lr = 0.0000735\n",
      "[1/25][8270/9765] Loss_D: 0.1171 Loss_G: 0.0501 Convergence: 0.1219 k= 0.051776 lr = 0.0000735\n",
      "[1/25][8280/9765] Loss_D: 0.1067 Loss_G: 0.0450 Convergence: 0.1104 k= 0.051779 lr = 0.0000735\n",
      "[1/25][8290/9765] Loss_D: 0.1131 Loss_G: 0.0519 Convergence: 0.1211 k= 0.051757 lr = 0.0000735\n",
      "[1/25][8300/9765] Loss_D: 0.1053 Loss_G: 0.0416 Convergence: 0.1089 k= 0.051738 lr = 0.0000735\n",
      "[1/25][8310/9765] Loss_D: 0.1198 Loss_G: 0.0456 Convergence: 0.1251 k= 0.051718 lr = 0.0000735\n",
      "[1/25][8320/9765] Loss_D: 0.1144 Loss_G: 0.0482 Convergence: 0.1185 k= 0.051675 lr = 0.0000735\n",
      "[1/25][8330/9765] Loss_D: 0.1161 Loss_G: 0.0466 Convergence: 0.1192 k= 0.051645 lr = 0.0000735\n",
      "[1/25][8340/9765] Loss_D: 0.1077 Loss_G: 0.0464 Convergence: 0.1124 k= 0.051649 lr = 0.0000735\n",
      "[1/25][8350/9765] Loss_D: 0.1001 Loss_G: 0.0522 Convergence: 0.1138 k= 0.051631 lr = 0.0000735\n",
      "[1/25][8360/9765] Loss_D: 0.1077 Loss_G: 0.0415 Convergence: 0.1120 k= 0.051603 lr = 0.0000735\n",
      "[1/25][8370/9765] Loss_D: 0.1116 Loss_G: 0.0437 Convergence: 0.1154 k= 0.051625 lr = 0.0000735\n",
      "[1/25][8380/9765] Loss_D: 0.1028 Loss_G: 0.0479 Convergence: 0.1111 k= 0.051587 lr = 0.0000735\n",
      "[1/25][8390/9765] Loss_D: 0.1183 Loss_G: 0.0439 Convergence: 0.1247 k= 0.051571 lr = 0.0000735\n",
      "[1/25][8400/9765] Loss_D: 0.1140 Loss_G: 0.0582 Convergence: 0.1279 k= 0.051577 lr = 0.0000735\n",
      "[1/25][8410/9765] Loss_D: 0.1071 Loss_G: 0.0424 Convergence: 0.1103 k= 0.051585 lr = 0.0000735\n",
      "[1/25][8420/9765] Loss_D: 0.1103 Loss_G: 0.0421 Convergence: 0.1152 k= 0.051576 lr = 0.0000735\n",
      "[1/25][8430/9765] Loss_D: 0.1049 Loss_G: 0.0450 Convergence: 0.1095 k= 0.051575 lr = 0.0000735\n",
      "[1/25][8440/9765] Loss_D: 0.1141 Loss_G: 0.0455 Convergence: 0.1177 k= 0.051562 lr = 0.0000735\n",
      "[1/25][8450/9765] Loss_D: 0.1162 Loss_G: 0.0478 Convergence: 0.1190 k= 0.051554 lr = 0.0000735\n",
      "[1/25][8460/9765] Loss_D: 0.1124 Loss_G: 0.0550 Convergence: 0.1237 k= 0.051524 lr = 0.0000735\n",
      "[1/25][8470/9765] Loss_D: 0.1096 Loss_G: 0.0448 Convergence: 0.1120 k= 0.051507 lr = 0.0000735\n",
      "[1/25][8480/9765] Loss_D: 0.1134 Loss_G: 0.0509 Convergence: 0.1204 k= 0.051491 lr = 0.0000735\n",
      "[1/25][8490/9765] Loss_D: 0.1042 Loss_G: 0.0467 Convergence: 0.1108 k= 0.051453 lr = 0.0000735\n",
      "[1/25][8500/9765] Loss_D: 0.1096 Loss_G: 0.0495 Convergence: 0.1171 k= 0.051394 lr = 0.0000735\n",
      "[1/25][8510/9765] Loss_D: 0.1119 Loss_G: 0.0532 Convergence: 0.1222 k= 0.051348 lr = 0.0000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][8520/9765] Loss_D: 0.1112 Loss_G: 0.0472 Convergence: 0.1152 k= 0.051314 lr = 0.0000735\n",
      "[1/25][8530/9765] Loss_D: 0.1136 Loss_G: 0.0475 Convergence: 0.1171 k= 0.051304 lr = 0.0000735\n",
      "[1/25][8540/9765] Loss_D: 0.1135 Loss_G: 0.0431 Convergence: 0.1190 k= 0.051307 lr = 0.0000735\n",
      "[1/25][8550/9765] Loss_D: 0.1121 Loss_G: 0.0476 Convergence: 0.1162 k= 0.051306 lr = 0.0000735\n",
      "[1/25][8560/9765] Loss_D: 0.1163 Loss_G: 0.0549 Convergence: 0.1264 k= 0.051283 lr = 0.0000735\n",
      "[1/25][8570/9765] Loss_D: 0.1012 Loss_G: 0.0463 Convergence: 0.1084 k= 0.051227 lr = 0.0000735\n",
      "[1/25][8580/9765] Loss_D: 0.1107 Loss_G: 0.0449 Convergence: 0.1132 k= 0.051261 lr = 0.0000735\n",
      "[1/25][8590/9765] Loss_D: 0.1078 Loss_G: 0.0506 Convergence: 0.1166 k= 0.051269 lr = 0.0000735\n",
      "[1/25][8600/9765] Loss_D: 0.1223 Loss_G: 0.0614 Convergence: 0.1362 k= 0.051242 lr = 0.0000735\n",
      "[1/25][8610/9765] Loss_D: 0.1121 Loss_G: 0.0387 Convergence: 0.1213 k= 0.051255 lr = 0.0000735\n",
      "[1/25][8620/9765] Loss_D: 0.1149 Loss_G: 0.0591 Convergence: 0.1298 k= 0.051193 lr = 0.0000735\n",
      "[1/25][8630/9765] Loss_D: 0.1188 Loss_G: 0.0406 Convergence: 0.1284 k= 0.051168 lr = 0.0000735\n",
      "[1/25][8640/9765] Loss_D: 0.1143 Loss_G: 0.0465 Convergence: 0.1167 k= 0.051187 lr = 0.0000735\n",
      "[1/25][8650/9765] Loss_D: 0.1168 Loss_G: 0.0639 Convergence: 0.1352 k= 0.051173 lr = 0.0000735\n",
      "[1/25][8660/9765] Loss_D: 0.1205 Loss_G: 0.0517 Convergence: 0.1254 k= 0.051120 lr = 0.0000735\n",
      "[1/25][8670/9765] Loss_D: 0.1085 Loss_G: 0.0465 Convergence: 0.1129 k= 0.051112 lr = 0.0000735\n",
      "[1/25][8680/9765] Loss_D: 0.1135 Loss_G: 0.0464 Convergence: 0.1159 k= 0.051123 lr = 0.0000735\n",
      "[1/25][8690/9765] Loss_D: 0.1100 Loss_G: 0.0532 Convergence: 0.1206 k= 0.051088 lr = 0.0000735\n",
      "[1/25][8700/9765] Loss_D: 0.1047 Loss_G: 0.0433 Convergence: 0.1074 k= 0.051083 lr = 0.0000735\n",
      "[1/25][8710/9765] Loss_D: 0.1163 Loss_G: 0.0426 Convergence: 0.1232 k= 0.051072 lr = 0.0000735\n",
      "[1/25][8720/9765] Loss_D: 0.1059 Loss_G: 0.0442 Convergence: 0.1090 k= 0.051063 lr = 0.0000735\n",
      "[1/25][8730/9765] Loss_D: 0.1219 Loss_G: 0.0525 Convergence: 0.1269 k= 0.051073 lr = 0.0000735\n",
      "[1/25][8740/9765] Loss_D: 0.1236 Loss_G: 0.0435 Convergence: 0.1325 k= 0.051070 lr = 0.0000735\n",
      "[1/25][8750/9765] Loss_D: 0.1132 Loss_G: 0.0488 Convergence: 0.1183 k= 0.051039 lr = 0.0000735\n",
      "[1/25][8760/9765] Loss_D: 0.1063 Loss_G: 0.0497 Convergence: 0.1148 k= 0.051022 lr = 0.0000735\n",
      "[1/25][8770/9765] Loss_D: 0.1096 Loss_G: 0.0464 Convergence: 0.1136 k= 0.051020 lr = 0.0000735\n",
      "[1/25][8780/9765] Loss_D: 0.1001 Loss_G: 0.0451 Convergence: 0.1066 k= 0.050967 lr = 0.0000735\n",
      "[1/25][8790/9765] Loss_D: 0.1067 Loss_G: 0.0442 Convergence: 0.1096 k= 0.050979 lr = 0.0000735\n",
      "[1/25][8800/9765] Loss_D: 0.1080 Loss_G: 0.0476 Convergence: 0.1140 k= 0.050966 lr = 0.0000735\n",
      "[1/25][8810/9765] Loss_D: 0.1075 Loss_G: 0.0500 Convergence: 0.1161 k= 0.050913 lr = 0.0000735\n",
      "[1/25][8820/9765] Loss_D: 0.1131 Loss_G: 0.0439 Convergence: 0.1180 k= 0.050902 lr = 0.0000735\n",
      "[1/25][8830/9765] Loss_D: 0.1152 Loss_G: 0.0434 Convergence: 0.1208 k= 0.050895 lr = 0.0000735\n",
      "[1/25][8840/9765] Loss_D: 0.1103 Loss_G: 0.0460 Convergence: 0.1135 k= 0.050892 lr = 0.0000735\n",
      "[1/25][8850/9765] Loss_D: 0.1101 Loss_G: 0.0433 Convergence: 0.1141 k= 0.050907 lr = 0.0000735\n",
      "[1/25][8860/9765] Loss_D: 0.1141 Loss_G: 0.0446 Convergence: 0.1178 k= 0.050895 lr = 0.0000735\n",
      "[1/25][8870/9765] Loss_D: 0.1212 Loss_G: 0.0505 Convergence: 0.1246 k= 0.050899 lr = 0.0000735\n",
      "[1/25][8880/9765] Loss_D: 0.1137 Loss_G: 0.0460 Convergence: 0.1165 k= 0.050879 lr = 0.0000735\n",
      "[1/25][8890/9765] Loss_D: 0.1062 Loss_G: 0.0440 Convergence: 0.1092 k= 0.050874 lr = 0.0000735\n",
      "[1/25][8900/9765] Loss_D: 0.1065 Loss_G: 0.0505 Convergence: 0.1159 k= 0.050817 lr = 0.0000735\n",
      "[1/25][8910/9765] Loss_D: 0.1143 Loss_G: 0.0443 Convergence: 0.1189 k= 0.050793 lr = 0.0000735\n",
      "[1/25][8920/9765] Loss_D: 0.1067 Loss_G: 0.0424 Convergence: 0.1104 k= 0.050782 lr = 0.0000735\n",
      "[1/25][8930/9765] Loss_D: 0.1021 Loss_G: 0.0389 Convergence: 0.1071 k= 0.050775 lr = 0.0000735\n",
      "[1/25][8940/9765] Loss_D: 0.1088 Loss_G: 0.0508 Convergence: 0.1175 k= 0.050725 lr = 0.0000735\n",
      "[1/25][8950/9765] Loss_D: 0.1141 Loss_G: 0.0539 Convergence: 0.1235 k= 0.050719 lr = 0.0000735\n",
      "[1/25][8960/9765] Loss_D: 0.1085 Loss_G: 0.0459 Convergence: 0.1123 k= 0.050724 lr = 0.0000735\n",
      "[1/25][8970/9765] Loss_D: 0.0990 Loss_G: 0.0431 Convergence: 0.1039 k= 0.050693 lr = 0.0000735\n",
      "[1/25][8980/9765] Loss_D: 0.1165 Loss_G: 0.0452 Convergence: 0.1211 k= 0.050689 lr = 0.0000735\n",
      "[1/25][8990/9765] Loss_D: 0.1080 Loss_G: 0.0419 Convergence: 0.1126 k= 0.050673 lr = 0.0000735\n",
      "[1/25][9000/9765] Loss_D: 0.1073 Loss_G: 0.0405 Convergence: 0.1131 k= 0.050641 lr = 0.0000735\n",
      "[1/25][9010/9765] Loss_D: 0.1150 Loss_G: 0.0422 Convergence: 0.1218 k= 0.050663 lr = 0.0000735\n",
      "[1/25][9020/9765] Loss_D: 0.1070 Loss_G: 0.0440 Convergence: 0.1094 k= 0.050647 lr = 0.0000735\n",
      "[1/25][9030/9765] Loss_D: 0.1047 Loss_G: 0.0413 Convergence: 0.1082 k= 0.050648 lr = 0.0000735\n",
      "[1/25][9040/9765] Loss_D: 0.1088 Loss_G: 0.0459 Convergence: 0.1127 k= 0.050638 lr = 0.0000735\n",
      "[1/25][9050/9765] Loss_D: 0.1125 Loss_G: 0.0496 Convergence: 0.1185 k= 0.050625 lr = 0.0000735\n",
      "[1/25][9060/9765] Loss_D: 0.1095 Loss_G: 0.0527 Convergence: 0.1197 k= 0.050621 lr = 0.0000735\n",
      "[1/25][9070/9765] Loss_D: 0.1105 Loss_G: 0.0466 Convergence: 0.1142 k= 0.050609 lr = 0.0000735\n",
      "[1/25][9080/9765] Loss_D: 0.0993 Loss_G: 0.0513 Convergence: 0.1123 k= 0.050585 lr = 0.0000735\n",
      "[1/25][9090/9765] Loss_D: 0.1149 Loss_G: 0.0535 Convergence: 0.1237 k= 0.050577 lr = 0.0000735\n",
      "[1/25][9100/9765] Loss_D: 0.1141 Loss_G: 0.0493 Convergence: 0.1191 k= 0.050602 lr = 0.0000735\n",
      "[1/25][9110/9765] Loss_D: 0.1165 Loss_G: 0.0525 Convergence: 0.1238 k= 0.050570 lr = 0.0000735\n",
      "[1/25][9120/9765] Loss_D: 0.1013 Loss_G: 0.0454 Convergence: 0.1074 k= 0.050581 lr = 0.0000735\n",
      "[1/25][9130/9765] Loss_D: 0.1065 Loss_G: 0.0437 Convergence: 0.1089 k= 0.050569 lr = 0.0000735\n",
      "[1/25][9140/9765] Loss_D: 0.1092 Loss_G: 0.0489 Convergence: 0.1158 k= 0.050550 lr = 0.0000735\n",
      "[1/25][9150/9765] Loss_D: 0.1093 Loss_G: 0.0479 Convergence: 0.1148 k= 0.050548 lr = 0.0000735\n",
      "[1/25][9160/9765] Loss_D: 0.1051 Loss_G: 0.0415 Convergence: 0.1084 k= 0.050553 lr = 0.0000735\n",
      "[1/25][9170/9765] Loss_D: 0.1020 Loss_G: 0.0437 Convergence: 0.1061 k= 0.050556 lr = 0.0000735\n",
      "[1/25][9180/9765] Loss_D: 0.1066 Loss_G: 0.0506 Convergence: 0.1158 k= 0.050548 lr = 0.0000735\n",
      "[1/25][9190/9765] Loss_D: 0.1173 Loss_G: 0.0424 Convergence: 0.1251 k= 0.050543 lr = 0.0000735\n",
      "[1/25][9200/9765] Loss_D: 0.1156 Loss_G: 0.0434 Convergence: 0.1217 k= 0.050472 lr = 0.0000735\n",
      "[1/25][9210/9765] Loss_D: 0.1124 Loss_G: 0.0502 Convergence: 0.1190 k= 0.050439 lr = 0.0000735\n",
      "[1/25][9220/9765] Loss_D: 0.1149 Loss_G: 0.0461 Convergence: 0.1180 k= 0.050409 lr = 0.0000735\n",
      "[1/25][9230/9765] Loss_D: 0.1092 Loss_G: 0.0441 Convergence: 0.1118 k= 0.050423 lr = 0.0000735\n",
      "[1/25][9240/9765] Loss_D: 0.1097 Loss_G: 0.0408 Convergence: 0.1157 k= 0.050436 lr = 0.0000735\n",
      "[1/25][9250/9765] Loss_D: 0.1056 Loss_G: 0.0420 Convergence: 0.1090 k= 0.050422 lr = 0.0000735\n",
      "[1/25][9260/9765] Loss_D: 0.1066 Loss_G: 0.0436 Convergence: 0.1090 k= 0.050407 lr = 0.0000735\n",
      "[1/25][9270/9765] Loss_D: 0.1160 Loss_G: 0.0493 Convergence: 0.1202 k= 0.050394 lr = 0.0000735\n",
      "[1/25][9280/9765] Loss_D: 0.1124 Loss_G: 0.0525 Convergence: 0.1213 k= 0.050392 lr = 0.0000735\n",
      "[1/25][9290/9765] Loss_D: 0.1101 Loss_G: 0.0461 Convergence: 0.1135 k= 0.050362 lr = 0.0000735\n",
      "[1/25][9300/9765] Loss_D: 0.1104 Loss_G: 0.0550 Convergence: 0.1225 k= 0.050370 lr = 0.0000735\n",
      "[1/25][9310/9765] Loss_D: 0.1246 Loss_G: 0.0481 Convergence: 0.1294 k= 0.050362 lr = 0.0000735\n",
      "[1/25][9320/9765] Loss_D: 0.1084 Loss_G: 0.0439 Convergence: 0.1110 k= 0.050345 lr = 0.0000735\n",
      "[1/25][9330/9765] Loss_D: 0.1063 Loss_G: 0.0453 Convergence: 0.1108 k= 0.050318 lr = 0.0000735\n",
      "[1/25][9340/9765] Loss_D: 0.1153 Loss_G: 0.0529 Convergence: 0.1236 k= 0.050304 lr = 0.0000735\n",
      "[1/25][9350/9765] Loss_D: 0.1184 Loss_G: 0.0463 Convergence: 0.1223 k= 0.050280 lr = 0.0000735\n",
      "[1/25][9360/9765] Loss_D: 0.1085 Loss_G: 0.0401 Convergence: 0.1149 k= 0.050262 lr = 0.0000735\n",
      "[1/25][9370/9765] Loss_D: 0.1133 Loss_G: 0.0487 Convergence: 0.1181 k= 0.050273 lr = 0.0000735\n",
      "[1/25][9380/9765] Loss_D: 0.1127 Loss_G: 0.0418 Convergence: 0.1190 k= 0.050270 lr = 0.0000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/25][9390/9765] Loss_D: 0.1053 Loss_G: 0.0471 Convergence: 0.1117 k= 0.050284 lr = 0.0000735\n",
      "[1/25][9400/9765] Loss_D: 0.1056 Loss_G: 0.0432 Convergence: 0.1079 k= 0.050274 lr = 0.0000735\n",
      "[1/25][9410/9765] Loss_D: 0.1005 Loss_G: 0.0424 Convergence: 0.1040 k= 0.050279 lr = 0.0000735\n",
      "[1/25][9420/9765] Loss_D: 0.1159 Loss_G: 0.0562 Convergence: 0.1273 k= 0.050232 lr = 0.0000735\n",
      "[1/25][9430/9765] Loss_D: 0.1172 Loss_G: 0.0401 Convergence: 0.1269 k= 0.050243 lr = 0.0000735\n",
      "[1/25][9440/9765] Loss_D: 0.1169 Loss_G: 0.0508 Convergence: 0.1225 k= 0.050237 lr = 0.0000735\n",
      "[1/25][9450/9765] Loss_D: 0.1097 Loss_G: 0.0434 Convergence: 0.1133 k= 0.050213 lr = 0.0000735\n",
      "[1/25][9460/9765] Loss_D: 0.1091 Loss_G: 0.0496 Convergence: 0.1164 k= 0.050209 lr = 0.0000735\n",
      "[1/25][9470/9765] Loss_D: 0.1103 Loss_G: 0.0462 Convergence: 0.1137 k= 0.050203 lr = 0.0000735\n",
      "[1/25][9480/9765] Loss_D: 0.0973 Loss_G: 0.0414 Convergence: 0.1012 k= 0.050193 lr = 0.0000735\n",
      "[1/25][9490/9765] Loss_D: 0.1158 Loss_G: 0.0446 Convergence: 0.1208 k= 0.050199 lr = 0.0000735\n",
      "[1/25][9500/9765] Loss_D: 0.1117 Loss_G: 0.0539 Convergence: 0.1223 k= 0.050174 lr = 0.0000735\n",
      "[1/25][9510/9765] Loss_D: 0.1099 Loss_G: 0.0453 Convergence: 0.1128 k= 0.050186 lr = 0.0000735\n",
      "[1/25][9520/9765] Loss_D: 0.1019 Loss_G: 0.0450 Convergence: 0.1075 k= 0.050164 lr = 0.0000735\n",
      "[1/25][9530/9765] Loss_D: 0.1111 Loss_G: 0.0523 Convergence: 0.1206 k= 0.050107 lr = 0.0000735\n",
      "[1/25][9540/9765] Loss_D: 0.1120 Loss_G: 0.0485 Convergence: 0.1170 k= 0.050106 lr = 0.0000735\n",
      "[1/25][9550/9765] Loss_D: 0.1174 Loss_G: 0.0451 Convergence: 0.1225 k= 0.050075 lr = 0.0000735\n",
      "[1/25][9560/9765] Loss_D: 0.1113 Loss_G: 0.0480 Convergence: 0.1163 k= 0.050078 lr = 0.0000735\n",
      "[1/25][9570/9765] Loss_D: 0.1096 Loss_G: 0.0441 Convergence: 0.1128 k= 0.050070 lr = 0.0000735\n",
      "[1/25][9580/9765] Loss_D: 0.1035 Loss_G: 0.0486 Convergence: 0.1120 k= 0.050075 lr = 0.0000735\n",
      "[1/25][9590/9765] Loss_D: 0.1035 Loss_G: 0.0429 Convergence: 0.1062 k= 0.050089 lr = 0.0000735\n",
      "[1/25][9600/9765] Loss_D: 0.1222 Loss_G: 0.0506 Convergence: 0.1252 k= 0.050076 lr = 0.0000735\n",
      "[1/25][9610/9765] Loss_D: 0.1222 Loss_G: 0.0554 Convergence: 0.1300 k= 0.050070 lr = 0.0000735\n",
      "[1/25][9620/9765] Loss_D: 0.1010 Loss_G: 0.0405 Convergence: 0.1043 k= 0.050008 lr = 0.0000735\n",
      "[1/25][9630/9765] Loss_D: 0.1060 Loss_G: 0.0490 Convergence: 0.1139 k= 0.050002 lr = 0.0000735\n",
      "[1/25][9640/9765] Loss_D: 0.1123 Loss_G: 0.0599 Convergence: 0.1287 k= 0.049975 lr = 0.0000735\n",
      "[1/25][9650/9765] Loss_D: 0.1150 Loss_G: 0.0476 Convergence: 0.1180 k= 0.049977 lr = 0.0000735\n",
      "[1/25][9660/9765] Loss_D: 0.1174 Loss_G: 0.0550 Convergence: 0.1270 k= 0.049913 lr = 0.0000735\n",
      "[1/25][9670/9765] Loss_D: 0.1119 Loss_G: 0.0396 Convergence: 0.1198 k= 0.049889 lr = 0.0000735\n",
      "[1/25][9680/9765] Loss_D: 0.1152 Loss_G: 0.0455 Convergence: 0.1188 k= 0.049881 lr = 0.0000735\n",
      "[1/25][9690/9765] Loss_D: 0.1144 Loss_G: 0.0489 Convergence: 0.1188 k= 0.049857 lr = 0.0000735\n",
      "[1/25][9700/9765] Loss_D: 0.1036 Loss_G: 0.0442 Convergence: 0.1076 k= 0.049861 lr = 0.0000735\n",
      "[1/25][9710/9765] Loss_D: 0.1102 Loss_G: 0.0493 Convergence: 0.1170 k= 0.049849 lr = 0.0000735\n",
      "[1/25][9720/9765] Loss_D: 0.1172 Loss_G: 0.0434 Convergence: 0.1236 k= 0.049849 lr = 0.0000735\n",
      "[1/25][9730/9765] Loss_D: 0.1110 Loss_G: 0.0433 Convergence: 0.1151 k= 0.049839 lr = 0.0000735\n",
      "[1/25][9740/9765] Loss_D: 0.1126 Loss_G: 0.0432 Convergence: 0.1179 k= 0.049824 lr = 0.0000735\n",
      "[1/25][9750/9765] Loss_D: 0.1172 Loss_G: 0.0527 Convergence: 0.1242 k= 0.049806 lr = 0.0000735\n",
      "[1/25][9760/9765] Loss_D: 0.1212 Loss_G: 0.0475 Convergence: 0.1253 k= 0.049792 lr = 0.0000735\n",
      "[2/25][0/9765] Loss_D: 0.1105 Loss_G: 0.0508 Convergence: 0.1185 k= 0.049784 lr = 0.0000735\n",
      "[2/25][10/9765] Loss_D: 0.1041 Loss_G: 0.0504 Convergence: 0.1145 k= 0.049780 lr = 0.0000735\n",
      "[2/25][20/9765] Loss_D: 0.1105 Loss_G: 0.0485 Convergence: 0.1161 k= 0.049712 lr = 0.0000735\n",
      "[2/25][30/9765] Loss_D: 0.1061 Loss_G: 0.0432 Convergence: 0.1086 k= 0.049700 lr = 0.0000735\n",
      "[2/25][40/9765] Loss_D: 0.1096 Loss_G: 0.0443 Convergence: 0.1122 k= 0.049691 lr = 0.0000735\n",
      "[2/25][50/9765] Loss_D: 0.0991 Loss_G: 0.0430 Convergence: 0.1038 k= 0.049687 lr = 0.0000735\n",
      "[2/25][60/9765] Loss_D: 0.1040 Loss_G: 0.0413 Convergence: 0.1074 k= 0.049663 lr = 0.0000735\n",
      "[2/25][70/9765] Loss_D: 0.1165 Loss_G: 0.0459 Convergence: 0.1198 k= 0.049664 lr = 0.0000735\n",
      "[2/25][80/9765] Loss_D: 0.1126 Loss_G: 0.0512 Convergence: 0.1201 k= 0.049662 lr = 0.0000735\n",
      "[2/25][90/9765] Loss_D: 0.1064 Loss_G: 0.0450 Convergence: 0.1100 k= 0.049663 lr = 0.0000735\n",
      "[2/25][100/9765] Loss_D: 0.1150 Loss_G: 0.0414 Convergence: 0.1226 k= 0.049685 lr = 0.0000735\n",
      "[2/25][110/9765] Loss_D: 0.1124 Loss_G: 0.0460 Convergence: 0.1148 k= 0.049676 lr = 0.0000735\n",
      "[2/25][120/9765] Loss_D: 0.1169 Loss_G: 0.0546 Convergence: 0.1262 k= 0.049647 lr = 0.0000735\n",
      "[2/25][130/9765] Loss_D: 0.1123 Loss_G: 0.0427 Convergence: 0.1172 k= 0.049657 lr = 0.0000735\n",
      "[2/25][140/9765] Loss_D: 0.1110 Loss_G: 0.0410 Convergence: 0.1176 k= 0.049626 lr = 0.0000735\n",
      "[2/25][150/9765] Loss_D: 0.1051 Loss_G: 0.0400 Convergence: 0.1101 k= 0.049620 lr = 0.0000735\n",
      "[2/25][160/9765] Loss_D: 0.1095 Loss_G: 0.0463 Convergence: 0.1133 k= 0.049515 lr = 0.0000735\n",
      "[2/25][170/9765] Loss_D: 0.1079 Loss_G: 0.0467 Convergence: 0.1127 k= 0.049531 lr = 0.0000735\n",
      "[2/25][180/9765] Loss_D: 0.1029 Loss_G: 0.0435 Convergence: 0.1067 k= 0.049511 lr = 0.0000735\n",
      "[2/25][190/9765] Loss_D: 0.1155 Loss_G: 0.0430 Convergence: 0.1215 k= 0.049510 lr = 0.0000735\n",
      "[2/25][200/9765] Loss_D: 0.1094 Loss_G: 0.0533 Convergence: 0.1203 k= 0.049512 lr = 0.0000735\n",
      "[2/25][210/9765] Loss_D: 0.1065 Loss_G: 0.0464 Convergence: 0.1117 k= 0.049492 lr = 0.0000735\n",
      "[2/25][220/9765] Loss_D: 0.1117 Loss_G: 0.0425 Convergence: 0.1168 k= 0.049489 lr = 0.0000735\n",
      "[2/25][230/9765] Loss_D: 0.1159 Loss_G: 0.0499 Convergence: 0.1209 k= 0.049464 lr = 0.0000735\n",
      "[2/25][240/9765] Loss_D: 0.1204 Loss_G: 0.0442 Convergence: 0.1273 k= 0.049404 lr = 0.0000735\n",
      "[2/25][250/9765] Loss_D: 0.1125 Loss_G: 0.0399 Convergence: 0.1207 k= 0.049418 lr = 0.0000735\n",
      "[2/25][260/9765] Loss_D: 0.1238 Loss_G: 0.0512 Convergence: 0.1268 k= 0.049422 lr = 0.0000735\n",
      "[2/25][270/9765] Loss_D: 0.1115 Loss_G: 0.0472 Convergence: 0.1155 k= 0.049421 lr = 0.0000735\n",
      "[2/25][280/9765] Loss_D: 0.1080 Loss_G: 0.0445 Convergence: 0.1107 k= 0.049400 lr = 0.0000735\n",
      "[2/25][290/9765] Loss_D: 0.1128 Loss_G: 0.0432 Convergence: 0.1176 k= 0.049383 lr = 0.0000735\n",
      "[2/25][300/9765] Loss_D: 0.1167 Loss_G: 0.0481 Convergence: 0.1194 k= 0.049374 lr = 0.0000735\n",
      "[2/25][310/9765] Loss_D: 0.1118 Loss_G: 0.0440 Convergence: 0.1156 k= 0.049364 lr = 0.0000735\n",
      "[2/25][320/9765] Loss_D: 0.1181 Loss_G: 0.0441 Convergence: 0.1239 k= 0.049391 lr = 0.0000735\n",
      "[2/25][330/9765] Loss_D: 0.1051 Loss_G: 0.0432 Convergence: 0.1076 k= 0.049379 lr = 0.0000735\n",
      "[2/25][340/9765] Loss_D: 0.1128 Loss_G: 0.0476 Convergence: 0.1166 k= 0.049364 lr = 0.0000735\n",
      "[2/25][350/9765] Loss_D: 0.1130 Loss_G: 0.0414 Convergence: 0.1195 k= 0.049357 lr = 0.0000735\n",
      "[2/25][360/9765] Loss_D: 0.1131 Loss_G: 0.0494 Convergence: 0.1186 k= 0.049336 lr = 0.0000735\n",
      "[2/25][370/9765] Loss_D: 0.1178 Loss_G: 0.0472 Convergence: 0.1202 k= 0.049320 lr = 0.0000735\n",
      "[2/25][380/9765] Loss_D: 0.1087 Loss_G: 0.0491 Convergence: 0.1156 k= 0.049286 lr = 0.0000735\n",
      "[2/25][390/9765] Loss_D: 0.1102 Loss_G: 0.0492 Convergence: 0.1166 k= 0.049288 lr = 0.0000735\n",
      "[2/25][400/9765] Loss_D: 0.1176 Loss_G: 0.0414 Convergence: 0.1262 k= 0.049294 lr = 0.0000735\n",
      "[2/25][410/9765] Loss_D: 0.1000 Loss_G: 0.0452 Convergence: 0.1066 k= 0.049303 lr = 0.0000735\n",
      "[2/25][420/9765] Loss_D: 0.1220 Loss_G: 0.0486 Convergence: 0.1255 k= 0.049256 lr = 0.0000735\n",
      "[2/25][430/9765] Loss_D: 0.0923 Loss_G: 0.0370 Convergence: 0.0949 k= 0.049262 lr = 0.0000735\n",
      "[2/25][440/9765] Loss_D: 0.1103 Loss_G: 0.0458 Convergence: 0.1134 k= 0.049263 lr = 0.0000735\n",
      "[2/25][450/9765] Loss_D: 0.1175 Loss_G: 0.0443 Convergence: 0.1234 k= 0.049251 lr = 0.0000735\n",
      "[2/25][460/9765] Loss_D: 0.1045 Loss_G: 0.0390 Convergence: 0.1104 k= 0.049263 lr = 0.0000735\n",
      "[2/25][470/9765] Loss_D: 0.1061 Loss_G: 0.0468 Convergence: 0.1118 k= 0.049273 lr = 0.0000735\n",
      "[2/25][480/9765] Loss_D: 0.1093 Loss_G: 0.0466 Convergence: 0.1137 k= 0.049240 lr = 0.0000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][490/9765] Loss_D: 0.1070 Loss_G: 0.0461 Convergence: 0.1116 k= 0.049248 lr = 0.0000735\n",
      "[2/25][500/9765] Loss_D: 0.1033 Loss_G: 0.0438 Convergence: 0.1070 k= 0.049265 lr = 0.0000735\n",
      "[2/25][510/9765] Loss_D: 0.1139 Loss_G: 0.0423 Convergence: 0.1204 k= 0.049272 lr = 0.0000735\n",
      "[2/25][520/9765] Loss_D: 0.0999 Loss_G: 0.0438 Convergence: 0.1052 k= 0.049213 lr = 0.0000735\n",
      "[2/25][530/9765] Loss_D: 0.1146 Loss_G: 0.0456 Convergence: 0.1178 k= 0.049209 lr = 0.0000735\n",
      "[2/25][540/9765] Loss_D: 0.1074 Loss_G: 0.0509 Convergence: 0.1167 k= 0.049206 lr = 0.0000735\n",
      "[2/25][550/9765] Loss_D: 0.1090 Loss_G: 0.0468 Convergence: 0.1134 k= 0.049193 lr = 0.0000735\n",
      "[2/25][560/9765] Loss_D: 0.1109 Loss_G: 0.0522 Convergence: 0.1200 k= 0.049176 lr = 0.0000735\n",
      "[2/25][570/9765] Loss_D: 0.1138 Loss_G: 0.0472 Convergence: 0.1166 k= 0.049180 lr = 0.0000735\n",
      "[2/25][580/9765] Loss_D: 0.1087 Loss_G: 0.0490 Convergence: 0.1156 k= 0.049160 lr = 0.0000735\n",
      "[2/25][590/9765] Loss_D: 0.1137 Loss_G: 0.0398 Convergence: 0.1227 k= 0.049152 lr = 0.0000735\n",
      "[2/25][600/9765] Loss_D: 0.1144 Loss_G: 0.0472 Convergence: 0.1172 k= 0.049152 lr = 0.0000735\n",
      "[2/25][610/9765] Loss_D: 0.1021 Loss_G: 0.0451 Convergence: 0.1079 k= 0.049132 lr = 0.0000735\n",
      "[2/25][620/9765] Loss_D: 0.1096 Loss_G: 0.0520 Convergence: 0.1192 k= 0.049085 lr = 0.0000735\n",
      "[2/25][630/9765] Loss_D: 0.1033 Loss_G: 0.0400 Convergence: 0.1078 k= 0.049067 lr = 0.0000735\n",
      "[2/25][640/9765] Loss_D: 0.1104 Loss_G: 0.0455 Convergence: 0.1130 k= 0.049087 lr = 0.0000735\n",
      "[2/25][650/9765] Loss_D: 0.1009 Loss_G: 0.0480 Convergence: 0.1099 k= 0.049095 lr = 0.0000735\n",
      "[2/25][660/9765] Loss_D: 0.1210 Loss_G: 0.0494 Convergence: 0.1234 k= 0.049097 lr = 0.0000735\n",
      "[2/25][670/9765] Loss_D: 0.1094 Loss_G: 0.0562 Convergence: 0.1231 k= 0.049049 lr = 0.0000735\n",
      "[2/25][680/9765] Loss_D: 0.1083 Loss_G: 0.0418 Convergence: 0.1126 k= 0.049053 lr = 0.0000735\n",
      "[2/25][690/9765] Loss_D: 0.1099 Loss_G: 0.0483 Convergence: 0.1158 k= 0.049033 lr = 0.0000735\n",
      "[2/25][700/9765] Loss_D: 0.1082 Loss_G: 0.0496 Convergence: 0.1157 k= 0.049037 lr = 0.0000735\n",
      "[2/25][710/9765] Loss_D: 0.1176 Loss_G: 0.0448 Convergence: 0.1231 k= 0.049028 lr = 0.0000735\n",
      "[2/25][720/9765] Loss_D: 0.1157 Loss_G: 0.0445 Convergence: 0.1208 k= 0.048971 lr = 0.0000735\n",
      "[2/25][730/9765] Loss_D: 0.1054 Loss_G: 0.0457 Convergence: 0.1101 k= 0.048953 lr = 0.0000735\n",
      "[2/25][740/9765] Loss_D: 0.1082 Loss_G: 0.0475 Convergence: 0.1137 k= 0.048947 lr = 0.0000735\n",
      "[2/25][750/9765] Loss_D: 0.1080 Loss_G: 0.0485 Convergence: 0.1146 k= 0.048936 lr = 0.0000735\n",
      "[2/25][760/9765] Loss_D: 0.0947 Loss_G: 0.0547 Convergence: 0.1130 k= 0.048880 lr = 0.0000735\n",
      "[2/25][770/9765] Loss_D: 0.1080 Loss_G: 0.0494 Convergence: 0.1155 k= 0.048881 lr = 0.0000735\n",
      "[2/25][780/9765] Loss_D: 0.1105 Loss_G: 0.0538 Convergence: 0.1214 k= 0.048877 lr = 0.0000735\n",
      "[2/25][790/9765] Loss_D: 0.1209 Loss_G: 0.0461 Convergence: 0.1262 k= 0.048847 lr = 0.0000735\n",
      "[2/25][800/9765] Loss_D: 0.1054 Loss_G: 0.0485 Convergence: 0.1130 k= 0.048840 lr = 0.0000735\n",
      "[2/25][810/9765] Loss_D: 0.1075 Loss_G: 0.0428 Convergence: 0.1108 k= 0.048805 lr = 0.0000735\n",
      "[2/25][820/9765] Loss_D: 0.1122 Loss_G: 0.0517 Convergence: 0.1205 k= 0.048787 lr = 0.0000735\n",
      "[2/25][830/9765] Loss_D: 0.1115 Loss_G: 0.0494 Convergence: 0.1177 k= 0.048765 lr = 0.0000735\n",
      "[2/25][840/9765] Loss_D: 0.1082 Loss_G: 0.0403 Convergence: 0.1139 k= 0.048760 lr = 0.0000735\n",
      "[2/25][850/9765] Loss_D: 0.1127 Loss_G: 0.0464 Convergence: 0.1153 k= 0.048757 lr = 0.0000735\n",
      "[2/25][860/9765] Loss_D: 0.1169 Loss_G: 0.0420 Convergence: 0.1250 k= 0.048752 lr = 0.0000735\n",
      "[2/25][870/9765] Loss_D: 0.1087 Loss_G: 0.0435 Convergence: 0.1119 k= 0.048756 lr = 0.0000735\n",
      "[2/25][880/9765] Loss_D: 0.1146 Loss_G: 0.0474 Convergence: 0.1176 k= 0.048749 lr = 0.0000735\n",
      "[2/25][890/9765] Loss_D: 0.1194 Loss_G: 0.0466 Convergence: 0.1235 k= 0.048735 lr = 0.0000735\n",
      "[2/25][900/9765] Loss_D: 0.1083 Loss_G: 0.0444 Convergence: 0.1108 k= 0.048733 lr = 0.0000735\n",
      "[2/25][910/9765] Loss_D: 0.1085 Loss_G: 0.0445 Convergence: 0.1109 k= 0.048745 lr = 0.0000735\n",
      "[2/25][920/9765] Loss_D: 0.1066 Loss_G: 0.0437 Convergence: 0.1090 k= 0.048740 lr = 0.0000735\n",
      "[2/25][930/9765] Loss_D: 0.1072 Loss_G: 0.0436 Convergence: 0.1095 k= 0.048745 lr = 0.0000735\n",
      "[2/25][940/9765] Loss_D: 0.1027 Loss_G: 0.0472 Convergence: 0.1101 k= 0.048710 lr = 0.0000735\n",
      "[2/25][950/9765] Loss_D: 0.1033 Loss_G: 0.0463 Convergence: 0.1094 k= 0.048735 lr = 0.0000735\n",
      "[2/25][960/9765] Loss_D: 0.1223 Loss_G: 0.0495 Convergence: 0.1253 k= 0.048669 lr = 0.0000735\n",
      "[2/25][970/9765] Loss_D: 0.1160 Loss_G: 0.0468 Convergence: 0.1187 k= 0.048637 lr = 0.0000735\n",
      "[2/25][980/9765] Loss_D: 0.1088 Loss_G: 0.0420 Convergence: 0.1133 k= 0.048662 lr = 0.0000735\n",
      "[2/25][990/9765] Loss_D: 0.1090 Loss_G: 0.0542 Convergence: 0.1209 k= 0.048606 lr = 0.0000735\n",
      "[2/25][1000/9765] Loss_D: 0.1070 Loss_G: 0.0465 Convergence: 0.1120 k= 0.048612 lr = 0.0000735\n",
      "[2/25][1010/9765] Loss_D: 0.1008 Loss_G: 0.0460 Convergence: 0.1079 k= 0.048561 lr = 0.0000735\n",
      "[2/25][1020/9765] Loss_D: 0.1209 Loss_G: 0.0503 Convergence: 0.1246 k= 0.048501 lr = 0.0000735\n",
      "[2/25][1030/9765] Loss_D: 0.1109 Loss_G: 0.0432 Convergence: 0.1156 k= 0.048486 lr = 0.0000735\n",
      "[2/25][1040/9765] Loss_D: 0.1072 Loss_G: 0.0477 Convergence: 0.1132 k= 0.048487 lr = 0.0000735\n",
      "[2/25][1050/9765] Loss_D: 0.1123 Loss_G: 0.0434 Convergence: 0.1164 k= 0.048471 lr = 0.0000735\n",
      "[2/25][1060/9765] Loss_D: 0.1033 Loss_G: 0.0368 Convergence: 0.1106 k= 0.048492 lr = 0.0000735\n",
      "[2/25][1070/9765] Loss_D: 0.1132 Loss_G: 0.0476 Convergence: 0.1170 k= 0.048500 lr = 0.0000735\n",
      "[2/25][1080/9765] Loss_D: 0.1008 Loss_G: 0.0463 Convergence: 0.1081 k= 0.048494 lr = 0.0000735\n",
      "[2/25][1090/9765] Loss_D: 0.1113 Loss_G: 0.0469 Convergence: 0.1152 k= 0.048473 lr = 0.0000735\n",
      "[2/25][1100/9765] Loss_D: 0.1159 Loss_G: 0.0479 Convergence: 0.1188 k= 0.048467 lr = 0.0000735\n",
      "[2/25][1110/9765] Loss_D: 0.1103 Loss_G: 0.0483 Convergence: 0.1158 k= 0.048445 lr = 0.0000735\n",
      "[2/25][1120/9765] Loss_D: 0.1095 Loss_G: 0.0460 Convergence: 0.1131 k= 0.048416 lr = 0.0000735\n",
      "[2/25][1130/9765] Loss_D: 0.1116 Loss_G: 0.0424 Convergence: 0.1172 k= 0.048411 lr = 0.0000735\n",
      "[2/25][1140/9765] Loss_D: 0.1115 Loss_G: 0.0434 Convergence: 0.1160 k= 0.048370 lr = 0.0000735\n",
      "[2/25][1150/9765] Loss_D: 0.1005 Loss_G: 0.0416 Convergence: 0.1031 k= 0.048370 lr = 0.0000735\n",
      "[2/25][1160/9765] Loss_D: 0.1143 Loss_G: 0.0486 Convergence: 0.1186 k= 0.048368 lr = 0.0000735\n",
      "[2/25][1170/9765] Loss_D: 0.1141 Loss_G: 0.0467 Convergence: 0.1164 k= 0.048351 lr = 0.0000735\n",
      "[2/25][1180/9765] Loss_D: 0.1190 Loss_G: 0.0603 Convergence: 0.1332 k= 0.048328 lr = 0.0000735\n",
      "[2/25][1190/9765] Loss_D: 0.1115 Loss_G: 0.0412 Convergence: 0.1177 k= 0.048329 lr = 0.0000735\n",
      "[2/25][1200/9765] Loss_D: 0.1237 Loss_G: 0.0484 Convergence: 0.1280 k= 0.048310 lr = 0.0000735\n",
      "[2/25][1210/9765] Loss_D: 0.1155 Loss_G: 0.0498 Convergence: 0.1204 k= 0.048289 lr = 0.0000735\n",
      "[2/25][1220/9765] Loss_D: 0.1143 Loss_G: 0.0464 Convergence: 0.1167 k= 0.048269 lr = 0.0000735\n",
      "[2/25][1230/9765] Loss_D: 0.1128 Loss_G: 0.0440 Convergence: 0.1169 k= 0.048268 lr = 0.0000735\n",
      "[2/25][1240/9765] Loss_D: 0.1051 Loss_G: 0.0445 Convergence: 0.1088 k= 0.048265 lr = 0.0000735\n",
      "[2/25][1250/9765] Loss_D: 0.1072 Loss_G: 0.0470 Convergence: 0.1126 k= 0.048247 lr = 0.0000735\n",
      "[2/25][1260/9765] Loss_D: 0.0990 Loss_G: 0.0473 Convergence: 0.1081 k= 0.048236 lr = 0.0000735\n",
      "[2/25][1270/9765] Loss_D: 0.1186 Loss_G: 0.0495 Convergence: 0.1219 k= 0.048240 lr = 0.0000735\n",
      "[2/25][1280/9765] Loss_D: 0.1183 Loss_G: 0.0486 Convergence: 0.1209 k= 0.048204 lr = 0.0000735\n",
      "[2/25][1290/9765] Loss_D: 0.1087 Loss_G: 0.0419 Convergence: 0.1129 k= 0.048188 lr = 0.0000735\n",
      "[2/25][1300/9765] Loss_D: 0.1217 Loss_G: 0.0455 Convergence: 0.1286 k= 0.048213 lr = 0.0000735\n",
      "[2/25][1310/9765] Loss_D: 0.1152 Loss_G: 0.0519 Convergence: 0.1226 k= 0.048106 lr = 0.0000735\n",
      "[2/25][1320/9765] Loss_D: 0.1133 Loss_G: 0.0392 Convergence: 0.1224 k= 0.048111 lr = 0.0000735\n",
      "[2/25][1330/9765] Loss_D: 0.1094 Loss_G: 0.0534 Convergence: 0.1205 k= 0.048071 lr = 0.0000735\n",
      "[2/25][1340/9765] Loss_D: 0.1090 Loss_G: 0.0431 Convergence: 0.1122 k= 0.048057 lr = 0.0000735\n",
      "[2/25][1350/9765] Loss_D: 0.1119 Loss_G: 0.0408 Convergence: 0.1186 k= 0.048047 lr = 0.0000735\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][1360/9765] Loss_D: 0.1064 Loss_G: 0.0450 Convergence: 0.1102 k= 0.048033 lr = 0.0000735\n",
      "[2/25][1370/9765] Loss_D: 0.1107 Loss_G: 0.0500 Convergence: 0.1176 k= 0.048036 lr = 0.0000735\n",
      "[2/25][1380/9765] Loss_D: 0.1142 Loss_G: 0.0481 Convergence: 0.1180 k= 0.047979 lr = 0.0000735\n",
      "[2/25][1390/9765] Loss_D: 0.1170 Loss_G: 0.0469 Convergence: 0.1203 k= 0.047956 lr = 0.0000735\n",
      "[2/25][1400/9765] Loss_D: 0.1069 Loss_G: 0.0490 Convergence: 0.1144 k= 0.047946 lr = 0.0000735\n",
      "[2/25][1410/9765] Loss_D: 0.1086 Loss_G: 0.0453 Convergence: 0.1118 k= 0.047936 lr = 0.0000735\n",
      "[2/25][1420/9765] Loss_D: 0.1158 Loss_G: 0.0428 Convergence: 0.1223 k= 0.047945 lr = 0.0000735\n",
      "[2/25][1430/9765] Loss_D: 0.1087 Loss_G: 0.0458 Convergence: 0.1123 k= 0.047914 lr = 0.0000735\n",
      "[2/25][1440/9765] Loss_D: 0.1108 Loss_G: 0.0445 Convergence: 0.1136 k= 0.047921 lr = 0.0000735\n",
      "[2/25][1450/9765] Loss_D: 0.1125 Loss_G: 0.0443 Convergence: 0.1160 k= 0.047921 lr = 0.0000735\n",
      "[2/25][1460/9765] Loss_D: 0.1081 Loss_G: 0.0416 Convergence: 0.1126 k= 0.047929 lr = 0.0000735\n",
      "[2/25][1470/9765] Loss_D: 0.1059 Loss_G: 0.0573 Convergence: 0.1221 k= 0.047912 lr = 0.0000698\n",
      "[2/25][1480/9765] Loss_D: 0.1078 Loss_G: 0.0418 Convergence: 0.1118 k= 0.047883 lr = 0.0000698\n",
      "[2/25][1490/9765] Loss_D: 0.1229 Loss_G: 0.0438 Convergence: 0.1311 k= 0.047886 lr = 0.0000698\n",
      "[2/25][1500/9765] Loss_D: 0.1142 Loss_G: 0.0473 Convergence: 0.1170 k= 0.047870 lr = 0.0000698\n",
      "[2/25][1510/9765] Loss_D: 0.1072 Loss_G: 0.0448 Convergence: 0.1103 k= 0.047861 lr = 0.0000698\n",
      "[2/25][1520/9765] Loss_D: 0.1158 Loss_G: 0.0428 Convergence: 0.1225 k= 0.047838 lr = 0.0000698\n",
      "[2/25][1530/9765] Loss_D: 0.1042 Loss_G: 0.0435 Convergence: 0.1071 k= 0.047821 lr = 0.0000698\n",
      "[2/25][1540/9765] Loss_D: 0.1079 Loss_G: 0.0445 Convergence: 0.1106 k= 0.047825 lr = 0.0000698\n",
      "[2/25][1550/9765] Loss_D: 0.1071 Loss_G: 0.0439 Convergence: 0.1095 k= 0.047791 lr = 0.0000698\n",
      "[2/25][1560/9765] Loss_D: 0.0995 Loss_G: 0.0445 Convergence: 0.1054 k= 0.047810 lr = 0.0000698\n",
      "[2/25][1570/9765] Loss_D: 0.1014 Loss_G: 0.0482 Convergence: 0.1102 k= 0.047783 lr = 0.0000698\n",
      "[2/25][1580/9765] Loss_D: 0.1032 Loss_G: 0.0427 Convergence: 0.1060 k= 0.047754 lr = 0.0000698\n",
      "[2/25][1590/9765] Loss_D: 0.1034 Loss_G: 0.0402 Convergence: 0.1073 k= 0.047753 lr = 0.0000698\n",
      "[2/25][1600/9765] Loss_D: 0.1168 Loss_G: 0.0492 Convergence: 0.1209 k= 0.047722 lr = 0.0000698\n",
      "[2/25][1610/9765] Loss_D: 0.1196 Loss_G: 0.0451 Convergence: 0.1255 k= 0.047722 lr = 0.0000698\n",
      "[2/25][1620/9765] Loss_D: 0.1122 Loss_G: 0.0506 Convergence: 0.1193 k= 0.047707 lr = 0.0000698\n",
      "[2/25][1630/9765] Loss_D: 0.1078 Loss_G: 0.0493 Convergence: 0.1153 k= 0.047704 lr = 0.0000698\n",
      "[2/25][1640/9765] Loss_D: 0.1073 Loss_G: 0.0458 Convergence: 0.1118 k= 0.047688 lr = 0.0000698\n",
      "[2/25][1650/9765] Loss_D: 0.1062 Loss_G: 0.0523 Convergence: 0.1171 k= 0.047673 lr = 0.0000698\n",
      "[2/25][1660/9765] Loss_D: 0.1023 Loss_G: 0.0428 Convergence: 0.1055 k= 0.047670 lr = 0.0000698\n",
      "[2/25][1670/9765] Loss_D: 0.1017 Loss_G: 0.0412 Convergence: 0.1044 k= 0.047661 lr = 0.0000698\n",
      "[2/25][1680/9765] Loss_D: 0.1039 Loss_G: 0.0431 Convergence: 0.1068 k= 0.047626 lr = 0.0000698\n",
      "[2/25][1690/9765] Loss_D: 0.1138 Loss_G: 0.0437 Convergence: 0.1186 k= 0.047611 lr = 0.0000698\n",
      "[2/25][1700/9765] Loss_D: 0.1093 Loss_G: 0.0470 Convergence: 0.1138 k= 0.047579 lr = 0.0000698\n",
      "[2/25][1710/9765] Loss_D: 0.1090 Loss_G: 0.0430 Convergence: 0.1125 k= 0.047580 lr = 0.0000698\n",
      "[2/25][1720/9765] Loss_D: 0.1042 Loss_G: 0.0437 Convergence: 0.1075 k= 0.047579 lr = 0.0000698\n",
      "[2/25][1730/9765] Loss_D: 0.1064 Loss_G: 0.0518 Convergence: 0.1170 k= 0.047529 lr = 0.0000698\n",
      "[2/25][1740/9765] Loss_D: 0.1101 Loss_G: 0.0411 Convergence: 0.1157 k= 0.047508 lr = 0.0000698\n",
      "[2/25][1750/9765] Loss_D: 0.1120 Loss_G: 0.0493 Convergence: 0.1177 k= 0.047512 lr = 0.0000698\n",
      "[2/25][1760/9765] Loss_D: 0.1109 Loss_G: 0.0450 Convergence: 0.1131 k= 0.047492 lr = 0.0000698\n",
      "[2/25][1770/9765] Loss_D: 0.1123 Loss_G: 0.0494 Convergence: 0.1180 k= 0.047494 lr = 0.0000698\n",
      "[2/25][1780/9765] Loss_D: 0.1096 Loss_G: 0.0462 Convergence: 0.1133 k= 0.047472 lr = 0.0000698\n",
      "[2/25][1790/9765] Loss_D: 0.1008 Loss_G: 0.0452 Convergence: 0.1069 k= 0.047496 lr = 0.0000698\n",
      "[2/25][1800/9765] Loss_D: 0.1086 Loss_G: 0.0440 Convergence: 0.1106 k= 0.047451 lr = 0.0000698\n",
      "[2/25][1810/9765] Loss_D: 0.1295 Loss_G: 0.0494 Convergence: 0.1346 k= 0.047449 lr = 0.0000698\n",
      "[2/25][1820/9765] Loss_D: 0.1040 Loss_G: 0.0459 Convergence: 0.1097 k= 0.047445 lr = 0.0000698\n",
      "[2/25][1830/9765] Loss_D: 0.1139 Loss_G: 0.0456 Convergence: 0.1168 k= 0.047450 lr = 0.0000698\n",
      "[2/25][1840/9765] Loss_D: 0.1127 Loss_G: 0.0468 Convergence: 0.1157 k= 0.047440 lr = 0.0000698\n",
      "[2/25][1850/9765] Loss_D: 0.1045 Loss_G: 0.0437 Convergence: 0.1077 k= 0.047421 lr = 0.0000698\n",
      "[2/25][1860/9765] Loss_D: 0.1047 Loss_G: 0.0457 Convergence: 0.1099 k= 0.047425 lr = 0.0000698\n",
      "[2/25][1870/9765] Loss_D: 0.1099 Loss_G: 0.0475 Convergence: 0.1147 k= 0.047409 lr = 0.0000698\n",
      "[2/25][1880/9765] Loss_D: 0.1112 Loss_G: 0.0432 Convergence: 0.1152 k= 0.047400 lr = 0.0000698\n",
      "[2/25][1890/9765] Loss_D: 0.1067 Loss_G: 0.0490 Convergence: 0.1145 k= 0.047360 lr = 0.0000698\n",
      "[2/25][1900/9765] Loss_D: 0.1101 Loss_G: 0.0413 Convergence: 0.1160 k= 0.047340 lr = 0.0000698\n",
      "[2/25][1910/9765] Loss_D: 0.1198 Loss_G: 0.0473 Convergence: 0.1235 k= 0.047327 lr = 0.0000698\n",
      "[2/25][1920/9765] Loss_D: 0.1102 Loss_G: 0.0476 Convergence: 0.1151 k= 0.047298 lr = 0.0000698\n",
      "[2/25][1930/9765] Loss_D: 0.1059 Loss_G: 0.0470 Convergence: 0.1116 k= 0.047301 lr = 0.0000698\n",
      "[2/25][1940/9765] Loss_D: 0.1307 Loss_G: 0.0459 Convergence: 0.1398 k= 0.047307 lr = 0.0000698\n",
      "[2/25][1950/9765] Loss_D: 0.1129 Loss_G: 0.0475 Convergence: 0.1166 k= 0.047261 lr = 0.0000698\n",
      "[2/25][1960/9765] Loss_D: 0.1067 Loss_G: 0.0477 Convergence: 0.1129 k= 0.047234 lr = 0.0000698\n",
      "[2/25][1970/9765] Loss_D: 0.1098 Loss_G: 0.0492 Convergence: 0.1162 k= 0.047234 lr = 0.0000698\n",
      "[2/25][1980/9765] Loss_D: 0.1079 Loss_G: 0.0445 Convergence: 0.1104 k= 0.047218 lr = 0.0000698\n",
      "[2/25][1990/9765] Loss_D: 0.1138 Loss_G: 0.0476 Convergence: 0.1171 k= 0.047213 lr = 0.0000698\n",
      "[2/25][2000/9765] Loss_D: 0.1118 Loss_G: 0.0558 Convergence: 0.1240 k= 0.047193 lr = 0.0000698\n",
      "[2/25][2010/9765] Loss_D: 0.1065 Loss_G: 0.0466 Convergence: 0.1118 k= 0.047140 lr = 0.0000698\n",
      "[2/25][2020/9765] Loss_D: 0.1075 Loss_G: 0.0513 Convergence: 0.1170 k= 0.047127 lr = 0.0000698\n",
      "[2/25][2030/9765] Loss_D: 0.1091 Loss_G: 0.0441 Convergence: 0.1116 k= 0.047124 lr = 0.0000698\n",
      "[2/25][2040/9765] Loss_D: 0.1087 Loss_G: 0.0513 Convergence: 0.1177 k= 0.047104 lr = 0.0000698\n",
      "[2/25][2050/9765] Loss_D: 0.1073 Loss_G: 0.0507 Convergence: 0.1163 k= 0.047079 lr = 0.0000698\n",
      "[2/25][2060/9765] Loss_D: 0.1051 Loss_G: 0.0476 Convergence: 0.1118 k= 0.047059 lr = 0.0000698\n",
      "[2/25][2070/9765] Loss_D: 0.1053 Loss_G: 0.0555 Convergence: 0.1199 k= 0.047013 lr = 0.0000698\n",
      "[2/25][2080/9765] Loss_D: 0.0943 Loss_G: 0.0554 Convergence: 0.1132 k= 0.046983 lr = 0.0000698\n",
      "[2/25][2090/9765] Loss_D: 0.1089 Loss_G: 0.0466 Convergence: 0.1130 k= 0.046974 lr = 0.0000698\n",
      "[2/25][2100/9765] Loss_D: 0.1061 Loss_G: 0.0502 Convergence: 0.1150 k= 0.046969 lr = 0.0000698\n",
      "[2/25][2110/9765] Loss_D: 0.1072 Loss_G: 0.0408 Convergence: 0.1120 k= 0.046952 lr = 0.0000698\n",
      "[2/25][2120/9765] Loss_D: 0.1128 Loss_G: 0.0431 Convergence: 0.1177 k= 0.046961 lr = 0.0000698\n",
      "[2/25][2130/9765] Loss_D: 0.1021 Loss_G: 0.0446 Convergence: 0.1071 k= 0.046954 lr = 0.0000698\n",
      "[2/25][2140/9765] Loss_D: 0.1082 Loss_G: 0.0511 Convergence: 0.1176 k= 0.046916 lr = 0.0000698\n",
      "[2/25][2150/9765] Loss_D: 0.1113 Loss_G: 0.0473 Convergence: 0.1153 k= 0.046888 lr = 0.0000698\n",
      "[2/25][2160/9765] Loss_D: 0.1094 Loss_G: 0.0558 Convergence: 0.1226 k= 0.046874 lr = 0.0000698\n",
      "[2/25][2170/9765] Loss_D: 0.1073 Loss_G: 0.0455 Convergence: 0.1110 k= 0.046849 lr = 0.0000698\n",
      "[2/25][2180/9765] Loss_D: 0.1063 Loss_G: 0.0486 Convergence: 0.1137 k= 0.046835 lr = 0.0000698\n",
      "[2/25][2190/9765] Loss_D: 0.1162 Loss_G: 0.0476 Convergence: 0.1187 k= 0.046773 lr = 0.0000698\n",
      "[2/25][2200/9765] Loss_D: 0.1044 Loss_G: 0.0416 Convergence: 0.1073 k= 0.046778 lr = 0.0000698\n",
      "[2/25][2210/9765] Loss_D: 0.1065 Loss_G: 0.0427 Convergence: 0.1094 k= 0.046790 lr = 0.0000698\n",
      "[2/25][2220/9765] Loss_D: 0.0981 Loss_G: 0.0448 Convergence: 0.1049 k= 0.046750 lr = 0.0000698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][2230/9765] Loss_D: 0.1177 Loss_G: 0.0491 Convergence: 0.1210 k= 0.046754 lr = 0.0000698\n",
      "[2/25][2240/9765] Loss_D: 0.1023 Loss_G: 0.0403 Convergence: 0.1062 k= 0.046736 lr = 0.0000698\n",
      "[2/25][2250/9765] Loss_D: 0.1073 Loss_G: 0.0421 Convergence: 0.1108 k= 0.046769 lr = 0.0000698\n",
      "[2/25][2260/9765] Loss_D: 0.1014 Loss_G: 0.0418 Convergence: 0.1039 k= 0.046776 lr = 0.0000698\n",
      "[2/25][2270/9765] Loss_D: 0.1060 Loss_G: 0.0396 Convergence: 0.1122 k= 0.046766 lr = 0.0000698\n",
      "[2/25][2280/9765] Loss_D: 0.1163 Loss_G: 0.0398 Convergence: 0.1257 k= 0.046791 lr = 0.0000698\n",
      "[2/25][2290/9765] Loss_D: 0.1121 Loss_G: 0.0436 Convergence: 0.1161 k= 0.046794 lr = 0.0000698\n",
      "[2/25][2300/9765] Loss_D: 0.1188 Loss_G: 0.0460 Convergence: 0.1232 k= 0.046796 lr = 0.0000698\n",
      "[2/25][2310/9765] Loss_D: 0.1089 Loss_G: 0.0459 Convergence: 0.1126 k= 0.046791 lr = 0.0000698\n",
      "[2/25][2320/9765] Loss_D: 0.1083 Loss_G: 0.0426 Convergence: 0.1120 k= 0.046758 lr = 0.0000698\n",
      "[2/25][2330/9765] Loss_D: 0.1117 Loss_G: 0.0419 Convergence: 0.1170 k= 0.046778 lr = 0.0000698\n",
      "[2/25][2340/9765] Loss_D: 0.1117 Loss_G: 0.0469 Convergence: 0.1152 k= 0.046728 lr = 0.0000698\n",
      "[2/25][2350/9765] Loss_D: 0.1084 Loss_G: 0.0471 Convergence: 0.1132 k= 0.046738 lr = 0.0000698\n",
      "[2/25][2360/9765] Loss_D: 0.1141 Loss_G: 0.0456 Convergence: 0.1178 k= 0.046711 lr = 0.0000698\n",
      "[2/25][2370/9765] Loss_D: 0.1044 Loss_G: 0.0558 Convergence: 0.1199 k= 0.046659 lr = 0.0000698\n",
      "[2/25][2380/9765] Loss_D: 0.1102 Loss_G: 0.0438 Convergence: 0.1131 k= 0.046655 lr = 0.0000698\n",
      "[2/25][2390/9765] Loss_D: 0.1192 Loss_G: 0.0435 Convergence: 0.1260 k= 0.046647 lr = 0.0000698\n",
      "[2/25][2400/9765] Loss_D: 0.1081 Loss_G: 0.0431 Convergence: 0.1112 k= 0.046664 lr = 0.0000698\n",
      "[2/25][2410/9765] Loss_D: 0.1141 Loss_G: 0.0520 Convergence: 0.1217 k= 0.046629 lr = 0.0000698\n",
      "[2/25][2420/9765] Loss_D: 0.1095 Loss_G: 0.0477 Convergence: 0.1146 k= 0.046605 lr = 0.0000698\n",
      "[2/25][2430/9765] Loss_D: 0.1048 Loss_G: 0.0402 Convergence: 0.1089 k= 0.046584 lr = 0.0000698\n",
      "[2/25][2440/9765] Loss_D: 0.1013 Loss_G: 0.0529 Convergence: 0.1149 k= 0.046545 lr = 0.0000698\n",
      "[2/25][2450/9765] Loss_D: 0.1057 Loss_G: 0.0487 Convergence: 0.1134 k= 0.046526 lr = 0.0000698\n",
      "[2/25][2460/9765] Loss_D: 0.1171 Loss_G: 0.0564 Convergence: 0.1279 k= 0.046507 lr = 0.0000698\n",
      "[2/25][2470/9765] Loss_D: 0.1038 Loss_G: 0.0441 Convergence: 0.1076 k= 0.046489 lr = 0.0000698\n",
      "[2/25][2480/9765] Loss_D: 0.1247 Loss_G: 0.0483 Convergence: 0.1291 k= 0.046491 lr = 0.0000698\n",
      "[2/25][2490/9765] Loss_D: 0.1076 Loss_G: 0.0456 Convergence: 0.1114 k= 0.046487 lr = 0.0000698\n",
      "[2/25][2500/9765] Loss_D: 0.0970 Loss_G: 0.0441 Convergence: 0.1034 k= 0.046466 lr = 0.0000698\n",
      "[2/25][2510/9765] Loss_D: 0.1120 Loss_G: 0.0434 Convergence: 0.1160 k= 0.046466 lr = 0.0000698\n",
      "[2/25][2520/9765] Loss_D: 0.1039 Loss_G: 0.0427 Convergence: 0.1061 k= 0.046461 lr = 0.0000698\n",
      "[2/25][2530/9765] Loss_D: 0.1116 Loss_G: 0.0459 Convergence: 0.1139 k= 0.046452 lr = 0.0000698\n",
      "[2/25][2540/9765] Loss_D: 0.1100 Loss_G: 0.0522 Convergence: 0.1195 k= 0.046425 lr = 0.0000698\n",
      "[2/25][2550/9765] Loss_D: 0.1161 Loss_G: 0.0457 Convergence: 0.1197 k= 0.046398 lr = 0.0000698\n",
      "[2/25][2560/9765] Loss_D: 0.1172 Loss_G: 0.0453 Convergence: 0.1218 k= 0.046394 lr = 0.0000698\n",
      "[2/25][2570/9765] Loss_D: 0.1036 Loss_G: 0.0479 Convergence: 0.1113 k= 0.046372 lr = 0.0000698\n",
      "[2/25][2580/9765] Loss_D: 0.1053 Loss_G: 0.0410 Convergence: 0.1091 k= 0.046361 lr = 0.0000698\n",
      "[2/25][2590/9765] Loss_D: 0.1132 Loss_G: 0.0459 Convergence: 0.1154 k= 0.046357 lr = 0.0000698\n",
      "[2/25][2600/9765] Loss_D: 0.1145 Loss_G: 0.0465 Convergence: 0.1168 k= 0.046335 lr = 0.0000698\n",
      "[2/25][2610/9765] Loss_D: 0.1058 Loss_G: 0.0442 Convergence: 0.1089 k= 0.046281 lr = 0.0000698\n",
      "[2/25][2620/9765] Loss_D: 0.1234 Loss_G: 0.0405 Convergence: 0.1351 k= 0.046281 lr = 0.0000698\n",
      "[2/25][2630/9765] Loss_D: 0.1113 Loss_G: 0.0444 Convergence: 0.1143 k= 0.046270 lr = 0.0000698\n",
      "[2/25][2640/9765] Loss_D: 0.1040 Loss_G: 0.0586 Convergence: 0.1224 k= 0.046210 lr = 0.0000698\n",
      "[2/25][2650/9765] Loss_D: 0.1159 Loss_G: 0.0495 Convergence: 0.1202 k= 0.046201 lr = 0.0000698\n",
      "[2/25][2660/9765] Loss_D: 0.1159 Loss_G: 0.0441 Convergence: 0.1205 k= 0.046185 lr = 0.0000698\n",
      "[2/25][2670/9765] Loss_D: 0.1025 Loss_G: 0.0441 Convergence: 0.1069 k= 0.046190 lr = 0.0000698\n",
      "[2/25][2680/9765] Loss_D: 0.1048 Loss_G: 0.0443 Convergence: 0.1083 k= 0.046196 lr = 0.0000698\n",
      "[2/25][2690/9765] Loss_D: 0.1078 Loss_G: 0.0429 Convergence: 0.1109 k= 0.046187 lr = 0.0000698\n",
      "[2/25][2700/9765] Loss_D: 0.1175 Loss_G: 0.0440 Convergence: 0.1235 k= 0.046186 lr = 0.0000698\n",
      "[2/25][2710/9765] Loss_D: 0.1060 Loss_G: 0.0440 Convergence: 0.1089 k= 0.046178 lr = 0.0000698\n",
      "[2/25][2720/9765] Loss_D: 0.1045 Loss_G: 0.0425 Convergence: 0.1066 k= 0.046142 lr = 0.0000698\n",
      "[2/25][2730/9765] Loss_D: 0.1085 Loss_G: 0.0432 Convergence: 0.1116 k= 0.046138 lr = 0.0000698\n",
      "[2/25][2740/9765] Loss_D: 0.1085 Loss_G: 0.0404 Convergence: 0.1143 k= 0.046144 lr = 0.0000698\n",
      "[2/25][2750/9765] Loss_D: 0.1073 Loss_G: 0.0447 Convergence: 0.1105 k= 0.046143 lr = 0.0000698\n",
      "[2/25][2760/9765] Loss_D: 0.1124 Loss_G: 0.0441 Convergence: 0.1164 k= 0.046125 lr = 0.0000698\n",
      "[2/25][2770/9765] Loss_D: 0.1040 Loss_G: 0.0427 Convergence: 0.1064 k= 0.046114 lr = 0.0000698\n",
      "[2/25][2780/9765] Loss_D: 0.1099 Loss_G: 0.0464 Convergence: 0.1137 k= 0.046090 lr = 0.0000698\n",
      "[2/25][2790/9765] Loss_D: 0.1215 Loss_G: 0.0465 Convergence: 0.1270 k= 0.046079 lr = 0.0000698\n",
      "[2/25][2800/9765] Loss_D: 0.1123 Loss_G: 0.0471 Convergence: 0.1157 k= 0.046046 lr = 0.0000698\n",
      "[2/25][2810/9765] Loss_D: 0.1151 Loss_G: 0.0417 Convergence: 0.1221 k= 0.046072 lr = 0.0000698\n",
      "[2/25][2820/9765] Loss_D: 0.1028 Loss_G: 0.0434 Convergence: 0.1062 k= 0.046033 lr = 0.0000698\n",
      "[2/25][2830/9765] Loss_D: 0.1047 Loss_G: 0.0407 Convergence: 0.1086 k= 0.046029 lr = 0.0000698\n",
      "[2/25][2840/9765] Loss_D: 0.1173 Loss_G: 0.0418 Convergence: 0.1252 k= 0.046024 lr = 0.0000698\n",
      "[2/25][2850/9765] Loss_D: 0.1090 Loss_G: 0.0440 Convergence: 0.1112 k= 0.046023 lr = 0.0000698\n",
      "[2/25][2860/9765] Loss_D: 0.1140 Loss_G: 0.0436 Convergence: 0.1189 k= 0.046025 lr = 0.0000698\n",
      "[2/25][2870/9765] Loss_D: 0.1124 Loss_G: 0.0518 Convergence: 0.1206 k= 0.045986 lr = 0.0000698\n",
      "[2/25][2880/9765] Loss_D: 0.1209 Loss_G: 0.0402 Convergence: 0.1317 k= 0.045962 lr = 0.0000698\n",
      "[2/25][2890/9765] Loss_D: 0.1130 Loss_G: 0.0494 Convergence: 0.1185 k= 0.045951 lr = 0.0000698\n",
      "[2/25][2900/9765] Loss_D: 0.1068 Loss_G: 0.0426 Convergence: 0.1098 k= 0.045948 lr = 0.0000698\n",
      "[2/25][2910/9765] Loss_D: 0.1110 Loss_G: 0.0451 Convergence: 0.1132 k= 0.045952 lr = 0.0000698\n",
      "[2/25][2920/9765] Loss_D: 0.1122 Loss_G: 0.0458 Convergence: 0.1144 k= 0.045920 lr = 0.0000698\n",
      "[2/25][2930/9765] Loss_D: 0.1072 Loss_G: 0.0392 Convergence: 0.1135 k= 0.045932 lr = 0.0000698\n",
      "[2/25][2940/9765] Loss_D: 0.1054 Loss_G: 0.0435 Convergence: 0.1080 k= 0.045920 lr = 0.0000698\n",
      "[2/25][2950/9765] Loss_D: 0.1113 Loss_G: 0.0454 Convergence: 0.1134 k= 0.045902 lr = 0.0000698\n",
      "[2/25][2960/9765] Loss_D: 0.1032 Loss_G: 0.0500 Convergence: 0.1132 k= 0.045886 lr = 0.0000698\n",
      "[2/25][2970/9765] Loss_D: 0.1110 Loss_G: 0.0458 Convergence: 0.1136 k= 0.045863 lr = 0.0000698\n",
      "[2/25][2980/9765] Loss_D: 0.1096 Loss_G: 0.0470 Convergence: 0.1139 k= 0.045870 lr = 0.0000698\n",
      "[2/25][2990/9765] Loss_D: 0.1120 Loss_G: 0.0460 Convergence: 0.1144 k= 0.045868 lr = 0.0000698\n",
      "[2/25][3000/9765] Loss_D: 0.1054 Loss_G: 0.0479 Convergence: 0.1123 k= 0.045858 lr = 0.0000698\n",
      "[2/25][3010/9765] Loss_D: 0.1087 Loss_G: 0.0458 Convergence: 0.1122 k= 0.045863 lr = 0.0000698\n",
      "[2/25][3020/9765] Loss_D: 0.1242 Loss_G: 0.0531 Convergence: 0.1289 k= 0.045854 lr = 0.0000698\n",
      "[2/25][3030/9765] Loss_D: 0.1050 Loss_G: 0.0497 Convergence: 0.1139 k= 0.045818 lr = 0.0000698\n",
      "[2/25][3040/9765] Loss_D: 0.0982 Loss_G: 0.0477 Convergence: 0.1079 k= 0.045762 lr = 0.0000698\n",
      "[2/25][3050/9765] Loss_D: 0.1016 Loss_G: 0.0449 Convergence: 0.1070 k= 0.045751 lr = 0.0000698\n",
      "[2/25][3060/9765] Loss_D: 0.1056 Loss_G: 0.0495 Convergence: 0.1142 k= 0.045736 lr = 0.0000698\n",
      "[2/25][3070/9765] Loss_D: 0.1098 Loss_G: 0.0474 Convergence: 0.1145 k= 0.045698 lr = 0.0000698\n",
      "[2/25][3080/9765] Loss_D: 0.1073 Loss_G: 0.0530 Convergence: 0.1186 k= 0.045685 lr = 0.0000698\n",
      "[2/25][3090/9765] Loss_D: 0.1062 Loss_G: 0.0418 Convergence: 0.1097 k= 0.045662 lr = 0.0000698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][3100/9765] Loss_D: 0.1063 Loss_G: 0.0444 Convergence: 0.1093 k= 0.045677 lr = 0.0000698\n",
      "[2/25][3110/9765] Loss_D: 0.1045 Loss_G: 0.0454 Convergence: 0.1094 k= 0.045648 lr = 0.0000698\n",
      "[2/25][3120/9765] Loss_D: 0.0997 Loss_G: 0.0424 Convergence: 0.1035 k= 0.045615 lr = 0.0000698\n",
      "[2/25][3130/9765] Loss_D: 0.1076 Loss_G: 0.0478 Convergence: 0.1137 k= 0.045637 lr = 0.0000698\n",
      "[2/25][3140/9765] Loss_D: 0.1036 Loss_G: 0.0450 Convergence: 0.1085 k= 0.045563 lr = 0.0000698\n",
      "[2/25][3150/9765] Loss_D: 0.1014 Loss_G: 0.0441 Convergence: 0.1061 k= 0.045571 lr = 0.0000698\n",
      "[2/25][3160/9765] Loss_D: 0.1020 Loss_G: 0.0467 Convergence: 0.1091 k= 0.045559 lr = 0.0000698\n",
      "[2/25][3170/9765] Loss_D: 0.1095 Loss_G: 0.0556 Convergence: 0.1224 k= 0.045539 lr = 0.0000698\n",
      "[2/25][3180/9765] Loss_D: 0.1110 Loss_G: 0.0473 Convergence: 0.1151 k= 0.045527 lr = 0.0000698\n",
      "[2/25][3190/9765] Loss_D: 0.1017 Loss_G: 0.0462 Convergence: 0.1085 k= 0.045537 lr = 0.0000698\n",
      "[2/25][3200/9765] Loss_D: 0.1072 Loss_G: 0.0413 Convergence: 0.1121 k= 0.045514 lr = 0.0000698\n",
      "[2/25][3210/9765] Loss_D: 0.1117 Loss_G: 0.0468 Convergence: 0.1152 k= 0.045498 lr = 0.0000698\n",
      "[2/25][3220/9765] Loss_D: 0.1071 Loss_G: 0.0479 Convergence: 0.1133 k= 0.045493 lr = 0.0000698\n",
      "[2/25][3230/9765] Loss_D: 0.1018 Loss_G: 0.0425 Convergence: 0.1047 k= 0.045480 lr = 0.0000698\n",
      "[2/25][3240/9765] Loss_D: 0.1097 Loss_G: 0.0448 Convergence: 0.1118 k= 0.045488 lr = 0.0000698\n",
      "[2/25][3250/9765] Loss_D: 0.1035 Loss_G: 0.0423 Convergence: 0.1055 k= 0.045494 lr = 0.0000698\n",
      "[2/25][3260/9765] Loss_D: 0.1094 Loss_G: 0.0505 Convergence: 0.1173 k= 0.045435 lr = 0.0000698\n",
      "[2/25][3270/9765] Loss_D: 0.1001 Loss_G: 0.0431 Convergence: 0.1043 k= 0.045413 lr = 0.0000698\n",
      "[2/25][3280/9765] Loss_D: 0.1017 Loss_G: 0.0461 Convergence: 0.1083 k= 0.045401 lr = 0.0000698\n",
      "[2/25][3290/9765] Loss_D: 0.0985 Loss_G: 0.0455 Convergence: 0.1058 k= 0.045350 lr = 0.0000698\n",
      "[2/25][3300/9765] Loss_D: 0.1216 Loss_G: 0.0529 Convergence: 0.1271 k= 0.045337 lr = 0.0000698\n",
      "[2/25][3310/9765] Loss_D: 0.1111 Loss_G: 0.0435 Convergence: 0.1146 k= 0.045319 lr = 0.0000698\n",
      "[2/25][3320/9765] Loss_D: 0.1156 Loss_G: 0.0461 Convergence: 0.1187 k= 0.045297 lr = 0.0000698\n",
      "[2/25][3330/9765] Loss_D: 0.1095 Loss_G: 0.0446 Convergence: 0.1114 k= 0.045303 lr = 0.0000698\n",
      "[2/25][3340/9765] Loss_D: 0.1101 Loss_G: 0.0437 Convergence: 0.1136 k= 0.045310 lr = 0.0000698\n",
      "[2/25][3350/9765] Loss_D: 0.1043 Loss_G: 0.0463 Convergence: 0.1100 k= 0.045305 lr = 0.0000698\n",
      "[2/25][3360/9765] Loss_D: 0.1081 Loss_G: 0.0398 Convergence: 0.1142 k= 0.045288 lr = 0.0000698\n",
      "[2/25][3370/9765] Loss_D: 0.1056 Loss_G: 0.0431 Convergence: 0.1077 k= 0.045264 lr = 0.0000698\n",
      "[2/25][3380/9765] Loss_D: 0.1071 Loss_G: 0.0470 Convergence: 0.1124 k= 0.045240 lr = 0.0000698\n",
      "[2/25][3390/9765] Loss_D: 0.1068 Loss_G: 0.0479 Convergence: 0.1131 k= 0.045255 lr = 0.0000698\n",
      "[2/25][3400/9765] Loss_D: 0.1103 Loss_G: 0.0484 Convergence: 0.1158 k= 0.045209 lr = 0.0000698\n",
      "[2/25][3410/9765] Loss_D: 0.1077 Loss_G: 0.0447 Convergence: 0.1104 k= 0.045230 lr = 0.0000698\n",
      "[2/25][3420/9765] Loss_D: 0.1132 Loss_G: 0.0506 Convergence: 0.1200 k= 0.045179 lr = 0.0000698\n",
      "[2/25][3430/9765] Loss_D: 0.0989 Loss_G: 0.0452 Convergence: 0.1056 k= 0.045189 lr = 0.0000698\n",
      "[2/25][3440/9765] Loss_D: 0.1025 Loss_G: 0.0460 Convergence: 0.1088 k= 0.045144 lr = 0.0000698\n",
      "[2/25][3450/9765] Loss_D: 0.1105 Loss_G: 0.0437 Convergence: 0.1138 k= 0.045149 lr = 0.0000698\n",
      "[2/25][3460/9765] Loss_D: 0.1075 Loss_G: 0.0416 Convergence: 0.1116 k= 0.045159 lr = 0.0000698\n",
      "[2/25][3470/9765] Loss_D: 0.1030 Loss_G: 0.0462 Convergence: 0.1092 k= 0.045129 lr = 0.0000698\n",
      "[2/25][3480/9765] Loss_D: 0.1084 Loss_G: 0.0540 Convergence: 0.1202 k= 0.045105 lr = 0.0000698\n",
      "[2/25][3490/9765] Loss_D: 0.1164 Loss_G: 0.0462 Convergence: 0.1195 k= 0.045090 lr = 0.0000698\n",
      "[2/25][3500/9765] Loss_D: 0.1078 Loss_G: 0.0481 Convergence: 0.1140 k= 0.045091 lr = 0.0000698\n",
      "[2/25][3510/9765] Loss_D: 0.1092 Loss_G: 0.0489 Convergence: 0.1156 k= 0.045071 lr = 0.0000698\n",
      "[2/25][3520/9765] Loss_D: 0.1090 Loss_G: 0.0396 Convergence: 0.1156 k= 0.045074 lr = 0.0000698\n",
      "[2/25][3530/9765] Loss_D: 0.0945 Loss_G: 0.0380 Convergence: 0.0968 k= 0.045073 lr = 0.0000698\n",
      "[2/25][3540/9765] Loss_D: 0.1024 Loss_G: 0.0488 Convergence: 0.1116 k= 0.045078 lr = 0.0000698\n",
      "[2/25][3550/9765] Loss_D: 0.1101 Loss_G: 0.0417 Convergence: 0.1150 k= 0.045043 lr = 0.0000698\n",
      "[2/25][3560/9765] Loss_D: 0.1181 Loss_G: 0.0500 Convergence: 0.1221 k= 0.045058 lr = 0.0000698\n",
      "[2/25][3570/9765] Loss_D: 0.1193 Loss_G: 0.0420 Convergence: 0.1275 k= 0.045065 lr = 0.0000698\n",
      "[2/25][3580/9765] Loss_D: 0.1013 Loss_G: 0.0398 Convergence: 0.1047 k= 0.045054 lr = 0.0000698\n",
      "[2/25][3590/9765] Loss_D: 0.1116 Loss_G: 0.0419 Convergence: 0.1171 k= 0.045064 lr = 0.0000698\n",
      "[2/25][3600/9765] Loss_D: 0.1140 Loss_G: 0.0455 Convergence: 0.1170 k= 0.045054 lr = 0.0000698\n",
      "[2/25][3610/9765] Loss_D: 0.1172 Loss_G: 0.0451 Convergence: 0.1217 k= 0.045036 lr = 0.0000698\n",
      "[2/25][3620/9765] Loss_D: 0.1107 Loss_G: 0.0481 Convergence: 0.1157 k= 0.045028 lr = 0.0000698\n",
      "[2/25][3630/9765] Loss_D: 0.1186 Loss_G: 0.0445 Convergence: 0.1247 k= 0.045019 lr = 0.0000698\n",
      "[2/25][3640/9765] Loss_D: 0.1052 Loss_G: 0.0471 Convergence: 0.1115 k= 0.044991 lr = 0.0000698\n",
      "[2/25][3650/9765] Loss_D: 0.1071 Loss_G: 0.0431 Convergence: 0.1092 k= 0.044999 lr = 0.0000698\n",
      "[2/25][3660/9765] Loss_D: 0.1010 Loss_G: 0.0499 Convergence: 0.1119 k= 0.044960 lr = 0.0000698\n",
      "[2/25][3670/9765] Loss_D: 0.1063 Loss_G: 0.0445 Convergence: 0.1094 k= 0.044943 lr = 0.0000698\n",
      "[2/25][3680/9765] Loss_D: 0.1072 Loss_G: 0.0467 Convergence: 0.1123 k= 0.044952 lr = 0.0000698\n",
      "[2/25][3690/9765] Loss_D: 0.1120 Loss_G: 0.0451 Convergence: 0.1148 k= 0.044908 lr = 0.0000698\n",
      "[2/25][3700/9765] Loss_D: 0.1087 Loss_G: 0.0413 Convergence: 0.1133 k= 0.044912 lr = 0.0000698\n",
      "[2/25][3710/9765] Loss_D: 0.1140 Loss_G: 0.0427 Convergence: 0.1199 k= 0.044907 lr = 0.0000698\n",
      "[2/25][3720/9765] Loss_D: 0.1062 Loss_G: 0.0403 Convergence: 0.1113 k= 0.044895 lr = 0.0000698\n",
      "[2/25][3730/9765] Loss_D: 0.1058 Loss_G: 0.0481 Convergence: 0.1127 k= 0.044886 lr = 0.0000698\n",
      "[2/25][3740/9765] Loss_D: 0.1075 Loss_G: 0.0440 Convergence: 0.1096 k= 0.044879 lr = 0.0000698\n",
      "[2/25][3750/9765] Loss_D: 0.1165 Loss_G: 0.0413 Convergence: 0.1244 k= 0.044876 lr = 0.0000698\n",
      "[2/25][3760/9765] Loss_D: 0.1046 Loss_G: 0.0438 Convergence: 0.1077 k= 0.044872 lr = 0.0000698\n",
      "[2/25][3770/9765] Loss_D: 0.1059 Loss_G: 0.0448 Convergence: 0.1097 k= 0.044833 lr = 0.0000698\n",
      "[2/25][3780/9765] Loss_D: 0.1109 Loss_G: 0.0426 Convergence: 0.1151 k= 0.044814 lr = 0.0000698\n",
      "[2/25][3790/9765] Loss_D: 0.1061 Loss_G: 0.0418 Convergence: 0.1093 k= 0.044827 lr = 0.0000698\n",
      "[2/25][3800/9765] Loss_D: 0.1015 Loss_G: 0.0507 Convergence: 0.1128 k= 0.044794 lr = 0.0000698\n",
      "[2/25][3810/9765] Loss_D: 0.1016 Loss_G: 0.0405 Convergence: 0.1043 k= 0.044773 lr = 0.0000698\n",
      "[2/25][3820/9765] Loss_D: 0.1022 Loss_G: 0.0444 Convergence: 0.1070 k= 0.044749 lr = 0.0000698\n",
      "[2/25][3830/9765] Loss_D: 0.1167 Loss_G: 0.0481 Convergence: 0.1195 k= 0.044727 lr = 0.0000698\n",
      "[2/25][3840/9765] Loss_D: 0.1150 Loss_G: 0.0493 Convergence: 0.1195 k= 0.044734 lr = 0.0000698\n",
      "[2/25][3850/9765] Loss_D: 0.1048 Loss_G: 0.0461 Convergence: 0.1101 k= 0.044699 lr = 0.0000698\n",
      "[2/25][3860/9765] Loss_D: 0.1222 Loss_G: 0.0412 Convergence: 0.1324 k= 0.044717 lr = 0.0000698\n",
      "[2/25][3870/9765] Loss_D: 0.1164 Loss_G: 0.0493 Convergence: 0.1204 k= 0.044709 lr = 0.0000698\n",
      "[2/25][3880/9765] Loss_D: 0.0986 Loss_G: 0.0420 Convergence: 0.1024 k= 0.044704 lr = 0.0000698\n",
      "[2/25][3890/9765] Loss_D: 0.1032 Loss_G: 0.0525 Convergence: 0.1156 k= 0.044708 lr = 0.0000698\n",
      "[2/25][3900/9765] Loss_D: 0.1028 Loss_G: 0.0480 Convergence: 0.1108 k= 0.044661 lr = 0.0000698\n",
      "[2/25][3910/9765] Loss_D: 0.1108 Loss_G: 0.0452 Convergence: 0.1130 k= 0.044663 lr = 0.0000698\n",
      "[2/25][3920/9765] Loss_D: 0.1039 Loss_G: 0.0513 Convergence: 0.1149 k= 0.044623 lr = 0.0000698\n",
      "[2/25][3930/9765] Loss_D: 0.1162 Loss_G: 0.0467 Convergence: 0.1188 k= 0.044617 lr = 0.0000698\n",
      "[2/25][3940/9765] Loss_D: 0.1145 Loss_G: 0.0431 Convergence: 0.1198 k= 0.044616 lr = 0.0000698\n",
      "[2/25][3950/9765] Loss_D: 0.1122 Loss_G: 0.0489 Convergence: 0.1177 k= 0.044563 lr = 0.0000698\n",
      "[2/25][3960/9765] Loss_D: 0.1125 Loss_G: 0.0442 Convergence: 0.1160 k= 0.044555 lr = 0.0000698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][3970/9765] Loss_D: 0.1030 Loss_G: 0.0428 Convergence: 0.1058 k= 0.044544 lr = 0.0000698\n",
      "[2/25][3980/9765] Loss_D: 0.0973 Loss_G: 0.0406 Convergence: 0.1001 k= 0.044539 lr = 0.0000698\n",
      "[2/25][3990/9765] Loss_D: 0.1095 Loss_G: 0.0470 Convergence: 0.1139 k= 0.044541 lr = 0.0000698\n",
      "[2/25][4000/9765] Loss_D: 0.1132 Loss_G: 0.0421 Convergence: 0.1196 k= 0.044493 lr = 0.0000698\n",
      "[2/25][4010/9765] Loss_D: 0.1129 Loss_G: 0.0488 Convergence: 0.1176 k= 0.044491 lr = 0.0000698\n",
      "[2/25][4020/9765] Loss_D: 0.1079 Loss_G: 0.0514 Convergence: 0.1173 k= 0.044444 lr = 0.0000698\n",
      "[2/25][4030/9765] Loss_D: 0.1113 Loss_G: 0.0432 Convergence: 0.1153 k= 0.044430 lr = 0.0000698\n",
      "[2/25][4040/9765] Loss_D: 0.1075 Loss_G: 0.0470 Convergence: 0.1127 k= 0.044422 lr = 0.0000698\n",
      "[2/25][4050/9765] Loss_D: 0.0965 Loss_G: 0.0391 Convergence: 0.0985 k= 0.044446 lr = 0.0000698\n",
      "[2/25][4060/9765] Loss_D: 0.1046 Loss_G: 0.0509 Convergence: 0.1148 k= 0.044435 lr = 0.0000698\n",
      "[2/25][4070/9765] Loss_D: 0.1233 Loss_G: 0.0467 Convergence: 0.1288 k= 0.044432 lr = 0.0000698\n",
      "[2/25][4080/9765] Loss_D: 0.1092 Loss_G: 0.0464 Convergence: 0.1131 k= 0.044428 lr = 0.0000698\n",
      "[2/25][4090/9765] Loss_D: 0.1065 Loss_G: 0.0447 Convergence: 0.1098 k= 0.044418 lr = 0.0000698\n",
      "[2/25][4100/9765] Loss_D: 0.1020 Loss_G: 0.0420 Convergence: 0.1044 k= 0.044411 lr = 0.0000698\n",
      "[2/25][4110/9765] Loss_D: 0.1107 Loss_G: 0.0425 Convergence: 0.1154 k= 0.044389 lr = 0.0000698\n",
      "[2/25][4120/9765] Loss_D: 0.1140 Loss_G: 0.0408 Convergence: 0.1213 k= 0.044397 lr = 0.0000698\n",
      "[2/25][4130/9765] Loss_D: 0.1158 Loss_G: 0.0472 Convergence: 0.1180 k= 0.044384 lr = 0.0000698\n",
      "[2/25][4140/9765] Loss_D: 0.1036 Loss_G: 0.0459 Convergence: 0.1093 k= 0.044352 lr = 0.0000698\n",
      "[2/25][4150/9765] Loss_D: 0.1128 Loss_G: 0.0415 Convergence: 0.1189 k= 0.044351 lr = 0.0000698\n",
      "[2/25][4160/9765] Loss_D: 0.1200 Loss_G: 0.0497 Convergence: 0.1229 k= 0.044342 lr = 0.0000698\n",
      "[2/25][4170/9765] Loss_D: 0.1178 Loss_G: 0.0426 Convergence: 0.1249 k= 0.044362 lr = 0.0000698\n",
      "[2/25][4180/9765] Loss_D: 0.1106 Loss_G: 0.0430 Convergence: 0.1146 k= 0.044373 lr = 0.0000698\n",
      "[2/25][4190/9765] Loss_D: 0.0989 Loss_G: 0.0420 Convergence: 0.1024 k= 0.044372 lr = 0.0000698\n",
      "[2/25][4200/9765] Loss_D: 0.1061 Loss_G: 0.0452 Convergence: 0.1102 k= 0.044349 lr = 0.0000698\n",
      "[2/25][4210/9765] Loss_D: 0.1027 Loss_G: 0.0403 Convergence: 0.1061 k= 0.044329 lr = 0.0000698\n",
      "[2/25][4220/9765] Loss_D: 0.1145 Loss_G: 0.0455 Convergence: 0.1174 k= 0.044340 lr = 0.0000698\n",
      "[2/25][4230/9765] Loss_D: 0.1118 Loss_G: 0.0461 Convergence: 0.1143 k= 0.044336 lr = 0.0000698\n",
      "[2/25][4240/9765] Loss_D: 0.1116 Loss_G: 0.0444 Convergence: 0.1146 k= 0.044307 lr = 0.0000698\n",
      "[2/25][4250/9765] Loss_D: 0.1142 Loss_G: 0.0438 Convergence: 0.1193 k= 0.044277 lr = 0.0000698\n",
      "[2/25][4260/9765] Loss_D: 0.1132 Loss_G: 0.0461 Convergence: 0.1152 k= 0.044273 lr = 0.0000698\n",
      "[2/25][4270/9765] Loss_D: 0.1171 Loss_G: 0.0442 Convergence: 0.1226 k= 0.044267 lr = 0.0000698\n",
      "[2/25][4280/9765] Loss_D: 0.1058 Loss_G: 0.0482 Convergence: 0.1129 k= 0.044247 lr = 0.0000698\n",
      "[2/25][4290/9765] Loss_D: 0.1179 Loss_G: 0.0555 Convergence: 0.1273 k= 0.044220 lr = 0.0000698\n",
      "[2/25][4300/9765] Loss_D: 0.1113 Loss_G: 0.0553 Convergence: 0.1233 k= 0.044123 lr = 0.0000698\n",
      "[2/25][4310/9765] Loss_D: 0.1076 Loss_G: 0.0452 Convergence: 0.1109 k= 0.044136 lr = 0.0000698\n",
      "[2/25][4320/9765] Loss_D: 0.1061 Loss_G: 0.0494 Convergence: 0.1142 k= 0.044116 lr = 0.0000698\n",
      "[2/25][4330/9765] Loss_D: 0.1048 Loss_G: 0.0390 Convergence: 0.1101 k= 0.044118 lr = 0.0000698\n",
      "[2/25][4340/9765] Loss_D: 0.1106 Loss_G: 0.0411 Convergence: 0.1167 k= 0.044095 lr = 0.0000698\n",
      "[2/25][4350/9765] Loss_D: 0.1112 Loss_G: 0.0445 Convergence: 0.1141 k= 0.044080 lr = 0.0000698\n",
      "[2/25][4360/9765] Loss_D: 0.1190 Loss_G: 0.0471 Convergence: 0.1221 k= 0.044093 lr = 0.0000698\n",
      "[2/25][4370/9765] Loss_D: 0.0991 Loss_G: 0.0428 Convergence: 0.1034 k= 0.044094 lr = 0.0000698\n",
      "[2/25][4380/9765] Loss_D: 0.1093 Loss_G: 0.0451 Convergence: 0.1122 k= 0.044066 lr = 0.0000698\n",
      "[2/25][4390/9765] Loss_D: 0.1041 Loss_G: 0.0428 Convergence: 0.1063 k= 0.044062 lr = 0.0000698\n",
      "[2/25][4400/9765] Loss_D: 0.1067 Loss_G: 0.0443 Convergence: 0.1096 k= 0.044043 lr = 0.0000698\n",
      "[2/25][4410/9765] Loss_D: 0.1166 Loss_G: 0.0514 Convergence: 0.1225 k= 0.044025 lr = 0.0000698\n",
      "[2/25][4420/9765] Loss_D: 0.1241 Loss_G: 0.0546 Convergence: 0.1303 k= 0.043972 lr = 0.0000698\n",
      "[2/25][4430/9765] Loss_D: 0.1066 Loss_G: 0.0501 Convergence: 0.1151 k= 0.043959 lr = 0.0000698\n",
      "[2/25][4440/9765] Loss_D: 0.1050 Loss_G: 0.0522 Convergence: 0.1165 k= 0.043937 lr = 0.0000698\n",
      "[2/25][4450/9765] Loss_D: 0.1098 Loss_G: 0.0433 Convergence: 0.1131 k= 0.043919 lr = 0.0000698\n",
      "[2/25][4460/9765] Loss_D: 0.1158 Loss_G: 0.0463 Convergence: 0.1186 k= 0.043900 lr = 0.0000698\n",
      "[2/25][4470/9765] Loss_D: 0.1100 Loss_G: 0.0550 Convergence: 0.1222 k= 0.043871 lr = 0.0000663\n",
      "[2/25][4480/9765] Loss_D: 0.1021 Loss_G: 0.0413 Convergence: 0.1047 k= 0.043839 lr = 0.0000663\n",
      "[2/25][4490/9765] Loss_D: 0.1056 Loss_G: 0.0422 Convergence: 0.1086 k= 0.043849 lr = 0.0000663\n",
      "[2/25][4500/9765] Loss_D: 0.1028 Loss_G: 0.0514 Convergence: 0.1142 k= 0.043839 lr = 0.0000663\n",
      "[2/25][4510/9765] Loss_D: 0.1010 Loss_G: 0.0497 Convergence: 0.1115 k= 0.043822 lr = 0.0000663\n",
      "[2/25][4520/9765] Loss_D: 0.1090 Loss_G: 0.0437 Convergence: 0.1116 k= 0.043800 lr = 0.0000663\n",
      "[2/25][4530/9765] Loss_D: 0.1000 Loss_G: 0.0461 Convergence: 0.1073 k= 0.043806 lr = 0.0000663\n",
      "[2/25][4540/9765] Loss_D: 0.1045 Loss_G: 0.0452 Convergence: 0.1092 k= 0.043776 lr = 0.0000663\n",
      "[2/25][4550/9765] Loss_D: 0.1193 Loss_G: 0.0479 Convergence: 0.1221 k= 0.043758 lr = 0.0000663\n",
      "[2/25][4560/9765] Loss_D: 0.1027 Loss_G: 0.0454 Convergence: 0.1082 k= 0.043744 lr = 0.0000663\n",
      "[2/25][4570/9765] Loss_D: 0.1133 Loss_G: 0.0456 Convergence: 0.1156 k= 0.043736 lr = 0.0000663\n",
      "[2/25][4580/9765] Loss_D: 0.1101 Loss_G: 0.0533 Convergence: 0.1206 k= 0.043725 lr = 0.0000663\n",
      "[2/25][4590/9765] Loss_D: 0.1137 Loss_G: 0.0460 Convergence: 0.1156 k= 0.043727 lr = 0.0000663\n",
      "[2/25][4600/9765] Loss_D: 0.1101 Loss_G: 0.0431 Convergence: 0.1135 k= 0.043735 lr = 0.0000663\n",
      "[2/25][4610/9765] Loss_D: 0.1048 Loss_G: 0.0455 Convergence: 0.1097 k= 0.043722 lr = 0.0000663\n",
      "[2/25][4620/9765] Loss_D: 0.1060 Loss_G: 0.0427 Convergence: 0.1081 k= 0.043723 lr = 0.0000663\n",
      "[2/25][4630/9765] Loss_D: 0.1086 Loss_G: 0.0469 Convergence: 0.1135 k= 0.043665 lr = 0.0000663\n",
      "[2/25][4640/9765] Loss_D: 0.1106 Loss_G: 0.0483 Convergence: 0.1159 k= 0.043667 lr = 0.0000663\n",
      "[2/25][4650/9765] Loss_D: 0.1138 Loss_G: 0.0481 Convergence: 0.1176 k= 0.043646 lr = 0.0000663\n",
      "[2/25][4660/9765] Loss_D: 0.1093 Loss_G: 0.0466 Convergence: 0.1133 k= 0.043618 lr = 0.0000663\n",
      "[2/25][4670/9765] Loss_D: 0.1032 Loss_G: 0.0409 Convergence: 0.1063 k= 0.043635 lr = 0.0000663\n",
      "[2/25][4680/9765] Loss_D: 0.1051 Loss_G: 0.0504 Convergence: 0.1146 k= 0.043579 lr = 0.0000663\n",
      "[2/25][4690/9765] Loss_D: 0.1145 Loss_G: 0.0404 Convergence: 0.1225 k= 0.043592 lr = 0.0000663\n",
      "[2/25][4700/9765] Loss_D: 0.1052 Loss_G: 0.0463 Convergence: 0.1105 k= 0.043595 lr = 0.0000663\n",
      "[2/25][4710/9765] Loss_D: 0.1021 Loss_G: 0.0418 Convergence: 0.1042 k= 0.043551 lr = 0.0000663\n",
      "[2/25][4720/9765] Loss_D: 0.1185 Loss_G: 0.0439 Convergence: 0.1251 k= 0.043549 lr = 0.0000663\n",
      "[2/25][4730/9765] Loss_D: 0.1024 Loss_G: 0.0446 Convergence: 0.1072 k= 0.043530 lr = 0.0000663\n",
      "[2/25][4740/9765] Loss_D: 0.1012 Loss_G: 0.0424 Convergence: 0.1043 k= 0.043521 lr = 0.0000663\n",
      "[2/25][4750/9765] Loss_D: 0.1102 Loss_G: 0.0460 Convergence: 0.1132 k= 0.043519 lr = 0.0000663\n",
      "[2/25][4760/9765] Loss_D: 0.1046 Loss_G: 0.0497 Convergence: 0.1135 k= 0.043493 lr = 0.0000663\n",
      "[2/25][4770/9765] Loss_D: 0.1180 Loss_G: 0.0450 Convergence: 0.1228 k= 0.043458 lr = 0.0000663\n",
      "[2/25][4780/9765] Loss_D: 0.1116 Loss_G: 0.0407 Convergence: 0.1179 k= 0.043453 lr = 0.0000663\n",
      "[2/25][4790/9765] Loss_D: 0.1093 Loss_G: 0.0427 Convergence: 0.1129 k= 0.043454 lr = 0.0000663\n",
      "[2/25][4800/9765] Loss_D: 0.1024 Loss_G: 0.0403 Convergence: 0.1056 k= 0.043461 lr = 0.0000663\n",
      "[2/25][4810/9765] Loss_D: 0.1041 Loss_G: 0.0464 Convergence: 0.1099 k= 0.043454 lr = 0.0000663\n",
      "[2/25][4820/9765] Loss_D: 0.1070 Loss_G: 0.0428 Convergence: 0.1096 k= 0.043442 lr = 0.0000663\n",
      "[2/25][4830/9765] Loss_D: 0.1088 Loss_G: 0.0433 Convergence: 0.1118 k= 0.043440 lr = 0.0000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][4840/9765] Loss_D: 0.1170 Loss_G: 0.0550 Convergence: 0.1265 k= 0.043427 lr = 0.0000663\n",
      "[2/25][4850/9765] Loss_D: 0.1198 Loss_G: 0.0411 Convergence: 0.1293 k= 0.043387 lr = 0.0000663\n",
      "[2/25][4860/9765] Loss_D: 0.1021 Loss_G: 0.0426 Convergence: 0.1050 k= 0.043383 lr = 0.0000663\n",
      "[2/25][4870/9765] Loss_D: 0.1052 Loss_G: 0.0455 Convergence: 0.1097 k= 0.043345 lr = 0.0000663\n",
      "[2/25][4880/9765] Loss_D: 0.1205 Loss_G: 0.0490 Convergence: 0.1224 k= 0.043342 lr = 0.0000663\n",
      "[2/25][4890/9765] Loss_D: 0.1079 Loss_G: 0.0454 Convergence: 0.1113 k= 0.043320 lr = 0.0000663\n",
      "[2/25][4900/9765] Loss_D: 0.1034 Loss_G: 0.0454 Convergence: 0.1085 k= 0.043322 lr = 0.0000663\n",
      "[2/25][4910/9765] Loss_D: 0.0954 Loss_G: 0.0428 Convergence: 0.1010 k= 0.043322 lr = 0.0000663\n",
      "[2/25][4920/9765] Loss_D: 0.1075 Loss_G: 0.0406 Convergence: 0.1125 k= 0.043339 lr = 0.0000663\n",
      "[2/25][4930/9765] Loss_D: 0.1130 Loss_G: 0.0528 Convergence: 0.1217 k= 0.043318 lr = 0.0000663\n",
      "[2/25][4940/9765] Loss_D: 0.1009 Loss_G: 0.0459 Convergence: 0.1076 k= 0.043294 lr = 0.0000663\n",
      "[2/25][4950/9765] Loss_D: 0.1071 Loss_G: 0.0419 Convergence: 0.1106 k= 0.043291 lr = 0.0000663\n",
      "[2/25][4960/9765] Loss_D: 0.1091 Loss_G: 0.0400 Convergence: 0.1153 k= 0.043253 lr = 0.0000663\n",
      "[2/25][4970/9765] Loss_D: 0.1198 Loss_G: 0.0492 Convergence: 0.1221 k= 0.043263 lr = 0.0000663\n",
      "[2/25][4980/9765] Loss_D: 0.1158 Loss_G: 0.0510 Convergence: 0.1217 k= 0.043262 lr = 0.0000663\n",
      "[2/25][4990/9765] Loss_D: 0.1082 Loss_G: 0.0438 Convergence: 0.1101 k= 0.043233 lr = 0.0000663\n",
      "[2/25][5000/9765] Loss_D: 0.1079 Loss_G: 0.0423 Convergence: 0.1114 k= 0.043244 lr = 0.0000663\n",
      "[2/25][5010/9765] Loss_D: 0.1019 Loss_G: 0.0434 Convergence: 0.1056 k= 0.043240 lr = 0.0000663\n",
      "[2/25][5020/9765] Loss_D: 0.1126 Loss_G: 0.0450 Convergence: 0.1153 k= 0.043250 lr = 0.0000663\n",
      "[2/25][5030/9765] Loss_D: 0.1077 Loss_G: 0.0536 Convergence: 0.1195 k= 0.043245 lr = 0.0000663\n",
      "[2/25][5040/9765] Loss_D: 0.1141 Loss_G: 0.0414 Convergence: 0.1210 k= 0.043207 lr = 0.0000663\n",
      "[2/25][5050/9765] Loss_D: 0.1134 Loss_G: 0.0459 Convergence: 0.1156 k= 0.043232 lr = 0.0000663\n",
      "[2/25][5060/9765] Loss_D: 0.1083 Loss_G: 0.0414 Convergence: 0.1128 k= 0.043204 lr = 0.0000663\n",
      "[2/25][5070/9765] Loss_D: 0.1076 Loss_G: 0.0444 Convergence: 0.1099 k= 0.043212 lr = 0.0000663\n",
      "[2/25][5080/9765] Loss_D: 0.1066 Loss_G: 0.0452 Convergence: 0.1102 k= 0.043199 lr = 0.0000663\n",
      "[2/25][5090/9765] Loss_D: 0.1057 Loss_G: 0.0426 Convergence: 0.1085 k= 0.043187 lr = 0.0000663\n",
      "[2/25][5100/9765] Loss_D: 0.1055 Loss_G: 0.0521 Convergence: 0.1165 k= 0.043175 lr = 0.0000663\n",
      "[2/25][5110/9765] Loss_D: 0.1075 Loss_G: 0.0422 Convergence: 0.1108 k= 0.043181 lr = 0.0000663\n",
      "[2/25][5120/9765] Loss_D: 0.1001 Loss_G: 0.0423 Convergence: 0.1035 k= 0.043153 lr = 0.0000663\n",
      "[2/25][5130/9765] Loss_D: 0.1107 Loss_G: 0.0484 Convergence: 0.1160 k= 0.043137 lr = 0.0000663\n",
      "[2/25][5140/9765] Loss_D: 0.1027 Loss_G: 0.0531 Convergence: 0.1159 k= 0.043114 lr = 0.0000663\n",
      "[2/25][5150/9765] Loss_D: 0.1106 Loss_G: 0.0469 Convergence: 0.1144 k= 0.043110 lr = 0.0000663\n",
      "[2/25][5160/9765] Loss_D: 0.1104 Loss_G: 0.0510 Convergence: 0.1185 k= 0.043083 lr = 0.0000663\n",
      "[2/25][5170/9765] Loss_D: 0.1120 Loss_G: 0.0467 Convergence: 0.1151 k= 0.043084 lr = 0.0000663\n",
      "[2/25][5180/9765] Loss_D: 0.1053 Loss_G: 0.0485 Convergence: 0.1128 k= 0.043078 lr = 0.0000663\n",
      "[2/25][5190/9765] Loss_D: 0.1172 Loss_G: 0.0455 Convergence: 0.1212 k= 0.043034 lr = 0.0000663\n",
      "[2/25][5200/9765] Loss_D: 0.1131 Loss_G: 0.0440 Convergence: 0.1167 k= 0.043049 lr = 0.0000663\n",
      "[2/25][5210/9765] Loss_D: 0.1071 Loss_G: 0.0456 Convergence: 0.1110 k= 0.043033 lr = 0.0000663\n",
      "[2/25][5220/9765] Loss_D: 0.1087 Loss_G: 0.0370 Convergence: 0.1174 k= 0.043045 lr = 0.0000663\n",
      "[2/25][5230/9765] Loss_D: 0.1043 Loss_G: 0.0460 Convergence: 0.1098 k= 0.043029 lr = 0.0000663\n",
      "[2/25][5240/9765] Loss_D: 0.1075 Loss_G: 0.0454 Convergence: 0.1110 k= 0.043040 lr = 0.0000663\n",
      "[2/25][5250/9765] Loss_D: 0.1013 Loss_G: 0.0383 Convergence: 0.1062 k= 0.043031 lr = 0.0000663\n",
      "[2/25][5260/9765] Loss_D: 0.1082 Loss_G: 0.0501 Convergence: 0.1162 k= 0.043000 lr = 0.0000663\n",
      "[2/25][5270/9765] Loss_D: 0.0966 Loss_G: 0.0416 Convergence: 0.1007 k= 0.042978 lr = 0.0000663\n",
      "[2/25][5280/9765] Loss_D: 0.1100 Loss_G: 0.0440 Convergence: 0.1124 k= 0.042988 lr = 0.0000663\n",
      "[2/25][5290/9765] Loss_D: 0.1057 Loss_G: 0.0513 Convergence: 0.1159 k= 0.042959 lr = 0.0000663\n",
      "[2/25][5300/9765] Loss_D: 0.0994 Loss_G: 0.0407 Convergence: 0.1014 k= 0.042973 lr = 0.0000663\n",
      "[2/25][5310/9765] Loss_D: 0.1007 Loss_G: 0.0505 Convergence: 0.1123 k= 0.042953 lr = 0.0000663\n",
      "[2/25][5320/9765] Loss_D: 0.1059 Loss_G: 0.0449 Convergence: 0.1097 k= 0.042917 lr = 0.0000663\n",
      "[2/25][5330/9765] Loss_D: 0.1190 Loss_G: 0.0504 Convergence: 0.1230 k= 0.042912 lr = 0.0000663\n",
      "[2/25][5340/9765] Loss_D: 0.1027 Loss_G: 0.0417 Convergence: 0.1047 k= 0.042889 lr = 0.0000663\n",
      "[2/25][5350/9765] Loss_D: 0.1111 Loss_G: 0.0411 Convergence: 0.1169 k= 0.042880 lr = 0.0000663\n",
      "[2/25][5360/9765] Loss_D: 0.1008 Loss_G: 0.0420 Convergence: 0.1038 k= 0.042896 lr = 0.0000663\n",
      "[2/25][5370/9765] Loss_D: 0.0980 Loss_G: 0.0432 Convergence: 0.1030 k= 0.042870 lr = 0.0000663\n",
      "[2/25][5380/9765] Loss_D: 0.1164 Loss_G: 0.0474 Convergence: 0.1184 k= 0.042877 lr = 0.0000663\n",
      "[2/25][5390/9765] Loss_D: 0.1173 Loss_G: 0.0425 Convergence: 0.1241 k= 0.042883 lr = 0.0000663\n",
      "[2/25][5400/9765] Loss_D: 0.1100 Loss_G: 0.0398 Convergence: 0.1172 k= 0.042883 lr = 0.0000663\n",
      "[2/25][5410/9765] Loss_D: 0.1164 Loss_G: 0.0462 Convergence: 0.1193 k= 0.042870 lr = 0.0000663\n",
      "[2/25][5420/9765] Loss_D: 0.1016 Loss_G: 0.0468 Convergence: 0.1089 k= 0.042844 lr = 0.0000663\n",
      "[2/25][5430/9765] Loss_D: 0.1131 Loss_G: 0.0407 Convergence: 0.1199 k= 0.042841 lr = 0.0000663\n",
      "[2/25][5440/9765] Loss_D: 0.1075 Loss_G: 0.0495 Convergence: 0.1151 k= 0.042834 lr = 0.0000663\n",
      "[2/25][5450/9765] Loss_D: 0.1044 Loss_G: 0.0437 Convergence: 0.1075 k= 0.042838 lr = 0.0000663\n",
      "[2/25][5460/9765] Loss_D: 0.1050 Loss_G: 0.0428 Convergence: 0.1069 k= 0.042845 lr = 0.0000663\n",
      "[2/25][5470/9765] Loss_D: 0.0934 Loss_G: 0.0458 Convergence: 0.1030 k= 0.042834 lr = 0.0000663\n",
      "[2/25][5480/9765] Loss_D: 0.1028 Loss_G: 0.0439 Convergence: 0.1068 k= 0.042823 lr = 0.0000663\n",
      "[2/25][5490/9765] Loss_D: 0.1041 Loss_G: 0.0431 Convergence: 0.1067 k= 0.042821 lr = 0.0000663\n",
      "[2/25][5500/9765] Loss_D: 0.1203 Loss_G: 0.0454 Convergence: 0.1257 k= 0.042825 lr = 0.0000663\n",
      "[2/25][5510/9765] Loss_D: 0.1051 Loss_G: 0.0483 Convergence: 0.1125 k= 0.042799 lr = 0.0000663\n",
      "[2/25][5520/9765] Loss_D: 0.1029 Loss_G: 0.0477 Convergence: 0.1106 k= 0.042774 lr = 0.0000663\n",
      "[2/25][5530/9765] Loss_D: 0.0992 Loss_G: 0.0396 Convergence: 0.1016 k= 0.042782 lr = 0.0000663\n",
      "[2/25][5540/9765] Loss_D: 0.1050 Loss_G: 0.0453 Convergence: 0.1094 k= 0.042773 lr = 0.0000663\n",
      "[2/25][5550/9765] Loss_D: 0.1092 Loss_G: 0.0484 Convergence: 0.1150 k= 0.042780 lr = 0.0000663\n",
      "[2/25][5560/9765] Loss_D: 0.1112 Loss_G: 0.0397 Convergence: 0.1184 k= 0.042781 lr = 0.0000663\n",
      "[2/25][5570/9765] Loss_D: 0.1045 Loss_G: 0.0465 Convergence: 0.1104 k= 0.042751 lr = 0.0000663\n",
      "[2/25][5580/9765] Loss_D: 0.1023 Loss_G: 0.0442 Convergence: 0.1068 k= 0.042723 lr = 0.0000663\n",
      "[2/25][5590/9765] Loss_D: 0.1096 Loss_G: 0.0435 Convergence: 0.1127 k= 0.042718 lr = 0.0000663\n",
      "[2/25][5600/9765] Loss_D: 0.0997 Loss_G: 0.0413 Convergence: 0.1023 k= 0.042690 lr = 0.0000663\n",
      "[2/25][5610/9765] Loss_D: 0.1059 Loss_G: 0.0395 Convergence: 0.1111 k= 0.042723 lr = 0.0000663\n",
      "[2/25][5620/9765] Loss_D: 0.1089 Loss_G: 0.0459 Convergence: 0.1124 k= 0.042714 lr = 0.0000663\n",
      "[2/25][5630/9765] Loss_D: 0.1107 Loss_G: 0.0515 Convergence: 0.1190 k= 0.042705 lr = 0.0000663\n",
      "[2/25][5640/9765] Loss_D: 0.1024 Loss_G: 0.0488 Convergence: 0.1112 k= 0.042696 lr = 0.0000663\n",
      "[2/25][5650/9765] Loss_D: 0.1099 Loss_G: 0.0481 Convergence: 0.1153 k= 0.042700 lr = 0.0000663\n",
      "[2/25][5660/9765] Loss_D: 0.1088 Loss_G: 0.0427 Convergence: 0.1120 k= 0.042702 lr = 0.0000663\n",
      "[2/25][5670/9765] Loss_D: 0.1059 Loss_G: 0.0457 Convergence: 0.1103 k= 0.042710 lr = 0.0000663\n",
      "[2/25][5680/9765] Loss_D: 0.1057 Loss_G: 0.0431 Convergence: 0.1075 k= 0.042708 lr = 0.0000663\n",
      "[2/25][5690/9765] Loss_D: 0.1107 Loss_G: 0.0531 Convergence: 0.1209 k= 0.042675 lr = 0.0000663\n",
      "[2/25][5700/9765] Loss_D: 0.1050 Loss_G: 0.0602 Convergence: 0.1242 k= 0.042669 lr = 0.0000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][5710/9765] Loss_D: 0.1017 Loss_G: 0.0464 Convergence: 0.1085 k= 0.042639 lr = 0.0000663\n",
      "[2/25][5720/9765] Loss_D: 0.1073 Loss_G: 0.0446 Convergence: 0.1100 k= 0.042624 lr = 0.0000663\n",
      "[2/25][5730/9765] Loss_D: 0.1024 Loss_G: 0.0447 Convergence: 0.1072 k= 0.042616 lr = 0.0000663\n",
      "[2/25][5740/9765] Loss_D: 0.1082 Loss_G: 0.0475 Convergence: 0.1136 k= 0.042641 lr = 0.0000663\n",
      "[2/25][5750/9765] Loss_D: 0.1095 Loss_G: 0.0459 Convergence: 0.1127 k= 0.042637 lr = 0.0000663\n",
      "[2/25][5760/9765] Loss_D: 0.1018 Loss_G: 0.0475 Convergence: 0.1097 k= 0.042621 lr = 0.0000663\n",
      "[2/25][5770/9765] Loss_D: 0.1109 Loss_G: 0.0528 Convergence: 0.1204 k= 0.042621 lr = 0.0000663\n",
      "[2/25][5780/9765] Loss_D: 0.1006 Loss_G: 0.0498 Convergence: 0.1113 k= 0.042586 lr = 0.0000663\n",
      "[2/25][5790/9765] Loss_D: 0.1039 Loss_G: 0.0392 Convergence: 0.1087 k= 0.042595 lr = 0.0000663\n",
      "[2/25][5800/9765] Loss_D: 0.0997 Loss_G: 0.0412 Convergence: 0.1023 k= 0.042593 lr = 0.0000663\n",
      "[2/25][5810/9765] Loss_D: 0.1072 Loss_G: 0.0447 Convergence: 0.1102 k= 0.042584 lr = 0.0000663\n",
      "[2/25][5820/9765] Loss_D: 0.1050 Loss_G: 0.0425 Convergence: 0.1075 k= 0.042585 lr = 0.0000663\n",
      "[2/25][5830/9765] Loss_D: 0.1140 Loss_G: 0.0422 Convergence: 0.1196 k= 0.042598 lr = 0.0000663\n",
      "[2/25][5840/9765] Loss_D: 0.1125 Loss_G: 0.0440 Convergence: 0.1162 k= 0.042613 lr = 0.0000663\n",
      "[2/25][5850/9765] Loss_D: 0.1068 Loss_G: 0.0433 Convergence: 0.1088 k= 0.042601 lr = 0.0000663\n",
      "[2/25][5860/9765] Loss_D: 0.1118 Loss_G: 0.0445 Convergence: 0.1152 k= 0.042578 lr = 0.0000663\n",
      "[2/25][5870/9765] Loss_D: 0.1248 Loss_G: 0.0482 Convergence: 0.1295 k= 0.042559 lr = 0.0000663\n",
      "[2/25][5880/9765] Loss_D: 0.1140 Loss_G: 0.0405 Convergence: 0.1216 k= 0.042549 lr = 0.0000663\n",
      "[2/25][5890/9765] Loss_D: 0.1050 Loss_G: 0.0420 Convergence: 0.1074 k= 0.042579 lr = 0.0000663\n",
      "[2/25][5900/9765] Loss_D: 0.1046 Loss_G: 0.0491 Convergence: 0.1131 k= 0.042581 lr = 0.0000663\n",
      "[2/25][5910/9765] Loss_D: 0.1135 Loss_G: 0.0483 Convergence: 0.1176 k= 0.042553 lr = 0.0000663\n",
      "[2/25][5920/9765] Loss_D: 0.1102 Loss_G: 0.0437 Convergence: 0.1132 k= 0.042556 lr = 0.0000663\n",
      "[2/25][5930/9765] Loss_D: 0.1010 Loss_G: 0.0393 Convergence: 0.1044 k= 0.042551 lr = 0.0000663\n",
      "[2/25][5940/9765] Loss_D: 0.1041 Loss_G: 0.0420 Convergence: 0.1066 k= 0.042549 lr = 0.0000663\n",
      "[2/25][5950/9765] Loss_D: 0.1121 Loss_G: 0.0400 Convergence: 0.1192 k= 0.042554 lr = 0.0000663\n",
      "[2/25][5960/9765] Loss_D: 0.1079 Loss_G: 0.0452 Convergence: 0.1111 k= 0.042543 lr = 0.0000663\n",
      "[2/25][5970/9765] Loss_D: 0.1016 Loss_G: 0.0465 Convergence: 0.1086 k= 0.042520 lr = 0.0000663\n",
      "[2/25][5980/9765] Loss_D: 0.1243 Loss_G: 0.0465 Convergence: 0.1301 k= 0.042516 lr = 0.0000663\n",
      "[2/25][5990/9765] Loss_D: 0.1070 Loss_G: 0.0391 Convergence: 0.1129 k= 0.042554 lr = 0.0000663\n",
      "[2/25][6000/9765] Loss_D: 0.1050 Loss_G: 0.0448 Convergence: 0.1089 k= 0.042548 lr = 0.0000663\n",
      "[2/25][6010/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.1001 k= 0.042568 lr = 0.0000663\n",
      "[2/25][6020/9765] Loss_D: 0.1143 Loss_G: 0.0444 Convergence: 0.1182 k= 0.042585 lr = 0.0000663\n",
      "[2/25][6030/9765] Loss_D: 0.1137 Loss_G: 0.0436 Convergence: 0.1184 k= 0.042570 lr = 0.0000663\n",
      "[2/25][6040/9765] Loss_D: 0.1047 Loss_G: 0.0423 Convergence: 0.1067 k= 0.042552 lr = 0.0000663\n",
      "[2/25][6050/9765] Loss_D: 0.1114 Loss_G: 0.0534 Convergence: 0.1213 k= 0.042536 lr = 0.0000663\n",
      "[2/25][6060/9765] Loss_D: 0.1057 Loss_G: 0.0448 Convergence: 0.1093 k= 0.042494 lr = 0.0000663\n",
      "[2/25][6070/9765] Loss_D: 0.1039 Loss_G: 0.0503 Convergence: 0.1137 k= 0.042461 lr = 0.0000663\n",
      "[2/25][6080/9765] Loss_D: 0.1143 Loss_G: 0.0459 Convergence: 0.1166 k= 0.042465 lr = 0.0000663\n",
      "[2/25][6090/9765] Loss_D: 0.1174 Loss_G: 0.0457 Convergence: 0.1210 k= 0.042462 lr = 0.0000663\n",
      "[2/25][6100/9765] Loss_D: 0.1041 Loss_G: 0.0395 Convergence: 0.1087 k= 0.042435 lr = 0.0000663\n",
      "[2/25][6110/9765] Loss_D: 0.1175 Loss_G: 0.0432 Convergence: 0.1239 k= 0.042445 lr = 0.0000663\n",
      "[2/25][6120/9765] Loss_D: 0.1036 Loss_G: 0.0452 Convergence: 0.1085 k= 0.042442 lr = 0.0000663\n",
      "[2/25][6130/9765] Loss_D: 0.1087 Loss_G: 0.0467 Convergence: 0.1132 k= 0.042435 lr = 0.0000663\n",
      "[2/25][6140/9765] Loss_D: 0.1072 Loss_G: 0.0473 Convergence: 0.1128 k= 0.042428 lr = 0.0000663\n",
      "[2/25][6150/9765] Loss_D: 0.1214 Loss_G: 0.0474 Convergence: 0.1250 k= 0.042436 lr = 0.0000663\n",
      "[2/25][6160/9765] Loss_D: 0.1204 Loss_G: 0.0488 Convergence: 0.1225 k= 0.042411 lr = 0.0000663\n",
      "[2/25][6170/9765] Loss_D: 0.1027 Loss_G: 0.0419 Convergence: 0.1045 k= 0.042415 lr = 0.0000663\n",
      "[2/25][6180/9765] Loss_D: 0.1059 Loss_G: 0.0492 Convergence: 0.1140 k= 0.042405 lr = 0.0000663\n",
      "[2/25][6190/9765] Loss_D: 0.1151 Loss_G: 0.0564 Convergence: 0.1266 k= 0.042392 lr = 0.0000663\n",
      "[2/25][6200/9765] Loss_D: 0.1031 Loss_G: 0.0485 Convergence: 0.1115 k= 0.042338 lr = 0.0000663\n",
      "[2/25][6210/9765] Loss_D: 0.1066 Loss_G: 0.0469 Convergence: 0.1119 k= 0.042337 lr = 0.0000663\n",
      "[2/25][6220/9765] Loss_D: 0.1077 Loss_G: 0.0431 Convergence: 0.1101 k= 0.042311 lr = 0.0000663\n",
      "[2/25][6230/9765] Loss_D: 0.0994 Loss_G: 0.0432 Convergence: 0.1039 k= 0.042325 lr = 0.0000663\n",
      "[2/25][6240/9765] Loss_D: 0.1090 Loss_G: 0.0432 Convergence: 0.1123 k= 0.042280 lr = 0.0000663\n",
      "[2/25][6250/9765] Loss_D: 0.1058 Loss_G: 0.0433 Convergence: 0.1077 k= 0.042279 lr = 0.0000663\n",
      "[2/25][6260/9765] Loss_D: 0.1038 Loss_G: 0.0424 Convergence: 0.1058 k= 0.042281 lr = 0.0000663\n",
      "[2/25][6270/9765] Loss_D: 0.1048 Loss_G: 0.0443 Convergence: 0.1083 k= 0.042276 lr = 0.0000663\n",
      "[2/25][6280/9765] Loss_D: 0.1099 Loss_G: 0.0414 Convergence: 0.1149 k= 0.042270 lr = 0.0000663\n",
      "[2/25][6290/9765] Loss_D: 0.1017 Loss_G: 0.0457 Convergence: 0.1077 k= 0.042275 lr = 0.0000663\n",
      "[2/25][6300/9765] Loss_D: 0.1105 Loss_G: 0.0432 Convergence: 0.1139 k= 0.042277 lr = 0.0000663\n",
      "[2/25][6310/9765] Loss_D: 0.1173 Loss_G: 0.0443 Convergence: 0.1224 k= 0.042256 lr = 0.0000663\n",
      "[2/25][6320/9765] Loss_D: 0.1056 Loss_G: 0.0443 Convergence: 0.1087 k= 0.042249 lr = 0.0000663\n",
      "[2/25][6330/9765] Loss_D: 0.1080 Loss_G: 0.0456 Convergence: 0.1115 k= 0.042246 lr = 0.0000663\n",
      "[2/25][6340/9765] Loss_D: 0.1065 Loss_G: 0.0464 Convergence: 0.1114 k= 0.042218 lr = 0.0000663\n",
      "[2/25][6350/9765] Loss_D: 0.1043 Loss_G: 0.0426 Convergence: 0.1061 k= 0.042228 lr = 0.0000663\n",
      "[2/25][6360/9765] Loss_D: 0.1076 Loss_G: 0.0458 Convergence: 0.1116 k= 0.042220 lr = 0.0000663\n",
      "[2/25][6370/9765] Loss_D: 0.1093 Loss_G: 0.0397 Convergence: 0.1160 k= 0.042217 lr = 0.0000663\n",
      "[2/25][6380/9765] Loss_D: 0.1157 Loss_G: 0.0450 Convergence: 0.1196 k= 0.042206 lr = 0.0000663\n",
      "[2/25][6390/9765] Loss_D: 0.1099 Loss_G: 0.0500 Convergence: 0.1173 k= 0.042187 lr = 0.0000663\n",
      "[2/25][6400/9765] Loss_D: 0.1112 Loss_G: 0.0475 Convergence: 0.1154 k= 0.042182 lr = 0.0000663\n",
      "[2/25][6410/9765] Loss_D: 0.1052 Loss_G: 0.0431 Convergence: 0.1072 k= 0.042166 lr = 0.0000663\n",
      "[2/25][6420/9765] Loss_D: 0.1004 Loss_G: 0.0421 Convergence: 0.1034 k= 0.042177 lr = 0.0000663\n",
      "[2/25][6430/9765] Loss_D: 0.1113 Loss_G: 0.0467 Convergence: 0.1148 k= 0.042185 lr = 0.0000663\n",
      "[2/25][6440/9765] Loss_D: 0.1116 Loss_G: 0.0414 Convergence: 0.1175 k= 0.042175 lr = 0.0000663\n",
      "[2/25][6450/9765] Loss_D: 0.1214 Loss_G: 0.0493 Convergence: 0.1233 k= 0.042185 lr = 0.0000663\n",
      "[2/25][6460/9765] Loss_D: 0.1017 Loss_G: 0.0432 Convergence: 0.1053 k= 0.042189 lr = 0.0000663\n",
      "[2/25][6470/9765] Loss_D: 0.1126 Loss_G: 0.0494 Convergence: 0.1181 k= 0.042187 lr = 0.0000663\n",
      "[2/25][6480/9765] Loss_D: 0.0998 Loss_G: 0.0443 Convergence: 0.1052 k= 0.042179 lr = 0.0000663\n",
      "[2/25][6490/9765] Loss_D: 0.1066 Loss_G: 0.0468 Convergence: 0.1119 k= 0.042183 lr = 0.0000663\n",
      "[2/25][6500/9765] Loss_D: 0.1169 Loss_G: 0.0445 Convergence: 0.1220 k= 0.042177 lr = 0.0000663\n",
      "[2/25][6510/9765] Loss_D: 0.1166 Loss_G: 0.0524 Convergence: 0.1235 k= 0.042140 lr = 0.0000663\n",
      "[2/25][6520/9765] Loss_D: 0.1014 Loss_G: 0.0431 Convergence: 0.1050 k= 0.042150 lr = 0.0000663\n",
      "[2/25][6530/9765] Loss_D: 0.1077 Loss_G: 0.0415 Convergence: 0.1116 k= 0.042163 lr = 0.0000663\n",
      "[2/25][6540/9765] Loss_D: 0.1168 Loss_G: 0.0522 Convergence: 0.1235 k= 0.042144 lr = 0.0000663\n",
      "[2/25][6550/9765] Loss_D: 0.1086 Loss_G: 0.0416 Convergence: 0.1127 k= 0.042141 lr = 0.0000663\n",
      "[2/25][6560/9765] Loss_D: 0.1071 Loss_G: 0.0436 Convergence: 0.1089 k= 0.042173 lr = 0.0000663\n",
      "[2/25][6570/9765] Loss_D: 0.0999 Loss_G: 0.0424 Convergence: 0.1035 k= 0.042163 lr = 0.0000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][6580/9765] Loss_D: 0.1113 Loss_G: 0.0419 Convergence: 0.1160 k= 0.042184 lr = 0.0000663\n",
      "[2/25][6590/9765] Loss_D: 0.1055 Loss_G: 0.0448 Convergence: 0.1093 k= 0.042184 lr = 0.0000663\n",
      "[2/25][6600/9765] Loss_D: 0.1064 Loss_G: 0.0430 Convergence: 0.1085 k= 0.042189 lr = 0.0000663\n",
      "[2/25][6610/9765] Loss_D: 0.1058 Loss_G: 0.0423 Convergence: 0.1084 k= 0.042185 lr = 0.0000663\n",
      "[2/25][6620/9765] Loss_D: 0.1054 Loss_G: 0.0455 Convergence: 0.1098 k= 0.042172 lr = 0.0000663\n",
      "[2/25][6630/9765] Loss_D: 0.1121 Loss_G: 0.0420 Convergence: 0.1178 k= 0.042168 lr = 0.0000663\n",
      "[2/25][6640/9765] Loss_D: 0.1189 Loss_G: 0.0446 Convergence: 0.1246 k= 0.042159 lr = 0.0000663\n",
      "[2/25][6650/9765] Loss_D: 0.1157 Loss_G: 0.0475 Convergence: 0.1182 k= 0.042148 lr = 0.0000663\n",
      "[2/25][6660/9765] Loss_D: 0.1073 Loss_G: 0.0479 Convergence: 0.1134 k= 0.042147 lr = 0.0000663\n",
      "[2/25][6670/9765] Loss_D: 0.1171 Loss_G: 0.0477 Convergence: 0.1193 k= 0.042121 lr = 0.0000663\n",
      "[2/25][6680/9765] Loss_D: 0.1051 Loss_G: 0.0400 Convergence: 0.1094 k= 0.042115 lr = 0.0000663\n",
      "[2/25][6690/9765] Loss_D: 0.1001 Loss_G: 0.0483 Convergence: 0.1095 k= 0.042106 lr = 0.0000663\n",
      "[2/25][6700/9765] Loss_D: 0.1039 Loss_G: 0.0425 Convergence: 0.1061 k= 0.042091 lr = 0.0000663\n",
      "[2/25][6710/9765] Loss_D: 0.0962 Loss_G: 0.0389 Convergence: 0.0983 k= 0.042090 lr = 0.0000663\n",
      "[2/25][6720/9765] Loss_D: 0.1062 Loss_G: 0.0391 Convergence: 0.1121 k= 0.042085 lr = 0.0000663\n",
      "[2/25][6730/9765] Loss_D: 0.1120 Loss_G: 0.0482 Convergence: 0.1165 k= 0.042091 lr = 0.0000663\n",
      "[2/25][6740/9765] Loss_D: 0.1058 Loss_G: 0.0465 Convergence: 0.1111 k= 0.042101 lr = 0.0000663\n",
      "[2/25][6750/9765] Loss_D: 0.1110 Loss_G: 0.0422 Convergence: 0.1156 k= 0.042090 lr = 0.0000663\n",
      "[2/25][6760/9765] Loss_D: 0.1096 Loss_G: 0.0418 Convergence: 0.1143 k= 0.042083 lr = 0.0000663\n",
      "[2/25][6770/9765] Loss_D: 0.1032 Loss_G: 0.0403 Convergence: 0.1064 k= 0.042090 lr = 0.0000663\n",
      "[2/25][6780/9765] Loss_D: 0.1015 Loss_G: 0.0453 Convergence: 0.1079 k= 0.042053 lr = 0.0000663\n",
      "[2/25][6790/9765] Loss_D: 0.1073 Loss_G: 0.0443 Convergence: 0.1097 k= 0.042011 lr = 0.0000663\n",
      "[2/25][6800/9765] Loss_D: 0.1069 Loss_G: 0.0415 Convergence: 0.1106 k= 0.041998 lr = 0.0000663\n",
      "[2/25][6810/9765] Loss_D: 0.1178 Loss_G: 0.0396 Convergence: 0.1275 k= 0.042047 lr = 0.0000663\n",
      "[2/25][6820/9765] Loss_D: 0.0949 Loss_G: 0.0456 Convergence: 0.1038 k= 0.042013 lr = 0.0000663\n",
      "[2/25][6830/9765] Loss_D: 0.1122 Loss_G: 0.0445 Convergence: 0.1147 k= 0.042036 lr = 0.0000663\n",
      "[2/25][6840/9765] Loss_D: 0.1090 Loss_G: 0.0475 Convergence: 0.1140 k= 0.042035 lr = 0.0000663\n",
      "[2/25][6850/9765] Loss_D: 0.1092 Loss_G: 0.0470 Convergence: 0.1138 k= 0.042003 lr = 0.0000663\n",
      "[2/25][6860/9765] Loss_D: 0.1095 Loss_G: 0.0445 Convergence: 0.1114 k= 0.042026 lr = 0.0000663\n",
      "[2/25][6870/9765] Loss_D: 0.1182 Loss_G: 0.0394 Convergence: 0.1285 k= 0.042017 lr = 0.0000663\n",
      "[2/25][6880/9765] Loss_D: 0.1083 Loss_G: 0.0489 Convergence: 0.1149 k= 0.041989 lr = 0.0000663\n",
      "[2/25][6890/9765] Loss_D: 0.1129 Loss_G: 0.0476 Convergence: 0.1163 k= 0.041973 lr = 0.0000663\n",
      "[2/25][6900/9765] Loss_D: 0.1101 Loss_G: 0.0436 Convergence: 0.1128 k= 0.041957 lr = 0.0000663\n",
      "[2/25][6910/9765] Loss_D: 0.1208 Loss_G: 0.0490 Convergence: 0.1230 k= 0.041943 lr = 0.0000663\n",
      "[2/25][6920/9765] Loss_D: 0.0990 Loss_G: 0.0429 Convergence: 0.1033 k= 0.041920 lr = 0.0000663\n",
      "[2/25][6930/9765] Loss_D: 0.1161 Loss_G: 0.0441 Convergence: 0.1212 k= 0.041910 lr = 0.0000663\n",
      "[2/25][6940/9765] Loss_D: 0.1147 Loss_G: 0.0460 Convergence: 0.1176 k= 0.041896 lr = 0.0000663\n",
      "[2/25][6950/9765] Loss_D: 0.0965 Loss_G: 0.0463 Convergence: 0.1053 k= 0.041864 lr = 0.0000663\n",
      "[2/25][6960/9765] Loss_D: 0.1042 Loss_G: 0.0434 Convergence: 0.1070 k= 0.041867 lr = 0.0000663\n",
      "[2/25][6970/9765] Loss_D: 0.1040 Loss_G: 0.0436 Convergence: 0.1071 k= 0.041856 lr = 0.0000663\n",
      "[2/25][6980/9765] Loss_D: 0.1019 Loss_G: 0.0422 Convergence: 0.1045 k= 0.041854 lr = 0.0000663\n",
      "[2/25][6990/9765] Loss_D: 0.1096 Loss_G: 0.0453 Convergence: 0.1122 k= 0.041843 lr = 0.0000663\n",
      "[2/25][7000/9765] Loss_D: 0.1115 Loss_G: 0.0478 Convergence: 0.1156 k= 0.041839 lr = 0.0000663\n",
      "[2/25][7010/9765] Loss_D: 0.1198 Loss_G: 0.0583 Convergence: 0.1315 k= 0.041834 lr = 0.0000663\n",
      "[2/25][7020/9765] Loss_D: 0.1144 Loss_G: 0.0468 Convergence: 0.1167 k= 0.041765 lr = 0.0000663\n",
      "[2/25][7030/9765] Loss_D: 0.1086 Loss_G: 0.0501 Convergence: 0.1163 k= 0.041747 lr = 0.0000663\n",
      "[2/25][7040/9765] Loss_D: 0.1064 Loss_G: 0.0461 Convergence: 0.1110 k= 0.041739 lr = 0.0000663\n",
      "[2/25][7050/9765] Loss_D: 0.1030 Loss_G: 0.0454 Convergence: 0.1083 k= 0.041731 lr = 0.0000663\n",
      "[2/25][7060/9765] Loss_D: 0.0949 Loss_G: 0.0561 Convergence: 0.1141 k= 0.041727 lr = 0.0000663\n",
      "[2/25][7070/9765] Loss_D: 0.1055 Loss_G: 0.0390 Convergence: 0.1111 k= 0.041730 lr = 0.0000663\n",
      "[2/25][7080/9765] Loss_D: 0.1015 Loss_G: 0.0430 Convergence: 0.1050 k= 0.041711 lr = 0.0000663\n",
      "[2/25][7090/9765] Loss_D: 0.1175 Loss_G: 0.0473 Convergence: 0.1197 k= 0.041713 lr = 0.0000663\n",
      "[2/25][7100/9765] Loss_D: 0.1105 Loss_G: 0.0404 Convergence: 0.1171 k= 0.041685 lr = 0.0000663\n",
      "[2/25][7110/9765] Loss_D: 0.1087 Loss_G: 0.0406 Convergence: 0.1142 k= 0.041697 lr = 0.0000663\n",
      "[2/25][7120/9765] Loss_D: 0.1080 Loss_G: 0.0498 Convergence: 0.1158 k= 0.041692 lr = 0.0000663\n",
      "[2/25][7130/9765] Loss_D: 0.1078 Loss_G: 0.0445 Convergence: 0.1103 k= 0.041685 lr = 0.0000663\n",
      "[2/25][7140/9765] Loss_D: 0.1040 Loss_G: 0.0391 Convergence: 0.1094 k= 0.041674 lr = 0.0000663\n",
      "[2/25][7150/9765] Loss_D: 0.1049 Loss_G: 0.0423 Convergence: 0.1070 k= 0.041669 lr = 0.0000663\n",
      "[2/25][7160/9765] Loss_D: 0.1067 Loss_G: 0.0429 Convergence: 0.1089 k= 0.041671 lr = 0.0000663\n",
      "[2/25][7170/9765] Loss_D: 0.1074 Loss_G: 0.0417 Convergence: 0.1109 k= 0.041695 lr = 0.0000663\n",
      "[2/25][7180/9765] Loss_D: 0.1106 Loss_G: 0.0465 Convergence: 0.1139 k= 0.041696 lr = 0.0000663\n",
      "[2/25][7190/9765] Loss_D: 0.1295 Loss_G: 0.0405 Convergence: 0.1430 k= 0.041704 lr = 0.0000663\n",
      "[2/25][7200/9765] Loss_D: 0.1117 Loss_G: 0.0438 Convergence: 0.1150 k= 0.041722 lr = 0.0000663\n",
      "[2/25][7210/9765] Loss_D: 0.1017 Loss_G: 0.0428 Convergence: 0.1050 k= 0.041699 lr = 0.0000663\n",
      "[2/25][7220/9765] Loss_D: 0.1105 Loss_G: 0.0497 Convergence: 0.1171 k= 0.041710 lr = 0.0000663\n",
      "[2/25][7230/9765] Loss_D: 0.1108 Loss_G: 0.0436 Convergence: 0.1143 k= 0.041674 lr = 0.0000663\n",
      "[2/25][7240/9765] Loss_D: 0.1071 Loss_G: 0.0407 Convergence: 0.1115 k= 0.041692 lr = 0.0000663\n",
      "[2/25][7250/9765] Loss_D: 0.1213 Loss_G: 0.0440 Convergence: 0.1282 k= 0.041681 lr = 0.0000663\n",
      "[2/25][7260/9765] Loss_D: 0.1024 Loss_G: 0.0488 Convergence: 0.1113 k= 0.041650 lr = 0.0000663\n",
      "[2/25][7270/9765] Loss_D: 0.1031 Loss_G: 0.0444 Convergence: 0.1074 k= 0.041655 lr = 0.0000663\n",
      "[2/25][7280/9765] Loss_D: 0.1032 Loss_G: 0.0408 Convergence: 0.1061 k= 0.041667 lr = 0.0000663\n",
      "[2/25][7290/9765] Loss_D: 0.1105 Loss_G: 0.0456 Convergence: 0.1129 k= 0.041668 lr = 0.0000663\n",
      "[2/25][7300/9765] Loss_D: 0.1038 Loss_G: 0.0411 Convergence: 0.1068 k= 0.041659 lr = 0.0000663\n",
      "[2/25][7310/9765] Loss_D: 0.1091 Loss_G: 0.0418 Convergence: 0.1133 k= 0.041671 lr = 0.0000663\n",
      "[2/25][7320/9765] Loss_D: 0.0981 Loss_G: 0.0499 Convergence: 0.1098 k= 0.041645 lr = 0.0000663\n",
      "[2/25][7330/9765] Loss_D: 0.1138 Loss_G: 0.0491 Convergence: 0.1185 k= 0.041610 lr = 0.0000663\n",
      "[2/25][7340/9765] Loss_D: 0.1102 Loss_G: 0.0519 Convergence: 0.1190 k= 0.041580 lr = 0.0000663\n",
      "[2/25][7350/9765] Loss_D: 0.0999 Loss_G: 0.0472 Convergence: 0.1083 k= 0.041581 lr = 0.0000663\n",
      "[2/25][7360/9765] Loss_D: 0.1024 Loss_G: 0.0421 Convergence: 0.1045 k= 0.041584 lr = 0.0000663\n",
      "[2/25][7370/9765] Loss_D: 0.1053 Loss_G: 0.0502 Convergence: 0.1146 k= 0.041546 lr = 0.0000663\n",
      "[2/25][7380/9765] Loss_D: 0.0960 Loss_G: 0.0410 Convergence: 0.0996 k= 0.041558 lr = 0.0000663\n",
      "[2/25][7390/9765] Loss_D: 0.1045 Loss_G: 0.0427 Convergence: 0.1065 k= 0.041571 lr = 0.0000663\n",
      "[2/25][7400/9765] Loss_D: 0.1103 Loss_G: 0.0454 Convergence: 0.1126 k= 0.041568 lr = 0.0000663\n",
      "[2/25][7410/9765] Loss_D: 0.1037 Loss_G: 0.0478 Convergence: 0.1111 k= 0.041565 lr = 0.0000663\n",
      "[2/25][7420/9765] Loss_D: 0.1108 Loss_G: 0.0423 Convergence: 0.1153 k= 0.041565 lr = 0.0000663\n",
      "[2/25][7430/9765] Loss_D: 0.0990 Loss_G: 0.0385 Convergence: 0.1023 k= 0.041571 lr = 0.0000663\n",
      "[2/25][7440/9765] Loss_D: 0.1032 Loss_G: 0.0475 Convergence: 0.1105 k= 0.041594 lr = 0.0000663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][7450/9765] Loss_D: 0.1042 Loss_G: 0.0451 Convergence: 0.1086 k= 0.041582 lr = 0.0000663\n",
      "[2/25][7460/9765] Loss_D: 0.1074 Loss_G: 0.0447 Convergence: 0.1102 k= 0.041570 lr = 0.0000663\n",
      "[2/25][7470/9765] Loss_D: 0.1097 Loss_G: 0.0499 Convergence: 0.1167 k= 0.041554 lr = 0.0000630\n",
      "[2/25][7480/9765] Loss_D: 0.1033 Loss_G: 0.0404 Convergence: 0.1065 k= 0.041566 lr = 0.0000630\n",
      "[2/25][7490/9765] Loss_D: 0.1000 Loss_G: 0.0413 Convergence: 0.1024 k= 0.041574 lr = 0.0000630\n",
      "[2/25][7500/9765] Loss_D: 0.1122 Loss_G: 0.0436 Convergence: 0.1164 k= 0.041556 lr = 0.0000630\n",
      "[2/25][7510/9765] Loss_D: 0.1092 Loss_G: 0.0472 Convergence: 0.1138 k= 0.041562 lr = 0.0000630\n",
      "[2/25][7520/9765] Loss_D: 0.1030 Loss_G: 0.0425 Convergence: 0.1053 k= 0.041551 lr = 0.0000630\n",
      "[2/25][7530/9765] Loss_D: 0.1018 Loss_G: 0.0412 Convergence: 0.1036 k= 0.041544 lr = 0.0000630\n",
      "[2/25][7540/9765] Loss_D: 0.0982 Loss_G: 0.0489 Convergence: 0.1089 k= 0.041540 lr = 0.0000630\n",
      "[2/25][7550/9765] Loss_D: 0.1049 Loss_G: 0.0432 Convergence: 0.1072 k= 0.041542 lr = 0.0000630\n",
      "[2/25][7560/9765] Loss_D: 0.1012 Loss_G: 0.0465 Convergence: 0.1082 k= 0.041532 lr = 0.0000630\n",
      "[2/25][7570/9765] Loss_D: 0.1028 Loss_G: 0.0397 Convergence: 0.1067 k= 0.041526 lr = 0.0000630\n",
      "[2/25][7580/9765] Loss_D: 0.1066 Loss_G: 0.0428 Convergence: 0.1087 k= 0.041552 lr = 0.0000630\n",
      "[2/25][7590/9765] Loss_D: 0.1043 Loss_G: 0.0441 Convergence: 0.1079 k= 0.041557 lr = 0.0000630\n",
      "[2/25][7600/9765] Loss_D: 0.1137 Loss_G: 0.0426 Convergence: 0.1189 k= 0.041557 lr = 0.0000630\n",
      "[2/25][7610/9765] Loss_D: 0.1101 Loss_G: 0.0476 Convergence: 0.1148 k= 0.041540 lr = 0.0000630\n",
      "[2/25][7620/9765] Loss_D: 0.1014 Loss_G: 0.0437 Convergence: 0.1056 k= 0.041541 lr = 0.0000630\n",
      "[2/25][7630/9765] Loss_D: 0.1087 Loss_G: 0.0436 Convergence: 0.1109 k= 0.041551 lr = 0.0000630\n",
      "[2/25][7640/9765] Loss_D: 0.1040 Loss_G: 0.0427 Convergence: 0.1061 k= 0.041522 lr = 0.0000630\n",
      "[2/25][7650/9765] Loss_D: 0.1186 Loss_G: 0.0426 Convergence: 0.1264 k= 0.041512 lr = 0.0000630\n",
      "[2/25][7660/9765] Loss_D: 0.1026 Loss_G: 0.0429 Convergence: 0.1056 k= 0.041496 lr = 0.0000630\n",
      "[2/25][7670/9765] Loss_D: 0.1254 Loss_G: 0.0423 Convergence: 0.1358 k= 0.041508 lr = 0.0000630\n",
      "[2/25][7680/9765] Loss_D: 0.1141 Loss_G: 0.0407 Convergence: 0.1215 k= 0.041537 lr = 0.0000630\n",
      "[2/25][7690/9765] Loss_D: 0.0971 Loss_G: 0.0432 Convergence: 0.1025 k= 0.041541 lr = 0.0000630\n",
      "[2/25][7700/9765] Loss_D: 0.0997 Loss_G: 0.0438 Convergence: 0.1048 k= 0.041524 lr = 0.0000630\n",
      "[2/25][7710/9765] Loss_D: 0.1003 Loss_G: 0.0469 Convergence: 0.1082 k= 0.041524 lr = 0.0000630\n",
      "[2/25][7720/9765] Loss_D: 0.1229 Loss_G: 0.0388 Convergence: 0.1357 k= 0.041526 lr = 0.0000630\n",
      "[2/25][7730/9765] Loss_D: 0.1172 Loss_G: 0.0439 Convergence: 0.1225 k= 0.041513 lr = 0.0000630\n",
      "[2/25][7740/9765] Loss_D: 0.1116 Loss_G: 0.0474 Convergence: 0.1155 k= 0.041488 lr = 0.0000630\n",
      "[2/25][7750/9765] Loss_D: 0.1097 Loss_G: 0.0408 Convergence: 0.1151 k= 0.041500 lr = 0.0000630\n",
      "[2/25][7760/9765] Loss_D: 0.1093 Loss_G: 0.0501 Convergence: 0.1169 k= 0.041503 lr = 0.0000630\n",
      "[2/25][7770/9765] Loss_D: 0.1182 Loss_G: 0.0413 Convergence: 0.1266 k= 0.041510 lr = 0.0000630\n",
      "[2/25][7780/9765] Loss_D: 0.1154 Loss_G: 0.0430 Convergence: 0.1213 k= 0.041538 lr = 0.0000630\n",
      "[2/25][7790/9765] Loss_D: 0.1039 Loss_G: 0.0485 Convergence: 0.1120 k= 0.041506 lr = 0.0000630\n",
      "[2/25][7800/9765] Loss_D: 0.1087 Loss_G: 0.0405 Convergence: 0.1145 k= 0.041513 lr = 0.0000630\n",
      "[2/25][7810/9765] Loss_D: 0.1056 Loss_G: 0.0469 Convergence: 0.1113 k= 0.041519 lr = 0.0000630\n",
      "[2/25][7820/9765] Loss_D: 0.1110 Loss_G: 0.0438 Convergence: 0.1141 k= 0.041503 lr = 0.0000630\n",
      "[2/25][7830/9765] Loss_D: 0.1047 Loss_G: 0.0399 Convergence: 0.1089 k= 0.041501 lr = 0.0000630\n",
      "[2/25][7840/9765] Loss_D: 0.1020 Loss_G: 0.0446 Convergence: 0.1069 k= 0.041468 lr = 0.0000630\n",
      "[2/25][7850/9765] Loss_D: 0.1108 Loss_G: 0.0445 Convergence: 0.1134 k= 0.041453 lr = 0.0000630\n",
      "[2/25][7860/9765] Loss_D: 0.1043 Loss_G: 0.0453 Convergence: 0.1090 k= 0.041432 lr = 0.0000630\n",
      "[2/25][7870/9765] Loss_D: 0.1062 Loss_G: 0.0428 Convergence: 0.1083 k= 0.041419 lr = 0.0000630\n",
      "[2/25][7880/9765] Loss_D: 0.1152 Loss_G: 0.0524 Convergence: 0.1228 k= 0.041385 lr = 0.0000630\n",
      "[2/25][7890/9765] Loss_D: 0.1133 Loss_G: 0.0377 Convergence: 0.1231 k= 0.041372 lr = 0.0000630\n",
      "[2/25][7900/9765] Loss_D: 0.1079 Loss_G: 0.0399 Convergence: 0.1137 k= 0.041395 lr = 0.0000630\n",
      "[2/25][7910/9765] Loss_D: 0.1097 Loss_G: 0.0428 Convergence: 0.1135 k= 0.041343 lr = 0.0000630\n",
      "[2/25][7920/9765] Loss_D: 0.1105 Loss_G: 0.0455 Convergence: 0.1128 k= 0.041345 lr = 0.0000630\n",
      "[2/25][7930/9765] Loss_D: 0.1001 Loss_G: 0.0432 Convergence: 0.1041 k= 0.041346 lr = 0.0000630\n",
      "[2/25][7940/9765] Loss_D: 0.1185 Loss_G: 0.0421 Convergence: 0.1261 k= 0.041355 lr = 0.0000630\n",
      "[2/25][7950/9765] Loss_D: 0.1126 Loss_G: 0.0415 Convergence: 0.1184 k= 0.041342 lr = 0.0000630\n",
      "[2/25][7960/9765] Loss_D: 0.1124 Loss_G: 0.0453 Convergence: 0.1147 k= 0.041336 lr = 0.0000630\n",
      "[2/25][7970/9765] Loss_D: 0.1026 Loss_G: 0.0428 Convergence: 0.1054 k= 0.041320 lr = 0.0000630\n",
      "[2/25][7980/9765] Loss_D: 0.1010 Loss_G: 0.0454 Convergence: 0.1069 k= 0.041304 lr = 0.0000630\n",
      "[2/25][7990/9765] Loss_D: 0.1043 Loss_G: 0.0392 Convergence: 0.1095 k= 0.041303 lr = 0.0000630\n",
      "[2/25][8000/9765] Loss_D: 0.1100 Loss_G: 0.0476 Convergence: 0.1147 k= 0.041316 lr = 0.0000630\n",
      "[2/25][8010/9765] Loss_D: 0.1088 Loss_G: 0.0400 Convergence: 0.1153 k= 0.041312 lr = 0.0000630\n",
      "[2/25][8020/9765] Loss_D: 0.1043 Loss_G: 0.0458 Convergence: 0.1095 k= 0.041308 lr = 0.0000630\n",
      "[2/25][8030/9765] Loss_D: 0.1138 Loss_G: 0.0461 Convergence: 0.1156 k= 0.041332 lr = 0.0000630\n",
      "[2/25][8040/9765] Loss_D: 0.1179 Loss_G: 0.0440 Convergence: 0.1236 k= 0.041341 lr = 0.0000630\n",
      "[2/25][8050/9765] Loss_D: 0.1147 Loss_G: 0.0434 Convergence: 0.1195 k= 0.041357 lr = 0.0000630\n",
      "[2/25][8060/9765] Loss_D: 0.1087 Loss_G: 0.0452 Convergence: 0.1114 k= 0.041351 lr = 0.0000630\n",
      "[2/25][8070/9765] Loss_D: 0.1111 Loss_G: 0.0491 Convergence: 0.1170 k= 0.041337 lr = 0.0000630\n",
      "[2/25][8080/9765] Loss_D: 0.1013 Loss_G: 0.0439 Convergence: 0.1057 k= 0.041338 lr = 0.0000630\n",
      "[2/25][8090/9765] Loss_D: 0.1097 Loss_G: 0.0387 Convergence: 0.1173 k= 0.041357 lr = 0.0000630\n",
      "[2/25][8100/9765] Loss_D: 0.0995 Loss_G: 0.0441 Convergence: 0.1049 k= 0.041343 lr = 0.0000630\n",
      "[2/25][8110/9765] Loss_D: 0.1050 Loss_G: 0.0422 Convergence: 0.1073 k= 0.041346 lr = 0.0000630\n",
      "[2/25][8120/9765] Loss_D: 0.1040 Loss_G: 0.0414 Convergence: 0.1064 k= 0.041356 lr = 0.0000630\n",
      "[2/25][8130/9765] Loss_D: 0.1022 Loss_G: 0.0467 Convergence: 0.1092 k= 0.041350 lr = 0.0000630\n",
      "[2/25][8140/9765] Loss_D: 0.1071 Loss_G: 0.0373 Convergence: 0.1151 k= 0.041349 lr = 0.0000630\n",
      "[2/25][8150/9765] Loss_D: 0.1030 Loss_G: 0.0412 Convergence: 0.1056 k= 0.041355 lr = 0.0000630\n",
      "[2/25][8160/9765] Loss_D: 0.1094 Loss_G: 0.0457 Convergence: 0.1124 k= 0.041346 lr = 0.0000630\n",
      "[2/25][8170/9765] Loss_D: 0.1141 Loss_G: 0.0441 Convergence: 0.1183 k= 0.041348 lr = 0.0000630\n",
      "[2/25][8180/9765] Loss_D: 0.1066 Loss_G: 0.0432 Convergence: 0.1086 k= 0.041365 lr = 0.0000630\n",
      "[2/25][8190/9765] Loss_D: 0.0978 Loss_G: 0.0440 Convergence: 0.1039 k= 0.041332 lr = 0.0000630\n",
      "[2/25][8200/9765] Loss_D: 0.1038 Loss_G: 0.0450 Convergence: 0.1082 k= 0.041353 lr = 0.0000630\n",
      "[2/25][8210/9765] Loss_D: 0.1201 Loss_G: 0.0454 Convergence: 0.1251 k= 0.041339 lr = 0.0000630\n",
      "[2/25][8220/9765] Loss_D: 0.0994 Loss_G: 0.0395 Convergence: 0.1019 k= 0.041337 lr = 0.0000630\n",
      "[2/25][8230/9765] Loss_D: 0.1068 Loss_G: 0.0500 Convergence: 0.1151 k= 0.041324 lr = 0.0000630\n",
      "[2/25][8240/9765] Loss_D: 0.1026 Loss_G: 0.0372 Convergence: 0.1088 k= 0.041321 lr = 0.0000630\n",
      "[2/25][8250/9765] Loss_D: 0.1065 Loss_G: 0.0460 Convergence: 0.1110 k= 0.041316 lr = 0.0000630\n",
      "[2/25][8260/9765] Loss_D: 0.1113 Loss_G: 0.0505 Convergence: 0.1184 k= 0.041292 lr = 0.0000630\n",
      "[2/25][8270/9765] Loss_D: 0.0985 Loss_G: 0.0415 Convergence: 0.1016 k= 0.041280 lr = 0.0000630\n",
      "[2/25][8280/9765] Loss_D: 0.1176 Loss_G: 0.0471 Convergence: 0.1200 k= 0.041305 lr = 0.0000630\n",
      "[2/25][8290/9765] Loss_D: 0.1223 Loss_G: 0.0426 Convergence: 0.1312 k= 0.041302 lr = 0.0000630\n",
      "[2/25][8300/9765] Loss_D: 0.1024 Loss_G: 0.0442 Convergence: 0.1067 k= 0.041280 lr = 0.0000630\n",
      "[2/25][8310/9765] Loss_D: 0.1141 Loss_G: 0.0475 Convergence: 0.1170 k= 0.041279 lr = 0.0000630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][8320/9765] Loss_D: 0.1015 Loss_G: 0.0471 Convergence: 0.1091 k= 0.041256 lr = 0.0000630\n",
      "[2/25][8330/9765] Loss_D: 0.1012 Loss_G: 0.0439 Convergence: 0.1057 k= 0.041253 lr = 0.0000630\n",
      "[2/25][8340/9765] Loss_D: 0.1120 Loss_G: 0.0420 Convergence: 0.1174 k= 0.041232 lr = 0.0000630\n",
      "[2/25][8350/9765] Loss_D: 0.1082 Loss_G: 0.0459 Convergence: 0.1119 k= 0.041224 lr = 0.0000630\n",
      "[2/25][8360/9765] Loss_D: 0.1155 Loss_G: 0.0449 Convergence: 0.1196 k= 0.041201 lr = 0.0000630\n",
      "[2/25][8370/9765] Loss_D: 0.1122 Loss_G: 0.0457 Convergence: 0.1141 k= 0.041189 lr = 0.0000630\n",
      "[2/25][8380/9765] Loss_D: 0.1069 Loss_G: 0.0453 Convergence: 0.1104 k= 0.041170 lr = 0.0000630\n",
      "[2/25][8390/9765] Loss_D: 0.1101 Loss_G: 0.0430 Convergence: 0.1135 k= 0.041164 lr = 0.0000630\n",
      "[2/25][8400/9765] Loss_D: 0.1083 Loss_G: 0.0408 Convergence: 0.1132 k= 0.041148 lr = 0.0000630\n",
      "[2/25][8410/9765] Loss_D: 0.1060 Loss_G: 0.0421 Convergence: 0.1088 k= 0.041169 lr = 0.0000630\n",
      "[2/25][8420/9765] Loss_D: 0.1098 Loss_G: 0.0393 Convergence: 0.1167 k= 0.041163 lr = 0.0000630\n",
      "[2/25][8430/9765] Loss_D: 0.1158 Loss_G: 0.0424 Convergence: 0.1221 k= 0.041161 lr = 0.0000630\n",
      "[2/25][8440/9765] Loss_D: 0.1064 Loss_G: 0.0539 Convergence: 0.1188 k= 0.041153 lr = 0.0000630\n",
      "[2/25][8450/9765] Loss_D: 0.1158 Loss_G: 0.0513 Convergence: 0.1218 k= 0.041162 lr = 0.0000630\n",
      "[2/25][8460/9765] Loss_D: 0.1025 Loss_G: 0.0423 Convergence: 0.1049 k= 0.041143 lr = 0.0000630\n",
      "[2/25][8470/9765] Loss_D: 0.1179 Loss_G: 0.0406 Convergence: 0.1270 k= 0.041151 lr = 0.0000630\n",
      "[2/25][8480/9765] Loss_D: 0.1093 Loss_G: 0.0398 Convergence: 0.1158 k= 0.041170 lr = 0.0000630\n",
      "[2/25][8490/9765] Loss_D: 0.1072 Loss_G: 0.0453 Convergence: 0.1109 k= 0.041190 lr = 0.0000630\n",
      "[2/25][8500/9765] Loss_D: 0.1059 Loss_G: 0.0446 Convergence: 0.1092 k= 0.041191 lr = 0.0000630\n",
      "[2/25][8510/9765] Loss_D: 0.1042 Loss_G: 0.0411 Convergence: 0.1073 k= 0.041161 lr = 0.0000630\n",
      "[2/25][8520/9765] Loss_D: 0.1067 Loss_G: 0.0466 Convergence: 0.1118 k= 0.041142 lr = 0.0000630\n",
      "[2/25][8530/9765] Loss_D: 0.1152 Loss_G: 0.0472 Convergence: 0.1172 k= 0.041169 lr = 0.0000630\n",
      "[2/25][8540/9765] Loss_D: 0.1018 Loss_G: 0.0393 Convergence: 0.1056 k= 0.041173 lr = 0.0000630\n",
      "[2/25][8550/9765] Loss_D: 0.1115 Loss_G: 0.0457 Convergence: 0.1137 k= 0.041178 lr = 0.0000630\n",
      "[2/25][8560/9765] Loss_D: 0.0959 Loss_G: 0.0430 Convergence: 0.1016 k= 0.041169 lr = 0.0000630\n",
      "[2/25][8570/9765] Loss_D: 0.1184 Loss_G: 0.0443 Convergence: 0.1237 k= 0.041154 lr = 0.0000630\n",
      "[2/25][8580/9765] Loss_D: 0.1136 Loss_G: 0.0413 Convergence: 0.1203 k= 0.041179 lr = 0.0000630\n",
      "[2/25][8590/9765] Loss_D: 0.1124 Loss_G: 0.0483 Convergence: 0.1168 k= 0.041182 lr = 0.0000630\n",
      "[2/25][8600/9765] Loss_D: 0.1045 Loss_G: 0.0460 Convergence: 0.1096 k= 0.041173 lr = 0.0000630\n",
      "[2/25][8610/9765] Loss_D: 0.1055 Loss_G: 0.0447 Convergence: 0.1091 k= 0.041166 lr = 0.0000630\n",
      "[2/25][8620/9765] Loss_D: 0.1186 Loss_G: 0.0400 Convergence: 0.1284 k= 0.041189 lr = 0.0000630\n",
      "[2/25][8630/9765] Loss_D: 0.0988 Loss_G: 0.0498 Convergence: 0.1100 k= 0.041189 lr = 0.0000630\n",
      "[2/25][8640/9765] Loss_D: 0.1087 Loss_G: 0.0511 Convergence: 0.1175 k= 0.041170 lr = 0.0000630\n",
      "[2/25][8650/9765] Loss_D: 0.1103 Loss_G: 0.0408 Convergence: 0.1162 k= 0.041157 lr = 0.0000630\n",
      "[2/25][8660/9765] Loss_D: 0.1123 Loss_G: 0.0456 Convergence: 0.1142 k= 0.041169 lr = 0.0000630\n",
      "[2/25][8670/9765] Loss_D: 0.1077 Loss_G: 0.0441 Convergence: 0.1098 k= 0.041161 lr = 0.0000630\n",
      "[2/25][8680/9765] Loss_D: 0.1109 Loss_G: 0.0451 Convergence: 0.1127 k= 0.041151 lr = 0.0000630\n",
      "[2/25][8690/9765] Loss_D: 0.1143 Loss_G: 0.0430 Convergence: 0.1195 k= 0.041147 lr = 0.0000630\n",
      "[2/25][8700/9765] Loss_D: 0.1049 Loss_G: 0.0455 Convergence: 0.1094 k= 0.041166 lr = 0.0000630\n",
      "[2/25][8710/9765] Loss_D: 0.1064 Loss_G: 0.0380 Convergence: 0.1132 k= 0.041135 lr = 0.0000630\n",
      "[2/25][8720/9765] Loss_D: 0.1025 Loss_G: 0.0429 Convergence: 0.1055 k= 0.041146 lr = 0.0000630\n",
      "[2/25][8730/9765] Loss_D: 0.1049 Loss_G: 0.0424 Convergence: 0.1069 k= 0.041156 lr = 0.0000630\n",
      "[2/25][8740/9765] Loss_D: 0.1023 Loss_G: 0.0444 Convergence: 0.1068 k= 0.041158 lr = 0.0000630\n",
      "[2/25][8750/9765] Loss_D: 0.1050 Loss_G: 0.0395 Convergence: 0.1103 k= 0.041168 lr = 0.0000630\n",
      "[2/25][8760/9765] Loss_D: 0.1007 Loss_G: 0.0430 Convergence: 0.1043 k= 0.041166 lr = 0.0000630\n",
      "[2/25][8770/9765] Loss_D: 0.1041 Loss_G: 0.0386 Convergence: 0.1096 k= 0.041212 lr = 0.0000630\n",
      "[2/25][8780/9765] Loss_D: 0.1040 Loss_G: 0.0460 Convergence: 0.1095 k= 0.041122 lr = 0.0000630\n",
      "[2/25][8790/9765] Loss_D: 0.1123 Loss_G: 0.0451 Convergence: 0.1145 k= 0.041132 lr = 0.0000630\n",
      "[2/25][8800/9765] Loss_D: 0.0974 Loss_G: 0.0521 Convergence: 0.1119 k= 0.041115 lr = 0.0000630\n",
      "[2/25][8810/9765] Loss_D: 0.1065 Loss_G: 0.0445 Convergence: 0.1094 k= 0.041103 lr = 0.0000630\n",
      "[2/25][8820/9765] Loss_D: 0.1048 Loss_G: 0.0440 Convergence: 0.1079 k= 0.041109 lr = 0.0000630\n",
      "[2/25][8830/9765] Loss_D: 0.1074 Loss_G: 0.0458 Convergence: 0.1114 k= 0.041106 lr = 0.0000630\n",
      "[2/25][8840/9765] Loss_D: 0.1113 Loss_G: 0.0422 Convergence: 0.1160 k= 0.041117 lr = 0.0000630\n",
      "[2/25][8850/9765] Loss_D: 0.1054 Loss_G: 0.0431 Convergence: 0.1074 k= 0.041116 lr = 0.0000630\n",
      "[2/25][8860/9765] Loss_D: 0.1155 Loss_G: 0.0414 Convergence: 0.1230 k= 0.041127 lr = 0.0000630\n",
      "[2/25][8870/9765] Loss_D: 0.1019 Loss_G: 0.0574 Convergence: 0.1196 k= 0.041113 lr = 0.0000630\n",
      "[2/25][8880/9765] Loss_D: 0.1048 Loss_G: 0.0399 Convergence: 0.1094 k= 0.041118 lr = 0.0000630\n",
      "[2/25][8890/9765] Loss_D: 0.1049 Loss_G: 0.0486 Convergence: 0.1125 k= 0.041132 lr = 0.0000630\n",
      "[2/25][8900/9765] Loss_D: 0.1074 Loss_G: 0.0547 Convergence: 0.1204 k= 0.041112 lr = 0.0000630\n",
      "[2/25][8910/9765] Loss_D: 0.0967 Loss_G: 0.0435 Convergence: 0.1026 k= 0.041099 lr = 0.0000630\n",
      "[2/25][8920/9765] Loss_D: 0.1032 Loss_G: 0.0441 Convergence: 0.1070 k= 0.041117 lr = 0.0000630\n",
      "[2/25][8930/9765] Loss_D: 0.1040 Loss_G: 0.0397 Convergence: 0.1082 k= 0.041137 lr = 0.0000630\n",
      "[2/25][8940/9765] Loss_D: 0.1051 Loss_G: 0.0374 Convergence: 0.1123 k= 0.041133 lr = 0.0000630\n",
      "[2/25][8950/9765] Loss_D: 0.1089 Loss_G: 0.0529 Convergence: 0.1194 k= 0.041088 lr = 0.0000630\n",
      "[2/25][8960/9765] Loss_D: 0.1092 Loss_G: 0.0438 Convergence: 0.1115 k= 0.041071 lr = 0.0000630\n",
      "[2/25][8970/9765] Loss_D: 0.1102 Loss_G: 0.0390 Convergence: 0.1178 k= 0.041061 lr = 0.0000630\n",
      "[2/25][8980/9765] Loss_D: 0.1218 Loss_G: 0.0420 Convergence: 0.1309 k= 0.041069 lr = 0.0000630\n",
      "[2/25][8990/9765] Loss_D: 0.1062 Loss_G: 0.0478 Convergence: 0.1126 k= 0.041055 lr = 0.0000630\n",
      "[2/25][9000/9765] Loss_D: 0.1055 Loss_G: 0.0453 Convergence: 0.1097 k= 0.041049 lr = 0.0000630\n",
      "[2/25][9010/9765] Loss_D: 0.1018 Loss_G: 0.0413 Convergence: 0.1035 k= 0.041047 lr = 0.0000630\n",
      "[2/25][9020/9765] Loss_D: 0.1068 Loss_G: 0.0443 Convergence: 0.1095 k= 0.041038 lr = 0.0000630\n",
      "[2/25][9030/9765] Loss_D: 0.1110 Loss_G: 0.0488 Convergence: 0.1165 k= 0.041019 lr = 0.0000630\n",
      "[2/25][9040/9765] Loss_D: 0.1128 Loss_G: 0.0450 Convergence: 0.1152 k= 0.041028 lr = 0.0000630\n",
      "[2/25][9050/9765] Loss_D: 0.1146 Loss_G: 0.0445 Convergence: 0.1181 k= 0.041003 lr = 0.0000630\n",
      "[2/25][9060/9765] Loss_D: 0.0973 Loss_G: 0.0420 Convergence: 0.1015 k= 0.040996 lr = 0.0000630\n",
      "[2/25][9070/9765] Loss_D: 0.1138 Loss_G: 0.0448 Convergence: 0.1167 k= 0.040980 lr = 0.0000630\n",
      "[2/25][9080/9765] Loss_D: 0.1022 Loss_G: 0.0431 Convergence: 0.1055 k= 0.041014 lr = 0.0000630\n",
      "[2/25][9090/9765] Loss_D: 0.0977 Loss_G: 0.0377 Convergence: 0.1015 k= 0.040998 lr = 0.0000630\n",
      "[2/25][9100/9765] Loss_D: 0.1099 Loss_G: 0.0373 Convergence: 0.1189 k= 0.041026 lr = 0.0000630\n",
      "[2/25][9110/9765] Loss_D: 0.1148 Loss_G: 0.0555 Convergence: 0.1255 k= 0.041026 lr = 0.0000630\n",
      "[2/25][9120/9765] Loss_D: 0.1070 Loss_G: 0.0442 Convergence: 0.1094 k= 0.041029 lr = 0.0000630\n",
      "[2/25][9130/9765] Loss_D: 0.1067 Loss_G: 0.0464 Convergence: 0.1114 k= 0.041034 lr = 0.0000630\n",
      "[2/25][9140/9765] Loss_D: 0.1056 Loss_G: 0.0471 Convergence: 0.1116 k= 0.041006 lr = 0.0000630\n",
      "[2/25][9150/9765] Loss_D: 0.1102 Loss_G: 0.0434 Convergence: 0.1135 k= 0.040957 lr = 0.0000630\n",
      "[2/25][9160/9765] Loss_D: 0.1117 Loss_G: 0.0444 Convergence: 0.1147 k= 0.040958 lr = 0.0000630\n",
      "[2/25][9170/9765] Loss_D: 0.0999 Loss_G: 0.0421 Convergence: 0.1032 k= 0.040936 lr = 0.0000630\n",
      "[2/25][9180/9765] Loss_D: 0.1115 Loss_G: 0.0459 Convergence: 0.1140 k= 0.040930 lr = 0.0000630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/25][9190/9765] Loss_D: 0.1121 Loss_G: 0.0423 Convergence: 0.1170 k= 0.040943 lr = 0.0000630\n",
      "[2/25][9200/9765] Loss_D: 0.1087 Loss_G: 0.0501 Convergence: 0.1165 k= 0.040905 lr = 0.0000630\n",
      "[2/25][9210/9765] Loss_D: 0.0992 Loss_G: 0.0421 Convergence: 0.1026 k= 0.040910 lr = 0.0000630\n",
      "[2/25][9220/9765] Loss_D: 0.1074 Loss_G: 0.0422 Convergence: 0.1106 k= 0.040900 lr = 0.0000630\n",
      "[2/25][9230/9765] Loss_D: 0.1076 Loss_G: 0.0426 Convergence: 0.1105 k= 0.040908 lr = 0.0000630\n",
      "[2/25][9240/9765] Loss_D: 0.1059 Loss_G: 0.0407 Convergence: 0.1104 k= 0.040902 lr = 0.0000630\n",
      "[2/25][9250/9765] Loss_D: 0.1206 Loss_G: 0.0501 Convergence: 0.1234 k= 0.040872 lr = 0.0000630\n",
      "[2/25][9260/9765] Loss_D: 0.1024 Loss_G: 0.0397 Convergence: 0.1062 k= 0.040881 lr = 0.0000630\n",
      "[2/25][9270/9765] Loss_D: 0.0996 Loss_G: 0.0438 Convergence: 0.1048 k= 0.040865 lr = 0.0000630\n",
      "[2/25][9280/9765] Loss_D: 0.1028 Loss_G: 0.0424 Convergence: 0.1051 k= 0.040853 lr = 0.0000630\n",
      "[2/25][9290/9765] Loss_D: 0.1153 Loss_G: 0.0435 Convergence: 0.1204 k= 0.040878 lr = 0.0000630\n",
      "[2/25][9300/9765] Loss_D: 0.1097 Loss_G: 0.0522 Convergence: 0.1191 k= 0.040867 lr = 0.0000630\n",
      "[2/25][9310/9765] Loss_D: 0.1088 Loss_G: 0.0394 Convergence: 0.1151 k= 0.040899 lr = 0.0000630\n",
      "[2/25][9320/9765] Loss_D: 0.1030 Loss_G: 0.0482 Convergence: 0.1111 k= 0.040849 lr = 0.0000630\n",
      "[2/25][9330/9765] Loss_D: 0.1146 Loss_G: 0.0483 Convergence: 0.1183 k= 0.040862 lr = 0.0000630\n",
      "[2/25][9340/9765] Loss_D: 0.1052 Loss_G: 0.0396 Convergence: 0.1100 k= 0.040863 lr = 0.0000630\n",
      "[2/25][9350/9765] Loss_D: 0.1093 Loss_G: 0.0461 Convergence: 0.1127 k= 0.040859 lr = 0.0000630\n",
      "[2/25][9360/9765] Loss_D: 0.1146 Loss_G: 0.0394 Convergence: 0.1234 k= 0.040848 lr = 0.0000630\n",
      "[2/25][9370/9765] Loss_D: 0.1052 Loss_G: 0.0446 Convergence: 0.1088 k= 0.040849 lr = 0.0000630\n",
      "[2/25][9380/9765] Loss_D: 0.1084 Loss_G: 0.0445 Convergence: 0.1109 k= 0.040821 lr = 0.0000630\n",
      "[2/25][9390/9765] Loss_D: 0.1081 Loss_G: 0.0448 Convergence: 0.1107 k= 0.040812 lr = 0.0000630\n",
      "[2/25][9400/9765] Loss_D: 0.1040 Loss_G: 0.0502 Convergence: 0.1137 k= 0.040806 lr = 0.0000630\n",
      "[2/25][9410/9765] Loss_D: 0.1113 Loss_G: 0.0416 Convergence: 0.1166 k= 0.040816 lr = 0.0000630\n",
      "[2/25][9420/9765] Loss_D: 0.0994 Loss_G: 0.0357 Convergence: 0.1057 k= 0.040823 lr = 0.0000630\n",
      "[2/25][9430/9765] Loss_D: 0.0930 Loss_G: 0.0474 Convergence: 0.1044 k= 0.040803 lr = 0.0000630\n",
      "[2/25][9440/9765] Loss_D: 0.1080 Loss_G: 0.0471 Convergence: 0.1130 k= 0.040772 lr = 0.0000630\n",
      "[2/25][9450/9765] Loss_D: 0.1057 Loss_G: 0.0394 Convergence: 0.1109 k= 0.040765 lr = 0.0000630\n",
      "[2/25][9460/9765] Loss_D: 0.1059 Loss_G: 0.0467 Convergence: 0.1115 k= 0.040749 lr = 0.0000630\n",
      "[2/25][9470/9765] Loss_D: 0.1004 Loss_G: 0.0460 Convergence: 0.1073 k= 0.040728 lr = 0.0000630\n",
      "[2/25][9480/9765] Loss_D: 0.0965 Loss_G: 0.0393 Convergence: 0.0983 k= 0.040727 lr = 0.0000630\n",
      "[2/25][9490/9765] Loss_D: 0.1167 Loss_G: 0.0404 Convergence: 0.1252 k= 0.040751 lr = 0.0000630\n",
      "[2/25][9500/9765] Loss_D: 0.1055 Loss_G: 0.0465 Convergence: 0.1109 k= 0.040766 lr = 0.0000630\n",
      "[2/25][9510/9765] Loss_D: 0.1100 Loss_G: 0.0421 Convergence: 0.1144 k= 0.040756 lr = 0.0000630\n",
      "[2/25][9520/9765] Loss_D: 0.1072 Loss_G: 0.0458 Convergence: 0.1112 k= 0.040745 lr = 0.0000630\n",
      "[2/25][9530/9765] Loss_D: 0.1032 Loss_G: 0.0385 Convergence: 0.1082 k= 0.040742 lr = 0.0000630\n",
      "[2/25][9540/9765] Loss_D: 0.1168 Loss_G: 0.0506 Convergence: 0.1218 k= 0.040732 lr = 0.0000630\n",
      "[2/25][9550/9765] Loss_D: 0.1072 Loss_G: 0.0422 Convergence: 0.1102 k= 0.040714 lr = 0.0000630\n",
      "[2/25][9560/9765] Loss_D: 0.1006 Loss_G: 0.0500 Convergence: 0.1114 k= 0.040695 lr = 0.0000630\n",
      "[2/25][9570/9765] Loss_D: 0.1289 Loss_G: 0.0456 Convergence: 0.1372 k= 0.040694 lr = 0.0000630\n",
      "[2/25][9580/9765] Loss_D: 0.1083 Loss_G: 0.0418 Convergence: 0.1121 k= 0.040710 lr = 0.0000630\n",
      "[2/25][9590/9765] Loss_D: 0.1095 Loss_G: 0.0399 Convergence: 0.1156 k= 0.040703 lr = 0.0000630\n",
      "[2/25][9600/9765] Loss_D: 0.1102 Loss_G: 0.0445 Convergence: 0.1122 k= 0.040701 lr = 0.0000630\n",
      "[2/25][9610/9765] Loss_D: 0.1080 Loss_G: 0.0514 Convergence: 0.1172 k= 0.040698 lr = 0.0000630\n",
      "[2/25][9620/9765] Loss_D: 0.1009 Loss_G: 0.0412 Convergence: 0.1028 k= 0.040699 lr = 0.0000630\n",
      "[2/25][9630/9765] Loss_D: 0.1014 Loss_G: 0.0464 Convergence: 0.1083 k= 0.040689 lr = 0.0000630\n",
      "[2/25][9640/9765] Loss_D: 0.1136 Loss_G: 0.0419 Convergence: 0.1195 k= 0.040702 lr = 0.0000630\n",
      "[2/25][9650/9765] Loss_D: 0.1000 Loss_G: 0.0439 Convergence: 0.1051 k= 0.040690 lr = 0.0000630\n",
      "[2/25][9660/9765] Loss_D: 0.1059 Loss_G: 0.0476 Convergence: 0.1122 k= 0.040670 lr = 0.0000630\n",
      "[2/25][9670/9765] Loss_D: 0.1083 Loss_G: 0.0434 Convergence: 0.1104 k= 0.040680 lr = 0.0000630\n",
      "[2/25][9680/9765] Loss_D: 0.1042 Loss_G: 0.0447 Convergence: 0.1082 k= 0.040664 lr = 0.0000630\n",
      "[2/25][9690/9765] Loss_D: 0.0988 Loss_G: 0.0360 Convergence: 0.1042 k= 0.040699 lr = 0.0000630\n",
      "[2/25][9700/9765] Loss_D: 0.1082 Loss_G: 0.0379 Convergence: 0.1160 k= 0.040705 lr = 0.0000630\n",
      "[2/25][9710/9765] Loss_D: 0.1125 Loss_G: 0.0460 Convergence: 0.1146 k= 0.040701 lr = 0.0000630\n",
      "[2/25][9720/9765] Loss_D: 0.0962 Loss_G: 0.0462 Convergence: 0.1051 k= 0.040701 lr = 0.0000630\n",
      "[2/25][9730/9765] Loss_D: 0.1065 Loss_G: 0.0428 Convergence: 0.1085 k= 0.040720 lr = 0.0000630\n",
      "[2/25][9740/9765] Loss_D: 0.0984 Loss_G: 0.0410 Convergence: 0.1012 k= 0.040724 lr = 0.0000630\n",
      "[2/25][9750/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1030 k= 0.040728 lr = 0.0000630\n",
      "[2/25][9760/9765] Loss_D: 0.0990 Loss_G: 0.0428 Convergence: 0.1034 k= 0.040731 lr = 0.0000630\n",
      "[3/25][0/9765] Loss_D: 0.1186 Loss_G: 0.0471 Convergence: 0.1214 k= 0.040739 lr = 0.0000630\n",
      "[3/25][10/9765] Loss_D: 0.1108 Loss_G: 0.0553 Convergence: 0.1228 k= 0.040700 lr = 0.0000630\n",
      "[3/25][20/9765] Loss_D: 0.1103 Loss_G: 0.0415 Convergence: 0.1151 k= 0.040695 lr = 0.0000630\n",
      "[3/25][30/9765] Loss_D: 0.1140 Loss_G: 0.0396 Convergence: 0.1224 k= 0.040699 lr = 0.0000630\n",
      "[3/25][40/9765] Loss_D: 0.0984 Loss_G: 0.0442 Convergence: 0.1043 k= 0.040692 lr = 0.0000630\n",
      "[3/25][50/9765] Loss_D: 0.1097 Loss_G: 0.0410 Convergence: 0.1148 k= 0.040711 lr = 0.0000630\n",
      "[3/25][60/9765] Loss_D: 0.1069 Loss_G: 0.0531 Convergence: 0.1183 k= 0.040707 lr = 0.0000630\n",
      "[3/25][70/9765] Loss_D: 0.1083 Loss_G: 0.0513 Convergence: 0.1173 k= 0.040691 lr = 0.0000630\n",
      "[3/25][80/9765] Loss_D: 0.1188 Loss_G: 0.0474 Convergence: 0.1215 k= 0.040678 lr = 0.0000630\n",
      "[3/25][90/9765] Loss_D: 0.1106 Loss_G: 0.0456 Convergence: 0.1129 k= 0.040677 lr = 0.0000630\n",
      "[3/25][100/9765] Loss_D: 0.1063 Loss_G: 0.0462 Convergence: 0.1111 k= 0.040660 lr = 0.0000630\n",
      "[3/25][110/9765] Loss_D: 0.0955 Loss_G: 0.0453 Convergence: 0.1038 k= 0.040654 lr = 0.0000630\n",
      "[3/25][120/9765] Loss_D: 0.1136 Loss_G: 0.0443 Convergence: 0.1172 k= 0.040642 lr = 0.0000630\n",
      "[3/25][130/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1030 k= 0.040655 lr = 0.0000630\n",
      "[3/25][140/9765] Loss_D: 0.1083 Loss_G: 0.0500 Convergence: 0.1162 k= 0.040630 lr = 0.0000630\n",
      "[3/25][150/9765] Loss_D: 0.1019 Loss_G: 0.0390 Convergence: 0.1064 k= 0.040619 lr = 0.0000630\n",
      "[3/25][160/9765] Loss_D: 0.1027 Loss_G: 0.0440 Convergence: 0.1068 k= 0.040614 lr = 0.0000630\n",
      "[3/25][170/9765] Loss_D: 0.1137 Loss_G: 0.0531 Convergence: 0.1223 k= 0.040582 lr = 0.0000630\n",
      "[3/25][180/9765] Loss_D: 0.1062 Loss_G: 0.0429 Convergence: 0.1080 k= 0.040593 lr = 0.0000630\n",
      "[3/25][190/9765] Loss_D: 0.1141 Loss_G: 0.0446 Convergence: 0.1177 k= 0.040587 lr = 0.0000630\n",
      "[3/25][200/9765] Loss_D: 0.1075 Loss_G: 0.0499 Convergence: 0.1155 k= 0.040581 lr = 0.0000630\n",
      "[3/25][210/9765] Loss_D: 0.1016 Loss_G: 0.0458 Convergence: 0.1078 k= 0.040562 lr = 0.0000630\n",
      "[3/25][220/9765] Loss_D: 0.1118 Loss_G: 0.0454 Convergence: 0.1142 k= 0.040544 lr = 0.0000630\n",
      "[3/25][230/9765] Loss_D: 0.1081 Loss_G: 0.0431 Convergence: 0.1108 k= 0.040515 lr = 0.0000630\n",
      "[3/25][240/9765] Loss_D: 0.1073 Loss_G: 0.0450 Convergence: 0.1105 k= 0.040499 lr = 0.0000630\n",
      "[3/25][250/9765] Loss_D: 0.1068 Loss_G: 0.0457 Convergence: 0.1108 k= 0.040475 lr = 0.0000630\n",
      "[3/25][260/9765] Loss_D: 0.1060 Loss_G: 0.0424 Convergence: 0.1081 k= 0.040480 lr = 0.0000630\n",
      "[3/25][270/9765] Loss_D: 0.1081 Loss_G: 0.0407 Convergence: 0.1128 k= 0.040476 lr = 0.0000630\n",
      "[3/25][280/9765] Loss_D: 0.1202 Loss_G: 0.0483 Convergence: 0.1225 k= 0.040478 lr = 0.0000630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][290/9765] Loss_D: 0.1110 Loss_G: 0.0483 Convergence: 0.1160 k= 0.040453 lr = 0.0000630\n",
      "[3/25][300/9765] Loss_D: 0.1183 Loss_G: 0.0461 Convergence: 0.1220 k= 0.040411 lr = 0.0000630\n",
      "[3/25][310/9765] Loss_D: 0.1205 Loss_G: 0.0404 Convergence: 0.1304 k= 0.040421 lr = 0.0000630\n",
      "[3/25][320/9765] Loss_D: 0.1026 Loss_G: 0.0409 Convergence: 0.1053 k= 0.040418 lr = 0.0000630\n",
      "[3/25][330/9765] Loss_D: 0.1019 Loss_G: 0.0405 Convergence: 0.1046 k= 0.040422 lr = 0.0000630\n",
      "[3/25][340/9765] Loss_D: 0.1048 Loss_G: 0.0454 Convergence: 0.1094 k= 0.040389 lr = 0.0000630\n",
      "[3/25][350/9765] Loss_D: 0.1120 Loss_G: 0.0442 Convergence: 0.1151 k= 0.040375 lr = 0.0000630\n",
      "[3/25][360/9765] Loss_D: 0.1044 Loss_G: 0.0437 Convergence: 0.1073 k= 0.040378 lr = 0.0000630\n",
      "[3/25][370/9765] Loss_D: 0.1112 Loss_G: 0.0433 Convergence: 0.1150 k= 0.040389 lr = 0.0000630\n",
      "[3/25][380/9765] Loss_D: 0.1122 Loss_G: 0.0482 Convergence: 0.1165 k= 0.040368 lr = 0.0000630\n",
      "[3/25][390/9765] Loss_D: 0.1035 Loss_G: 0.0456 Convergence: 0.1088 k= 0.040365 lr = 0.0000630\n",
      "[3/25][400/9765] Loss_D: 0.1001 Loss_G: 0.0456 Convergence: 0.1068 k= 0.040335 lr = 0.0000630\n",
      "[3/25][410/9765] Loss_D: 0.1071 Loss_G: 0.0479 Convergence: 0.1132 k= 0.040330 lr = 0.0000630\n",
      "[3/25][420/9765] Loss_D: 0.1164 Loss_G: 0.0529 Convergence: 0.1241 k= 0.040299 lr = 0.0000630\n",
      "[3/25][430/9765] Loss_D: 0.1078 Loss_G: 0.0451 Convergence: 0.1109 k= 0.040277 lr = 0.0000630\n",
      "[3/25][440/9765] Loss_D: 0.1184 Loss_G: 0.0457 Convergence: 0.1225 k= 0.040288 lr = 0.0000630\n",
      "[3/25][450/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.1002 k= 0.040275 lr = 0.0000630\n",
      "[3/25][460/9765] Loss_D: 0.1085 Loss_G: 0.0484 Convergence: 0.1145 k= 0.040272 lr = 0.0000630\n",
      "[3/25][470/9765] Loss_D: 0.0907 Loss_G: 0.0426 Convergence: 0.0980 k= 0.040294 lr = 0.0000630\n",
      "[3/25][480/9765] Loss_D: 0.1010 Loss_G: 0.0411 Convergence: 0.1027 k= 0.040312 lr = 0.0000630\n",
      "[3/25][490/9765] Loss_D: 0.1046 Loss_G: 0.0437 Convergence: 0.1075 k= 0.040322 lr = 0.0000630\n",
      "[3/25][500/9765] Loss_D: 0.0999 Loss_G: 0.0414 Convergence: 0.1022 k= 0.040337 lr = 0.0000630\n",
      "[3/25][510/9765] Loss_D: 0.1122 Loss_G: 0.0467 Convergence: 0.1150 k= 0.040356 lr = 0.0000630\n",
      "[3/25][520/9765] Loss_D: 0.1049 Loss_G: 0.0464 Convergence: 0.1105 k= 0.040339 lr = 0.0000630\n",
      "[3/25][530/9765] Loss_D: 0.1107 Loss_G: 0.0400 Convergence: 0.1173 k= 0.040341 lr = 0.0000630\n",
      "[3/25][540/9765] Loss_D: 0.1067 Loss_G: 0.0444 Convergence: 0.1095 k= 0.040351 lr = 0.0000630\n",
      "[3/25][550/9765] Loss_D: 0.1074 Loss_G: 0.0423 Convergence: 0.1103 k= 0.040344 lr = 0.0000630\n",
      "[3/25][560/9765] Loss_D: 0.1091 Loss_G: 0.0470 Convergence: 0.1134 k= 0.040338 lr = 0.0000630\n",
      "[3/25][570/9765] Loss_D: 0.1070 Loss_G: 0.0385 Convergence: 0.1138 k= 0.040340 lr = 0.0000630\n",
      "[3/25][580/9765] Loss_D: 0.1112 Loss_G: 0.0451 Convergence: 0.1130 k= 0.040349 lr = 0.0000630\n",
      "[3/25][590/9765] Loss_D: 0.1098 Loss_G: 0.0425 Convergence: 0.1137 k= 0.040347 lr = 0.0000630\n",
      "[3/25][600/9765] Loss_D: 0.1091 Loss_G: 0.0454 Convergence: 0.1121 k= 0.040332 lr = 0.0000630\n",
      "[3/25][610/9765] Loss_D: 0.1012 Loss_G: 0.0376 Convergence: 0.1063 k= 0.040344 lr = 0.0000630\n",
      "[3/25][620/9765] Loss_D: 0.1067 Loss_G: 0.0435 Convergence: 0.1086 k= 0.040336 lr = 0.0000630\n",
      "[3/25][630/9765] Loss_D: 0.1173 Loss_G: 0.0416 Convergence: 0.1248 k= 0.040334 lr = 0.0000630\n",
      "[3/25][640/9765] Loss_D: 0.0941 Loss_G: 0.0391 Convergence: 0.0965 k= 0.040336 lr = 0.0000630\n",
      "[3/25][650/9765] Loss_D: 0.1101 Loss_G: 0.0410 Convergence: 0.1154 k= 0.040349 lr = 0.0000630\n",
      "[3/25][660/9765] Loss_D: 0.1065 Loss_G: 0.0446 Convergence: 0.1095 k= 0.040354 lr = 0.0000630\n",
      "[3/25][670/9765] Loss_D: 0.1007 Loss_G: 0.0396 Convergence: 0.1037 k= 0.040363 lr = 0.0000630\n",
      "[3/25][680/9765] Loss_D: 0.1059 Loss_G: 0.0422 Convergence: 0.1086 k= 0.040353 lr = 0.0000630\n",
      "[3/25][690/9765] Loss_D: 0.1067 Loss_G: 0.0475 Convergence: 0.1126 k= 0.040341 lr = 0.0000630\n",
      "[3/25][700/9765] Loss_D: 0.1044 Loss_G: 0.0422 Convergence: 0.1063 k= 0.040296 lr = 0.0000630\n",
      "[3/25][710/9765] Loss_D: 0.1090 Loss_G: 0.0432 Convergence: 0.1119 k= 0.040294 lr = 0.0000599\n",
      "[3/25][720/9765] Loss_D: 0.1036 Loss_G: 0.0458 Convergence: 0.1090 k= 0.040296 lr = 0.0000599\n",
      "[3/25][730/9765] Loss_D: 0.0995 Loss_G: 0.0425 Convergence: 0.1033 k= 0.040271 lr = 0.0000599\n",
      "[3/25][740/9765] Loss_D: 0.1056 Loss_G: 0.0449 Convergence: 0.1092 k= 0.040269 lr = 0.0000599\n",
      "[3/25][750/9765] Loss_D: 0.1088 Loss_G: 0.0457 Convergence: 0.1120 k= 0.040260 lr = 0.0000599\n",
      "[3/25][760/9765] Loss_D: 0.0959 Loss_G: 0.0441 Convergence: 0.1027 k= 0.040241 lr = 0.0000599\n",
      "[3/25][770/9765] Loss_D: 0.1130 Loss_G: 0.0428 Convergence: 0.1178 k= 0.040238 lr = 0.0000599\n",
      "[3/25][780/9765] Loss_D: 0.0969 Loss_G: 0.0486 Convergence: 0.1077 k= 0.040210 lr = 0.0000599\n",
      "[3/25][790/9765] Loss_D: 0.1015 Loss_G: 0.0399 Convergence: 0.1047 k= 0.040196 lr = 0.0000599\n",
      "[3/25][800/9765] Loss_D: 0.1159 Loss_G: 0.0468 Convergence: 0.1183 k= 0.040195 lr = 0.0000599\n",
      "[3/25][810/9765] Loss_D: 0.1019 Loss_G: 0.0398 Convergence: 0.1053 k= 0.040164 lr = 0.0000599\n",
      "[3/25][820/9765] Loss_D: 0.1096 Loss_G: 0.0514 Convergence: 0.1183 k= 0.040140 lr = 0.0000599\n",
      "[3/25][830/9765] Loss_D: 0.1014 Loss_G: 0.0398 Convergence: 0.1046 k= 0.040136 lr = 0.0000599\n",
      "[3/25][840/9765] Loss_D: 0.0980 Loss_G: 0.0421 Convergence: 0.1019 k= 0.040103 lr = 0.0000599\n",
      "[3/25][850/9765] Loss_D: 0.1007 Loss_G: 0.0392 Convergence: 0.1040 k= 0.040098 lr = 0.0000599\n",
      "[3/25][860/9765] Loss_D: 0.1006 Loss_G: 0.0446 Convergence: 0.1059 k= 0.040104 lr = 0.0000599\n",
      "[3/25][870/9765] Loss_D: 0.1123 Loss_G: 0.0401 Convergence: 0.1194 k= 0.040122 lr = 0.0000599\n",
      "[3/25][880/9765] Loss_D: 0.1061 Loss_G: 0.0437 Convergence: 0.1084 k= 0.040121 lr = 0.0000599\n",
      "[3/25][890/9765] Loss_D: 0.1115 Loss_G: 0.0490 Convergence: 0.1170 k= 0.040106 lr = 0.0000599\n",
      "[3/25][900/9765] Loss_D: 0.0956 Loss_G: 0.0505 Convergence: 0.1089 k= 0.040071 lr = 0.0000599\n",
      "[3/25][910/9765] Loss_D: 0.1081 Loss_G: 0.0444 Convergence: 0.1102 k= 0.040074 lr = 0.0000599\n",
      "[3/25][920/9765] Loss_D: 0.1087 Loss_G: 0.0542 Convergence: 0.1206 k= 0.040057 lr = 0.0000599\n",
      "[3/25][930/9765] Loss_D: 0.1014 Loss_G: 0.0410 Convergence: 0.1031 k= 0.040063 lr = 0.0000599\n",
      "[3/25][940/9765] Loss_D: 0.1032 Loss_G: 0.0409 Convergence: 0.1059 k= 0.040057 lr = 0.0000599\n",
      "[3/25][950/9765] Loss_D: 0.1075 Loss_G: 0.0415 Convergence: 0.1112 k= 0.040059 lr = 0.0000599\n",
      "[3/25][960/9765] Loss_D: 0.1100 Loss_G: 0.0552 Convergence: 0.1222 k= 0.040048 lr = 0.0000599\n",
      "[3/25][970/9765] Loss_D: 0.1080 Loss_G: 0.0378 Convergence: 0.1156 k= 0.040030 lr = 0.0000599\n",
      "[3/25][980/9765] Loss_D: 0.1024 Loss_G: 0.0396 Convergence: 0.1060 k= 0.040039 lr = 0.0000599\n",
      "[3/25][990/9765] Loss_D: 0.1091 Loss_G: 0.0442 Convergence: 0.1109 k= 0.040039 lr = 0.0000599\n",
      "[3/25][1000/9765] Loss_D: 0.1127 Loss_G: 0.0405 Convergence: 0.1197 k= 0.040052 lr = 0.0000599\n",
      "[3/25][1010/9765] Loss_D: 0.1108 Loss_G: 0.0421 Convergence: 0.1153 k= 0.040070 lr = 0.0000599\n",
      "[3/25][1020/9765] Loss_D: 0.1060 Loss_G: 0.0441 Convergence: 0.1088 k= 0.040064 lr = 0.0000599\n",
      "[3/25][1030/9765] Loss_D: 0.0965 Loss_G: 0.0405 Convergence: 0.0995 k= 0.040067 lr = 0.0000599\n",
      "[3/25][1040/9765] Loss_D: 0.1113 Loss_G: 0.0387 Convergence: 0.1193 k= 0.040090 lr = 0.0000599\n",
      "[3/25][1050/9765] Loss_D: 0.1114 Loss_G: 0.0500 Convergence: 0.1179 k= 0.040102 lr = 0.0000599\n",
      "[3/25][1060/9765] Loss_D: 0.0943 Loss_G: 0.0407 Convergence: 0.0982 k= 0.040098 lr = 0.0000599\n",
      "[3/25][1070/9765] Loss_D: 0.1130 Loss_G: 0.0497 Convergence: 0.1187 k= 0.040072 lr = 0.0000599\n",
      "[3/25][1080/9765] Loss_D: 0.1069 Loss_G: 0.0423 Convergence: 0.1095 k= 0.040060 lr = 0.0000599\n",
      "[3/25][1090/9765] Loss_D: 0.1116 Loss_G: 0.0428 Convergence: 0.1164 k= 0.040037 lr = 0.0000599\n",
      "[3/25][1100/9765] Loss_D: 0.1060 Loss_G: 0.0422 Convergence: 0.1087 k= 0.040040 lr = 0.0000599\n",
      "[3/25][1110/9765] Loss_D: 0.1045 Loss_G: 0.0466 Convergence: 0.1103 k= 0.040003 lr = 0.0000599\n",
      "[3/25][1120/9765] Loss_D: 0.1055 Loss_G: 0.0427 Convergence: 0.1072 k= 0.040033 lr = 0.0000599\n",
      "[3/25][1130/9765] Loss_D: 0.1272 Loss_G: 0.0425 Convergence: 0.1380 k= 0.040035 lr = 0.0000599\n",
      "[3/25][1140/9765] Loss_D: 0.1053 Loss_G: 0.0507 Convergence: 0.1150 k= 0.039999 lr = 0.0000599\n",
      "[3/25][1150/9765] Loss_D: 0.1055 Loss_G: 0.0387 Convergence: 0.1113 k= 0.040015 lr = 0.0000599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][1160/9765] Loss_D: 0.1000 Loss_G: 0.0405 Convergence: 0.1020 k= 0.040009 lr = 0.0000599\n",
      "[3/25][1170/9765] Loss_D: 0.1119 Loss_G: 0.0415 Convergence: 0.1174 k= 0.040015 lr = 0.0000599\n",
      "[3/25][1180/9765] Loss_D: 0.1053 Loss_G: 0.0424 Convergence: 0.1076 k= 0.040001 lr = 0.0000599\n",
      "[3/25][1190/9765] Loss_D: 0.1085 Loss_G: 0.0439 Convergence: 0.1101 k= 0.040020 lr = 0.0000599\n",
      "[3/25][1200/9765] Loss_D: 0.1051 Loss_G: 0.0420 Convergence: 0.1076 k= 0.040000 lr = 0.0000599\n",
      "[3/25][1210/9765] Loss_D: 0.1055 Loss_G: 0.0401 Convergence: 0.1097 k= 0.040004 lr = 0.0000599\n",
      "[3/25][1220/9765] Loss_D: 0.0993 Loss_G: 0.0487 Convergence: 0.1094 k= 0.039994 lr = 0.0000599\n",
      "[3/25][1230/9765] Loss_D: 0.1107 Loss_G: 0.0419 Convergence: 0.1154 k= 0.039997 lr = 0.0000599\n",
      "[3/25][1240/9765] Loss_D: 0.1099 Loss_G: 0.0437 Convergence: 0.1124 k= 0.039989 lr = 0.0000599\n",
      "[3/25][1250/9765] Loss_D: 0.1086 Loss_G: 0.0464 Convergence: 0.1127 k= 0.039960 lr = 0.0000599\n",
      "[3/25][1260/9765] Loss_D: 0.0950 Loss_G: 0.0429 Convergence: 0.1010 k= 0.039947 lr = 0.0000599\n",
      "[3/25][1270/9765] Loss_D: 0.1051 Loss_G: 0.0506 Convergence: 0.1148 k= 0.039923 lr = 0.0000599\n",
      "[3/25][1280/9765] Loss_D: 0.1073 Loss_G: 0.0433 Convergence: 0.1093 k= 0.039913 lr = 0.0000599\n",
      "[3/25][1290/9765] Loss_D: 0.0982 Loss_G: 0.0484 Convergence: 0.1084 k= 0.039895 lr = 0.0000599\n",
      "[3/25][1300/9765] Loss_D: 0.1061 Loss_G: 0.0425 Convergence: 0.1085 k= 0.039892 lr = 0.0000599\n",
      "[3/25][1310/9765] Loss_D: 0.1169 Loss_G: 0.0521 Convergence: 0.1233 k= 0.039903 lr = 0.0000599\n",
      "[3/25][1320/9765] Loss_D: 0.1059 Loss_G: 0.0418 Convergence: 0.1086 k= 0.039877 lr = 0.0000599\n",
      "[3/25][1330/9765] Loss_D: 0.1089 Loss_G: 0.0384 Convergence: 0.1161 k= 0.039870 lr = 0.0000599\n",
      "[3/25][1340/9765] Loss_D: 0.1051 Loss_G: 0.0419 Convergence: 0.1075 k= 0.039892 lr = 0.0000599\n",
      "[3/25][1350/9765] Loss_D: 0.1234 Loss_G: 0.0384 Convergence: 0.1363 k= 0.039879 lr = 0.0000599\n",
      "[3/25][1360/9765] Loss_D: 0.1087 Loss_G: 0.0426 Convergence: 0.1116 k= 0.039891 lr = 0.0000599\n",
      "[3/25][1370/9765] Loss_D: 0.1050 Loss_G: 0.0448 Convergence: 0.1088 k= 0.039892 lr = 0.0000599\n",
      "[3/25][1380/9765] Loss_D: 0.1076 Loss_G: 0.0445 Convergence: 0.1102 k= 0.039894 lr = 0.0000599\n",
      "[3/25][1390/9765] Loss_D: 0.1094 Loss_G: 0.0418 Convergence: 0.1137 k= 0.039911 lr = 0.0000599\n",
      "[3/25][1400/9765] Loss_D: 0.1122 Loss_G: 0.0465 Convergence: 0.1149 k= 0.039909 lr = 0.0000599\n",
      "[3/25][1410/9765] Loss_D: 0.1002 Loss_G: 0.0470 Convergence: 0.1080 k= 0.039901 lr = 0.0000599\n",
      "[3/25][1420/9765] Loss_D: 0.1063 Loss_G: 0.0482 Convergence: 0.1131 k= 0.039885 lr = 0.0000599\n",
      "[3/25][1430/9765] Loss_D: 0.1099 Loss_G: 0.0410 Convergence: 0.1152 k= 0.039917 lr = 0.0000599\n",
      "[3/25][1440/9765] Loss_D: 0.1045 Loss_G: 0.0463 Convergence: 0.1100 k= 0.039925 lr = 0.0000599\n",
      "[3/25][1450/9765] Loss_D: 0.1099 Loss_G: 0.0413 Convergence: 0.1152 k= 0.039896 lr = 0.0000599\n",
      "[3/25][1460/9765] Loss_D: 0.1119 Loss_G: 0.0397 Convergence: 0.1191 k= 0.039903 lr = 0.0000599\n",
      "[3/25][1470/9765] Loss_D: 0.1027 Loss_G: 0.0437 Convergence: 0.1063 k= 0.039906 lr = 0.0000599\n",
      "[3/25][1480/9765] Loss_D: 0.1106 Loss_G: 0.0448 Convergence: 0.1122 k= 0.039901 lr = 0.0000599\n",
      "[3/25][1490/9765] Loss_D: 0.1102 Loss_G: 0.0439 Convergence: 0.1126 k= 0.039904 lr = 0.0000599\n",
      "[3/25][1500/9765] Loss_D: 0.1149 Loss_G: 0.0501 Convergence: 0.1201 k= 0.039895 lr = 0.0000599\n",
      "[3/25][1510/9765] Loss_D: 0.1034 Loss_G: 0.0478 Convergence: 0.1110 k= 0.039863 lr = 0.0000599\n",
      "[3/25][1520/9765] Loss_D: 0.1054 Loss_G: 0.0418 Convergence: 0.1077 k= 0.039869 lr = 0.0000599\n",
      "[3/25][1530/9765] Loss_D: 0.1135 Loss_G: 0.0382 Convergence: 0.1231 k= 0.039878 lr = 0.0000599\n",
      "[3/25][1540/9765] Loss_D: 0.1045 Loss_G: 0.0398 Convergence: 0.1088 k= 0.039881 lr = 0.0000599\n",
      "[3/25][1550/9765] Loss_D: 0.1190 Loss_G: 0.0468 Convergence: 0.1221 k= 0.039883 lr = 0.0000599\n",
      "[3/25][1560/9765] Loss_D: 0.1088 Loss_G: 0.0494 Convergence: 0.1158 k= 0.039851 lr = 0.0000599\n",
      "[3/25][1570/9765] Loss_D: 0.0989 Loss_G: 0.0449 Convergence: 0.1053 k= 0.039826 lr = 0.0000599\n",
      "[3/25][1580/9765] Loss_D: 0.1031 Loss_G: 0.0414 Convergence: 0.1052 k= 0.039844 lr = 0.0000599\n",
      "[3/25][1590/9765] Loss_D: 0.1057 Loss_G: 0.0470 Convergence: 0.1115 k= 0.039823 lr = 0.0000599\n",
      "[3/25][1600/9765] Loss_D: 0.1052 Loss_G: 0.0433 Convergence: 0.1074 k= 0.039835 lr = 0.0000599\n",
      "[3/25][1610/9765] Loss_D: 0.1055 Loss_G: 0.0509 Convergence: 0.1153 k= 0.039813 lr = 0.0000599\n",
      "[3/25][1620/9765] Loss_D: 0.1113 Loss_G: 0.0388 Convergence: 0.1197 k= 0.039811 lr = 0.0000599\n",
      "[3/25][1630/9765] Loss_D: 0.1084 Loss_G: 0.0483 Convergence: 0.1144 k= 0.039821 lr = 0.0000599\n",
      "[3/25][1640/9765] Loss_D: 0.1006 Loss_G: 0.0480 Convergence: 0.1094 k= 0.039781 lr = 0.0000599\n",
      "[3/25][1650/9765] Loss_D: 0.1064 Loss_G: 0.0453 Convergence: 0.1102 k= 0.039772 lr = 0.0000599\n",
      "[3/25][1660/9765] Loss_D: 0.1175 Loss_G: 0.0436 Convergence: 0.1231 k= 0.039767 lr = 0.0000599\n",
      "[3/25][1670/9765] Loss_D: 0.0960 Loss_G: 0.0404 Convergence: 0.0990 k= 0.039773 lr = 0.0000599\n",
      "[3/25][1680/9765] Loss_D: 0.1058 Loss_G: 0.0400 Convergence: 0.1102 k= 0.039766 lr = 0.0000599\n",
      "[3/25][1690/9765] Loss_D: 0.1080 Loss_G: 0.0493 Convergence: 0.1152 k= 0.039752 lr = 0.0000599\n",
      "[3/25][1700/9765] Loss_D: 0.1067 Loss_G: 0.0452 Convergence: 0.1102 k= 0.039746 lr = 0.0000599\n",
      "[3/25][1710/9765] Loss_D: 0.1118 Loss_G: 0.0401 Convergence: 0.1187 k= 0.039762 lr = 0.0000599\n",
      "[3/25][1720/9765] Loss_D: 0.1080 Loss_G: 0.0449 Convergence: 0.1108 k= 0.039753 lr = 0.0000599\n",
      "[3/25][1730/9765] Loss_D: 0.1075 Loss_G: 0.0474 Convergence: 0.1129 k= 0.039767 lr = 0.0000599\n",
      "[3/25][1740/9765] Loss_D: 0.1048 Loss_G: 0.0473 Convergence: 0.1113 k= 0.039768 lr = 0.0000599\n",
      "[3/25][1750/9765] Loss_D: 0.1181 Loss_G: 0.0473 Convergence: 0.1206 k= 0.039775 lr = 0.0000599\n",
      "[3/25][1760/9765] Loss_D: 0.1058 Loss_G: 0.0421 Convergence: 0.1082 k= 0.039774 lr = 0.0000599\n",
      "[3/25][1770/9765] Loss_D: 0.1059 Loss_G: 0.0465 Convergence: 0.1110 k= 0.039748 lr = 0.0000599\n",
      "[3/25][1780/9765] Loss_D: 0.1032 Loss_G: 0.0456 Convergence: 0.1086 k= 0.039748 lr = 0.0000599\n",
      "[3/25][1790/9765] Loss_D: 0.1043 Loss_G: 0.0429 Convergence: 0.1066 k= 0.039747 lr = 0.0000599\n",
      "[3/25][1800/9765] Loss_D: 0.0985 Loss_G: 0.0406 Convergence: 0.1008 k= 0.039739 lr = 0.0000599\n",
      "[3/25][1810/9765] Loss_D: 0.1040 Loss_G: 0.0443 Convergence: 0.1077 k= 0.039735 lr = 0.0000599\n",
      "[3/25][1820/9765] Loss_D: 0.0998 Loss_G: 0.0416 Convergence: 0.1025 k= 0.039719 lr = 0.0000599\n",
      "[3/25][1830/9765] Loss_D: 0.0973 Loss_G: 0.0393 Convergence: 0.0990 k= 0.039749 lr = 0.0000599\n",
      "[3/25][1840/9765] Loss_D: 0.1069 Loss_G: 0.0428 Convergence: 0.1098 k= 0.039712 lr = 0.0000599\n",
      "[3/25][1850/9765] Loss_D: 0.1085 Loss_G: 0.0382 Convergence: 0.1160 k= 0.039701 lr = 0.0000599\n",
      "[3/25][1860/9765] Loss_D: 0.1052 Loss_G: 0.0433 Convergence: 0.1074 k= 0.039712 lr = 0.0000599\n",
      "[3/25][1870/9765] Loss_D: 0.1002 Loss_G: 0.0443 Convergence: 0.1054 k= 0.039668 lr = 0.0000599\n",
      "[3/25][1880/9765] Loss_D: 0.1057 Loss_G: 0.0533 Convergence: 0.1177 k= 0.039700 lr = 0.0000599\n",
      "[3/25][1890/9765] Loss_D: 0.1006 Loss_G: 0.0421 Convergence: 0.1035 k= 0.039672 lr = 0.0000599\n",
      "[3/25][1900/9765] Loss_D: 0.1081 Loss_G: 0.0403 Convergence: 0.1131 k= 0.039685 lr = 0.0000599\n",
      "[3/25][1910/9765] Loss_D: 0.0993 Loss_G: 0.0458 Convergence: 0.1065 k= 0.039648 lr = 0.0000599\n",
      "[3/25][1920/9765] Loss_D: 0.1032 Loss_G: 0.0435 Convergence: 0.1064 k= 0.039625 lr = 0.0000599\n",
      "[3/25][1930/9765] Loss_D: 0.1047 Loss_G: 0.0452 Convergence: 0.1091 k= 0.039601 lr = 0.0000599\n",
      "[3/25][1940/9765] Loss_D: 0.1046 Loss_G: 0.0491 Convergence: 0.1129 k= 0.039570 lr = 0.0000599\n",
      "[3/25][1950/9765] Loss_D: 0.1057 Loss_G: 0.0445 Convergence: 0.1089 k= 0.039574 lr = 0.0000599\n",
      "[3/25][1960/9765] Loss_D: 0.1091 Loss_G: 0.0472 Convergence: 0.1137 k= 0.039535 lr = 0.0000599\n",
      "[3/25][1970/9765] Loss_D: 0.1138 Loss_G: 0.0441 Convergence: 0.1174 k= 0.039520 lr = 0.0000599\n",
      "[3/25][1980/9765] Loss_D: 0.0998 Loss_G: 0.0421 Convergence: 0.1030 k= 0.039509 lr = 0.0000599\n",
      "[3/25][1990/9765] Loss_D: 0.1065 Loss_G: 0.0447 Convergence: 0.1099 k= 0.039492 lr = 0.0000599\n",
      "[3/25][2000/9765] Loss_D: 0.1076 Loss_G: 0.0399 Convergence: 0.1131 k= 0.039493 lr = 0.0000599\n",
      "[3/25][2010/9765] Loss_D: 0.1183 Loss_G: 0.0456 Convergence: 0.1226 k= 0.039488 lr = 0.0000599\n",
      "[3/25][2020/9765] Loss_D: 0.1062 Loss_G: 0.0453 Convergence: 0.1099 k= 0.039485 lr = 0.0000599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][2030/9765] Loss_D: 0.0972 Loss_G: 0.0449 Convergence: 0.1043 k= 0.039475 lr = 0.0000599\n",
      "[3/25][2040/9765] Loss_D: 0.1039 Loss_G: 0.0462 Convergence: 0.1096 k= 0.039449 lr = 0.0000599\n",
      "[3/25][2050/9765] Loss_D: 0.1082 Loss_G: 0.0423 Convergence: 0.1115 k= 0.039435 lr = 0.0000599\n",
      "[3/25][2060/9765] Loss_D: 0.1192 Loss_G: 0.0441 Convergence: 0.1252 k= 0.039438 lr = 0.0000599\n",
      "[3/25][2070/9765] Loss_D: 0.1049 Loss_G: 0.0473 Convergence: 0.1112 k= 0.039434 lr = 0.0000599\n",
      "[3/25][2080/9765] Loss_D: 0.1158 Loss_G: 0.0406 Convergence: 0.1237 k= 0.039449 lr = 0.0000599\n",
      "[3/25][2090/9765] Loss_D: 0.1136 Loss_G: 0.0471 Convergence: 0.1164 k= 0.039436 lr = 0.0000599\n",
      "[3/25][2100/9765] Loss_D: 0.1005 Loss_G: 0.0391 Convergence: 0.1038 k= 0.039421 lr = 0.0000599\n",
      "[3/25][2110/9765] Loss_D: 0.1134 Loss_G: 0.0405 Convergence: 0.1205 k= 0.039439 lr = 0.0000599\n",
      "[3/25][2120/9765] Loss_D: 0.1054 Loss_G: 0.0452 Convergence: 0.1095 k= 0.039416 lr = 0.0000599\n",
      "[3/25][2130/9765] Loss_D: 0.1058 Loss_G: 0.0465 Convergence: 0.1110 k= 0.039417 lr = 0.0000599\n",
      "[3/25][2140/9765] Loss_D: 0.1119 Loss_G: 0.0468 Convergence: 0.1150 k= 0.039415 lr = 0.0000599\n",
      "[3/25][2150/9765] Loss_D: 0.0975 Loss_G: 0.0501 Convergence: 0.1097 k= 0.039383 lr = 0.0000599\n",
      "[3/25][2160/9765] Loss_D: 0.1032 Loss_G: 0.0440 Convergence: 0.1070 k= 0.039376 lr = 0.0000599\n",
      "[3/25][2170/9765] Loss_D: 0.1004 Loss_G: 0.0447 Convergence: 0.1060 k= 0.039364 lr = 0.0000599\n",
      "[3/25][2180/9765] Loss_D: 0.1137 Loss_G: 0.0455 Convergence: 0.1160 k= 0.039345 lr = 0.0000599\n",
      "[3/25][2190/9765] Loss_D: 0.1056 Loss_G: 0.0522 Convergence: 0.1166 k= 0.039318 lr = 0.0000599\n",
      "[3/25][2200/9765] Loss_D: 0.1026 Loss_G: 0.0439 Convergence: 0.1065 k= 0.039310 lr = 0.0000599\n",
      "[3/25][2210/9765] Loss_D: 0.1052 Loss_G: 0.0430 Convergence: 0.1072 k= 0.039301 lr = 0.0000599\n",
      "[3/25][2220/9765] Loss_D: 0.1015 Loss_G: 0.0469 Convergence: 0.1088 k= 0.039294 lr = 0.0000599\n",
      "[3/25][2230/9765] Loss_D: 0.1026 Loss_G: 0.0462 Convergence: 0.1087 k= 0.039285 lr = 0.0000599\n",
      "[3/25][2240/9765] Loss_D: 0.1028 Loss_G: 0.0378 Convergence: 0.1084 k= 0.039293 lr = 0.0000599\n",
      "[3/25][2250/9765] Loss_D: 0.1050 Loss_G: 0.0515 Convergence: 0.1155 k= 0.039264 lr = 0.0000599\n",
      "[3/25][2260/9765] Loss_D: 0.1020 Loss_G: 0.0435 Convergence: 0.1056 k= 0.039260 lr = 0.0000599\n",
      "[3/25][2270/9765] Loss_D: 0.0937 Loss_G: 0.0395 Convergence: 0.0968 k= 0.039272 lr = 0.0000599\n",
      "[3/25][2280/9765] Loss_D: 0.1034 Loss_G: 0.0434 Convergence: 0.1064 k= 0.039251 lr = 0.0000599\n",
      "[3/25][2290/9765] Loss_D: 0.1038 Loss_G: 0.0410 Convergence: 0.1065 k= 0.039292 lr = 0.0000599\n",
      "[3/25][2300/9765] Loss_D: 0.1025 Loss_G: 0.0458 Convergence: 0.1083 k= 0.039243 lr = 0.0000599\n",
      "[3/25][2310/9765] Loss_D: 0.1089 Loss_G: 0.0446 Convergence: 0.1110 k= 0.039214 lr = 0.0000599\n",
      "[3/25][2320/9765] Loss_D: 0.0967 Loss_G: 0.0408 Convergence: 0.0998 k= 0.039206 lr = 0.0000599\n",
      "[3/25][2330/9765] Loss_D: 0.1107 Loss_G: 0.0455 Convergence: 0.1129 k= 0.039216 lr = 0.0000599\n",
      "[3/25][2340/9765] Loss_D: 0.1031 Loss_G: 0.0410 Convergence: 0.1056 k= 0.039209 lr = 0.0000599\n",
      "[3/25][2350/9765] Loss_D: 0.1048 Loss_G: 0.0445 Convergence: 0.1083 k= 0.039192 lr = 0.0000599\n",
      "[3/25][2360/9765] Loss_D: 0.1001 Loss_G: 0.0459 Convergence: 0.1068 k= 0.039176 lr = 0.0000599\n",
      "[3/25][2370/9765] Loss_D: 0.1099 Loss_G: 0.0448 Convergence: 0.1118 k= 0.039139 lr = 0.0000599\n",
      "[3/25][2380/9765] Loss_D: 0.1024 Loss_G: 0.0406 Convergence: 0.1052 k= 0.039108 lr = 0.0000599\n",
      "[3/25][2390/9765] Loss_D: 0.0964 Loss_G: 0.0431 Convergence: 0.1020 k= 0.039124 lr = 0.0000599\n",
      "[3/25][2400/9765] Loss_D: 0.1114 Loss_G: 0.0400 Convergence: 0.1181 k= 0.039120 lr = 0.0000599\n",
      "[3/25][2410/9765] Loss_D: 0.1051 Loss_G: 0.0425 Convergence: 0.1070 k= 0.039113 lr = 0.0000599\n",
      "[3/25][2420/9765] Loss_D: 0.1077 Loss_G: 0.0386 Convergence: 0.1143 k= 0.039131 lr = 0.0000599\n",
      "[3/25][2430/9765] Loss_D: 0.1081 Loss_G: 0.0447 Convergence: 0.1107 k= 0.039114 lr = 0.0000599\n",
      "[3/25][2440/9765] Loss_D: 0.1041 Loss_G: 0.0461 Convergence: 0.1096 k= 0.039087 lr = 0.0000599\n",
      "[3/25][2450/9765] Loss_D: 0.1141 Loss_G: 0.0501 Convergence: 0.1197 k= 0.039064 lr = 0.0000599\n",
      "[3/25][2460/9765] Loss_D: 0.1018 Loss_G: 0.0455 Convergence: 0.1076 k= 0.039016 lr = 0.0000599\n",
      "[3/25][2470/9765] Loss_D: 0.1051 Loss_G: 0.0411 Convergence: 0.1085 k= 0.039022 lr = 0.0000599\n",
      "[3/25][2480/9765] Loss_D: 0.1097 Loss_G: 0.0453 Convergence: 0.1123 k= 0.038973 lr = 0.0000599\n",
      "[3/25][2490/9765] Loss_D: 0.1085 Loss_G: 0.0392 Convergence: 0.1147 k= 0.038994 lr = 0.0000599\n",
      "[3/25][2500/9765] Loss_D: 0.0999 Loss_G: 0.0449 Convergence: 0.1059 k= 0.039013 lr = 0.0000599\n",
      "[3/25][2510/9765] Loss_D: 0.1060 Loss_G: 0.0416 Convergence: 0.1092 k= 0.038992 lr = 0.0000599\n",
      "[3/25][2520/9765] Loss_D: 0.1029 Loss_G: 0.0496 Convergence: 0.1123 k= 0.039009 lr = 0.0000599\n",
      "[3/25][2530/9765] Loss_D: 0.0981 Loss_G: 0.0486 Convergence: 0.1085 k= 0.039026 lr = 0.0000599\n",
      "[3/25][2540/9765] Loss_D: 0.1144 Loss_G: 0.0445 Convergence: 0.1180 k= 0.038963 lr = 0.0000599\n",
      "[3/25][2550/9765] Loss_D: 0.1102 Loss_G: 0.0366 Convergence: 0.1196 k= 0.038987 lr = 0.0000599\n",
      "[3/25][2560/9765] Loss_D: 0.0998 Loss_G: 0.0450 Convergence: 0.1061 k= 0.038984 lr = 0.0000599\n",
      "[3/25][2570/9765] Loss_D: 0.1072 Loss_G: 0.0456 Convergence: 0.1107 k= 0.038982 lr = 0.0000599\n",
      "[3/25][2580/9765] Loss_D: 0.1113 Loss_G: 0.0460 Convergence: 0.1137 k= 0.038999 lr = 0.0000599\n",
      "[3/25][2590/9765] Loss_D: 0.1041 Loss_G: 0.0420 Convergence: 0.1060 k= 0.038988 lr = 0.0000599\n",
      "[3/25][2600/9765] Loss_D: 0.1166 Loss_G: 0.0444 Convergence: 0.1211 k= 0.039008 lr = 0.0000599\n",
      "[3/25][2610/9765] Loss_D: 0.1115 Loss_G: 0.0435 Convergence: 0.1149 k= 0.038997 lr = 0.0000599\n",
      "[3/25][2620/9765] Loss_D: 0.0991 Loss_G: 0.0438 Convergence: 0.1043 k= 0.038986 lr = 0.0000599\n",
      "[3/25][2630/9765] Loss_D: 0.1006 Loss_G: 0.0439 Convergence: 0.1052 k= 0.038953 lr = 0.0000599\n",
      "[3/25][2640/9765] Loss_D: 0.1035 Loss_G: 0.0421 Convergence: 0.1051 k= 0.038949 lr = 0.0000599\n",
      "[3/25][2650/9765] Loss_D: 0.1031 Loss_G: 0.0435 Convergence: 0.1064 k= 0.038951 lr = 0.0000599\n",
      "[3/25][2660/9765] Loss_D: 0.1118 Loss_G: 0.0422 Convergence: 0.1168 k= 0.038954 lr = 0.0000599\n",
      "[3/25][2670/9765] Loss_D: 0.0998 Loss_G: 0.0464 Convergence: 0.1074 k= 0.038947 lr = 0.0000599\n",
      "[3/25][2680/9765] Loss_D: 0.1160 Loss_G: 0.0428 Convergence: 0.1217 k= 0.038983 lr = 0.0000599\n",
      "[3/25][2690/9765] Loss_D: 0.1111 Loss_G: 0.0482 Convergence: 0.1159 k= 0.038931 lr = 0.0000599\n",
      "[3/25][2700/9765] Loss_D: 0.1072 Loss_G: 0.0421 Convergence: 0.1101 k= 0.038924 lr = 0.0000599\n",
      "[3/25][2710/9765] Loss_D: 0.0978 Loss_G: 0.0422 Convergence: 0.1018 k= 0.038918 lr = 0.0000599\n",
      "[3/25][2720/9765] Loss_D: 0.1072 Loss_G: 0.0494 Convergence: 0.1147 k= 0.038903 lr = 0.0000599\n",
      "[3/25][2730/9765] Loss_D: 0.1093 Loss_G: 0.0438 Convergence: 0.1115 k= 0.038902 lr = 0.0000599\n",
      "[3/25][2740/9765] Loss_D: 0.0987 Loss_G: 0.0421 Convergence: 0.1024 k= 0.038897 lr = 0.0000599\n",
      "[3/25][2750/9765] Loss_D: 0.1038 Loss_G: 0.0399 Convergence: 0.1075 k= 0.038903 lr = 0.0000599\n",
      "[3/25][2760/9765] Loss_D: 0.0992 Loss_G: 0.0460 Convergence: 0.1067 k= 0.038869 lr = 0.0000599\n",
      "[3/25][2770/9765] Loss_D: 0.1136 Loss_G: 0.0495 Convergence: 0.1187 k= 0.038871 lr = 0.0000599\n",
      "[3/25][2780/9765] Loss_D: 0.0989 Loss_G: 0.0389 Convergence: 0.1018 k= 0.038865 lr = 0.0000599\n",
      "[3/25][2790/9765] Loss_D: 0.1069 Loss_G: 0.0440 Convergence: 0.1092 k= 0.038850 lr = 0.0000599\n",
      "[3/25][2800/9765] Loss_D: 0.0924 Loss_G: 0.0440 Convergence: 0.1004 k= 0.038863 lr = 0.0000599\n",
      "[3/25][2810/9765] Loss_D: 0.1037 Loss_G: 0.0460 Convergence: 0.1092 k= 0.038879 lr = 0.0000599\n",
      "[3/25][2820/9765] Loss_D: 0.1091 Loss_G: 0.0455 Convergence: 0.1120 k= 0.038872 lr = 0.0000599\n",
      "[3/25][2830/9765] Loss_D: 0.1110 Loss_G: 0.0427 Convergence: 0.1149 k= 0.038896 lr = 0.0000599\n",
      "[3/25][2840/9765] Loss_D: 0.1193 Loss_G: 0.0512 Convergence: 0.1239 k= 0.038882 lr = 0.0000599\n",
      "[3/25][2850/9765] Loss_D: 0.0948 Loss_G: 0.0417 Convergence: 0.0995 k= 0.038871 lr = 0.0000599\n",
      "[3/25][2860/9765] Loss_D: 0.0993 Loss_G: 0.0416 Convergence: 0.1021 k= 0.038819 lr = 0.0000599\n",
      "[3/25][2870/9765] Loss_D: 0.1068 Loss_G: 0.0415 Convergence: 0.1102 k= 0.038821 lr = 0.0000599\n",
      "[3/25][2880/9765] Loss_D: 0.0970 Loss_G: 0.0418 Convergence: 0.1009 k= 0.038822 lr = 0.0000599\n",
      "[3/25][2890/9765] Loss_D: 0.1001 Loss_G: 0.0441 Convergence: 0.1052 k= 0.038786 lr = 0.0000599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][2900/9765] Loss_D: 0.1075 Loss_G: 0.0474 Convergence: 0.1129 k= 0.038786 lr = 0.0000599\n",
      "[3/25][2910/9765] Loss_D: 0.0988 Loss_G: 0.0404 Convergence: 0.1007 k= 0.038776 lr = 0.0000599\n",
      "[3/25][2920/9765] Loss_D: 0.1035 Loss_G: 0.0445 Convergence: 0.1076 k= 0.038772 lr = 0.0000599\n",
      "[3/25][2930/9765] Loss_D: 0.1102 Loss_G: 0.0470 Convergence: 0.1142 k= 0.038758 lr = 0.0000599\n",
      "[3/25][2940/9765] Loss_D: 0.1012 Loss_G: 0.0451 Convergence: 0.1069 k= 0.038753 lr = 0.0000599\n",
      "[3/25][2950/9765] Loss_D: 0.0993 Loss_G: 0.0371 Convergence: 0.1040 k= 0.038765 lr = 0.0000599\n",
      "[3/25][2960/9765] Loss_D: 0.1183 Loss_G: 0.0509 Convergence: 0.1229 k= 0.038720 lr = 0.0000599\n",
      "[3/25][2970/9765] Loss_D: 0.1094 Loss_G: 0.0404 Convergence: 0.1149 k= 0.038702 lr = 0.0000599\n",
      "[3/25][2980/9765] Loss_D: 0.1028 Loss_G: 0.0450 Convergence: 0.1076 k= 0.038718 lr = 0.0000599\n",
      "[3/25][2990/9765] Loss_D: 0.1086 Loss_G: 0.0426 Convergence: 0.1118 k= 0.038721 lr = 0.0000599\n",
      "[3/25][3000/9765] Loss_D: 0.1023 Loss_G: 0.0408 Convergence: 0.1047 k= 0.038687 lr = 0.0000599\n",
      "[3/25][3010/9765] Loss_D: 0.1096 Loss_G: 0.0421 Convergence: 0.1136 k= 0.038693 lr = 0.0000599\n",
      "[3/25][3020/9765] Loss_D: 0.0935 Loss_G: 0.0401 Convergence: 0.0972 k= 0.038696 lr = 0.0000599\n",
      "[3/25][3030/9765] Loss_D: 0.1113 Loss_G: 0.0433 Convergence: 0.1146 k= 0.038701 lr = 0.0000599\n",
      "[3/25][3040/9765] Loss_D: 0.0964 Loss_G: 0.0424 Convergence: 0.1013 k= 0.038661 lr = 0.0000599\n",
      "[3/25][3050/9765] Loss_D: 0.1177 Loss_G: 0.0470 Convergence: 0.1205 k= 0.038643 lr = 0.0000599\n",
      "[3/25][3060/9765] Loss_D: 0.1143 Loss_G: 0.0446 Convergence: 0.1177 k= 0.038625 lr = 0.0000599\n",
      "[3/25][3070/9765] Loss_D: 0.1102 Loss_G: 0.0448 Convergence: 0.1119 k= 0.038632 lr = 0.0000599\n",
      "[3/25][3080/9765] Loss_D: 0.1102 Loss_G: 0.0425 Convergence: 0.1138 k= 0.038632 lr = 0.0000599\n",
      "[3/25][3090/9765] Loss_D: 0.1081 Loss_G: 0.0462 Convergence: 0.1122 k= 0.038603 lr = 0.0000599\n",
      "[3/25][3100/9765] Loss_D: 0.1018 Loss_G: 0.0410 Convergence: 0.1036 k= 0.038589 lr = 0.0000599\n",
      "[3/25][3110/9765] Loss_D: 0.1059 Loss_G: 0.0455 Convergence: 0.1100 k= 0.038582 lr = 0.0000599\n",
      "[3/25][3120/9765] Loss_D: 0.1091 Loss_G: 0.0463 Convergence: 0.1128 k= 0.038553 lr = 0.0000599\n",
      "[3/25][3130/9765] Loss_D: 0.1061 Loss_G: 0.0413 Convergence: 0.1094 k= 0.038546 lr = 0.0000599\n",
      "[3/25][3140/9765] Loss_D: 0.1114 Loss_G: 0.0507 Convergence: 0.1186 k= 0.038545 lr = 0.0000599\n",
      "[3/25][3150/9765] Loss_D: 0.1018 Loss_G: 0.0435 Convergence: 0.1056 k= 0.038528 lr = 0.0000599\n",
      "[3/25][3160/9765] Loss_D: 0.1068 Loss_G: 0.0372 Convergence: 0.1146 k= 0.038539 lr = 0.0000599\n",
      "[3/25][3170/9765] Loss_D: 0.1055 Loss_G: 0.0451 Convergence: 0.1093 k= 0.038556 lr = 0.0000599\n",
      "[3/25][3180/9765] Loss_D: 0.0979 Loss_G: 0.0422 Convergence: 0.1019 k= 0.038497 lr = 0.0000599\n",
      "[3/25][3190/9765] Loss_D: 0.1017 Loss_G: 0.0356 Convergence: 0.1087 k= 0.038534 lr = 0.0000599\n",
      "[3/25][3200/9765] Loss_D: 0.1118 Loss_G: 0.0515 Convergence: 0.1196 k= 0.038496 lr = 0.0000599\n",
      "[3/25][3210/9765] Loss_D: 0.1016 Loss_G: 0.0396 Convergence: 0.1047 k= 0.038490 lr = 0.0000599\n",
      "[3/25][3220/9765] Loss_D: 0.0972 Loss_G: 0.0515 Convergence: 0.1108 k= 0.038486 lr = 0.0000599\n",
      "[3/25][3230/9765] Loss_D: 0.1072 Loss_G: 0.0406 Convergence: 0.1117 k= 0.038460 lr = 0.0000599\n",
      "[3/25][3240/9765] Loss_D: 0.1049 Loss_G: 0.0425 Convergence: 0.1066 k= 0.038471 lr = 0.0000599\n",
      "[3/25][3250/9765] Loss_D: 0.1084 Loss_G: 0.0444 Convergence: 0.1105 k= 0.038455 lr = 0.0000599\n",
      "[3/25][3260/9765] Loss_D: 0.0956 Loss_G: 0.0426 Convergence: 0.1008 k= 0.038462 lr = 0.0000599\n",
      "[3/25][3270/9765] Loss_D: 0.1137 Loss_G: 0.0456 Convergence: 0.1159 k= 0.038448 lr = 0.0000599\n",
      "[3/25][3280/9765] Loss_D: 0.1005 Loss_G: 0.0417 Convergence: 0.1028 k= 0.038461 lr = 0.0000599\n",
      "[3/25][3290/9765] Loss_D: 0.1090 Loss_G: 0.0459 Convergence: 0.1124 k= 0.038476 lr = 0.0000599\n",
      "[3/25][3300/9765] Loss_D: 0.1046 Loss_G: 0.0413 Convergence: 0.1078 k= 0.038473 lr = 0.0000599\n",
      "[3/25][3310/9765] Loss_D: 0.1105 Loss_G: 0.0456 Convergence: 0.1129 k= 0.038500 lr = 0.0000599\n",
      "[3/25][3320/9765] Loss_D: 0.1082 Loss_G: 0.0443 Convergence: 0.1102 k= 0.038479 lr = 0.0000599\n",
      "[3/25][3330/9765] Loss_D: 0.1021 Loss_G: 0.0398 Convergence: 0.1054 k= 0.038476 lr = 0.0000599\n",
      "[3/25][3340/9765] Loss_D: 0.1098 Loss_G: 0.0403 Convergence: 0.1156 k= 0.038470 lr = 0.0000599\n",
      "[3/25][3350/9765] Loss_D: 0.1032 Loss_G: 0.0468 Convergence: 0.1096 k= 0.038435 lr = 0.0000599\n",
      "[3/25][3360/9765] Loss_D: 0.1027 Loss_G: 0.0400 Convergence: 0.1060 k= 0.038430 lr = 0.0000599\n",
      "[3/25][3370/9765] Loss_D: 0.0996 Loss_G: 0.0405 Convergence: 0.1012 k= 0.038429 lr = 0.0000599\n",
      "[3/25][3380/9765] Loss_D: 0.1102 Loss_G: 0.0419 Convergence: 0.1145 k= 0.038397 lr = 0.0000599\n",
      "[3/25][3390/9765] Loss_D: 0.0945 Loss_G: 0.0433 Convergence: 0.1010 k= 0.038388 lr = 0.0000599\n",
      "[3/25][3400/9765] Loss_D: 0.1082 Loss_G: 0.0440 Convergence: 0.1099 k= 0.038388 lr = 0.0000599\n",
      "[3/25][3410/9765] Loss_D: 0.1033 Loss_G: 0.0450 Convergence: 0.1080 k= 0.038400 lr = 0.0000599\n",
      "[3/25][3420/9765] Loss_D: 0.1027 Loss_G: 0.0464 Convergence: 0.1090 k= 0.038355 lr = 0.0000599\n",
      "[3/25][3430/9765] Loss_D: 0.1059 Loss_G: 0.0363 Convergence: 0.1140 k= 0.038360 lr = 0.0000599\n",
      "[3/25][3440/9765] Loss_D: 0.0978 Loss_G: 0.0492 Convergence: 0.1089 k= 0.038322 lr = 0.0000599\n",
      "[3/25][3450/9765] Loss_D: 0.1062 Loss_G: 0.0450 Convergence: 0.1096 k= 0.038296 lr = 0.0000599\n",
      "[3/25][3460/9765] Loss_D: 0.1104 Loss_G: 0.0438 Convergence: 0.1133 k= 0.038272 lr = 0.0000599\n",
      "[3/25][3470/9765] Loss_D: 0.1194 Loss_G: 0.0436 Convergence: 0.1258 k= 0.038245 lr = 0.0000599\n",
      "[3/25][3480/9765] Loss_D: 0.1027 Loss_G: 0.0439 Convergence: 0.1064 k= 0.038256 lr = 0.0000599\n",
      "[3/25][3490/9765] Loss_D: 0.1041 Loss_G: 0.0404 Convergence: 0.1075 k= 0.038255 lr = 0.0000599\n",
      "[3/25][3500/9765] Loss_D: 0.1049 Loss_G: 0.0447 Convergence: 0.1086 k= 0.038245 lr = 0.0000599\n",
      "[3/25][3510/9765] Loss_D: 0.1123 Loss_G: 0.0415 Convergence: 0.1181 k= 0.038240 lr = 0.0000599\n",
      "[3/25][3520/9765] Loss_D: 0.1053 Loss_G: 0.0492 Convergence: 0.1134 k= 0.038237 lr = 0.0000599\n",
      "[3/25][3530/9765] Loss_D: 0.1187 Loss_G: 0.0435 Convergence: 0.1257 k= 0.038228 lr = 0.0000599\n",
      "[3/25][3540/9765] Loss_D: 0.1014 Loss_G: 0.0399 Convergence: 0.1044 k= 0.038205 lr = 0.0000599\n",
      "[3/25][3550/9765] Loss_D: 0.1165 Loss_G: 0.0447 Convergence: 0.1206 k= 0.038206 lr = 0.0000599\n",
      "[3/25][3560/9765] Loss_D: 0.1023 Loss_G: 0.0463 Convergence: 0.1087 k= 0.038189 lr = 0.0000599\n",
      "[3/25][3570/9765] Loss_D: 0.1145 Loss_G: 0.0415 Convergence: 0.1215 k= 0.038174 lr = 0.0000599\n",
      "[3/25][3580/9765] Loss_D: 0.1108 Loss_G: 0.0463 Convergence: 0.1138 k= 0.038135 lr = 0.0000599\n",
      "[3/25][3590/9765] Loss_D: 0.1042 Loss_G: 0.0398 Convergence: 0.1082 k= 0.038121 lr = 0.0000599\n",
      "[3/25][3600/9765] Loss_D: 0.1033 Loss_G: 0.0435 Convergence: 0.1064 k= 0.038097 lr = 0.0000599\n",
      "[3/25][3610/9765] Loss_D: 0.1082 Loss_G: 0.0423 Convergence: 0.1114 k= 0.038119 lr = 0.0000599\n",
      "[3/25][3620/9765] Loss_D: 0.1085 Loss_G: 0.0358 Convergence: 0.1182 k= 0.038124 lr = 0.0000599\n",
      "[3/25][3630/9765] Loss_D: 0.1007 Loss_G: 0.0449 Convergence: 0.1064 k= 0.038144 lr = 0.0000599\n",
      "[3/25][3640/9765] Loss_D: 0.1009 Loss_G: 0.0437 Convergence: 0.1054 k= 0.038101 lr = 0.0000599\n",
      "[3/25][3650/9765] Loss_D: 0.1129 Loss_G: 0.0568 Convergence: 0.1257 k= 0.038104 lr = 0.0000599\n",
      "[3/25][3660/9765] Loss_D: 0.1201 Loss_G: 0.0424 Convergence: 0.1280 k= 0.038092 lr = 0.0000599\n",
      "[3/25][3670/9765] Loss_D: 0.1014 Loss_G: 0.0388 Convergence: 0.1050 k= 0.038077 lr = 0.0000599\n",
      "[3/25][3680/9765] Loss_D: 0.1157 Loss_G: 0.0414 Convergence: 0.1228 k= 0.038086 lr = 0.0000599\n",
      "[3/25][3690/9765] Loss_D: 0.1030 Loss_G: 0.0373 Convergence: 0.1091 k= 0.038113 lr = 0.0000599\n",
      "[3/25][3700/9765] Loss_D: 0.1036 Loss_G: 0.0441 Convergence: 0.1073 k= 0.038092 lr = 0.0000599\n",
      "[3/25][3710/9765] Loss_D: 0.1057 Loss_G: 0.0390 Convergence: 0.1110 k= 0.038080 lr = 0.0000569\n",
      "[3/25][3720/9765] Loss_D: 0.1022 Loss_G: 0.0418 Convergence: 0.1042 k= 0.038098 lr = 0.0000569\n",
      "[3/25][3730/9765] Loss_D: 0.0995 Loss_G: 0.0405 Convergence: 0.1012 k= 0.038058 lr = 0.0000569\n",
      "[3/25][3740/9765] Loss_D: 0.1075 Loss_G: 0.0450 Convergence: 0.1104 k= 0.038048 lr = 0.0000569\n",
      "[3/25][3750/9765] Loss_D: 0.1070 Loss_G: 0.0445 Convergence: 0.1097 k= 0.038044 lr = 0.0000569\n",
      "[3/25][3760/9765] Loss_D: 0.0915 Loss_G: 0.0424 Convergence: 0.0982 k= 0.037983 lr = 0.0000569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][3770/9765] Loss_D: 0.1120 Loss_G: 0.0459 Convergence: 0.1140 k= 0.038012 lr = 0.0000569\n",
      "[3/25][3780/9765] Loss_D: 0.1024 Loss_G: 0.0502 Convergence: 0.1126 k= 0.037977 lr = 0.0000569\n",
      "[3/25][3790/9765] Loss_D: 0.1056 Loss_G: 0.0447 Convergence: 0.1090 k= 0.037978 lr = 0.0000569\n",
      "[3/25][3800/9765] Loss_D: 0.1060 Loss_G: 0.0424 Convergence: 0.1084 k= 0.037961 lr = 0.0000569\n",
      "[3/25][3810/9765] Loss_D: 0.1101 Loss_G: 0.0463 Convergence: 0.1133 k= 0.037964 lr = 0.0000569\n",
      "[3/25][3820/9765] Loss_D: 0.1032 Loss_G: 0.0404 Convergence: 0.1063 k= 0.037960 lr = 0.0000569\n",
      "[3/25][3830/9765] Loss_D: 0.1192 Loss_G: 0.0474 Convergence: 0.1218 k= 0.037944 lr = 0.0000569\n",
      "[3/25][3840/9765] Loss_D: 0.1030 Loss_G: 0.0455 Convergence: 0.1083 k= 0.037928 lr = 0.0000569\n",
      "[3/25][3850/9765] Loss_D: 0.1017 Loss_G: 0.0440 Convergence: 0.1061 k= 0.037906 lr = 0.0000569\n",
      "[3/25][3860/9765] Loss_D: 0.1076 Loss_G: 0.0444 Convergence: 0.1098 k= 0.037904 lr = 0.0000569\n",
      "[3/25][3870/9765] Loss_D: 0.1046 Loss_G: 0.0393 Convergence: 0.1093 k= 0.037908 lr = 0.0000569\n",
      "[3/25][3880/9765] Loss_D: 0.1103 Loss_G: 0.0446 Convergence: 0.1121 k= 0.037874 lr = 0.0000569\n",
      "[3/25][3890/9765] Loss_D: 0.1102 Loss_G: 0.0451 Convergence: 0.1122 k= 0.037859 lr = 0.0000569\n",
      "[3/25][3900/9765] Loss_D: 0.1071 Loss_G: 0.0402 Convergence: 0.1119 k= 0.037861 lr = 0.0000569\n",
      "[3/25][3910/9765] Loss_D: 0.1003 Loss_G: 0.0362 Convergence: 0.1063 k= 0.037866 lr = 0.0000569\n",
      "[3/25][3920/9765] Loss_D: 0.1165 Loss_G: 0.0490 Convergence: 0.1200 k= 0.037863 lr = 0.0000569\n",
      "[3/25][3930/9765] Loss_D: 0.1058 Loss_G: 0.0420 Convergence: 0.1085 k= 0.037830 lr = 0.0000569\n",
      "[3/25][3940/9765] Loss_D: 0.1054 Loss_G: 0.0426 Convergence: 0.1071 k= 0.037823 lr = 0.0000569\n",
      "[3/25][3950/9765] Loss_D: 0.1013 Loss_G: 0.0483 Convergence: 0.1102 k= 0.037783 lr = 0.0000569\n",
      "[3/25][3960/9765] Loss_D: 0.1025 Loss_G: 0.0418 Convergence: 0.1042 k= 0.037764 lr = 0.0000569\n",
      "[3/25][3970/9765] Loss_D: 0.1024 Loss_G: 0.0432 Convergence: 0.1056 k= 0.037757 lr = 0.0000569\n",
      "[3/25][3980/9765] Loss_D: 0.1210 Loss_G: 0.0481 Convergence: 0.1237 k= 0.037756 lr = 0.0000569\n",
      "[3/25][3990/9765] Loss_D: 0.1031 Loss_G: 0.0396 Convergence: 0.1071 k= 0.037747 lr = 0.0000569\n",
      "[3/25][4000/9765] Loss_D: 0.1072 Loss_G: 0.0464 Convergence: 0.1117 k= 0.037717 lr = 0.0000569\n",
      "[3/25][4010/9765] Loss_D: 0.1011 Loss_G: 0.0393 Convergence: 0.1043 k= 0.037708 lr = 0.0000569\n",
      "[3/25][4020/9765] Loss_D: 0.0984 Loss_G: 0.0442 Convergence: 0.1043 k= 0.037714 lr = 0.0000569\n",
      "[3/25][4030/9765] Loss_D: 0.1111 Loss_G: 0.0425 Convergence: 0.1155 k= 0.037708 lr = 0.0000569\n",
      "[3/25][4040/9765] Loss_D: 0.1195 Loss_G: 0.0385 Convergence: 0.1308 k= 0.037729 lr = 0.0000569\n",
      "[3/25][4050/9765] Loss_D: 0.1014 Loss_G: 0.0424 Convergence: 0.1043 k= 0.037705 lr = 0.0000569\n",
      "[3/25][4060/9765] Loss_D: 0.1141 Loss_G: 0.0486 Convergence: 0.1182 k= 0.037700 lr = 0.0000569\n",
      "[3/25][4070/9765] Loss_D: 0.1125 Loss_G: 0.0435 Convergence: 0.1160 k= 0.037715 lr = 0.0000569\n",
      "[3/25][4080/9765] Loss_D: 0.1177 Loss_G: 0.0447 Convergence: 0.1223 k= 0.037725 lr = 0.0000569\n",
      "[3/25][4090/9765] Loss_D: 0.1056 Loss_G: 0.0448 Convergence: 0.1091 k= 0.037726 lr = 0.0000569\n",
      "[3/25][4100/9765] Loss_D: 0.0993 Loss_G: 0.0479 Convergence: 0.1085 k= 0.037697 lr = 0.0000569\n",
      "[3/25][4110/9765] Loss_D: 0.1118 Loss_G: 0.0458 Convergence: 0.1139 k= 0.037693 lr = 0.0000569\n",
      "[3/25][4120/9765] Loss_D: 0.0942 Loss_G: 0.0438 Convergence: 0.1013 k= 0.037669 lr = 0.0000569\n",
      "[3/25][4130/9765] Loss_D: 0.0963 Loss_G: 0.0415 Convergence: 0.1001 k= 0.037670 lr = 0.0000569\n",
      "[3/25][4140/9765] Loss_D: 0.0942 Loss_G: 0.0473 Convergence: 0.1049 k= 0.037620 lr = 0.0000569\n",
      "[3/25][4150/9765] Loss_D: 0.1147 Loss_G: 0.0378 Convergence: 0.1250 k= 0.037631 lr = 0.0000569\n",
      "[3/25][4160/9765] Loss_D: 0.1016 Loss_G: 0.0517 Convergence: 0.1136 k= 0.037617 lr = 0.0000569\n",
      "[3/25][4170/9765] Loss_D: 0.1066 Loss_G: 0.0424 Convergence: 0.1090 k= 0.037589 lr = 0.0000569\n",
      "[3/25][4180/9765] Loss_D: 0.1151 Loss_G: 0.0404 Convergence: 0.1229 k= 0.037587 lr = 0.0000569\n",
      "[3/25][4190/9765] Loss_D: 0.1187 Loss_G: 0.0447 Convergence: 0.1238 k= 0.037577 lr = 0.0000569\n",
      "[3/25][4200/9765] Loss_D: 0.1069 Loss_G: 0.0437 Convergence: 0.1089 k= 0.037570 lr = 0.0000569\n",
      "[3/25][4210/9765] Loss_D: 0.0972 Loss_G: 0.0407 Convergence: 0.1000 k= 0.037565 lr = 0.0000569\n",
      "[3/25][4220/9765] Loss_D: 0.1107 Loss_G: 0.0464 Convergence: 0.1137 k= 0.037549 lr = 0.0000569\n",
      "[3/25][4230/9765] Loss_D: 0.1060 Loss_G: 0.0414 Convergence: 0.1090 k= 0.037554 lr = 0.0000569\n",
      "[3/25][4240/9765] Loss_D: 0.1082 Loss_G: 0.0500 Convergence: 0.1159 k= 0.037541 lr = 0.0000569\n",
      "[3/25][4250/9765] Loss_D: 0.1102 Loss_G: 0.0412 Convergence: 0.1153 k= 0.037543 lr = 0.0000569\n",
      "[3/25][4260/9765] Loss_D: 0.1003 Loss_G: 0.0384 Convergence: 0.1044 k= 0.037520 lr = 0.0000569\n",
      "[3/25][4270/9765] Loss_D: 0.1049 Loss_G: 0.0471 Convergence: 0.1110 k= 0.037509 lr = 0.0000569\n",
      "[3/25][4280/9765] Loss_D: 0.1038 Loss_G: 0.0402 Convergence: 0.1070 k= 0.037529 lr = 0.0000569\n",
      "[3/25][4290/9765] Loss_D: 0.1046 Loss_G: 0.0565 Convergence: 0.1205 k= 0.037513 lr = 0.0000569\n",
      "[3/25][4300/9765] Loss_D: 0.1145 Loss_G: 0.0420 Convergence: 0.1205 k= 0.037487 lr = 0.0000569\n",
      "[3/25][4310/9765] Loss_D: 0.1119 Loss_G: 0.0414 Convergence: 0.1173 k= 0.037474 lr = 0.0000569\n",
      "[3/25][4320/9765] Loss_D: 0.0965 Loss_G: 0.0413 Convergence: 0.1000 k= 0.037474 lr = 0.0000569\n",
      "[3/25][4330/9765] Loss_D: 0.1095 Loss_G: 0.0377 Convergence: 0.1174 k= 0.037462 lr = 0.0000569\n",
      "[3/25][4340/9765] Loss_D: 0.1072 Loss_G: 0.0429 Convergence: 0.1093 k= 0.037478 lr = 0.0000569\n",
      "[3/25][4350/9765] Loss_D: 0.1072 Loss_G: 0.0435 Convergence: 0.1089 k= 0.037457 lr = 0.0000569\n",
      "[3/25][4360/9765] Loss_D: 0.1053 Loss_G: 0.0409 Convergence: 0.1085 k= 0.037473 lr = 0.0000569\n",
      "[3/25][4370/9765] Loss_D: 0.1041 Loss_G: 0.0415 Convergence: 0.1063 k= 0.037514 lr = 0.0000569\n",
      "[3/25][4380/9765] Loss_D: 0.1113 Loss_G: 0.0419 Convergence: 0.1161 k= 0.037465 lr = 0.0000569\n",
      "[3/25][4390/9765] Loss_D: 0.0962 Loss_G: 0.0396 Convergence: 0.0983 k= 0.037484 lr = 0.0000569\n",
      "[3/25][4400/9765] Loss_D: 0.1115 Loss_G: 0.0504 Convergence: 0.1184 k= 0.037466 lr = 0.0000569\n",
      "[3/25][4410/9765] Loss_D: 0.1120 Loss_G: 0.0400 Convergence: 0.1191 k= 0.037462 lr = 0.0000569\n",
      "[3/25][4420/9765] Loss_D: 0.1048 Loss_G: 0.0413 Convergence: 0.1078 k= 0.037455 lr = 0.0000569\n",
      "[3/25][4430/9765] Loss_D: 0.1033 Loss_G: 0.0481 Convergence: 0.1111 k= 0.037449 lr = 0.0000569\n",
      "[3/25][4440/9765] Loss_D: 0.1033 Loss_G: 0.0417 Convergence: 0.1051 k= 0.037410 lr = 0.0000569\n",
      "[3/25][4450/9765] Loss_D: 0.1097 Loss_G: 0.0425 Convergence: 0.1134 k= 0.037422 lr = 0.0000569\n",
      "[3/25][4460/9765] Loss_D: 0.1017 Loss_G: 0.0437 Convergence: 0.1057 k= 0.037401 lr = 0.0000569\n",
      "[3/25][4470/9765] Loss_D: 0.1058 Loss_G: 0.0415 Convergence: 0.1087 k= 0.037407 lr = 0.0000569\n",
      "[3/25][4480/9765] Loss_D: 0.1061 Loss_G: 0.0484 Convergence: 0.1130 k= 0.037391 lr = 0.0000569\n",
      "[3/25][4490/9765] Loss_D: 0.1097 Loss_G: 0.0436 Convergence: 0.1133 k= 0.037359 lr = 0.0000569\n",
      "[3/25][4500/9765] Loss_D: 0.1043 Loss_G: 0.0475 Convergence: 0.1110 k= 0.037321 lr = 0.0000569\n",
      "[3/25][4510/9765] Loss_D: 0.0955 Loss_G: 0.0431 Convergence: 0.1014 k= 0.037328 lr = 0.0000569\n",
      "[3/25][4520/9765] Loss_D: 0.1225 Loss_G: 0.0446 Convergence: 0.1291 k= 0.037316 lr = 0.0000569\n",
      "[3/25][4530/9765] Loss_D: 0.1114 Loss_G: 0.0441 Convergence: 0.1138 k= 0.037310 lr = 0.0000569\n",
      "[3/25][4540/9765] Loss_D: 0.1047 Loss_G: 0.0524 Convergence: 0.1162 k= 0.037302 lr = 0.0000569\n",
      "[3/25][4550/9765] Loss_D: 0.1148 Loss_G: 0.0414 Convergence: 0.1214 k= 0.037268 lr = 0.0000569\n",
      "[3/25][4560/9765] Loss_D: 0.0972 Loss_G: 0.0429 Convergence: 0.1022 k= 0.037300 lr = 0.0000569\n",
      "[3/25][4570/9765] Loss_D: 0.1067 Loss_G: 0.0447 Convergence: 0.1097 k= 0.037271 lr = 0.0000569\n",
      "[3/25][4580/9765] Loss_D: 0.1081 Loss_G: 0.0445 Convergence: 0.1102 k= 0.037276 lr = 0.0000569\n",
      "[3/25][4590/9765] Loss_D: 0.1027 Loss_G: 0.0460 Convergence: 0.1085 k= 0.037274 lr = 0.0000569\n",
      "[3/25][4600/9765] Loss_D: 0.1155 Loss_G: 0.0458 Convergence: 0.1181 k= 0.037251 lr = 0.0000569\n",
      "[3/25][4610/9765] Loss_D: 0.1127 Loss_G: 0.0411 Convergence: 0.1189 k= 0.037251 lr = 0.0000569\n",
      "[3/25][4620/9765] Loss_D: 0.1135 Loss_G: 0.0457 Convergence: 0.1156 k= 0.037247 lr = 0.0000569\n",
      "[3/25][4630/9765] Loss_D: 0.0993 Loss_G: 0.0463 Convergence: 0.1071 k= 0.037218 lr = 0.0000569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][4640/9765] Loss_D: 0.1134 Loss_G: 0.0385 Convergence: 0.1222 k= 0.037178 lr = 0.0000569\n",
      "[3/25][4650/9765] Loss_D: 0.1018 Loss_G: 0.0480 Convergence: 0.1102 k= 0.037157 lr = 0.0000569\n",
      "[3/25][4660/9765] Loss_D: 0.1008 Loss_G: 0.0426 Convergence: 0.1040 k= 0.037146 lr = 0.0000569\n",
      "[3/25][4670/9765] Loss_D: 0.1072 Loss_G: 0.0394 Convergence: 0.1127 k= 0.037143 lr = 0.0000569\n",
      "[3/25][4680/9765] Loss_D: 0.1056 Loss_G: 0.0470 Convergence: 0.1112 k= 0.037126 lr = 0.0000569\n",
      "[3/25][4690/9765] Loss_D: 0.0974 Loss_G: 0.0473 Convergence: 0.1067 k= 0.037117 lr = 0.0000569\n",
      "[3/25][4700/9765] Loss_D: 0.0970 Loss_G: 0.0377 Convergence: 0.1000 k= 0.037136 lr = 0.0000569\n",
      "[3/25][4710/9765] Loss_D: 0.1043 Loss_G: 0.0505 Convergence: 0.1141 k= 0.037119 lr = 0.0000569\n",
      "[3/25][4720/9765] Loss_D: 0.1078 Loss_G: 0.0425 Convergence: 0.1106 k= 0.037096 lr = 0.0000569\n",
      "[3/25][4730/9765] Loss_D: 0.1046 Loss_G: 0.0424 Convergence: 0.1062 k= 0.037086 lr = 0.0000569\n",
      "[3/25][4740/9765] Loss_D: 0.1080 Loss_G: 0.0461 Convergence: 0.1119 k= 0.037065 lr = 0.0000569\n",
      "[3/25][4750/9765] Loss_D: 0.1088 Loss_G: 0.0407 Convergence: 0.1137 k= 0.037070 lr = 0.0000569\n",
      "[3/25][4760/9765] Loss_D: 0.1005 Loss_G: 0.0380 Convergence: 0.1045 k= 0.037074 lr = 0.0000569\n",
      "[3/25][4770/9765] Loss_D: 0.0994 Loss_G: 0.0452 Convergence: 0.1058 k= 0.037061 lr = 0.0000569\n",
      "[3/25][4780/9765] Loss_D: 0.1033 Loss_G: 0.0482 Convergence: 0.1112 k= 0.037024 lr = 0.0000569\n",
      "[3/25][4790/9765] Loss_D: 0.1052 Loss_G: 0.0454 Convergence: 0.1095 k= 0.037000 lr = 0.0000569\n",
      "[3/25][4800/9765] Loss_D: 0.1027 Loss_G: 0.0507 Convergence: 0.1134 k= 0.036962 lr = 0.0000569\n",
      "[3/25][4810/9765] Loss_D: 0.0986 Loss_G: 0.0425 Convergence: 0.1027 k= 0.036946 lr = 0.0000569\n",
      "[3/25][4820/9765] Loss_D: 0.1044 Loss_G: 0.0462 Convergence: 0.1099 k= 0.036959 lr = 0.0000569\n",
      "[3/25][4830/9765] Loss_D: 0.1015 Loss_G: 0.0462 Convergence: 0.1080 k= 0.036947 lr = 0.0000569\n",
      "[3/25][4840/9765] Loss_D: 0.1040 Loss_G: 0.0450 Convergence: 0.1083 k= 0.036943 lr = 0.0000569\n",
      "[3/25][4850/9765] Loss_D: 0.1075 Loss_G: 0.0410 Convergence: 0.1118 k= 0.036968 lr = 0.0000569\n",
      "[3/25][4860/9765] Loss_D: 0.0907 Loss_G: 0.0413 Convergence: 0.0967 k= 0.036941 lr = 0.0000569\n",
      "[3/25][4870/9765] Loss_D: 0.0996 Loss_G: 0.0428 Convergence: 0.1035 k= 0.036938 lr = 0.0000569\n",
      "[3/25][4880/9765] Loss_D: 0.1055 Loss_G: 0.0409 Convergence: 0.1089 k= 0.036933 lr = 0.0000569\n",
      "[3/25][4890/9765] Loss_D: 0.0975 Loss_G: 0.0414 Convergence: 0.1009 k= 0.036899 lr = 0.0000569\n",
      "[3/25][4900/9765] Loss_D: 0.1058 Loss_G: 0.0422 Convergence: 0.1083 k= 0.036908 lr = 0.0000569\n",
      "[3/25][4910/9765] Loss_D: 0.1031 Loss_G: 0.0435 Convergence: 0.1063 k= 0.036871 lr = 0.0000569\n",
      "[3/25][4920/9765] Loss_D: 0.1067 Loss_G: 0.0441 Convergence: 0.1091 k= 0.036859 lr = 0.0000569\n",
      "[3/25][4930/9765] Loss_D: 0.1124 Loss_G: 0.0480 Convergence: 0.1164 k= 0.036852 lr = 0.0000569\n",
      "[3/25][4940/9765] Loss_D: 0.1160 Loss_G: 0.0466 Convergence: 0.1181 k= 0.036830 lr = 0.0000569\n",
      "[3/25][4950/9765] Loss_D: 0.1135 Loss_G: 0.0442 Convergence: 0.1169 k= 0.036845 lr = 0.0000569\n",
      "[3/25][4960/9765] Loss_D: 0.1068 Loss_G: 0.0408 Convergence: 0.1107 k= 0.036838 lr = 0.0000569\n",
      "[3/25][4970/9765] Loss_D: 0.1090 Loss_G: 0.0477 Convergence: 0.1140 k= 0.036795 lr = 0.0000569\n",
      "[3/25][4980/9765] Loss_D: 0.0992 Loss_G: 0.0456 Convergence: 0.1061 k= 0.036778 lr = 0.0000569\n",
      "[3/25][4990/9765] Loss_D: 0.1119 Loss_G: 0.0413 Convergence: 0.1176 k= 0.036755 lr = 0.0000569\n",
      "[3/25][5000/9765] Loss_D: 0.1039 Loss_G: 0.0424 Convergence: 0.1057 k= 0.036749 lr = 0.0000569\n",
      "[3/25][5010/9765] Loss_D: 0.1098 Loss_G: 0.0448 Convergence: 0.1116 k= 0.036726 lr = 0.0000569\n",
      "[3/25][5020/9765] Loss_D: 0.1022 Loss_G: 0.0359 Convergence: 0.1090 k= 0.036745 lr = 0.0000569\n",
      "[3/25][5030/9765] Loss_D: 0.1084 Loss_G: 0.0471 Convergence: 0.1130 k= 0.036743 lr = 0.0000569\n",
      "[3/25][5040/9765] Loss_D: 0.0997 Loss_G: 0.0435 Convergence: 0.1044 k= 0.036667 lr = 0.0000569\n",
      "[3/25][5050/9765] Loss_D: 0.0919 Loss_G: 0.0379 Convergence: 0.0939 k= 0.036650 lr = 0.0000569\n",
      "[3/25][5060/9765] Loss_D: 0.1076 Loss_G: 0.0473 Convergence: 0.1129 k= 0.036638 lr = 0.0000569\n",
      "[3/25][5070/9765] Loss_D: 0.0986 Loss_G: 0.0438 Convergence: 0.1039 k= 0.036599 lr = 0.0000569\n",
      "[3/25][5080/9765] Loss_D: 0.1129 Loss_G: 0.0463 Convergence: 0.1149 k= 0.036579 lr = 0.0000569\n",
      "[3/25][5090/9765] Loss_D: 0.1158 Loss_G: 0.0421 Convergence: 0.1221 k= 0.036563 lr = 0.0000569\n",
      "[3/25][5100/9765] Loss_D: 0.1067 Loss_G: 0.0447 Convergence: 0.1097 k= 0.036542 lr = 0.0000569\n",
      "[3/25][5110/9765] Loss_D: 0.0995 Loss_G: 0.0425 Convergence: 0.1031 k= 0.036521 lr = 0.0000569\n",
      "[3/25][5120/9765] Loss_D: 0.1105 Loss_G: 0.0412 Convergence: 0.1156 k= 0.036503 lr = 0.0000569\n",
      "[3/25][5130/9765] Loss_D: 0.0979 Loss_G: 0.0439 Convergence: 0.1036 k= 0.036488 lr = 0.0000569\n",
      "[3/25][5140/9765] Loss_D: 0.1256 Loss_G: 0.0429 Convergence: 0.1350 k= 0.036490 lr = 0.0000569\n",
      "[3/25][5150/9765] Loss_D: 0.1057 Loss_G: 0.0418 Convergence: 0.1082 k= 0.036479 lr = 0.0000569\n",
      "[3/25][5160/9765] Loss_D: 0.1065 Loss_G: 0.0422 Convergence: 0.1090 k= 0.036472 lr = 0.0000569\n",
      "[3/25][5170/9765] Loss_D: 0.1005 Loss_G: 0.0419 Convergence: 0.1031 k= 0.036477 lr = 0.0000569\n",
      "[3/25][5180/9765] Loss_D: 0.1074 Loss_G: 0.0437 Convergence: 0.1091 k= 0.036455 lr = 0.0000569\n",
      "[3/25][5190/9765] Loss_D: 0.1130 Loss_G: 0.0436 Convergence: 0.1165 k= 0.036449 lr = 0.0000569\n",
      "[3/25][5200/9765] Loss_D: 0.1040 Loss_G: 0.0493 Convergence: 0.1126 k= 0.036422 lr = 0.0000569\n",
      "[3/25][5210/9765] Loss_D: 0.1132 Loss_G: 0.0493 Convergence: 0.1181 k= 0.036394 lr = 0.0000569\n",
      "[3/25][5220/9765] Loss_D: 0.1087 Loss_G: 0.0379 Convergence: 0.1163 k= 0.036397 lr = 0.0000569\n",
      "[3/25][5230/9765] Loss_D: 0.1082 Loss_G: 0.0411 Convergence: 0.1125 k= 0.036405 lr = 0.0000569\n",
      "[3/25][5240/9765] Loss_D: 0.1043 Loss_G: 0.0421 Convergence: 0.1062 k= 0.036386 lr = 0.0000569\n",
      "[3/25][5250/9765] Loss_D: 0.0973 Loss_G: 0.0438 Convergence: 0.1032 k= 0.036385 lr = 0.0000569\n",
      "[3/25][5260/9765] Loss_D: 0.0980 Loss_G: 0.0489 Convergence: 0.1086 k= 0.036345 lr = 0.0000569\n",
      "[3/25][5270/9765] Loss_D: 0.1043 Loss_G: 0.0399 Convergence: 0.1082 k= 0.036323 lr = 0.0000569\n",
      "[3/25][5280/9765] Loss_D: 0.1084 Loss_G: 0.0434 Convergence: 0.1105 k= 0.036323 lr = 0.0000569\n",
      "[3/25][5290/9765] Loss_D: 0.1086 Loss_G: 0.0441 Convergence: 0.1102 k= 0.036329 lr = 0.0000569\n",
      "[3/25][5300/9765] Loss_D: 0.0953 Loss_G: 0.0435 Convergence: 0.1016 k= 0.036276 lr = 0.0000569\n",
      "[3/25][5310/9765] Loss_D: 0.1205 Loss_G: 0.0451 Convergence: 0.1259 k= 0.036297 lr = 0.0000569\n",
      "[3/25][5320/9765] Loss_D: 0.1039 Loss_G: 0.0462 Convergence: 0.1095 k= 0.036270 lr = 0.0000569\n",
      "[3/25][5330/9765] Loss_D: 0.1080 Loss_G: 0.0373 Convergence: 0.1157 k= 0.036240 lr = 0.0000569\n",
      "[3/25][5340/9765] Loss_D: 0.1074 Loss_G: 0.0422 Convergence: 0.1101 k= 0.036284 lr = 0.0000569\n",
      "[3/25][5350/9765] Loss_D: 0.0945 Loss_G: 0.0455 Convergence: 0.1033 k= 0.036269 lr = 0.0000569\n",
      "[3/25][5360/9765] Loss_D: 0.1013 Loss_G: 0.0379 Convergence: 0.1062 k= 0.036250 lr = 0.0000569\n",
      "[3/25][5370/9765] Loss_D: 0.1079 Loss_G: 0.0491 Convergence: 0.1148 k= 0.036269 lr = 0.0000569\n",
      "[3/25][5380/9765] Loss_D: 0.1108 Loss_G: 0.0434 Convergence: 0.1142 k= 0.036225 lr = 0.0000569\n",
      "[3/25][5390/9765] Loss_D: 0.1066 Loss_G: 0.0382 Convergence: 0.1130 k= 0.036225 lr = 0.0000569\n",
      "[3/25][5400/9765] Loss_D: 0.1077 Loss_G: 0.0458 Convergence: 0.1115 k= 0.036230 lr = 0.0000569\n",
      "[3/25][5410/9765] Loss_D: 0.1006 Loss_G: 0.0486 Convergence: 0.1099 k= 0.036189 lr = 0.0000569\n",
      "[3/25][5420/9765] Loss_D: 0.1037 Loss_G: 0.0463 Convergence: 0.1095 k= 0.036182 lr = 0.0000569\n",
      "[3/25][5430/9765] Loss_D: 0.1167 Loss_G: 0.0427 Convergence: 0.1227 k= 0.036178 lr = 0.0000569\n",
      "[3/25][5440/9765] Loss_D: 0.1201 Loss_G: 0.0472 Convergence: 0.1231 k= 0.036168 lr = 0.0000569\n",
      "[3/25][5450/9765] Loss_D: 0.1025 Loss_G: 0.0467 Convergence: 0.1093 k= 0.036135 lr = 0.0000569\n",
      "[3/25][5460/9765] Loss_D: 0.1121 Loss_G: 0.0473 Convergence: 0.1156 k= 0.036112 lr = 0.0000569\n",
      "[3/25][5470/9765] Loss_D: 0.1101 Loss_G: 0.0395 Convergence: 0.1167 k= 0.036108 lr = 0.0000569\n",
      "[3/25][5480/9765] Loss_D: 0.1085 Loss_G: 0.0427 Convergence: 0.1114 k= 0.036093 lr = 0.0000569\n",
      "[3/25][5490/9765] Loss_D: 0.1017 Loss_G: 0.0440 Convergence: 0.1061 k= 0.036076 lr = 0.0000569\n",
      "[3/25][5500/9765] Loss_D: 0.1170 Loss_G: 0.0545 Convergence: 0.1258 k= 0.036062 lr = 0.0000569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][5510/9765] Loss_D: 0.1069 Loss_G: 0.0424 Convergence: 0.1094 k= 0.036053 lr = 0.0000569\n",
      "[3/25][5520/9765] Loss_D: 0.0922 Loss_G: 0.0424 Convergence: 0.0987 k= 0.036034 lr = 0.0000569\n",
      "[3/25][5530/9765] Loss_D: 0.1009 Loss_G: 0.0420 Convergence: 0.1035 k= 0.036040 lr = 0.0000569\n",
      "[3/25][5540/9765] Loss_D: 0.1006 Loss_G: 0.0445 Convergence: 0.1057 k= 0.036070 lr = 0.0000569\n",
      "[3/25][5550/9765] Loss_D: 0.1051 Loss_G: 0.0449 Convergence: 0.1090 k= 0.036035 lr = 0.0000569\n",
      "[3/25][5560/9765] Loss_D: 0.1008 Loss_G: 0.0419 Convergence: 0.1032 k= 0.036064 lr = 0.0000569\n",
      "[3/25][5570/9765] Loss_D: 0.1004 Loss_G: 0.0469 Convergence: 0.1080 k= 0.036098 lr = 0.0000569\n",
      "[3/25][5580/9765] Loss_D: 0.0954 Loss_G: 0.0447 Convergence: 0.1030 k= 0.036033 lr = 0.0000569\n",
      "[3/25][5590/9765] Loss_D: 0.1057 Loss_G: 0.0411 Convergence: 0.1089 k= 0.036028 lr = 0.0000569\n",
      "[3/25][5600/9765] Loss_D: 0.1054 Loss_G: 0.0477 Convergence: 0.1118 k= 0.036029 lr = 0.0000569\n",
      "[3/25][5610/9765] Loss_D: 0.1071 Loss_G: 0.0586 Convergence: 0.1239 k= 0.035974 lr = 0.0000569\n",
      "[3/25][5620/9765] Loss_D: 0.1003 Loss_G: 0.0421 Convergence: 0.1032 k= 0.035976 lr = 0.0000569\n",
      "[3/25][5630/9765] Loss_D: 0.1086 Loss_G: 0.0506 Convergence: 0.1168 k= 0.035960 lr = 0.0000569\n",
      "[3/25][5640/9765] Loss_D: 0.1057 Loss_G: 0.0412 Convergence: 0.1091 k= 0.035922 lr = 0.0000569\n",
      "[3/25][5650/9765] Loss_D: 0.1028 Loss_G: 0.0415 Convergence: 0.1045 k= 0.035919 lr = 0.0000569\n",
      "[3/25][5660/9765] Loss_D: 0.1090 Loss_G: 0.0439 Convergence: 0.1109 k= 0.035898 lr = 0.0000569\n",
      "[3/25][5670/9765] Loss_D: 0.1021 Loss_G: 0.0365 Convergence: 0.1082 k= 0.035915 lr = 0.0000569\n",
      "[3/25][5680/9765] Loss_D: 0.0990 Loss_G: 0.0386 Convergence: 0.1020 k= 0.035915 lr = 0.0000569\n",
      "[3/25][5690/9765] Loss_D: 0.1088 Loss_G: 0.0459 Convergence: 0.1121 k= 0.035918 lr = 0.0000569\n",
      "[3/25][5700/9765] Loss_D: 0.1034 Loss_G: 0.0429 Convergence: 0.1060 k= 0.035889 lr = 0.0000569\n",
      "[3/25][5710/9765] Loss_D: 0.0985 Loss_G: 0.0411 Convergence: 0.1011 k= 0.035887 lr = 0.0000569\n",
      "[3/25][5720/9765] Loss_D: 0.1104 Loss_G: 0.0438 Convergence: 0.1128 k= 0.035884 lr = 0.0000569\n",
      "[3/25][5730/9765] Loss_D: 0.1009 Loss_G: 0.0432 Convergence: 0.1047 k= 0.035867 lr = 0.0000569\n",
      "[3/25][5740/9765] Loss_D: 0.1055 Loss_G: 0.0500 Convergence: 0.1142 k= 0.035847 lr = 0.0000569\n",
      "[3/25][5750/9765] Loss_D: 0.1043 Loss_G: 0.0489 Convergence: 0.1126 k= 0.035816 lr = 0.0000569\n",
      "[3/25][5760/9765] Loss_D: 0.1061 Loss_G: 0.0487 Convergence: 0.1133 k= 0.035776 lr = 0.0000569\n",
      "[3/25][5770/9765] Loss_D: 0.1042 Loss_G: 0.0434 Convergence: 0.1069 k= 0.035768 lr = 0.0000569\n",
      "[3/25][5780/9765] Loss_D: 0.1093 Loss_G: 0.0454 Convergence: 0.1120 k= 0.035769 lr = 0.0000569\n",
      "[3/25][5790/9765] Loss_D: 0.1029 Loss_G: 0.0463 Convergence: 0.1090 k= 0.035754 lr = 0.0000569\n",
      "[3/25][5800/9765] Loss_D: 0.1016 Loss_G: 0.0423 Convergence: 0.1043 k= 0.035733 lr = 0.0000569\n",
      "[3/25][5810/9765] Loss_D: 0.0999 Loss_G: 0.0462 Convergence: 0.1070 k= 0.035738 lr = 0.0000569\n",
      "[3/25][5820/9765] Loss_D: 0.1041 Loss_G: 0.0394 Convergence: 0.1082 k= 0.035763 lr = 0.0000569\n",
      "[3/25][5830/9765] Loss_D: 0.1041 Loss_G: 0.0462 Convergence: 0.1097 k= 0.035760 lr = 0.0000569\n",
      "[3/25][5840/9765] Loss_D: 0.0984 Loss_G: 0.0424 Convergence: 0.1024 k= 0.035721 lr = 0.0000569\n",
      "[3/25][5850/9765] Loss_D: 0.1040 Loss_G: 0.0426 Convergence: 0.1059 k= 0.035720 lr = 0.0000569\n",
      "[3/25][5860/9765] Loss_D: 0.1071 Loss_G: 0.0433 Convergence: 0.1087 k= 0.035684 lr = 0.0000569\n",
      "[3/25][5870/9765] Loss_D: 0.1071 Loss_G: 0.0467 Convergence: 0.1119 k= 0.035647 lr = 0.0000569\n",
      "[3/25][5880/9765] Loss_D: 0.1050 Loss_G: 0.0429 Convergence: 0.1068 k= 0.035655 lr = 0.0000569\n",
      "[3/25][5890/9765] Loss_D: 0.1103 Loss_G: 0.0545 Convergence: 0.1217 k= 0.035614 lr = 0.0000569\n",
      "[3/25][5900/9765] Loss_D: 0.1098 Loss_G: 0.0421 Convergence: 0.1135 k= 0.035605 lr = 0.0000569\n",
      "[3/25][5910/9765] Loss_D: 0.1058 Loss_G: 0.0541 Convergence: 0.1187 k= 0.035590 lr = 0.0000569\n",
      "[3/25][5920/9765] Loss_D: 0.1080 Loss_G: 0.0435 Convergence: 0.1101 k= 0.035543 lr = 0.0000569\n",
      "[3/25][5930/9765] Loss_D: 0.0967 Loss_G: 0.0379 Convergence: 0.0993 k= 0.035561 lr = 0.0000569\n",
      "[3/25][5940/9765] Loss_D: 0.1063 Loss_G: 0.0430 Convergence: 0.1079 k= 0.035534 lr = 0.0000569\n",
      "[3/25][5950/9765] Loss_D: 0.1005 Loss_G: 0.0419 Convergence: 0.1030 k= 0.035520 lr = 0.0000569\n",
      "[3/25][5960/9765] Loss_D: 0.1114 Loss_G: 0.0419 Convergence: 0.1159 k= 0.035524 lr = 0.0000569\n",
      "[3/25][5970/9765] Loss_D: 0.1072 Loss_G: 0.0414 Convergence: 0.1107 k= 0.035516 lr = 0.0000569\n",
      "[3/25][5980/9765] Loss_D: 0.1032 Loss_G: 0.0444 Convergence: 0.1072 k= 0.035510 lr = 0.0000569\n",
      "[3/25][5990/9765] Loss_D: 0.1005 Loss_G: 0.0451 Convergence: 0.1063 k= 0.035490 lr = 0.0000569\n",
      "[3/25][6000/9765] Loss_D: 0.1047 Loss_G: 0.0443 Convergence: 0.1080 k= 0.035478 lr = 0.0000569\n",
      "[3/25][6010/9765] Loss_D: 0.1106 Loss_G: 0.0515 Convergence: 0.1187 k= 0.035472 lr = 0.0000569\n",
      "[3/25][6020/9765] Loss_D: 0.0988 Loss_G: 0.0417 Convergence: 0.1018 k= 0.035452 lr = 0.0000569\n",
      "[3/25][6030/9765] Loss_D: 0.0984 Loss_G: 0.0428 Convergence: 0.1027 k= 0.035437 lr = 0.0000569\n",
      "[3/25][6040/9765] Loss_D: 0.0990 Loss_G: 0.0461 Convergence: 0.1064 k= 0.035395 lr = 0.0000569\n",
      "[3/25][6050/9765] Loss_D: 0.0994 Loss_G: 0.0442 Convergence: 0.1049 k= 0.035373 lr = 0.0000569\n",
      "[3/25][6060/9765] Loss_D: 0.0999 Loss_G: 0.0432 Convergence: 0.1041 k= 0.035358 lr = 0.0000569\n",
      "[3/25][6070/9765] Loss_D: 0.1111 Loss_G: 0.0449 Convergence: 0.1125 k= 0.035359 lr = 0.0000569\n",
      "[3/25][6080/9765] Loss_D: 0.1110 Loss_G: 0.0412 Convergence: 0.1164 k= 0.035345 lr = 0.0000569\n",
      "[3/25][6090/9765] Loss_D: 0.1114 Loss_G: 0.0443 Convergence: 0.1140 k= 0.035338 lr = 0.0000569\n",
      "[3/25][6100/9765] Loss_D: 0.1040 Loss_G: 0.0491 Convergence: 0.1124 k= 0.035321 lr = 0.0000569\n",
      "[3/25][6110/9765] Loss_D: 0.1118 Loss_G: 0.0401 Convergence: 0.1184 k= 0.035332 lr = 0.0000569\n",
      "[3/25][6120/9765] Loss_D: 0.1093 Loss_G: 0.0456 Convergence: 0.1120 k= 0.035316 lr = 0.0000569\n",
      "[3/25][6130/9765] Loss_D: 0.1119 Loss_G: 0.0429 Convergence: 0.1162 k= 0.035298 lr = 0.0000569\n",
      "[3/25][6140/9765] Loss_D: 0.0966 Loss_G: 0.0407 Convergence: 0.0995 k= 0.035311 lr = 0.0000569\n",
      "[3/25][6150/9765] Loss_D: 0.1038 Loss_G: 0.0461 Convergence: 0.1093 k= 0.035272 lr = 0.0000569\n",
      "[3/25][6160/9765] Loss_D: 0.1098 Loss_G: 0.0423 Convergence: 0.1136 k= 0.035250 lr = 0.0000569\n",
      "[3/25][6170/9765] Loss_D: 0.1097 Loss_G: 0.0399 Convergence: 0.1156 k= 0.035272 lr = 0.0000569\n",
      "[3/25][6180/9765] Loss_D: 0.0993 Loss_G: 0.0472 Convergence: 0.1077 k= 0.035220 lr = 0.0000569\n",
      "[3/25][6190/9765] Loss_D: 0.1063 Loss_G: 0.0416 Convergence: 0.1094 k= 0.035162 lr = 0.0000569\n",
      "[3/25][6200/9765] Loss_D: 0.0974 Loss_G: 0.0463 Convergence: 0.1056 k= 0.035130 lr = 0.0000569\n",
      "[3/25][6210/9765] Loss_D: 0.1041 Loss_G: 0.0448 Convergence: 0.1082 k= 0.035092 lr = 0.0000569\n",
      "[3/25][6220/9765] Loss_D: 0.1039 Loss_G: 0.0541 Convergence: 0.1174 k= 0.035095 lr = 0.0000569\n",
      "[3/25][6230/9765] Loss_D: 0.1044 Loss_G: 0.0444 Convergence: 0.1079 k= 0.035083 lr = 0.0000569\n",
      "[3/25][6240/9765] Loss_D: 0.1138 Loss_G: 0.0422 Convergence: 0.1191 k= 0.035081 lr = 0.0000569\n",
      "[3/25][6250/9765] Loss_D: 0.1207 Loss_G: 0.0448 Convergence: 0.1264 k= 0.035052 lr = 0.0000569\n",
      "[3/25][6260/9765] Loss_D: 0.1111 Loss_G: 0.0419 Convergence: 0.1158 k= 0.035062 lr = 0.0000569\n",
      "[3/25][6270/9765] Loss_D: 0.0912 Loss_G: 0.0400 Convergence: 0.0955 k= 0.035083 lr = 0.0000569\n",
      "[3/25][6280/9765] Loss_D: 0.1092 Loss_G: 0.0480 Convergence: 0.1144 k= 0.035073 lr = 0.0000569\n",
      "[3/25][6290/9765] Loss_D: 0.1063 Loss_G: 0.0426 Convergence: 0.1084 k= 0.035076 lr = 0.0000569\n",
      "[3/25][6300/9765] Loss_D: 0.1002 Loss_G: 0.0403 Convergence: 0.1019 k= 0.035037 lr = 0.0000569\n",
      "[3/25][6310/9765] Loss_D: 0.1042 Loss_G: 0.0394 Convergence: 0.1083 k= 0.035050 lr = 0.0000569\n",
      "[3/25][6320/9765] Loss_D: 0.1056 Loss_G: 0.0457 Convergence: 0.1100 k= 0.035034 lr = 0.0000569\n",
      "[3/25][6330/9765] Loss_D: 0.1034 Loss_G: 0.0390 Convergence: 0.1082 k= 0.035028 lr = 0.0000569\n",
      "[3/25][6340/9765] Loss_D: 0.1022 Loss_G: 0.0442 Convergence: 0.1063 k= 0.035006 lr = 0.0000569\n",
      "[3/25][6350/9765] Loss_D: 0.1108 Loss_G: 0.0451 Convergence: 0.1125 k= 0.034955 lr = 0.0000569\n",
      "[3/25][6360/9765] Loss_D: 0.0982 Loss_G: 0.0402 Convergence: 0.1000 k= 0.034950 lr = 0.0000569\n",
      "[3/25][6370/9765] Loss_D: 0.1000 Loss_G: 0.0448 Convergence: 0.1056 k= 0.034949 lr = 0.0000569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][6380/9765] Loss_D: 0.1020 Loss_G: 0.0481 Convergence: 0.1101 k= 0.034919 lr = 0.0000569\n",
      "[3/25][6390/9765] Loss_D: 0.1066 Loss_G: 0.0445 Convergence: 0.1093 k= 0.034914 lr = 0.0000569\n",
      "[3/25][6400/9765] Loss_D: 0.1031 Loss_G: 0.0427 Convergence: 0.1055 k= 0.034895 lr = 0.0000569\n",
      "[3/25][6410/9765] Loss_D: 0.1135 Loss_G: 0.0439 Convergence: 0.1172 k= 0.034881 lr = 0.0000569\n",
      "[3/25][6420/9765] Loss_D: 0.0972 Loss_G: 0.0411 Convergence: 0.1003 k= 0.034890 lr = 0.0000569\n",
      "[3/25][6430/9765] Loss_D: 0.1036 Loss_G: 0.0429 Convergence: 0.1059 k= 0.034885 lr = 0.0000569\n",
      "[3/25][6440/9765] Loss_D: 0.1114 Loss_G: 0.0374 Convergence: 0.1204 k= 0.034893 lr = 0.0000569\n",
      "[3/25][6450/9765] Loss_D: 0.1122 Loss_G: 0.0470 Convergence: 0.1152 k= 0.034871 lr = 0.0000569\n",
      "[3/25][6460/9765] Loss_D: 0.1102 Loss_G: 0.0440 Convergence: 0.1122 k= 0.034860 lr = 0.0000569\n",
      "[3/25][6470/9765] Loss_D: 0.0996 Loss_G: 0.0448 Convergence: 0.1055 k= 0.034877 lr = 0.0000569\n",
      "[3/25][6480/9765] Loss_D: 0.1010 Loss_G: 0.0458 Convergence: 0.1073 k= 0.034840 lr = 0.0000569\n",
      "[3/25][6490/9765] Loss_D: 0.1095 Loss_G: 0.0451 Convergence: 0.1117 k= 0.034834 lr = 0.0000569\n",
      "[3/25][6500/9765] Loss_D: 0.1025 Loss_G: 0.0426 Convergence: 0.1049 k= 0.034823 lr = 0.0000569\n",
      "[3/25][6510/9765] Loss_D: 0.1103 Loss_G: 0.0601 Convergence: 0.1272 k= 0.034788 lr = 0.0000569\n",
      "[3/25][6520/9765] Loss_D: 0.1117 Loss_G: 0.0465 Convergence: 0.1143 k= 0.034765 lr = 0.0000569\n",
      "[3/25][6530/9765] Loss_D: 0.1101 Loss_G: 0.0536 Convergence: 0.1207 k= 0.034747 lr = 0.0000569\n",
      "[3/25][6540/9765] Loss_D: 0.1127 Loss_G: 0.0438 Convergence: 0.1161 k= 0.034722 lr = 0.0000569\n",
      "[3/25][6550/9765] Loss_D: 0.1010 Loss_G: 0.0425 Convergence: 0.1040 k= 0.034742 lr = 0.0000569\n",
      "[3/25][6560/9765] Loss_D: 0.1065 Loss_G: 0.0432 Convergence: 0.1082 k= 0.034724 lr = 0.0000569\n",
      "[3/25][6570/9765] Loss_D: 0.0997 Loss_G: 0.0410 Convergence: 0.1017 k= 0.034730 lr = 0.0000569\n",
      "[3/25][6580/9765] Loss_D: 0.1023 Loss_G: 0.0441 Convergence: 0.1064 k= 0.034732 lr = 0.0000569\n",
      "[3/25][6590/9765] Loss_D: 0.1021 Loss_G: 0.0448 Convergence: 0.1069 k= 0.034705 lr = 0.0000569\n",
      "[3/25][6600/9765] Loss_D: 0.1075 Loss_G: 0.0411 Convergence: 0.1113 k= 0.034712 lr = 0.0000569\n",
      "[3/25][6610/9765] Loss_D: 0.1058 Loss_G: 0.0417 Convergence: 0.1084 k= 0.034709 lr = 0.0000569\n",
      "[3/25][6620/9765] Loss_D: 0.1009 Loss_G: 0.0472 Convergence: 0.1085 k= 0.034689 lr = 0.0000569\n",
      "[3/25][6630/9765] Loss_D: 0.1137 Loss_G: 0.0437 Convergence: 0.1175 k= 0.034660 lr = 0.0000569\n",
      "[3/25][6640/9765] Loss_D: 0.1030 Loss_G: 0.0394 Convergence: 0.1066 k= 0.034634 lr = 0.0000569\n",
      "[3/25][6650/9765] Loss_D: 0.0935 Loss_G: 0.0434 Convergence: 0.1005 k= 0.034625 lr = 0.0000569\n",
      "[3/25][6660/9765] Loss_D: 0.1076 Loss_G: 0.0450 Convergence: 0.1104 k= 0.034622 lr = 0.0000569\n",
      "[3/25][6670/9765] Loss_D: 0.1031 Loss_G: 0.0433 Convergence: 0.1060 k= 0.034615 lr = 0.0000569\n",
      "[3/25][6680/9765] Loss_D: 0.1013 Loss_G: 0.0403 Convergence: 0.1033 k= 0.034624 lr = 0.0000569\n",
      "[3/25][6690/9765] Loss_D: 0.1081 Loss_G: 0.0421 Convergence: 0.1115 k= 0.034607 lr = 0.0000569\n",
      "[3/25][6700/9765] Loss_D: 0.1039 Loss_G: 0.0445 Convergence: 0.1077 k= 0.034567 lr = 0.0000569\n",
      "[3/25][6710/9765] Loss_D: 0.0989 Loss_G: 0.0413 Convergence: 0.1015 k= 0.034566 lr = 0.0000540\n",
      "[3/25][6720/9765] Loss_D: 0.1109 Loss_G: 0.0453 Convergence: 0.1128 k= 0.034555 lr = 0.0000540\n",
      "[3/25][6730/9765] Loss_D: 0.1066 Loss_G: 0.0421 Convergence: 0.1091 k= 0.034540 lr = 0.0000540\n",
      "[3/25][6740/9765] Loss_D: 0.1174 Loss_G: 0.0531 Convergence: 0.1245 k= 0.034531 lr = 0.0000540\n",
      "[3/25][6750/9765] Loss_D: 0.1030 Loss_G: 0.0428 Convergence: 0.1056 k= 0.034501 lr = 0.0000540\n",
      "[3/25][6760/9765] Loss_D: 0.1066 Loss_G: 0.0509 Convergence: 0.1158 k= 0.034464 lr = 0.0000540\n",
      "[3/25][6770/9765] Loss_D: 0.1024 Loss_G: 0.0408 Convergence: 0.1046 k= 0.034467 lr = 0.0000540\n",
      "[3/25][6780/9765] Loss_D: 0.1133 Loss_G: 0.0423 Convergence: 0.1184 k= 0.034492 lr = 0.0000540\n",
      "[3/25][6790/9765] Loss_D: 0.1056 Loss_G: 0.0446 Convergence: 0.1090 k= 0.034491 lr = 0.0000540\n",
      "[3/25][6800/9765] Loss_D: 0.1049 Loss_G: 0.0442 Convergence: 0.1080 k= 0.034466 lr = 0.0000540\n",
      "[3/25][6810/9765] Loss_D: 0.1051 Loss_G: 0.0434 Convergence: 0.1073 k= 0.034495 lr = 0.0000540\n",
      "[3/25][6820/9765] Loss_D: 0.1028 Loss_G: 0.0363 Convergence: 0.1093 k= 0.034525 lr = 0.0000540\n",
      "[3/25][6830/9765] Loss_D: 0.1096 Loss_G: 0.0425 Convergence: 0.1129 k= 0.034504 lr = 0.0000540\n",
      "[3/25][6840/9765] Loss_D: 0.1091 Loss_G: 0.0412 Convergence: 0.1136 k= 0.034523 lr = 0.0000540\n",
      "[3/25][6850/9765] Loss_D: 0.1100 Loss_G: 0.0448 Convergence: 0.1117 k= 0.034504 lr = 0.0000540\n",
      "[3/25][6860/9765] Loss_D: 0.1041 Loss_G: 0.0457 Convergence: 0.1092 k= 0.034482 lr = 0.0000540\n",
      "[3/25][6870/9765] Loss_D: 0.1145 Loss_G: 0.0406 Convergence: 0.1216 k= 0.034478 lr = 0.0000540\n",
      "[3/25][6880/9765] Loss_D: 0.1060 Loss_G: 0.0468 Convergence: 0.1113 k= 0.034455 lr = 0.0000540\n",
      "[3/25][6890/9765] Loss_D: 0.1065 Loss_G: 0.0430 Convergence: 0.1080 k= 0.034432 lr = 0.0000540\n",
      "[3/25][6900/9765] Loss_D: 0.1012 Loss_G: 0.0448 Convergence: 0.1064 k= 0.034428 lr = 0.0000540\n",
      "[3/25][6910/9765] Loss_D: 0.1014 Loss_G: 0.0411 Convergence: 0.1029 k= 0.034414 lr = 0.0000540\n",
      "[3/25][6920/9765] Loss_D: 0.1028 Loss_G: 0.0390 Convergence: 0.1067 k= 0.034416 lr = 0.0000540\n",
      "[3/25][6930/9765] Loss_D: 0.0942 Loss_G: 0.0462 Convergence: 0.1035 k= 0.034420 lr = 0.0000540\n",
      "[3/25][6940/9765] Loss_D: 0.0997 Loss_G: 0.0424 Convergence: 0.1030 k= 0.034428 lr = 0.0000540\n",
      "[3/25][6950/9765] Loss_D: 0.1104 Loss_G: 0.0419 Convergence: 0.1147 k= 0.034430 lr = 0.0000540\n",
      "[3/25][6960/9765] Loss_D: 0.1093 Loss_G: 0.0450 Convergence: 0.1116 k= 0.034413 lr = 0.0000540\n",
      "[3/25][6970/9765] Loss_D: 0.1040 Loss_G: 0.0459 Convergence: 0.1092 k= 0.034404 lr = 0.0000540\n",
      "[3/25][6980/9765] Loss_D: 0.1093 Loss_G: 0.0417 Convergence: 0.1132 k= 0.034406 lr = 0.0000540\n",
      "[3/25][6990/9765] Loss_D: 0.1085 Loss_G: 0.0506 Convergence: 0.1166 k= 0.034385 lr = 0.0000540\n",
      "[3/25][7000/9765] Loss_D: 0.1006 Loss_G: 0.0416 Convergence: 0.1027 k= 0.034400 lr = 0.0000540\n",
      "[3/25][7010/9765] Loss_D: 0.1139 Loss_G: 0.0479 Convergence: 0.1172 k= 0.034363 lr = 0.0000540\n",
      "[3/25][7020/9765] Loss_D: 0.1061 Loss_G: 0.0435 Convergence: 0.1080 k= 0.034373 lr = 0.0000540\n",
      "[3/25][7030/9765] Loss_D: 0.0950 Loss_G: 0.0472 Convergence: 0.1051 k= 0.034377 lr = 0.0000540\n",
      "[3/25][7040/9765] Loss_D: 0.1149 Loss_G: 0.0422 Convergence: 0.1209 k= 0.034340 lr = 0.0000540\n",
      "[3/25][7050/9765] Loss_D: 0.1034 Loss_G: 0.0450 Convergence: 0.1080 k= 0.034316 lr = 0.0000540\n",
      "[3/25][7060/9765] Loss_D: 0.1178 Loss_G: 0.0455 Convergence: 0.1215 k= 0.034306 lr = 0.0000540\n",
      "[3/25][7070/9765] Loss_D: 0.1055 Loss_G: 0.0385 Convergence: 0.1111 k= 0.034293 lr = 0.0000540\n",
      "[3/25][7080/9765] Loss_D: 0.1101 Loss_G: 0.0454 Convergence: 0.1123 k= 0.034304 lr = 0.0000540\n",
      "[3/25][7090/9765] Loss_D: 0.1030 Loss_G: 0.0424 Convergence: 0.1050 k= 0.034311 lr = 0.0000540\n",
      "[3/25][7100/9765] Loss_D: 0.1012 Loss_G: 0.0411 Convergence: 0.1027 k= 0.034300 lr = 0.0000540\n",
      "[3/25][7110/9765] Loss_D: 0.0998 Loss_G: 0.0442 Convergence: 0.1049 k= 0.034301 lr = 0.0000540\n",
      "[3/25][7120/9765] Loss_D: 0.1071 Loss_G: 0.0384 Convergence: 0.1134 k= 0.034290 lr = 0.0000540\n",
      "[3/25][7130/9765] Loss_D: 0.1043 Loss_G: 0.0487 Convergence: 0.1122 k= 0.034267 lr = 0.0000540\n",
      "[3/25][7140/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1010 k= 0.034262 lr = 0.0000540\n",
      "[3/25][7150/9765] Loss_D: 0.1021 Loss_G: 0.0422 Convergence: 0.1044 k= 0.034273 lr = 0.0000540\n",
      "[3/25][7160/9765] Loss_D: 0.1074 Loss_G: 0.0411 Convergence: 0.1113 k= 0.034265 lr = 0.0000540\n",
      "[3/25][7170/9765] Loss_D: 0.1011 Loss_G: 0.0430 Convergence: 0.1045 k= 0.034267 lr = 0.0000540\n",
      "[3/25][7180/9765] Loss_D: 0.0986 Loss_G: 0.0440 Convergence: 0.1041 k= 0.034255 lr = 0.0000540\n",
      "[3/25][7190/9765] Loss_D: 0.0997 Loss_G: 0.0477 Convergence: 0.1084 k= 0.034215 lr = 0.0000540\n",
      "[3/25][7200/9765] Loss_D: 0.1000 Loss_G: 0.0401 Convergence: 0.1019 k= 0.034216 lr = 0.0000540\n",
      "[3/25][7210/9765] Loss_D: 0.1142 Loss_G: 0.0540 Convergence: 0.1235 k= 0.034195 lr = 0.0000540\n",
      "[3/25][7220/9765] Loss_D: 0.1012 Loss_G: 0.0397 Convergence: 0.1038 k= 0.034206 lr = 0.0000540\n",
      "[3/25][7230/9765] Loss_D: 0.1060 Loss_G: 0.0419 Convergence: 0.1083 k= 0.034203 lr = 0.0000540\n",
      "[3/25][7240/9765] Loss_D: 0.1024 Loss_G: 0.0473 Convergence: 0.1097 k= 0.034175 lr = 0.0000540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][7250/9765] Loss_D: 0.1111 Loss_G: 0.0437 Convergence: 0.1139 k= 0.034171 lr = 0.0000540\n",
      "[3/25][7260/9765] Loss_D: 0.1117 Loss_G: 0.0435 Convergence: 0.1149 k= 0.034194 lr = 0.0000540\n",
      "[3/25][7270/9765] Loss_D: 0.1124 Loss_G: 0.0428 Convergence: 0.1166 k= 0.034173 lr = 0.0000540\n",
      "[3/25][7280/9765] Loss_D: 0.1024 Loss_G: 0.0422 Convergence: 0.1046 k= 0.034162 lr = 0.0000540\n",
      "[3/25][7290/9765] Loss_D: 0.0977 Loss_G: 0.0412 Convergence: 0.1007 k= 0.034156 lr = 0.0000540\n",
      "[3/25][7300/9765] Loss_D: 0.0975 Loss_G: 0.0403 Convergence: 0.0997 k= 0.034161 lr = 0.0000540\n",
      "[3/25][7310/9765] Loss_D: 0.0995 Loss_G: 0.0497 Convergence: 0.1104 k= 0.034150 lr = 0.0000540\n",
      "[3/25][7320/9765] Loss_D: 0.1154 Loss_G: 0.0423 Convergence: 0.1213 k= 0.034105 lr = 0.0000540\n",
      "[3/25][7330/9765] Loss_D: 0.0994 Loss_G: 0.0378 Convergence: 0.1033 k= 0.034095 lr = 0.0000540\n",
      "[3/25][7340/9765] Loss_D: 0.1034 Loss_G: 0.0368 Convergence: 0.1098 k= 0.034131 lr = 0.0000540\n",
      "[3/25][7350/9765] Loss_D: 0.1087 Loss_G: 0.0479 Convergence: 0.1139 k= 0.034112 lr = 0.0000540\n",
      "[3/25][7360/9765] Loss_D: 0.1024 Loss_G: 0.0454 Convergence: 0.1078 k= 0.034080 lr = 0.0000540\n",
      "[3/25][7370/9765] Loss_D: 0.1029 Loss_G: 0.0492 Convergence: 0.1118 k= 0.034070 lr = 0.0000540\n",
      "[3/25][7380/9765] Loss_D: 0.1094 Loss_G: 0.0388 Convergence: 0.1163 k= 0.034053 lr = 0.0000540\n",
      "[3/25][7390/9765] Loss_D: 0.1087 Loss_G: 0.0425 Convergence: 0.1115 k= 0.034067 lr = 0.0000540\n",
      "[3/25][7400/9765] Loss_D: 0.1109 Loss_G: 0.0441 Convergence: 0.1132 k= 0.034052 lr = 0.0000540\n",
      "[3/25][7410/9765] Loss_D: 0.0978 Loss_G: 0.0419 Convergence: 0.1015 k= 0.034046 lr = 0.0000540\n",
      "[3/25][7420/9765] Loss_D: 0.1117 Loss_G: 0.0442 Convergence: 0.1142 k= 0.034045 lr = 0.0000540\n",
      "[3/25][7430/9765] Loss_D: 0.1022 Loss_G: 0.0418 Convergence: 0.1039 k= 0.034036 lr = 0.0000540\n",
      "[3/25][7440/9765] Loss_D: 0.1083 Loss_G: 0.0416 Convergence: 0.1118 k= 0.034032 lr = 0.0000540\n",
      "[3/25][7450/9765] Loss_D: 0.1047 Loss_G: 0.0453 Convergence: 0.1090 k= 0.034025 lr = 0.0000540\n",
      "[3/25][7460/9765] Loss_D: 0.1032 Loss_G: 0.0393 Convergence: 0.1071 k= 0.034047 lr = 0.0000540\n",
      "[3/25][7470/9765] Loss_D: 0.1082 Loss_G: 0.0489 Convergence: 0.1147 k= 0.034036 lr = 0.0000540\n",
      "[3/25][7480/9765] Loss_D: 0.0977 Loss_G: 0.0398 Convergence: 0.0993 k= 0.034031 lr = 0.0000540\n",
      "[3/25][7490/9765] Loss_D: 0.0977 Loss_G: 0.0362 Convergence: 0.1023 k= 0.034069 lr = 0.0000540\n",
      "[3/25][7500/9765] Loss_D: 0.0994 Loss_G: 0.0562 Convergence: 0.1168 k= 0.034031 lr = 0.0000540\n",
      "[3/25][7510/9765] Loss_D: 0.0959 Loss_G: 0.0452 Convergence: 0.1036 k= 0.033966 lr = 0.0000540\n",
      "[3/25][7520/9765] Loss_D: 0.1114 Loss_G: 0.0427 Convergence: 0.1153 k= 0.033948 lr = 0.0000540\n",
      "[3/25][7530/9765] Loss_D: 0.1139 Loss_G: 0.0424 Convergence: 0.1190 k= 0.033944 lr = 0.0000540\n",
      "[3/25][7540/9765] Loss_D: 0.1083 Loss_G: 0.0427 Convergence: 0.1107 k= 0.033970 lr = 0.0000540\n",
      "[3/25][7550/9765] Loss_D: 0.1018 Loss_G: 0.0524 Convergence: 0.1143 k= 0.033945 lr = 0.0000540\n",
      "[3/25][7560/9765] Loss_D: 0.1074 Loss_G: 0.0344 Convergence: 0.1175 k= 0.033954 lr = 0.0000540\n",
      "[3/25][7570/9765] Loss_D: 0.1082 Loss_G: 0.0495 Convergence: 0.1154 k= 0.033950 lr = 0.0000540\n",
      "[3/25][7580/9765] Loss_D: 0.1015 Loss_G: 0.0396 Convergence: 0.1044 k= 0.033938 lr = 0.0000540\n",
      "[3/25][7590/9765] Loss_D: 0.1046 Loss_G: 0.0440 Convergence: 0.1077 k= 0.033946 lr = 0.0000540\n",
      "[3/25][7600/9765] Loss_D: 0.1022 Loss_G: 0.0396 Convergence: 0.1055 k= 0.033986 lr = 0.0000540\n",
      "[3/25][7610/9765] Loss_D: 0.1022 Loss_G: 0.0418 Convergence: 0.1040 k= 0.033966 lr = 0.0000540\n",
      "[3/25][7620/9765] Loss_D: 0.1056 Loss_G: 0.0457 Convergence: 0.1098 k= 0.033947 lr = 0.0000540\n",
      "[3/25][7630/9765] Loss_D: 0.0964 Loss_G: 0.0424 Convergence: 0.1011 k= 0.033936 lr = 0.0000540\n",
      "[3/25][7640/9765] Loss_D: 0.1126 Loss_G: 0.0420 Convergence: 0.1180 k= 0.033897 lr = 0.0000540\n",
      "[3/25][7650/9765] Loss_D: 0.1122 Loss_G: 0.0456 Convergence: 0.1138 k= 0.033873 lr = 0.0000540\n",
      "[3/25][7660/9765] Loss_D: 0.1083 Loss_G: 0.0425 Convergence: 0.1110 k= 0.033894 lr = 0.0000540\n",
      "[3/25][7670/9765] Loss_D: 0.1074 Loss_G: 0.0445 Convergence: 0.1098 k= 0.033845 lr = 0.0000540\n",
      "[3/25][7680/9765] Loss_D: 0.1009 Loss_G: 0.0433 Convergence: 0.1047 k= 0.033861 lr = 0.0000540\n",
      "[3/25][7690/9765] Loss_D: 0.1063 Loss_G: 0.0377 Convergence: 0.1132 k= 0.033872 lr = 0.0000540\n",
      "[3/25][7700/9765] Loss_D: 0.1124 Loss_G: 0.0531 Convergence: 0.1214 k= 0.033846 lr = 0.0000540\n",
      "[3/25][7710/9765] Loss_D: 0.1083 Loss_G: 0.0366 Convergence: 0.1168 k= 0.033866 lr = 0.0000540\n",
      "[3/25][7720/9765] Loss_D: 0.0948 Loss_G: 0.0397 Convergence: 0.0975 k= 0.033872 lr = 0.0000540\n",
      "[3/25][7730/9765] Loss_D: 0.1002 Loss_G: 0.0461 Convergence: 0.1072 k= 0.033848 lr = 0.0000540\n",
      "[3/25][7740/9765] Loss_D: 0.1007 Loss_G: 0.0426 Convergence: 0.1038 k= 0.033848 lr = 0.0000540\n",
      "[3/25][7750/9765] Loss_D: 0.1103 Loss_G: 0.0470 Convergence: 0.1140 k= 0.033848 lr = 0.0000540\n",
      "[3/25][7760/9765] Loss_D: 0.1036 Loss_G: 0.0437 Convergence: 0.1066 k= 0.033852 lr = 0.0000540\n",
      "[3/25][7770/9765] Loss_D: 0.0994 Loss_G: 0.0422 Convergence: 0.1027 k= 0.033846 lr = 0.0000540\n",
      "[3/25][7780/9765] Loss_D: 0.1000 Loss_G: 0.0418 Convergence: 0.1026 k= 0.033854 lr = 0.0000540\n",
      "[3/25][7790/9765] Loss_D: 0.0972 Loss_G: 0.0405 Convergence: 0.0997 k= 0.033853 lr = 0.0000540\n",
      "[3/25][7800/9765] Loss_D: 0.1010 Loss_G: 0.0379 Convergence: 0.1053 k= 0.033855 lr = 0.0000540\n",
      "[3/25][7810/9765] Loss_D: 0.0970 Loss_G: 0.0421 Convergence: 0.1011 k= 0.033883 lr = 0.0000540\n",
      "[3/25][7820/9765] Loss_D: 0.1163 Loss_G: 0.0474 Convergence: 0.1181 k= 0.033845 lr = 0.0000540\n",
      "[3/25][7830/9765] Loss_D: 0.0998 Loss_G: 0.0385 Convergence: 0.1030 k= 0.033824 lr = 0.0000540\n",
      "[3/25][7840/9765] Loss_D: 0.1108 Loss_G: 0.0428 Convergence: 0.1142 k= 0.033848 lr = 0.0000540\n",
      "[3/25][7850/9765] Loss_D: 0.1055 Loss_G: 0.0422 Convergence: 0.1075 k= 0.033827 lr = 0.0000540\n",
      "[3/25][7860/9765] Loss_D: 0.1096 Loss_G: 0.0469 Convergence: 0.1136 k= 0.033802 lr = 0.0000540\n",
      "[3/25][7870/9765] Loss_D: 0.1040 Loss_G: 0.0467 Convergence: 0.1099 k= 0.033795 lr = 0.0000540\n",
      "[3/25][7880/9765] Loss_D: 0.0985 Loss_G: 0.0416 Convergence: 0.1015 k= 0.033777 lr = 0.0000540\n",
      "[3/25][7890/9765] Loss_D: 0.1030 Loss_G: 0.0431 Convergence: 0.1058 k= 0.033793 lr = 0.0000540\n",
      "[3/25][7900/9765] Loss_D: 0.1055 Loss_G: 0.0418 Convergence: 0.1077 k= 0.033770 lr = 0.0000540\n",
      "[3/25][7910/9765] Loss_D: 0.1111 Loss_G: 0.0432 Convergence: 0.1143 k= 0.033779 lr = 0.0000540\n",
      "[3/25][7920/9765] Loss_D: 0.1010 Loss_G: 0.0423 Convergence: 0.1037 k= 0.033787 lr = 0.0000540\n",
      "[3/25][7930/9765] Loss_D: 0.1050 Loss_G: 0.0399 Convergence: 0.1090 k= 0.033775 lr = 0.0000540\n",
      "[3/25][7940/9765] Loss_D: 0.1025 Loss_G: 0.0393 Convergence: 0.1061 k= 0.033773 lr = 0.0000540\n",
      "[3/25][7950/9765] Loss_D: 0.1017 Loss_G: 0.0428 Convergence: 0.1047 k= 0.033772 lr = 0.0000540\n",
      "[3/25][7960/9765] Loss_D: 0.1024 Loss_G: 0.0414 Convergence: 0.1041 k= 0.033724 lr = 0.0000540\n",
      "[3/25][7970/9765] Loss_D: 0.1002 Loss_G: 0.0403 Convergence: 0.1019 k= 0.033717 lr = 0.0000540\n",
      "[3/25][7980/9765] Loss_D: 0.1040 Loss_G: 0.0425 Convergence: 0.1057 k= 0.033740 lr = 0.0000540\n",
      "[3/25][7990/9765] Loss_D: 0.1063 Loss_G: 0.0419 Convergence: 0.1089 k= 0.033710 lr = 0.0000540\n",
      "[3/25][8000/9765] Loss_D: 0.1013 Loss_G: 0.0435 Convergence: 0.1052 k= 0.033680 lr = 0.0000540\n",
      "[3/25][8010/9765] Loss_D: 0.1027 Loss_G: 0.0417 Convergence: 0.1042 k= 0.033695 lr = 0.0000540\n",
      "[3/25][8020/9765] Loss_D: 0.1025 Loss_G: 0.0498 Convergence: 0.1123 k= 0.033650 lr = 0.0000540\n",
      "[3/25][8030/9765] Loss_D: 0.1099 Loss_G: 0.0436 Convergence: 0.1122 k= 0.033631 lr = 0.0000540\n",
      "[3/25][8040/9765] Loss_D: 0.0967 Loss_G: 0.0412 Convergence: 0.1000 k= 0.033643 lr = 0.0000540\n",
      "[3/25][8050/9765] Loss_D: 0.1076 Loss_G: 0.0414 Convergence: 0.1112 k= 0.033638 lr = 0.0000540\n",
      "[3/25][8060/9765] Loss_D: 0.0991 Loss_G: 0.0451 Convergence: 0.1055 k= 0.033631 lr = 0.0000540\n",
      "[3/25][8070/9765] Loss_D: 0.1135 Loss_G: 0.0455 Convergence: 0.1154 k= 0.033613 lr = 0.0000540\n",
      "[3/25][8080/9765] Loss_D: 0.0983 Loss_G: 0.0439 Convergence: 0.1038 k= 0.033589 lr = 0.0000540\n",
      "[3/25][8090/9765] Loss_D: 0.1064 Loss_G: 0.0385 Convergence: 0.1123 k= 0.033606 lr = 0.0000540\n",
      "[3/25][8100/9765] Loss_D: 0.0998 Loss_G: 0.0513 Convergence: 0.1121 k= 0.033610 lr = 0.0000540\n",
      "[3/25][8110/9765] Loss_D: 0.0980 Loss_G: 0.0407 Convergence: 0.1003 k= 0.033560 lr = 0.0000540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][8120/9765] Loss_D: 0.1193 Loss_G: 0.0375 Convergence: 0.1313 k= 0.033594 lr = 0.0000540\n",
      "[3/25][8130/9765] Loss_D: 0.1199 Loss_G: 0.0465 Convergence: 0.1233 k= 0.033585 lr = 0.0000540\n",
      "[3/25][8140/9765] Loss_D: 0.1124 Loss_G: 0.0458 Convergence: 0.1141 k= 0.033588 lr = 0.0000540\n",
      "[3/25][8150/9765] Loss_D: 0.1146 Loss_G: 0.0464 Convergence: 0.1161 k= 0.033607 lr = 0.0000540\n",
      "[3/25][8160/9765] Loss_D: 0.1029 Loss_G: 0.0452 Convergence: 0.1078 k= 0.033577 lr = 0.0000540\n",
      "[3/25][8170/9765] Loss_D: 0.1063 Loss_G: 0.0424 Convergence: 0.1084 k= 0.033567 lr = 0.0000540\n",
      "[3/25][8180/9765] Loss_D: 0.0921 Loss_G: 0.0401 Convergence: 0.0962 k= 0.033549 lr = 0.0000540\n",
      "[3/25][8190/9765] Loss_D: 0.1113 Loss_G: 0.0418 Convergence: 0.1161 k= 0.033549 lr = 0.0000540\n",
      "[3/25][8200/9765] Loss_D: 0.0974 Loss_G: 0.0476 Convergence: 0.1069 k= 0.033516 lr = 0.0000540\n",
      "[3/25][8210/9765] Loss_D: 0.1064 Loss_G: 0.0403 Convergence: 0.1106 k= 0.033524 lr = 0.0000540\n",
      "[3/25][8220/9765] Loss_D: 0.1117 Loss_G: 0.0413 Convergence: 0.1169 k= 0.033541 lr = 0.0000540\n",
      "[3/25][8230/9765] Loss_D: 0.1028 Loss_G: 0.0413 Convergence: 0.1046 k= 0.033524 lr = 0.0000540\n",
      "[3/25][8240/9765] Loss_D: 0.1084 Loss_G: 0.0445 Convergence: 0.1104 k= 0.033540 lr = 0.0000540\n",
      "[3/25][8250/9765] Loss_D: 0.1041 Loss_G: 0.0421 Convergence: 0.1057 k= 0.033531 lr = 0.0000540\n",
      "[3/25][8260/9765] Loss_D: 0.1029 Loss_G: 0.0437 Convergence: 0.1063 k= 0.033498 lr = 0.0000540\n",
      "[3/25][8270/9765] Loss_D: 0.0999 Loss_G: 0.0383 Convergence: 0.1033 k= 0.033479 lr = 0.0000540\n",
      "[3/25][8280/9765] Loss_D: 0.1081 Loss_G: 0.0441 Convergence: 0.1098 k= 0.033493 lr = 0.0000540\n",
      "[3/25][8290/9765] Loss_D: 0.1073 Loss_G: 0.0456 Convergence: 0.1109 k= 0.033506 lr = 0.0000540\n",
      "[3/25][8300/9765] Loss_D: 0.1053 Loss_G: 0.0419 Convergence: 0.1076 k= 0.033446 lr = 0.0000540\n",
      "[3/25][8310/9765] Loss_D: 0.1108 Loss_G: 0.0388 Convergence: 0.1181 k= 0.033461 lr = 0.0000540\n",
      "[3/25][8320/9765] Loss_D: 0.1043 Loss_G: 0.0443 Convergence: 0.1078 k= 0.033448 lr = 0.0000540\n",
      "[3/25][8330/9765] Loss_D: 0.1147 Loss_G: 0.0509 Convergence: 0.1207 k= 0.033431 lr = 0.0000540\n",
      "[3/25][8340/9765] Loss_D: 0.0975 Loss_G: 0.0380 Convergence: 0.1001 k= 0.033414 lr = 0.0000540\n",
      "[3/25][8350/9765] Loss_D: 0.1031 Loss_G: 0.0480 Convergence: 0.1107 k= 0.033401 lr = 0.0000540\n",
      "[3/25][8360/9765] Loss_D: 0.1033 Loss_G: 0.0424 Convergence: 0.1052 k= 0.033389 lr = 0.0000540\n",
      "[3/25][8370/9765] Loss_D: 0.1001 Loss_G: 0.0414 Convergence: 0.1022 k= 0.033387 lr = 0.0000540\n",
      "[3/25][8380/9765] Loss_D: 0.1051 Loss_G: 0.0602 Convergence: 0.1241 k= 0.033357 lr = 0.0000540\n",
      "[3/25][8390/9765] Loss_D: 0.1098 Loss_G: 0.0375 Convergence: 0.1181 k= 0.033346 lr = 0.0000540\n",
      "[3/25][8400/9765] Loss_D: 0.1000 Loss_G: 0.0437 Convergence: 0.1045 k= 0.033330 lr = 0.0000540\n",
      "[3/25][8410/9765] Loss_D: 0.1075 Loss_G: 0.0419 Convergence: 0.1104 k= 0.033343 lr = 0.0000540\n",
      "[3/25][8420/9765] Loss_D: 0.0988 Loss_G: 0.0455 Convergence: 0.1055 k= 0.033331 lr = 0.0000540\n",
      "[3/25][8430/9765] Loss_D: 0.0995 Loss_G: 0.0458 Convergence: 0.1063 k= 0.033287 lr = 0.0000540\n",
      "[3/25][8440/9765] Loss_D: 0.1032 Loss_G: 0.0384 Convergence: 0.1078 k= 0.033317 lr = 0.0000540\n",
      "[3/25][8450/9765] Loss_D: 0.0986 Loss_G: 0.0446 Convergence: 0.1046 k= 0.033309 lr = 0.0000540\n",
      "[3/25][8460/9765] Loss_D: 0.1126 Loss_G: 0.0546 Convergence: 0.1230 k= 0.033264 lr = 0.0000540\n",
      "[3/25][8470/9765] Loss_D: 0.0942 Loss_G: 0.0407 Convergence: 0.0982 k= 0.033238 lr = 0.0000540\n",
      "[3/25][8480/9765] Loss_D: 0.0992 Loss_G: 0.0504 Convergence: 0.1107 k= 0.033201 lr = 0.0000540\n",
      "[3/25][8490/9765] Loss_D: 0.1035 Loss_G: 0.0385 Convergence: 0.1081 k= 0.033223 lr = 0.0000540\n",
      "[3/25][8500/9765] Loss_D: 0.1045 Loss_G: 0.0412 Convergence: 0.1069 k= 0.033238 lr = 0.0000540\n",
      "[3/25][8510/9765] Loss_D: 0.1226 Loss_G: 0.0449 Convergence: 0.1288 k= 0.033228 lr = 0.0000540\n",
      "[3/25][8520/9765] Loss_D: 0.0926 Loss_G: 0.0441 Convergence: 0.1005 k= 0.033249 lr = 0.0000540\n",
      "[3/25][8530/9765] Loss_D: 0.1036 Loss_G: 0.0440 Convergence: 0.1071 k= 0.033212 lr = 0.0000540\n",
      "[3/25][8540/9765] Loss_D: 0.1097 Loss_G: 0.0454 Convergence: 0.1120 k= 0.033232 lr = 0.0000540\n",
      "[3/25][8550/9765] Loss_D: 0.1133 Loss_G: 0.0446 Convergence: 0.1159 k= 0.033220 lr = 0.0000540\n",
      "[3/25][8560/9765] Loss_D: 0.1067 Loss_G: 0.0481 Convergence: 0.1130 k= 0.033227 lr = 0.0000540\n",
      "[3/25][8570/9765] Loss_D: 0.1038 Loss_G: 0.0404 Convergence: 0.1070 k= 0.033247 lr = 0.0000540\n",
      "[3/25][8580/9765] Loss_D: 0.0998 Loss_G: 0.0420 Convergence: 0.1028 k= 0.033230 lr = 0.0000540\n",
      "[3/25][8590/9765] Loss_D: 0.1018 Loss_G: 0.0420 Convergence: 0.1039 k= 0.033213 lr = 0.0000540\n",
      "[3/25][8600/9765] Loss_D: 0.1015 Loss_G: 0.0426 Convergence: 0.1043 k= 0.033215 lr = 0.0000540\n",
      "[3/25][8610/9765] Loss_D: 0.1117 Loss_G: 0.0470 Convergence: 0.1149 k= 0.033213 lr = 0.0000540\n",
      "[3/25][8620/9765] Loss_D: 0.0958 Loss_G: 0.0411 Convergence: 0.0994 k= 0.033183 lr = 0.0000540\n",
      "[3/25][8630/9765] Loss_D: 0.1087 Loss_G: 0.0417 Convergence: 0.1124 k= 0.033203 lr = 0.0000540\n",
      "[3/25][8640/9765] Loss_D: 0.1069 Loss_G: 0.0443 Convergence: 0.1092 k= 0.033204 lr = 0.0000540\n",
      "[3/25][8650/9765] Loss_D: 0.1010 Loss_G: 0.0423 Convergence: 0.1037 k= 0.033195 lr = 0.0000540\n",
      "[3/25][8660/9765] Loss_D: 0.1067 Loss_G: 0.0423 Convergence: 0.1090 k= 0.033195 lr = 0.0000540\n",
      "[3/25][8670/9765] Loss_D: 0.0980 Loss_G: 0.0448 Convergence: 0.1044 k= 0.033175 lr = 0.0000540\n",
      "[3/25][8680/9765] Loss_D: 0.1009 Loss_G: 0.0417 Convergence: 0.1030 k= 0.033174 lr = 0.0000540\n",
      "[3/25][8690/9765] Loss_D: 0.1084 Loss_G: 0.0380 Convergence: 0.1154 k= 0.033206 lr = 0.0000540\n",
      "[3/25][8700/9765] Loss_D: 0.1071 Loss_G: 0.0416 Convergence: 0.1106 k= 0.033202 lr = 0.0000540\n",
      "[3/25][8710/9765] Loss_D: 0.1045 Loss_G: 0.0436 Convergence: 0.1071 k= 0.033190 lr = 0.0000540\n",
      "[3/25][8720/9765] Loss_D: 0.1026 Loss_G: 0.0447 Convergence: 0.1071 k= 0.033186 lr = 0.0000540\n",
      "[3/25][8730/9765] Loss_D: 0.1011 Loss_G: 0.0422 Convergence: 0.1037 k= 0.033153 lr = 0.0000540\n",
      "[3/25][8740/9765] Loss_D: 0.1040 Loss_G: 0.0412 Convergence: 0.1063 k= 0.033177 lr = 0.0000540\n",
      "[3/25][8750/9765] Loss_D: 0.1041 Loss_G: 0.0428 Convergence: 0.1061 k= 0.033182 lr = 0.0000540\n",
      "[3/25][8760/9765] Loss_D: 0.1013 Loss_G: 0.0420 Convergence: 0.1036 k= 0.033181 lr = 0.0000540\n",
      "[3/25][8770/9765] Loss_D: 0.1015 Loss_G: 0.0466 Convergence: 0.1084 k= 0.033164 lr = 0.0000540\n",
      "[3/25][8780/9765] Loss_D: 0.1046 Loss_G: 0.0376 Convergence: 0.1109 k= 0.033196 lr = 0.0000540\n",
      "[3/25][8790/9765] Loss_D: 0.1079 Loss_G: 0.0483 Convergence: 0.1139 k= 0.033216 lr = 0.0000540\n",
      "[3/25][8800/9765] Loss_D: 0.1019 Loss_G: 0.0458 Convergence: 0.1079 k= 0.033174 lr = 0.0000540\n",
      "[3/25][8810/9765] Loss_D: 0.1000 Loss_G: 0.0443 Convergence: 0.1051 k= 0.033186 lr = 0.0000540\n",
      "[3/25][8820/9765] Loss_D: 0.0986 Loss_G: 0.0464 Convergence: 0.1063 k= 0.033173 lr = 0.0000540\n",
      "[3/25][8830/9765] Loss_D: 0.1119 Loss_G: 0.0477 Convergence: 0.1157 k= 0.033167 lr = 0.0000540\n",
      "[3/25][8840/9765] Loss_D: 0.1007 Loss_G: 0.0412 Convergence: 0.1024 k= 0.033158 lr = 0.0000540\n",
      "[3/25][8850/9765] Loss_D: 0.1034 Loss_G: 0.0469 Convergence: 0.1098 k= 0.033140 lr = 0.0000540\n",
      "[3/25][8860/9765] Loss_D: 0.1037 Loss_G: 0.0436 Convergence: 0.1067 k= 0.033133 lr = 0.0000540\n",
      "[3/25][8870/9765] Loss_D: 0.0991 Loss_G: 0.0471 Convergence: 0.1074 k= 0.033116 lr = 0.0000540\n",
      "[3/25][8880/9765] Loss_D: 0.0970 Loss_G: 0.0424 Convergence: 0.1015 k= 0.033103 lr = 0.0000540\n",
      "[3/25][8890/9765] Loss_D: 0.1006 Loss_G: 0.0465 Convergence: 0.1077 k= 0.033076 lr = 0.0000540\n",
      "[3/25][8900/9765] Loss_D: 0.0986 Loss_G: 0.0392 Convergence: 0.1007 k= 0.033072 lr = 0.0000540\n",
      "[3/25][8910/9765] Loss_D: 0.1092 Loss_G: 0.0424 Convergence: 0.1124 k= 0.033081 lr = 0.0000540\n",
      "[3/25][8920/9765] Loss_D: 0.1084 Loss_G: 0.0401 Convergence: 0.1136 k= 0.033077 lr = 0.0000540\n",
      "[3/25][8930/9765] Loss_D: 0.1037 Loss_G: 0.0461 Convergence: 0.1091 k= 0.033061 lr = 0.0000540\n",
      "[3/25][8940/9765] Loss_D: 0.1021 Loss_G: 0.0401 Convergence: 0.1047 k= 0.033050 lr = 0.0000540\n",
      "[3/25][8950/9765] Loss_D: 0.1059 Loss_G: 0.0436 Convergence: 0.1080 k= 0.033058 lr = 0.0000540\n",
      "[3/25][8960/9765] Loss_D: 0.1099 Loss_G: 0.0433 Convergence: 0.1127 k= 0.033025 lr = 0.0000540\n",
      "[3/25][8970/9765] Loss_D: 0.1030 Loss_G: 0.0453 Convergence: 0.1080 k= 0.033034 lr = 0.0000540\n",
      "[3/25][8980/9765] Loss_D: 0.1092 Loss_G: 0.0434 Convergence: 0.1113 k= 0.033021 lr = 0.0000540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/25][8990/9765] Loss_D: 0.1120 Loss_G: 0.0408 Convergence: 0.1178 k= 0.033038 lr = 0.0000540\n",
      "[3/25][9000/9765] Loss_D: 0.1061 Loss_G: 0.0372 Convergence: 0.1133 k= 0.033074 lr = 0.0000540\n",
      "[3/25][9010/9765] Loss_D: 0.1073 Loss_G: 0.0408 Convergence: 0.1114 k= 0.033075 lr = 0.0000540\n",
      "[3/25][9020/9765] Loss_D: 0.1030 Loss_G: 0.0426 Convergence: 0.1052 k= 0.033065 lr = 0.0000540\n",
      "[3/25][9030/9765] Loss_D: 0.1053 Loss_G: 0.0389 Convergence: 0.1105 k= 0.033064 lr = 0.0000540\n",
      "[3/25][9040/9765] Loss_D: 0.0971 Loss_G: 0.0431 Convergence: 0.1022 k= 0.033060 lr = 0.0000540\n",
      "[3/25][9050/9765] Loss_D: 0.1065 Loss_G: 0.0483 Convergence: 0.1131 k= 0.033059 lr = 0.0000540\n",
      "[3/25][9060/9765] Loss_D: 0.1069 Loss_G: 0.0459 Convergence: 0.1111 k= 0.033044 lr = 0.0000540\n",
      "[3/25][9070/9765] Loss_D: 0.1030 Loss_G: 0.0422 Convergence: 0.1048 k= 0.033040 lr = 0.0000540\n",
      "[3/25][9080/9765] Loss_D: 0.0989 Loss_G: 0.0445 Convergence: 0.1047 k= 0.032998 lr = 0.0000540\n",
      "[3/25][9090/9765] Loss_D: 0.1027 Loss_G: 0.0414 Convergence: 0.1042 k= 0.032989 lr = 0.0000540\n",
      "[3/25][9100/9765] Loss_D: 0.1010 Loss_G: 0.0364 Convergence: 0.1067 k= 0.033012 lr = 0.0000540\n",
      "[3/25][9110/9765] Loss_D: 0.1031 Loss_G: 0.0426 Convergence: 0.1053 k= 0.033027 lr = 0.0000540\n",
      "[3/25][9120/9765] Loss_D: 0.0986 Loss_G: 0.0429 Convergence: 0.1028 k= 0.033012 lr = 0.0000540\n",
      "[3/25][9130/9765] Loss_D: 0.1065 Loss_G: 0.0440 Convergence: 0.1088 k= 0.033009 lr = 0.0000540\n",
      "[3/25][9140/9765] Loss_D: 0.1033 Loss_G: 0.0412 Convergence: 0.1054 k= 0.033001 lr = 0.0000540\n",
      "[3/25][9150/9765] Loss_D: 0.1021 Loss_G: 0.0422 Convergence: 0.1043 k= 0.032996 lr = 0.0000540\n",
      "[3/25][9160/9765] Loss_D: 0.1107 Loss_G: 0.0440 Convergence: 0.1130 k= 0.032999 lr = 0.0000540\n",
      "[3/25][9170/9765] Loss_D: 0.1041 Loss_G: 0.0436 Convergence: 0.1069 k= 0.033008 lr = 0.0000540\n",
      "[3/25][9180/9765] Loss_D: 0.0950 Loss_G: 0.0411 Convergence: 0.0989 k= 0.032994 lr = 0.0000540\n",
      "[3/25][9190/9765] Loss_D: 0.1187 Loss_G: 0.0408 Convergence: 0.1272 k= 0.033005 lr = 0.0000540\n",
      "[3/25][9200/9765] Loss_D: 0.1065 Loss_G: 0.0413 Convergence: 0.1096 k= 0.033026 lr = 0.0000540\n",
      "[3/25][9210/9765] Loss_D: 0.1013 Loss_G: 0.0482 Convergence: 0.1100 k= 0.033008 lr = 0.0000540\n",
      "[3/25][9220/9765] Loss_D: 0.1086 Loss_G: 0.0456 Convergence: 0.1116 k= 0.032991 lr = 0.0000540\n",
      "[3/25][9230/9765] Loss_D: 0.1082 Loss_G: 0.0371 Convergence: 0.1161 k= 0.032980 lr = 0.0000540\n",
      "[3/25][9240/9765] Loss_D: 0.1041 Loss_G: 0.0398 Convergence: 0.1078 k= 0.033001 lr = 0.0000540\n",
      "[3/25][9250/9765] Loss_D: 0.1071 Loss_G: 0.0415 Convergence: 0.1102 k= 0.033009 lr = 0.0000540\n",
      "[3/25][9260/9765] Loss_D: 0.1010 Loss_G: 0.0433 Convergence: 0.1047 k= 0.032991 lr = 0.0000540\n",
      "[3/25][9270/9765] Loss_D: 0.1079 Loss_G: 0.0424 Convergence: 0.1105 k= 0.032983 lr = 0.0000540\n",
      "[3/25][9280/9765] Loss_D: 0.1083 Loss_G: 0.0406 Convergence: 0.1129 k= 0.032985 lr = 0.0000540\n",
      "[3/25][9290/9765] Loss_D: 0.0997 Loss_G: 0.0428 Convergence: 0.1034 k= 0.032980 lr = 0.0000540\n",
      "[3/25][9300/9765] Loss_D: 0.1034 Loss_G: 0.0399 Convergence: 0.1069 k= 0.032963 lr = 0.0000540\n",
      "[3/25][9310/9765] Loss_D: 0.0925 Loss_G: 0.0563 Convergence: 0.1127 k= 0.032937 lr = 0.0000540\n",
      "[3/25][9320/9765] Loss_D: 0.1187 Loss_G: 0.0414 Convergence: 0.1270 k= 0.032933 lr = 0.0000540\n",
      "[3/25][9330/9765] Loss_D: 0.1039 Loss_G: 0.0478 Convergence: 0.1111 k= 0.032907 lr = 0.0000540\n",
      "[3/25][9340/9765] Loss_D: 0.1123 Loss_G: 0.0465 Convergence: 0.1147 k= 0.032922 lr = 0.0000540\n",
      "[3/25][9350/9765] Loss_D: 0.1057 Loss_G: 0.0480 Convergence: 0.1123 k= 0.032923 lr = 0.0000540\n",
      "[3/25][9360/9765] Loss_D: 0.1073 Loss_G: 0.0425 Convergence: 0.1096 k= 0.032927 lr = 0.0000540\n",
      "[3/25][9370/9765] Loss_D: 0.1103 Loss_G: 0.0477 Convergence: 0.1147 k= 0.032908 lr = 0.0000540\n",
      "[3/25][9380/9765] Loss_D: 0.0953 Loss_G: 0.0418 Convergence: 0.0998 k= 0.032938 lr = 0.0000540\n",
      "[3/25][9390/9765] Loss_D: 0.1071 Loss_G: 0.0373 Convergence: 0.1143 k= 0.032976 lr = 0.0000540\n",
      "[3/25][9400/9765] Loss_D: 0.1026 Loss_G: 0.0479 Convergence: 0.1105 k= 0.032977 lr = 0.0000540\n",
      "[3/25][9410/9765] Loss_D: 0.1015 Loss_G: 0.0487 Convergence: 0.1104 k= 0.032947 lr = 0.0000540\n",
      "[3/25][9420/9765] Loss_D: 0.1086 Loss_G: 0.0424 Convergence: 0.1118 k= 0.032936 lr = 0.0000540\n",
      "[3/25][9430/9765] Loss_D: 0.1022 Loss_G: 0.0430 Convergence: 0.1052 k= 0.032926 lr = 0.0000540\n",
      "[3/25][9440/9765] Loss_D: 0.1054 Loss_G: 0.0426 Convergence: 0.1070 k= 0.032928 lr = 0.0000540\n",
      "[3/25][9450/9765] Loss_D: 0.0989 Loss_G: 0.0415 Convergence: 0.1015 k= 0.032959 lr = 0.0000540\n",
      "[3/25][9460/9765] Loss_D: 0.1008 Loss_G: 0.0433 Convergence: 0.1046 k= 0.032951 lr = 0.0000540\n",
      "[3/25][9470/9765] Loss_D: 0.1021 Loss_G: 0.0409 Convergence: 0.1041 k= 0.032925 lr = 0.0000540\n",
      "[3/25][9480/9765] Loss_D: 0.0981 Loss_G: 0.0511 Convergence: 0.1107 k= 0.032913 lr = 0.0000540\n",
      "[3/25][9490/9765] Loss_D: 0.1042 Loss_G: 0.0430 Convergence: 0.1063 k= 0.032919 lr = 0.0000540\n",
      "[3/25][9500/9765] Loss_D: 0.0995 Loss_G: 0.0408 Convergence: 0.1014 k= 0.032903 lr = 0.0000540\n",
      "[3/25][9510/9765] Loss_D: 0.0994 Loss_G: 0.0426 Convergence: 0.1031 k= 0.032915 lr = 0.0000540\n",
      "[3/25][9520/9765] Loss_D: 0.1094 Loss_G: 0.0508 Convergence: 0.1173 k= 0.032901 lr = 0.0000540\n",
      "[3/25][9530/9765] Loss_D: 0.1034 Loss_G: 0.0395 Convergence: 0.1070 k= 0.032859 lr = 0.0000540\n",
      "[3/25][9540/9765] Loss_D: 0.1038 Loss_G: 0.0404 Convergence: 0.1067 k= 0.032858 lr = 0.0000540\n",
      "[3/25][9550/9765] Loss_D: 0.1002 Loss_G: 0.0465 Convergence: 0.1075 k= 0.032845 lr = 0.0000540\n",
      "[3/25][9560/9765] Loss_D: 0.1082 Loss_G: 0.0430 Convergence: 0.1104 k= 0.032844 lr = 0.0000540\n",
      "[3/25][9570/9765] Loss_D: 0.1016 Loss_G: 0.0401 Convergence: 0.1041 k= 0.032821 lr = 0.0000540\n",
      "[3/25][9580/9765] Loss_D: 0.1007 Loss_G: 0.0434 Convergence: 0.1047 k= 0.032833 lr = 0.0000540\n",
      "[3/25][9590/9765] Loss_D: 0.1056 Loss_G: 0.0443 Convergence: 0.1085 k= 0.032833 lr = 0.0000540\n",
      "[3/25][9600/9765] Loss_D: 0.1001 Loss_G: 0.0380 Convergence: 0.1040 k= 0.032849 lr = 0.0000540\n",
      "[3/25][9610/9765] Loss_D: 0.1038 Loss_G: 0.0438 Convergence: 0.1068 k= 0.032848 lr = 0.0000540\n",
      "[3/25][9620/9765] Loss_D: 0.1091 Loss_G: 0.0441 Convergence: 0.1105 k= 0.032853 lr = 0.0000540\n",
      "[3/25][9630/9765] Loss_D: 0.1116 Loss_G: 0.0409 Convergence: 0.1171 k= 0.032847 lr = 0.0000540\n",
      "[3/25][9640/9765] Loss_D: 0.1132 Loss_G: 0.0420 Convergence: 0.1183 k= 0.032859 lr = 0.0000540\n",
      "[3/25][9650/9765] Loss_D: 0.1052 Loss_G: 0.0475 Convergence: 0.1114 k= 0.032849 lr = 0.0000540\n",
      "[3/25][9660/9765] Loss_D: 0.1064 Loss_G: 0.0425 Convergence: 0.1084 k= 0.032855 lr = 0.0000540\n",
      "[3/25][9670/9765] Loss_D: 0.1037 Loss_G: 0.0454 Convergence: 0.1084 k= 0.032828 lr = 0.0000540\n",
      "[3/25][9680/9765] Loss_D: 0.1147 Loss_G: 0.0395 Convergence: 0.1228 k= 0.032841 lr = 0.0000540\n",
      "[3/25][9690/9765] Loss_D: 0.1032 Loss_G: 0.0510 Convergence: 0.1138 k= 0.032808 lr = 0.0000540\n",
      "[3/25][9700/9765] Loss_D: 0.1020 Loss_G: 0.0435 Convergence: 0.1056 k= 0.032760 lr = 0.0000540\n",
      "[3/25][9710/9765] Loss_D: 0.0976 Loss_G: 0.0425 Convergence: 0.1018 k= 0.032746 lr = 0.0000513\n",
      "[3/25][9720/9765] Loss_D: 0.1002 Loss_G: 0.0446 Convergence: 0.1056 k= 0.032743 lr = 0.0000513\n",
      "[3/25][9730/9765] Loss_D: 0.1055 Loss_G: 0.0494 Convergence: 0.1136 k= 0.032728 lr = 0.0000513\n",
      "[3/25][9740/9765] Loss_D: 0.1102 Loss_G: 0.0455 Convergence: 0.1124 k= 0.032740 lr = 0.0000513\n",
      "[3/25][9750/9765] Loss_D: 0.1012 Loss_G: 0.0421 Convergence: 0.1037 k= 0.032750 lr = 0.0000513\n",
      "[3/25][9760/9765] Loss_D: 0.1053 Loss_G: 0.0418 Convergence: 0.1075 k= 0.032744 lr = 0.0000513\n",
      "[4/25][0/9765] Loss_D: 0.1067 Loss_G: 0.0452 Convergence: 0.1101 k= 0.032747 lr = 0.0000513\n",
      "[4/25][10/9765] Loss_D: 0.0993 Loss_G: 0.0379 Convergence: 0.1029 k= 0.032739 lr = 0.0000513\n",
      "[4/25][20/9765] Loss_D: 0.0985 Loss_G: 0.0403 Convergence: 0.1002 k= 0.032727 lr = 0.0000513\n",
      "[4/25][30/9765] Loss_D: 0.1122 Loss_G: 0.0439 Convergence: 0.1152 k= 0.032701 lr = 0.0000513\n",
      "[4/25][40/9765] Loss_D: 0.1068 Loss_G: 0.0395 Convergence: 0.1119 k= 0.032707 lr = 0.0000513\n",
      "[4/25][50/9765] Loss_D: 0.1054 Loss_G: 0.0449 Convergence: 0.1090 k= 0.032705 lr = 0.0000513\n",
      "[4/25][60/9765] Loss_D: 0.1064 Loss_G: 0.0380 Convergence: 0.1127 k= 0.032717 lr = 0.0000513\n",
      "[4/25][70/9765] Loss_D: 0.1004 Loss_G: 0.0402 Convergence: 0.1021 k= 0.032739 lr = 0.0000513\n",
      "[4/25][80/9765] Loss_D: 0.0994 Loss_G: 0.0409 Convergence: 0.1013 k= 0.032745 lr = 0.0000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][90/9765] Loss_D: 0.1072 Loss_G: 0.0441 Convergence: 0.1092 k= 0.032730 lr = 0.0000513\n",
      "[4/25][100/9765] Loss_D: 0.1055 Loss_G: 0.0424 Convergence: 0.1072 k= 0.032730 lr = 0.0000513\n",
      "[4/25][110/9765] Loss_D: 0.0981 Loss_G: 0.0442 Convergence: 0.1038 k= 0.032719 lr = 0.0000513\n",
      "[4/25][120/9765] Loss_D: 0.1016 Loss_G: 0.0425 Convergence: 0.1044 k= 0.032700 lr = 0.0000513\n",
      "[4/25][130/9765] Loss_D: 0.0983 Loss_G: 0.0411 Convergence: 0.1009 k= 0.032717 lr = 0.0000513\n",
      "[4/25][140/9765] Loss_D: 0.1107 Loss_G: 0.0421 Convergence: 0.1148 k= 0.032732 lr = 0.0000513\n",
      "[4/25][150/9765] Loss_D: 0.1036 Loss_G: 0.0470 Convergence: 0.1101 k= 0.032723 lr = 0.0000513\n",
      "[4/25][160/9765] Loss_D: 0.1097 Loss_G: 0.0419 Convergence: 0.1137 k= 0.032671 lr = 0.0000513\n",
      "[4/25][170/9765] Loss_D: 0.1053 Loss_G: 0.0447 Convergence: 0.1087 k= 0.032667 lr = 0.0000513\n",
      "[4/25][180/9765] Loss_D: 0.1121 Loss_G: 0.0406 Convergence: 0.1182 k= 0.032674 lr = 0.0000513\n",
      "[4/25][190/9765] Loss_D: 0.1026 Loss_G: 0.0424 Convergence: 0.1048 k= 0.032689 lr = 0.0000513\n",
      "[4/25][200/9765] Loss_D: 0.1053 Loss_G: 0.0440 Convergence: 0.1081 k= 0.032682 lr = 0.0000513\n",
      "[4/25][210/9765] Loss_D: 0.1062 Loss_G: 0.0390 Convergence: 0.1115 k= 0.032694 lr = 0.0000513\n",
      "[4/25][220/9765] Loss_D: 0.1055 Loss_G: 0.0431 Convergence: 0.1071 k= 0.032708 lr = 0.0000513\n",
      "[4/25][230/9765] Loss_D: 0.1023 Loss_G: 0.0446 Convergence: 0.1069 k= 0.032675 lr = 0.0000513\n",
      "[4/25][240/9765] Loss_D: 0.0948 Loss_G: 0.0389 Convergence: 0.0966 k= 0.032678 lr = 0.0000513\n",
      "[4/25][250/9765] Loss_D: 0.1074 Loss_G: 0.0386 Convergence: 0.1134 k= 0.032695 lr = 0.0000513\n",
      "[4/25][260/9765] Loss_D: 0.1029 Loss_G: 0.0395 Convergence: 0.1064 k= 0.032704 lr = 0.0000513\n",
      "[4/25][270/9765] Loss_D: 0.0959 Loss_G: 0.0423 Convergence: 0.1007 k= 0.032695 lr = 0.0000513\n",
      "[4/25][280/9765] Loss_D: 0.1099 Loss_G: 0.0451 Convergence: 0.1119 k= 0.032699 lr = 0.0000513\n",
      "[4/25][290/9765] Loss_D: 0.1035 Loss_G: 0.0423 Convergence: 0.1052 k= 0.032684 lr = 0.0000513\n",
      "[4/25][300/9765] Loss_D: 0.1039 Loss_G: 0.0437 Convergence: 0.1069 k= 0.032683 lr = 0.0000513\n",
      "[4/25][310/9765] Loss_D: 0.0946 Loss_G: 0.0426 Convergence: 0.1001 k= 0.032683 lr = 0.0000513\n",
      "[4/25][320/9765] Loss_D: 0.0943 Loss_G: 0.0407 Convergence: 0.0982 k= 0.032642 lr = 0.0000513\n",
      "[4/25][330/9765] Loss_D: 0.1023 Loss_G: 0.0375 Convergence: 0.1076 k= 0.032634 lr = 0.0000513\n",
      "[4/25][340/9765] Loss_D: 0.1084 Loss_G: 0.0452 Convergence: 0.1111 k= 0.032660 lr = 0.0000513\n",
      "[4/25][350/9765] Loss_D: 0.1018 Loss_G: 0.0433 Convergence: 0.1052 k= 0.032643 lr = 0.0000513\n",
      "[4/25][360/9765] Loss_D: 0.1004 Loss_G: 0.0416 Convergence: 0.1027 k= 0.032657 lr = 0.0000513\n",
      "[4/25][370/9765] Loss_D: 0.1017 Loss_G: 0.0409 Convergence: 0.1035 k= 0.032636 lr = 0.0000513\n",
      "[4/25][380/9765] Loss_D: 0.1080 Loss_G: 0.0439 Convergence: 0.1095 k= 0.032650 lr = 0.0000513\n",
      "[4/25][390/9765] Loss_D: 0.0997 Loss_G: 0.0425 Convergence: 0.1032 k= 0.032660 lr = 0.0000513\n",
      "[4/25][400/9765] Loss_D: 0.1106 Loss_G: 0.0466 Convergence: 0.1139 k= 0.032637 lr = 0.0000513\n",
      "[4/25][410/9765] Loss_D: 0.1087 Loss_G: 0.0409 Convergence: 0.1133 k= 0.032623 lr = 0.0000513\n",
      "[4/25][420/9765] Loss_D: 0.0983 Loss_G: 0.0404 Convergence: 0.1002 k= 0.032605 lr = 0.0000513\n",
      "[4/25][430/9765] Loss_D: 0.1033 Loss_G: 0.0382 Convergence: 0.1083 k= 0.032625 lr = 0.0000513\n",
      "[4/25][440/9765] Loss_D: 0.0987 Loss_G: 0.0380 Convergence: 0.1019 k= 0.032634 lr = 0.0000513\n",
      "[4/25][450/9765] Loss_D: 0.0999 Loss_G: 0.0409 Convergence: 0.1016 k= 0.032638 lr = 0.0000513\n",
      "[4/25][460/9765] Loss_D: 0.1019 Loss_G: 0.0376 Convergence: 0.1070 k= 0.032639 lr = 0.0000513\n",
      "[4/25][470/9765] Loss_D: 0.0952 Loss_G: 0.0407 Convergence: 0.0985 k= 0.032640 lr = 0.0000513\n",
      "[4/25][480/9765] Loss_D: 0.1024 Loss_G: 0.0419 Convergence: 0.1042 k= 0.032628 lr = 0.0000513\n",
      "[4/25][490/9765] Loss_D: 0.1121 Loss_G: 0.0422 Convergence: 0.1167 k= 0.032641 lr = 0.0000513\n",
      "[4/25][500/9765] Loss_D: 0.1041 Loss_G: 0.0442 Convergence: 0.1076 k= 0.032629 lr = 0.0000513\n",
      "[4/25][510/9765] Loss_D: 0.1097 Loss_G: 0.0439 Convergence: 0.1115 k= 0.032620 lr = 0.0000513\n",
      "[4/25][520/9765] Loss_D: 0.1015 Loss_G: 0.0391 Convergence: 0.1049 k= 0.032603 lr = 0.0000513\n",
      "[4/25][530/9765] Loss_D: 0.1084 Loss_G: 0.0368 Convergence: 0.1168 k= 0.032633 lr = 0.0000513\n",
      "[4/25][540/9765] Loss_D: 0.1091 Loss_G: 0.0498 Convergence: 0.1160 k= 0.032626 lr = 0.0000513\n",
      "[4/25][550/9765] Loss_D: 0.0970 Loss_G: 0.0417 Convergence: 0.1007 k= 0.032606 lr = 0.0000513\n",
      "[4/25][560/9765] Loss_D: 0.1197 Loss_G: 0.0445 Convergence: 0.1251 k= 0.032592 lr = 0.0000513\n",
      "[4/25][570/9765] Loss_D: 0.1097 Loss_G: 0.0452 Convergence: 0.1117 k= 0.032599 lr = 0.0000513\n",
      "[4/25][580/9765] Loss_D: 0.1189 Loss_G: 0.0438 Convergence: 0.1244 k= 0.032567 lr = 0.0000513\n",
      "[4/25][590/9765] Loss_D: 0.0996 Loss_G: 0.0386 Convergence: 0.1028 k= 0.032569 lr = 0.0000513\n",
      "[4/25][600/9765] Loss_D: 0.0979 Loss_G: 0.0424 Convergence: 0.1019 k= 0.032541 lr = 0.0000513\n",
      "[4/25][610/9765] Loss_D: 0.0967 Loss_G: 0.0355 Convergence: 0.1017 k= 0.032553 lr = 0.0000513\n",
      "[4/25][620/9765] Loss_D: 0.1141 Loss_G: 0.0478 Convergence: 0.1172 k= 0.032582 lr = 0.0000513\n",
      "[4/25][630/9765] Loss_D: 0.1107 Loss_G: 0.0437 Convergence: 0.1133 k= 0.032540 lr = 0.0000513\n",
      "[4/25][640/9765] Loss_D: 0.1023 Loss_G: 0.0446 Convergence: 0.1068 k= 0.032537 lr = 0.0000513\n",
      "[4/25][650/9765] Loss_D: 0.0996 Loss_G: 0.0448 Convergence: 0.1055 k= 0.032537 lr = 0.0000513\n",
      "[4/25][660/9765] Loss_D: 0.1112 Loss_G: 0.0407 Convergence: 0.1168 k= 0.032527 lr = 0.0000513\n",
      "[4/25][670/9765] Loss_D: 0.1054 Loss_G: 0.0420 Convergence: 0.1076 k= 0.032513 lr = 0.0000513\n",
      "[4/25][680/9765] Loss_D: 0.1016 Loss_G: 0.0421 Convergence: 0.1040 k= 0.032500 lr = 0.0000513\n",
      "[4/25][690/9765] Loss_D: 0.1103 Loss_G: 0.0436 Convergence: 0.1126 k= 0.032509 lr = 0.0000513\n",
      "[4/25][700/9765] Loss_D: 0.1027 Loss_G: 0.0449 Convergence: 0.1074 k= 0.032478 lr = 0.0000513\n",
      "[4/25][710/9765] Loss_D: 0.1091 Loss_G: 0.0424 Convergence: 0.1121 k= 0.032477 lr = 0.0000513\n",
      "[4/25][720/9765] Loss_D: 0.0990 Loss_G: 0.0414 Convergence: 0.1016 k= 0.032490 lr = 0.0000513\n",
      "[4/25][730/9765] Loss_D: 0.0985 Loss_G: 0.0410 Convergence: 0.1008 k= 0.032496 lr = 0.0000513\n",
      "[4/25][740/9765] Loss_D: 0.1012 Loss_G: 0.0435 Convergence: 0.1050 k= 0.032515 lr = 0.0000513\n",
      "[4/25][750/9765] Loss_D: 0.0986 Loss_G: 0.0388 Convergence: 0.1010 k= 0.032542 lr = 0.0000513\n",
      "[4/25][760/9765] Loss_D: 0.1109 Loss_G: 0.0442 Convergence: 0.1131 k= 0.032556 lr = 0.0000513\n",
      "[4/25][770/9765] Loss_D: 0.0977 Loss_G: 0.0480 Convergence: 0.1074 k= 0.032564 lr = 0.0000513\n",
      "[4/25][780/9765] Loss_D: 0.1122 Loss_G: 0.0360 Convergence: 0.1228 k= 0.032575 lr = 0.0000513\n",
      "[4/25][790/9765] Loss_D: 0.0980 Loss_G: 0.0391 Convergence: 0.0999 k= 0.032565 lr = 0.0000513\n",
      "[4/25][800/9765] Loss_D: 0.1068 Loss_G: 0.0417 Convergence: 0.1096 k= 0.032591 lr = 0.0000513\n",
      "[4/25][810/9765] Loss_D: 0.1077 Loss_G: 0.0458 Convergence: 0.1111 k= 0.032603 lr = 0.0000513\n",
      "[4/25][820/9765] Loss_D: 0.0980 Loss_G: 0.0444 Convergence: 0.1041 k= 0.032553 lr = 0.0000513\n",
      "[4/25][830/9765] Loss_D: 0.1111 Loss_G: 0.0408 Convergence: 0.1164 k= 0.032546 lr = 0.0000513\n",
      "[4/25][840/9765] Loss_D: 0.1062 Loss_G: 0.0395 Convergence: 0.1112 k= 0.032538 lr = 0.0000513\n",
      "[4/25][850/9765] Loss_D: 0.1039 Loss_G: 0.0425 Convergence: 0.1056 k= 0.032535 lr = 0.0000513\n",
      "[4/25][860/9765] Loss_D: 0.1007 Loss_G: 0.0400 Convergence: 0.1029 k= 0.032544 lr = 0.0000513\n",
      "[4/25][870/9765] Loss_D: 0.1051 Loss_G: 0.0426 Convergence: 0.1065 k= 0.032550 lr = 0.0000513\n",
      "[4/25][880/9765] Loss_D: 0.0966 Loss_G: 0.0393 Convergence: 0.0981 k= 0.032548 lr = 0.0000513\n",
      "[4/25][890/9765] Loss_D: 0.1100 Loss_G: 0.0429 Convergence: 0.1129 k= 0.032547 lr = 0.0000513\n",
      "[4/25][900/9765] Loss_D: 0.1060 Loss_G: 0.0427 Convergence: 0.1075 k= 0.032572 lr = 0.0000513\n",
      "[4/25][910/9765] Loss_D: 0.1070 Loss_G: 0.0415 Convergence: 0.1103 k= 0.032563 lr = 0.0000513\n",
      "[4/25][920/9765] Loss_D: 0.1017 Loss_G: 0.0386 Convergence: 0.1057 k= 0.032548 lr = 0.0000513\n",
      "[4/25][930/9765] Loss_D: 0.1010 Loss_G: 0.0415 Convergence: 0.1030 k= 0.032559 lr = 0.0000513\n",
      "[4/25][940/9765] Loss_D: 0.0975 Loss_G: 0.0408 Convergence: 0.1001 k= 0.032550 lr = 0.0000513\n",
      "[4/25][950/9765] Loss_D: 0.0988 Loss_G: 0.0403 Convergence: 0.1004 k= 0.032555 lr = 0.0000513\n",
      "[4/25][960/9765] Loss_D: 0.1064 Loss_G: 0.0400 Convergence: 0.1110 k= 0.032545 lr = 0.0000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][970/9765] Loss_D: 0.1041 Loss_G: 0.0415 Convergence: 0.1061 k= 0.032543 lr = 0.0000513\n",
      "[4/25][980/9765] Loss_D: 0.1123 Loss_G: 0.0410 Convergence: 0.1180 k= 0.032560 lr = 0.0000513\n",
      "[4/25][990/9765] Loss_D: 0.0998 Loss_G: 0.0399 Convergence: 0.1015 k= 0.032574 lr = 0.0000513\n",
      "[4/25][1000/9765] Loss_D: 0.0977 Loss_G: 0.0398 Convergence: 0.0992 k= 0.032584 lr = 0.0000513\n",
      "[4/25][1010/9765] Loss_D: 0.1148 Loss_G: 0.0544 Convergence: 0.1241 k= 0.032540 lr = 0.0000513\n",
      "[4/25][1020/9765] Loss_D: 0.0962 Loss_G: 0.0403 Convergence: 0.0988 k= 0.032524 lr = 0.0000513\n",
      "[4/25][1030/9765] Loss_D: 0.0944 Loss_G: 0.0437 Convergence: 0.1011 k= 0.032536 lr = 0.0000513\n",
      "[4/25][1040/9765] Loss_D: 0.1001 Loss_G: 0.0437 Convergence: 0.1046 k= 0.032490 lr = 0.0000513\n",
      "[4/25][1050/9765] Loss_D: 0.1018 Loss_G: 0.0410 Convergence: 0.1032 k= 0.032491 lr = 0.0000513\n",
      "[4/25][1060/9765] Loss_D: 0.0987 Loss_G: 0.0411 Convergence: 0.1012 k= 0.032488 lr = 0.0000513\n",
      "[4/25][1070/9765] Loss_D: 0.1032 Loss_G: 0.0432 Convergence: 0.1059 k= 0.032464 lr = 0.0000513\n",
      "[4/25][1080/9765] Loss_D: 0.1007 Loss_G: 0.0400 Convergence: 0.1028 k= 0.032462 lr = 0.0000513\n",
      "[4/25][1090/9765] Loss_D: 0.1055 Loss_G: 0.0437 Convergence: 0.1078 k= 0.032465 lr = 0.0000513\n",
      "[4/25][1100/9765] Loss_D: 0.1151 Loss_G: 0.0437 Convergence: 0.1195 k= 0.032446 lr = 0.0000513\n",
      "[4/25][1110/9765] Loss_D: 0.1119 Loss_G: 0.0422 Convergence: 0.1164 k= 0.032428 lr = 0.0000513\n",
      "[4/25][1120/9765] Loss_D: 0.1160 Loss_G: 0.0389 Convergence: 0.1254 k= 0.032446 lr = 0.0000513\n",
      "[4/25][1130/9765] Loss_D: 0.0999 Loss_G: 0.0434 Convergence: 0.1040 k= 0.032433 lr = 0.0000513\n",
      "[4/25][1140/9765] Loss_D: 0.1041 Loss_G: 0.0426 Convergence: 0.1058 k= 0.032452 lr = 0.0000513\n",
      "[4/25][1150/9765] Loss_D: 0.1061 Loss_G: 0.0412 Convergence: 0.1092 k= 0.032433 lr = 0.0000513\n",
      "[4/25][1160/9765] Loss_D: 0.1082 Loss_G: 0.0427 Convergence: 0.1106 k= 0.032454 lr = 0.0000513\n",
      "[4/25][1170/9765] Loss_D: 0.0989 Loss_G: 0.0448 Convergence: 0.1050 k= 0.032455 lr = 0.0000513\n",
      "[4/25][1180/9765] Loss_D: 0.1125 Loss_G: 0.0384 Convergence: 0.1208 k= 0.032447 lr = 0.0000513\n",
      "[4/25][1190/9765] Loss_D: 0.1012 Loss_G: 0.0443 Convergence: 0.1058 k= 0.032431 lr = 0.0000513\n",
      "[4/25][1200/9765] Loss_D: 0.1081 Loss_G: 0.0382 Convergence: 0.1150 k= 0.032433 lr = 0.0000513\n",
      "[4/25][1210/9765] Loss_D: 0.1014 Loss_G: 0.0367 Convergence: 0.1070 k= 0.032459 lr = 0.0000513\n",
      "[4/25][1220/9765] Loss_D: 0.1014 Loss_G: 0.0475 Convergence: 0.1092 k= 0.032463 lr = 0.0000513\n",
      "[4/25][1230/9765] Loss_D: 0.1178 Loss_G: 0.0455 Convergence: 0.1215 k= 0.032425 lr = 0.0000513\n",
      "[4/25][1240/9765] Loss_D: 0.1063 Loss_G: 0.0413 Convergence: 0.1092 k= 0.032404 lr = 0.0000513\n",
      "[4/25][1250/9765] Loss_D: 0.1084 Loss_G: 0.0400 Convergence: 0.1136 k= 0.032416 lr = 0.0000513\n",
      "[4/25][1260/9765] Loss_D: 0.1056 Loss_G: 0.0458 Convergence: 0.1100 k= 0.032393 lr = 0.0000513\n",
      "[4/25][1270/9765] Loss_D: 0.1117 Loss_G: 0.0401 Convergence: 0.1180 k= 0.032364 lr = 0.0000513\n",
      "[4/25][1280/9765] Loss_D: 0.1048 Loss_G: 0.0409 Convergence: 0.1077 k= 0.032342 lr = 0.0000513\n",
      "[4/25][1290/9765] Loss_D: 0.1098 Loss_G: 0.0461 Convergence: 0.1128 k= 0.032344 lr = 0.0000513\n",
      "[4/25][1300/9765] Loss_D: 0.1024 Loss_G: 0.0428 Convergence: 0.1050 k= 0.032335 lr = 0.0000513\n",
      "[4/25][1310/9765] Loss_D: 0.0991 Loss_G: 0.0416 Convergence: 0.1019 k= 0.032335 lr = 0.0000513\n",
      "[4/25][1320/9765] Loss_D: 0.1120 Loss_G: 0.0448 Convergence: 0.1139 k= 0.032331 lr = 0.0000513\n",
      "[4/25][1330/9765] Loss_D: 0.1024 Loss_G: 0.0389 Convergence: 0.1061 k= 0.032358 lr = 0.0000513\n",
      "[4/25][1340/9765] Loss_D: 0.1073 Loss_G: 0.0408 Convergence: 0.1112 k= 0.032350 lr = 0.0000513\n",
      "[4/25][1350/9765] Loss_D: 0.1065 Loss_G: 0.0409 Convergence: 0.1101 k= 0.032345 lr = 0.0000513\n",
      "[4/25][1360/9765] Loss_D: 0.1115 Loss_G: 0.0431 Convergence: 0.1150 k= 0.032319 lr = 0.0000513\n",
      "[4/25][1370/9765] Loss_D: 0.1015 Loss_G: 0.0400 Convergence: 0.1042 k= 0.032312 lr = 0.0000513\n",
      "[4/25][1380/9765] Loss_D: 0.1001 Loss_G: 0.0409 Convergence: 0.1017 k= 0.032319 lr = 0.0000513\n",
      "[4/25][1390/9765] Loss_D: 0.0958 Loss_G: 0.0492 Convergence: 0.1077 k= 0.032288 lr = 0.0000513\n",
      "[4/25][1400/9765] Loss_D: 0.1127 Loss_G: 0.0399 Convergence: 0.1197 k= 0.032285 lr = 0.0000513\n",
      "[4/25][1410/9765] Loss_D: 0.1001 Loss_G: 0.0400 Convergence: 0.1020 k= 0.032282 lr = 0.0000513\n",
      "[4/25][1420/9765] Loss_D: 0.0983 Loss_G: 0.0421 Convergence: 0.1019 k= 0.032272 lr = 0.0000513\n",
      "[4/25][1430/9765] Loss_D: 0.1174 Loss_G: 0.0408 Convergence: 0.1255 k= 0.032286 lr = 0.0000513\n",
      "[4/25][1440/9765] Loss_D: 0.1203 Loss_G: 0.0449 Convergence: 0.1257 k= 0.032275 lr = 0.0000513\n",
      "[4/25][1450/9765] Loss_D: 0.0967 Loss_G: 0.0405 Convergence: 0.0993 k= 0.032242 lr = 0.0000513\n",
      "[4/25][1460/9765] Loss_D: 0.1058 Loss_G: 0.0448 Convergence: 0.1092 k= 0.032259 lr = 0.0000513\n",
      "[4/25][1470/9765] Loss_D: 0.1108 Loss_G: 0.0399 Convergence: 0.1170 k= 0.032249 lr = 0.0000513\n",
      "[4/25][1480/9765] Loss_D: 0.1029 Loss_G: 0.0465 Convergence: 0.1091 k= 0.032247 lr = 0.0000513\n",
      "[4/25][1490/9765] Loss_D: 0.0919 Loss_G: 0.0400 Convergence: 0.0960 k= 0.032224 lr = 0.0000513\n",
      "[4/25][1500/9765] Loss_D: 0.1062 Loss_G: 0.0440 Convergence: 0.1085 k= 0.032227 lr = 0.0000513\n",
      "[4/25][1510/9765] Loss_D: 0.0965 Loss_G: 0.0400 Convergence: 0.0988 k= 0.032208 lr = 0.0000513\n",
      "[4/25][1520/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1016 k= 0.032204 lr = 0.0000513\n",
      "[4/25][1530/9765] Loss_D: 0.1035 Loss_G: 0.0405 Convergence: 0.1062 k= 0.032195 lr = 0.0000513\n",
      "[4/25][1540/9765] Loss_D: 0.1037 Loss_G: 0.0445 Convergence: 0.1075 k= 0.032169 lr = 0.0000513\n",
      "[4/25][1550/9765] Loss_D: 0.1030 Loss_G: 0.0492 Convergence: 0.1119 k= 0.032167 lr = 0.0000513\n",
      "[4/25][1560/9765] Loss_D: 0.0999 Loss_G: 0.0377 Convergence: 0.1039 k= 0.032190 lr = 0.0000513\n",
      "[4/25][1570/9765] Loss_D: 0.1004 Loss_G: 0.0481 Convergence: 0.1092 k= 0.032197 lr = 0.0000513\n",
      "[4/25][1580/9765] Loss_D: 0.0932 Loss_G: 0.0377 Convergence: 0.0946 k= 0.032182 lr = 0.0000513\n",
      "[4/25][1590/9765] Loss_D: 0.1095 Loss_G: 0.0445 Convergence: 0.1111 k= 0.032217 lr = 0.0000513\n",
      "[4/25][1600/9765] Loss_D: 0.1074 Loss_G: 0.0506 Convergence: 0.1159 k= 0.032156 lr = 0.0000513\n",
      "[4/25][1610/9765] Loss_D: 0.0992 Loss_G: 0.0438 Convergence: 0.1042 k= 0.032133 lr = 0.0000513\n",
      "[4/25][1620/9765] Loss_D: 0.1096 Loss_G: 0.0414 Convergence: 0.1137 k= 0.032143 lr = 0.0000513\n",
      "[4/25][1630/9765] Loss_D: 0.0984 Loss_G: 0.0409 Convergence: 0.1007 k= 0.032134 lr = 0.0000513\n",
      "[4/25][1640/9765] Loss_D: 0.1023 Loss_G: 0.0445 Convergence: 0.1068 k= 0.032131 lr = 0.0000513\n",
      "[4/25][1650/9765] Loss_D: 0.1091 Loss_G: 0.0425 Convergence: 0.1120 k= 0.032124 lr = 0.0000513\n",
      "[4/25][1660/9765] Loss_D: 0.1085 Loss_G: 0.0464 Convergence: 0.1125 k= 0.032109 lr = 0.0000513\n",
      "[4/25][1670/9765] Loss_D: 0.1148 Loss_G: 0.0398 Convergence: 0.1226 k= 0.032109 lr = 0.0000513\n",
      "[4/25][1680/9765] Loss_D: 0.1056 Loss_G: 0.0395 Convergence: 0.1102 k= 0.032126 lr = 0.0000513\n",
      "[4/25][1690/9765] Loss_D: 0.1017 Loss_G: 0.0420 Convergence: 0.1038 k= 0.032133 lr = 0.0000513\n",
      "[4/25][1700/9765] Loss_D: 0.0970 Loss_G: 0.0446 Convergence: 0.1037 k= 0.032114 lr = 0.0000513\n",
      "[4/25][1710/9765] Loss_D: 0.1072 Loss_G: 0.0421 Convergence: 0.1098 k= 0.032132 lr = 0.0000513\n",
      "[4/25][1720/9765] Loss_D: 0.1000 Loss_G: 0.0448 Convergence: 0.1056 k= 0.032117 lr = 0.0000513\n",
      "[4/25][1730/9765] Loss_D: 0.1043 Loss_G: 0.0396 Convergence: 0.1082 k= 0.032119 lr = 0.0000513\n",
      "[4/25][1740/9765] Loss_D: 0.1064 Loss_G: 0.0394 Convergence: 0.1113 k= 0.032143 lr = 0.0000513\n",
      "[4/25][1750/9765] Loss_D: 0.1013 Loss_G: 0.0365 Convergence: 0.1071 k= 0.032136 lr = 0.0000513\n",
      "[4/25][1760/9765] Loss_D: 0.1077 Loss_G: 0.0441 Convergence: 0.1095 k= 0.032160 lr = 0.0000513\n",
      "[4/25][1770/9765] Loss_D: 0.1049 Loss_G: 0.0474 Convergence: 0.1111 k= 0.032137 lr = 0.0000513\n",
      "[4/25][1780/9765] Loss_D: 0.1054 Loss_G: 0.0417 Convergence: 0.1076 k= 0.032132 lr = 0.0000513\n",
      "[4/25][1790/9765] Loss_D: 0.1070 Loss_G: 0.0409 Convergence: 0.1107 k= 0.032135 lr = 0.0000513\n",
      "[4/25][1800/9765] Loss_D: 0.1051 Loss_G: 0.0435 Convergence: 0.1073 k= 0.032153 lr = 0.0000513\n",
      "[4/25][1810/9765] Loss_D: 0.0963 Loss_G: 0.0392 Convergence: 0.0977 k= 0.032150 lr = 0.0000513\n",
      "[4/25][1820/9765] Loss_D: 0.1125 Loss_G: 0.0485 Convergence: 0.1168 k= 0.032164 lr = 0.0000513\n",
      "[4/25][1830/9765] Loss_D: 0.1093 Loss_G: 0.0410 Convergence: 0.1140 k= 0.032149 lr = 0.0000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][1840/9765] Loss_D: 0.1144 Loss_G: 0.0405 Convergence: 0.1214 k= 0.032157 lr = 0.0000513\n",
      "[4/25][1850/9765] Loss_D: 0.1099 Loss_G: 0.0387 Convergence: 0.1169 k= 0.032173 lr = 0.0000513\n",
      "[4/25][1860/9765] Loss_D: 0.1038 Loss_G: 0.0409 Convergence: 0.1062 k= 0.032191 lr = 0.0000513\n",
      "[4/25][1870/9765] Loss_D: 0.1081 Loss_G: 0.0412 Convergence: 0.1119 k= 0.032187 lr = 0.0000513\n",
      "[4/25][1880/9765] Loss_D: 0.1011 Loss_G: 0.0455 Convergence: 0.1071 k= 0.032154 lr = 0.0000513\n",
      "[4/25][1890/9765] Loss_D: 0.1051 Loss_G: 0.0412 Convergence: 0.1077 k= 0.032152 lr = 0.0000513\n",
      "[4/25][1900/9765] Loss_D: 0.0979 Loss_G: 0.0408 Convergence: 0.1003 k= 0.032176 lr = 0.0000513\n",
      "[4/25][1910/9765] Loss_D: 0.1058 Loss_G: 0.0468 Convergence: 0.1111 k= 0.032116 lr = 0.0000513\n",
      "[4/25][1920/9765] Loss_D: 0.1054 Loss_G: 0.0417 Convergence: 0.1078 k= 0.032125 lr = 0.0000513\n",
      "[4/25][1930/9765] Loss_D: 0.1083 Loss_G: 0.0395 Convergence: 0.1142 k= 0.032133 lr = 0.0000513\n",
      "[4/25][1940/9765] Loss_D: 0.1010 Loss_G: 0.0480 Convergence: 0.1095 k= 0.032100 lr = 0.0000513\n",
      "[4/25][1950/9765] Loss_D: 0.0979 Loss_G: 0.0420 Convergence: 0.1016 k= 0.032074 lr = 0.0000513\n",
      "[4/25][1960/9765] Loss_D: 0.1040 Loss_G: 0.0443 Convergence: 0.1075 k= 0.032073 lr = 0.0000513\n",
      "[4/25][1970/9765] Loss_D: 0.0994 Loss_G: 0.0474 Convergence: 0.1080 k= 0.032068 lr = 0.0000513\n",
      "[4/25][1980/9765] Loss_D: 0.1127 Loss_G: 0.0471 Convergence: 0.1156 k= 0.032041 lr = 0.0000513\n",
      "[4/25][1990/9765] Loss_D: 0.1059 Loss_G: 0.0403 Convergence: 0.1097 k= 0.032031 lr = 0.0000513\n",
      "[4/25][2000/9765] Loss_D: 0.1015 Loss_G: 0.0399 Convergence: 0.1042 k= 0.032046 lr = 0.0000513\n",
      "[4/25][2010/9765] Loss_D: 0.1101 Loss_G: 0.0522 Convergence: 0.1192 k= 0.032031 lr = 0.0000513\n",
      "[4/25][2020/9765] Loss_D: 0.1067 Loss_G: 0.0461 Convergence: 0.1109 k= 0.031985 lr = 0.0000513\n",
      "[4/25][2030/9765] Loss_D: 0.1057 Loss_G: 0.0407 Convergence: 0.1094 k= 0.031985 lr = 0.0000513\n",
      "[4/25][2040/9765] Loss_D: 0.1009 Loss_G: 0.0436 Convergence: 0.1050 k= 0.031985 lr = 0.0000513\n",
      "[4/25][2050/9765] Loss_D: 0.1029 Loss_G: 0.0423 Convergence: 0.1049 k= 0.031972 lr = 0.0000513\n",
      "[4/25][2060/9765] Loss_D: 0.1119 Loss_G: 0.0410 Convergence: 0.1174 k= 0.031988 lr = 0.0000513\n",
      "[4/25][2070/9765] Loss_D: 0.1045 Loss_G: 0.0502 Convergence: 0.1138 k= 0.031963 lr = 0.0000513\n",
      "[4/25][2080/9765] Loss_D: 0.1034 Loss_G: 0.0365 Convergence: 0.1101 k= 0.031970 lr = 0.0000513\n",
      "[4/25][2090/9765] Loss_D: 0.0972 Loss_G: 0.0404 Convergence: 0.0995 k= 0.032005 lr = 0.0000513\n",
      "[4/25][2100/9765] Loss_D: 0.1086 Loss_G: 0.0431 Convergence: 0.1109 k= 0.031974 lr = 0.0000513\n",
      "[4/25][2110/9765] Loss_D: 0.1080 Loss_G: 0.0432 Convergence: 0.1100 k= 0.031994 lr = 0.0000513\n",
      "[4/25][2120/9765] Loss_D: 0.1063 Loss_G: 0.0415 Convergence: 0.1092 k= 0.032031 lr = 0.0000513\n",
      "[4/25][2130/9765] Loss_D: 0.1042 Loss_G: 0.0425 Convergence: 0.1058 k= 0.032011 lr = 0.0000513\n",
      "[4/25][2140/9765] Loss_D: 0.1030 Loss_G: 0.0372 Convergence: 0.1087 k= 0.032024 lr = 0.0000513\n",
      "[4/25][2150/9765] Loss_D: 0.1063 Loss_G: 0.0436 Convergence: 0.1081 k= 0.032038 lr = 0.0000513\n",
      "[4/25][2160/9765] Loss_D: 0.0996 Loss_G: 0.0463 Convergence: 0.1068 k= 0.032034 lr = 0.0000513\n",
      "[4/25][2170/9765] Loss_D: 0.0967 Loss_G: 0.0364 Convergence: 0.1007 k= 0.032031 lr = 0.0000513\n",
      "[4/25][2180/9765] Loss_D: 0.1088 Loss_G: 0.0453 Convergence: 0.1114 k= 0.032051 lr = 0.0000513\n",
      "[4/25][2190/9765] Loss_D: 0.1087 Loss_G: 0.0443 Convergence: 0.1104 k= 0.032036 lr = 0.0000513\n",
      "[4/25][2200/9765] Loss_D: 0.1098 Loss_G: 0.0431 Convergence: 0.1126 k= 0.032041 lr = 0.0000513\n",
      "[4/25][2210/9765] Loss_D: 0.1036 Loss_G: 0.0387 Convergence: 0.1080 k= 0.032047 lr = 0.0000513\n",
      "[4/25][2220/9765] Loss_D: 0.0986 Loss_G: 0.0413 Convergence: 0.1012 k= 0.032050 lr = 0.0000513\n",
      "[4/25][2230/9765] Loss_D: 0.0971 Loss_G: 0.0383 Convergence: 0.0995 k= 0.032046 lr = 0.0000513\n",
      "[4/25][2240/9765] Loss_D: 0.1078 Loss_G: 0.0467 Convergence: 0.1122 k= 0.032047 lr = 0.0000513\n",
      "[4/25][2250/9765] Loss_D: 0.0926 Loss_G: 0.0377 Convergence: 0.0941 k= 0.032035 lr = 0.0000513\n",
      "[4/25][2260/9765] Loss_D: 0.1056 Loss_G: 0.0381 Convergence: 0.1115 k= 0.032057 lr = 0.0000513\n",
      "[4/25][2270/9765] Loss_D: 0.1019 Loss_G: 0.0429 Convergence: 0.1049 k= 0.032042 lr = 0.0000513\n",
      "[4/25][2280/9765] Loss_D: 0.1044 Loss_G: 0.0437 Convergence: 0.1071 k= 0.032035 lr = 0.0000513\n",
      "[4/25][2290/9765] Loss_D: 0.0960 Loss_G: 0.0460 Convergence: 0.1044 k= 0.032021 lr = 0.0000513\n",
      "[4/25][2300/9765] Loss_D: 0.0957 Loss_G: 0.0391 Convergence: 0.0972 k= 0.032024 lr = 0.0000513\n",
      "[4/25][2310/9765] Loss_D: 0.1119 Loss_G: 0.0470 Convergence: 0.1151 k= 0.032032 lr = 0.0000513\n",
      "[4/25][2320/9765] Loss_D: 0.1198 Loss_G: 0.0438 Convergence: 0.1258 k= 0.032019 lr = 0.0000513\n",
      "[4/25][2330/9765] Loss_D: 0.1027 Loss_G: 0.0417 Convergence: 0.1041 k= 0.031995 lr = 0.0000513\n",
      "[4/25][2340/9765] Loss_D: 0.0978 Loss_G: 0.0503 Convergence: 0.1099 k= 0.031945 lr = 0.0000513\n",
      "[4/25][2350/9765] Loss_D: 0.1122 Loss_G: 0.0429 Convergence: 0.1159 k= 0.031939 lr = 0.0000513\n",
      "[4/25][2360/9765] Loss_D: 0.1088 Loss_G: 0.0395 Convergence: 0.1146 k= 0.031956 lr = 0.0000513\n",
      "[4/25][2370/9765] Loss_D: 0.1043 Loss_G: 0.0407 Convergence: 0.1074 k= 0.031918 lr = 0.0000513\n",
      "[4/25][2380/9765] Loss_D: 0.1015 Loss_G: 0.0377 Convergence: 0.1062 k= 0.031926 lr = 0.0000513\n",
      "[4/25][2390/9765] Loss_D: 0.1035 Loss_G: 0.0449 Convergence: 0.1078 k= 0.031919 lr = 0.0000513\n",
      "[4/25][2400/9765] Loss_D: 0.1130 Loss_G: 0.0414 Convergence: 0.1187 k= 0.031936 lr = 0.0000513\n",
      "[4/25][2410/9765] Loss_D: 0.1059 Loss_G: 0.0453 Convergence: 0.1097 k= 0.031900 lr = 0.0000513\n",
      "[4/25][2420/9765] Loss_D: 0.1071 Loss_G: 0.0439 Convergence: 0.1089 k= 0.031900 lr = 0.0000513\n",
      "[4/25][2430/9765] Loss_D: 0.0967 Loss_G: 0.0372 Convergence: 0.0999 k= 0.031912 lr = 0.0000513\n",
      "[4/25][2440/9765] Loss_D: 0.1068 Loss_G: 0.0409 Convergence: 0.1104 k= 0.031932 lr = 0.0000513\n",
      "[4/25][2450/9765] Loss_D: 0.1020 Loss_G: 0.0430 Convergence: 0.1050 k= 0.031931 lr = 0.0000513\n",
      "[4/25][2460/9765] Loss_D: 0.1042 Loss_G: 0.0488 Convergence: 0.1122 k= 0.031892 lr = 0.0000513\n",
      "[4/25][2470/9765] Loss_D: 0.0922 Loss_G: 0.0410 Convergence: 0.0972 k= 0.031889 lr = 0.0000513\n",
      "[4/25][2480/9765] Loss_D: 0.1106 Loss_G: 0.0457 Convergence: 0.1128 k= 0.031885 lr = 0.0000513\n",
      "[4/25][2490/9765] Loss_D: 0.0957 Loss_G: 0.0433 Convergence: 0.1015 k= 0.031864 lr = 0.0000513\n",
      "[4/25][2500/9765] Loss_D: 0.0971 Loss_G: 0.0479 Convergence: 0.1070 k= 0.031821 lr = 0.0000513\n",
      "[4/25][2510/9765] Loss_D: 0.1021 Loss_G: 0.0364 Convergence: 0.1082 k= 0.031833 lr = 0.0000513\n",
      "[4/25][2520/9765] Loss_D: 0.1076 Loss_G: 0.0497 Convergence: 0.1151 k= 0.031845 lr = 0.0000513\n",
      "[4/25][2530/9765] Loss_D: 0.0970 Loss_G: 0.0432 Convergence: 0.1023 k= 0.031831 lr = 0.0000513\n",
      "[4/25][2540/9765] Loss_D: 0.0965 Loss_G: 0.0447 Convergence: 0.1033 k= 0.031827 lr = 0.0000513\n",
      "[4/25][2550/9765] Loss_D: 0.1153 Loss_G: 0.0408 Convergence: 0.1224 k= 0.031808 lr = 0.0000513\n",
      "[4/25][2560/9765] Loss_D: 0.1029 Loss_G: 0.0406 Convergence: 0.1054 k= 0.031807 lr = 0.0000513\n",
      "[4/25][2570/9765] Loss_D: 0.1050 Loss_G: 0.0407 Convergence: 0.1081 k= 0.031807 lr = 0.0000513\n",
      "[4/25][2580/9765] Loss_D: 0.1034 Loss_G: 0.0483 Convergence: 0.1111 k= 0.031820 lr = 0.0000513\n",
      "[4/25][2590/9765] Loss_D: 0.1074 Loss_G: 0.0459 Convergence: 0.1112 k= 0.031800 lr = 0.0000513\n",
      "[4/25][2600/9765] Loss_D: 0.0969 Loss_G: 0.0407 Convergence: 0.0996 k= 0.031799 lr = 0.0000513\n",
      "[4/25][2610/9765] Loss_D: 0.1074 Loss_G: 0.0451 Convergence: 0.1103 k= 0.031791 lr = 0.0000513\n",
      "[4/25][2620/9765] Loss_D: 0.1030 Loss_G: 0.0403 Convergence: 0.1057 k= 0.031776 lr = 0.0000513\n",
      "[4/25][2630/9765] Loss_D: 0.0999 Loss_G: 0.0405 Convergence: 0.1013 k= 0.031766 lr = 0.0000513\n",
      "[4/25][2640/9765] Loss_D: 0.0955 Loss_G: 0.0463 Convergence: 0.1044 k= 0.031762 lr = 0.0000513\n",
      "[4/25][2650/9765] Loss_D: 0.0993 Loss_G: 0.0421 Convergence: 0.1025 k= 0.031741 lr = 0.0000513\n",
      "[4/25][2660/9765] Loss_D: 0.1051 Loss_G: 0.0415 Convergence: 0.1075 k= 0.031748 lr = 0.0000513\n",
      "[4/25][2670/9765] Loss_D: 0.1001 Loss_G: 0.0454 Convergence: 0.1063 k= 0.031732 lr = 0.0000513\n",
      "[4/25][2680/9765] Loss_D: 0.1068 Loss_G: 0.0390 Convergence: 0.1123 k= 0.031726 lr = 0.0000513\n",
      "[4/25][2690/9765] Loss_D: 0.1052 Loss_G: 0.0400 Convergence: 0.1090 k= 0.031727 lr = 0.0000513\n",
      "[4/25][2700/9765] Loss_D: 0.0989 Loss_G: 0.0387 Convergence: 0.1015 k= 0.031734 lr = 0.0000513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][2710/9765] Loss_D: 0.1098 Loss_G: 0.0394 Convergence: 0.1162 k= 0.031707 lr = 0.0000513\n",
      "[4/25][2720/9765] Loss_D: 0.1032 Loss_G: 0.0463 Convergence: 0.1092 k= 0.031699 lr = 0.0000513\n",
      "[4/25][2730/9765] Loss_D: 0.1058 Loss_G: 0.0394 Convergence: 0.1104 k= 0.031674 lr = 0.0000513\n",
      "[4/25][2740/9765] Loss_D: 0.1076 Loss_G: 0.0464 Convergence: 0.1118 k= 0.031728 lr = 0.0000513\n",
      "[4/25][2750/9765] Loss_D: 0.1039 Loss_G: 0.0437 Convergence: 0.1068 k= 0.031668 lr = 0.0000513\n",
      "[4/25][2760/9765] Loss_D: 0.0980 Loss_G: 0.0419 Convergence: 0.1015 k= 0.031658 lr = 0.0000513\n",
      "[4/25][2770/9765] Loss_D: 0.0998 Loss_G: 0.0417 Convergence: 0.1024 k= 0.031662 lr = 0.0000513\n",
      "[4/25][2780/9765] Loss_D: 0.1072 Loss_G: 0.0408 Convergence: 0.1110 k= 0.031633 lr = 0.0000513\n",
      "[4/25][2790/9765] Loss_D: 0.0987 Loss_G: 0.0394 Convergence: 0.1006 k= 0.031636 lr = 0.0000513\n",
      "[4/25][2800/9765] Loss_D: 0.1055 Loss_G: 0.0395 Convergence: 0.1101 k= 0.031628 lr = 0.0000513\n",
      "[4/25][2810/9765] Loss_D: 0.1075 Loss_G: 0.0443 Convergence: 0.1097 k= 0.031629 lr = 0.0000513\n",
      "[4/25][2820/9765] Loss_D: 0.0990 Loss_G: 0.0412 Convergence: 0.1014 k= 0.031617 lr = 0.0000513\n",
      "[4/25][2830/9765] Loss_D: 0.1055 Loss_G: 0.0416 Convergence: 0.1077 k= 0.031606 lr = 0.0000513\n",
      "[4/25][2840/9765] Loss_D: 0.1027 Loss_G: 0.0432 Convergence: 0.1057 k= 0.031579 lr = 0.0000513\n",
      "[4/25][2850/9765] Loss_D: 0.0989 Loss_G: 0.0376 Convergence: 0.1024 k= 0.031590 lr = 0.0000513\n",
      "[4/25][2860/9765] Loss_D: 0.1073 Loss_G: 0.0490 Convergence: 0.1142 k= 0.031580 lr = 0.0000513\n",
      "[4/25][2870/9765] Loss_D: 0.1025 Loss_G: 0.0435 Convergence: 0.1059 k= 0.031547 lr = 0.0000513\n",
      "[4/25][2880/9765] Loss_D: 0.1035 Loss_G: 0.0422 Convergence: 0.1050 k= 0.031553 lr = 0.0000513\n",
      "[4/25][2890/9765] Loss_D: 0.1170 Loss_G: 0.0457 Convergence: 0.1199 k= 0.031546 lr = 0.0000513\n",
      "[4/25][2900/9765] Loss_D: 0.1003 Loss_G: 0.0387 Convergence: 0.1035 k= 0.031537 lr = 0.0000513\n",
      "[4/25][2910/9765] Loss_D: 0.0983 Loss_G: 0.0452 Convergence: 0.1051 k= 0.031527 lr = 0.0000513\n",
      "[4/25][2920/9765] Loss_D: 0.1078 Loss_G: 0.0420 Convergence: 0.1108 k= 0.031519 lr = 0.0000513\n",
      "[4/25][2930/9765] Loss_D: 0.0989 Loss_G: 0.0412 Convergence: 0.1013 k= 0.031525 lr = 0.0000513\n",
      "[4/25][2940/9765] Loss_D: 0.0994 Loss_G: 0.0527 Convergence: 0.1131 k= 0.031506 lr = 0.0000488\n",
      "[4/25][2950/9765] Loss_D: 0.1035 Loss_G: 0.0465 Convergence: 0.1092 k= 0.031516 lr = 0.0000488\n",
      "[4/25][2960/9765] Loss_D: 0.1026 Loss_G: 0.0435 Convergence: 0.1059 k= 0.031513 lr = 0.0000488\n",
      "[4/25][2970/9765] Loss_D: 0.0992 Loss_G: 0.0422 Convergence: 0.1025 k= 0.031511 lr = 0.0000488\n",
      "[4/25][2980/9765] Loss_D: 0.0973 Loss_G: 0.0395 Convergence: 0.0986 k= 0.031531 lr = 0.0000488\n",
      "[4/25][2990/9765] Loss_D: 0.1064 Loss_G: 0.0386 Convergence: 0.1120 k= 0.031539 lr = 0.0000488\n",
      "[4/25][3000/9765] Loss_D: 0.1094 Loss_G: 0.0427 Convergence: 0.1123 k= 0.031531 lr = 0.0000488\n",
      "[4/25][3010/9765] Loss_D: 0.1033 Loss_G: 0.0418 Convergence: 0.1046 k= 0.031541 lr = 0.0000488\n",
      "[4/25][3020/9765] Loss_D: 0.0958 Loss_G: 0.0376 Convergence: 0.0979 k= 0.031557 lr = 0.0000488\n",
      "[4/25][3030/9765] Loss_D: 0.1015 Loss_G: 0.0417 Convergence: 0.1033 k= 0.031593 lr = 0.0000488\n",
      "[4/25][3040/9765] Loss_D: 0.1022 Loss_G: 0.0404 Convergence: 0.1043 k= 0.031597 lr = 0.0000488\n",
      "[4/25][3050/9765] Loss_D: 0.1110 Loss_G: 0.0434 Convergence: 0.1137 k= 0.031597 lr = 0.0000488\n",
      "[4/25][3060/9765] Loss_D: 0.1057 Loss_G: 0.0415 Convergence: 0.1086 k= 0.031589 lr = 0.0000488\n",
      "[4/25][3070/9765] Loss_D: 0.0985 Loss_G: 0.0460 Convergence: 0.1059 k= 0.031569 lr = 0.0000488\n",
      "[4/25][3080/9765] Loss_D: 0.1090 Loss_G: 0.0385 Convergence: 0.1158 k= 0.031591 lr = 0.0000488\n",
      "[4/25][3090/9765] Loss_D: 0.0993 Loss_G: 0.0411 Convergence: 0.1014 k= 0.031606 lr = 0.0000488\n",
      "[4/25][3100/9765] Loss_D: 0.1080 Loss_G: 0.0476 Convergence: 0.1132 k= 0.031590 lr = 0.0000488\n",
      "[4/25][3110/9765] Loss_D: 0.0965 Loss_G: 0.0384 Convergence: 0.0984 k= 0.031591 lr = 0.0000488\n",
      "[4/25][3120/9765] Loss_D: 0.1124 Loss_G: 0.0386 Convergence: 0.1205 k= 0.031630 lr = 0.0000488\n",
      "[4/25][3130/9765] Loss_D: 0.1109 Loss_G: 0.0461 Convergence: 0.1135 k= 0.031577 lr = 0.0000488\n",
      "[4/25][3140/9765] Loss_D: 0.1097 Loss_G: 0.0411 Convergence: 0.1144 k= 0.031572 lr = 0.0000488\n",
      "[4/25][3150/9765] Loss_D: 0.1035 Loss_G: 0.0437 Convergence: 0.1066 k= 0.031568 lr = 0.0000488\n",
      "[4/25][3160/9765] Loss_D: 0.1005 Loss_G: 0.0420 Convergence: 0.1030 k= 0.031552 lr = 0.0000488\n",
      "[4/25][3170/9765] Loss_D: 0.0991 Loss_G: 0.0452 Convergence: 0.1053 k= 0.031515 lr = 0.0000488\n",
      "[4/25][3180/9765] Loss_D: 0.1093 Loss_G: 0.0435 Convergence: 0.1115 k= 0.031512 lr = 0.0000488\n",
      "[4/25][3190/9765] Loss_D: 0.0928 Loss_G: 0.0410 Convergence: 0.0974 k= 0.031497 lr = 0.0000488\n",
      "[4/25][3200/9765] Loss_D: 0.1070 Loss_G: 0.0428 Convergence: 0.1088 k= 0.031503 lr = 0.0000488\n",
      "[4/25][3210/9765] Loss_D: 0.0980 Loss_G: 0.0433 Convergence: 0.1028 k= 0.031509 lr = 0.0000488\n",
      "[4/25][3220/9765] Loss_D: 0.1040 Loss_G: 0.0418 Convergence: 0.1054 k= 0.031539 lr = 0.0000488\n",
      "[4/25][3230/9765] Loss_D: 0.1079 Loss_G: 0.0450 Convergence: 0.1106 k= 0.031514 lr = 0.0000488\n",
      "[4/25][3240/9765] Loss_D: 0.1039 Loss_G: 0.0443 Convergence: 0.1074 k= 0.031502 lr = 0.0000488\n",
      "[4/25][3250/9765] Loss_D: 0.1090 Loss_G: 0.0431 Convergence: 0.1113 k= 0.031492 lr = 0.0000488\n",
      "[4/25][3260/9765] Loss_D: 0.1014 Loss_G: 0.0506 Convergence: 0.1124 k= 0.031454 lr = 0.0000488\n",
      "[4/25][3270/9765] Loss_D: 0.1006 Loss_G: 0.0414 Convergence: 0.1025 k= 0.031430 lr = 0.0000488\n",
      "[4/25][3280/9765] Loss_D: 0.1003 Loss_G: 0.0405 Convergence: 0.1016 k= 0.031453 lr = 0.0000488\n",
      "[4/25][3290/9765] Loss_D: 0.0976 Loss_G: 0.0440 Convergence: 0.1034 k= 0.031467 lr = 0.0000488\n",
      "[4/25][3300/9765] Loss_D: 0.1089 Loss_G: 0.0369 Convergence: 0.1173 k= 0.031481 lr = 0.0000488\n",
      "[4/25][3310/9765] Loss_D: 0.1054 Loss_G: 0.0469 Convergence: 0.1108 k= 0.031476 lr = 0.0000488\n",
      "[4/25][3320/9765] Loss_D: 0.1039 Loss_G: 0.0415 Convergence: 0.1058 k= 0.031487 lr = 0.0000488\n",
      "[4/25][3330/9765] Loss_D: 0.1007 Loss_G: 0.0416 Convergence: 0.1028 k= 0.031486 lr = 0.0000488\n",
      "[4/25][3340/9765] Loss_D: 0.0944 Loss_G: 0.0410 Convergence: 0.0984 k= 0.031485 lr = 0.0000488\n",
      "[4/25][3350/9765] Loss_D: 0.1020 Loss_G: 0.0438 Convergence: 0.1057 k= 0.031452 lr = 0.0000488\n",
      "[4/25][3360/9765] Loss_D: 0.0946 Loss_G: 0.0382 Convergence: 0.0958 k= 0.031469 lr = 0.0000488\n",
      "[4/25][3370/9765] Loss_D: 0.1082 Loss_G: 0.0496 Convergence: 0.1154 k= 0.031471 lr = 0.0000488\n",
      "[4/25][3380/9765] Loss_D: 0.1093 Loss_G: 0.0397 Convergence: 0.1152 k= 0.031460 lr = 0.0000488\n",
      "[4/25][3390/9765] Loss_D: 0.1211 Loss_G: 0.0404 Convergence: 0.1307 k= 0.031475 lr = 0.0000488\n",
      "[4/25][3400/9765] Loss_D: 0.1050 Loss_G: 0.0398 Convergence: 0.1089 k= 0.031489 lr = 0.0000488\n",
      "[4/25][3410/9765] Loss_D: 0.0977 Loss_G: 0.0396 Convergence: 0.0990 k= 0.031486 lr = 0.0000488\n",
      "[4/25][3420/9765] Loss_D: 0.1042 Loss_G: 0.0367 Convergence: 0.1106 k= 0.031534 lr = 0.0000488\n",
      "[4/25][3430/9765] Loss_D: 0.1073 Loss_G: 0.0441 Convergence: 0.1092 k= 0.031523 lr = 0.0000488\n",
      "[4/25][3440/9765] Loss_D: 0.1048 Loss_G: 0.0394 Convergence: 0.1091 k= 0.031523 lr = 0.0000488\n",
      "[4/25][3450/9765] Loss_D: 0.1103 Loss_G: 0.0434 Convergence: 0.1128 k= 0.031514 lr = 0.0000488\n",
      "[4/25][3460/9765] Loss_D: 0.1010 Loss_G: 0.0405 Convergence: 0.1026 k= 0.031514 lr = 0.0000488\n",
      "[4/25][3470/9765] Loss_D: 0.1042 Loss_G: 0.0448 Convergence: 0.1081 k= 0.031506 lr = 0.0000488\n",
      "[4/25][3480/9765] Loss_D: 0.0963 Loss_G: 0.0455 Convergence: 0.1042 k= 0.031506 lr = 0.0000488\n",
      "[4/25][3490/9765] Loss_D: 0.0944 Loss_G: 0.0420 Convergence: 0.0994 k= 0.031500 lr = 0.0000488\n",
      "[4/25][3500/9765] Loss_D: 0.0966 Loss_G: 0.0393 Convergence: 0.0980 k= 0.031482 lr = 0.0000488\n",
      "[4/25][3510/9765] Loss_D: 0.0973 Loss_G: 0.0410 Convergence: 0.1002 k= 0.031467 lr = 0.0000488\n",
      "[4/25][3520/9765] Loss_D: 0.1010 Loss_G: 0.0450 Convergence: 0.1064 k= 0.031452 lr = 0.0000488\n",
      "[4/25][3530/9765] Loss_D: 0.0986 Loss_G: 0.0395 Convergence: 0.1003 k= 0.031453 lr = 0.0000488\n",
      "[4/25][3540/9765] Loss_D: 0.0996 Loss_G: 0.0469 Convergence: 0.1076 k= 0.031442 lr = 0.0000488\n",
      "[4/25][3550/9765] Loss_D: 0.1080 Loss_G: 0.0441 Convergence: 0.1098 k= 0.031446 lr = 0.0000488\n",
      "[4/25][3560/9765] Loss_D: 0.0976 Loss_G: 0.0508 Convergence: 0.1101 k= 0.031441 lr = 0.0000488\n",
      "[4/25][3570/9765] Loss_D: 0.1097 Loss_G: 0.0420 Convergence: 0.1134 k= 0.031451 lr = 0.0000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][3580/9765] Loss_D: 0.1065 Loss_G: 0.0390 Convergence: 0.1117 k= 0.031470 lr = 0.0000488\n",
      "[4/25][3590/9765] Loss_D: 0.1012 Loss_G: 0.0397 Convergence: 0.1038 k= 0.031480 lr = 0.0000488\n",
      "[4/25][3600/9765] Loss_D: 0.1056 Loss_G: 0.0433 Convergence: 0.1074 k= 0.031459 lr = 0.0000488\n",
      "[4/25][3610/9765] Loss_D: 0.1002 Loss_G: 0.0404 Convergence: 0.1016 k= 0.031468 lr = 0.0000488\n",
      "[4/25][3620/9765] Loss_D: 0.1061 Loss_G: 0.0411 Convergence: 0.1092 k= 0.031472 lr = 0.0000488\n",
      "[4/25][3630/9765] Loss_D: 0.0981 Loss_G: 0.0437 Convergence: 0.1034 k= 0.031447 lr = 0.0000488\n",
      "[4/25][3640/9765] Loss_D: 0.1108 Loss_G: 0.0439 Convergence: 0.1133 k= 0.031438 lr = 0.0000488\n",
      "[4/25][3650/9765] Loss_D: 0.1014 Loss_G: 0.0407 Convergence: 0.1031 k= 0.031433 lr = 0.0000488\n",
      "[4/25][3660/9765] Loss_D: 0.1054 Loss_G: 0.0421 Convergence: 0.1074 k= 0.031428 lr = 0.0000488\n",
      "[4/25][3670/9765] Loss_D: 0.1061 Loss_G: 0.0454 Convergence: 0.1098 k= 0.031409 lr = 0.0000488\n",
      "[4/25][3680/9765] Loss_D: 0.1089 Loss_G: 0.0452 Convergence: 0.1113 k= 0.031408 lr = 0.0000488\n",
      "[4/25][3690/9765] Loss_D: 0.1091 Loss_G: 0.0494 Convergence: 0.1157 k= 0.031362 lr = 0.0000488\n",
      "[4/25][3700/9765] Loss_D: 0.0956 Loss_G: 0.0419 Convergence: 0.1001 k= 0.031323 lr = 0.0000488\n",
      "[4/25][3710/9765] Loss_D: 0.1006 Loss_G: 0.0418 Convergence: 0.1029 k= 0.031345 lr = 0.0000488\n",
      "[4/25][3720/9765] Loss_D: 0.1003 Loss_G: 0.0415 Convergence: 0.1024 k= 0.031355 lr = 0.0000488\n",
      "[4/25][3730/9765] Loss_D: 0.1130 Loss_G: 0.0476 Convergence: 0.1163 k= 0.031330 lr = 0.0000488\n",
      "[4/25][3740/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0966 k= 0.031341 lr = 0.0000488\n",
      "[4/25][3750/9765] Loss_D: 0.1059 Loss_G: 0.0415 Convergence: 0.1087 k= 0.031333 lr = 0.0000488\n",
      "[4/25][3760/9765] Loss_D: 0.0933 Loss_G: 0.0416 Convergence: 0.0984 k= 0.031338 lr = 0.0000488\n",
      "[4/25][3770/9765] Loss_D: 0.1006 Loss_G: 0.0422 Convergence: 0.1033 k= 0.031336 lr = 0.0000488\n",
      "[4/25][3780/9765] Loss_D: 0.1009 Loss_G: 0.0436 Convergence: 0.1048 k= 0.031327 lr = 0.0000488\n",
      "[4/25][3790/9765] Loss_D: 0.1010 Loss_G: 0.0431 Convergence: 0.1045 k= 0.031301 lr = 0.0000488\n",
      "[4/25][3800/9765] Loss_D: 0.0901 Loss_G: 0.0401 Convergence: 0.0949 k= 0.031318 lr = 0.0000488\n",
      "[4/25][3810/9765] Loss_D: 0.1019 Loss_G: 0.0477 Convergence: 0.1097 k= 0.031311 lr = 0.0000488\n",
      "[4/25][3820/9765] Loss_D: 0.1122 Loss_G: 0.0457 Convergence: 0.1138 k= 0.031285 lr = 0.0000488\n",
      "[4/25][3830/9765] Loss_D: 0.1050 Loss_G: 0.0434 Convergence: 0.1071 k= 0.031271 lr = 0.0000488\n",
      "[4/25][3840/9765] Loss_D: 0.1107 Loss_G: 0.0436 Convergence: 0.1133 k= 0.031247 lr = 0.0000488\n",
      "[4/25][3850/9765] Loss_D: 0.1102 Loss_G: 0.0454 Convergence: 0.1123 k= 0.031227 lr = 0.0000488\n",
      "[4/25][3860/9765] Loss_D: 0.1014 Loss_G: 0.0440 Convergence: 0.1057 k= 0.031226 lr = 0.0000488\n",
      "[4/25][3870/9765] Loss_D: 0.1068 Loss_G: 0.0467 Convergence: 0.1115 k= 0.031193 lr = 0.0000488\n",
      "[4/25][3880/9765] Loss_D: 0.0983 Loss_G: 0.0428 Convergence: 0.1026 k= 0.031168 lr = 0.0000488\n",
      "[4/25][3890/9765] Loss_D: 0.0994 Loss_G: 0.0395 Convergence: 0.1013 k= 0.031172 lr = 0.0000488\n",
      "[4/25][3900/9765] Loss_D: 0.1017 Loss_G: 0.0381 Convergence: 0.1061 k= 0.031184 lr = 0.0000488\n",
      "[4/25][3910/9765] Loss_D: 0.1015 Loss_G: 0.0402 Convergence: 0.1039 k= 0.031171 lr = 0.0000488\n",
      "[4/25][3920/9765] Loss_D: 0.0903 Loss_G: 0.0404 Convergence: 0.0953 k= 0.031186 lr = 0.0000488\n",
      "[4/25][3930/9765] Loss_D: 0.1029 Loss_G: 0.0437 Convergence: 0.1062 k= 0.031180 lr = 0.0000488\n",
      "[4/25][3940/9765] Loss_D: 0.0999 Loss_G: 0.0421 Convergence: 0.1028 k= 0.031179 lr = 0.0000488\n",
      "[4/25][3950/9765] Loss_D: 0.1084 Loss_G: 0.0433 Convergence: 0.1102 k= 0.031193 lr = 0.0000488\n",
      "[4/25][3960/9765] Loss_D: 0.1100 Loss_G: 0.0414 Convergence: 0.1146 k= 0.031191 lr = 0.0000488\n",
      "[4/25][3970/9765] Loss_D: 0.1014 Loss_G: 0.0418 Convergence: 0.1034 k= 0.031174 lr = 0.0000488\n",
      "[4/25][3980/9765] Loss_D: 0.1008 Loss_G: 0.0439 Convergence: 0.1051 k= 0.031190 lr = 0.0000488\n",
      "[4/25][3990/9765] Loss_D: 0.1044 Loss_G: 0.0392 Convergence: 0.1088 k= 0.031195 lr = 0.0000488\n",
      "[4/25][4000/9765] Loss_D: 0.0964 Loss_G: 0.0381 Convergence: 0.0987 k= 0.031184 lr = 0.0000488\n",
      "[4/25][4010/9765] Loss_D: 0.1076 Loss_G: 0.0406 Convergence: 0.1119 k= 0.031199 lr = 0.0000488\n",
      "[4/25][4020/9765] Loss_D: 0.1029 Loss_G: 0.0430 Convergence: 0.1055 k= 0.031188 lr = 0.0000488\n",
      "[4/25][4030/9765] Loss_D: 0.1025 Loss_G: 0.0435 Convergence: 0.1058 k= 0.031159 lr = 0.0000488\n",
      "[4/25][4040/9765] Loss_D: 0.1069 Loss_G: 0.0430 Convergence: 0.1085 k= 0.031135 lr = 0.0000488\n",
      "[4/25][4050/9765] Loss_D: 0.1101 Loss_G: 0.0440 Convergence: 0.1121 k= 0.031126 lr = 0.0000488\n",
      "[4/25][4060/9765] Loss_D: 0.1022 Loss_G: 0.0403 Convergence: 0.1046 k= 0.031134 lr = 0.0000488\n",
      "[4/25][4070/9765] Loss_D: 0.1030 Loss_G: 0.0456 Convergence: 0.1082 k= 0.031127 lr = 0.0000488\n",
      "[4/25][4080/9765] Loss_D: 0.0965 Loss_G: 0.0406 Convergence: 0.0993 k= 0.031091 lr = 0.0000488\n",
      "[4/25][4090/9765] Loss_D: 0.0979 Loss_G: 0.0501 Convergence: 0.1096 k= 0.031095 lr = 0.0000488\n",
      "[4/25][4100/9765] Loss_D: 0.0963 Loss_G: 0.0435 Convergence: 0.1022 k= 0.031036 lr = 0.0000488\n",
      "[4/25][4110/9765] Loss_D: 0.1058 Loss_G: 0.0414 Convergence: 0.1083 k= 0.031059 lr = 0.0000488\n",
      "[4/25][4120/9765] Loss_D: 0.1027 Loss_G: 0.0399 Convergence: 0.1057 k= 0.031071 lr = 0.0000488\n",
      "[4/25][4130/9765] Loss_D: 0.1085 Loss_G: 0.0430 Convergence: 0.1108 k= 0.031078 lr = 0.0000488\n",
      "[4/25][4140/9765] Loss_D: 0.0998 Loss_G: 0.0382 Convergence: 0.1033 k= 0.031060 lr = 0.0000488\n",
      "[4/25][4150/9765] Loss_D: 0.1119 Loss_G: 0.0444 Convergence: 0.1143 k= 0.031064 lr = 0.0000488\n",
      "[4/25][4160/9765] Loss_D: 0.1119 Loss_G: 0.0457 Convergence: 0.1137 k= 0.031084 lr = 0.0000488\n",
      "[4/25][4170/9765] Loss_D: 0.1043 Loss_G: 0.0420 Convergence: 0.1059 k= 0.031047 lr = 0.0000488\n",
      "[4/25][4180/9765] Loss_D: 0.1088 Loss_G: 0.0418 Convergence: 0.1121 k= 0.031055 lr = 0.0000488\n",
      "[4/25][4190/9765] Loss_D: 0.1047 Loss_G: 0.0401 Convergence: 0.1081 k= 0.031026 lr = 0.0000488\n",
      "[4/25][4200/9765] Loss_D: 0.1073 Loss_G: 0.0403 Convergence: 0.1116 k= 0.031020 lr = 0.0000488\n",
      "[4/25][4210/9765] Loss_D: 0.1031 Loss_G: 0.0404 Convergence: 0.1056 k= 0.031051 lr = 0.0000488\n",
      "[4/25][4220/9765] Loss_D: 0.1075 Loss_G: 0.0428 Convergence: 0.1095 k= 0.031066 lr = 0.0000488\n",
      "[4/25][4230/9765] Loss_D: 0.1086 Loss_G: 0.0466 Convergence: 0.1126 k= 0.031033 lr = 0.0000488\n",
      "[4/25][4240/9765] Loss_D: 0.0993 Loss_G: 0.0413 Convergence: 0.1016 k= 0.031021 lr = 0.0000488\n",
      "[4/25][4250/9765] Loss_D: 0.1105 Loss_G: 0.0411 Convergence: 0.1155 k= 0.031008 lr = 0.0000488\n",
      "[4/25][4260/9765] Loss_D: 0.0963 Loss_G: 0.0391 Convergence: 0.0977 k= 0.031001 lr = 0.0000488\n",
      "[4/25][4270/9765] Loss_D: 0.0900 Loss_G: 0.0384 Convergence: 0.0930 k= 0.031018 lr = 0.0000488\n",
      "[4/25][4280/9765] Loss_D: 0.1192 Loss_G: 0.0508 Convergence: 0.1231 k= 0.031007 lr = 0.0000488\n",
      "[4/25][4290/9765] Loss_D: 0.1119 Loss_G: 0.0413 Convergence: 0.1171 k= 0.030998 lr = 0.0000488\n",
      "[4/25][4300/9765] Loss_D: 0.1170 Loss_G: 0.0482 Convergence: 0.1192 k= 0.030968 lr = 0.0000488\n",
      "[4/25][4310/9765] Loss_D: 0.1116 Loss_G: 0.0446 Convergence: 0.1136 k= 0.030960 lr = 0.0000488\n",
      "[4/25][4320/9765] Loss_D: 0.1062 Loss_G: 0.0402 Convergence: 0.1103 k= 0.030949 lr = 0.0000488\n",
      "[4/25][4330/9765] Loss_D: 0.0998 Loss_G: 0.0418 Convergence: 0.1024 k= 0.030949 lr = 0.0000488\n",
      "[4/25][4340/9765] Loss_D: 0.1128 Loss_G: 0.0435 Convergence: 0.1162 k= 0.030957 lr = 0.0000488\n",
      "[4/25][4350/9765] Loss_D: 0.1075 Loss_G: 0.0412 Convergence: 0.1112 k= 0.030937 lr = 0.0000488\n",
      "[4/25][4360/9765] Loss_D: 0.0983 Loss_G: 0.0375 Convergence: 0.1016 k= 0.030953 lr = 0.0000488\n",
      "[4/25][4370/9765] Loss_D: 0.1151 Loss_G: 0.0468 Convergence: 0.1166 k= 0.030939 lr = 0.0000488\n",
      "[4/25][4380/9765] Loss_D: 0.0995 Loss_G: 0.0435 Convergence: 0.1040 k= 0.030920 lr = 0.0000488\n",
      "[4/25][4390/9765] Loss_D: 0.1049 Loss_G: 0.0369 Convergence: 0.1117 k= 0.030946 lr = 0.0000488\n",
      "[4/25][4400/9765] Loss_D: 0.0947 Loss_G: 0.0416 Convergence: 0.0992 k= 0.030947 lr = 0.0000488\n",
      "[4/25][4410/9765] Loss_D: 0.0933 Loss_G: 0.0430 Convergence: 0.0997 k= 0.030896 lr = 0.0000488\n",
      "[4/25][4420/9765] Loss_D: 0.1000 Loss_G: 0.0394 Convergence: 0.1021 k= 0.030934 lr = 0.0000488\n",
      "[4/25][4430/9765] Loss_D: 0.1039 Loss_G: 0.0520 Convergence: 0.1152 k= 0.030919 lr = 0.0000488\n",
      "[4/25][4440/9765] Loss_D: 0.1127 Loss_G: 0.0424 Convergence: 0.1172 k= 0.030860 lr = 0.0000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][4450/9765] Loss_D: 0.0905 Loss_G: 0.0378 Convergence: 0.0927 k= 0.030877 lr = 0.0000488\n",
      "[4/25][4460/9765] Loss_D: 0.0925 Loss_G: 0.0407 Convergence: 0.0969 k= 0.030875 lr = 0.0000488\n",
      "[4/25][4470/9765] Loss_D: 0.1048 Loss_G: 0.0408 Convergence: 0.1080 k= 0.030879 lr = 0.0000488\n",
      "[4/25][4480/9765] Loss_D: 0.1079 Loss_G: 0.0416 Convergence: 0.1114 k= 0.030884 lr = 0.0000488\n",
      "[4/25][4490/9765] Loss_D: 0.1102 Loss_G: 0.0405 Convergence: 0.1155 k= 0.030880 lr = 0.0000488\n",
      "[4/25][4500/9765] Loss_D: 0.1039 Loss_G: 0.0447 Convergence: 0.1078 k= 0.030894 lr = 0.0000488\n",
      "[4/25][4510/9765] Loss_D: 0.1000 Loss_G: 0.0402 Convergence: 0.1017 k= 0.030893 lr = 0.0000488\n",
      "[4/25][4520/9765] Loss_D: 0.1058 Loss_G: 0.0411 Convergence: 0.1090 k= 0.030892 lr = 0.0000488\n",
      "[4/25][4530/9765] Loss_D: 0.1072 Loss_G: 0.0370 Convergence: 0.1147 k= 0.030923 lr = 0.0000488\n",
      "[4/25][4540/9765] Loss_D: 0.1015 Loss_G: 0.0403 Convergence: 0.1035 k= 0.030929 lr = 0.0000488\n",
      "[4/25][4550/9765] Loss_D: 0.1074 Loss_G: 0.0403 Convergence: 0.1118 k= 0.030905 lr = 0.0000488\n",
      "[4/25][4560/9765] Loss_D: 0.0987 Loss_G: 0.0407 Convergence: 0.1008 k= 0.030905 lr = 0.0000488\n",
      "[4/25][4570/9765] Loss_D: 0.0987 Loss_G: 0.0386 Convergence: 0.1012 k= 0.030912 lr = 0.0000488\n",
      "[4/25][4580/9765] Loss_D: 0.1059 Loss_G: 0.0427 Convergence: 0.1074 k= 0.030915 lr = 0.0000488\n",
      "[4/25][4590/9765] Loss_D: 0.1140 Loss_G: 0.0429 Convergence: 0.1186 k= 0.030922 lr = 0.0000488\n",
      "[4/25][4600/9765] Loss_D: 0.0992 Loss_G: 0.0415 Convergence: 0.1018 k= 0.030906 lr = 0.0000488\n",
      "[4/25][4610/9765] Loss_D: 0.1070 Loss_G: 0.0425 Convergence: 0.1089 k= 0.030907 lr = 0.0000488\n",
      "[4/25][4620/9765] Loss_D: 0.0937 Loss_G: 0.0426 Convergence: 0.0996 k= 0.030906 lr = 0.0000488\n",
      "[4/25][4630/9765] Loss_D: 0.1118 Loss_G: 0.0437 Convergence: 0.1146 k= 0.030915 lr = 0.0000488\n",
      "[4/25][4640/9765] Loss_D: 0.1007 Loss_G: 0.0422 Convergence: 0.1034 k= 0.030891 lr = 0.0000488\n",
      "[4/25][4650/9765] Loss_D: 0.1081 Loss_G: 0.0417 Convergence: 0.1113 k= 0.030883 lr = 0.0000488\n",
      "[4/25][4660/9765] Loss_D: 0.1004 Loss_G: 0.0489 Convergence: 0.1099 k= 0.030867 lr = 0.0000488\n",
      "[4/25][4670/9765] Loss_D: 0.1069 Loss_G: 0.0409 Convergence: 0.1107 k= 0.030861 lr = 0.0000488\n",
      "[4/25][4680/9765] Loss_D: 0.1026 Loss_G: 0.0463 Convergence: 0.1087 k= 0.030844 lr = 0.0000488\n",
      "[4/25][4690/9765] Loss_D: 0.1043 Loss_G: 0.0427 Convergence: 0.1060 k= 0.030836 lr = 0.0000488\n",
      "[4/25][4700/9765] Loss_D: 0.1008 Loss_G: 0.0416 Convergence: 0.1030 k= 0.030820 lr = 0.0000488\n",
      "[4/25][4710/9765] Loss_D: 0.1140 Loss_G: 0.0453 Convergence: 0.1163 k= 0.030791 lr = 0.0000488\n",
      "[4/25][4720/9765] Loss_D: 0.1041 Loss_G: 0.0350 Convergence: 0.1122 k= 0.030792 lr = 0.0000488\n",
      "[4/25][4730/9765] Loss_D: 0.1119 Loss_G: 0.0500 Convergence: 0.1179 k= 0.030804 lr = 0.0000488\n",
      "[4/25][4740/9765] Loss_D: 0.1051 Loss_G: 0.0494 Convergence: 0.1133 k= 0.030775 lr = 0.0000488\n",
      "[4/25][4750/9765] Loss_D: 0.1058 Loss_G: 0.0435 Convergence: 0.1078 k= 0.030771 lr = 0.0000488\n",
      "[4/25][4760/9765] Loss_D: 0.0997 Loss_G: 0.0406 Convergence: 0.1012 k= 0.030772 lr = 0.0000488\n",
      "[4/25][4770/9765] Loss_D: 0.1085 Loss_G: 0.0427 Convergence: 0.1112 k= 0.030777 lr = 0.0000488\n",
      "[4/25][4780/9765] Loss_D: 0.1002 Loss_G: 0.0415 Convergence: 0.1023 k= 0.030755 lr = 0.0000488\n",
      "[4/25][4790/9765] Loss_D: 0.1051 Loss_G: 0.0418 Convergence: 0.1072 k= 0.030743 lr = 0.0000488\n",
      "[4/25][4800/9765] Loss_D: 0.1089 Loss_G: 0.0394 Convergence: 0.1148 k= 0.030755 lr = 0.0000488\n",
      "[4/25][4810/9765] Loss_D: 0.1030 Loss_G: 0.0385 Convergence: 0.1074 k= 0.030784 lr = 0.0000488\n",
      "[4/25][4820/9765] Loss_D: 0.1015 Loss_G: 0.0501 Convergence: 0.1117 k= 0.030788 lr = 0.0000488\n",
      "[4/25][4830/9765] Loss_D: 0.1087 Loss_G: 0.0387 Convergence: 0.1152 k= 0.030759 lr = 0.0000488\n",
      "[4/25][4840/9765] Loss_D: 0.1057 Loss_G: 0.0405 Convergence: 0.1091 k= 0.030761 lr = 0.0000488\n",
      "[4/25][4850/9765] Loss_D: 0.1013 Loss_G: 0.0410 Convergence: 0.1025 k= 0.030771 lr = 0.0000488\n",
      "[4/25][4860/9765] Loss_D: 0.0932 Loss_G: 0.0404 Convergence: 0.0971 k= 0.030771 lr = 0.0000488\n",
      "[4/25][4870/9765] Loss_D: 0.0957 Loss_G: 0.0413 Convergence: 0.0994 k= 0.030781 lr = 0.0000488\n",
      "[4/25][4880/9765] Loss_D: 0.1022 Loss_G: 0.0476 Convergence: 0.1097 k= 0.030776 lr = 0.0000488\n",
      "[4/25][4890/9765] Loss_D: 0.1047 Loss_G: 0.0406 Convergence: 0.1077 k= 0.030778 lr = 0.0000488\n",
      "[4/25][4900/9765] Loss_D: 0.1049 Loss_G: 0.0413 Convergence: 0.1074 k= 0.030797 lr = 0.0000488\n",
      "[4/25][4910/9765] Loss_D: 0.1018 Loss_G: 0.0468 Convergence: 0.1087 k= 0.030800 lr = 0.0000488\n",
      "[4/25][4920/9765] Loss_D: 0.1064 Loss_G: 0.0440 Convergence: 0.1087 k= 0.030786 lr = 0.0000488\n",
      "[4/25][4930/9765] Loss_D: 0.1029 Loss_G: 0.0450 Convergence: 0.1075 k= 0.030766 lr = 0.0000488\n",
      "[4/25][4940/9765] Loss_D: 0.1137 Loss_G: 0.0367 Convergence: 0.1241 k= 0.030781 lr = 0.0000488\n",
      "[4/25][4950/9765] Loss_D: 0.0965 Loss_G: 0.0511 Convergence: 0.1100 k= 0.030757 lr = 0.0000488\n",
      "[4/25][4960/9765] Loss_D: 0.1001 Loss_G: 0.0439 Convergence: 0.1048 k= 0.030727 lr = 0.0000488\n",
      "[4/25][4970/9765] Loss_D: 0.1112 Loss_G: 0.0371 Convergence: 0.1203 k= 0.030744 lr = 0.0000488\n",
      "[4/25][4980/9765] Loss_D: 0.1064 Loss_G: 0.0519 Convergence: 0.1166 k= 0.030735 lr = 0.0000488\n",
      "[4/25][4990/9765] Loss_D: 0.0975 Loss_G: 0.0452 Convergence: 0.1044 k= 0.030710 lr = 0.0000488\n",
      "[4/25][5000/9765] Loss_D: 0.1065 Loss_G: 0.0374 Convergence: 0.1133 k= 0.030714 lr = 0.0000488\n",
      "[4/25][5010/9765] Loss_D: 0.1135 Loss_G: 0.0431 Convergence: 0.1176 k= 0.030728 lr = 0.0000488\n",
      "[4/25][5020/9765] Loss_D: 0.0956 Loss_G: 0.0408 Convergence: 0.0990 k= 0.030722 lr = 0.0000488\n",
      "[4/25][5030/9765] Loss_D: 0.1060 Loss_G: 0.0393 Convergence: 0.1108 k= 0.030742 lr = 0.0000488\n",
      "[4/25][5040/9765] Loss_D: 0.1090 Loss_G: 0.0430 Convergence: 0.1114 k= 0.030721 lr = 0.0000488\n",
      "[4/25][5050/9765] Loss_D: 0.1043 Loss_G: 0.0409 Convergence: 0.1070 k= 0.030717 lr = 0.0000488\n",
      "[4/25][5060/9765] Loss_D: 0.0988 Loss_G: 0.0481 Convergence: 0.1082 k= 0.030708 lr = 0.0000488\n",
      "[4/25][5070/9765] Loss_D: 0.1015 Loss_G: 0.0397 Convergence: 0.1041 k= 0.030706 lr = 0.0000488\n",
      "[4/25][5080/9765] Loss_D: 0.0931 Loss_G: 0.0400 Convergence: 0.0967 k= 0.030703 lr = 0.0000488\n",
      "[4/25][5090/9765] Loss_D: 0.0974 Loss_G: 0.0396 Convergence: 0.0988 k= 0.030703 lr = 0.0000488\n",
      "[4/25][5100/9765] Loss_D: 0.0901 Loss_G: 0.0407 Convergence: 0.0955 k= 0.030698 lr = 0.0000488\n",
      "[4/25][5110/9765] Loss_D: 0.1049 Loss_G: 0.0394 Convergence: 0.1091 k= 0.030689 lr = 0.0000488\n",
      "[4/25][5120/9765] Loss_D: 0.1052 Loss_G: 0.0412 Convergence: 0.1080 k= 0.030689 lr = 0.0000488\n",
      "[4/25][5130/9765] Loss_D: 0.1084 Loss_G: 0.0433 Convergence: 0.1103 k= 0.030688 lr = 0.0000488\n",
      "[4/25][5140/9765] Loss_D: 0.1048 Loss_G: 0.0382 Convergence: 0.1100 k= 0.030704 lr = 0.0000488\n",
      "[4/25][5150/9765] Loss_D: 0.1068 Loss_G: 0.0481 Convergence: 0.1129 k= 0.030717 lr = 0.0000488\n",
      "[4/25][5160/9765] Loss_D: 0.1084 Loss_G: 0.0438 Convergence: 0.1099 k= 0.030699 lr = 0.0000488\n",
      "[4/25][5170/9765] Loss_D: 0.1144 Loss_G: 0.0359 Convergence: 0.1259 k= 0.030706 lr = 0.0000488\n",
      "[4/25][5180/9765] Loss_D: 0.1148 Loss_G: 0.0506 Convergence: 0.1204 k= 0.030708 lr = 0.0000488\n",
      "[4/25][5190/9765] Loss_D: 0.1043 Loss_G: 0.0407 Convergence: 0.1070 k= 0.030682 lr = 0.0000488\n",
      "[4/25][5200/9765] Loss_D: 0.1040 Loss_G: 0.0414 Convergence: 0.1061 k= 0.030660 lr = 0.0000488\n",
      "[4/25][5210/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1014 k= 0.030669 lr = 0.0000488\n",
      "[4/25][5220/9765] Loss_D: 0.1007 Loss_G: 0.0355 Convergence: 0.1069 k= 0.030681 lr = 0.0000488\n",
      "[4/25][5230/9765] Loss_D: 0.0982 Loss_G: 0.0419 Convergence: 0.1016 k= 0.030675 lr = 0.0000488\n",
      "[4/25][5240/9765] Loss_D: 0.1040 Loss_G: 0.0408 Convergence: 0.1068 k= 0.030691 lr = 0.0000488\n",
      "[4/25][5250/9765] Loss_D: 0.0934 Loss_G: 0.0389 Convergence: 0.0957 k= 0.030704 lr = 0.0000488\n",
      "[4/25][5260/9765] Loss_D: 0.1063 Loss_G: 0.0455 Convergence: 0.1100 k= 0.030723 lr = 0.0000488\n",
      "[4/25][5270/9765] Loss_D: 0.0967 Loss_G: 0.0452 Convergence: 0.1040 k= 0.030711 lr = 0.0000488\n",
      "[4/25][5280/9765] Loss_D: 0.1000 Loss_G: 0.0401 Convergence: 0.1017 k= 0.030692 lr = 0.0000488\n",
      "[4/25][5290/9765] Loss_D: 0.1071 Loss_G: 0.0439 Convergence: 0.1089 k= 0.030703 lr = 0.0000488\n",
      "[4/25][5300/9765] Loss_D: 0.1043 Loss_G: 0.0472 Convergence: 0.1107 k= 0.030671 lr = 0.0000488\n",
      "[4/25][5310/9765] Loss_D: 0.0954 Loss_G: 0.0437 Convergence: 0.1017 k= 0.030654 lr = 0.0000488\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][5320/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1022 k= 0.030666 lr = 0.0000488\n",
      "[4/25][5330/9765] Loss_D: 0.0987 Loss_G: 0.0438 Convergence: 0.1038 k= 0.030656 lr = 0.0000488\n",
      "[4/25][5340/9765] Loss_D: 0.1067 Loss_G: 0.0419 Convergence: 0.1093 k= 0.030668 lr = 0.0000488\n",
      "[4/25][5350/9765] Loss_D: 0.1063 Loss_G: 0.0417 Convergence: 0.1089 k= 0.030665 lr = 0.0000488\n",
      "[4/25][5360/9765] Loss_D: 0.1094 Loss_G: 0.0423 Convergence: 0.1127 k= 0.030649 lr = 0.0000488\n",
      "[4/25][5370/9765] Loss_D: 0.1063 Loss_G: 0.0392 Convergence: 0.1113 k= 0.030649 lr = 0.0000488\n",
      "[4/25][5380/9765] Loss_D: 0.1097 Loss_G: 0.0410 Convergence: 0.1147 k= 0.030637 lr = 0.0000488\n",
      "[4/25][5390/9765] Loss_D: 0.1141 Loss_G: 0.0423 Convergence: 0.1191 k= 0.030651 lr = 0.0000488\n",
      "[4/25][5400/9765] Loss_D: 0.1134 Loss_G: 0.0447 Convergence: 0.1158 k= 0.030637 lr = 0.0000488\n",
      "[4/25][5410/9765] Loss_D: 0.1061 Loss_G: 0.0400 Convergence: 0.1103 k= 0.030640 lr = 0.0000488\n",
      "[4/25][5420/9765] Loss_D: 0.1024 Loss_G: 0.0436 Convergence: 0.1058 k= 0.030640 lr = 0.0000488\n",
      "[4/25][5430/9765] Loss_D: 0.1035 Loss_G: 0.0416 Convergence: 0.1052 k= 0.030642 lr = 0.0000488\n",
      "[4/25][5440/9765] Loss_D: 0.1081 Loss_G: 0.0427 Convergence: 0.1106 k= 0.030616 lr = 0.0000488\n",
      "[4/25][5450/9765] Loss_D: 0.1142 Loss_G: 0.0446 Convergence: 0.1172 k= 0.030626 lr = 0.0000488\n",
      "[4/25][5460/9765] Loss_D: 0.1013 Loss_G: 0.0496 Convergence: 0.1112 k= 0.030587 lr = 0.0000488\n",
      "[4/25][5470/9765] Loss_D: 0.1046 Loss_G: 0.0395 Convergence: 0.1086 k= 0.030580 lr = 0.0000488\n",
      "[4/25][5480/9765] Loss_D: 0.0909 Loss_G: 0.0465 Convergence: 0.1018 k= 0.030569 lr = 0.0000488\n",
      "[4/25][5490/9765] Loss_D: 0.1047 Loss_G: 0.0415 Convergence: 0.1068 k= 0.030557 lr = 0.0000488\n",
      "[4/25][5500/9765] Loss_D: 0.0914 Loss_G: 0.0406 Convergence: 0.0961 k= 0.030577 lr = 0.0000488\n",
      "[4/25][5510/9765] Loss_D: 0.1024 Loss_G: 0.0406 Convergence: 0.1046 k= 0.030577 lr = 0.0000488\n",
      "[4/25][5520/9765] Loss_D: 0.1020 Loss_G: 0.0421 Convergence: 0.1041 k= 0.030578 lr = 0.0000488\n",
      "[4/25][5530/9765] Loss_D: 0.0989 Loss_G: 0.0410 Convergence: 0.1011 k= 0.030586 lr = 0.0000488\n",
      "[4/25][5540/9765] Loss_D: 0.1044 Loss_G: 0.0373 Convergence: 0.1104 k= 0.030609 lr = 0.0000488\n",
      "[4/25][5550/9765] Loss_D: 0.0946 Loss_G: 0.0512 Convergence: 0.1088 k= 0.030586 lr = 0.0000488\n",
      "[4/25][5560/9765] Loss_D: 0.1007 Loss_G: 0.0459 Convergence: 0.1070 k= 0.030541 lr = 0.0000488\n",
      "[4/25][5570/9765] Loss_D: 0.1053 Loss_G: 0.0415 Convergence: 0.1076 k= 0.030554 lr = 0.0000488\n",
      "[4/25][5580/9765] Loss_D: 0.1110 Loss_G: 0.0448 Convergence: 0.1122 k= 0.030550 lr = 0.0000488\n",
      "[4/25][5590/9765] Loss_D: 0.1044 Loss_G: 0.0442 Convergence: 0.1077 k= 0.030534 lr = 0.0000488\n",
      "[4/25][5600/9765] Loss_D: 0.1118 Loss_G: 0.0457 Convergence: 0.1135 k= 0.030536 lr = 0.0000488\n",
      "[4/25][5610/9765] Loss_D: 0.1040 Loss_G: 0.0426 Convergence: 0.1057 k= 0.030553 lr = 0.0000488\n",
      "[4/25][5620/9765] Loss_D: 0.1084 Loss_G: 0.0410 Convergence: 0.1125 k= 0.030539 lr = 0.0000488\n",
      "[4/25][5630/9765] Loss_D: 0.1094 Loss_G: 0.0400 Convergence: 0.1149 k= 0.030534 lr = 0.0000488\n",
      "[4/25][5640/9765] Loss_D: 0.1082 Loss_G: 0.0428 Convergence: 0.1105 k= 0.030510 lr = 0.0000488\n",
      "[4/25][5650/9765] Loss_D: 0.1040 Loss_G: 0.0433 Convergence: 0.1065 k= 0.030503 lr = 0.0000488\n",
      "[4/25][5660/9765] Loss_D: 0.1045 Loss_G: 0.0421 Convergence: 0.1059 k= 0.030519 lr = 0.0000488\n",
      "[4/25][5670/9765] Loss_D: 0.0999 Loss_G: 0.0378 Convergence: 0.1038 k= 0.030517 lr = 0.0000488\n",
      "[4/25][5680/9765] Loss_D: 0.1077 Loss_G: 0.0425 Convergence: 0.1099 k= 0.030561 lr = 0.0000488\n",
      "[4/25][5690/9765] Loss_D: 0.1149 Loss_G: 0.0420 Convergence: 0.1206 k= 0.030584 lr = 0.0000488\n",
      "[4/25][5700/9765] Loss_D: 0.1096 Loss_G: 0.0416 Convergence: 0.1137 k= 0.030591 lr = 0.0000488\n",
      "[4/25][5710/9765] Loss_D: 0.1008 Loss_G: 0.0495 Convergence: 0.1107 k= 0.030583 lr = 0.0000488\n",
      "[4/25][5720/9765] Loss_D: 0.1139 Loss_G: 0.0427 Convergence: 0.1187 k= 0.030591 lr = 0.0000488\n",
      "[4/25][5730/9765] Loss_D: 0.1038 Loss_G: 0.0397 Convergence: 0.1073 k= 0.030565 lr = 0.0000488\n",
      "[4/25][5740/9765] Loss_D: 0.0998 Loss_G: 0.0420 Convergence: 0.1025 k= 0.030560 lr = 0.0000488\n",
      "[4/25][5750/9765] Loss_D: 0.1047 Loss_G: 0.0404 Convergence: 0.1080 k= 0.030570 lr = 0.0000488\n",
      "[4/25][5760/9765] Loss_D: 0.0956 Loss_G: 0.0445 Convergence: 0.1027 k= 0.030523 lr = 0.0000488\n",
      "[4/25][5770/9765] Loss_D: 0.1000 Loss_G: 0.0418 Convergence: 0.1026 k= 0.030533 lr = 0.0000488\n",
      "[4/25][5780/9765] Loss_D: 0.1007 Loss_G: 0.0384 Convergence: 0.1041 k= 0.030573 lr = 0.0000488\n",
      "[4/25][5790/9765] Loss_D: 0.0947 Loss_G: 0.0471 Convergence: 0.1048 k= 0.030523 lr = 0.0000488\n",
      "[4/25][5800/9765] Loss_D: 0.1027 Loss_G: 0.0414 Convergence: 0.1041 k= 0.030484 lr = 0.0000488\n",
      "[4/25][5810/9765] Loss_D: 0.1041 Loss_G: 0.0369 Convergence: 0.1103 k= 0.030521 lr = 0.0000488\n",
      "[4/25][5820/9765] Loss_D: 0.1078 Loss_G: 0.0559 Convergence: 0.1215 k= 0.030519 lr = 0.0000488\n",
      "[4/25][5830/9765] Loss_D: 0.0943 Loss_G: 0.0423 Convergence: 0.0997 k= 0.030433 lr = 0.0000488\n",
      "[4/25][5840/9765] Loss_D: 0.0989 Loss_G: 0.0400 Convergence: 0.1002 k= 0.030438 lr = 0.0000488\n",
      "[4/25][5850/9765] Loss_D: 0.0997 Loss_G: 0.0404 Convergence: 0.1010 k= 0.030450 lr = 0.0000488\n",
      "[4/25][5860/9765] Loss_D: 0.1081 Loss_G: 0.0376 Convergence: 0.1154 k= 0.030456 lr = 0.0000488\n",
      "[4/25][5870/9765] Loss_D: 0.1089 Loss_G: 0.0412 Convergence: 0.1129 k= 0.030478 lr = 0.0000488\n",
      "[4/25][5880/9765] Loss_D: 0.1002 Loss_G: 0.0435 Convergence: 0.1044 k= 0.030463 lr = 0.0000488\n",
      "[4/25][5890/9765] Loss_D: 0.1101 Loss_G: 0.0400 Convergence: 0.1158 k= 0.030468 lr = 0.0000488\n",
      "[4/25][5900/9765] Loss_D: 0.0974 Loss_G: 0.0375 Convergence: 0.1004 k= 0.030483 lr = 0.0000488\n",
      "[4/25][5910/9765] Loss_D: 0.1089 Loss_G: 0.0483 Convergence: 0.1144 k= 0.030490 lr = 0.0000488\n",
      "[4/25][5920/9765] Loss_D: 0.1077 Loss_G: 0.0391 Convergence: 0.1134 k= 0.030490 lr = 0.0000488\n",
      "[4/25][5930/9765] Loss_D: 0.0950 Loss_G: 0.0415 Convergence: 0.0993 k= 0.030485 lr = 0.0000488\n",
      "[4/25][5940/9765] Loss_D: 0.1036 Loss_G: 0.0521 Convergence: 0.1150 k= 0.030484 lr = 0.0000463\n",
      "[4/25][5950/9765] Loss_D: 0.0992 Loss_G: 0.0422 Convergence: 0.1024 k= 0.030473 lr = 0.0000463\n",
      "[4/25][5960/9765] Loss_D: 0.1058 Loss_G: 0.0411 Convergence: 0.1086 k= 0.030500 lr = 0.0000463\n",
      "[4/25][5970/9765] Loss_D: 0.1055 Loss_G: 0.0374 Convergence: 0.1119 k= 0.030517 lr = 0.0000463\n",
      "[4/25][5980/9765] Loss_D: 0.1033 Loss_G: 0.0418 Convergence: 0.1046 k= 0.030526 lr = 0.0000463\n",
      "[4/25][5990/9765] Loss_D: 0.1088 Loss_G: 0.0430 Convergence: 0.1110 k= 0.030524 lr = 0.0000463\n",
      "[4/25][6000/9765] Loss_D: 0.1015 Loss_G: 0.0397 Convergence: 0.1041 k= 0.030536 lr = 0.0000463\n",
      "[4/25][6010/9765] Loss_D: 0.1146 Loss_G: 0.0467 Convergence: 0.1163 k= 0.030536 lr = 0.0000463\n",
      "[4/25][6020/9765] Loss_D: 0.0977 Loss_G: 0.0436 Convergence: 0.1030 k= 0.030491 lr = 0.0000463\n",
      "[4/25][6030/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0955 k= 0.030537 lr = 0.0000463\n",
      "[4/25][6040/9765] Loss_D: 0.1059 Loss_G: 0.0406 Convergence: 0.1095 k= 0.030529 lr = 0.0000463\n",
      "[4/25][6050/9765] Loss_D: 0.0997 Loss_G: 0.0453 Convergence: 0.1060 k= 0.030492 lr = 0.0000463\n",
      "[4/25][6060/9765] Loss_D: 0.0971 Loss_G: 0.0414 Convergence: 0.1004 k= 0.030501 lr = 0.0000463\n",
      "[4/25][6070/9765] Loss_D: 0.1010 Loss_G: 0.0510 Convergence: 0.1125 k= 0.030493 lr = 0.0000463\n",
      "[4/25][6080/9765] Loss_D: 0.1057 Loss_G: 0.0437 Convergence: 0.1079 k= 0.030469 lr = 0.0000463\n",
      "[4/25][6090/9765] Loss_D: 0.1107 Loss_G: 0.0417 Convergence: 0.1151 k= 0.030467 lr = 0.0000463\n",
      "[4/25][6100/9765] Loss_D: 0.0976 Loss_G: 0.0415 Convergence: 0.1008 k= 0.030472 lr = 0.0000463\n",
      "[4/25][6110/9765] Loss_D: 0.1094 Loss_G: 0.0443 Convergence: 0.1106 k= 0.030479 lr = 0.0000463\n",
      "[4/25][6120/9765] Loss_D: 0.1128 Loss_G: 0.0447 Convergence: 0.1150 k= 0.030477 lr = 0.0000463\n",
      "[4/25][6130/9765] Loss_D: 0.1019 Loss_G: 0.0390 Convergence: 0.1053 k= 0.030471 lr = 0.0000463\n",
      "[4/25][6140/9765] Loss_D: 0.1072 Loss_G: 0.0389 Convergence: 0.1127 k= 0.030515 lr = 0.0000463\n",
      "[4/25][6150/9765] Loss_D: 0.1067 Loss_G: 0.0404 Convergence: 0.1104 k= 0.030520 lr = 0.0000463\n",
      "[4/25][6160/9765] Loss_D: 0.1035 Loss_G: 0.0421 Convergence: 0.1050 k= 0.030526 lr = 0.0000463\n",
      "[4/25][6170/9765] Loss_D: 0.1093 Loss_G: 0.0515 Convergence: 0.1178 k= 0.030506 lr = 0.0000463\n",
      "[4/25][6180/9765] Loss_D: 0.1076 Loss_G: 0.0424 Convergence: 0.1101 k= 0.030480 lr = 0.0000463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][6190/9765] Loss_D: 0.1101 Loss_G: 0.0505 Convergence: 0.1173 k= 0.030477 lr = 0.0000463\n",
      "[4/25][6200/9765] Loss_D: 0.1048 Loss_G: 0.0388 Convergence: 0.1096 k= 0.030488 lr = 0.0000463\n",
      "[4/25][6210/9765] Loss_D: 0.1098 Loss_G: 0.0452 Convergence: 0.1118 k= 0.030474 lr = 0.0000463\n",
      "[4/25][6220/9765] Loss_D: 0.1021 Loss_G: 0.0420 Convergence: 0.1041 k= 0.030456 lr = 0.0000463\n",
      "[4/25][6230/9765] Loss_D: 0.1014 Loss_G: 0.0386 Convergence: 0.1050 k= 0.030449 lr = 0.0000463\n",
      "[4/25][6240/9765] Loss_D: 0.1035 Loss_G: 0.0416 Convergence: 0.1050 k= 0.030471 lr = 0.0000463\n",
      "[4/25][6250/9765] Loss_D: 0.1105 Loss_G: 0.0423 Convergence: 0.1142 k= 0.030481 lr = 0.0000463\n",
      "[4/25][6260/9765] Loss_D: 0.1209 Loss_G: 0.0384 Convergence: 0.1326 k= 0.030501 lr = 0.0000463\n",
      "[4/25][6270/9765] Loss_D: 0.0968 Loss_G: 0.0420 Convergence: 0.1008 k= 0.030535 lr = 0.0000463\n",
      "[4/25][6280/9765] Loss_D: 0.1093 Loss_G: 0.0420 Convergence: 0.1128 k= 0.030538 lr = 0.0000463\n",
      "[4/25][6290/9765] Loss_D: 0.0960 Loss_G: 0.0361 Convergence: 0.0998 k= 0.030578 lr = 0.0000463\n",
      "[4/25][6300/9765] Loss_D: 0.0988 Loss_G: 0.0386 Convergence: 0.1015 k= 0.030558 lr = 0.0000463\n",
      "[4/25][6310/9765] Loss_D: 0.1010 Loss_G: 0.0503 Convergence: 0.1117 k= 0.030546 lr = 0.0000463\n",
      "[4/25][6320/9765] Loss_D: 0.1074 Loss_G: 0.0379 Convergence: 0.1141 k= 0.030572 lr = 0.0000463\n",
      "[4/25][6330/9765] Loss_D: 0.1095 Loss_G: 0.0435 Convergence: 0.1114 k= 0.030562 lr = 0.0000463\n",
      "[4/25][6340/9765] Loss_D: 0.1047 Loss_G: 0.0393 Convergence: 0.1090 k= 0.030588 lr = 0.0000463\n",
      "[4/25][6350/9765] Loss_D: 0.1052 Loss_G: 0.0455 Convergence: 0.1094 k= 0.030575 lr = 0.0000463\n",
      "[4/25][6360/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1008 k= 0.030521 lr = 0.0000463\n",
      "[4/25][6370/9765] Loss_D: 0.1113 Loss_G: 0.0413 Convergence: 0.1162 k= 0.030527 lr = 0.0000463\n",
      "[4/25][6380/9765] Loss_D: 0.0993 Loss_G: 0.0447 Convergence: 0.1050 k= 0.030511 lr = 0.0000463\n",
      "[4/25][6390/9765] Loss_D: 0.1147 Loss_G: 0.0437 Convergence: 0.1186 k= 0.030462 lr = 0.0000463\n",
      "[4/25][6400/9765] Loss_D: 0.0991 Loss_G: 0.0375 Convergence: 0.1029 k= 0.030483 lr = 0.0000463\n",
      "[4/25][6410/9765] Loss_D: 0.1063 Loss_G: 0.0415 Convergence: 0.1091 k= 0.030514 lr = 0.0000463\n",
      "[4/25][6420/9765] Loss_D: 0.0990 Loss_G: 0.0419 Convergence: 0.1021 k= 0.030495 lr = 0.0000463\n",
      "[4/25][6430/9765] Loss_D: 0.0937 Loss_G: 0.0364 Convergence: 0.0964 k= 0.030505 lr = 0.0000463\n",
      "[4/25][6440/9765] Loss_D: 0.1062 Loss_G: 0.0454 Convergence: 0.1099 k= 0.030516 lr = 0.0000463\n",
      "[4/25][6450/9765] Loss_D: 0.1032 Loss_G: 0.0415 Convergence: 0.1046 k= 0.030508 lr = 0.0000463\n",
      "[4/25][6460/9765] Loss_D: 0.1164 Loss_G: 0.0417 Convergence: 0.1231 k= 0.030489 lr = 0.0000463\n",
      "[4/25][6470/9765] Loss_D: 0.1012 Loss_G: 0.0437 Convergence: 0.1052 k= 0.030484 lr = 0.0000463\n",
      "[4/25][6480/9765] Loss_D: 0.1062 Loss_G: 0.0399 Convergence: 0.1106 k= 0.030474 lr = 0.0000463\n",
      "[4/25][6490/9765] Loss_D: 0.0992 Loss_G: 0.0395 Convergence: 0.1009 k= 0.030485 lr = 0.0000463\n",
      "[4/25][6500/9765] Loss_D: 0.0959 Loss_G: 0.0397 Convergence: 0.0980 k= 0.030499 lr = 0.0000463\n",
      "[4/25][6510/9765] Loss_D: 0.1126 Loss_G: 0.0440 Convergence: 0.1155 k= 0.030505 lr = 0.0000463\n",
      "[4/25][6520/9765] Loss_D: 0.1101 Loss_G: 0.0406 Convergence: 0.1154 k= 0.030509 lr = 0.0000463\n",
      "[4/25][6530/9765] Loss_D: 0.0989 Loss_G: 0.0447 Convergence: 0.1048 k= 0.030504 lr = 0.0000463\n",
      "[4/25][6540/9765] Loss_D: 0.0983 Loss_G: 0.0441 Convergence: 0.1039 k= 0.030500 lr = 0.0000463\n",
      "[4/25][6550/9765] Loss_D: 0.1047 Loss_G: 0.0437 Convergence: 0.1073 k= 0.030480 lr = 0.0000463\n",
      "[4/25][6560/9765] Loss_D: 0.1033 Loss_G: 0.0425 Convergence: 0.1052 k= 0.030469 lr = 0.0000463\n",
      "[4/25][6570/9765] Loss_D: 0.0981 Loss_G: 0.0378 Convergence: 0.1012 k= 0.030484 lr = 0.0000463\n",
      "[4/25][6580/9765] Loss_D: 0.0977 Loss_G: 0.0497 Convergence: 0.1093 k= 0.030480 lr = 0.0000463\n",
      "[4/25][6590/9765] Loss_D: 0.1019 Loss_G: 0.0388 Convergence: 0.1055 k= 0.030469 lr = 0.0000463\n",
      "[4/25][6600/9765] Loss_D: 0.0926 Loss_G: 0.0415 Convergence: 0.0979 k= 0.030475 lr = 0.0000463\n",
      "[4/25][6610/9765] Loss_D: 0.0967 Loss_G: 0.0421 Convergence: 0.1009 k= 0.030486 lr = 0.0000463\n",
      "[4/25][6620/9765] Loss_D: 0.0997 Loss_G: 0.0482 Convergence: 0.1088 k= 0.030490 lr = 0.0000463\n",
      "[4/25][6630/9765] Loss_D: 0.1044 Loss_G: 0.0452 Convergence: 0.1087 k= 0.030448 lr = 0.0000463\n",
      "[4/25][6640/9765] Loss_D: 0.1028 Loss_G: 0.0378 Convergence: 0.1078 k= 0.030462 lr = 0.0000463\n",
      "[4/25][6650/9765] Loss_D: 0.1054 Loss_G: 0.0426 Convergence: 0.1067 k= 0.030483 lr = 0.0000463\n",
      "[4/25][6660/9765] Loss_D: 0.1010 Loss_G: 0.0424 Convergence: 0.1037 k= 0.030432 lr = 0.0000463\n",
      "[4/25][6670/9765] Loss_D: 0.0988 Loss_G: 0.0410 Convergence: 0.1010 k= 0.030427 lr = 0.0000463\n",
      "[4/25][6680/9765] Loss_D: 0.1096 Loss_G: 0.0415 Convergence: 0.1136 k= 0.030439 lr = 0.0000463\n",
      "[4/25][6690/9765] Loss_D: 0.1176 Loss_G: 0.0471 Convergence: 0.1195 k= 0.030424 lr = 0.0000463\n",
      "[4/25][6700/9765] Loss_D: 0.0990 Loss_G: 0.0426 Convergence: 0.1027 k= 0.030416 lr = 0.0000463\n",
      "[4/25][6710/9765] Loss_D: 0.1005 Loss_G: 0.0431 Convergence: 0.1042 k= 0.030411 lr = 0.0000463\n",
      "[4/25][6720/9765] Loss_D: 0.1105 Loss_G: 0.0407 Convergence: 0.1158 k= 0.030416 lr = 0.0000463\n",
      "[4/25][6730/9765] Loss_D: 0.1034 Loss_G: 0.0491 Convergence: 0.1119 k= 0.030411 lr = 0.0000463\n",
      "[4/25][6740/9765] Loss_D: 0.0975 Loss_G: 0.0398 Convergence: 0.0990 k= 0.030409 lr = 0.0000463\n",
      "[4/25][6750/9765] Loss_D: 0.1030 Loss_G: 0.0465 Convergence: 0.1091 k= 0.030423 lr = 0.0000463\n",
      "[4/25][6760/9765] Loss_D: 0.1044 Loss_G: 0.0411 Convergence: 0.1067 k= 0.030429 lr = 0.0000463\n",
      "[4/25][6770/9765] Loss_D: 0.1190 Loss_G: 0.0456 Convergence: 0.1228 k= 0.030423 lr = 0.0000463\n",
      "[4/25][6780/9765] Loss_D: 0.1084 Loss_G: 0.0429 Convergence: 0.1105 k= 0.030415 lr = 0.0000463\n",
      "[4/25][6790/9765] Loss_D: 0.1059 Loss_G: 0.0385 Convergence: 0.1116 k= 0.030410 lr = 0.0000463\n",
      "[4/25][6800/9765] Loss_D: 0.1098 Loss_G: 0.0411 Convergence: 0.1143 k= 0.030431 lr = 0.0000463\n",
      "[4/25][6810/9765] Loss_D: 0.1055 Loss_G: 0.0376 Convergence: 0.1116 k= 0.030459 lr = 0.0000463\n",
      "[4/25][6820/9765] Loss_D: 0.1013 Loss_G: 0.0388 Convergence: 0.1046 k= 0.030465 lr = 0.0000463\n",
      "[4/25][6830/9765] Loss_D: 0.1099 Loss_G: 0.0377 Convergence: 0.1177 k= 0.030468 lr = 0.0000463\n",
      "[4/25][6840/9765] Loss_D: 0.1069 Loss_G: 0.0426 Convergence: 0.1090 k= 0.030472 lr = 0.0000463\n",
      "[4/25][6850/9765] Loss_D: 0.1046 Loss_G: 0.0466 Convergence: 0.1101 k= 0.030465 lr = 0.0000463\n",
      "[4/25][6860/9765] Loss_D: 0.0971 Loss_G: 0.0456 Convergence: 0.1047 k= 0.030458 lr = 0.0000463\n",
      "[4/25][6870/9765] Loss_D: 0.1036 Loss_G: 0.0398 Convergence: 0.1069 k= 0.030450 lr = 0.0000463\n",
      "[4/25][6880/9765] Loss_D: 0.1000 Loss_G: 0.0441 Convergence: 0.1048 k= 0.030451 lr = 0.0000463\n",
      "[4/25][6890/9765] Loss_D: 0.0995 Loss_G: 0.0407 Convergence: 0.1012 k= 0.030449 lr = 0.0000463\n",
      "[4/25][6900/9765] Loss_D: 0.1130 Loss_G: 0.0392 Convergence: 0.1207 k= 0.030443 lr = 0.0000463\n",
      "[4/25][6910/9765] Loss_D: 0.1030 Loss_G: 0.0394 Convergence: 0.1064 k= 0.030452 lr = 0.0000463\n",
      "[4/25][6920/9765] Loss_D: 0.1057 Loss_G: 0.0381 Convergence: 0.1115 k= 0.030468 lr = 0.0000463\n",
      "[4/25][6930/9765] Loss_D: 0.1003 Loss_G: 0.0406 Convergence: 0.1016 k= 0.030481 lr = 0.0000463\n",
      "[4/25][6940/9765] Loss_D: 0.1066 Loss_G: 0.0409 Convergence: 0.1100 k= 0.030485 lr = 0.0000463\n",
      "[4/25][6950/9765] Loss_D: 0.1072 Loss_G: 0.0422 Convergence: 0.1097 k= 0.030492 lr = 0.0000463\n",
      "[4/25][6960/9765] Loss_D: 0.0933 Loss_G: 0.0423 Convergence: 0.0990 k= 0.030488 lr = 0.0000463\n",
      "[4/25][6970/9765] Loss_D: 0.0987 Loss_G: 0.0365 Convergence: 0.1033 k= 0.030487 lr = 0.0000463\n",
      "[4/25][6980/9765] Loss_D: 0.0994 Loss_G: 0.0415 Convergence: 0.1020 k= 0.030531 lr = 0.0000463\n",
      "[4/25][6990/9765] Loss_D: 0.1002 Loss_G: 0.0404 Convergence: 0.1018 k= 0.030516 lr = 0.0000463\n",
      "[4/25][7000/9765] Loss_D: 0.0974 Loss_G: 0.0406 Convergence: 0.0997 k= 0.030502 lr = 0.0000463\n",
      "[4/25][7010/9765] Loss_D: 0.0990 Loss_G: 0.0484 Convergence: 0.1085 k= 0.030495 lr = 0.0000463\n",
      "[4/25][7020/9765] Loss_D: 0.1067 Loss_G: 0.0441 Convergence: 0.1089 k= 0.030467 lr = 0.0000463\n",
      "[4/25][7030/9765] Loss_D: 0.1075 Loss_G: 0.0416 Convergence: 0.1106 k= 0.030476 lr = 0.0000463\n",
      "[4/25][7040/9765] Loss_D: 0.1153 Loss_G: 0.0375 Convergence: 0.1254 k= 0.030518 lr = 0.0000463\n",
      "[4/25][7050/9765] Loss_D: 0.1030 Loss_G: 0.0435 Convergence: 0.1060 k= 0.030508 lr = 0.0000463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][7060/9765] Loss_D: 0.1177 Loss_G: 0.0448 Convergence: 0.1219 k= 0.030489 lr = 0.0000463\n",
      "[4/25][7070/9765] Loss_D: 0.1031 Loss_G: 0.0380 Convergence: 0.1081 k= 0.030486 lr = 0.0000463\n",
      "[4/25][7080/9765] Loss_D: 0.0980 Loss_G: 0.0482 Convergence: 0.1079 k= 0.030476 lr = 0.0000463\n",
      "[4/25][7090/9765] Loss_D: 0.0981 Loss_G: 0.0401 Convergence: 0.0997 k= 0.030471 lr = 0.0000463\n",
      "[4/25][7100/9765] Loss_D: 0.1088 Loss_G: 0.0423 Convergence: 0.1118 k= 0.030482 lr = 0.0000463\n",
      "[4/25][7110/9765] Loss_D: 0.1042 Loss_G: 0.0422 Convergence: 0.1056 k= 0.030458 lr = 0.0000463\n",
      "[4/25][7120/9765] Loss_D: 0.1084 Loss_G: 0.0423 Convergence: 0.1114 k= 0.030452 lr = 0.0000463\n",
      "[4/25][7130/9765] Loss_D: 0.1092 Loss_G: 0.0415 Convergence: 0.1132 k= 0.030452 lr = 0.0000463\n",
      "[4/25][7140/9765] Loss_D: 0.1069 Loss_G: 0.0375 Convergence: 0.1138 k= 0.030474 lr = 0.0000463\n",
      "[4/25][7150/9765] Loss_D: 0.0994 Loss_G: 0.0410 Convergence: 0.1014 k= 0.030455 lr = 0.0000463\n",
      "[4/25][7160/9765] Loss_D: 0.1041 Loss_G: 0.0451 Convergence: 0.1083 k= 0.030422 lr = 0.0000463\n",
      "[4/25][7170/9765] Loss_D: 0.0982 Loss_G: 0.0405 Convergence: 0.1001 k= 0.030447 lr = 0.0000463\n",
      "[4/25][7180/9765] Loss_D: 0.0938 Loss_G: 0.0378 Convergence: 0.0952 k= 0.030462 lr = 0.0000463\n",
      "[4/25][7190/9765] Loss_D: 0.1029 Loss_G: 0.0444 Convergence: 0.1069 k= 0.030439 lr = 0.0000463\n",
      "[4/25][7200/9765] Loss_D: 0.1122 Loss_G: 0.0404 Convergence: 0.1184 k= 0.030456 lr = 0.0000463\n",
      "[4/25][7210/9765] Loss_D: 0.0971 Loss_G: 0.0367 Convergence: 0.1007 k= 0.030480 lr = 0.0000463\n",
      "[4/25][7220/9765] Loss_D: 0.1179 Loss_G: 0.0429 Convergence: 0.1240 k= 0.030491 lr = 0.0000463\n",
      "[4/25][7230/9765] Loss_D: 0.1112 Loss_G: 0.0387 Convergence: 0.1187 k= 0.030483 lr = 0.0000463\n",
      "[4/25][7240/9765] Loss_D: 0.0948 Loss_G: 0.0393 Convergence: 0.0969 k= 0.030510 lr = 0.0000463\n",
      "[4/25][7250/9765] Loss_D: 0.0964 Loss_G: 0.0414 Convergence: 0.0999 k= 0.030514 lr = 0.0000463\n",
      "[4/25][7260/9765] Loss_D: 0.1042 Loss_G: 0.0440 Convergence: 0.1073 k= 0.030494 lr = 0.0000463\n",
      "[4/25][7270/9765] Loss_D: 0.1105 Loss_G: 0.0438 Convergence: 0.1126 k= 0.030512 lr = 0.0000463\n",
      "[4/25][7280/9765] Loss_D: 0.1028 Loss_G: 0.0436 Convergence: 0.1061 k= 0.030494 lr = 0.0000463\n",
      "[4/25][7290/9765] Loss_D: 0.1077 Loss_G: 0.0423 Convergence: 0.1104 k= 0.030481 lr = 0.0000463\n",
      "[4/25][7300/9765] Loss_D: 0.1100 Loss_G: 0.0403 Convergence: 0.1154 k= 0.030478 lr = 0.0000463\n",
      "[4/25][7310/9765] Loss_D: 0.1057 Loss_G: 0.0428 Convergence: 0.1070 k= 0.030467 lr = 0.0000463\n",
      "[4/25][7320/9765] Loss_D: 0.0908 Loss_G: 0.0426 Convergence: 0.0979 k= 0.030441 lr = 0.0000463\n",
      "[4/25][7330/9765] Loss_D: 0.1012 Loss_G: 0.0407 Convergence: 0.1026 k= 0.030430 lr = 0.0000463\n",
      "[4/25][7340/9765] Loss_D: 0.1029 Loss_G: 0.0435 Convergence: 0.1059 k= 0.030445 lr = 0.0000463\n",
      "[4/25][7350/9765] Loss_D: 0.1049 Loss_G: 0.0448 Convergence: 0.1085 k= 0.030424 lr = 0.0000463\n",
      "[4/25][7360/9765] Loss_D: 0.1057 Loss_G: 0.0422 Convergence: 0.1075 k= 0.030419 lr = 0.0000463\n",
      "[4/25][7370/9765] Loss_D: 0.0975 Loss_G: 0.0373 Convergence: 0.1007 k= 0.030435 lr = 0.0000463\n",
      "[4/25][7380/9765] Loss_D: 0.1020 Loss_G: 0.0434 Convergence: 0.1053 k= 0.030445 lr = 0.0000463\n",
      "[4/25][7390/9765] Loss_D: 0.1119 Loss_G: 0.0428 Convergence: 0.1157 k= 0.030433 lr = 0.0000463\n",
      "[4/25][7400/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1015 k= 0.030448 lr = 0.0000463\n",
      "[4/25][7410/9765] Loss_D: 0.1066 Loss_G: 0.0483 Convergence: 0.1131 k= 0.030454 lr = 0.0000463\n",
      "[4/25][7420/9765] Loss_D: 0.1122 Loss_G: 0.0418 Convergence: 0.1171 k= 0.030434 lr = 0.0000463\n",
      "[4/25][7430/9765] Loss_D: 0.1066 Loss_G: 0.0403 Convergence: 0.1106 k= 0.030460 lr = 0.0000463\n",
      "[4/25][7440/9765] Loss_D: 0.0934 Loss_G: 0.0437 Convergence: 0.1005 k= 0.030451 lr = 0.0000463\n",
      "[4/25][7450/9765] Loss_D: 0.1113 Loss_G: 0.0434 Convergence: 0.1144 k= 0.030440 lr = 0.0000463\n",
      "[4/25][7460/9765] Loss_D: 0.1146 Loss_G: 0.0398 Convergence: 0.1223 k= 0.030457 lr = 0.0000463\n",
      "[4/25][7470/9765] Loss_D: 0.1129 Loss_G: 0.0419 Convergence: 0.1180 k= 0.030451 lr = 0.0000463\n",
      "[4/25][7480/9765] Loss_D: 0.0963 Loss_G: 0.0432 Convergence: 0.1016 k= 0.030441 lr = 0.0000463\n",
      "[4/25][7490/9765] Loss_D: 0.0967 Loss_G: 0.0399 Convergence: 0.0987 k= 0.030458 lr = 0.0000463\n",
      "[4/25][7500/9765] Loss_D: 0.1074 Loss_G: 0.0388 Convergence: 0.1133 k= 0.030445 lr = 0.0000463\n",
      "[4/25][7510/9765] Loss_D: 0.1042 Loss_G: 0.0437 Convergence: 0.1070 k= 0.030421 lr = 0.0000463\n",
      "[4/25][7520/9765] Loss_D: 0.0983 Loss_G: 0.0373 Convergence: 0.1019 k= 0.030437 lr = 0.0000463\n",
      "[4/25][7530/9765] Loss_D: 0.1089 Loss_G: 0.0426 Convergence: 0.1116 k= 0.030428 lr = 0.0000463\n",
      "[4/25][7540/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0970 k= 0.030457 lr = 0.0000463\n",
      "[4/25][7550/9765] Loss_D: 0.1023 Loss_G: 0.0378 Convergence: 0.1071 k= 0.030476 lr = 0.0000463\n",
      "[4/25][7560/9765] Loss_D: 0.1098 Loss_G: 0.0469 Convergence: 0.1135 k= 0.030465 lr = 0.0000463\n",
      "[4/25][7570/9765] Loss_D: 0.1020 Loss_G: 0.0444 Convergence: 0.1063 k= 0.030485 lr = 0.0000463\n",
      "[4/25][7580/9765] Loss_D: 0.1049 Loss_G: 0.0422 Convergence: 0.1064 k= 0.030495 lr = 0.0000463\n",
      "[4/25][7590/9765] Loss_D: 0.1031 Loss_G: 0.0407 Convergence: 0.1055 k= 0.030458 lr = 0.0000463\n",
      "[4/25][7600/9765] Loss_D: 0.0956 Loss_G: 0.0378 Convergence: 0.0976 k= 0.030478 lr = 0.0000463\n",
      "[4/25][7610/9765] Loss_D: 0.0998 Loss_G: 0.0485 Convergence: 0.1092 k= 0.030494 lr = 0.0000463\n",
      "[4/25][7620/9765] Loss_D: 0.1088 Loss_G: 0.0414 Convergence: 0.1128 k= 0.030454 lr = 0.0000463\n",
      "[4/25][7630/9765] Loss_D: 0.0975 Loss_G: 0.0398 Convergence: 0.0991 k= 0.030453 lr = 0.0000463\n",
      "[4/25][7640/9765] Loss_D: 0.1043 Loss_G: 0.0391 Convergence: 0.1086 k= 0.030470 lr = 0.0000463\n",
      "[4/25][7650/9765] Loss_D: 0.0964 Loss_G: 0.0436 Convergence: 0.1022 k= 0.030458 lr = 0.0000463\n",
      "[4/25][7660/9765] Loss_D: 0.1166 Loss_G: 0.0464 Convergence: 0.1188 k= 0.030437 lr = 0.0000463\n",
      "[4/25][7670/9765] Loss_D: 0.1025 Loss_G: 0.0403 Convergence: 0.1048 k= 0.030461 lr = 0.0000463\n",
      "[4/25][7680/9765] Loss_D: 0.1080 Loss_G: 0.0440 Convergence: 0.1096 k= 0.030464 lr = 0.0000463\n",
      "[4/25][7690/9765] Loss_D: 0.1024 Loss_G: 0.0398 Convergence: 0.1053 k= 0.030462 lr = 0.0000463\n",
      "[4/25][7700/9765] Loss_D: 0.1101 Loss_G: 0.0432 Convergence: 0.1126 k= 0.030454 lr = 0.0000463\n",
      "[4/25][7710/9765] Loss_D: 0.1000 Loss_G: 0.0411 Convergence: 0.1018 k= 0.030464 lr = 0.0000463\n",
      "[4/25][7720/9765] Loss_D: 0.1160 Loss_G: 0.0407 Convergence: 0.1233 k= 0.030461 lr = 0.0000463\n",
      "[4/25][7730/9765] Loss_D: 0.0975 Loss_G: 0.0447 Convergence: 0.1040 k= 0.030436 lr = 0.0000463\n",
      "[4/25][7740/9765] Loss_D: 0.1131 Loss_G: 0.0483 Convergence: 0.1170 k= 0.030408 lr = 0.0000463\n",
      "[4/25][7750/9765] Loss_D: 0.1064 Loss_G: 0.0435 Convergence: 0.1081 k= 0.030419 lr = 0.0000463\n",
      "[4/25][7760/9765] Loss_D: 0.1109 Loss_G: 0.0394 Convergence: 0.1176 k= 0.030415 lr = 0.0000463\n",
      "[4/25][7770/9765] Loss_D: 0.1092 Loss_G: 0.0392 Convergence: 0.1154 k= 0.030429 lr = 0.0000463\n",
      "[4/25][7780/9765] Loss_D: 0.1074 Loss_G: 0.0528 Convergence: 0.1181 k= 0.030395 lr = 0.0000463\n",
      "[4/25][7790/9765] Loss_D: 0.1029 Loss_G: 0.0430 Convergence: 0.1055 k= 0.030366 lr = 0.0000463\n",
      "[4/25][7800/9765] Loss_D: 0.1048 Loss_G: 0.0390 Convergence: 0.1093 k= 0.030373 lr = 0.0000463\n",
      "[4/25][7810/9765] Loss_D: 0.1037 Loss_G: 0.0430 Convergence: 0.1059 k= 0.030375 lr = 0.0000463\n",
      "[4/25][7820/9765] Loss_D: 0.0938 Loss_G: 0.0395 Convergence: 0.0965 k= 0.030398 lr = 0.0000463\n",
      "[4/25][7830/9765] Loss_D: 0.1131 Loss_G: 0.0406 Convergence: 0.1195 k= 0.030414 lr = 0.0000463\n",
      "[4/25][7840/9765] Loss_D: 0.1151 Loss_G: 0.0448 Convergence: 0.1183 k= 0.030413 lr = 0.0000463\n",
      "[4/25][7850/9765] Loss_D: 0.1051 Loss_G: 0.0426 Convergence: 0.1064 k= 0.030411 lr = 0.0000463\n",
      "[4/25][7860/9765] Loss_D: 0.1031 Loss_G: 0.0395 Convergence: 0.1066 k= 0.030405 lr = 0.0000463\n",
      "[4/25][7870/9765] Loss_D: 0.0967 Loss_G: 0.0452 Convergence: 0.1041 k= 0.030380 lr = 0.0000463\n",
      "[4/25][7880/9765] Loss_D: 0.1069 Loss_G: 0.0394 Convergence: 0.1120 k= 0.030386 lr = 0.0000463\n",
      "[4/25][7890/9765] Loss_D: 0.1143 Loss_G: 0.0426 Convergence: 0.1191 k= 0.030387 lr = 0.0000463\n",
      "[4/25][7900/9765] Loss_D: 0.1140 Loss_G: 0.0388 Convergence: 0.1225 k= 0.030391 lr = 0.0000463\n",
      "[4/25][7910/9765] Loss_D: 0.1032 Loss_G: 0.0389 Convergence: 0.1072 k= 0.030407 lr = 0.0000463\n",
      "[4/25][7920/9765] Loss_D: 0.1075 Loss_G: 0.0478 Convergence: 0.1131 k= 0.030392 lr = 0.0000463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][7930/9765] Loss_D: 0.1033 Loss_G: 0.0442 Convergence: 0.1070 k= 0.030384 lr = 0.0000463\n",
      "[4/25][7940/9765] Loss_D: 0.1029 Loss_G: 0.0418 Convergence: 0.1043 k= 0.030385 lr = 0.0000463\n",
      "[4/25][7950/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0956 k= 0.030386 lr = 0.0000463\n",
      "[4/25][7960/9765] Loss_D: 0.1022 Loss_G: 0.0430 Convergence: 0.1051 k= 0.030358 lr = 0.0000463\n",
      "[4/25][7970/9765] Loss_D: 0.1056 Loss_G: 0.0386 Convergence: 0.1109 k= 0.030346 lr = 0.0000463\n",
      "[4/25][7980/9765] Loss_D: 0.0984 Loss_G: 0.0446 Convergence: 0.1043 k= 0.030353 lr = 0.0000463\n",
      "[4/25][7990/9765] Loss_D: 0.1072 Loss_G: 0.0439 Convergence: 0.1090 k= 0.030326 lr = 0.0000463\n",
      "[4/25][8000/9765] Loss_D: 0.1137 Loss_G: 0.0414 Convergence: 0.1194 k= 0.030313 lr = 0.0000463\n",
      "[4/25][8010/9765] Loss_D: 0.1153 Loss_G: 0.0359 Convergence: 0.1271 k= 0.030354 lr = 0.0000463\n",
      "[4/25][8020/9765] Loss_D: 0.1031 Loss_G: 0.0493 Convergence: 0.1120 k= 0.030342 lr = 0.0000463\n",
      "[4/25][8030/9765] Loss_D: 0.0967 Loss_G: 0.0431 Convergence: 0.1019 k= 0.030289 lr = 0.0000463\n",
      "[4/25][8040/9765] Loss_D: 0.1196 Loss_G: 0.0414 Convergence: 0.1278 k= 0.030309 lr = 0.0000463\n",
      "[4/25][8050/9765] Loss_D: 0.1163 Loss_G: 0.0430 Convergence: 0.1216 k= 0.030312 lr = 0.0000463\n",
      "[4/25][8060/9765] Loss_D: 0.1076 Loss_G: 0.0489 Convergence: 0.1142 k= 0.030326 lr = 0.0000463\n",
      "[4/25][8070/9765] Loss_D: 0.1069 Loss_G: 0.0400 Convergence: 0.1112 k= 0.030329 lr = 0.0000463\n",
      "[4/25][8080/9765] Loss_D: 0.1000 Loss_G: 0.0438 Convergence: 0.1045 k= 0.030322 lr = 0.0000463\n",
      "[4/25][8090/9765] Loss_D: 0.1146 Loss_G: 0.0440 Convergence: 0.1182 k= 0.030315 lr = 0.0000463\n",
      "[4/25][8100/9765] Loss_D: 0.0973 Loss_G: 0.0385 Convergence: 0.0995 k= 0.030304 lr = 0.0000463\n",
      "[4/25][8110/9765] Loss_D: 0.0966 Loss_G: 0.0374 Convergence: 0.0995 k= 0.030312 lr = 0.0000463\n",
      "[4/25][8120/9765] Loss_D: 0.1015 Loss_G: 0.0414 Convergence: 0.1031 k= 0.030317 lr = 0.0000463\n",
      "[4/25][8130/9765] Loss_D: 0.1011 Loss_G: 0.0415 Convergence: 0.1029 k= 0.030289 lr = 0.0000463\n",
      "[4/25][8140/9765] Loss_D: 0.0956 Loss_G: 0.0391 Convergence: 0.0972 k= 0.030281 lr = 0.0000463\n",
      "[4/25][8150/9765] Loss_D: 0.1081 Loss_G: 0.0418 Convergence: 0.1112 k= 0.030284 lr = 0.0000463\n",
      "[4/25][8160/9765] Loss_D: 0.0963 Loss_G: 0.0387 Convergence: 0.0978 k= 0.030282 lr = 0.0000463\n",
      "[4/25][8170/9765] Loss_D: 0.1102 Loss_G: 0.0438 Convergence: 0.1123 k= 0.030294 lr = 0.0000463\n",
      "[4/25][8180/9765] Loss_D: 0.1021 Loss_G: 0.0425 Convergence: 0.1046 k= 0.030282 lr = 0.0000463\n",
      "[4/25][8190/9765] Loss_D: 0.1061 Loss_G: 0.0396 Convergence: 0.1106 k= 0.030274 lr = 0.0000463\n",
      "[4/25][8200/9765] Loss_D: 0.1019 Loss_G: 0.0370 Convergence: 0.1073 k= 0.030297 lr = 0.0000463\n",
      "[4/25][8210/9765] Loss_D: 0.1054 Loss_G: 0.0408 Convergence: 0.1085 k= 0.030286 lr = 0.0000463\n",
      "[4/25][8220/9765] Loss_D: 0.1048 Loss_G: 0.0432 Convergence: 0.1068 k= 0.030266 lr = 0.0000463\n",
      "[4/25][8230/9765] Loss_D: 0.1039 Loss_G: 0.0439 Convergence: 0.1070 k= 0.030254 lr = 0.0000463\n",
      "[4/25][8240/9765] Loss_D: 0.1086 Loss_G: 0.0434 Convergence: 0.1102 k= 0.030253 lr = 0.0000463\n",
      "[4/25][8250/9765] Loss_D: 0.1032 Loss_G: 0.0385 Convergence: 0.1078 k= 0.030264 lr = 0.0000463\n",
      "[4/25][8260/9765] Loss_D: 0.1015 Loss_G: 0.0414 Convergence: 0.1030 k= 0.030255 lr = 0.0000463\n",
      "[4/25][8270/9765] Loss_D: 0.1086 Loss_G: 0.0416 Convergence: 0.1124 k= 0.030249 lr = 0.0000463\n",
      "[4/25][8280/9765] Loss_D: 0.1036 Loss_G: 0.0459 Convergence: 0.1089 k= 0.030224 lr = 0.0000463\n",
      "[4/25][8290/9765] Loss_D: 0.1098 Loss_G: 0.0428 Convergence: 0.1127 k= 0.030193 lr = 0.0000463\n",
      "[4/25][8300/9765] Loss_D: 0.1041 Loss_G: 0.0419 Convergence: 0.1055 k= 0.030211 lr = 0.0000463\n",
      "[4/25][8310/9765] Loss_D: 0.1080 Loss_G: 0.0427 Convergence: 0.1102 k= 0.030215 lr = 0.0000463\n",
      "[4/25][8320/9765] Loss_D: 0.1028 Loss_G: 0.0409 Convergence: 0.1047 k= 0.030221 lr = 0.0000463\n",
      "[4/25][8330/9765] Loss_D: 0.1070 Loss_G: 0.0444 Convergence: 0.1093 k= 0.030227 lr = 0.0000463\n",
      "[4/25][8340/9765] Loss_D: 0.1107 Loss_G: 0.0409 Convergence: 0.1157 k= 0.030208 lr = 0.0000463\n",
      "[4/25][8350/9765] Loss_D: 0.1002 Loss_G: 0.0387 Convergence: 0.1032 k= 0.030210 lr = 0.0000463\n",
      "[4/25][8360/9765] Loss_D: 0.1068 Loss_G: 0.0422 Convergence: 0.1089 k= 0.030234 lr = 0.0000463\n",
      "[4/25][8370/9765] Loss_D: 0.1059 Loss_G: 0.0490 Convergence: 0.1134 k= 0.030200 lr = 0.0000463\n",
      "[4/25][8380/9765] Loss_D: 0.1039 Loss_G: 0.0389 Convergence: 0.1083 k= 0.030199 lr = 0.0000463\n",
      "[4/25][8390/9765] Loss_D: 0.0991 Loss_G: 0.0396 Convergence: 0.1008 k= 0.030221 lr = 0.0000463\n",
      "[4/25][8400/9765] Loss_D: 0.1079 Loss_G: 0.0555 Convergence: 0.1212 k= 0.030187 lr = 0.0000463\n",
      "[4/25][8410/9765] Loss_D: 0.1019 Loss_G: 0.0436 Convergence: 0.1055 k= 0.030132 lr = 0.0000463\n",
      "[4/25][8420/9765] Loss_D: 0.1109 Loss_G: 0.0387 Convergence: 0.1181 k= 0.030153 lr = 0.0000463\n",
      "[4/25][8430/9765] Loss_D: 0.1013 Loss_G: 0.0432 Convergence: 0.1047 k= 0.030173 lr = 0.0000463\n",
      "[4/25][8440/9765] Loss_D: 0.1041 Loss_G: 0.0406 Convergence: 0.1068 k= 0.030153 lr = 0.0000463\n",
      "[4/25][8450/9765] Loss_D: 0.1148 Loss_G: 0.0410 Convergence: 0.1214 k= 0.030147 lr = 0.0000463\n",
      "[4/25][8460/9765] Loss_D: 0.0970 Loss_G: 0.0399 Convergence: 0.0989 k= 0.030164 lr = 0.0000463\n",
      "[4/25][8470/9765] Loss_D: 0.0985 Loss_G: 0.0493 Convergence: 0.1092 k= 0.030147 lr = 0.0000463\n",
      "[4/25][8480/9765] Loss_D: 0.1079 Loss_G: 0.0415 Convergence: 0.1113 k= 0.030151 lr = 0.0000463\n",
      "[4/25][8490/9765] Loss_D: 0.1108 Loss_G: 0.0412 Convergence: 0.1154 k= 0.030157 lr = 0.0000463\n",
      "[4/25][8500/9765] Loss_D: 0.1040 Loss_G: 0.0424 Convergence: 0.1055 k= 0.030144 lr = 0.0000463\n",
      "[4/25][8510/9765] Loss_D: 0.1023 Loss_G: 0.0440 Convergence: 0.1061 k= 0.030130 lr = 0.0000463\n",
      "[4/25][8520/9765] Loss_D: 0.0995 Loss_G: 0.0383 Convergence: 0.1026 k= 0.030140 lr = 0.0000463\n",
      "[4/25][8530/9765] Loss_D: 0.1009 Loss_G: 0.0405 Convergence: 0.1024 k= 0.030134 lr = 0.0000463\n",
      "[4/25][8540/9765] Loss_D: 0.0939 Loss_G: 0.0415 Convergence: 0.0985 k= 0.030134 lr = 0.0000463\n",
      "[4/25][8550/9765] Loss_D: 0.1055 Loss_G: 0.0413 Convergence: 0.1080 k= 0.030138 lr = 0.0000463\n",
      "[4/25][8560/9765] Loss_D: 0.1041 Loss_G: 0.0404 Convergence: 0.1070 k= 0.030146 lr = 0.0000463\n",
      "[4/25][8570/9765] Loss_D: 0.1062 Loss_G: 0.0437 Convergence: 0.1082 k= 0.030139 lr = 0.0000463\n",
      "[4/25][8580/9765] Loss_D: 0.0963 Loss_G: 0.0405 Convergence: 0.0990 k= 0.030149 lr = 0.0000463\n",
      "[4/25][8590/9765] Loss_D: 0.1062 Loss_G: 0.0411 Convergence: 0.1093 k= 0.030154 lr = 0.0000463\n",
      "[4/25][8600/9765] Loss_D: 0.1090 Loss_G: 0.0419 Convergence: 0.1124 k= 0.030165 lr = 0.0000463\n",
      "[4/25][8610/9765] Loss_D: 0.1006 Loss_G: 0.0436 Convergence: 0.1049 k= 0.030132 lr = 0.0000463\n",
      "[4/25][8620/9765] Loss_D: 0.0967 Loss_G: 0.0408 Convergence: 0.0996 k= 0.030110 lr = 0.0000463\n",
      "[4/25][8630/9765] Loss_D: 0.1129 Loss_G: 0.0393 Convergence: 0.1204 k= 0.030145 lr = 0.0000463\n",
      "[4/25][8640/9765] Loss_D: 0.0930 Loss_G: 0.0399 Convergence: 0.0964 k= 0.030166 lr = 0.0000463\n",
      "[4/25][8650/9765] Loss_D: 0.0945 Loss_G: 0.0417 Convergence: 0.0992 k= 0.030151 lr = 0.0000463\n",
      "[4/25][8660/9765] Loss_D: 0.1032 Loss_G: 0.0454 Convergence: 0.1081 k= 0.030129 lr = 0.0000463\n",
      "[4/25][8670/9765] Loss_D: 0.1069 Loss_G: 0.0395 Convergence: 0.1119 k= 0.030142 lr = 0.0000463\n",
      "[4/25][8680/9765] Loss_D: 0.0978 Loss_G: 0.0448 Convergence: 0.1043 k= 0.030108 lr = 0.0000463\n",
      "[4/25][8690/9765] Loss_D: 0.1055 Loss_G: 0.0408 Convergence: 0.1086 k= 0.030074 lr = 0.0000463\n",
      "[4/25][8700/9765] Loss_D: 0.1054 Loss_G: 0.0387 Convergence: 0.1104 k= 0.030074 lr = 0.0000463\n",
      "[4/25][8710/9765] Loss_D: 0.0932 Loss_G: 0.0424 Convergence: 0.0992 k= 0.030066 lr = 0.0000463\n",
      "[4/25][8720/9765] Loss_D: 0.1076 Loss_G: 0.0444 Convergence: 0.1097 k= 0.030039 lr = 0.0000463\n",
      "[4/25][8730/9765] Loss_D: 0.1075 Loss_G: 0.0419 Convergence: 0.1102 k= 0.030037 lr = 0.0000463\n",
      "[4/25][8740/9765] Loss_D: 0.1008 Loss_G: 0.0421 Convergence: 0.1034 k= 0.030036 lr = 0.0000463\n",
      "[4/25][8750/9765] Loss_D: 0.0984 Loss_G: 0.0417 Convergence: 0.1015 k= 0.030026 lr = 0.0000463\n",
      "[4/25][8760/9765] Loss_D: 0.1026 Loss_G: 0.0442 Convergence: 0.1065 k= 0.030027 lr = 0.0000463\n",
      "[4/25][8770/9765] Loss_D: 0.1026 Loss_G: 0.0365 Convergence: 0.1088 k= 0.030015 lr = 0.0000463\n",
      "[4/25][8780/9765] Loss_D: 0.0991 Loss_G: 0.0402 Convergence: 0.1004 k= 0.030028 lr = 0.0000463\n",
      "[4/25][8790/9765] Loss_D: 0.1017 Loss_G: 0.0423 Convergence: 0.1041 k= 0.030031 lr = 0.0000463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][8800/9765] Loss_D: 0.0997 Loss_G: 0.0433 Convergence: 0.1039 k= 0.030023 lr = 0.0000463\n",
      "[4/25][8810/9765] Loss_D: 0.0951 Loss_G: 0.0472 Convergence: 0.1050 k= 0.030009 lr = 0.0000463\n",
      "[4/25][8820/9765] Loss_D: 0.1018 Loss_G: 0.0471 Convergence: 0.1089 k= 0.029997 lr = 0.0000463\n",
      "[4/25][8830/9765] Loss_D: 0.1005 Loss_G: 0.0339 Convergence: 0.1083 k= 0.030002 lr = 0.0000463\n",
      "[4/25][8840/9765] Loss_D: 0.1032 Loss_G: 0.0416 Convergence: 0.1045 k= 0.030029 lr = 0.0000463\n",
      "[4/25][8850/9765] Loss_D: 0.1029 Loss_G: 0.0529 Convergence: 0.1155 k= 0.029939 lr = 0.0000463\n",
      "[4/25][8860/9765] Loss_D: 0.1016 Loss_G: 0.0432 Convergence: 0.1049 k= 0.029873 lr = 0.0000463\n",
      "[4/25][8870/9765] Loss_D: 0.0991 Loss_G: 0.0419 Convergence: 0.1021 k= 0.029862 lr = 0.0000463\n",
      "[4/25][8880/9765] Loss_D: 0.0979 Loss_G: 0.0435 Convergence: 0.1030 k= 0.029851 lr = 0.0000463\n",
      "[4/25][8890/9765] Loss_D: 0.0870 Loss_G: 0.0524 Convergence: 0.1054 k= 0.029793 lr = 0.0000463\n",
      "[4/25][8900/9765] Loss_D: 0.1008 Loss_G: 0.0426 Convergence: 0.1038 k= 0.029764 lr = 0.0000463\n",
      "[4/25][8910/9765] Loss_D: 0.1037 Loss_G: 0.0379 Convergence: 0.1090 k= 0.029776 lr = 0.0000463\n",
      "[4/25][8920/9765] Loss_D: 0.1003 Loss_G: 0.0440 Convergence: 0.1049 k= 0.029786 lr = 0.0000463\n",
      "[4/25][8930/9765] Loss_D: 0.1038 Loss_G: 0.0429 Convergence: 0.1060 k= 0.029761 lr = 0.0000463\n",
      "[4/25][8940/9765] Loss_D: 0.0933 Loss_G: 0.0527 Convergence: 0.1094 k= 0.029745 lr = 0.0000440\n",
      "[4/25][8950/9765] Loss_D: 0.1105 Loss_G: 0.0406 Convergence: 0.1156 k= 0.029767 lr = 0.0000440\n",
      "[4/25][8960/9765] Loss_D: 0.1069 Loss_G: 0.0491 Convergence: 0.1141 k= 0.029720 lr = 0.0000440\n",
      "[4/25][8970/9765] Loss_D: 0.0977 Loss_G: 0.0324 Convergence: 0.1057 k= 0.029745 lr = 0.0000440\n",
      "[4/25][8980/9765] Loss_D: 0.0978 Loss_G: 0.0451 Convergence: 0.1045 k= 0.029784 lr = 0.0000440\n",
      "[4/25][8990/9765] Loss_D: 0.0921 Loss_G: 0.0396 Convergence: 0.0956 k= 0.029800 lr = 0.0000440\n",
      "[4/25][9000/9765] Loss_D: 0.0933 Loss_G: 0.0437 Convergence: 0.1004 k= 0.029785 lr = 0.0000440\n",
      "[4/25][9010/9765] Loss_D: 0.1138 Loss_G: 0.0377 Convergence: 0.1231 k= 0.029799 lr = 0.0000440\n",
      "[4/25][9020/9765] Loss_D: 0.1049 Loss_G: 0.0474 Convergence: 0.1111 k= 0.029770 lr = 0.0000440\n",
      "[4/25][9030/9765] Loss_D: 0.1043 Loss_G: 0.0412 Convergence: 0.1066 k= 0.029757 lr = 0.0000440\n",
      "[4/25][9040/9765] Loss_D: 0.1021 Loss_G: 0.0406 Convergence: 0.1040 k= 0.029746 lr = 0.0000440\n",
      "[4/25][9050/9765] Loss_D: 0.0975 Loss_G: 0.0397 Convergence: 0.0988 k= 0.029749 lr = 0.0000440\n",
      "[4/25][9060/9765] Loss_D: 0.1046 Loss_G: 0.0399 Convergence: 0.1081 k= 0.029770 lr = 0.0000440\n",
      "[4/25][9070/9765] Loss_D: 0.1175 Loss_G: 0.0418 Convergence: 0.1245 k= 0.029757 lr = 0.0000440\n",
      "[4/25][9080/9765] Loss_D: 0.1100 Loss_G: 0.0438 Convergence: 0.1119 k= 0.029764 lr = 0.0000440\n",
      "[4/25][9090/9765] Loss_D: 0.1028 Loss_G: 0.0400 Convergence: 0.1056 k= 0.029752 lr = 0.0000440\n",
      "[4/25][9100/9765] Loss_D: 0.1077 Loss_G: 0.0403 Convergence: 0.1120 k= 0.029764 lr = 0.0000440\n",
      "[4/25][9110/9765] Loss_D: 0.0955 Loss_G: 0.0426 Convergence: 0.1006 k= 0.029778 lr = 0.0000440\n",
      "[4/25][9120/9765] Loss_D: 0.1084 Loss_G: 0.0459 Convergence: 0.1117 k= 0.029769 lr = 0.0000440\n",
      "[4/25][9130/9765] Loss_D: 0.0988 Loss_G: 0.0401 Convergence: 0.1001 k= 0.029785 lr = 0.0000440\n",
      "[4/25][9140/9765] Loss_D: 0.0925 Loss_G: 0.0415 Convergence: 0.0978 k= 0.029781 lr = 0.0000440\n",
      "[4/25][9150/9765] Loss_D: 0.1058 Loss_G: 0.0395 Convergence: 0.1103 k= 0.029784 lr = 0.0000440\n",
      "[4/25][9160/9765] Loss_D: 0.1020 Loss_G: 0.0406 Convergence: 0.1040 k= 0.029778 lr = 0.0000440\n",
      "[4/25][9170/9765] Loss_D: 0.1025 Loss_G: 0.0395 Convergence: 0.1055 k= 0.029788 lr = 0.0000440\n",
      "[4/25][9180/9765] Loss_D: 0.1083 Loss_G: 0.0420 Convergence: 0.1113 k= 0.029801 lr = 0.0000440\n",
      "[4/25][9190/9765] Loss_D: 0.1000 Loss_G: 0.0405 Convergence: 0.1012 k= 0.029808 lr = 0.0000440\n",
      "[4/25][9200/9765] Loss_D: 0.0945 Loss_G: 0.0377 Convergence: 0.0963 k= 0.029823 lr = 0.0000440\n",
      "[4/25][9210/9765] Loss_D: 0.1035 Loss_G: 0.0474 Convergence: 0.1102 k= 0.029821 lr = 0.0000440\n",
      "[4/25][9220/9765] Loss_D: 0.1092 Loss_G: 0.0413 Convergence: 0.1134 k= 0.029819 lr = 0.0000440\n",
      "[4/25][9230/9765] Loss_D: 0.1034 Loss_G: 0.0417 Convergence: 0.1047 k= 0.029828 lr = 0.0000440\n",
      "[4/25][9240/9765] Loss_D: 0.1179 Loss_G: 0.0408 Convergence: 0.1260 k= 0.029863 lr = 0.0000440\n",
      "[4/25][9250/9765] Loss_D: 0.1029 Loss_G: 0.0357 Convergence: 0.1099 k= 0.029897 lr = 0.0000440\n",
      "[4/25][9260/9765] Loss_D: 0.0972 Loss_G: 0.0459 Convergence: 0.1050 k= 0.029887 lr = 0.0000440\n",
      "[4/25][9270/9765] Loss_D: 0.0962 Loss_G: 0.0398 Convergence: 0.0982 k= 0.029880 lr = 0.0000440\n",
      "[4/25][9280/9765] Loss_D: 0.1043 Loss_G: 0.0431 Convergence: 0.1064 k= 0.029852 lr = 0.0000440\n",
      "[4/25][9290/9765] Loss_D: 0.1000 Loss_G: 0.0460 Convergence: 0.1068 k= 0.029851 lr = 0.0000440\n",
      "[4/25][9300/9765] Loss_D: 0.1040 Loss_G: 0.0496 Convergence: 0.1128 k= 0.029830 lr = 0.0000440\n",
      "[4/25][9310/9765] Loss_D: 0.1046 Loss_G: 0.0407 Convergence: 0.1075 k= 0.029816 lr = 0.0000440\n",
      "[4/25][9320/9765] Loss_D: 0.1116 Loss_G: 0.0427 Convergence: 0.1152 k= 0.029843 lr = 0.0000440\n",
      "[4/25][9330/9765] Loss_D: 0.0954 Loss_G: 0.0396 Convergence: 0.0976 k= 0.029819 lr = 0.0000440\n",
      "[4/25][9340/9765] Loss_D: 0.0999 Loss_G: 0.0447 Convergence: 0.1054 k= 0.029832 lr = 0.0000440\n",
      "[4/25][9350/9765] Loss_D: 0.1013 Loss_G: 0.0446 Convergence: 0.1062 k= 0.029795 lr = 0.0000440\n",
      "[4/25][9360/9765] Loss_D: 0.1042 Loss_G: 0.0415 Convergence: 0.1060 k= 0.029782 lr = 0.0000440\n",
      "[4/25][9370/9765] Loss_D: 0.1048 Loss_G: 0.0347 Convergence: 0.1134 k= 0.029815 lr = 0.0000440\n",
      "[4/25][9380/9765] Loss_D: 0.1019 Loss_G: 0.0445 Convergence: 0.1063 k= 0.029815 lr = 0.0000440\n",
      "[4/25][9390/9765] Loss_D: 0.1006 Loss_G: 0.0425 Convergence: 0.1036 k= 0.029771 lr = 0.0000440\n",
      "[4/25][9400/9765] Loss_D: 0.0889 Loss_G: 0.0343 Convergence: 0.0918 k= 0.029804 lr = 0.0000440\n",
      "[4/25][9410/9765] Loss_D: 0.1063 Loss_G: 0.0474 Convergence: 0.1120 k= 0.029793 lr = 0.0000440\n",
      "[4/25][9420/9765] Loss_D: 0.0983 Loss_G: 0.0387 Convergence: 0.1007 k= 0.029765 lr = 0.0000440\n",
      "[4/25][9430/9765] Loss_D: 0.1081 Loss_G: 0.0420 Convergence: 0.1109 k= 0.029767 lr = 0.0000440\n",
      "[4/25][9440/9765] Loss_D: 0.0976 Loss_G: 0.0386 Convergence: 0.0997 k= 0.029768 lr = 0.0000440\n",
      "[4/25][9450/9765] Loss_D: 0.1037 Loss_G: 0.0394 Convergence: 0.1074 k= 0.029763 lr = 0.0000440\n",
      "[4/25][9460/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1028 k= 0.029760 lr = 0.0000440\n",
      "[4/25][9470/9765] Loss_D: 0.1171 Loss_G: 0.0421 Convergence: 0.1234 k= 0.029770 lr = 0.0000440\n",
      "[4/25][9480/9765] Loss_D: 0.1013 Loss_G: 0.0438 Convergence: 0.1053 k= 0.029762 lr = 0.0000440\n",
      "[4/25][9490/9765] Loss_D: 0.1029 Loss_G: 0.0380 Convergence: 0.1076 k= 0.029768 lr = 0.0000440\n",
      "[4/25][9500/9765] Loss_D: 0.1039 Loss_G: 0.0442 Convergence: 0.1073 k= 0.029801 lr = 0.0000440\n",
      "[4/25][9510/9765] Loss_D: 0.0991 Loss_G: 0.0410 Convergence: 0.1012 k= 0.029809 lr = 0.0000440\n",
      "[4/25][9520/9765] Loss_D: 0.0960 Loss_G: 0.0462 Convergence: 0.1045 k= 0.029787 lr = 0.0000440\n",
      "[4/25][9530/9765] Loss_D: 0.1001 Loss_G: 0.0411 Convergence: 0.1020 k= 0.029780 lr = 0.0000440\n",
      "[4/25][9540/9765] Loss_D: 0.0981 Loss_G: 0.0386 Convergence: 0.1003 k= 0.029795 lr = 0.0000440\n",
      "[4/25][9550/9765] Loss_D: 0.1144 Loss_G: 0.0420 Convergence: 0.1198 k= 0.029786 lr = 0.0000440\n",
      "[4/25][9560/9765] Loss_D: 0.1002 Loss_G: 0.0413 Convergence: 0.1022 k= 0.029765 lr = 0.0000440\n",
      "[4/25][9570/9765] Loss_D: 0.1086 Loss_G: 0.0433 Convergence: 0.1103 k= 0.029752 lr = 0.0000440\n",
      "[4/25][9580/9765] Loss_D: 0.1001 Loss_G: 0.0405 Convergence: 0.1013 k= 0.029756 lr = 0.0000440\n",
      "[4/25][9590/9765] Loss_D: 0.0987 Loss_G: 0.0415 Convergence: 0.1013 k= 0.029762 lr = 0.0000440\n",
      "[4/25][9600/9765] Loss_D: 0.1012 Loss_G: 0.0482 Convergence: 0.1097 k= 0.029746 lr = 0.0000440\n",
      "[4/25][9610/9765] Loss_D: 0.1088 Loss_G: 0.0407 Convergence: 0.1133 k= 0.029733 lr = 0.0000440\n",
      "[4/25][9620/9765] Loss_D: 0.1070 Loss_G: 0.0399 Convergence: 0.1115 k= 0.029744 lr = 0.0000440\n",
      "[4/25][9630/9765] Loss_D: 0.1029 Loss_G: 0.0394 Convergence: 0.1063 k= 0.029760 lr = 0.0000440\n",
      "[4/25][9640/9765] Loss_D: 0.0996 Loss_G: 0.0492 Convergence: 0.1098 k= 0.029724 lr = 0.0000440\n",
      "[4/25][9650/9765] Loss_D: 0.1028 Loss_G: 0.0406 Convergence: 0.1050 k= 0.029711 lr = 0.0000440\n",
      "[4/25][9660/9765] Loss_D: 0.0946 Loss_G: 0.0411 Convergence: 0.0986 k= 0.029728 lr = 0.0000440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/25][9670/9765] Loss_D: 0.1098 Loss_G: 0.0388 Convergence: 0.1164 k= 0.029741 lr = 0.0000440\n",
      "[4/25][9680/9765] Loss_D: 0.1026 Loss_G: 0.0450 Convergence: 0.1072 k= 0.029753 lr = 0.0000440\n",
      "[4/25][9690/9765] Loss_D: 0.0998 Loss_G: 0.0414 Convergence: 0.1021 k= 0.029720 lr = 0.0000440\n",
      "[4/25][9700/9765] Loss_D: 0.0986 Loss_G: 0.0391 Convergence: 0.1007 k= 0.029712 lr = 0.0000440\n",
      "[4/25][9710/9765] Loss_D: 0.1025 Loss_G: 0.0446 Convergence: 0.1069 k= 0.029713 lr = 0.0000440\n",
      "[4/25][9720/9765] Loss_D: 0.1100 Loss_G: 0.0494 Convergence: 0.1163 k= 0.029664 lr = 0.0000440\n",
      "[4/25][9730/9765] Loss_D: 0.1067 Loss_G: 0.0403 Convergence: 0.1107 k= 0.029651 lr = 0.0000440\n",
      "[4/25][9740/9765] Loss_D: 0.1076 Loss_G: 0.0377 Convergence: 0.1144 k= 0.029683 lr = 0.0000440\n",
      "[4/25][9750/9765] Loss_D: 0.1106 Loss_G: 0.0465 Convergence: 0.1136 k= 0.029662 lr = 0.0000440\n",
      "[4/25][9760/9765] Loss_D: 0.0989 Loss_G: 0.0445 Convergence: 0.1046 k= 0.029615 lr = 0.0000440\n",
      "[5/25][0/9765] Loss_D: 0.1054 Loss_G: 0.0358 Convergence: 0.1132 k= 0.029641 lr = 0.0000440\n",
      "[5/25][10/9765] Loss_D: 0.1099 Loss_G: 0.0426 Convergence: 0.1130 k= 0.029665 lr = 0.0000440\n",
      "[5/25][20/9765] Loss_D: 0.1027 Loss_G: 0.0411 Convergence: 0.1044 k= 0.029654 lr = 0.0000440\n",
      "[5/25][30/9765] Loss_D: 0.0963 Loss_G: 0.0418 Convergence: 0.1003 k= 0.029660 lr = 0.0000440\n",
      "[5/25][40/9765] Loss_D: 0.0955 Loss_G: 0.0414 Convergence: 0.0994 k= 0.029668 lr = 0.0000440\n",
      "[5/25][50/9765] Loss_D: 0.1005 Loss_G: 0.0392 Convergence: 0.1031 k= 0.029681 lr = 0.0000440\n",
      "[5/25][60/9765] Loss_D: 0.0943 Loss_G: 0.0524 Convergence: 0.1097 k= 0.029660 lr = 0.0000440\n",
      "[5/25][70/9765] Loss_D: 0.1061 Loss_G: 0.0443 Convergence: 0.1087 k= 0.029662 lr = 0.0000440\n",
      "[5/25][80/9765] Loss_D: 0.1027 Loss_G: 0.0463 Convergence: 0.1087 k= 0.029641 lr = 0.0000440\n",
      "[5/25][90/9765] Loss_D: 0.1050 Loss_G: 0.0386 Convergence: 0.1098 k= 0.029667 lr = 0.0000440\n",
      "[5/25][100/9765] Loss_D: 0.0977 Loss_G: 0.0399 Convergence: 0.0992 k= 0.029681 lr = 0.0000440\n",
      "[5/25][110/9765] Loss_D: 0.1173 Loss_G: 0.0441 Convergence: 0.1220 k= 0.029667 lr = 0.0000440\n",
      "[5/25][120/9765] Loss_D: 0.1153 Loss_G: 0.0414 Convergence: 0.1218 k= 0.029671 lr = 0.0000440\n",
      "[5/25][130/9765] Loss_D: 0.1113 Loss_G: 0.0420 Convergence: 0.1155 k= 0.029673 lr = 0.0000440\n",
      "[5/25][140/9765] Loss_D: 0.1136 Loss_G: 0.0390 Convergence: 0.1216 k= 0.029653 lr = 0.0000440\n",
      "[5/25][150/9765] Loss_D: 0.1002 Loss_G: 0.0427 Convergence: 0.1035 k= 0.029637 lr = 0.0000440\n",
      "[5/25][160/9765] Loss_D: 0.1088 Loss_G: 0.0394 Convergence: 0.1144 k= 0.029613 lr = 0.0000440\n",
      "[5/25][170/9765] Loss_D: 0.1163 Loss_G: 0.0449 Convergence: 0.1195 k= 0.029635 lr = 0.0000440\n",
      "[5/25][180/9765] Loss_D: 0.1011 Loss_G: 0.0479 Convergence: 0.1093 k= 0.029614 lr = 0.0000440\n",
      "[5/25][190/9765] Loss_D: 0.1108 Loss_G: 0.0404 Convergence: 0.1163 k= 0.029598 lr = 0.0000440\n",
      "[5/25][200/9765] Loss_D: 0.1029 Loss_G: 0.0367 Convergence: 0.1087 k= 0.029627 lr = 0.0000440\n",
      "[5/25][210/9765] Loss_D: 0.1187 Loss_G: 0.0453 Convergence: 0.1227 k= 0.029656 lr = 0.0000440\n",
      "[5/25][220/9765] Loss_D: 0.1019 Loss_G: 0.0415 Convergence: 0.1034 k= 0.029624 lr = 0.0000440\n",
      "[5/25][230/9765] Loss_D: 0.1038 Loss_G: 0.0421 Convergence: 0.1052 k= 0.029624 lr = 0.0000440\n",
      "[5/25][240/9765] Loss_D: 0.1030 Loss_G: 0.0444 Convergence: 0.1070 k= 0.029619 lr = 0.0000440\n",
      "[5/25][250/9765] Loss_D: 0.1004 Loss_G: 0.0462 Convergence: 0.1072 k= 0.029590 lr = 0.0000440\n",
      "[5/25][260/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1048 k= 0.029574 lr = 0.0000440\n",
      "[5/25][270/9765] Loss_D: 0.1075 Loss_G: 0.0359 Convergence: 0.1162 k= 0.029606 lr = 0.0000440\n",
      "[5/25][280/9765] Loss_D: 0.1027 Loss_G: 0.0448 Convergence: 0.1070 k= 0.029614 lr = 0.0000440\n",
      "[5/25][290/9765] Loss_D: 0.0942 Loss_G: 0.0465 Convergence: 0.1038 k= 0.029586 lr = 0.0000440\n",
      "[5/25][300/9765] Loss_D: 0.0990 Loss_G: 0.0388 Convergence: 0.1014 k= 0.029587 lr = 0.0000440\n",
      "[5/25][310/9765] Loss_D: 0.1047 Loss_G: 0.0421 Convergence: 0.1062 k= 0.029587 lr = 0.0000440\n",
      "[5/25][320/9765] Loss_D: 0.1039 Loss_G: 0.0391 Convergence: 0.1080 k= 0.029600 lr = 0.0000440\n",
      "[5/25][330/9765] Loss_D: 0.1027 Loss_G: 0.0425 Convergence: 0.1049 k= 0.029606 lr = 0.0000440\n",
      "[5/25][340/9765] Loss_D: 0.0998 Loss_G: 0.0411 Convergence: 0.1017 k= 0.029594 lr = 0.0000440\n",
      "[5/25][350/9765] Loss_D: 0.0962 Loss_G: 0.0415 Convergence: 0.1000 k= 0.029583 lr = 0.0000440\n",
      "[5/25][360/9765] Loss_D: 0.1107 Loss_G: 0.0452 Convergence: 0.1123 k= 0.029603 lr = 0.0000440\n",
      "[5/25][370/9765] Loss_D: 0.0881 Loss_G: 0.0447 Convergence: 0.0984 k= 0.029589 lr = 0.0000440\n",
      "[5/25][380/9765] Loss_D: 0.1070 Loss_G: 0.0335 Convergence: 0.1178 k= 0.029628 lr = 0.0000440\n",
      "[5/25][390/9765] Loss_D: 0.0882 Loss_G: 0.0426 Convergence: 0.0963 k= 0.029656 lr = 0.0000440\n",
      "[5/25][400/9765] Loss_D: 0.1013 Loss_G: 0.0468 Convergence: 0.1084 k= 0.029604 lr = 0.0000440\n",
      "[5/25][410/9765] Loss_D: 0.1007 Loss_G: 0.0408 Convergence: 0.1020 k= 0.029609 lr = 0.0000440\n",
      "[5/25][420/9765] Loss_D: 0.1058 Loss_G: 0.0396 Convergence: 0.1102 k= 0.029612 lr = 0.0000440\n",
      "[5/25][430/9765] Loss_D: 0.0947 Loss_G: 0.0403 Convergence: 0.0978 k= 0.029609 lr = 0.0000440\n",
      "[5/25][440/9765] Loss_D: 0.0993 Loss_G: 0.0429 Convergence: 0.1033 k= 0.029606 lr = 0.0000440\n",
      "[5/25][450/9765] Loss_D: 0.1023 Loss_G: 0.0415 Convergence: 0.1036 k= 0.029599 lr = 0.0000440\n",
      "[5/25][460/9765] Loss_D: 0.1054 Loss_G: 0.0424 Convergence: 0.1069 k= 0.029592 lr = 0.0000440\n",
      "[5/25][470/9765] Loss_D: 0.0990 Loss_G: 0.0431 Convergence: 0.1033 k= 0.029581 lr = 0.0000440\n",
      "[5/25][480/9765] Loss_D: 0.0978 Loss_G: 0.0412 Convergence: 0.1007 k= 0.029593 lr = 0.0000440\n",
      "[5/25][490/9765] Loss_D: 0.1147 Loss_G: 0.0440 Convergence: 0.1183 k= 0.029613 lr = 0.0000440\n",
      "[5/25][500/9765] Loss_D: 0.0987 Loss_G: 0.0451 Convergence: 0.1051 k= 0.029579 lr = 0.0000440\n",
      "[5/25][510/9765] Loss_D: 0.1095 Loss_G: 0.0418 Convergence: 0.1132 k= 0.029565 lr = 0.0000440\n",
      "[5/25][520/9765] Loss_D: 0.1058 Loss_G: 0.0418 Convergence: 0.1079 k= 0.029564 lr = 0.0000440\n",
      "[5/25][530/9765] Loss_D: 0.1127 Loss_G: 0.0407 Convergence: 0.1188 k= 0.029558 lr = 0.0000440\n",
      "[5/25][540/9765] Loss_D: 0.1040 Loss_G: 0.0386 Convergence: 0.1086 k= 0.029548 lr = 0.0000440\n",
      "[5/25][550/9765] Loss_D: 0.1037 Loss_G: 0.0404 Convergence: 0.1064 k= 0.029544 lr = 0.0000440\n",
      "[5/25][560/9765] Loss_D: 0.0972 Loss_G: 0.0414 Convergence: 0.1005 k= 0.029540 lr = 0.0000440\n",
      "[5/25][570/9765] Loss_D: 0.1095 Loss_G: 0.0428 Convergence: 0.1121 k= 0.029540 lr = 0.0000440\n",
      "[5/25][580/9765] Loss_D: 0.1070 Loss_G: 0.0352 Convergence: 0.1162 k= 0.029548 lr = 0.0000440\n",
      "[5/25][590/9765] Loss_D: 0.1053 Loss_G: 0.0478 Convergence: 0.1117 k= 0.029567 lr = 0.0000440\n",
      "[5/25][600/9765] Loss_D: 0.1051 Loss_G: 0.0490 Convergence: 0.1129 k= 0.029448 lr = 0.0000440\n",
      "[5/25][610/9765] Loss_D: 0.1006 Loss_G: 0.0426 Convergence: 0.1037 k= 0.029413 lr = 0.0000440\n",
      "[5/25][620/9765] Loss_D: 0.1101 Loss_G: 0.0395 Convergence: 0.1165 k= 0.029424 lr = 0.0000440\n",
      "[5/25][630/9765] Loss_D: 0.1004 Loss_G: 0.0434 Convergence: 0.1044 k= 0.029422 lr = 0.0000440\n",
      "[5/25][640/9765] Loss_D: 0.0978 Loss_G: 0.0424 Convergence: 0.1018 k= 0.029408 lr = 0.0000440\n",
      "[5/25][650/9765] Loss_D: 0.1051 Loss_G: 0.0392 Convergence: 0.1096 k= 0.029416 lr = 0.0000440\n",
      "[5/25][660/9765] Loss_D: 0.0978 Loss_G: 0.0478 Convergence: 0.1074 k= 0.029393 lr = 0.0000440\n",
      "[5/25][670/9765] Loss_D: 0.1101 Loss_G: 0.0429 Convergence: 0.1129 k= 0.029365 lr = 0.0000440\n",
      "[5/25][680/9765] Loss_D: 0.0941 Loss_G: 0.0447 Convergence: 0.1020 k= 0.029359 lr = 0.0000440\n",
      "[5/25][690/9765] Loss_D: 0.1052 Loss_G: 0.0405 Convergence: 0.1086 k= 0.029364 lr = 0.0000440\n",
      "[5/25][700/9765] Loss_D: 0.1104 Loss_G: 0.0420 Convergence: 0.1143 k= 0.029364 lr = 0.0000440\n",
      "[5/25][710/9765] Loss_D: 0.1009 Loss_G: 0.0439 Convergence: 0.1052 k= 0.029335 lr = 0.0000440\n",
      "[5/25][720/9765] Loss_D: 0.0951 Loss_G: 0.0370 Convergence: 0.0978 k= 0.029340 lr = 0.0000440\n",
      "[5/25][730/9765] Loss_D: 0.1047 Loss_G: 0.0432 Convergence: 0.1068 k= 0.029345 lr = 0.0000440\n",
      "[5/25][740/9765] Loss_D: 0.1067 Loss_G: 0.0432 Convergence: 0.1080 k= 0.029335 lr = 0.0000440\n",
      "[5/25][750/9765] Loss_D: 0.1025 Loss_G: 0.0419 Convergence: 0.1042 k= 0.029325 lr = 0.0000440\n",
      "[5/25][760/9765] Loss_D: 0.1113 Loss_G: 0.0397 Convergence: 0.1178 k= 0.029346 lr = 0.0000440\n",
      "[5/25][770/9765] Loss_D: 0.0983 Loss_G: 0.0435 Convergence: 0.1031 k= 0.029336 lr = 0.0000440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][780/9765] Loss_D: 0.1125 Loss_G: 0.0418 Convergence: 0.1173 k= 0.029345 lr = 0.0000440\n",
      "[5/25][790/9765] Loss_D: 0.1101 Loss_G: 0.0401 Convergence: 0.1158 k= 0.029336 lr = 0.0000440\n",
      "[5/25][800/9765] Loss_D: 0.0982 Loss_G: 0.0454 Convergence: 0.1051 k= 0.029332 lr = 0.0000440\n",
      "[5/25][810/9765] Loss_D: 0.1079 Loss_G: 0.0433 Convergence: 0.1095 k= 0.029322 lr = 0.0000440\n",
      "[5/25][820/9765] Loss_D: 0.0919 Loss_G: 0.0435 Convergence: 0.0994 k= 0.029310 lr = 0.0000440\n",
      "[5/25][830/9765] Loss_D: 0.0935 Loss_G: 0.0393 Convergence: 0.0963 k= 0.029321 lr = 0.0000440\n",
      "[5/25][840/9765] Loss_D: 0.1067 Loss_G: 0.0459 Convergence: 0.1106 k= 0.029292 lr = 0.0000440\n",
      "[5/25][850/9765] Loss_D: 0.1105 Loss_G: 0.0378 Convergence: 0.1184 k= 0.029284 lr = 0.0000440\n",
      "[5/25][860/9765] Loss_D: 0.0946 Loss_G: 0.0435 Convergence: 0.1010 k= 0.029278 lr = 0.0000440\n",
      "[5/25][870/9765] Loss_D: 0.0955 Loss_G: 0.0396 Convergence: 0.0976 k= 0.029284 lr = 0.0000440\n",
      "[5/25][880/9765] Loss_D: 0.1057 Loss_G: 0.0451 Convergence: 0.1093 k= 0.029238 lr = 0.0000440\n",
      "[5/25][890/9765] Loss_D: 0.1051 Loss_G: 0.0349 Convergence: 0.1137 k= 0.029251 lr = 0.0000440\n",
      "[5/25][900/9765] Loss_D: 0.1113 Loss_G: 0.0402 Convergence: 0.1173 k= 0.029282 lr = 0.0000440\n",
      "[5/25][910/9765] Loss_D: 0.1061 Loss_G: 0.0454 Convergence: 0.1098 k= 0.029251 lr = 0.0000440\n",
      "[5/25][920/9765] Loss_D: 0.1007 Loss_G: 0.0398 Convergence: 0.1029 k= 0.029247 lr = 0.0000440\n",
      "[5/25][930/9765] Loss_D: 0.0981 Loss_G: 0.0362 Convergence: 0.1027 k= 0.029275 lr = 0.0000440\n",
      "[5/25][940/9765] Loss_D: 0.0894 Loss_G: 0.0447 Convergence: 0.0990 k= 0.029280 lr = 0.0000440\n",
      "[5/25][950/9765] Loss_D: 0.0955 Loss_G: 0.0401 Convergence: 0.0982 k= 0.029266 lr = 0.0000440\n",
      "[5/25][960/9765] Loss_D: 0.1096 Loss_G: 0.0392 Convergence: 0.1157 k= 0.029284 lr = 0.0000440\n",
      "[5/25][970/9765] Loss_D: 0.1073 Loss_G: 0.0448 Convergence: 0.1099 k= 0.029315 lr = 0.0000440\n",
      "[5/25][980/9765] Loss_D: 0.1052 Loss_G: 0.0446 Convergence: 0.1084 k= 0.029321 lr = 0.0000440\n",
      "[5/25][990/9765] Loss_D: 0.1016 Loss_G: 0.0420 Convergence: 0.1037 k= 0.029320 lr = 0.0000440\n",
      "[5/25][1000/9765] Loss_D: 0.1082 Loss_G: 0.0402 Convergence: 0.1129 k= 0.029312 lr = 0.0000440\n",
      "[5/25][1010/9765] Loss_D: 0.1002 Loss_G: 0.0377 Convergence: 0.1042 k= 0.029308 lr = 0.0000440\n",
      "[5/25][1020/9765] Loss_D: 0.1017 Loss_G: 0.0430 Convergence: 0.1047 k= 0.029323 lr = 0.0000440\n",
      "[5/25][1030/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1012 k= 0.029340 lr = 0.0000440\n",
      "[5/25][1040/9765] Loss_D: 0.1081 Loss_G: 0.0460 Convergence: 0.1116 k= 0.029328 lr = 0.0000440\n",
      "[5/25][1050/9765] Loss_D: 0.1028 Loss_G: 0.0406 Convergence: 0.1049 k= 0.029345 lr = 0.0000440\n",
      "[5/25][1060/9765] Loss_D: 0.1019 Loss_G: 0.0393 Convergence: 0.1049 k= 0.029350 lr = 0.0000440\n",
      "[5/25][1070/9765] Loss_D: 0.0882 Loss_G: 0.0395 Convergence: 0.0932 k= 0.029353 lr = 0.0000440\n",
      "[5/25][1080/9765] Loss_D: 0.1110 Loss_G: 0.0419 Convergence: 0.1151 k= 0.029373 lr = 0.0000440\n",
      "[5/25][1090/9765] Loss_D: 0.1031 Loss_G: 0.0373 Convergence: 0.1086 k= 0.029373 lr = 0.0000440\n",
      "[5/25][1100/9765] Loss_D: 0.1053 Loss_G: 0.0407 Convergence: 0.1083 k= 0.029401 lr = 0.0000440\n",
      "[5/25][1110/9765] Loss_D: 0.1042 Loss_G: 0.0475 Convergence: 0.1109 k= 0.029393 lr = 0.0000440\n",
      "[5/25][1120/9765] Loss_D: 0.1001 Loss_G: 0.0378 Convergence: 0.1038 k= 0.029376 lr = 0.0000440\n",
      "[5/25][1130/9765] Loss_D: 0.1053 Loss_G: 0.0416 Convergence: 0.1075 k= 0.029385 lr = 0.0000440\n",
      "[5/25][1140/9765] Loss_D: 0.1017 Loss_G: 0.0403 Convergence: 0.1037 k= 0.029369 lr = 0.0000440\n",
      "[5/25][1150/9765] Loss_D: 0.0931 Loss_G: 0.0406 Convergence: 0.0973 k= 0.029344 lr = 0.0000440\n",
      "[5/25][1160/9765] Loss_D: 0.1016 Loss_G: 0.0413 Convergence: 0.1030 k= 0.029377 lr = 0.0000440\n",
      "[5/25][1170/9765] Loss_D: 0.0956 Loss_G: 0.0416 Convergence: 0.0998 k= 0.029343 lr = 0.0000440\n",
      "[5/25][1180/9765] Loss_D: 0.0998 Loss_G: 0.0386 Convergence: 0.1026 k= 0.029345 lr = 0.0000440\n",
      "[5/25][1190/9765] Loss_D: 0.0977 Loss_G: 0.0433 Convergence: 0.1026 k= 0.029381 lr = 0.0000440\n",
      "[5/25][1200/9765] Loss_D: 0.0978 Loss_G: 0.0405 Convergence: 0.0999 k= 0.029364 lr = 0.0000440\n",
      "[5/25][1210/9765] Loss_D: 0.1075 Loss_G: 0.0401 Convergence: 0.1119 k= 0.029382 lr = 0.0000440\n",
      "[5/25][1220/9765] Loss_D: 0.1057 Loss_G: 0.0423 Convergence: 0.1074 k= 0.029343 lr = 0.0000440\n",
      "[5/25][1230/9765] Loss_D: 0.0966 Loss_G: 0.0379 Convergence: 0.0989 k= 0.029361 lr = 0.0000440\n",
      "[5/25][1240/9765] Loss_D: 0.1138 Loss_G: 0.0445 Convergence: 0.1165 k= 0.029346 lr = 0.0000440\n",
      "[5/25][1250/9765] Loss_D: 0.1053 Loss_G: 0.0444 Convergence: 0.1083 k= 0.029332 lr = 0.0000440\n",
      "[5/25][1260/9765] Loss_D: 0.1094 Loss_G: 0.0430 Convergence: 0.1118 k= 0.029325 lr = 0.0000440\n",
      "[5/25][1270/9765] Loss_D: 0.0953 Loss_G: 0.0422 Convergence: 0.1002 k= 0.029302 lr = 0.0000440\n",
      "[5/25][1280/9765] Loss_D: 0.1015 Loss_G: 0.0431 Convergence: 0.1047 k= 0.029317 lr = 0.0000440\n",
      "[5/25][1290/9765] Loss_D: 0.1017 Loss_G: 0.0409 Convergence: 0.1032 k= 0.029302 lr = 0.0000440\n",
      "[5/25][1300/9765] Loss_D: 0.1011 Loss_G: 0.0418 Convergence: 0.1033 k= 0.029292 lr = 0.0000440\n",
      "[5/25][1310/9765] Loss_D: 0.1051 Loss_G: 0.0397 Convergence: 0.1090 k= 0.029289 lr = 0.0000440\n",
      "[5/25][1320/9765] Loss_D: 0.1092 Loss_G: 0.0426 Convergence: 0.1119 k= 0.029288 lr = 0.0000440\n",
      "[5/25][1330/9765] Loss_D: 0.1103 Loss_G: 0.0480 Convergence: 0.1149 k= 0.029281 lr = 0.0000440\n",
      "[5/25][1340/9765] Loss_D: 0.1065 Loss_G: 0.0439 Convergence: 0.1086 k= 0.029283 lr = 0.0000440\n",
      "[5/25][1350/9765] Loss_D: 0.1002 Loss_G: 0.0416 Convergence: 0.1024 k= 0.029289 lr = 0.0000440\n",
      "[5/25][1360/9765] Loss_D: 0.1106 Loss_G: 0.0426 Convergence: 0.1140 k= 0.029279 lr = 0.0000440\n",
      "[5/25][1370/9765] Loss_D: 0.1058 Loss_G: 0.0461 Convergence: 0.1103 k= 0.029238 lr = 0.0000440\n",
      "[5/25][1380/9765] Loss_D: 0.1132 Loss_G: 0.0394 Convergence: 0.1208 k= 0.029222 lr = 0.0000440\n",
      "[5/25][1390/9765] Loss_D: 0.0976 Loss_G: 0.0425 Convergence: 0.1017 k= 0.029225 lr = 0.0000440\n",
      "[5/25][1400/9765] Loss_D: 0.0984 Loss_G: 0.0404 Convergence: 0.1001 k= 0.029216 lr = 0.0000440\n",
      "[5/25][1410/9765] Loss_D: 0.1089 Loss_G: 0.0486 Convergence: 0.1148 k= 0.029207 lr = 0.0000440\n",
      "[5/25][1420/9765] Loss_D: 0.1082 Loss_G: 0.0407 Convergence: 0.1124 k= 0.029214 lr = 0.0000440\n",
      "[5/25][1430/9765] Loss_D: 0.1020 Loss_G: 0.0419 Convergence: 0.1038 k= 0.029217 lr = 0.0000440\n",
      "[5/25][1440/9765] Loss_D: 0.0953 Loss_G: 0.0407 Convergence: 0.0985 k= 0.029228 lr = 0.0000440\n",
      "[5/25][1450/9765] Loss_D: 0.1094 Loss_G: 0.0434 Convergence: 0.1114 k= 0.029234 lr = 0.0000440\n",
      "[5/25][1460/9765] Loss_D: 0.1033 Loss_G: 0.0426 Convergence: 0.1054 k= 0.029210 lr = 0.0000440\n",
      "[5/25][1470/9765] Loss_D: 0.1050 Loss_G: 0.0418 Convergence: 0.1069 k= 0.029197 lr = 0.0000440\n",
      "[5/25][1480/9765] Loss_D: 0.1021 Loss_G: 0.0402 Convergence: 0.1046 k= 0.029208 lr = 0.0000440\n",
      "[5/25][1490/9765] Loss_D: 0.1017 Loss_G: 0.0412 Convergence: 0.1029 k= 0.029197 lr = 0.0000440\n",
      "[5/25][1500/9765] Loss_D: 0.0959 Loss_G: 0.0417 Convergence: 0.0999 k= 0.029191 lr = 0.0000440\n",
      "[5/25][1510/9765] Loss_D: 0.1081 Loss_G: 0.0466 Convergence: 0.1122 k= 0.029208 lr = 0.0000440\n",
      "[5/25][1520/9765] Loss_D: 0.1028 Loss_G: 0.0391 Convergence: 0.1066 k= 0.029162 lr = 0.0000440\n",
      "[5/25][1530/9765] Loss_D: 0.0972 Loss_G: 0.0423 Convergence: 0.1013 k= 0.029155 lr = 0.0000440\n",
      "[5/25][1540/9765] Loss_D: 0.1018 Loss_G: 0.0451 Convergence: 0.1070 k= 0.029153 lr = 0.0000440\n",
      "[5/25][1550/9765] Loss_D: 0.1083 Loss_G: 0.0383 Convergence: 0.1149 k= 0.029138 lr = 0.0000440\n",
      "[5/25][1560/9765] Loss_D: 0.1064 Loss_G: 0.0420 Convergence: 0.1086 k= 0.029140 lr = 0.0000440\n",
      "[5/25][1570/9765] Loss_D: 0.1082 Loss_G: 0.0440 Convergence: 0.1097 k= 0.029128 lr = 0.0000440\n",
      "[5/25][1580/9765] Loss_D: 0.1168 Loss_G: 0.0407 Convergence: 0.1247 k= 0.029136 lr = 0.0000440\n",
      "[5/25][1590/9765] Loss_D: 0.1056 Loss_G: 0.0428 Convergence: 0.1069 k= 0.029129 lr = 0.0000440\n",
      "[5/25][1600/9765] Loss_D: 0.1044 Loss_G: 0.0443 Convergence: 0.1076 k= 0.029131 lr = 0.0000440\n",
      "[5/25][1610/9765] Loss_D: 0.1022 Loss_G: 0.0433 Convergence: 0.1054 k= 0.029153 lr = 0.0000440\n",
      "[5/25][1620/9765] Loss_D: 0.1121 Loss_G: 0.0397 Convergence: 0.1188 k= 0.029150 lr = 0.0000440\n",
      "[5/25][1630/9765] Loss_D: 0.1026 Loss_G: 0.0434 Convergence: 0.1057 k= 0.029128 lr = 0.0000440\n",
      "[5/25][1640/9765] Loss_D: 0.1071 Loss_G: 0.0415 Convergence: 0.1101 k= 0.029097 lr = 0.0000440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][1650/9765] Loss_D: 0.1013 Loss_G: 0.0397 Convergence: 0.1037 k= 0.029114 lr = 0.0000440\n",
      "[5/25][1660/9765] Loss_D: 0.1009 Loss_G: 0.0381 Convergence: 0.1048 k= 0.029127 lr = 0.0000440\n",
      "[5/25][1670/9765] Loss_D: 0.0993 Loss_G: 0.0424 Convergence: 0.1027 k= 0.029116 lr = 0.0000440\n",
      "[5/25][1680/9765] Loss_D: 0.1067 Loss_G: 0.0414 Convergence: 0.1097 k= 0.029102 lr = 0.0000440\n",
      "[5/25][1690/9765] Loss_D: 0.1022 Loss_G: 0.0422 Convergence: 0.1043 k= 0.029091 lr = 0.0000440\n",
      "[5/25][1700/9765] Loss_D: 0.0973 Loss_G: 0.0461 Convergence: 0.1053 k= 0.029074 lr = 0.0000440\n",
      "[5/25][1710/9765] Loss_D: 0.1048 Loss_G: 0.0451 Convergence: 0.1088 k= 0.029007 lr = 0.0000440\n",
      "[5/25][1720/9765] Loss_D: 0.1084 Loss_G: 0.0382 Convergence: 0.1151 k= 0.029026 lr = 0.0000440\n",
      "[5/25][1730/9765] Loss_D: 0.0945 Loss_G: 0.0425 Convergence: 0.0999 k= 0.029031 lr = 0.0000440\n",
      "[5/25][1740/9765] Loss_D: 0.1122 Loss_G: 0.0434 Convergence: 0.1155 k= 0.029007 lr = 0.0000440\n",
      "[5/25][1750/9765] Loss_D: 0.1064 Loss_G: 0.0384 Convergence: 0.1121 k= 0.029032 lr = 0.0000440\n",
      "[5/25][1760/9765] Loss_D: 0.1036 Loss_G: 0.0378 Convergence: 0.1089 k= 0.029044 lr = 0.0000440\n",
      "[5/25][1770/9765] Loss_D: 0.1091 Loss_G: 0.0426 Convergence: 0.1117 k= 0.029071 lr = 0.0000440\n",
      "[5/25][1780/9765] Loss_D: 0.0937 Loss_G: 0.0378 Convergence: 0.0949 k= 0.029044 lr = 0.0000440\n",
      "[5/25][1790/9765] Loss_D: 0.1011 Loss_G: 0.0393 Convergence: 0.1039 k= 0.029073 lr = 0.0000440\n",
      "[5/25][1800/9765] Loss_D: 0.1011 Loss_G: 0.0431 Convergence: 0.1044 k= 0.029071 lr = 0.0000440\n",
      "[5/25][1810/9765] Loss_D: 0.1011 Loss_G: 0.0396 Convergence: 0.1036 k= 0.029055 lr = 0.0000440\n",
      "[5/25][1820/9765] Loss_D: 0.0945 Loss_G: 0.0410 Convergence: 0.0984 k= 0.029075 lr = 0.0000440\n",
      "[5/25][1830/9765] Loss_D: 0.1064 Loss_G: 0.0420 Convergence: 0.1087 k= 0.029054 lr = 0.0000440\n",
      "[5/25][1840/9765] Loss_D: 0.1075 Loss_G: 0.0403 Convergence: 0.1120 k= 0.029037 lr = 0.0000440\n",
      "[5/25][1850/9765] Loss_D: 0.1137 Loss_G: 0.0387 Convergence: 0.1221 k= 0.029053 lr = 0.0000440\n",
      "[5/25][1860/9765] Loss_D: 0.1141 Loss_G: 0.0449 Convergence: 0.1165 k= 0.029051 lr = 0.0000440\n",
      "[5/25][1870/9765] Loss_D: 0.0999 Loss_G: 0.0472 Convergence: 0.1079 k= 0.029028 lr = 0.0000440\n",
      "[5/25][1880/9765] Loss_D: 0.1041 Loss_G: 0.0413 Convergence: 0.1060 k= 0.029020 lr = 0.0000440\n",
      "[5/25][1890/9765] Loss_D: 0.1086 Loss_G: 0.0409 Convergence: 0.1128 k= 0.029014 lr = 0.0000440\n",
      "[5/25][1900/9765] Loss_D: 0.0942 Loss_G: 0.0393 Convergence: 0.0966 k= 0.028991 lr = 0.0000440\n",
      "[5/25][1910/9765] Loss_D: 0.1034 Loss_G: 0.0389 Convergence: 0.1075 k= 0.029002 lr = 0.0000440\n",
      "[5/25][1920/9765] Loss_D: 0.1088 Loss_G: 0.0401 Convergence: 0.1140 k= 0.029023 lr = 0.0000440\n",
      "[5/25][1930/9765] Loss_D: 0.1103 Loss_G: 0.0435 Convergence: 0.1128 k= 0.029001 lr = 0.0000440\n",
      "[5/25][1940/9765] Loss_D: 0.1037 Loss_G: 0.0416 Convergence: 0.1054 k= 0.028998 lr = 0.0000440\n",
      "[5/25][1950/9765] Loss_D: 0.0967 Loss_G: 0.0402 Convergence: 0.0989 k= 0.029015 lr = 0.0000440\n",
      "[5/25][1960/9765] Loss_D: 0.1069 Loss_G: 0.0380 Convergence: 0.1133 k= 0.029025 lr = 0.0000440\n",
      "[5/25][1970/9765] Loss_D: 0.0969 Loss_G: 0.0375 Convergence: 0.0995 k= 0.029033 lr = 0.0000440\n",
      "[5/25][1980/9765] Loss_D: 0.1016 Loss_G: 0.0396 Convergence: 0.1043 k= 0.029051 lr = 0.0000440\n",
      "[5/25][1990/9765] Loss_D: 0.1028 Loss_G: 0.0439 Convergence: 0.1064 k= 0.029012 lr = 0.0000440\n",
      "[5/25][2000/9765] Loss_D: 0.1118 Loss_G: 0.0362 Convergence: 0.1219 k= 0.029025 lr = 0.0000440\n",
      "[5/25][2010/9765] Loss_D: 0.1054 Loss_G: 0.0455 Convergence: 0.1096 k= 0.029036 lr = 0.0000440\n",
      "[5/25][2020/9765] Loss_D: 0.1001 Loss_G: 0.0407 Convergence: 0.1015 k= 0.029003 lr = 0.0000440\n",
      "[5/25][2030/9765] Loss_D: 0.1038 Loss_G: 0.0431 Convergence: 0.1061 k= 0.028972 lr = 0.0000440\n",
      "[5/25][2040/9765] Loss_D: 0.1066 Loss_G: 0.0419 Convergence: 0.1090 k= 0.028980 lr = 0.0000440\n",
      "[5/25][2050/9765] Loss_D: 0.0908 Loss_G: 0.0381 Convergence: 0.0933 k= 0.028989 lr = 0.0000440\n",
      "[5/25][2060/9765] Loss_D: 0.1098 Loss_G: 0.0457 Convergence: 0.1124 k= 0.028984 lr = 0.0000440\n",
      "[5/25][2070/9765] Loss_D: 0.1081 Loss_G: 0.0358 Convergence: 0.1171 k= 0.028967 lr = 0.0000440\n",
      "[5/25][2080/9765] Loss_D: 0.0954 Loss_G: 0.0395 Convergence: 0.0975 k= 0.028981 lr = 0.0000440\n",
      "[5/25][2090/9765] Loss_D: 0.0970 Loss_G: 0.0371 Convergence: 0.1006 k= 0.028992 lr = 0.0000440\n",
      "[5/25][2100/9765] Loss_D: 0.1065 Loss_G: 0.0441 Convergence: 0.1088 k= 0.028967 lr = 0.0000440\n",
      "[5/25][2110/9765] Loss_D: 0.1066 Loss_G: 0.0451 Convergence: 0.1098 k= 0.028957 lr = 0.0000440\n",
      "[5/25][2120/9765] Loss_D: 0.1094 Loss_G: 0.0423 Convergence: 0.1126 k= 0.028948 lr = 0.0000440\n",
      "[5/25][2130/9765] Loss_D: 0.0921 Loss_G: 0.0376 Convergence: 0.0935 k= 0.028954 lr = 0.0000440\n",
      "[5/25][2140/9765] Loss_D: 0.1005 Loss_G: 0.0405 Convergence: 0.1019 k= 0.028971 lr = 0.0000440\n",
      "[5/25][2150/9765] Loss_D: 0.1057 Loss_G: 0.0404 Convergence: 0.1093 k= 0.028979 lr = 0.0000440\n",
      "[5/25][2160/9765] Loss_D: 0.1047 Loss_G: 0.0396 Convergence: 0.1085 k= 0.028988 lr = 0.0000440\n",
      "[5/25][2170/9765] Loss_D: 0.1063 Loss_G: 0.0381 Convergence: 0.1124 k= 0.028995 lr = 0.0000440\n",
      "[5/25][2180/9765] Loss_D: 0.1098 Loss_G: 0.0392 Convergence: 0.1162 k= 0.028994 lr = 0.0000418\n",
      "[5/25][2190/9765] Loss_D: 0.0997 Loss_G: 0.0412 Convergence: 0.1017 k= 0.029011 lr = 0.0000418\n",
      "[5/25][2200/9765] Loss_D: 0.1040 Loss_G: 0.0397 Convergence: 0.1075 k= 0.028987 lr = 0.0000418\n",
      "[5/25][2210/9765] Loss_D: 0.1038 Loss_G: 0.0445 Convergence: 0.1075 k= 0.028976 lr = 0.0000418\n",
      "[5/25][2220/9765] Loss_D: 0.1036 Loss_G: 0.0403 Convergence: 0.1064 k= 0.028985 lr = 0.0000418\n",
      "[5/25][2230/9765] Loss_D: 0.1038 Loss_G: 0.0404 Convergence: 0.1066 k= 0.029002 lr = 0.0000418\n",
      "[5/25][2240/9765] Loss_D: 0.1026 Loss_G: 0.0434 Convergence: 0.1058 k= 0.028986 lr = 0.0000418\n",
      "[5/25][2250/9765] Loss_D: 0.1067 Loss_G: 0.0417 Convergence: 0.1095 k= 0.028950 lr = 0.0000418\n",
      "[5/25][2260/9765] Loss_D: 0.1101 Loss_G: 0.0417 Convergence: 0.1139 k= 0.028975 lr = 0.0000418\n",
      "[5/25][2270/9765] Loss_D: 0.1016 Loss_G: 0.0385 Convergence: 0.1054 k= 0.029008 lr = 0.0000418\n",
      "[5/25][2280/9765] Loss_D: 0.1023 Loss_G: 0.0394 Convergence: 0.1056 k= 0.029007 lr = 0.0000418\n",
      "[5/25][2290/9765] Loss_D: 0.1015 Loss_G: 0.0393 Convergence: 0.1044 k= 0.029004 lr = 0.0000418\n",
      "[5/25][2300/9765] Loss_D: 0.1026 Loss_G: 0.0427 Convergence: 0.1049 k= 0.029022 lr = 0.0000418\n",
      "[5/25][2310/9765] Loss_D: 0.0972 Loss_G: 0.0420 Convergence: 0.1010 k= 0.029013 lr = 0.0000418\n",
      "[5/25][2320/9765] Loss_D: 0.0991 Loss_G: 0.0443 Convergence: 0.1046 k= 0.029006 lr = 0.0000418\n",
      "[5/25][2330/9765] Loss_D: 0.0926 Loss_G: 0.0410 Convergence: 0.0972 k= 0.028988 lr = 0.0000418\n",
      "[5/25][2340/9765] Loss_D: 0.0999 Loss_G: 0.0392 Convergence: 0.1023 k= 0.028993 lr = 0.0000418\n",
      "[5/25][2350/9765] Loss_D: 0.1075 Loss_G: 0.0445 Convergence: 0.1097 k= 0.028991 lr = 0.0000418\n",
      "[5/25][2360/9765] Loss_D: 0.1091 Loss_G: 0.0454 Convergence: 0.1116 k= 0.028968 lr = 0.0000418\n",
      "[5/25][2370/9765] Loss_D: 0.1005 Loss_G: 0.0389 Convergence: 0.1034 k= 0.028962 lr = 0.0000418\n",
      "[5/25][2380/9765] Loss_D: 0.0928 Loss_G: 0.0407 Convergence: 0.0971 k= 0.028963 lr = 0.0000418\n",
      "[5/25][2390/9765] Loss_D: 0.0972 Loss_G: 0.0471 Convergence: 0.1062 k= 0.028954 lr = 0.0000418\n",
      "[5/25][2400/9765] Loss_D: 0.0969 Loss_G: 0.0379 Convergence: 0.0995 k= 0.028955 lr = 0.0000418\n",
      "[5/25][2410/9765] Loss_D: 0.1038 Loss_G: 0.0395 Convergence: 0.1075 k= 0.028964 lr = 0.0000418\n",
      "[5/25][2420/9765] Loss_D: 0.1048 Loss_G: 0.0453 Convergence: 0.1089 k= 0.028956 lr = 0.0000418\n",
      "[5/25][2430/9765] Loss_D: 0.1057 Loss_G: 0.0436 Convergence: 0.1078 k= 0.028938 lr = 0.0000418\n",
      "[5/25][2440/9765] Loss_D: 0.0987 Loss_G: 0.0411 Convergence: 0.1010 k= 0.028941 lr = 0.0000418\n",
      "[5/25][2450/9765] Loss_D: 0.1100 Loss_G: 0.0416 Convergence: 0.1140 k= 0.028947 lr = 0.0000418\n",
      "[5/25][2460/9765] Loss_D: 0.0982 Loss_G: 0.0425 Convergence: 0.1022 k= 0.028942 lr = 0.0000418\n",
      "[5/25][2470/9765] Loss_D: 0.1020 Loss_G: 0.0421 Convergence: 0.1040 k= 0.028952 lr = 0.0000418\n",
      "[5/25][2480/9765] Loss_D: 0.0970 Loss_G: 0.0415 Convergence: 0.1004 k= 0.028951 lr = 0.0000418\n",
      "[5/25][2490/9765] Loss_D: 0.1029 Loss_G: 0.0385 Convergence: 0.1071 k= 0.028963 lr = 0.0000418\n",
      "[5/25][2500/9765] Loss_D: 0.1039 Loss_G: 0.0428 Convergence: 0.1059 k= 0.028969 lr = 0.0000418\n",
      "[5/25][2510/9765] Loss_D: 0.1034 Loss_G: 0.0516 Convergence: 0.1144 k= 0.028977 lr = 0.0000418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][2520/9765] Loss_D: 0.0981 Loss_G: 0.0436 Convergence: 0.1032 k= 0.028941 lr = 0.0000418\n",
      "[5/25][2530/9765] Loss_D: 0.1035 Loss_G: 0.0384 Convergence: 0.1081 k= 0.028940 lr = 0.0000418\n",
      "[5/25][2540/9765] Loss_D: 0.1056 Loss_G: 0.0498 Convergence: 0.1140 k= 0.028912 lr = 0.0000418\n",
      "[5/25][2550/9765] Loss_D: 0.1016 Loss_G: 0.0377 Convergence: 0.1061 k= 0.028908 lr = 0.0000418\n",
      "[5/25][2560/9765] Loss_D: 0.1073 Loss_G: 0.0390 Convergence: 0.1128 k= 0.028912 lr = 0.0000418\n",
      "[5/25][2570/9765] Loss_D: 0.0961 Loss_G: 0.0397 Convergence: 0.0980 k= 0.028905 lr = 0.0000418\n",
      "[5/25][2580/9765] Loss_D: 0.0989 Loss_G: 0.0446 Convergence: 0.1047 k= 0.028908 lr = 0.0000418\n",
      "[5/25][2590/9765] Loss_D: 0.1032 Loss_G: 0.0411 Convergence: 0.1050 k= 0.028900 lr = 0.0000418\n",
      "[5/25][2600/9765] Loss_D: 0.1043 Loss_G: 0.0437 Convergence: 0.1071 k= 0.028894 lr = 0.0000418\n",
      "[5/25][2610/9765] Loss_D: 0.0977 Loss_G: 0.0493 Convergence: 0.1087 k= 0.028856 lr = 0.0000418\n",
      "[5/25][2620/9765] Loss_D: 0.1063 Loss_G: 0.0401 Convergence: 0.1103 k= 0.028855 lr = 0.0000418\n",
      "[5/25][2630/9765] Loss_D: 0.0969 Loss_G: 0.0411 Convergence: 0.0999 k= 0.028863 lr = 0.0000418\n",
      "[5/25][2640/9765] Loss_D: 0.1035 Loss_G: 0.0413 Convergence: 0.1051 k= 0.028874 lr = 0.0000418\n",
      "[5/25][2650/9765] Loss_D: 0.0980 Loss_G: 0.0378 Convergence: 0.1008 k= 0.028872 lr = 0.0000418\n",
      "[5/25][2660/9765] Loss_D: 0.1032 Loss_G: 0.0444 Convergence: 0.1071 k= 0.028874 lr = 0.0000418\n",
      "[5/25][2670/9765] Loss_D: 0.0981 Loss_G: 0.0384 Convergence: 0.1004 k= 0.028890 lr = 0.0000418\n",
      "[5/25][2680/9765] Loss_D: 0.0950 Loss_G: 0.0440 Convergence: 0.1017 k= 0.028873 lr = 0.0000418\n",
      "[5/25][2690/9765] Loss_D: 0.0999 Loss_G: 0.0394 Convergence: 0.1019 k= 0.028870 lr = 0.0000418\n",
      "[5/25][2700/9765] Loss_D: 0.1022 Loss_G: 0.0395 Convergence: 0.1052 k= 0.028889 lr = 0.0000418\n",
      "[5/25][2710/9765] Loss_D: 0.1003 Loss_G: 0.0423 Convergence: 0.1031 k= 0.028880 lr = 0.0000418\n",
      "[5/25][2720/9765] Loss_D: 0.1019 Loss_G: 0.0462 Convergence: 0.1081 k= 0.028882 lr = 0.0000418\n",
      "[5/25][2730/9765] Loss_D: 0.0993 Loss_G: 0.0398 Convergence: 0.1009 k= 0.028867 lr = 0.0000418\n",
      "[5/25][2740/9765] Loss_D: 0.1017 Loss_G: 0.0406 Convergence: 0.1035 k= 0.028894 lr = 0.0000418\n",
      "[5/25][2750/9765] Loss_D: 0.1046 Loss_G: 0.0403 Convergence: 0.1075 k= 0.028886 lr = 0.0000418\n",
      "[5/25][2760/9765] Loss_D: 0.1076 Loss_G: 0.0416 Convergence: 0.1106 k= 0.028888 lr = 0.0000418\n",
      "[5/25][2770/9765] Loss_D: 0.1045 Loss_G: 0.0385 Convergence: 0.1093 k= 0.028896 lr = 0.0000418\n",
      "[5/25][2780/9765] Loss_D: 0.1067 Loss_G: 0.0415 Convergence: 0.1097 k= 0.028897 lr = 0.0000418\n",
      "[5/25][2790/9765] Loss_D: 0.0982 Loss_G: 0.0453 Convergence: 0.1050 k= 0.028859 lr = 0.0000418\n",
      "[5/25][2800/9765] Loss_D: 0.1132 Loss_G: 0.0410 Convergence: 0.1191 k= 0.028860 lr = 0.0000418\n",
      "[5/25][2810/9765] Loss_D: 0.1092 Loss_G: 0.0443 Convergence: 0.1106 k= 0.028863 lr = 0.0000418\n",
      "[5/25][2820/9765] Loss_D: 0.0965 Loss_G: 0.0457 Convergence: 0.1043 k= 0.028821 lr = 0.0000418\n",
      "[5/25][2830/9765] Loss_D: 0.1023 Loss_G: 0.0409 Convergence: 0.1040 k= 0.028811 lr = 0.0000418\n",
      "[5/25][2840/9765] Loss_D: 0.1131 Loss_G: 0.0445 Convergence: 0.1156 k= 0.028823 lr = 0.0000418\n",
      "[5/25][2850/9765] Loss_D: 0.1087 Loss_G: 0.0514 Convergence: 0.1175 k= 0.028775 lr = 0.0000418\n",
      "[5/25][2860/9765] Loss_D: 0.1044 Loss_G: 0.0526 Convergence: 0.1160 k= 0.028721 lr = 0.0000418\n",
      "[5/25][2870/9765] Loss_D: 0.0979 Loss_G: 0.0390 Convergence: 0.0996 k= 0.028713 lr = 0.0000418\n",
      "[5/25][2880/9765] Loss_D: 0.0974 Loss_G: 0.0399 Convergence: 0.0990 k= 0.028732 lr = 0.0000418\n",
      "[5/25][2890/9765] Loss_D: 0.1035 Loss_G: 0.0444 Convergence: 0.1072 k= 0.028709 lr = 0.0000418\n",
      "[5/25][2900/9765] Loss_D: 0.1019 Loss_G: 0.0410 Convergence: 0.1033 k= 0.028696 lr = 0.0000418\n",
      "[5/25][2910/9765] Loss_D: 0.1095 Loss_G: 0.0410 Convergence: 0.1137 k= 0.028714 lr = 0.0000418\n",
      "[5/25][2920/9765] Loss_D: 0.1043 Loss_G: 0.0389 Convergence: 0.1086 k= 0.028742 lr = 0.0000418\n",
      "[5/25][2930/9765] Loss_D: 0.1021 Loss_G: 0.0457 Convergence: 0.1078 k= 0.028727 lr = 0.0000418\n",
      "[5/25][2940/9765] Loss_D: 0.1096 Loss_G: 0.0409 Convergence: 0.1142 k= 0.028705 lr = 0.0000418\n",
      "[5/25][2950/9765] Loss_D: 0.0982 Loss_G: 0.0392 Convergence: 0.0999 k= 0.028709 lr = 0.0000418\n",
      "[5/25][2960/9765] Loss_D: 0.1047 Loss_G: 0.0423 Convergence: 0.1059 k= 0.028705 lr = 0.0000418\n",
      "[5/25][2970/9765] Loss_D: 0.1024 Loss_G: 0.0432 Convergence: 0.1053 k= 0.028684 lr = 0.0000418\n",
      "[5/25][2980/9765] Loss_D: 0.1019 Loss_G: 0.0417 Convergence: 0.1035 k= 0.028686 lr = 0.0000418\n",
      "[5/25][2990/9765] Loss_D: 0.0965 Loss_G: 0.0409 Convergence: 0.0995 k= 0.028666 lr = 0.0000418\n",
      "[5/25][3000/9765] Loss_D: 0.0913 Loss_G: 0.0422 Convergence: 0.0977 k= 0.028677 lr = 0.0000418\n",
      "[5/25][3010/9765] Loss_D: 0.1019 Loss_G: 0.0409 Convergence: 0.1034 k= 0.028667 lr = 0.0000418\n",
      "[5/25][3020/9765] Loss_D: 0.1109 Loss_G: 0.0387 Convergence: 0.1180 k= 0.028686 lr = 0.0000418\n",
      "[5/25][3030/9765] Loss_D: 0.0973 Loss_G: 0.0374 Convergence: 0.1004 k= 0.028700 lr = 0.0000418\n",
      "[5/25][3040/9765] Loss_D: 0.0930 Loss_G: 0.0384 Convergence: 0.0948 k= 0.028728 lr = 0.0000418\n",
      "[5/25][3050/9765] Loss_D: 0.1070 Loss_G: 0.0415 Convergence: 0.1099 k= 0.028732 lr = 0.0000418\n",
      "[5/25][3060/9765] Loss_D: 0.1038 Loss_G: 0.0448 Convergence: 0.1078 k= 0.028727 lr = 0.0000418\n",
      "[5/25][3070/9765] Loss_D: 0.0944 Loss_G: 0.0396 Convergence: 0.0970 k= 0.028738 lr = 0.0000418\n",
      "[5/25][3080/9765] Loss_D: 0.1006 Loss_G: 0.0407 Convergence: 0.1018 k= 0.028747 lr = 0.0000418\n",
      "[5/25][3090/9765] Loss_D: 0.1137 Loss_G: 0.0459 Convergence: 0.1150 k= 0.028746 lr = 0.0000418\n",
      "[5/25][3100/9765] Loss_D: 0.0964 Loss_G: 0.0408 Convergence: 0.0993 k= 0.028738 lr = 0.0000418\n",
      "[5/25][3110/9765] Loss_D: 0.1033 Loss_G: 0.0408 Convergence: 0.1055 k= 0.028739 lr = 0.0000418\n",
      "[5/25][3120/9765] Loss_D: 0.0989 Loss_G: 0.0486 Convergence: 0.1086 k= 0.028717 lr = 0.0000418\n",
      "[5/25][3130/9765] Loss_D: 0.1053 Loss_G: 0.0399 Convergence: 0.1092 k= 0.028671 lr = 0.0000418\n",
      "[5/25][3140/9765] Loss_D: 0.1158 Loss_G: 0.0410 Convergence: 0.1227 k= 0.028689 lr = 0.0000418\n",
      "[5/25][3150/9765] Loss_D: 0.1072 Loss_G: 0.0417 Convergence: 0.1101 k= 0.028693 lr = 0.0000418\n",
      "[5/25][3160/9765] Loss_D: 0.1111 Loss_G: 0.0444 Convergence: 0.1129 k= 0.028665 lr = 0.0000418\n",
      "[5/25][3170/9765] Loss_D: 0.1013 Loss_G: 0.0429 Convergence: 0.1044 k= 0.028649 lr = 0.0000418\n",
      "[5/25][3180/9765] Loss_D: 0.1046 Loss_G: 0.0421 Convergence: 0.1059 k= 0.028642 lr = 0.0000418\n",
      "[5/25][3190/9765] Loss_D: 0.1033 Loss_G: 0.0512 Convergence: 0.1140 k= 0.028613 lr = 0.0000418\n",
      "[5/25][3200/9765] Loss_D: 0.1132 Loss_G: 0.0434 Convergence: 0.1166 k= 0.028582 lr = 0.0000418\n",
      "[5/25][3210/9765] Loss_D: 0.1068 Loss_G: 0.0366 Convergence: 0.1145 k= 0.028602 lr = 0.0000418\n",
      "[5/25][3220/9765] Loss_D: 0.1094 Loss_G: 0.0394 Convergence: 0.1155 k= 0.028637 lr = 0.0000418\n",
      "[5/25][3230/9765] Loss_D: 0.1122 Loss_G: 0.0503 Convergence: 0.1185 k= 0.028606 lr = 0.0000418\n",
      "[5/25][3240/9765] Loss_D: 0.1049 Loss_G: 0.0395 Convergence: 0.1089 k= 0.028591 lr = 0.0000418\n",
      "[5/25][3250/9765] Loss_D: 0.1122 Loss_G: 0.0403 Convergence: 0.1183 k= 0.028616 lr = 0.0000418\n",
      "[5/25][3260/9765] Loss_D: 0.1019 Loss_G: 0.0436 Convergence: 0.1055 k= 0.028583 lr = 0.0000418\n",
      "[5/25][3270/9765] Loss_D: 0.0960 Loss_G: 0.0401 Convergence: 0.0984 k= 0.028588 lr = 0.0000418\n",
      "[5/25][3280/9765] Loss_D: 0.1083 Loss_G: 0.0421 Convergence: 0.1109 k= 0.028618 lr = 0.0000418\n",
      "[5/25][3290/9765] Loss_D: 0.1097 Loss_G: 0.0448 Convergence: 0.1113 k= 0.028602 lr = 0.0000418\n",
      "[5/25][3300/9765] Loss_D: 0.0998 Loss_G: 0.0382 Convergence: 0.1031 k= 0.028610 lr = 0.0000418\n",
      "[5/25][3310/9765] Loss_D: 0.0987 Loss_G: 0.0404 Convergence: 0.1004 k= 0.028609 lr = 0.0000418\n",
      "[5/25][3320/9765] Loss_D: 0.1141 Loss_G: 0.0466 Convergence: 0.1158 k= 0.028591 lr = 0.0000418\n",
      "[5/25][3330/9765] Loss_D: 0.1055 Loss_G: 0.0434 Convergence: 0.1075 k= 0.028575 lr = 0.0000418\n",
      "[5/25][3340/9765] Loss_D: 0.1027 Loss_G: 0.0405 Convergence: 0.1049 k= 0.028588 lr = 0.0000418\n",
      "[5/25][3350/9765] Loss_D: 0.0985 Loss_G: 0.0369 Convergence: 0.1023 k= 0.028619 lr = 0.0000418\n",
      "[5/25][3360/9765] Loss_D: 0.0866 Loss_G: 0.0374 Convergence: 0.0900 k= 0.028612 lr = 0.0000418\n",
      "[5/25][3370/9765] Loss_D: 0.1014 Loss_G: 0.0428 Convergence: 0.1044 k= 0.028633 lr = 0.0000418\n",
      "[5/25][3380/9765] Loss_D: 0.1001 Loss_G: 0.0406 Convergence: 0.1014 k= 0.028628 lr = 0.0000418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][3390/9765] Loss_D: 0.1041 Loss_G: 0.0408 Convergence: 0.1065 k= 0.028636 lr = 0.0000418\n",
      "[5/25][3400/9765] Loss_D: 0.1111 Loss_G: 0.0431 Convergence: 0.1140 k= 0.028641 lr = 0.0000418\n",
      "[5/25][3410/9765] Loss_D: 0.0929 Loss_G: 0.0398 Convergence: 0.0962 k= 0.028634 lr = 0.0000418\n",
      "[5/25][3420/9765] Loss_D: 0.0971 Loss_G: 0.0400 Convergence: 0.0989 k= 0.028650 lr = 0.0000418\n",
      "[5/25][3430/9765] Loss_D: 0.1111 Loss_G: 0.0427 Convergence: 0.1145 k= 0.028656 lr = 0.0000418\n",
      "[5/25][3440/9765] Loss_D: 0.1020 Loss_G: 0.0429 Convergence: 0.1049 k= 0.028632 lr = 0.0000418\n",
      "[5/25][3450/9765] Loss_D: 0.1020 Loss_G: 0.0407 Convergence: 0.1038 k= 0.028637 lr = 0.0000418\n",
      "[5/25][3460/9765] Loss_D: 0.1023 Loss_G: 0.0429 Convergence: 0.1050 k= 0.028625 lr = 0.0000418\n",
      "[5/25][3470/9765] Loss_D: 0.1048 Loss_G: 0.0432 Convergence: 0.1068 k= 0.028642 lr = 0.0000418\n",
      "[5/25][3480/9765] Loss_D: 0.0989 Loss_G: 0.0402 Convergence: 0.1002 k= 0.028623 lr = 0.0000418\n",
      "[5/25][3490/9765] Loss_D: 0.0933 Loss_G: 0.0391 Convergence: 0.0958 k= 0.028617 lr = 0.0000418\n",
      "[5/25][3500/9765] Loss_D: 0.1025 Loss_G: 0.0396 Convergence: 0.1055 k= 0.028632 lr = 0.0000418\n",
      "[5/25][3510/9765] Loss_D: 0.1090 Loss_G: 0.0438 Convergence: 0.1105 k= 0.028636 lr = 0.0000418\n",
      "[5/25][3520/9765] Loss_D: 0.1012 Loss_G: 0.0417 Convergence: 0.1031 k= 0.028608 lr = 0.0000418\n",
      "[5/25][3530/9765] Loss_D: 0.0982 Loss_G: 0.0409 Convergence: 0.1005 k= 0.028618 lr = 0.0000418\n",
      "[5/25][3540/9765] Loss_D: 0.1049 Loss_G: 0.0425 Convergence: 0.1061 k= 0.028624 lr = 0.0000418\n",
      "[5/25][3550/9765] Loss_D: 0.1168 Loss_G: 0.0404 Convergence: 0.1248 k= 0.028605 lr = 0.0000418\n",
      "[5/25][3560/9765] Loss_D: 0.1007 Loss_G: 0.0386 Convergence: 0.1040 k= 0.028609 lr = 0.0000418\n",
      "[5/25][3570/9765] Loss_D: 0.1074 Loss_G: 0.0432 Convergence: 0.1087 k= 0.028622 lr = 0.0000418\n",
      "[5/25][3580/9765] Loss_D: 0.1016 Loss_G: 0.0455 Convergence: 0.1072 k= 0.028619 lr = 0.0000418\n",
      "[5/25][3590/9765] Loss_D: 0.1046 Loss_G: 0.0383 Convergence: 0.1096 k= 0.028604 lr = 0.0000418\n",
      "[5/25][3600/9765] Loss_D: 0.0964 Loss_G: 0.0401 Convergence: 0.0987 k= 0.028619 lr = 0.0000418\n",
      "[5/25][3610/9765] Loss_D: 0.0938 Loss_G: 0.0415 Convergence: 0.0985 k= 0.028579 lr = 0.0000418\n",
      "[5/25][3620/9765] Loss_D: 0.0885 Loss_G: 0.0362 Convergence: 0.0899 k= 0.028571 lr = 0.0000418\n",
      "[5/25][3630/9765] Loss_D: 0.0960 Loss_G: 0.0381 Convergence: 0.0978 k= 0.028593 lr = 0.0000418\n",
      "[5/25][3640/9765] Loss_D: 0.1055 Loss_G: 0.0447 Convergence: 0.1087 k= 0.028596 lr = 0.0000418\n",
      "[5/25][3650/9765] Loss_D: 0.1109 Loss_G: 0.0440 Convergence: 0.1128 k= 0.028537 lr = 0.0000418\n",
      "[5/25][3660/9765] Loss_D: 0.1088 Loss_G: 0.0463 Convergence: 0.1123 k= 0.028529 lr = 0.0000418\n",
      "[5/25][3670/9765] Loss_D: 0.1035 Loss_G: 0.0435 Convergence: 0.1063 k= 0.028514 lr = 0.0000418\n",
      "[5/25][3680/9765] Loss_D: 0.0965 Loss_G: 0.0417 Convergence: 0.1002 k= 0.028500 lr = 0.0000418\n",
      "[5/25][3690/9765] Loss_D: 0.1024 Loss_G: 0.0421 Convergence: 0.1042 k= 0.028496 lr = 0.0000418\n",
      "[5/25][3700/9765] Loss_D: 0.1049 Loss_G: 0.0430 Convergence: 0.1066 k= 0.028482 lr = 0.0000418\n",
      "[5/25][3710/9765] Loss_D: 0.1049 Loss_G: 0.0424 Convergence: 0.1061 k= 0.028469 lr = 0.0000418\n",
      "[5/25][3720/9765] Loss_D: 0.1004 Loss_G: 0.0394 Convergence: 0.1028 k= 0.028474 lr = 0.0000418\n",
      "[5/25][3730/9765] Loss_D: 0.1016 Loss_G: 0.0482 Convergence: 0.1099 k= 0.028479 lr = 0.0000418\n",
      "[5/25][3740/9765] Loss_D: 0.0968 Loss_G: 0.0399 Convergence: 0.0987 k= 0.028477 lr = 0.0000418\n",
      "[5/25][3750/9765] Loss_D: 0.1020 Loss_G: 0.0428 Convergence: 0.1047 k= 0.028426 lr = 0.0000418\n",
      "[5/25][3760/9765] Loss_D: 0.1111 Loss_G: 0.0422 Convergence: 0.1149 k= 0.028441 lr = 0.0000418\n",
      "[5/25][3770/9765] Loss_D: 0.1029 Loss_G: 0.0442 Convergence: 0.1067 k= 0.028447 lr = 0.0000418\n",
      "[5/25][3780/9765] Loss_D: 0.1038 Loss_G: 0.0422 Convergence: 0.1052 k= 0.028440 lr = 0.0000418\n",
      "[5/25][3790/9765] Loss_D: 0.1075 Loss_G: 0.0374 Convergence: 0.1145 k= 0.028457 lr = 0.0000418\n",
      "[5/25][3800/9765] Loss_D: 0.0993 Loss_G: 0.0402 Convergence: 0.1005 k= 0.028462 lr = 0.0000418\n",
      "[5/25][3810/9765] Loss_D: 0.0954 Loss_G: 0.0369 Convergence: 0.0981 k= 0.028472 lr = 0.0000418\n",
      "[5/25][3820/9765] Loss_D: 0.0993 Loss_G: 0.0417 Convergence: 0.1020 k= 0.028487 lr = 0.0000418\n",
      "[5/25][3830/9765] Loss_D: 0.1063 Loss_G: 0.0370 Convergence: 0.1135 k= 0.028479 lr = 0.0000418\n",
      "[5/25][3840/9765] Loss_D: 0.1051 Loss_G: 0.0448 Convergence: 0.1087 k= 0.028477 lr = 0.0000418\n",
      "[5/25][3850/9765] Loss_D: 0.0984 Loss_G: 0.0445 Convergence: 0.1043 k= 0.028442 lr = 0.0000418\n",
      "[5/25][3860/9765] Loss_D: 0.0988 Loss_G: 0.0379 Convergence: 0.1019 k= 0.028449 lr = 0.0000418\n",
      "[5/25][3870/9765] Loss_D: 0.1060 Loss_G: 0.0474 Convergence: 0.1118 k= 0.028459 lr = 0.0000418\n",
      "[5/25][3880/9765] Loss_D: 0.1043 Loss_G: 0.0420 Convergence: 0.1056 k= 0.028441 lr = 0.0000418\n",
      "[5/25][3890/9765] Loss_D: 0.0998 Loss_G: 0.0385 Convergence: 0.1027 k= 0.028442 lr = 0.0000418\n",
      "[5/25][3900/9765] Loss_D: 0.0991 Loss_G: 0.0412 Convergence: 0.1013 k= 0.028465 lr = 0.0000418\n",
      "[5/25][3910/9765] Loss_D: 0.1024 Loss_G: 0.0411 Convergence: 0.1039 k= 0.028457 lr = 0.0000418\n",
      "[5/25][3920/9765] Loss_D: 0.1001 Loss_G: 0.0418 Convergence: 0.1025 k= 0.028479 lr = 0.0000418\n",
      "[5/25][3930/9765] Loss_D: 0.1020 Loss_G: 0.0415 Convergence: 0.1034 k= 0.028442 lr = 0.0000418\n",
      "[5/25][3940/9765] Loss_D: 0.1036 Loss_G: 0.0440 Convergence: 0.1069 k= 0.028447 lr = 0.0000418\n",
      "[5/25][3950/9765] Loss_D: 0.1082 Loss_G: 0.0382 Convergence: 0.1148 k= 0.028455 lr = 0.0000418\n",
      "[5/25][3960/9765] Loss_D: 0.1056 Loss_G: 0.0436 Convergence: 0.1076 k= 0.028444 lr = 0.0000418\n",
      "[5/25][3970/9765] Loss_D: 0.1069 Loss_G: 0.0411 Convergence: 0.1100 k= 0.028468 lr = 0.0000418\n",
      "[5/25][3980/9765] Loss_D: 0.1042 Loss_G: 0.0424 Convergence: 0.1056 k= 0.028454 lr = 0.0000418\n",
      "[5/25][3990/9765] Loss_D: 0.1105 Loss_G: 0.0409 Convergence: 0.1156 k= 0.028474 lr = 0.0000418\n",
      "[5/25][4000/9765] Loss_D: 0.1057 Loss_G: 0.0400 Convergence: 0.1097 k= 0.028492 lr = 0.0000418\n",
      "[5/25][4010/9765] Loss_D: 0.0946 Loss_G: 0.0426 Convergence: 0.1001 k= 0.028449 lr = 0.0000418\n",
      "[5/25][4020/9765] Loss_D: 0.1117 Loss_G: 0.0362 Convergence: 0.1217 k= 0.028470 lr = 0.0000418\n",
      "[5/25][4030/9765] Loss_D: 0.1025 Loss_G: 0.0461 Convergence: 0.1084 k= 0.028454 lr = 0.0000418\n",
      "[5/25][4040/9765] Loss_D: 0.1051 Loss_G: 0.0404 Convergence: 0.1084 k= 0.028439 lr = 0.0000418\n",
      "[5/25][4050/9765] Loss_D: 0.1070 Loss_G: 0.0376 Convergence: 0.1137 k= 0.028448 lr = 0.0000418\n",
      "[5/25][4060/9765] Loss_D: 0.1091 Loss_G: 0.0425 Convergence: 0.1118 k= 0.028470 lr = 0.0000418\n",
      "[5/25][4070/9765] Loss_D: 0.1040 Loss_G: 0.0453 Convergence: 0.1084 k= 0.028463 lr = 0.0000418\n",
      "[5/25][4080/9765] Loss_D: 0.0983 Loss_G: 0.0456 Convergence: 0.1052 k= 0.028422 lr = 0.0000418\n",
      "[5/25][4090/9765] Loss_D: 0.1014 Loss_G: 0.0322 Convergence: 0.1111 k= 0.028425 lr = 0.0000418\n",
      "[5/25][4100/9765] Loss_D: 0.1035 Loss_G: 0.0449 Convergence: 0.1077 k= 0.028438 lr = 0.0000418\n",
      "[5/25][4110/9765] Loss_D: 0.1124 Loss_G: 0.0480 Convergence: 0.1163 k= 0.028401 lr = 0.0000418\n",
      "[5/25][4120/9765] Loss_D: 0.1058 Loss_G: 0.0415 Convergence: 0.1082 k= 0.028396 lr = 0.0000418\n",
      "[5/25][4130/9765] Loss_D: 0.1062 Loss_G: 0.0409 Convergence: 0.1093 k= 0.028404 lr = 0.0000418\n",
      "[5/25][4140/9765] Loss_D: 0.1007 Loss_G: 0.0433 Convergence: 0.1044 k= 0.028407 lr = 0.0000418\n",
      "[5/25][4150/9765] Loss_D: 0.1007 Loss_G: 0.0447 Convergence: 0.1058 k= 0.028394 lr = 0.0000418\n",
      "[5/25][4160/9765] Loss_D: 0.1069 Loss_G: 0.0438 Convergence: 0.1086 k= 0.028411 lr = 0.0000418\n",
      "[5/25][4170/9765] Loss_D: 0.1011 Loss_G: 0.0445 Convergence: 0.1059 k= 0.028422 lr = 0.0000418\n",
      "[5/25][4180/9765] Loss_D: 0.1002 Loss_G: 0.0401 Convergence: 0.1017 k= 0.028401 lr = 0.0000418\n",
      "[5/25][4190/9765] Loss_D: 0.0986 Loss_G: 0.0436 Convergence: 0.1034 k= 0.028400 lr = 0.0000418\n",
      "[5/25][4200/9765] Loss_D: 0.1018 Loss_G: 0.0425 Convergence: 0.1043 k= 0.028396 lr = 0.0000418\n",
      "[5/25][4210/9765] Loss_D: 0.1078 Loss_G: 0.0445 Convergence: 0.1098 k= 0.028394 lr = 0.0000418\n",
      "[5/25][4220/9765] Loss_D: 0.1098 Loss_G: 0.0393 Convergence: 0.1160 k= 0.028418 lr = 0.0000418\n",
      "[5/25][4230/9765] Loss_D: 0.1018 Loss_G: 0.0409 Convergence: 0.1034 k= 0.028439 lr = 0.0000418\n",
      "[5/25][4240/9765] Loss_D: 0.0992 Loss_G: 0.0425 Convergence: 0.1028 k= 0.028451 lr = 0.0000418\n",
      "[5/25][4250/9765] Loss_D: 0.1135 Loss_G: 0.0435 Convergence: 0.1170 k= 0.028458 lr = 0.0000418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][4260/9765] Loss_D: 0.1133 Loss_G: 0.0377 Convergence: 0.1224 k= 0.028430 lr = 0.0000418\n",
      "[5/25][4270/9765] Loss_D: 0.1056 Loss_G: 0.0405 Convergence: 0.1089 k= 0.028430 lr = 0.0000418\n",
      "[5/25][4280/9765] Loss_D: 0.0923 Loss_G: 0.0372 Convergence: 0.0936 k= 0.028438 lr = 0.0000418\n",
      "[5/25][4290/9765] Loss_D: 0.1057 Loss_G: 0.0449 Convergence: 0.1090 k= 0.028447 lr = 0.0000418\n",
      "[5/25][4300/9765] Loss_D: 0.1039 Loss_G: 0.0417 Convergence: 0.1053 k= 0.028450 lr = 0.0000418\n",
      "[5/25][4310/9765] Loss_D: 0.0980 Loss_G: 0.0388 Convergence: 0.1000 k= 0.028450 lr = 0.0000418\n",
      "[5/25][4320/9765] Loss_D: 0.1050 Loss_G: 0.0377 Convergence: 0.1108 k= 0.028481 lr = 0.0000418\n",
      "[5/25][4330/9765] Loss_D: 0.0962 Loss_G: 0.0455 Convergence: 0.1039 k= 0.028468 lr = 0.0000418\n",
      "[5/25][4340/9765] Loss_D: 0.1068 Loss_G: 0.0419 Convergence: 0.1093 k= 0.028434 lr = 0.0000418\n",
      "[5/25][4350/9765] Loss_D: 0.0976 Loss_G: 0.0411 Convergence: 0.1003 k= 0.028442 lr = 0.0000418\n",
      "[5/25][4360/9765] Loss_D: 0.1033 Loss_G: 0.0407 Convergence: 0.1053 k= 0.028457 lr = 0.0000418\n",
      "[5/25][4370/9765] Loss_D: 0.0951 Loss_G: 0.0424 Convergence: 0.1002 k= 0.028452 lr = 0.0000418\n",
      "[5/25][4380/9765] Loss_D: 0.1050 Loss_G: 0.0364 Convergence: 0.1120 k= 0.028465 lr = 0.0000418\n",
      "[5/25][4390/9765] Loss_D: 0.1011 Loss_G: 0.0417 Convergence: 0.1031 k= 0.028483 lr = 0.0000418\n",
      "[5/25][4400/9765] Loss_D: 0.1010 Loss_G: 0.0522 Convergence: 0.1136 k= 0.028447 lr = 0.0000418\n",
      "[5/25][4410/9765] Loss_D: 0.1030 Loss_G: 0.0405 Convergence: 0.1054 k= 0.028447 lr = 0.0000418\n",
      "[5/25][4420/9765] Loss_D: 0.1000 Loss_G: 0.0403 Convergence: 0.1014 k= 0.028438 lr = 0.0000418\n",
      "[5/25][4430/9765] Loss_D: 0.1042 Loss_G: 0.0430 Convergence: 0.1063 k= 0.028433 lr = 0.0000418\n",
      "[5/25][4440/9765] Loss_D: 0.0995 Loss_G: 0.0436 Convergence: 0.1040 k= 0.028415 lr = 0.0000418\n",
      "[5/25][4450/9765] Loss_D: 0.1178 Loss_G: 0.0486 Convergence: 0.1201 k= 0.028398 lr = 0.0000418\n",
      "[5/25][4460/9765] Loss_D: 0.1028 Loss_G: 0.0444 Convergence: 0.1068 k= 0.028384 lr = 0.0000418\n",
      "[5/25][4470/9765] Loss_D: 0.0964 Loss_G: 0.0415 Convergence: 0.1001 k= 0.028367 lr = 0.0000418\n",
      "[5/25][4480/9765] Loss_D: 0.0982 Loss_G: 0.0366 Convergence: 0.1023 k= 0.028360 lr = 0.0000418\n",
      "[5/25][4490/9765] Loss_D: 0.0923 Loss_G: 0.0415 Convergence: 0.0976 k= 0.028393 lr = 0.0000418\n",
      "[5/25][4500/9765] Loss_D: 0.1080 Loss_G: 0.0421 Convergence: 0.1107 k= 0.028376 lr = 0.0000418\n",
      "[5/25][4510/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.1002 k= 0.028384 lr = 0.0000418\n",
      "[5/25][4520/9765] Loss_D: 0.0952 Loss_G: 0.0469 Convergence: 0.1048 k= 0.028368 lr = 0.0000418\n",
      "[5/25][4530/9765] Loss_D: 0.0936 Loss_G: 0.0371 Convergence: 0.0954 k= 0.028367 lr = 0.0000418\n",
      "[5/25][4540/9765] Loss_D: 0.0994 Loss_G: 0.0375 Convergence: 0.1031 k= 0.028398 lr = 0.0000418\n",
      "[5/25][4550/9765] Loss_D: 0.1161 Loss_G: 0.0408 Convergence: 0.1234 k= 0.028382 lr = 0.0000418\n",
      "[5/25][4560/9765] Loss_D: 0.0941 Loss_G: 0.0395 Convergence: 0.0966 k= 0.028378 lr = 0.0000418\n",
      "[5/25][4570/9765] Loss_D: 0.1020 Loss_G: 0.0399 Convergence: 0.1046 k= 0.028373 lr = 0.0000418\n",
      "[5/25][4580/9765] Loss_D: 0.0987 Loss_G: 0.0443 Convergence: 0.1042 k= 0.028395 lr = 0.0000418\n",
      "[5/25][4590/9765] Loss_D: 0.1018 Loss_G: 0.0420 Convergence: 0.1037 k= 0.028402 lr = 0.0000418\n",
      "[5/25][4600/9765] Loss_D: 0.1137 Loss_G: 0.0416 Convergence: 0.1191 k= 0.028373 lr = 0.0000418\n",
      "[5/25][4610/9765] Loss_D: 0.1065 Loss_G: 0.0402 Convergence: 0.1105 k= 0.028375 lr = 0.0000418\n",
      "[5/25][4620/9765] Loss_D: 0.0968 Loss_G: 0.0407 Convergence: 0.0995 k= 0.028372 lr = 0.0000418\n",
      "[5/25][4630/9765] Loss_D: 0.0960 Loss_G: 0.0407 Convergence: 0.0990 k= 0.028358 lr = 0.0000418\n",
      "[5/25][4640/9765] Loss_D: 0.0995 Loss_G: 0.0407 Convergence: 0.1010 k= 0.028362 lr = 0.0000418\n",
      "[5/25][4650/9765] Loss_D: 0.1069 Loss_G: 0.0408 Convergence: 0.1105 k= 0.028366 lr = 0.0000418\n",
      "[5/25][4660/9765] Loss_D: 0.0983 Loss_G: 0.0426 Convergence: 0.1023 k= 0.028371 lr = 0.0000418\n",
      "[5/25][4670/9765] Loss_D: 0.0994 Loss_G: 0.0411 Convergence: 0.1013 k= 0.028398 lr = 0.0000418\n",
      "[5/25][4680/9765] Loss_D: 0.1066 Loss_G: 0.0453 Convergence: 0.1100 k= 0.028372 lr = 0.0000418\n",
      "[5/25][4690/9765] Loss_D: 0.0992 Loss_G: 0.0413 Convergence: 0.1015 k= 0.028378 lr = 0.0000418\n",
      "[5/25][4700/9765] Loss_D: 0.1089 Loss_G: 0.0454 Convergence: 0.1115 k= 0.028385 lr = 0.0000418\n",
      "[5/25][4710/9765] Loss_D: 0.1041 Loss_G: 0.0390 Convergence: 0.1082 k= 0.028386 lr = 0.0000418\n",
      "[5/25][4720/9765] Loss_D: 0.1112 Loss_G: 0.0434 Convergence: 0.1140 k= 0.028391 lr = 0.0000418\n",
      "[5/25][4730/9765] Loss_D: 0.1000 Loss_G: 0.0467 Convergence: 0.1076 k= 0.028371 lr = 0.0000418\n",
      "[5/25][4740/9765] Loss_D: 0.1074 Loss_G: 0.0419 Convergence: 0.1101 k= 0.028374 lr = 0.0000418\n",
      "[5/25][4750/9765] Loss_D: 0.0911 Loss_G: 0.0413 Convergence: 0.0967 k= 0.028374 lr = 0.0000418\n",
      "[5/25][4760/9765] Loss_D: 0.1001 Loss_G: 0.0422 Convergence: 0.1029 k= 0.028372 lr = 0.0000418\n",
      "[5/25][4770/9765] Loss_D: 0.1083 Loss_G: 0.0409 Convergence: 0.1123 k= 0.028359 lr = 0.0000418\n",
      "[5/25][4780/9765] Loss_D: 0.0981 Loss_G: 0.0351 Convergence: 0.1038 k= 0.028374 lr = 0.0000418\n",
      "[5/25][4790/9765] Loss_D: 0.1093 Loss_G: 0.0484 Convergence: 0.1148 k= 0.028386 lr = 0.0000418\n",
      "[5/25][4800/9765] Loss_D: 0.1032 Loss_G: 0.0420 Convergence: 0.1047 k= 0.028332 lr = 0.0000418\n",
      "[5/25][4810/9765] Loss_D: 0.0958 Loss_G: 0.0389 Convergence: 0.0971 k= 0.028338 lr = 0.0000418\n",
      "[5/25][4820/9765] Loss_D: 0.1018 Loss_G: 0.0413 Convergence: 0.1030 k= 0.028351 lr = 0.0000418\n",
      "[5/25][4830/9765] Loss_D: 0.0939 Loss_G: 0.0413 Convergence: 0.0983 k= 0.028358 lr = 0.0000418\n",
      "[5/25][4840/9765] Loss_D: 0.1028 Loss_G: 0.0438 Convergence: 0.1061 k= 0.028338 lr = 0.0000418\n",
      "[5/25][4850/9765] Loss_D: 0.0925 Loss_G: 0.0382 Convergence: 0.0944 k= 0.028323 lr = 0.0000418\n",
      "[5/25][4860/9765] Loss_D: 0.1120 Loss_G: 0.0439 Convergence: 0.1146 k= 0.028343 lr = 0.0000418\n",
      "[5/25][4870/9765] Loss_D: 0.0983 Loss_G: 0.0433 Convergence: 0.1030 k= 0.028324 lr = 0.0000418\n",
      "[5/25][4880/9765] Loss_D: 0.0989 Loss_G: 0.0453 Convergence: 0.1053 k= 0.028322 lr = 0.0000418\n",
      "[5/25][4890/9765] Loss_D: 0.1081 Loss_G: 0.0404 Convergence: 0.1124 k= 0.028327 lr = 0.0000418\n",
      "[5/25][4900/9765] Loss_D: 0.1011 Loss_G: 0.0454 Convergence: 0.1068 k= 0.028334 lr = 0.0000418\n",
      "[5/25][4910/9765] Loss_D: 0.0980 Loss_G: 0.0382 Convergence: 0.1004 k= 0.028326 lr = 0.0000418\n",
      "[5/25][4920/9765] Loss_D: 0.0950 Loss_G: 0.0407 Convergence: 0.0984 k= 0.028312 lr = 0.0000418\n",
      "[5/25][4930/9765] Loss_D: 0.0983 Loss_G: 0.0389 Convergence: 0.1003 k= 0.028313 lr = 0.0000418\n",
      "[5/25][4940/9765] Loss_D: 0.0897 Loss_G: 0.0459 Convergence: 0.1004 k= 0.028315 lr = 0.0000418\n",
      "[5/25][4950/9765] Loss_D: 0.1056 Loss_G: 0.0392 Convergence: 0.1102 k= 0.028317 lr = 0.0000418\n",
      "[5/25][4960/9765] Loss_D: 0.1011 Loss_G: 0.0436 Convergence: 0.1050 k= 0.028313 lr = 0.0000418\n",
      "[5/25][4970/9765] Loss_D: 0.1029 Loss_G: 0.0404 Convergence: 0.1053 k= 0.028289 lr = 0.0000418\n",
      "[5/25][4980/9765] Loss_D: 0.1046 Loss_G: 0.0406 Convergence: 0.1073 k= 0.028305 lr = 0.0000418\n",
      "[5/25][4990/9765] Loss_D: 0.1015 Loss_G: 0.0421 Convergence: 0.1037 k= 0.028291 lr = 0.0000418\n",
      "[5/25][5000/9765] Loss_D: 0.1100 Loss_G: 0.0427 Convergence: 0.1131 k= 0.028255 lr = 0.0000418\n",
      "[5/25][5010/9765] Loss_D: 0.1067 Loss_G: 0.0392 Convergence: 0.1118 k= 0.028254 lr = 0.0000418\n",
      "[5/25][5020/9765] Loss_D: 0.1008 Loss_G: 0.0415 Convergence: 0.1027 k= 0.028261 lr = 0.0000418\n",
      "[5/25][5030/9765] Loss_D: 0.1039 Loss_G: 0.0414 Convergence: 0.1059 k= 0.028245 lr = 0.0000418\n",
      "[5/25][5040/9765] Loss_D: 0.1095 Loss_G: 0.0445 Convergence: 0.1110 k= 0.028234 lr = 0.0000418\n",
      "[5/25][5050/9765] Loss_D: 0.1090 Loss_G: 0.0425 Convergence: 0.1117 k= 0.028229 lr = 0.0000418\n",
      "[5/25][5060/9765] Loss_D: 0.1055 Loss_G: 0.0392 Convergence: 0.1099 k= 0.028258 lr = 0.0000418\n",
      "[5/25][5070/9765] Loss_D: 0.1014 Loss_G: 0.0416 Convergence: 0.1032 k= 0.028274 lr = 0.0000418\n",
      "[5/25][5080/9765] Loss_D: 0.0937 Loss_G: 0.0387 Convergence: 0.0955 k= 0.028274 lr = 0.0000418\n",
      "[5/25][5090/9765] Loss_D: 0.0988 Loss_G: 0.0373 Convergence: 0.1025 k= 0.028291 lr = 0.0000418\n",
      "[5/25][5100/9765] Loss_D: 0.1018 Loss_G: 0.0400 Convergence: 0.1042 k= 0.028303 lr = 0.0000418\n",
      "[5/25][5110/9765] Loss_D: 0.1017 Loss_G: 0.0425 Convergence: 0.1041 k= 0.028298 lr = 0.0000418\n",
      "[5/25][5120/9765] Loss_D: 0.0971 Loss_G: 0.0373 Convergence: 0.1001 k= 0.028309 lr = 0.0000418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][5130/9765] Loss_D: 0.1036 Loss_G: 0.0388 Convergence: 0.1080 k= 0.028272 lr = 0.0000418\n",
      "[5/25][5140/9765] Loss_D: 0.1079 Loss_G: 0.0408 Convergence: 0.1118 k= 0.028296 lr = 0.0000418\n",
      "[5/25][5150/9765] Loss_D: 0.1079 Loss_G: 0.0389 Convergence: 0.1136 k= 0.028296 lr = 0.0000418\n",
      "[5/25][5160/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.1005 k= 0.028309 lr = 0.0000418\n",
      "[5/25][5170/9765] Loss_D: 0.1012 Loss_G: 0.0419 Convergence: 0.1033 k= 0.028317 lr = 0.0000418\n",
      "[5/25][5180/9765] Loss_D: 0.1055 Loss_G: 0.0401 Convergence: 0.1092 k= 0.028299 lr = 0.0000397\n",
      "[5/25][5190/9765] Loss_D: 0.1036 Loss_G: 0.0407 Convergence: 0.1059 k= 0.028285 lr = 0.0000397\n",
      "[5/25][5200/9765] Loss_D: 0.1060 Loss_G: 0.0384 Convergence: 0.1116 k= 0.028293 lr = 0.0000397\n",
      "[5/25][5210/9765] Loss_D: 0.1036 Loss_G: 0.0404 Convergence: 0.1062 k= 0.028302 lr = 0.0000397\n",
      "[5/25][5220/9765] Loss_D: 0.1029 Loss_G: 0.0370 Convergence: 0.1084 k= 0.028331 lr = 0.0000397\n",
      "[5/25][5230/9765] Loss_D: 0.1071 Loss_G: 0.0469 Convergence: 0.1119 k= 0.028325 lr = 0.0000397\n",
      "[5/25][5240/9765] Loss_D: 0.1071 Loss_G: 0.0483 Convergence: 0.1133 k= 0.028251 lr = 0.0000397\n",
      "[5/25][5250/9765] Loss_D: 0.1020 Loss_G: 0.0378 Convergence: 0.1064 k= 0.028267 lr = 0.0000397\n",
      "[5/25][5260/9765] Loss_D: 0.0988 Loss_G: 0.0391 Convergence: 0.1009 k= 0.028269 lr = 0.0000397\n",
      "[5/25][5270/9765] Loss_D: 0.0905 Loss_G: 0.0431 Convergence: 0.0982 k= 0.028220 lr = 0.0000397\n",
      "[5/25][5280/9765] Loss_D: 0.1027 Loss_G: 0.0408 Convergence: 0.1046 k= 0.028229 lr = 0.0000397\n",
      "[5/25][5290/9765] Loss_D: 0.1015 Loss_G: 0.0417 Convergence: 0.1033 k= 0.028243 lr = 0.0000397\n",
      "[5/25][5300/9765] Loss_D: 0.1043 Loss_G: 0.0414 Convergence: 0.1062 k= 0.028217 lr = 0.0000397\n",
      "[5/25][5310/9765] Loss_D: 0.1051 Loss_G: 0.0418 Convergence: 0.1069 k= 0.028210 lr = 0.0000397\n",
      "[5/25][5320/9765] Loss_D: 0.1044 Loss_G: 0.0402 Convergence: 0.1076 k= 0.028207 lr = 0.0000397\n",
      "[5/25][5330/9765] Loss_D: 0.0954 Loss_G: 0.0356 Convergence: 0.0994 k= 0.028239 lr = 0.0000397\n",
      "[5/25][5340/9765] Loss_D: 0.1051 Loss_G: 0.0446 Convergence: 0.1083 k= 0.028269 lr = 0.0000397\n",
      "[5/25][5350/9765] Loss_D: 0.1104 Loss_G: 0.0542 Convergence: 0.1213 k= 0.028221 lr = 0.0000397\n",
      "[5/25][5360/9765] Loss_D: 0.0997 Loss_G: 0.0426 Convergence: 0.1032 k= 0.028162 lr = 0.0000397\n",
      "[5/25][5370/9765] Loss_D: 0.1123 Loss_G: 0.0391 Convergence: 0.1197 k= 0.028177 lr = 0.0000397\n",
      "[5/25][5380/9765] Loss_D: 0.0921 Loss_G: 0.0390 Convergence: 0.0949 k= 0.028195 lr = 0.0000397\n",
      "[5/25][5390/9765] Loss_D: 0.1003 Loss_G: 0.0437 Convergence: 0.1047 k= 0.028154 lr = 0.0000397\n",
      "[5/25][5400/9765] Loss_D: 0.1085 Loss_G: 0.0446 Convergence: 0.1104 k= 0.028130 lr = 0.0000397\n",
      "[5/25][5410/9765] Loss_D: 0.0943 Loss_G: 0.0404 Convergence: 0.0977 k= 0.028122 lr = 0.0000397\n",
      "[5/25][5420/9765] Loss_D: 0.1058 Loss_G: 0.0359 Convergence: 0.1137 k= 0.028147 lr = 0.0000397\n",
      "[5/25][5430/9765] Loss_D: 0.1019 Loss_G: 0.0423 Convergence: 0.1041 k= 0.028116 lr = 0.0000397\n",
      "[5/25][5440/9765] Loss_D: 0.1033 Loss_G: 0.0427 Convergence: 0.1053 k= 0.028093 lr = 0.0000397\n",
      "[5/25][5450/9765] Loss_D: 0.1093 Loss_G: 0.0391 Convergence: 0.1154 k= 0.028106 lr = 0.0000397\n",
      "[5/25][5460/9765] Loss_D: 0.1021 Loss_G: 0.0413 Convergence: 0.1032 k= 0.028123 lr = 0.0000397\n",
      "[5/25][5470/9765] Loss_D: 0.1003 Loss_G: 0.0405 Convergence: 0.1014 k= 0.028138 lr = 0.0000397\n",
      "[5/25][5480/9765] Loss_D: 0.1009 Loss_G: 0.0466 Convergence: 0.1079 k= 0.028105 lr = 0.0000397\n",
      "[5/25][5490/9765] Loss_D: 0.1047 Loss_G: 0.0449 Convergence: 0.1085 k= 0.028096 lr = 0.0000397\n",
      "[5/25][5500/9765] Loss_D: 0.1044 Loss_G: 0.0387 Convergence: 0.1091 k= 0.028108 lr = 0.0000397\n",
      "[5/25][5510/9765] Loss_D: 0.1060 Loss_G: 0.0393 Convergence: 0.1106 k= 0.028103 lr = 0.0000397\n",
      "[5/25][5520/9765] Loss_D: 0.1009 Loss_G: 0.0461 Convergence: 0.1074 k= 0.028085 lr = 0.0000397\n",
      "[5/25][5530/9765] Loss_D: 0.1005 Loss_G: 0.0383 Convergence: 0.1040 k= 0.028081 lr = 0.0000397\n",
      "[5/25][5540/9765] Loss_D: 0.0861 Loss_G: 0.0394 Convergence: 0.0918 k= 0.028084 lr = 0.0000397\n",
      "[5/25][5550/9765] Loss_D: 0.1034 Loss_G: 0.0432 Convergence: 0.1059 k= 0.028089 lr = 0.0000397\n",
      "[5/25][5560/9765] Loss_D: 0.0905 Loss_G: 0.0420 Convergence: 0.0970 k= 0.028087 lr = 0.0000397\n",
      "[5/25][5570/9765] Loss_D: 0.0971 Loss_G: 0.0443 Convergence: 0.1032 k= 0.028079 lr = 0.0000397\n",
      "[5/25][5580/9765] Loss_D: 0.1094 Loss_G: 0.0372 Convergence: 0.1175 k= 0.028106 lr = 0.0000397\n",
      "[5/25][5590/9765] Loss_D: 0.1112 Loss_G: 0.0415 Convergence: 0.1158 k= 0.028107 lr = 0.0000397\n",
      "[5/25][5600/9765] Loss_D: 0.1022 Loss_G: 0.0418 Convergence: 0.1038 k= 0.028097 lr = 0.0000397\n",
      "[5/25][5610/9765] Loss_D: 0.1092 Loss_G: 0.0413 Convergence: 0.1132 k= 0.028084 lr = 0.0000397\n",
      "[5/25][5620/9765] Loss_D: 0.1040 Loss_G: 0.0374 Convergence: 0.1098 k= 0.028105 lr = 0.0000397\n",
      "[5/25][5630/9765] Loss_D: 0.1027 Loss_G: 0.0437 Convergence: 0.1060 k= 0.028116 lr = 0.0000397\n",
      "[5/25][5640/9765] Loss_D: 0.1093 Loss_G: 0.0433 Convergence: 0.1115 k= 0.028091 lr = 0.0000397\n",
      "[5/25][5650/9765] Loss_D: 0.1038 Loss_G: 0.0432 Convergence: 0.1062 k= 0.028076 lr = 0.0000397\n",
      "[5/25][5660/9765] Loss_D: 0.1026 Loss_G: 0.0402 Convergence: 0.1050 k= 0.028079 lr = 0.0000397\n",
      "[5/25][5670/9765] Loss_D: 0.0920 Loss_G: 0.0396 Convergence: 0.0954 k= 0.028072 lr = 0.0000397\n",
      "[5/25][5680/9765] Loss_D: 0.0960 Loss_G: 0.0439 Convergence: 0.1023 k= 0.028069 lr = 0.0000397\n",
      "[5/25][5690/9765] Loss_D: 0.0975 Loss_G: 0.0394 Convergence: 0.0985 k= 0.028079 lr = 0.0000397\n",
      "[5/25][5700/9765] Loss_D: 0.1003 Loss_G: 0.0431 Convergence: 0.1040 k= 0.028072 lr = 0.0000397\n",
      "[5/25][5710/9765] Loss_D: 0.0992 Loss_G: 0.0448 Convergence: 0.1050 k= 0.028059 lr = 0.0000397\n",
      "[5/25][5720/9765] Loss_D: 0.0975 Loss_G: 0.0424 Convergence: 0.1016 k= 0.028065 lr = 0.0000397\n",
      "[5/25][5730/9765] Loss_D: 0.1039 Loss_G: 0.0433 Convergence: 0.1064 k= 0.028065 lr = 0.0000397\n",
      "[5/25][5740/9765] Loss_D: 0.0949 Loss_G: 0.0434 Convergence: 0.1011 k= 0.028055 lr = 0.0000397\n",
      "[5/25][5750/9765] Loss_D: 0.1114 Loss_G: 0.0418 Convergence: 0.1156 k= 0.028065 lr = 0.0000397\n",
      "[5/25][5760/9765] Loss_D: 0.1060 Loss_G: 0.0403 Convergence: 0.1096 k= 0.028097 lr = 0.0000397\n",
      "[5/25][5770/9765] Loss_D: 0.1027 Loss_G: 0.0428 Convergence: 0.1050 k= 0.028093 lr = 0.0000397\n",
      "[5/25][5780/9765] Loss_D: 0.0955 Loss_G: 0.0416 Convergence: 0.0995 k= 0.028075 lr = 0.0000397\n",
      "[5/25][5790/9765] Loss_D: 0.1018 Loss_G: 0.0407 Convergence: 0.1035 k= 0.028068 lr = 0.0000397\n",
      "[5/25][5800/9765] Loss_D: 0.1048 Loss_G: 0.0446 Convergence: 0.1083 k= 0.028077 lr = 0.0000397\n",
      "[5/25][5810/9765] Loss_D: 0.1040 Loss_G: 0.0394 Convergence: 0.1077 k= 0.028082 lr = 0.0000397\n",
      "[5/25][5820/9765] Loss_D: 0.1055 Loss_G: 0.0430 Convergence: 0.1071 k= 0.028085 lr = 0.0000397\n",
      "[5/25][5830/9765] Loss_D: 0.1000 Loss_G: 0.0386 Convergence: 0.1029 k= 0.028092 lr = 0.0000397\n",
      "[5/25][5840/9765] Loss_D: 0.1004 Loss_G: 0.0411 Convergence: 0.1021 k= 0.028093 lr = 0.0000397\n",
      "[5/25][5850/9765] Loss_D: 0.0959 Loss_G: 0.0440 Convergence: 0.1023 k= 0.028080 lr = 0.0000397\n",
      "[5/25][5860/9765] Loss_D: 0.1122 Loss_G: 0.0438 Convergence: 0.1149 k= 0.028084 lr = 0.0000397\n",
      "[5/25][5870/9765] Loss_D: 0.0911 Loss_G: 0.0402 Convergence: 0.0955 k= 0.028076 lr = 0.0000397\n",
      "[5/25][5880/9765] Loss_D: 0.0996 Loss_G: 0.0410 Convergence: 0.1014 k= 0.028079 lr = 0.0000397\n",
      "[5/25][5890/9765] Loss_D: 0.0927 Loss_G: 0.0423 Convergence: 0.0987 k= 0.028072 lr = 0.0000397\n",
      "[5/25][5900/9765] Loss_D: 0.0952 Loss_G: 0.0357 Convergence: 0.0990 k= 0.028068 lr = 0.0000397\n",
      "[5/25][5910/9765] Loss_D: 0.1027 Loss_G: 0.0401 Convergence: 0.1051 k= 0.028109 lr = 0.0000397\n",
      "[5/25][5920/9765] Loss_D: 0.0968 Loss_G: 0.0476 Convergence: 0.1065 k= 0.028082 lr = 0.0000397\n",
      "[5/25][5930/9765] Loss_D: 0.0961 Loss_G: 0.0424 Convergence: 0.1009 k= 0.028054 lr = 0.0000397\n",
      "[5/25][5940/9765] Loss_D: 0.1110 Loss_G: 0.0365 Convergence: 0.1203 k= 0.028081 lr = 0.0000397\n",
      "[5/25][5950/9765] Loss_D: 0.0977 Loss_G: 0.0467 Convergence: 0.1061 k= 0.028070 lr = 0.0000397\n",
      "[5/25][5960/9765] Loss_D: 0.0949 Loss_G: 0.0386 Convergence: 0.0964 k= 0.028045 lr = 0.0000397\n",
      "[5/25][5970/9765] Loss_D: 0.1148 Loss_G: 0.0368 Convergence: 0.1252 k= 0.028071 lr = 0.0000397\n",
      "[5/25][5980/9765] Loss_D: 0.1147 Loss_G: 0.0412 Convergence: 0.1209 k= 0.028114 lr = 0.0000397\n",
      "[5/25][5990/9765] Loss_D: 0.1002 Loss_G: 0.0442 Convergence: 0.1050 k= 0.028096 lr = 0.0000397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][6000/9765] Loss_D: 0.0983 Loss_G: 0.0407 Convergence: 0.1003 k= 0.028082 lr = 0.0000397\n",
      "[5/25][6010/9765] Loss_D: 0.1034 Loss_G: 0.0395 Convergence: 0.1069 k= 0.028104 lr = 0.0000397\n",
      "[5/25][6020/9765] Loss_D: 0.0931 Loss_G: 0.0437 Convergence: 0.1003 k= 0.028081 lr = 0.0000397\n",
      "[5/25][6030/9765] Loss_D: 0.0958 Loss_G: 0.0434 Convergence: 0.1016 k= 0.028085 lr = 0.0000397\n",
      "[5/25][6040/9765] Loss_D: 0.1020 Loss_G: 0.0419 Convergence: 0.1038 k= 0.028077 lr = 0.0000397\n",
      "[5/25][6050/9765] Loss_D: 0.0977 Loss_G: 0.0396 Convergence: 0.0989 k= 0.028085 lr = 0.0000397\n",
      "[5/25][6060/9765] Loss_D: 0.0948 Loss_G: 0.0411 Convergence: 0.0986 k= 0.028098 lr = 0.0000397\n",
      "[5/25][6070/9765] Loss_D: 0.0961 Loss_G: 0.0403 Convergence: 0.0987 k= 0.028094 lr = 0.0000397\n",
      "[5/25][6080/9765] Loss_D: 0.1052 Loss_G: 0.0381 Convergence: 0.1109 k= 0.028124 lr = 0.0000397\n",
      "[5/25][6090/9765] Loss_D: 0.1071 Loss_G: 0.0380 Convergence: 0.1133 k= 0.028139 lr = 0.0000397\n",
      "[5/25][6100/9765] Loss_D: 0.1025 Loss_G: 0.0482 Convergence: 0.1105 k= 0.028128 lr = 0.0000397\n",
      "[5/25][6110/9765] Loss_D: 0.1063 Loss_G: 0.0409 Convergence: 0.1093 k= 0.028121 lr = 0.0000397\n",
      "[5/25][6120/9765] Loss_D: 0.0992 Loss_G: 0.0428 Convergence: 0.1031 k= 0.028104 lr = 0.0000397\n",
      "[5/25][6130/9765] Loss_D: 0.0921 Loss_G: 0.0368 Convergence: 0.0936 k= 0.028104 lr = 0.0000397\n",
      "[5/25][6140/9765] Loss_D: 0.1024 Loss_G: 0.0361 Convergence: 0.1086 k= 0.028146 lr = 0.0000397\n",
      "[5/25][6150/9765] Loss_D: 0.1099 Loss_G: 0.0364 Convergence: 0.1189 k= 0.028187 lr = 0.0000397\n",
      "[5/25][6160/9765] Loss_D: 0.0938 Loss_G: 0.0505 Convergence: 0.1076 k= 0.028123 lr = 0.0000397\n",
      "[5/25][6170/9765] Loss_D: 0.1019 Loss_G: 0.0374 Convergence: 0.1067 k= 0.028105 lr = 0.0000397\n",
      "[5/25][6180/9765] Loss_D: 0.1074 Loss_G: 0.0398 Convergence: 0.1121 k= 0.028136 lr = 0.0000397\n",
      "[5/25][6190/9765] Loss_D: 0.0955 Loss_G: 0.0368 Convergence: 0.0985 k= 0.028151 lr = 0.0000397\n",
      "[5/25][6200/9765] Loss_D: 0.0960 Loss_G: 0.0454 Convergence: 0.1037 k= 0.028138 lr = 0.0000397\n",
      "[5/25][6210/9765] Loss_D: 0.1078 Loss_G: 0.0420 Convergence: 0.1105 k= 0.028108 lr = 0.0000397\n",
      "[5/25][6220/9765] Loss_D: 0.0989 Loss_G: 0.0389 Convergence: 0.1012 k= 0.028111 lr = 0.0000397\n",
      "[5/25][6230/9765] Loss_D: 0.1073 Loss_G: 0.0435 Convergence: 0.1087 k= 0.028113 lr = 0.0000397\n",
      "[5/25][6240/9765] Loss_D: 0.1056 Loss_G: 0.0391 Convergence: 0.1102 k= 0.028115 lr = 0.0000397\n",
      "[5/25][6250/9765] Loss_D: 0.1023 Loss_G: 0.0410 Convergence: 0.1036 k= 0.028135 lr = 0.0000397\n",
      "[5/25][6260/9765] Loss_D: 0.1003 Loss_G: 0.0355 Convergence: 0.1064 k= 0.028176 lr = 0.0000397\n",
      "[5/25][6270/9765] Loss_D: 0.1089 Loss_G: 0.0439 Convergence: 0.1101 k= 0.028163 lr = 0.0000397\n",
      "[5/25][6280/9765] Loss_D: 0.1005 Loss_G: 0.0389 Convergence: 0.1033 k= 0.028150 lr = 0.0000397\n",
      "[5/25][6290/9765] Loss_D: 0.1015 Loss_G: 0.0405 Convergence: 0.1032 k= 0.028175 lr = 0.0000397\n",
      "[5/25][6300/9765] Loss_D: 0.0998 Loss_G: 0.0421 Convergence: 0.1028 k= 0.028169 lr = 0.0000397\n",
      "[5/25][6310/9765] Loss_D: 0.0981 Loss_G: 0.0397 Convergence: 0.0993 k= 0.028173 lr = 0.0000397\n",
      "[5/25][6320/9765] Loss_D: 0.1062 Loss_G: 0.0393 Convergence: 0.1110 k= 0.028186 lr = 0.0000397\n",
      "[5/25][6330/9765] Loss_D: 0.1088 Loss_G: 0.0427 Convergence: 0.1113 k= 0.028180 lr = 0.0000397\n",
      "[5/25][6340/9765] Loss_D: 0.0970 Loss_G: 0.0378 Convergence: 0.0995 k= 0.028184 lr = 0.0000397\n",
      "[5/25][6350/9765] Loss_D: 0.0996 Loss_G: 0.0413 Convergence: 0.1018 k= 0.028183 lr = 0.0000397\n",
      "[5/25][6360/9765] Loss_D: 0.1092 Loss_G: 0.0431 Convergence: 0.1115 k= 0.028197 lr = 0.0000397\n",
      "[5/25][6370/9765] Loss_D: 0.1059 Loss_G: 0.0386 Convergence: 0.1112 k= 0.028196 lr = 0.0000397\n",
      "[5/25][6380/9765] Loss_D: 0.1138 Loss_G: 0.0405 Convergence: 0.1204 k= 0.028202 lr = 0.0000397\n",
      "[5/25][6390/9765] Loss_D: 0.1002 Loss_G: 0.0411 Convergence: 0.1019 k= 0.028198 lr = 0.0000397\n",
      "[5/25][6400/9765] Loss_D: 0.1164 Loss_G: 0.0449 Convergence: 0.1198 k= 0.028180 lr = 0.0000397\n",
      "[5/25][6410/9765] Loss_D: 0.1088 Loss_G: 0.0437 Convergence: 0.1104 k= 0.028169 lr = 0.0000397\n",
      "[5/25][6420/9765] Loss_D: 0.1137 Loss_G: 0.0452 Convergence: 0.1157 k= 0.028183 lr = 0.0000397\n",
      "[5/25][6430/9765] Loss_D: 0.1031 Loss_G: 0.0423 Convergence: 0.1048 k= 0.028146 lr = 0.0000397\n",
      "[5/25][6440/9765] Loss_D: 0.0997 Loss_G: 0.0451 Convergence: 0.1056 k= 0.028136 lr = 0.0000397\n",
      "[5/25][6450/9765] Loss_D: 0.1065 Loss_G: 0.0410 Convergence: 0.1098 k= 0.028135 lr = 0.0000397\n",
      "[5/25][6460/9765] Loss_D: 0.0974 Loss_G: 0.0416 Convergence: 0.1007 k= 0.028164 lr = 0.0000397\n",
      "[5/25][6470/9765] Loss_D: 0.1034 Loss_G: 0.0444 Convergence: 0.1072 k= 0.028165 lr = 0.0000397\n",
      "[5/25][6480/9765] Loss_D: 0.0967 Loss_G: 0.0357 Convergence: 0.1012 k= 0.028155 lr = 0.0000397\n",
      "[5/25][6490/9765] Loss_D: 0.1036 Loss_G: 0.0399 Convergence: 0.1066 k= 0.028165 lr = 0.0000397\n",
      "[5/25][6500/9765] Loss_D: 0.0977 Loss_G: 0.0492 Convergence: 0.1086 k= 0.028122 lr = 0.0000397\n",
      "[5/25][6510/9765] Loss_D: 0.1091 Loss_G: 0.0385 Convergence: 0.1158 k= 0.028127 lr = 0.0000397\n",
      "[5/25][6520/9765] Loss_D: 0.0949 Loss_G: 0.0403 Convergence: 0.0979 k= 0.028118 lr = 0.0000397\n",
      "[5/25][6530/9765] Loss_D: 0.0995 Loss_G: 0.0399 Convergence: 0.1011 k= 0.028115 lr = 0.0000397\n",
      "[5/25][6540/9765] Loss_D: 0.1098 Loss_G: 0.0413 Convergence: 0.1141 k= 0.028102 lr = 0.0000397\n",
      "[5/25][6550/9765] Loss_D: 0.0979 Loss_G: 0.0418 Convergence: 0.1013 k= 0.028092 lr = 0.0000397\n",
      "[5/25][6560/9765] Loss_D: 0.1011 Loss_G: 0.0378 Convergence: 0.1052 k= 0.028098 lr = 0.0000397\n",
      "[5/25][6570/9765] Loss_D: 0.0966 Loss_G: 0.0397 Convergence: 0.0984 k= 0.028116 lr = 0.0000397\n",
      "[5/25][6580/9765] Loss_D: 0.0988 Loss_G: 0.0407 Convergence: 0.1007 k= 0.028102 lr = 0.0000397\n",
      "[5/25][6590/9765] Loss_D: 0.0985 Loss_G: 0.0471 Convergence: 0.1069 k= 0.028103 lr = 0.0000397\n",
      "[5/25][6600/9765] Loss_D: 0.1066 Loss_G: 0.0400 Convergence: 0.1108 k= 0.028090 lr = 0.0000397\n",
      "[5/25][6610/9765] Loss_D: 0.1029 Loss_G: 0.0462 Convergence: 0.1086 k= 0.028076 lr = 0.0000397\n",
      "[5/25][6620/9765] Loss_D: 0.0989 Loss_G: 0.0419 Convergence: 0.1019 k= 0.028068 lr = 0.0000397\n",
      "[5/25][6630/9765] Loss_D: 0.1064 Loss_G: 0.0428 Convergence: 0.1079 k= 0.028020 lr = 0.0000397\n",
      "[5/25][6640/9765] Loss_D: 0.1021 Loss_G: 0.0390 Convergence: 0.1057 k= 0.028024 lr = 0.0000397\n",
      "[5/25][6650/9765] Loss_D: 0.0951 Loss_G: 0.0465 Convergence: 0.1043 k= 0.028012 lr = 0.0000397\n",
      "[5/25][6660/9765] Loss_D: 0.0967 Loss_G: 0.0450 Convergence: 0.1036 k= 0.027964 lr = 0.0000397\n",
      "[5/25][6670/9765] Loss_D: 0.0965 Loss_G: 0.0452 Convergence: 0.1038 k= 0.027963 lr = 0.0000397\n",
      "[5/25][6680/9765] Loss_D: 0.0985 Loss_G: 0.0382 Convergence: 0.1013 k= 0.027978 lr = 0.0000397\n",
      "[5/25][6690/9765] Loss_D: 0.1131 Loss_G: 0.0448 Convergence: 0.1152 k= 0.027976 lr = 0.0000397\n",
      "[5/25][6700/9765] Loss_D: 0.1005 Loss_G: 0.0425 Convergence: 0.1036 k= 0.027975 lr = 0.0000397\n",
      "[5/25][6710/9765] Loss_D: 0.0937 Loss_G: 0.0406 Convergence: 0.0975 k= 0.027977 lr = 0.0000397\n",
      "[5/25][6720/9765] Loss_D: 0.1010 Loss_G: 0.0437 Convergence: 0.1052 k= 0.027966 lr = 0.0000397\n",
      "[5/25][6730/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1026 k= 0.027948 lr = 0.0000397\n",
      "[5/25][6740/9765] Loss_D: 0.1055 Loss_G: 0.0426 Convergence: 0.1066 k= 0.027957 lr = 0.0000397\n",
      "[5/25][6750/9765] Loss_D: 0.1000 Loss_G: 0.0409 Convergence: 0.1017 k= 0.027958 lr = 0.0000397\n",
      "[5/25][6760/9765] Loss_D: 0.1042 Loss_G: 0.0387 Convergence: 0.1087 k= 0.027974 lr = 0.0000397\n",
      "[5/25][6770/9765] Loss_D: 0.1000 Loss_G: 0.0451 Convergence: 0.1058 k= 0.027966 lr = 0.0000397\n",
      "[5/25][6780/9765] Loss_D: 0.0981 Loss_G: 0.0406 Convergence: 0.1002 k= 0.027961 lr = 0.0000397\n",
      "[5/25][6790/9765] Loss_D: 0.1082 Loss_G: 0.0416 Convergence: 0.1116 k= 0.027975 lr = 0.0000397\n",
      "[5/25][6800/9765] Loss_D: 0.1074 Loss_G: 0.0408 Convergence: 0.1111 k= 0.027972 lr = 0.0000397\n",
      "[5/25][6810/9765] Loss_D: 0.0999 Loss_G: 0.0419 Convergence: 0.1026 k= 0.027946 lr = 0.0000397\n",
      "[5/25][6820/9765] Loss_D: 0.1027 Loss_G: 0.0365 Convergence: 0.1091 k= 0.027965 lr = 0.0000397\n",
      "[5/25][6830/9765] Loss_D: 0.0986 Loss_G: 0.0395 Convergence: 0.1002 k= 0.027974 lr = 0.0000397\n",
      "[5/25][6840/9765] Loss_D: 0.1110 Loss_G: 0.0427 Convergence: 0.1142 k= 0.027988 lr = 0.0000397\n",
      "[5/25][6850/9765] Loss_D: 0.1085 Loss_G: 0.0444 Convergence: 0.1102 k= 0.027988 lr = 0.0000397\n",
      "[5/25][6860/9765] Loss_D: 0.1141 Loss_G: 0.0447 Convergence: 0.1169 k= 0.027992 lr = 0.0000397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][6870/9765] Loss_D: 0.1046 Loss_G: 0.0445 Convergence: 0.1080 k= 0.027978 lr = 0.0000397\n",
      "[5/25][6880/9765] Loss_D: 0.1013 Loss_G: 0.0383 Convergence: 0.1051 k= 0.027990 lr = 0.0000397\n",
      "[5/25][6890/9765] Loss_D: 0.1119 Loss_G: 0.0423 Convergence: 0.1160 k= 0.027987 lr = 0.0000397\n",
      "[5/25][6900/9765] Loss_D: 0.0982 Loss_G: 0.0441 Convergence: 0.1037 k= 0.027973 lr = 0.0000397\n",
      "[5/25][6910/9765] Loss_D: 0.1075 Loss_G: 0.0412 Convergence: 0.1109 k= 0.027968 lr = 0.0000397\n",
      "[5/25][6920/9765] Loss_D: 0.1067 Loss_G: 0.0431 Convergence: 0.1079 k= 0.027971 lr = 0.0000397\n",
      "[5/25][6930/9765] Loss_D: 0.0952 Loss_G: 0.0416 Convergence: 0.0994 k= 0.027958 lr = 0.0000397\n",
      "[5/25][6940/9765] Loss_D: 0.1034 Loss_G: 0.0395 Convergence: 0.1068 k= 0.027960 lr = 0.0000397\n",
      "[5/25][6950/9765] Loss_D: 0.0930 Loss_G: 0.0415 Convergence: 0.0980 k= 0.027954 lr = 0.0000397\n",
      "[5/25][6960/9765] Loss_D: 0.1069 Loss_G: 0.0422 Convergence: 0.1090 k= 0.027952 lr = 0.0000397\n",
      "[5/25][6970/9765] Loss_D: 0.1054 Loss_G: 0.0419 Convergence: 0.1072 k= 0.027955 lr = 0.0000397\n",
      "[5/25][6980/9765] Loss_D: 0.0990 Loss_G: 0.0418 Convergence: 0.1019 k= 0.027931 lr = 0.0000397\n",
      "[5/25][6990/9765] Loss_D: 0.1094 Loss_G: 0.0431 Convergence: 0.1119 k= 0.027947 lr = 0.0000397\n",
      "[5/25][7000/9765] Loss_D: 0.0961 Loss_G: 0.0425 Convergence: 0.1008 k= 0.027929 lr = 0.0000397\n",
      "[5/25][7010/9765] Loss_D: 0.1009 Loss_G: 0.0412 Convergence: 0.1025 k= 0.027931 lr = 0.0000397\n",
      "[5/25][7020/9765] Loss_D: 0.0993 Loss_G: 0.0427 Convergence: 0.1030 k= 0.027919 lr = 0.0000397\n",
      "[5/25][7030/9765] Loss_D: 0.1084 Loss_G: 0.0465 Convergence: 0.1124 k= 0.027899 lr = 0.0000397\n",
      "[5/25][7040/9765] Loss_D: 0.1110 Loss_G: 0.0427 Convergence: 0.1143 k= 0.027918 lr = 0.0000397\n",
      "[5/25][7050/9765] Loss_D: 0.1015 Loss_G: 0.0396 Convergence: 0.1042 k= 0.027897 lr = 0.0000397\n",
      "[5/25][7060/9765] Loss_D: 0.0964 Loss_G: 0.0444 Convergence: 0.1029 k= 0.027870 lr = 0.0000397\n",
      "[5/25][7070/9765] Loss_D: 0.1029 Loss_G: 0.0424 Convergence: 0.1049 k= 0.027866 lr = 0.0000397\n",
      "[5/25][7080/9765] Loss_D: 0.1001 Loss_G: 0.0375 Convergence: 0.1041 k= 0.027867 lr = 0.0000397\n",
      "[5/25][7090/9765] Loss_D: 0.0960 Loss_G: 0.0390 Convergence: 0.0973 k= 0.027894 lr = 0.0000397\n",
      "[5/25][7100/9765] Loss_D: 0.0884 Loss_G: 0.0439 Convergence: 0.0977 k= 0.027866 lr = 0.0000397\n",
      "[5/25][7110/9765] Loss_D: 0.0978 Loss_G: 0.0408 Convergence: 0.1002 k= 0.027850 lr = 0.0000397\n",
      "[5/25][7120/9765] Loss_D: 0.1058 Loss_G: 0.0378 Convergence: 0.1118 k= 0.027864 lr = 0.0000397\n",
      "[5/25][7130/9765] Loss_D: 0.1112 Loss_G: 0.0428 Convergence: 0.1146 k= 0.027868 lr = 0.0000397\n",
      "[5/25][7140/9765] Loss_D: 0.1002 Loss_G: 0.0435 Convergence: 0.1044 k= 0.027851 lr = 0.0000397\n",
      "[5/25][7150/9765] Loss_D: 0.1132 Loss_G: 0.0398 Convergence: 0.1202 k= 0.027881 lr = 0.0000397\n",
      "[5/25][7160/9765] Loss_D: 0.1034 Loss_G: 0.0461 Convergence: 0.1089 k= 0.027875 lr = 0.0000397\n",
      "[5/25][7170/9765] Loss_D: 0.1074 Loss_G: 0.0391 Convergence: 0.1130 k= 0.027868 lr = 0.0000397\n",
      "[5/25][7180/9765] Loss_D: 0.0887 Loss_G: 0.0371 Convergence: 0.0909 k= 0.027889 lr = 0.0000397\n",
      "[5/25][7190/9765] Loss_D: 0.0980 Loss_G: 0.0366 Convergence: 0.1021 k= 0.027904 lr = 0.0000397\n",
      "[5/25][7200/9765] Loss_D: 0.0989 Loss_G: 0.0447 Convergence: 0.1048 k= 0.027880 lr = 0.0000397\n",
      "[5/25][7210/9765] Loss_D: 0.0908 Loss_G: 0.0386 Convergence: 0.0938 k= 0.027862 lr = 0.0000397\n",
      "[5/25][7220/9765] Loss_D: 0.0920 Loss_G: 0.0355 Convergence: 0.0948 k= 0.027881 lr = 0.0000397\n",
      "[5/25][7230/9765] Loss_D: 0.0999 Loss_G: 0.0404 Convergence: 0.1010 k= 0.027895 lr = 0.0000397\n",
      "[5/25][7240/9765] Loss_D: 0.1043 Loss_G: 0.0449 Convergence: 0.1082 k= 0.027864 lr = 0.0000397\n",
      "[5/25][7250/9765] Loss_D: 0.0969 Loss_G: 0.0373 Convergence: 0.0999 k= 0.027865 lr = 0.0000397\n",
      "[5/25][7260/9765] Loss_D: 0.1092 Loss_G: 0.0428 Convergence: 0.1116 k= 0.027882 lr = 0.0000397\n",
      "[5/25][7270/9765] Loss_D: 0.1052 Loss_G: 0.0451 Convergence: 0.1090 k= 0.027850 lr = 0.0000397\n",
      "[5/25][7280/9765] Loss_D: 0.1044 Loss_G: 0.0397 Convergence: 0.1080 k= 0.027831 lr = 0.0000397\n",
      "[5/25][7290/9765] Loss_D: 0.0991 Loss_G: 0.0361 Convergence: 0.1042 k= 0.027848 lr = 0.0000397\n",
      "[5/25][7300/9765] Loss_D: 0.1040 Loss_G: 0.0388 Convergence: 0.1083 k= 0.027885 lr = 0.0000397\n",
      "[5/25][7310/9765] Loss_D: 0.0978 Loss_G: 0.0413 Convergence: 0.1007 k= 0.027894 lr = 0.0000397\n",
      "[5/25][7320/9765] Loss_D: 0.0903 Loss_G: 0.0418 Convergence: 0.0967 k= 0.027884 lr = 0.0000397\n",
      "[5/25][7330/9765] Loss_D: 0.1003 Loss_G: 0.0393 Convergence: 0.1025 k= 0.027883 lr = 0.0000397\n",
      "[5/25][7340/9765] Loss_D: 0.1028 Loss_G: 0.0390 Convergence: 0.1064 k= 0.027889 lr = 0.0000397\n",
      "[5/25][7350/9765] Loss_D: 0.1019 Loss_G: 0.0436 Convergence: 0.1054 k= 0.027896 lr = 0.0000397\n",
      "[5/25][7360/9765] Loss_D: 0.0936 Loss_G: 0.0427 Convergence: 0.0995 k= 0.027904 lr = 0.0000397\n",
      "[5/25][7370/9765] Loss_D: 0.1039 Loss_G: 0.0452 Convergence: 0.1083 k= 0.027881 lr = 0.0000397\n",
      "[5/25][7380/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0960 k= 0.027876 lr = 0.0000397\n",
      "[5/25][7390/9765] Loss_D: 0.1061 Loss_G: 0.0379 Convergence: 0.1121 k= 0.027913 lr = 0.0000397\n",
      "[5/25][7400/9765] Loss_D: 0.1128 Loss_G: 0.0461 Convergence: 0.1145 k= 0.027905 lr = 0.0000397\n",
      "[5/25][7410/9765] Loss_D: 0.1007 Loss_G: 0.0379 Convergence: 0.1047 k= 0.027915 lr = 0.0000397\n",
      "[5/25][7420/9765] Loss_D: 0.0989 Loss_G: 0.0422 Convergence: 0.1023 k= 0.027913 lr = 0.0000397\n",
      "[5/25][7430/9765] Loss_D: 0.1011 Loss_G: 0.0468 Convergence: 0.1082 k= 0.027904 lr = 0.0000397\n",
      "[5/25][7440/9765] Loss_D: 0.1048 Loss_G: 0.0397 Convergence: 0.1084 k= 0.027912 lr = 0.0000397\n",
      "[5/25][7450/9765] Loss_D: 0.0954 Loss_G: 0.0401 Convergence: 0.0981 k= 0.027920 lr = 0.0000397\n",
      "[5/25][7460/9765] Loss_D: 0.1002 Loss_G: 0.0373 Convergence: 0.1044 k= 0.027935 lr = 0.0000397\n",
      "[5/25][7470/9765] Loss_D: 0.1129 Loss_G: 0.0457 Convergence: 0.1142 k= 0.027941 lr = 0.0000397\n",
      "[5/25][7480/9765] Loss_D: 0.0981 Loss_G: 0.0392 Convergence: 0.0996 k= 0.027924 lr = 0.0000397\n",
      "[5/25][7490/9765] Loss_D: 0.1079 Loss_G: 0.0422 Convergence: 0.1105 k= 0.027932 lr = 0.0000397\n",
      "[5/25][7500/9765] Loss_D: 0.1021 Loss_G: 0.0416 Convergence: 0.1036 k= 0.027909 lr = 0.0000397\n",
      "[5/25][7510/9765] Loss_D: 0.1084 Loss_G: 0.0458 Convergence: 0.1115 k= 0.027919 lr = 0.0000397\n",
      "[5/25][7520/9765] Loss_D: 0.1108 Loss_G: 0.0413 Convergence: 0.1154 k= 0.027917 lr = 0.0000397\n",
      "[5/25][7530/9765] Loss_D: 0.1025 Loss_G: 0.0403 Convergence: 0.1048 k= 0.027926 lr = 0.0000397\n",
      "[5/25][7540/9765] Loss_D: 0.0999 Loss_G: 0.0438 Convergence: 0.1044 k= 0.027924 lr = 0.0000397\n",
      "[5/25][7550/9765] Loss_D: 0.0982 Loss_G: 0.0405 Convergence: 0.1001 k= 0.027910 lr = 0.0000397\n",
      "[5/25][7560/9765] Loss_D: 0.1038 Loss_G: 0.0393 Convergence: 0.1075 k= 0.027920 lr = 0.0000397\n",
      "[5/25][7570/9765] Loss_D: 0.1052 Loss_G: 0.0420 Convergence: 0.1068 k= 0.027911 lr = 0.0000397\n",
      "[5/25][7580/9765] Loss_D: 0.1017 Loss_G: 0.0410 Convergence: 0.1028 k= 0.027936 lr = 0.0000397\n",
      "[5/25][7590/9765] Loss_D: 0.1075 Loss_G: 0.0426 Convergence: 0.1096 k= 0.027906 lr = 0.0000397\n",
      "[5/25][7600/9765] Loss_D: 0.0928 Loss_G: 0.0379 Convergence: 0.0942 k= 0.027865 lr = 0.0000397\n",
      "[5/25][7610/9765] Loss_D: 0.1058 Loss_G: 0.0379 Convergence: 0.1116 k= 0.027908 lr = 0.0000397\n",
      "[5/25][7620/9765] Loss_D: 0.1058 Loss_G: 0.0460 Convergence: 0.1102 k= 0.027913 lr = 0.0000397\n",
      "[5/25][7630/9765] Loss_D: 0.0987 Loss_G: 0.0426 Convergence: 0.1025 k= 0.027898 lr = 0.0000397\n",
      "[5/25][7640/9765] Loss_D: 0.1057 Loss_G: 0.0420 Convergence: 0.1076 k= 0.027899 lr = 0.0000397\n",
      "[5/25][7650/9765] Loss_D: 0.0994 Loss_G: 0.0411 Convergence: 0.1014 k= 0.027895 lr = 0.0000397\n",
      "[5/25][7660/9765] Loss_D: 0.1087 Loss_G: 0.0410 Convergence: 0.1130 k= 0.027905 lr = 0.0000397\n",
      "[5/25][7670/9765] Loss_D: 0.0988 Loss_G: 0.0430 Convergence: 0.1029 k= 0.027900 lr = 0.0000397\n",
      "[5/25][7680/9765] Loss_D: 0.1113 Loss_G: 0.0397 Convergence: 0.1177 k= 0.027897 lr = 0.0000397\n",
      "[5/25][7690/9765] Loss_D: 0.0995 Loss_G: 0.0358 Convergence: 0.1051 k= 0.027898 lr = 0.0000397\n",
      "[5/25][7700/9765] Loss_D: 0.1056 Loss_G: 0.0402 Convergence: 0.1092 k= 0.027915 lr = 0.0000397\n",
      "[5/25][7710/9765] Loss_D: 0.0946 Loss_G: 0.0420 Convergence: 0.0994 k= 0.027903 lr = 0.0000397\n",
      "[5/25][7720/9765] Loss_D: 0.0972 Loss_G: 0.0433 Convergence: 0.1023 k= 0.027905 lr = 0.0000397\n",
      "[5/25][7730/9765] Loss_D: 0.0988 Loss_G: 0.0406 Convergence: 0.1006 k= 0.027886 lr = 0.0000397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][7740/9765] Loss_D: 0.1029 Loss_G: 0.0413 Convergence: 0.1043 k= 0.027888 lr = 0.0000397\n",
      "[5/25][7750/9765] Loss_D: 0.1041 Loss_G: 0.0415 Convergence: 0.1059 k= 0.027891 lr = 0.0000397\n",
      "[5/25][7760/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.1001 k= 0.027885 lr = 0.0000397\n",
      "[5/25][7770/9765] Loss_D: 0.1049 Loss_G: 0.0427 Convergence: 0.1063 k= 0.027887 lr = 0.0000397\n",
      "[5/25][7780/9765] Loss_D: 0.0980 Loss_G: 0.0440 Convergence: 0.1035 k= 0.027867 lr = 0.0000397\n",
      "[5/25][7790/9765] Loss_D: 0.1014 Loss_G: 0.0424 Convergence: 0.1039 k= 0.027834 lr = 0.0000397\n",
      "[5/25][7800/9765] Loss_D: 0.0985 Loss_G: 0.0395 Convergence: 0.1000 k= 0.027820 lr = 0.0000397\n",
      "[5/25][7810/9765] Loss_D: 0.0970 Loss_G: 0.0390 Convergence: 0.0982 k= 0.027849 lr = 0.0000397\n",
      "[5/25][7820/9765] Loss_D: 0.1039 Loss_G: 0.0496 Convergence: 0.1129 k= 0.027812 lr = 0.0000397\n",
      "[5/25][7830/9765] Loss_D: 0.0946 Loss_G: 0.0432 Convergence: 0.1007 k= 0.027758 lr = 0.0000397\n",
      "[5/25][7840/9765] Loss_D: 0.1049 Loss_G: 0.0372 Convergence: 0.1112 k= 0.027771 lr = 0.0000397\n",
      "[5/25][7850/9765] Loss_D: 0.0995 Loss_G: 0.0398 Convergence: 0.1011 k= 0.027764 lr = 0.0000397\n",
      "[5/25][7860/9765] Loss_D: 0.1007 Loss_G: 0.0441 Convergence: 0.1052 k= 0.027741 lr = 0.0000397\n",
      "[5/25][7870/9765] Loss_D: 0.1060 Loss_G: 0.0400 Convergence: 0.1099 k= 0.027763 lr = 0.0000397\n",
      "[5/25][7880/9765] Loss_D: 0.1028 Loss_G: 0.0461 Convergence: 0.1085 k= 0.027755 lr = 0.0000397\n",
      "[5/25][7890/9765] Loss_D: 0.1053 Loss_G: 0.0412 Convergence: 0.1078 k= 0.027750 lr = 0.0000397\n",
      "[5/25][7900/9765] Loss_D: 0.0971 Loss_G: 0.0388 Convergence: 0.0986 k= 0.027759 lr = 0.0000397\n",
      "[5/25][7910/9765] Loss_D: 0.1016 Loss_G: 0.0412 Convergence: 0.1029 k= 0.027744 lr = 0.0000397\n",
      "[5/25][7920/9765] Loss_D: 0.1005 Loss_G: 0.0393 Convergence: 0.1028 k= 0.027760 lr = 0.0000397\n",
      "[5/25][7930/9765] Loss_D: 0.1022 Loss_G: 0.0421 Convergence: 0.1041 k= 0.027760 lr = 0.0000397\n",
      "[5/25][7940/9765] Loss_D: 0.0986 Loss_G: 0.0437 Convergence: 0.1036 k= 0.027756 lr = 0.0000397\n",
      "[5/25][7950/9765] Loss_D: 0.0948 Loss_G: 0.0416 Convergence: 0.0992 k= 0.027745 lr = 0.0000397\n",
      "[5/25][7960/9765] Loss_D: 0.1109 Loss_G: 0.0394 Convergence: 0.1175 k= 0.027745 lr = 0.0000397\n",
      "[5/25][7970/9765] Loss_D: 0.1102 Loss_G: 0.0441 Convergence: 0.1119 k= 0.027749 lr = 0.0000397\n",
      "[5/25][7980/9765] Loss_D: 0.1034 Loss_G: 0.0457 Convergence: 0.1085 k= 0.027723 lr = 0.0000397\n",
      "[5/25][7990/9765] Loss_D: 0.0951 Loss_G: 0.0397 Convergence: 0.0974 k= 0.027717 lr = 0.0000397\n",
      "[5/25][8000/9765] Loss_D: 0.1039 Loss_G: 0.0385 Convergence: 0.1085 k= 0.027734 lr = 0.0000397\n",
      "[5/25][8010/9765] Loss_D: 0.1010 Loss_G: 0.0411 Convergence: 0.1023 k= 0.027737 lr = 0.0000397\n",
      "[5/25][8020/9765] Loss_D: 0.1008 Loss_G: 0.0385 Convergence: 0.1041 k= 0.027758 lr = 0.0000397\n",
      "[5/25][8030/9765] Loss_D: 0.1003 Loss_G: 0.0425 Convergence: 0.1034 k= 0.027747 lr = 0.0000397\n",
      "[5/25][8040/9765] Loss_D: 0.1077 Loss_G: 0.0457 Convergence: 0.1110 k= 0.027750 lr = 0.0000397\n",
      "[5/25][8050/9765] Loss_D: 0.1073 Loss_G: 0.0442 Convergence: 0.1093 k= 0.027733 lr = 0.0000397\n",
      "[5/25][8060/9765] Loss_D: 0.1016 Loss_G: 0.0433 Convergence: 0.1050 k= 0.027724 lr = 0.0000397\n",
      "[5/25][8070/9765] Loss_D: 0.1015 Loss_G: 0.0378 Convergence: 0.1057 k= 0.027730 lr = 0.0000397\n",
      "[5/25][8080/9765] Loss_D: 0.1122 Loss_G: 0.0390 Convergence: 0.1196 k= 0.027740 lr = 0.0000397\n",
      "[5/25][8090/9765] Loss_D: 0.1088 Loss_G: 0.0452 Convergence: 0.1111 k= 0.027743 lr = 0.0000397\n",
      "[5/25][8100/9765] Loss_D: 0.1060 Loss_G: 0.0462 Convergence: 0.1106 k= 0.027706 lr = 0.0000397\n",
      "[5/25][8110/9765] Loss_D: 0.0931 Loss_G: 0.0369 Convergence: 0.0950 k= 0.027716 lr = 0.0000397\n",
      "[5/25][8120/9765] Loss_D: 0.1034 Loss_G: 0.0375 Convergence: 0.1088 k= 0.027736 lr = 0.0000397\n",
      "[5/25][8130/9765] Loss_D: 0.0930 Loss_G: 0.0414 Convergence: 0.0979 k= 0.027735 lr = 0.0000397\n",
      "[5/25][8140/9765] Loss_D: 0.1093 Loss_G: 0.0388 Convergence: 0.1158 k= 0.027729 lr = 0.0000397\n",
      "[5/25][8150/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0980 k= 0.027752 lr = 0.0000397\n",
      "[5/25][8160/9765] Loss_D: 0.1061 Loss_G: 0.0386 Convergence: 0.1114 k= 0.027800 lr = 0.0000397\n",
      "[5/25][8170/9765] Loss_D: 0.1071 Loss_G: 0.0487 Convergence: 0.1137 k= 0.027782 lr = 0.0000397\n",
      "[5/25][8180/9765] Loss_D: 0.0963 Loss_G: 0.0437 Convergence: 0.1021 k= 0.027760 lr = 0.0000377\n",
      "[5/25][8190/9765] Loss_D: 0.0991 Loss_G: 0.0440 Convergence: 0.1042 k= 0.027761 lr = 0.0000377\n",
      "[5/25][8200/9765] Loss_D: 0.0947 Loss_G: 0.0360 Convergence: 0.0981 k= 0.027771 lr = 0.0000377\n",
      "[5/25][8210/9765] Loss_D: 0.0954 Loss_G: 0.0382 Convergence: 0.0970 k= 0.027773 lr = 0.0000377\n",
      "[5/25][8220/9765] Loss_D: 0.1106 Loss_G: 0.0373 Convergence: 0.1191 k= 0.027783 lr = 0.0000377\n",
      "[5/25][8230/9765] Loss_D: 0.1024 Loss_G: 0.0373 Convergence: 0.1075 k= 0.027821 lr = 0.0000377\n",
      "[5/25][8240/9765] Loss_D: 0.0994 Loss_G: 0.0434 Convergence: 0.1037 k= 0.027836 lr = 0.0000377\n",
      "[5/25][8250/9765] Loss_D: 0.1100 Loss_G: 0.0408 Convergence: 0.1147 k= 0.027816 lr = 0.0000377\n",
      "[5/25][8260/9765] Loss_D: 0.1066 Loss_G: 0.0433 Convergence: 0.1080 k= 0.027814 lr = 0.0000377\n",
      "[5/25][8270/9765] Loss_D: 0.1093 Loss_G: 0.0403 Convergence: 0.1143 k= 0.027816 lr = 0.0000377\n",
      "[5/25][8280/9765] Loss_D: 0.1002 Loss_G: 0.0435 Convergence: 0.1043 k= 0.027817 lr = 0.0000377\n",
      "[5/25][8290/9765] Loss_D: 0.1096 Loss_G: 0.0400 Convergence: 0.1150 k= 0.027828 lr = 0.0000377\n",
      "[5/25][8300/9765] Loss_D: 0.1004 Loss_G: 0.0401 Convergence: 0.1021 k= 0.027813 lr = 0.0000377\n",
      "[5/25][8310/9765] Loss_D: 0.0936 Loss_G: 0.0429 Convergence: 0.0997 k= 0.027806 lr = 0.0000377\n",
      "[5/25][8320/9765] Loss_D: 0.0972 Loss_G: 0.0388 Convergence: 0.0987 k= 0.027820 lr = 0.0000377\n",
      "[5/25][8330/9765] Loss_D: 0.0944 Loss_G: 0.0423 Convergence: 0.0997 k= 0.027795 lr = 0.0000377\n",
      "[5/25][8340/9765] Loss_D: 0.1122 Loss_G: 0.0390 Convergence: 0.1196 k= 0.027802 lr = 0.0000377\n",
      "[5/25][8350/9765] Loss_D: 0.1047 Loss_G: 0.0435 Convergence: 0.1070 k= 0.027815 lr = 0.0000377\n",
      "[5/25][8360/9765] Loss_D: 0.0950 Loss_G: 0.0426 Convergence: 0.1003 k= 0.027827 lr = 0.0000377\n",
      "[5/25][8370/9765] Loss_D: 0.1050 Loss_G: 0.0420 Convergence: 0.1066 k= 0.027807 lr = 0.0000377\n",
      "[5/25][8380/9765] Loss_D: 0.0995 Loss_G: 0.0411 Convergence: 0.1014 k= 0.027830 lr = 0.0000377\n",
      "[5/25][8390/9765] Loss_D: 0.0888 Loss_G: 0.0392 Convergence: 0.0932 k= 0.027836 lr = 0.0000377\n",
      "[5/25][8400/9765] Loss_D: 0.1156 Loss_G: 0.0443 Convergence: 0.1192 k= 0.027836 lr = 0.0000377\n",
      "[5/25][8410/9765] Loss_D: 0.0975 Loss_G: 0.0380 Convergence: 0.0999 k= 0.027837 lr = 0.0000377\n",
      "[5/25][8420/9765] Loss_D: 0.1019 Loss_G: 0.0355 Convergence: 0.1087 k= 0.027848 lr = 0.0000377\n",
      "[5/25][8430/9765] Loss_D: 0.0950 Loss_G: 0.0445 Convergence: 0.1022 k= 0.027860 lr = 0.0000377\n",
      "[5/25][8440/9765] Loss_D: 0.0989 Loss_G: 0.0378 Convergence: 0.1020 k= 0.027869 lr = 0.0000377\n",
      "[5/25][8450/9765] Loss_D: 0.1067 Loss_G: 0.0420 Convergence: 0.1090 k= 0.027907 lr = 0.0000377\n",
      "[5/25][8460/9765] Loss_D: 0.0975 Loss_G: 0.0490 Convergence: 0.1082 k= 0.027888 lr = 0.0000377\n",
      "[5/25][8470/9765] Loss_D: 0.1141 Loss_G: 0.0421 Convergence: 0.1191 k= 0.027856 lr = 0.0000377\n",
      "[5/25][8480/9765] Loss_D: 0.1013 Loss_G: 0.0405 Convergence: 0.1027 k= 0.027902 lr = 0.0000377\n",
      "[5/25][8490/9765] Loss_D: 0.1018 Loss_G: 0.0411 Convergence: 0.1027 k= 0.027926 lr = 0.0000377\n",
      "[5/25][8500/9765] Loss_D: 0.1014 Loss_G: 0.0402 Convergence: 0.1033 k= 0.027927 lr = 0.0000377\n",
      "[5/25][8510/9765] Loss_D: 0.1038 Loss_G: 0.0437 Convergence: 0.1067 k= 0.027938 lr = 0.0000377\n",
      "[5/25][8520/9765] Loss_D: 0.1001 Loss_G: 0.0391 Convergence: 0.1026 k= 0.027950 lr = 0.0000377\n",
      "[5/25][8530/9765] Loss_D: 0.1095 Loss_G: 0.0419 Convergence: 0.1132 k= 0.027924 lr = 0.0000377\n",
      "[5/25][8540/9765] Loss_D: 0.1045 Loss_G: 0.0415 Convergence: 0.1064 k= 0.027910 lr = 0.0000377\n",
      "[5/25][8550/9765] Loss_D: 0.1055 Loss_G: 0.0427 Convergence: 0.1067 k= 0.027920 lr = 0.0000377\n",
      "[5/25][8560/9765] Loss_D: 0.0977 Loss_G: 0.0394 Convergence: 0.0991 k= 0.027918 lr = 0.0000377\n",
      "[5/25][8570/9765] Loss_D: 0.1087 Loss_G: 0.0386 Convergence: 0.1149 k= 0.027953 lr = 0.0000377\n",
      "[5/25][8580/9765] Loss_D: 0.1022 Loss_G: 0.0406 Convergence: 0.1041 k= 0.027959 lr = 0.0000377\n",
      "[5/25][8590/9765] Loss_D: 0.0949 Loss_G: 0.0411 Convergence: 0.0988 k= 0.027936 lr = 0.0000377\n",
      "[5/25][8600/9765] Loss_D: 0.0918 Loss_G: 0.0409 Convergence: 0.0966 k= 0.027944 lr = 0.0000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][8610/9765] Loss_D: 0.1011 Loss_G: 0.0395 Convergence: 0.1034 k= 0.027949 lr = 0.0000377\n",
      "[5/25][8620/9765] Loss_D: 0.1003 Loss_G: 0.0429 Convergence: 0.1038 k= 0.027948 lr = 0.0000377\n",
      "[5/25][8630/9765] Loss_D: 0.1052 Loss_G: 0.0407 Convergence: 0.1080 k= 0.027945 lr = 0.0000377\n",
      "[5/25][8640/9765] Loss_D: 0.0953 Loss_G: 0.0401 Convergence: 0.0980 k= 0.027950 lr = 0.0000377\n",
      "[5/25][8650/9765] Loss_D: 0.0925 Loss_G: 0.0428 Convergence: 0.0991 k= 0.027923 lr = 0.0000377\n",
      "[5/25][8660/9765] Loss_D: 0.0976 Loss_G: 0.0412 Convergence: 0.1004 k= 0.027926 lr = 0.0000377\n",
      "[5/25][8670/9765] Loss_D: 0.0999 Loss_G: 0.0405 Convergence: 0.1011 k= 0.027929 lr = 0.0000377\n",
      "[5/25][8680/9765] Loss_D: 0.0961 Loss_G: 0.0412 Convergence: 0.0996 k= 0.027922 lr = 0.0000377\n",
      "[5/25][8690/9765] Loss_D: 0.0981 Loss_G: 0.0440 Convergence: 0.1035 k= 0.027919 lr = 0.0000377\n",
      "[5/25][8700/9765] Loss_D: 0.0987 Loss_G: 0.0416 Convergence: 0.1015 k= 0.027917 lr = 0.0000377\n",
      "[5/25][8710/9765] Loss_D: 0.1102 Loss_G: 0.0396 Convergence: 0.1161 k= 0.027914 lr = 0.0000377\n",
      "[5/25][8720/9765] Loss_D: 0.0918 Loss_G: 0.0409 Convergence: 0.0967 k= 0.027926 lr = 0.0000377\n",
      "[5/25][8730/9765] Loss_D: 0.1015 Loss_G: 0.0414 Convergence: 0.1029 k= 0.027927 lr = 0.0000377\n",
      "[5/25][8740/9765] Loss_D: 0.1037 Loss_G: 0.0448 Convergence: 0.1077 k= 0.027921 lr = 0.0000377\n",
      "[5/25][8750/9765] Loss_D: 0.1088 Loss_G: 0.0407 Convergence: 0.1133 k= 0.027922 lr = 0.0000377\n",
      "[5/25][8760/9765] Loss_D: 0.0994 Loss_G: 0.0414 Convergence: 0.1018 k= 0.027923 lr = 0.0000377\n",
      "[5/25][8770/9765] Loss_D: 0.1040 Loss_G: 0.0446 Convergence: 0.1078 k= 0.027905 lr = 0.0000377\n",
      "[5/25][8780/9765] Loss_D: 0.1055 Loss_G: 0.0411 Convergence: 0.1084 k= 0.027876 lr = 0.0000377\n",
      "[5/25][8790/9765] Loss_D: 0.0920 Loss_G: 0.0432 Convergence: 0.0991 k= 0.027884 lr = 0.0000377\n",
      "[5/25][8800/9765] Loss_D: 0.0919 Loss_G: 0.0408 Convergence: 0.0966 k= 0.027887 lr = 0.0000377\n",
      "[5/25][8810/9765] Loss_D: 0.0913 Loss_G: 0.0427 Convergence: 0.0983 k= 0.027867 lr = 0.0000377\n",
      "[5/25][8820/9765] Loss_D: 0.0978 Loss_G: 0.0423 Convergence: 0.1016 k= 0.027873 lr = 0.0000377\n",
      "[5/25][8830/9765] Loss_D: 0.1051 Loss_G: 0.0397 Convergence: 0.1089 k= 0.027881 lr = 0.0000377\n",
      "[5/25][8840/9765] Loss_D: 0.1102 Loss_G: 0.0419 Convergence: 0.1140 k= 0.027883 lr = 0.0000377\n",
      "[5/25][8850/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1006 k= 0.027877 lr = 0.0000377\n",
      "[5/25][8860/9765] Loss_D: 0.1121 Loss_G: 0.0410 Convergence: 0.1177 k= 0.027878 lr = 0.0000377\n",
      "[5/25][8870/9765] Loss_D: 0.1043 Loss_G: 0.0499 Convergence: 0.1132 k= 0.027841 lr = 0.0000377\n",
      "[5/25][8880/9765] Loss_D: 0.1041 Loss_G: 0.0401 Convergence: 0.1071 k= 0.027846 lr = 0.0000377\n",
      "[5/25][8890/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0987 k= 0.027856 lr = 0.0000377\n",
      "[5/25][8900/9765] Loss_D: 0.0966 Loss_G: 0.0443 Convergence: 0.1030 k= 0.027831 lr = 0.0000377\n",
      "[5/25][8910/9765] Loss_D: 0.0973 Loss_G: 0.0391 Convergence: 0.0987 k= 0.027813 lr = 0.0000377\n",
      "[5/25][8920/9765] Loss_D: 0.1005 Loss_G: 0.0385 Convergence: 0.1038 k= 0.027835 lr = 0.0000377\n",
      "[5/25][8930/9765] Loss_D: 0.1043 Loss_G: 0.0451 Convergence: 0.1085 k= 0.027842 lr = 0.0000377\n",
      "[5/25][8940/9765] Loss_D: 0.0990 Loss_G: 0.0461 Convergence: 0.1063 k= 0.027814 lr = 0.0000377\n",
      "[5/25][8950/9765] Loss_D: 0.1054 Loss_G: 0.0361 Convergence: 0.1130 k= 0.027817 lr = 0.0000377\n",
      "[5/25][8960/9765] Loss_D: 0.0914 Loss_G: 0.0415 Convergence: 0.0971 k= 0.027825 lr = 0.0000377\n",
      "[5/25][8970/9765] Loss_D: 0.1074 Loss_G: 0.0423 Convergence: 0.1095 k= 0.027835 lr = 0.0000377\n",
      "[5/25][8980/9765] Loss_D: 0.1062 Loss_G: 0.0400 Convergence: 0.1104 k= 0.027805 lr = 0.0000377\n",
      "[5/25][8990/9765] Loss_D: 0.0985 Loss_G: 0.0435 Convergence: 0.1032 k= 0.027802 lr = 0.0000377\n",
      "[5/25][9000/9765] Loss_D: 0.0936 Loss_G: 0.0405 Convergence: 0.0974 k= 0.027788 lr = 0.0000377\n",
      "[5/25][9010/9765] Loss_D: 0.1019 Loss_G: 0.0405 Convergence: 0.1037 k= 0.027793 lr = 0.0000377\n",
      "[5/25][9020/9765] Loss_D: 0.1059 Loss_G: 0.0427 Convergence: 0.1072 k= 0.027789 lr = 0.0000377\n",
      "[5/25][9030/9765] Loss_D: 0.0977 Loss_G: 0.0420 Convergence: 0.1013 k= 0.027807 lr = 0.0000377\n",
      "[5/25][9040/9765] Loss_D: 0.0951 Loss_G: 0.0411 Convergence: 0.0989 k= 0.027815 lr = 0.0000377\n",
      "[5/25][9050/9765] Loss_D: 0.1054 Loss_G: 0.0455 Convergence: 0.1095 k= 0.027815 lr = 0.0000377\n",
      "[5/25][9060/9765] Loss_D: 0.1094 Loss_G: 0.0425 Convergence: 0.1123 k= 0.027817 lr = 0.0000377\n",
      "[5/25][9070/9765] Loss_D: 0.1027 Loss_G: 0.0419 Convergence: 0.1042 k= 0.027825 lr = 0.0000377\n",
      "[5/25][9080/9765] Loss_D: 0.0974 Loss_G: 0.0374 Convergence: 0.1004 k= 0.027829 lr = 0.0000377\n",
      "[5/25][9090/9765] Loss_D: 0.1050 Loss_G: 0.0387 Convergence: 0.1098 k= 0.027828 lr = 0.0000377\n",
      "[5/25][9100/9765] Loss_D: 0.0908 Loss_G: 0.0408 Convergence: 0.0959 k= 0.027821 lr = 0.0000377\n",
      "[5/25][9110/9765] Loss_D: 0.0966 Loss_G: 0.0397 Convergence: 0.0983 k= 0.027803 lr = 0.0000377\n",
      "[5/25][9120/9765] Loss_D: 0.1019 Loss_G: 0.0463 Convergence: 0.1082 k= 0.027783 lr = 0.0000377\n",
      "[5/25][9130/9765] Loss_D: 0.0995 Loss_G: 0.0430 Convergence: 0.1035 k= 0.027785 lr = 0.0000377\n",
      "[5/25][9140/9765] Loss_D: 0.1028 Loss_G: 0.0362 Convergence: 0.1093 k= 0.027800 lr = 0.0000377\n",
      "[5/25][9150/9765] Loss_D: 0.1088 Loss_G: 0.0465 Convergence: 0.1125 k= 0.027812 lr = 0.0000377\n",
      "[5/25][9160/9765] Loss_D: 0.1026 Loss_G: 0.0429 Convergence: 0.1052 k= 0.027779 lr = 0.0000377\n",
      "[5/25][9170/9765] Loss_D: 0.1044 Loss_G: 0.0387 Convergence: 0.1091 k= 0.027762 lr = 0.0000377\n",
      "[5/25][9180/9765] Loss_D: 0.0956 Loss_G: 0.0382 Convergence: 0.0972 k= 0.027746 lr = 0.0000377\n",
      "[5/25][9190/9765] Loss_D: 0.1008 Loss_G: 0.0445 Convergence: 0.1057 k= 0.027717 lr = 0.0000377\n",
      "[5/25][9200/9765] Loss_D: 0.1028 Loss_G: 0.0393 Convergence: 0.1061 k= 0.027719 lr = 0.0000377\n",
      "[5/25][9210/9765] Loss_D: 0.1095 Loss_G: 0.0381 Convergence: 0.1167 k= 0.027724 lr = 0.0000377\n",
      "[5/25][9220/9765] Loss_D: 0.1061 Loss_G: 0.0380 Convergence: 0.1120 k= 0.027753 lr = 0.0000377\n",
      "[5/25][9230/9765] Loss_D: 0.0972 Loss_G: 0.0475 Convergence: 0.1066 k= 0.027740 lr = 0.0000377\n",
      "[5/25][9240/9765] Loss_D: 0.0989 Loss_G: 0.0400 Convergence: 0.1000 k= 0.027703 lr = 0.0000377\n",
      "[5/25][9250/9765] Loss_D: 0.0952 Loss_G: 0.0380 Convergence: 0.0968 k= 0.027715 lr = 0.0000377\n",
      "[5/25][9260/9765] Loss_D: 0.1034 Loss_G: 0.0393 Convergence: 0.1068 k= 0.027735 lr = 0.0000377\n",
      "[5/25][9270/9765] Loss_D: 0.1043 Loss_G: 0.0439 Convergence: 0.1072 k= 0.027742 lr = 0.0000377\n",
      "[5/25][9280/9765] Loss_D: 0.1030 Loss_G: 0.0399 Convergence: 0.1057 k= 0.027688 lr = 0.0000377\n",
      "[5/25][9290/9765] Loss_D: 0.1062 Loss_G: 0.0359 Convergence: 0.1142 k= 0.027694 lr = 0.0000377\n",
      "[5/25][9300/9765] Loss_D: 0.1039 Loss_G: 0.0412 Convergence: 0.1058 k= 0.027693 lr = 0.0000377\n",
      "[5/25][9310/9765] Loss_D: 0.0892 Loss_G: 0.0453 Convergence: 0.0995 k= 0.027662 lr = 0.0000377\n",
      "[5/25][9320/9765] Loss_D: 0.1017 Loss_G: 0.0435 Convergence: 0.1053 k= 0.027651 lr = 0.0000377\n",
      "[5/25][9330/9765] Loss_D: 0.1012 Loss_G: 0.0397 Convergence: 0.1034 k= 0.027679 lr = 0.0000377\n",
      "[5/25][9340/9765] Loss_D: 0.1019 Loss_G: 0.0449 Convergence: 0.1067 k= 0.027679 lr = 0.0000377\n",
      "[5/25][9350/9765] Loss_D: 0.0937 Loss_G: 0.0386 Convergence: 0.0954 k= 0.027675 lr = 0.0000377\n",
      "[5/25][9360/9765] Loss_D: 0.0980 Loss_G: 0.0392 Convergence: 0.0995 k= 0.027683 lr = 0.0000377\n",
      "[5/25][9370/9765] Loss_D: 0.0908 Loss_G: 0.0414 Convergence: 0.0966 k= 0.027688 lr = 0.0000377\n",
      "[5/25][9380/9765] Loss_D: 0.0951 Loss_G: 0.0443 Convergence: 0.1020 k= 0.027691 lr = 0.0000377\n",
      "[5/25][9390/9765] Loss_D: 0.1021 Loss_G: 0.0453 Convergence: 0.1073 k= 0.027663 lr = 0.0000377\n",
      "[5/25][9400/9765] Loss_D: 0.0994 Loss_G: 0.0379 Convergence: 0.1028 k= 0.027661 lr = 0.0000377\n",
      "[5/25][9410/9765] Loss_D: 0.0964 Loss_G: 0.0442 Convergence: 0.1028 k= 0.027656 lr = 0.0000377\n",
      "[5/25][9420/9765] Loss_D: 0.1054 Loss_G: 0.0389 Convergence: 0.1102 k= 0.027666 lr = 0.0000377\n",
      "[5/25][9430/9765] Loss_D: 0.1066 Loss_G: 0.0410 Convergence: 0.1098 k= 0.027658 lr = 0.0000377\n",
      "[5/25][9440/9765] Loss_D: 0.0970 Loss_G: 0.0370 Convergence: 0.1003 k= 0.027647 lr = 0.0000377\n",
      "[5/25][9450/9765] Loss_D: 0.1137 Loss_G: 0.0386 Convergence: 0.1221 k= 0.027681 lr = 0.0000377\n",
      "[5/25][9460/9765] Loss_D: 0.1019 Loss_G: 0.0397 Convergence: 0.1045 k= 0.027685 lr = 0.0000377\n",
      "[5/25][9470/9765] Loss_D: 0.1055 Loss_G: 0.0389 Convergence: 0.1102 k= 0.027710 lr = 0.0000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/25][9480/9765] Loss_D: 0.0991 Loss_G: 0.0432 Convergence: 0.1033 k= 0.027678 lr = 0.0000377\n",
      "[5/25][9490/9765] Loss_D: 0.1043 Loss_G: 0.0444 Convergence: 0.1077 k= 0.027656 lr = 0.0000377\n",
      "[5/25][9500/9765] Loss_D: 0.0957 Loss_G: 0.0412 Convergence: 0.0993 k= 0.027637 lr = 0.0000377\n",
      "[5/25][9510/9765] Loss_D: 0.1022 Loss_G: 0.0392 Convergence: 0.1054 k= 0.027649 lr = 0.0000377\n",
      "[5/25][9520/9765] Loss_D: 0.1041 Loss_G: 0.0420 Convergence: 0.1054 k= 0.027658 lr = 0.0000377\n",
      "[5/25][9530/9765] Loss_D: 0.1052 Loss_G: 0.0445 Convergence: 0.1083 k= 0.027664 lr = 0.0000377\n",
      "[5/25][9540/9765] Loss_D: 0.1106 Loss_G: 0.0416 Convergence: 0.1147 k= 0.027641 lr = 0.0000377\n",
      "[5/25][9550/9765] Loss_D: 0.1106 Loss_G: 0.0401 Convergence: 0.1162 k= 0.027666 lr = 0.0000377\n",
      "[5/25][9560/9765] Loss_D: 0.0906 Loss_G: 0.0401 Convergence: 0.0951 k= 0.027672 lr = 0.0000377\n",
      "[5/25][9570/9765] Loss_D: 0.0993 Loss_G: 0.0371 Convergence: 0.1034 k= 0.027666 lr = 0.0000377\n",
      "[5/25][9580/9765] Loss_D: 0.0994 Loss_G: 0.0399 Convergence: 0.1009 k= 0.027671 lr = 0.0000377\n",
      "[5/25][9590/9765] Loss_D: 0.1036 Loss_G: 0.0408 Convergence: 0.1058 k= 0.027688 lr = 0.0000377\n",
      "[5/25][9600/9765] Loss_D: 0.0932 Loss_G: 0.0408 Convergence: 0.0974 k= 0.027668 lr = 0.0000377\n",
      "[5/25][9610/9765] Loss_D: 0.0963 Loss_G: 0.0434 Convergence: 0.1019 k= 0.027680 lr = 0.0000377\n",
      "[5/25][9620/9765] Loss_D: 0.1043 Loss_G: 0.0414 Convergence: 0.1062 k= 0.027677 lr = 0.0000377\n",
      "[5/25][9630/9765] Loss_D: 0.0963 Loss_G: 0.0437 Convergence: 0.1021 k= 0.027643 lr = 0.0000377\n",
      "[5/25][9640/9765] Loss_D: 0.1005 Loss_G: 0.0419 Convergence: 0.1029 k= 0.027642 lr = 0.0000377\n",
      "[5/25][9650/9765] Loss_D: 0.1120 Loss_G: 0.0423 Convergence: 0.1161 k= 0.027641 lr = 0.0000377\n",
      "[5/25][9660/9765] Loss_D: 0.0994 Loss_G: 0.0408 Convergence: 0.1011 k= 0.027645 lr = 0.0000377\n",
      "[5/25][9670/9765] Loss_D: 0.1002 Loss_G: 0.0435 Convergence: 0.1043 k= 0.027643 lr = 0.0000377\n",
      "[5/25][9680/9765] Loss_D: 0.0992 Loss_G: 0.0489 Convergence: 0.1092 k= 0.027618 lr = 0.0000377\n",
      "[5/25][9690/9765] Loss_D: 0.1046 Loss_G: 0.0432 Convergence: 0.1066 k= 0.027599 lr = 0.0000377\n",
      "[5/25][9700/9765] Loss_D: 0.1045 Loss_G: 0.0374 Convergence: 0.1105 k= 0.027617 lr = 0.0000377\n",
      "[5/25][9710/9765] Loss_D: 0.0977 Loss_G: 0.0407 Convergence: 0.1000 k= 0.027592 lr = 0.0000377\n",
      "[5/25][9720/9765] Loss_D: 0.0942 Loss_G: 0.0453 Convergence: 0.1026 k= 0.027571 lr = 0.0000377\n",
      "[5/25][9730/9765] Loss_D: 0.0960 Loss_G: 0.0390 Convergence: 0.0972 k= 0.027561 lr = 0.0000377\n",
      "[5/25][9740/9765] Loss_D: 0.0953 Loss_G: 0.0400 Convergence: 0.0978 k= 0.027587 lr = 0.0000377\n",
      "[5/25][9750/9765] Loss_D: 0.1045 Loss_G: 0.0484 Convergence: 0.1119 k= 0.027553 lr = 0.0000377\n",
      "[5/25][9760/9765] Loss_D: 0.0896 Loss_G: 0.0420 Convergence: 0.0965 k= 0.027523 lr = 0.0000377\n",
      "[6/25][0/9765] Loss_D: 0.0976 Loss_G: 0.0362 Convergence: 0.1019 k= 0.027540 lr = 0.0000377\n",
      "[6/25][10/9765] Loss_D: 0.0998 Loss_G: 0.0398 Convergence: 0.1015 k= 0.027563 lr = 0.0000377\n",
      "[6/25][20/9765] Loss_D: 0.0979 Loss_G: 0.0445 Convergence: 0.1039 k= 0.027547 lr = 0.0000377\n",
      "[6/25][30/9765] Loss_D: 0.0978 Loss_G: 0.0413 Convergence: 0.1006 k= 0.027502 lr = 0.0000377\n",
      "[6/25][40/9765] Loss_D: 0.0948 Loss_G: 0.0413 Convergence: 0.0988 k= 0.027502 lr = 0.0000377\n",
      "[6/25][50/9765] Loss_D: 0.1033 Loss_G: 0.0387 Convergence: 0.1074 k= 0.027535 lr = 0.0000377\n",
      "[6/25][60/9765] Loss_D: 0.1063 Loss_G: 0.0418 Convergence: 0.1086 k= 0.027541 lr = 0.0000377\n",
      "[6/25][70/9765] Loss_D: 0.1087 Loss_G: 0.0466 Convergence: 0.1126 k= 0.027520 lr = 0.0000377\n",
      "[6/25][80/9765] Loss_D: 0.0996 Loss_G: 0.0427 Convergence: 0.1031 k= 0.027500 lr = 0.0000377\n",
      "[6/25][90/9765] Loss_D: 0.1169 Loss_G: 0.0419 Convergence: 0.1234 k= 0.027518 lr = 0.0000377\n",
      "[6/25][100/9765] Loss_D: 0.1023 Loss_G: 0.0436 Convergence: 0.1056 k= 0.027515 lr = 0.0000377\n",
      "[6/25][110/9765] Loss_D: 0.0952 Loss_G: 0.0422 Convergence: 0.1000 k= 0.027477 lr = 0.0000377\n",
      "[6/25][120/9765] Loss_D: 0.0975 Loss_G: 0.0446 Convergence: 0.1038 k= 0.027462 lr = 0.0000377\n",
      "[6/25][130/9765] Loss_D: 0.0926 Loss_G: 0.0392 Convergence: 0.0955 k= 0.027452 lr = 0.0000377\n",
      "[6/25][140/9765] Loss_D: 0.1073 Loss_G: 0.0418 Convergence: 0.1100 k= 0.027442 lr = 0.0000377\n",
      "[6/25][150/9765] Loss_D: 0.0879 Loss_G: 0.0389 Convergence: 0.0923 k= 0.027441 lr = 0.0000377\n",
      "[6/25][160/9765] Loss_D: 0.0948 Loss_G: 0.0442 Convergence: 0.1019 k= 0.027429 lr = 0.0000377\n",
      "[6/25][170/9765] Loss_D: 0.1047 Loss_G: 0.0381 Convergence: 0.1099 k= 0.027434 lr = 0.0000377\n",
      "[6/25][180/9765] Loss_D: 0.1040 Loss_G: 0.0393 Convergence: 0.1078 k= 0.027438 lr = 0.0000377\n",
      "[6/25][190/9765] Loss_D: 0.0964 Loss_G: 0.0367 Convergence: 0.0997 k= 0.027445 lr = 0.0000377\n",
      "[6/25][200/9765] Loss_D: 0.0906 Loss_G: 0.0434 Convergence: 0.0984 k= 0.027449 lr = 0.0000377\n",
      "[6/25][210/9765] Loss_D: 0.1040 Loss_G: 0.0381 Convergence: 0.1088 k= 0.027451 lr = 0.0000377\n",
      "[6/25][220/9765] Loss_D: 0.1056 Loss_G: 0.0388 Convergence: 0.1104 k= 0.027490 lr = 0.0000377\n",
      "[6/25][230/9765] Loss_D: 0.0972 Loss_G: 0.0382 Convergence: 0.0992 k= 0.027497 lr = 0.0000377\n",
      "[6/25][240/9765] Loss_D: 0.1111 Loss_G: 0.0457 Convergence: 0.1131 k= 0.027475 lr = 0.0000377\n",
      "[6/25][250/9765] Loss_D: 0.0967 Loss_G: 0.0378 Convergence: 0.0991 k= 0.027453 lr = 0.0000377\n",
      "[6/25][260/9765] Loss_D: 0.1007 Loss_G: 0.0412 Convergence: 0.1023 k= 0.027450 lr = 0.0000377\n",
      "[6/25][270/9765] Loss_D: 0.1055 Loss_G: 0.0466 Convergence: 0.1106 k= 0.027421 lr = 0.0000377\n",
      "[6/25][280/9765] Loss_D: 0.1078 Loss_G: 0.0419 Convergence: 0.1106 k= 0.027406 lr = 0.0000377\n",
      "[6/25][290/9765] Loss_D: 0.1060 Loss_G: 0.0374 Convergence: 0.1124 k= 0.027398 lr = 0.0000377\n",
      "[6/25][300/9765] Loss_D: 0.1079 Loss_G: 0.0412 Convergence: 0.1113 k= 0.027415 lr = 0.0000377\n",
      "[6/25][310/9765] Loss_D: 0.1064 Loss_G: 0.0398 Convergence: 0.1107 k= 0.027396 lr = 0.0000377\n",
      "[6/25][320/9765] Loss_D: 0.1029 Loss_G: 0.0401 Convergence: 0.1055 k= 0.027402 lr = 0.0000377\n",
      "[6/25][330/9765] Loss_D: 0.0948 Loss_G: 0.0393 Convergence: 0.0968 k= 0.027408 lr = 0.0000377\n",
      "[6/25][340/9765] Loss_D: 0.0943 Loss_G: 0.0365 Convergence: 0.0970 k= 0.027410 lr = 0.0000377\n",
      "[6/25][350/9765] Loss_D: 0.0970 Loss_G: 0.0439 Convergence: 0.1027 k= 0.027400 lr = 0.0000377\n",
      "[6/25][360/9765] Loss_D: 0.0967 Loss_G: 0.0408 Convergence: 0.0994 k= 0.027402 lr = 0.0000377\n",
      "[6/25][370/9765] Loss_D: 0.0969 Loss_G: 0.0406 Convergence: 0.0994 k= 0.027401 lr = 0.0000377\n",
      "[6/25][380/9765] Loss_D: 0.1056 Loss_G: 0.0463 Convergence: 0.1104 k= 0.027381 lr = 0.0000377\n",
      "[6/25][390/9765] Loss_D: 0.1062 Loss_G: 0.0416 Convergence: 0.1086 k= 0.027375 lr = 0.0000377\n",
      "[6/25][400/9765] Loss_D: 0.0997 Loss_G: 0.0411 Convergence: 0.1015 k= 0.027381 lr = 0.0000377\n",
      "[6/25][410/9765] Loss_D: 0.0926 Loss_G: 0.0360 Convergence: 0.0952 k= 0.027392 lr = 0.0000377\n",
      "[6/25][420/9765] Loss_D: 0.1180 Loss_G: 0.0468 Convergence: 0.1200 k= 0.027405 lr = 0.0000377\n",
      "[6/25][430/9765] Loss_D: 0.1069 Loss_G: 0.0414 Convergence: 0.1099 k= 0.027404 lr = 0.0000377\n",
      "[6/25][440/9765] Loss_D: 0.0991 Loss_G: 0.0401 Convergence: 0.1002 k= 0.027412 lr = 0.0000377\n",
      "[6/25][450/9765] Loss_D: 0.1059 Loss_G: 0.0440 Convergence: 0.1083 k= 0.027407 lr = 0.0000377\n",
      "[6/25][460/9765] Loss_D: 0.0960 Loss_G: 0.0436 Convergence: 0.1018 k= 0.027380 lr = 0.0000377\n",
      "[6/25][470/9765] Loss_D: 0.0968 Loss_G: 0.0413 Convergence: 0.1001 k= 0.027369 lr = 0.0000377\n",
      "[6/25][480/9765] Loss_D: 0.0983 Loss_G: 0.0384 Convergence: 0.1008 k= 0.027402 lr = 0.0000377\n",
      "[6/25][490/9765] Loss_D: 0.1112 Loss_G: 0.0441 Convergence: 0.1132 k= 0.027402 lr = 0.0000377\n",
      "[6/25][500/9765] Loss_D: 0.1009 Loss_G: 0.0416 Convergence: 0.1028 k= 0.027365 lr = 0.0000377\n",
      "[6/25][510/9765] Loss_D: 0.1080 Loss_G: 0.0405 Convergence: 0.1122 k= 0.027341 lr = 0.0000377\n",
      "[6/25][520/9765] Loss_D: 0.1153 Loss_G: 0.0394 Convergence: 0.1236 k= 0.027361 lr = 0.0000377\n",
      "[6/25][530/9765] Loss_D: 0.1030 Loss_G: 0.0403 Convergence: 0.1055 k= 0.027367 lr = 0.0000377\n",
      "[6/25][540/9765] Loss_D: 0.0986 Loss_G: 0.0424 Convergence: 0.1022 k= 0.027365 lr = 0.0000377\n",
      "[6/25][550/9765] Loss_D: 0.1065 Loss_G: 0.0401 Convergence: 0.1104 k= 0.027364 lr = 0.0000377\n",
      "[6/25][560/9765] Loss_D: 0.0977 Loss_G: 0.0428 Convergence: 0.1021 k= 0.027381 lr = 0.0000377\n",
      "[6/25][570/9765] Loss_D: 0.1003 Loss_G: 0.0417 Convergence: 0.1026 k= 0.027369 lr = 0.0000377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][580/9765] Loss_D: 0.0979 Loss_G: 0.0401 Convergence: 0.0994 k= 0.027354 lr = 0.0000377\n",
      "[6/25][590/9765] Loss_D: 0.0911 Loss_G: 0.0397 Convergence: 0.0950 k= 0.027364 lr = 0.0000377\n",
      "[6/25][600/9765] Loss_D: 0.1002 Loss_G: 0.0404 Convergence: 0.1015 k= 0.027349 lr = 0.0000377\n",
      "[6/25][610/9765] Loss_D: 0.1027 Loss_G: 0.0412 Convergence: 0.1042 k= 0.027335 lr = 0.0000377\n",
      "[6/25][620/9765] Loss_D: 0.1027 Loss_G: 0.0358 Convergence: 0.1094 k= 0.027360 lr = 0.0000377\n",
      "[6/25][630/9765] Loss_D: 0.1033 Loss_G: 0.0435 Convergence: 0.1062 k= 0.027345 lr = 0.0000377\n",
      "[6/25][640/9765] Loss_D: 0.1092 Loss_G: 0.0396 Convergence: 0.1147 k= 0.027354 lr = 0.0000377\n",
      "[6/25][650/9765] Loss_D: 0.1028 Loss_G: 0.0466 Convergence: 0.1091 k= 0.027364 lr = 0.0000377\n",
      "[6/25][660/9765] Loss_D: 0.1065 Loss_G: 0.0430 Convergence: 0.1076 k= 0.027353 lr = 0.0000377\n",
      "[6/25][670/9765] Loss_D: 0.1015 Loss_G: 0.0443 Convergence: 0.1059 k= 0.027333 lr = 0.0000377\n",
      "[6/25][680/9765] Loss_D: 0.1076 Loss_G: 0.0379 Convergence: 0.1141 k= 0.027346 lr = 0.0000377\n",
      "[6/25][690/9765] Loss_D: 0.0962 Loss_G: 0.0412 Convergence: 0.0997 k= 0.027354 lr = 0.0000377\n",
      "[6/25][700/9765] Loss_D: 0.1118 Loss_G: 0.0460 Convergence: 0.1139 k= 0.027337 lr = 0.0000377\n",
      "[6/25][710/9765] Loss_D: 0.1069 Loss_G: 0.0462 Convergence: 0.1111 k= 0.027310 lr = 0.0000377\n",
      "[6/25][720/9765] Loss_D: 0.0994 Loss_G: 0.0426 Convergence: 0.1029 k= 0.027311 lr = 0.0000377\n",
      "[6/25][730/9765] Loss_D: 0.0993 Loss_G: 0.0405 Convergence: 0.1007 k= 0.027316 lr = 0.0000377\n",
      "[6/25][740/9765] Loss_D: 0.0972 Loss_G: 0.0437 Convergence: 0.1027 k= 0.027321 lr = 0.0000377\n",
      "[6/25][750/9765] Loss_D: 0.0928 Loss_G: 0.0402 Convergence: 0.0966 k= 0.027287 lr = 0.0000377\n",
      "[6/25][760/9765] Loss_D: 0.1015 Loss_G: 0.0422 Convergence: 0.1037 k= 0.027284 lr = 0.0000377\n",
      "[6/25][770/9765] Loss_D: 0.1087 Loss_G: 0.0422 Convergence: 0.1115 k= 0.027285 lr = 0.0000377\n",
      "[6/25][780/9765] Loss_D: 0.1052 Loss_G: 0.0387 Convergence: 0.1101 k= 0.027295 lr = 0.0000377\n",
      "[6/25][790/9765] Loss_D: 0.0965 Loss_G: 0.0383 Convergence: 0.0984 k= 0.027299 lr = 0.0000377\n",
      "[6/25][800/9765] Loss_D: 0.1005 Loss_G: 0.0453 Convergence: 0.1064 k= 0.027275 lr = 0.0000377\n",
      "[6/25][810/9765] Loss_D: 0.0986 Loss_G: 0.0377 Convergence: 0.1017 k= 0.027260 lr = 0.0000377\n",
      "[6/25][820/9765] Loss_D: 0.0998 Loss_G: 0.0378 Convergence: 0.1035 k= 0.027293 lr = 0.0000377\n",
      "[6/25][830/9765] Loss_D: 0.0945 Loss_G: 0.0479 Convergence: 0.1054 k= 0.027276 lr = 0.0000377\n",
      "[6/25][840/9765] Loss_D: 0.0943 Loss_G: 0.0427 Convergence: 0.1000 k= 0.027245 lr = 0.0000377\n",
      "[6/25][850/9765] Loss_D: 0.1040 Loss_G: 0.0381 Convergence: 0.1089 k= 0.027255 lr = 0.0000377\n",
      "[6/25][860/9765] Loss_D: 0.1043 Loss_G: 0.0394 Convergence: 0.1082 k= 0.027265 lr = 0.0000377\n",
      "[6/25][870/9765] Loss_D: 0.0989 Loss_G: 0.0414 Convergence: 0.1014 k= 0.027279 lr = 0.0000377\n",
      "[6/25][880/9765] Loss_D: 0.1054 Loss_G: 0.0435 Convergence: 0.1075 k= 0.027245 lr = 0.0000377\n",
      "[6/25][890/9765] Loss_D: 0.1015 Loss_G: 0.0384 Convergence: 0.1052 k= 0.027223 lr = 0.0000377\n",
      "[6/25][900/9765] Loss_D: 0.1064 Loss_G: 0.0419 Convergence: 0.1087 k= 0.027232 lr = 0.0000377\n",
      "[6/25][910/9765] Loss_D: 0.1014 Loss_G: 0.0415 Convergence: 0.1030 k= 0.027225 lr = 0.0000377\n",
      "[6/25][920/9765] Loss_D: 0.0985 Loss_G: 0.0398 Convergence: 0.0996 k= 0.027209 lr = 0.0000377\n",
      "[6/25][930/9765] Loss_D: 0.1060 Loss_G: 0.0438 Convergence: 0.1081 k= 0.027223 lr = 0.0000377\n",
      "[6/25][940/9765] Loss_D: 0.1008 Loss_G: 0.0380 Convergence: 0.1046 k= 0.027214 lr = 0.0000377\n",
      "[6/25][950/9765] Loss_D: 0.0990 Loss_G: 0.0389 Convergence: 0.1011 k= 0.027223 lr = 0.0000377\n",
      "[6/25][960/9765] Loss_D: 0.0924 Loss_G: 0.0401 Convergence: 0.0962 k= 0.027214 lr = 0.0000377\n",
      "[6/25][970/9765] Loss_D: 0.1031 Loss_G: 0.0424 Convergence: 0.1050 k= 0.027232 lr = 0.0000377\n",
      "[6/25][980/9765] Loss_D: 0.0985 Loss_G: 0.0448 Convergence: 0.1046 k= 0.027204 lr = 0.0000377\n",
      "[6/25][990/9765] Loss_D: 0.0995 Loss_G: 0.0442 Convergence: 0.1046 k= 0.027208 lr = 0.0000377\n",
      "[6/25][1000/9765] Loss_D: 0.1062 Loss_G: 0.0424 Convergence: 0.1079 k= 0.027208 lr = 0.0000377\n",
      "[6/25][1010/9765] Loss_D: 0.0997 Loss_G: 0.0408 Convergence: 0.1013 k= 0.027217 lr = 0.0000377\n",
      "[6/25][1020/9765] Loss_D: 0.1001 Loss_G: 0.0437 Convergence: 0.1044 k= 0.027189 lr = 0.0000377\n",
      "[6/25][1030/9765] Loss_D: 0.1004 Loss_G: 0.0426 Convergence: 0.1035 k= 0.027183 lr = 0.0000377\n",
      "[6/25][1040/9765] Loss_D: 0.0975 Loss_G: 0.0403 Convergence: 0.0994 k= 0.027194 lr = 0.0000377\n",
      "[6/25][1050/9765] Loss_D: 0.1037 Loss_G: 0.0437 Convergence: 0.1067 k= 0.027163 lr = 0.0000377\n",
      "[6/25][1060/9765] Loss_D: 0.1085 Loss_G: 0.0400 Convergence: 0.1133 k= 0.027160 lr = 0.0000377\n",
      "[6/25][1070/9765] Loss_D: 0.1071 Loss_G: 0.0451 Convergence: 0.1100 k= 0.027178 lr = 0.0000377\n",
      "[6/25][1080/9765] Loss_D: 0.0997 Loss_G: 0.0383 Convergence: 0.1027 k= 0.027174 lr = 0.0000377\n",
      "[6/25][1090/9765] Loss_D: 0.0906 Loss_G: 0.0431 Convergence: 0.0982 k= 0.027171 lr = 0.0000377\n",
      "[6/25][1100/9765] Loss_D: 0.1032 Loss_G: 0.0410 Convergence: 0.1050 k= 0.027158 lr = 0.0000377\n",
      "[6/25][1110/9765] Loss_D: 0.1032 Loss_G: 0.0421 Convergence: 0.1047 k= 0.027143 lr = 0.0000377\n",
      "[6/25][1120/9765] Loss_D: 0.0971 Loss_G: 0.0445 Convergence: 0.1034 k= 0.027131 lr = 0.0000377\n",
      "[6/25][1130/9765] Loss_D: 0.0990 Loss_G: 0.0410 Convergence: 0.1010 k= 0.027145 lr = 0.0000377\n",
      "[6/25][1140/9765] Loss_D: 0.0968 Loss_G: 0.0377 Convergence: 0.0994 k= 0.027172 lr = 0.0000377\n",
      "[6/25][1150/9765] Loss_D: 0.1010 Loss_G: 0.0526 Convergence: 0.1140 k= 0.027133 lr = 0.0000377\n",
      "[6/25][1160/9765] Loss_D: 0.1033 Loss_G: 0.0431 Convergence: 0.1058 k= 0.027104 lr = 0.0000377\n",
      "[6/25][1170/9765] Loss_D: 0.0940 Loss_G: 0.0366 Convergence: 0.0964 k= 0.027098 lr = 0.0000377\n",
      "[6/25][1180/9765] Loss_D: 0.1026 Loss_G: 0.0427 Convergence: 0.1049 k= 0.027102 lr = 0.0000377\n",
      "[6/25][1190/9765] Loss_D: 0.0971 Loss_G: 0.0425 Convergence: 0.1015 k= 0.027088 lr = 0.0000377\n",
      "[6/25][1200/9765] Loss_D: 0.0975 Loss_G: 0.0404 Convergence: 0.0995 k= 0.027079 lr = 0.0000377\n",
      "[6/25][1210/9765] Loss_D: 0.0978 Loss_G: 0.0365 Convergence: 0.1018 k= 0.027084 lr = 0.0000377\n",
      "[6/25][1220/9765] Loss_D: 0.1025 Loss_G: 0.0386 Convergence: 0.1062 k= 0.027096 lr = 0.0000377\n",
      "[6/25][1230/9765] Loss_D: 0.0970 Loss_G: 0.0406 Convergence: 0.0994 k= 0.027107 lr = 0.0000377\n",
      "[6/25][1240/9765] Loss_D: 0.0997 Loss_G: 0.0467 Convergence: 0.1072 k= 0.027096 lr = 0.0000377\n",
      "[6/25][1250/9765] Loss_D: 0.1048 Loss_G: 0.0409 Convergence: 0.1074 k= 0.027066 lr = 0.0000377\n",
      "[6/25][1260/9765] Loss_D: 0.1004 Loss_G: 0.0397 Convergence: 0.1022 k= 0.027081 lr = 0.0000377\n",
      "[6/25][1270/9765] Loss_D: 0.0928 Loss_G: 0.0439 Convergence: 0.1003 k= 0.027071 lr = 0.0000377\n",
      "[6/25][1280/9765] Loss_D: 0.0959 Loss_G: 0.0461 Convergence: 0.1043 k= 0.027020 lr = 0.0000377\n",
      "[6/25][1290/9765] Loss_D: 0.1124 Loss_G: 0.0360 Convergence: 0.1228 k= 0.027030 lr = 0.0000377\n",
      "[6/25][1300/9765] Loss_D: 0.0974 Loss_G: 0.0406 Convergence: 0.0996 k= 0.027060 lr = 0.0000377\n",
      "[6/25][1310/9765] Loss_D: 0.1085 Loss_G: 0.0412 Convergence: 0.1123 k= 0.027064 lr = 0.0000377\n",
      "[6/25][1320/9765] Loss_D: 0.1002 Loss_G: 0.0395 Convergence: 0.1022 k= 0.027038 lr = 0.0000377\n",
      "[6/25][1330/9765] Loss_D: 0.0998 Loss_G: 0.0412 Convergence: 0.1017 k= 0.027056 lr = 0.0000377\n",
      "[6/25][1340/9765] Loss_D: 0.0981 Loss_G: 0.0441 Convergence: 0.1037 k= 0.027047 lr = 0.0000377\n",
      "[6/25][1350/9765] Loss_D: 0.0941 Loss_G: 0.0369 Convergence: 0.0962 k= 0.027029 lr = 0.0000377\n",
      "[6/25][1360/9765] Loss_D: 0.0948 Loss_G: 0.0406 Convergence: 0.0981 k= 0.027054 lr = 0.0000377\n",
      "[6/25][1370/9765] Loss_D: 0.0981 Loss_G: 0.0414 Convergence: 0.1009 k= 0.027045 lr = 0.0000377\n",
      "[6/25][1380/9765] Loss_D: 0.1013 Loss_G: 0.0415 Convergence: 0.1029 k= 0.027052 lr = 0.0000377\n",
      "[6/25][1390/9765] Loss_D: 0.0979 Loss_G: 0.0392 Convergence: 0.0994 k= 0.027047 lr = 0.0000377\n",
      "[6/25][1400/9765] Loss_D: 0.0997 Loss_G: 0.0391 Convergence: 0.1021 k= 0.027047 lr = 0.0000377\n",
      "[6/25][1410/9765] Loss_D: 0.1023 Loss_G: 0.0442 Convergence: 0.1062 k= 0.027043 lr = 0.0000358\n",
      "[6/25][1420/9765] Loss_D: 0.1016 Loss_G: 0.0411 Convergence: 0.1026 k= 0.027050 lr = 0.0000358\n",
      "[6/25][1430/9765] Loss_D: 0.1001 Loss_G: 0.0408 Convergence: 0.1016 k= 0.027044 lr = 0.0000358\n",
      "[6/25][1440/9765] Loss_D: 0.0990 Loss_G: 0.0393 Convergence: 0.1008 k= 0.027065 lr = 0.0000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][1450/9765] Loss_D: 0.0912 Loss_G: 0.0382 Convergence: 0.0936 k= 0.027074 lr = 0.0000358\n",
      "[6/25][1460/9765] Loss_D: 0.0928 Loss_G: 0.0392 Convergence: 0.0956 k= 0.027068 lr = 0.0000358\n",
      "[6/25][1470/9765] Loss_D: 0.0963 Loss_G: 0.0423 Convergence: 0.1008 k= 0.027060 lr = 0.0000358\n",
      "[6/25][1480/9765] Loss_D: 0.1008 Loss_G: 0.0420 Convergence: 0.1032 k= 0.027050 lr = 0.0000358\n",
      "[6/25][1490/9765] Loss_D: 0.1036 Loss_G: 0.0428 Convergence: 0.1056 k= 0.027037 lr = 0.0000358\n",
      "[6/25][1500/9765] Loss_D: 0.1025 Loss_G: 0.0414 Convergence: 0.1038 k= 0.027030 lr = 0.0000358\n",
      "[6/25][1510/9765] Loss_D: 0.0995 Loss_G: 0.0467 Convergence: 0.1072 k= 0.027002 lr = 0.0000358\n",
      "[6/25][1520/9765] Loss_D: 0.0921 Loss_G: 0.0405 Convergence: 0.0965 k= 0.026988 lr = 0.0000358\n",
      "[6/25][1530/9765] Loss_D: 0.0963 Loss_G: 0.0421 Convergence: 0.1006 k= 0.026967 lr = 0.0000358\n",
      "[6/25][1540/9765] Loss_D: 0.1024 Loss_G: 0.0434 Convergence: 0.1055 k= 0.026966 lr = 0.0000358\n",
      "[6/25][1550/9765] Loss_D: 0.0939 Loss_G: 0.0415 Convergence: 0.0985 k= 0.026972 lr = 0.0000358\n",
      "[6/25][1560/9765] Loss_D: 0.1012 Loss_G: 0.0399 Convergence: 0.1034 k= 0.026963 lr = 0.0000358\n",
      "[6/25][1570/9765] Loss_D: 0.1165 Loss_G: 0.0388 Convergence: 0.1258 k= 0.026971 lr = 0.0000358\n",
      "[6/25][1580/9765] Loss_D: 0.1155 Loss_G: 0.0444 Convergence: 0.1188 k= 0.026966 lr = 0.0000358\n",
      "[6/25][1590/9765] Loss_D: 0.1001 Loss_G: 0.0425 Convergence: 0.1033 k= 0.026964 lr = 0.0000358\n",
      "[6/25][1600/9765] Loss_D: 0.0926 Loss_G: 0.0438 Convergence: 0.1000 k= 0.026964 lr = 0.0000358\n",
      "[6/25][1610/9765] Loss_D: 0.1070 Loss_G: 0.0460 Convergence: 0.1109 k= 0.026935 lr = 0.0000358\n",
      "[6/25][1620/9765] Loss_D: 0.0991 Loss_G: 0.0447 Convergence: 0.1049 k= 0.026899 lr = 0.0000358\n",
      "[6/25][1630/9765] Loss_D: 0.1020 Loss_G: 0.0392 Convergence: 0.1050 k= 0.026904 lr = 0.0000358\n",
      "[6/25][1640/9765] Loss_D: 0.1070 Loss_G: 0.0428 Convergence: 0.1085 k= 0.026895 lr = 0.0000358\n",
      "[6/25][1650/9765] Loss_D: 0.1033 Loss_G: 0.0418 Convergence: 0.1045 k= 0.026877 lr = 0.0000358\n",
      "[6/25][1660/9765] Loss_D: 0.1100 Loss_G: 0.0430 Convergence: 0.1126 k= 0.026867 lr = 0.0000358\n",
      "[6/25][1670/9765] Loss_D: 0.0984 Loss_G: 0.0385 Convergence: 0.1007 k= 0.026854 lr = 0.0000358\n",
      "[6/25][1680/9765] Loss_D: 0.1019 Loss_G: 0.0428 Convergence: 0.1047 k= 0.026866 lr = 0.0000358\n",
      "[6/25][1690/9765] Loss_D: 0.1016 Loss_G: 0.0414 Convergence: 0.1030 k= 0.026854 lr = 0.0000358\n",
      "[6/25][1700/9765] Loss_D: 0.1042 Loss_G: 0.0389 Convergence: 0.1085 k= 0.026850 lr = 0.0000358\n",
      "[6/25][1710/9765] Loss_D: 0.1107 Loss_G: 0.0391 Convergence: 0.1172 k= 0.026879 lr = 0.0000358\n",
      "[6/25][1720/9765] Loss_D: 0.1057 Loss_G: 0.0401 Convergence: 0.1094 k= 0.026892 lr = 0.0000358\n",
      "[6/25][1730/9765] Loss_D: 0.1041 Loss_G: 0.0461 Convergence: 0.1093 k= 0.026860 lr = 0.0000358\n",
      "[6/25][1740/9765] Loss_D: 0.1036 Loss_G: 0.0398 Convergence: 0.1068 k= 0.026862 lr = 0.0000358\n",
      "[6/25][1750/9765] Loss_D: 0.1044 Loss_G: 0.0422 Convergence: 0.1055 k= 0.026887 lr = 0.0000358\n",
      "[6/25][1760/9765] Loss_D: 0.1034 Loss_G: 0.0435 Convergence: 0.1062 k= 0.026860 lr = 0.0000358\n",
      "[6/25][1770/9765] Loss_D: 0.1050 Loss_G: 0.0434 Convergence: 0.1071 k= 0.026838 lr = 0.0000358\n",
      "[6/25][1780/9765] Loss_D: 0.1084 Loss_G: 0.0372 Convergence: 0.1160 k= 0.026856 lr = 0.0000358\n",
      "[6/25][1790/9765] Loss_D: 0.1013 Loss_G: 0.0383 Convergence: 0.1049 k= 0.026874 lr = 0.0000358\n",
      "[6/25][1800/9765] Loss_D: 0.0995 Loss_G: 0.0437 Convergence: 0.1041 k= 0.026867 lr = 0.0000358\n",
      "[6/25][1810/9765] Loss_D: 0.1068 Loss_G: 0.0366 Convergence: 0.1143 k= 0.026844 lr = 0.0000358\n",
      "[6/25][1820/9765] Loss_D: 0.1004 Loss_G: 0.0425 Convergence: 0.1035 k= 0.026880 lr = 0.0000358\n",
      "[6/25][1830/9765] Loss_D: 0.0940 Loss_G: 0.0391 Convergence: 0.0961 k= 0.026897 lr = 0.0000358\n",
      "[6/25][1840/9765] Loss_D: 0.1080 Loss_G: 0.0446 Convergence: 0.1101 k= 0.026917 lr = 0.0000358\n",
      "[6/25][1850/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0949 k= 0.026904 lr = 0.0000358\n",
      "[6/25][1860/9765] Loss_D: 0.0973 Loss_G: 0.0404 Convergence: 0.0994 k= 0.026929 lr = 0.0000358\n",
      "[6/25][1870/9765] Loss_D: 0.1023 Loss_G: 0.0393 Convergence: 0.1054 k= 0.026920 lr = 0.0000358\n",
      "[6/25][1880/9765] Loss_D: 0.1063 Loss_G: 0.0416 Convergence: 0.1087 k= 0.026908 lr = 0.0000358\n",
      "[6/25][1890/9765] Loss_D: 0.0973 Loss_G: 0.0415 Convergence: 0.1005 k= 0.026897 lr = 0.0000358\n",
      "[6/25][1900/9765] Loss_D: 0.1109 Loss_G: 0.0455 Convergence: 0.1127 k= 0.026903 lr = 0.0000358\n",
      "[6/25][1910/9765] Loss_D: 0.0907 Loss_G: 0.0422 Convergence: 0.0973 k= 0.026898 lr = 0.0000358\n",
      "[6/25][1920/9765] Loss_D: 0.0957 Loss_G: 0.0374 Convergence: 0.0982 k= 0.026902 lr = 0.0000358\n",
      "[6/25][1930/9765] Loss_D: 0.0976 Loss_G: 0.0403 Convergence: 0.0996 k= 0.026896 lr = 0.0000358\n",
      "[6/25][1940/9765] Loss_D: 0.1016 Loss_G: 0.0406 Convergence: 0.1032 k= 0.026890 lr = 0.0000358\n",
      "[6/25][1950/9765] Loss_D: 0.1048 Loss_G: 0.0380 Convergence: 0.1102 k= 0.026897 lr = 0.0000358\n",
      "[6/25][1960/9765] Loss_D: 0.0966 Loss_G: 0.0364 Convergence: 0.1003 k= 0.026904 lr = 0.0000358\n",
      "[6/25][1970/9765] Loss_D: 0.1011 Loss_G: 0.0385 Convergence: 0.1045 k= 0.026931 lr = 0.0000358\n",
      "[6/25][1980/9765] Loss_D: 0.1011 Loss_G: 0.0449 Convergence: 0.1063 k= 0.026905 lr = 0.0000358\n",
      "[6/25][1990/9765] Loss_D: 0.1054 Loss_G: 0.0394 Convergence: 0.1095 k= 0.026921 lr = 0.0000358\n",
      "[6/25][2000/9765] Loss_D: 0.1090 Loss_G: 0.0433 Convergence: 0.1108 k= 0.026913 lr = 0.0000358\n",
      "[6/25][2010/9765] Loss_D: 0.1006 Loss_G: 0.0414 Convergence: 0.1024 k= 0.026922 lr = 0.0000358\n",
      "[6/25][2020/9765] Loss_D: 0.1087 Loss_G: 0.0426 Convergence: 0.1113 k= 0.026899 lr = 0.0000358\n",
      "[6/25][2030/9765] Loss_D: 0.1009 Loss_G: 0.0389 Convergence: 0.1038 k= 0.026894 lr = 0.0000358\n",
      "[6/25][2040/9765] Loss_D: 0.1094 Loss_G: 0.0377 Convergence: 0.1168 k= 0.026914 lr = 0.0000358\n",
      "[6/25][2050/9765] Loss_D: 0.1028 Loss_G: 0.0377 Convergence: 0.1076 k= 0.026941 lr = 0.0000358\n",
      "[6/25][2060/9765] Loss_D: 0.1021 Loss_G: 0.0484 Convergence: 0.1104 k= 0.026915 lr = 0.0000358\n",
      "[6/25][2070/9765] Loss_D: 0.1004 Loss_G: 0.0410 Convergence: 0.1019 k= 0.026865 lr = 0.0000358\n",
      "[6/25][2080/9765] Loss_D: 0.0901 Loss_G: 0.0454 Convergence: 0.1002 k= 0.026879 lr = 0.0000358\n",
      "[6/25][2090/9765] Loss_D: 0.1089 Loss_G: 0.0435 Convergence: 0.1105 k= 0.026851 lr = 0.0000358\n",
      "[6/25][2100/9765] Loss_D: 0.1021 Loss_G: 0.0441 Convergence: 0.1061 k= 0.026844 lr = 0.0000358\n",
      "[6/25][2110/9765] Loss_D: 0.1049 Loss_G: 0.0429 Convergence: 0.1065 k= 0.026832 lr = 0.0000358\n",
      "[6/25][2120/9765] Loss_D: 0.1047 Loss_G: 0.0417 Convergence: 0.1064 k= 0.026826 lr = 0.0000358\n",
      "[6/25][2130/9765] Loss_D: 0.1041 Loss_G: 0.0373 Convergence: 0.1099 k= 0.026815 lr = 0.0000358\n",
      "[6/25][2140/9765] Loss_D: 0.1071 Loss_G: 0.0397 Convergence: 0.1117 k= 0.026837 lr = 0.0000358\n",
      "[6/25][2150/9765] Loss_D: 0.1022 Loss_G: 0.0419 Convergence: 0.1038 k= 0.026842 lr = 0.0000358\n",
      "[6/25][2160/9765] Loss_D: 0.0927 Loss_G: 0.0444 Convergence: 0.1007 k= 0.026805 lr = 0.0000358\n",
      "[6/25][2170/9765] Loss_D: 0.1043 Loss_G: 0.0374 Convergence: 0.1101 k= 0.026812 lr = 0.0000358\n",
      "[6/25][2180/9765] Loss_D: 0.1028 Loss_G: 0.0434 Convergence: 0.1058 k= 0.026804 lr = 0.0000358\n",
      "[6/25][2190/9765] Loss_D: 0.1035 Loss_G: 0.0450 Convergence: 0.1078 k= 0.026772 lr = 0.0000358\n",
      "[6/25][2200/9765] Loss_D: 0.1062 Loss_G: 0.0393 Convergence: 0.1107 k= 0.026775 lr = 0.0000358\n",
      "[6/25][2210/9765] Loss_D: 0.0964 Loss_G: 0.0446 Convergence: 0.1031 k= 0.026770 lr = 0.0000358\n",
      "[6/25][2220/9765] Loss_D: 0.1098 Loss_G: 0.0366 Convergence: 0.1185 k= 0.026771 lr = 0.0000358\n",
      "[6/25][2230/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0990 k= 0.026807 lr = 0.0000358\n",
      "[6/25][2240/9765] Loss_D: 0.1019 Loss_G: 0.0399 Convergence: 0.1042 k= 0.026803 lr = 0.0000358\n",
      "[6/25][2250/9765] Loss_D: 0.0981 Loss_G: 0.0378 Convergence: 0.1009 k= 0.026804 lr = 0.0000358\n",
      "[6/25][2260/9765] Loss_D: 0.1013 Loss_G: 0.0403 Convergence: 0.1029 k= 0.026813 lr = 0.0000358\n",
      "[6/25][2270/9765] Loss_D: 0.1005 Loss_G: 0.0434 Convergence: 0.1044 k= 0.026799 lr = 0.0000358\n",
      "[6/25][2280/9765] Loss_D: 0.0977 Loss_G: 0.0419 Convergence: 0.1011 k= 0.026765 lr = 0.0000358\n",
      "[6/25][2290/9765] Loss_D: 0.1114 Loss_G: 0.0373 Convergence: 0.1201 k= 0.026784 lr = 0.0000358\n",
      "[6/25][2300/9765] Loss_D: 0.0972 Loss_G: 0.0426 Convergence: 0.1016 k= 0.026787 lr = 0.0000358\n",
      "[6/25][2310/9765] Loss_D: 0.1041 Loss_G: 0.0409 Convergence: 0.1065 k= 0.026775 lr = 0.0000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][2320/9765] Loss_D: 0.1097 Loss_G: 0.0421 Convergence: 0.1132 k= 0.026775 lr = 0.0000358\n",
      "[6/25][2330/9765] Loss_D: 0.1064 Loss_G: 0.0454 Convergence: 0.1099 k= 0.026752 lr = 0.0000358\n",
      "[6/25][2340/9765] Loss_D: 0.0977 Loss_G: 0.0375 Convergence: 0.1007 k= 0.026749 lr = 0.0000358\n",
      "[6/25][2350/9765] Loss_D: 0.0964 Loss_G: 0.0475 Convergence: 0.1060 k= 0.026750 lr = 0.0000358\n",
      "[6/25][2360/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0967 k= 0.026737 lr = 0.0000358\n",
      "[6/25][2370/9765] Loss_D: 0.0982 Loss_G: 0.0387 Convergence: 0.1002 k= 0.026752 lr = 0.0000358\n",
      "[6/25][2380/9765] Loss_D: 0.1029 Loss_G: 0.0412 Convergence: 0.1044 k= 0.026746 lr = 0.0000358\n",
      "[6/25][2390/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0978 k= 0.026744 lr = 0.0000358\n",
      "[6/25][2400/9765] Loss_D: 0.1062 Loss_G: 0.0463 Convergence: 0.1107 k= 0.026734 lr = 0.0000358\n",
      "[6/25][2410/9765] Loss_D: 0.1005 Loss_G: 0.0418 Convergence: 0.1028 k= 0.026738 lr = 0.0000358\n",
      "[6/25][2420/9765] Loss_D: 0.1055 Loss_G: 0.0393 Convergence: 0.1097 k= 0.026757 lr = 0.0000358\n",
      "[6/25][2430/9765] Loss_D: 0.0964 Loss_G: 0.0411 Convergence: 0.0996 k= 0.026768 lr = 0.0000358\n",
      "[6/25][2440/9765] Loss_D: 0.1085 Loss_G: 0.0399 Convergence: 0.1134 k= 0.026792 lr = 0.0000358\n",
      "[6/25][2450/9765] Loss_D: 0.0922 Loss_G: 0.0453 Convergence: 0.1012 k= 0.026818 lr = 0.0000358\n",
      "[6/25][2460/9765] Loss_D: 0.1111 Loss_G: 0.0468 Convergence: 0.1141 k= 0.026793 lr = 0.0000358\n",
      "[6/25][2470/9765] Loss_D: 0.1021 Loss_G: 0.0437 Convergence: 0.1057 k= 0.026778 lr = 0.0000358\n",
      "[6/25][2480/9765] Loss_D: 0.0872 Loss_G: 0.0377 Convergence: 0.0906 k= 0.026786 lr = 0.0000358\n",
      "[6/25][2490/9765] Loss_D: 0.0996 Loss_G: 0.0397 Convergence: 0.1012 k= 0.026793 lr = 0.0000358\n",
      "[6/25][2500/9765] Loss_D: 0.1103 Loss_G: 0.0402 Convergence: 0.1156 k= 0.026799 lr = 0.0000358\n",
      "[6/25][2510/9765] Loss_D: 0.1013 Loss_G: 0.0406 Convergence: 0.1027 k= 0.026807 lr = 0.0000358\n",
      "[6/25][2520/9765] Loss_D: 0.0945 Loss_G: 0.0378 Convergence: 0.0960 k= 0.026772 lr = 0.0000358\n",
      "[6/25][2530/9765] Loss_D: 0.0914 Loss_G: 0.0412 Convergence: 0.0967 k= 0.026795 lr = 0.0000358\n",
      "[6/25][2540/9765] Loss_D: 0.1059 Loss_G: 0.0428 Convergence: 0.1071 k= 0.026804 lr = 0.0000358\n",
      "[6/25][2550/9765] Loss_D: 0.1074 Loss_G: 0.0434 Convergence: 0.1084 k= 0.026788 lr = 0.0000358\n",
      "[6/25][2560/9765] Loss_D: 0.1073 Loss_G: 0.0400 Convergence: 0.1119 k= 0.026788 lr = 0.0000358\n",
      "[6/25][2570/9765] Loss_D: 0.1000 Loss_G: 0.0398 Convergence: 0.1016 k= 0.026788 lr = 0.0000358\n",
      "[6/25][2580/9765] Loss_D: 0.0929 Loss_G: 0.0378 Convergence: 0.0942 k= 0.026801 lr = 0.0000358\n",
      "[6/25][2590/9765] Loss_D: 0.1009 Loss_G: 0.0402 Convergence: 0.1025 k= 0.026817 lr = 0.0000358\n",
      "[6/25][2600/9765] Loss_D: 0.0889 Loss_G: 0.0435 Convergence: 0.0977 k= 0.026784 lr = 0.0000358\n",
      "[6/25][2610/9765] Loss_D: 0.1010 Loss_G: 0.0351 Convergence: 0.1077 k= 0.026763 lr = 0.0000358\n",
      "[6/25][2620/9765] Loss_D: 0.1092 Loss_G: 0.0416 Convergence: 0.1127 k= 0.026797 lr = 0.0000358\n",
      "[6/25][2630/9765] Loss_D: 0.1026 Loss_G: 0.0417 Convergence: 0.1040 k= 0.026802 lr = 0.0000358\n",
      "[6/25][2640/9765] Loss_D: 0.1000 Loss_G: 0.0442 Convergence: 0.1049 k= 0.026773 lr = 0.0000358\n",
      "[6/25][2650/9765] Loss_D: 0.0964 Loss_G: 0.0397 Convergence: 0.0982 k= 0.026754 lr = 0.0000358\n",
      "[6/25][2660/9765] Loss_D: 0.1051 Loss_G: 0.0350 Convergence: 0.1133 k= 0.026793 lr = 0.0000358\n",
      "[6/25][2670/9765] Loss_D: 0.1014 Loss_G: 0.0415 Convergence: 0.1029 k= 0.026830 lr = 0.0000358\n",
      "[6/25][2680/9765] Loss_D: 0.0954 Loss_G: 0.0485 Convergence: 0.1066 k= 0.026752 lr = 0.0000358\n",
      "[6/25][2690/9765] Loss_D: 0.0970 Loss_G: 0.0390 Convergence: 0.0983 k= 0.026741 lr = 0.0000358\n",
      "[6/25][2700/9765] Loss_D: 0.0958 Loss_G: 0.0376 Convergence: 0.0979 k= 0.026770 lr = 0.0000358\n",
      "[6/25][2710/9765] Loss_D: 0.1020 Loss_G: 0.0435 Convergence: 0.1053 k= 0.026764 lr = 0.0000358\n",
      "[6/25][2720/9765] Loss_D: 0.1045 Loss_G: 0.0399 Convergence: 0.1078 k= 0.026781 lr = 0.0000358\n",
      "[6/25][2730/9765] Loss_D: 0.1100 Loss_G: 0.0396 Convergence: 0.1160 k= 0.026793 lr = 0.0000358\n",
      "[6/25][2740/9765] Loss_D: 0.1024 Loss_G: 0.0423 Convergence: 0.1044 k= 0.026796 lr = 0.0000358\n",
      "[6/25][2750/9765] Loss_D: 0.1007 Loss_G: 0.0472 Convergence: 0.1083 k= 0.026796 lr = 0.0000358\n",
      "[6/25][2760/9765] Loss_D: 0.1050 Loss_G: 0.0418 Convergence: 0.1068 k= 0.026765 lr = 0.0000358\n",
      "[6/25][2770/9765] Loss_D: 0.1114 Loss_G: 0.0427 Convergence: 0.1150 k= 0.026755 lr = 0.0000358\n",
      "[6/25][2780/9765] Loss_D: 0.1028 Loss_G: 0.0425 Convergence: 0.1049 k= 0.026749 lr = 0.0000358\n",
      "[6/25][2790/9765] Loss_D: 0.1067 Loss_G: 0.0436 Convergence: 0.1083 k= 0.026740 lr = 0.0000358\n",
      "[6/25][2800/9765] Loss_D: 0.1008 Loss_G: 0.0410 Convergence: 0.1021 k= 0.026734 lr = 0.0000358\n",
      "[6/25][2810/9765] Loss_D: 0.1008 Loss_G: 0.0399 Convergence: 0.1029 k= 0.026723 lr = 0.0000358\n",
      "[6/25][2820/9765] Loss_D: 0.1092 Loss_G: 0.0412 Convergence: 0.1133 k= 0.026720 lr = 0.0000358\n",
      "[6/25][2830/9765] Loss_D: 0.1078 Loss_G: 0.0445 Convergence: 0.1099 k= 0.026730 lr = 0.0000358\n",
      "[6/25][2840/9765] Loss_D: 0.1059 Loss_G: 0.0421 Convergence: 0.1076 k= 0.026737 lr = 0.0000358\n",
      "[6/25][2850/9765] Loss_D: 0.1025 Loss_G: 0.0379 Convergence: 0.1069 k= 0.026762 lr = 0.0000358\n",
      "[6/25][2860/9765] Loss_D: 0.1087 Loss_G: 0.0421 Convergence: 0.1115 k= 0.026780 lr = 0.0000358\n",
      "[6/25][2870/9765] Loss_D: 0.0948 Loss_G: 0.0393 Convergence: 0.0968 k= 0.026754 lr = 0.0000358\n",
      "[6/25][2880/9765] Loss_D: 0.1059 Loss_G: 0.0452 Convergence: 0.1093 k= 0.026758 lr = 0.0000358\n",
      "[6/25][2890/9765] Loss_D: 0.1044 Loss_G: 0.0425 Convergence: 0.1059 k= 0.026726 lr = 0.0000358\n",
      "[6/25][2900/9765] Loss_D: 0.0973 Loss_G: 0.0417 Convergence: 0.1007 k= 0.026705 lr = 0.0000358\n",
      "[6/25][2910/9765] Loss_D: 0.1127 Loss_G: 0.0416 Convergence: 0.1177 k= 0.026703 lr = 0.0000358\n",
      "[6/25][2920/9765] Loss_D: 0.0970 Loss_G: 0.0393 Convergence: 0.0982 k= 0.026718 lr = 0.0000358\n",
      "[6/25][2930/9765] Loss_D: 0.1063 Loss_G: 0.0408 Convergence: 0.1095 k= 0.026728 lr = 0.0000358\n",
      "[6/25][2940/9765] Loss_D: 0.0980 Loss_G: 0.0423 Convergence: 0.1018 k= 0.026705 lr = 0.0000358\n",
      "[6/25][2950/9765] Loss_D: 0.0966 Loss_G: 0.0381 Convergence: 0.0986 k= 0.026713 lr = 0.0000358\n",
      "[6/25][2960/9765] Loss_D: 0.1107 Loss_G: 0.0432 Convergence: 0.1134 k= 0.026722 lr = 0.0000358\n",
      "[6/25][2970/9765] Loss_D: 0.0943 Loss_G: 0.0424 Convergence: 0.0997 k= 0.026683 lr = 0.0000358\n",
      "[6/25][2980/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.1004 k= 0.026687 lr = 0.0000358\n",
      "[6/25][2990/9765] Loss_D: 0.0986 Loss_G: 0.0420 Convergence: 0.1018 k= 0.026696 lr = 0.0000358\n",
      "[6/25][3000/9765] Loss_D: 0.0963 Loss_G: 0.0381 Convergence: 0.0980 k= 0.026715 lr = 0.0000358\n",
      "[6/25][3010/9765] Loss_D: 0.1030 Loss_G: 0.0418 Convergence: 0.1043 k= 0.026726 lr = 0.0000358\n",
      "[6/25][3020/9765] Loss_D: 0.1078 Loss_G: 0.0403 Convergence: 0.1122 k= 0.026727 lr = 0.0000358\n",
      "[6/25][3030/9765] Loss_D: 0.1066 Loss_G: 0.0391 Convergence: 0.1116 k= 0.026753 lr = 0.0000358\n",
      "[6/25][3040/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1036 k= 0.026739 lr = 0.0000358\n",
      "[6/25][3050/9765] Loss_D: 0.1001 Loss_G: 0.0382 Convergence: 0.1034 k= 0.026753 lr = 0.0000358\n",
      "[6/25][3060/9765] Loss_D: 0.0932 Loss_G: 0.0390 Convergence: 0.0955 k= 0.026759 lr = 0.0000358\n",
      "[6/25][3070/9765] Loss_D: 0.1003 Loss_G: 0.0403 Convergence: 0.1017 k= 0.026765 lr = 0.0000358\n",
      "[6/25][3080/9765] Loss_D: 0.1078 Loss_G: 0.0398 Convergence: 0.1126 k= 0.026780 lr = 0.0000358\n",
      "[6/25][3090/9765] Loss_D: 0.0981 Loss_G: 0.0407 Convergence: 0.1002 k= 0.026778 lr = 0.0000358\n",
      "[6/25][3100/9765] Loss_D: 0.1110 Loss_G: 0.0455 Convergence: 0.1129 k= 0.026759 lr = 0.0000358\n",
      "[6/25][3110/9765] Loss_D: 0.1012 Loss_G: 0.0438 Convergence: 0.1052 k= 0.026727 lr = 0.0000358\n",
      "[6/25][3120/9765] Loss_D: 0.0982 Loss_G: 0.0396 Convergence: 0.0993 k= 0.026736 lr = 0.0000358\n",
      "[6/25][3130/9765] Loss_D: 0.0916 Loss_G: 0.0430 Convergence: 0.0987 k= 0.026730 lr = 0.0000358\n",
      "[6/25][3140/9765] Loss_D: 0.0952 Loss_G: 0.0420 Convergence: 0.0998 k= 0.026645 lr = 0.0000358\n",
      "[6/25][3150/9765] Loss_D: 0.0966 Loss_G: 0.0368 Convergence: 0.0998 k= 0.026667 lr = 0.0000358\n",
      "[6/25][3160/9765] Loss_D: 0.0971 Loss_G: 0.0397 Convergence: 0.0986 k= 0.026668 lr = 0.0000358\n",
      "[6/25][3170/9765] Loss_D: 0.1058 Loss_G: 0.0437 Convergence: 0.1079 k= 0.026654 lr = 0.0000358\n",
      "[6/25][3180/9765] Loss_D: 0.1019 Loss_G: 0.0414 Convergence: 0.1032 k= 0.026641 lr = 0.0000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][3190/9765] Loss_D: 0.0907 Loss_G: 0.0371 Convergence: 0.0921 k= 0.026647 lr = 0.0000358\n",
      "[6/25][3200/9765] Loss_D: 0.1046 Loss_G: 0.0402 Convergence: 0.1077 k= 0.026660 lr = 0.0000358\n",
      "[6/25][3210/9765] Loss_D: 0.1007 Loss_G: 0.0434 Convergence: 0.1045 k= 0.026641 lr = 0.0000358\n",
      "[6/25][3220/9765] Loss_D: 0.0989 Loss_G: 0.0413 Convergence: 0.1013 k= 0.026609 lr = 0.0000358\n",
      "[6/25][3230/9765] Loss_D: 0.0926 Loss_G: 0.0398 Convergence: 0.0961 k= 0.026615 lr = 0.0000358\n",
      "[6/25][3240/9765] Loss_D: 0.0984 Loss_G: 0.0464 Convergence: 0.1062 k= 0.026592 lr = 0.0000358\n",
      "[6/25][3250/9765] Loss_D: 0.0950 Loss_G: 0.0410 Convergence: 0.0986 k= 0.026599 lr = 0.0000358\n",
      "[6/25][3260/9765] Loss_D: 0.1057 Loss_G: 0.0415 Convergence: 0.1080 k= 0.026609 lr = 0.0000358\n",
      "[6/25][3270/9765] Loss_D: 0.1036 Loss_G: 0.0388 Convergence: 0.1077 k= 0.026596 lr = 0.0000358\n",
      "[6/25][3280/9765] Loss_D: 0.1005 Loss_G: 0.0396 Convergence: 0.1029 k= 0.026591 lr = 0.0000358\n",
      "[6/25][3290/9765] Loss_D: 0.1063 Loss_G: 0.0417 Convergence: 0.1086 k= 0.026579 lr = 0.0000358\n",
      "[6/25][3300/9765] Loss_D: 0.0984 Loss_G: 0.0412 Convergence: 0.1008 k= 0.026577 lr = 0.0000358\n",
      "[6/25][3310/9765] Loss_D: 0.1089 Loss_G: 0.0418 Convergence: 0.1123 k= 0.026564 lr = 0.0000358\n",
      "[6/25][3320/9765] Loss_D: 0.1007 Loss_G: 0.0417 Convergence: 0.1028 k= 0.026546 lr = 0.0000358\n",
      "[6/25][3330/9765] Loss_D: 0.0991 Loss_G: 0.0393 Convergence: 0.1009 k= 0.026528 lr = 0.0000358\n",
      "[6/25][3340/9765] Loss_D: 0.1091 Loss_G: 0.0418 Convergence: 0.1125 k= 0.026534 lr = 0.0000358\n",
      "[6/25][3350/9765] Loss_D: 0.1073 Loss_G: 0.0419 Convergence: 0.1098 k= 0.026517 lr = 0.0000358\n",
      "[6/25][3360/9765] Loss_D: 0.1019 Loss_G: 0.0384 Convergence: 0.1056 k= 0.026529 lr = 0.0000358\n",
      "[6/25][3370/9765] Loss_D: 0.1109 Loss_G: 0.0381 Convergence: 0.1185 k= 0.026553 lr = 0.0000358\n",
      "[6/25][3380/9765] Loss_D: 0.1074 Loss_G: 0.0407 Convergence: 0.1112 k= 0.026563 lr = 0.0000358\n",
      "[6/25][3390/9765] Loss_D: 0.0931 Loss_G: 0.0411 Convergence: 0.0976 k= 0.026549 lr = 0.0000358\n",
      "[6/25][3400/9765] Loss_D: 0.0983 Loss_G: 0.0420 Convergence: 0.1016 k= 0.026542 lr = 0.0000358\n",
      "[6/25][3410/9765] Loss_D: 0.0973 Loss_G: 0.0404 Convergence: 0.0994 k= 0.026558 lr = 0.0000358\n",
      "[6/25][3420/9765] Loss_D: 0.0946 Loss_G: 0.0408 Convergence: 0.0983 k= 0.026538 lr = 0.0000358\n",
      "[6/25][3430/9765] Loss_D: 0.1026 Loss_G: 0.0458 Convergence: 0.1080 k= 0.026515 lr = 0.0000358\n",
      "[6/25][3440/9765] Loss_D: 0.0990 Loss_G: 0.0397 Convergence: 0.1005 k= 0.026507 lr = 0.0000358\n",
      "[6/25][3450/9765] Loss_D: 0.1069 Loss_G: 0.0453 Convergence: 0.1101 k= 0.026523 lr = 0.0000358\n",
      "[6/25][3460/9765] Loss_D: 0.0967 Loss_G: 0.0380 Convergence: 0.0988 k= 0.026530 lr = 0.0000358\n",
      "[6/25][3470/9765] Loss_D: 0.1041 Loss_G: 0.0410 Convergence: 0.1063 k= 0.026513 lr = 0.0000358\n",
      "[6/25][3480/9765] Loss_D: 0.1042 Loss_G: 0.0387 Convergence: 0.1086 k= 0.026509 lr = 0.0000358\n",
      "[6/25][3490/9765] Loss_D: 0.0966 Loss_G: 0.0377 Convergence: 0.0989 k= 0.026517 lr = 0.0000358\n",
      "[6/25][3500/9765] Loss_D: 0.1017 Loss_G: 0.0439 Convergence: 0.1055 k= 0.026509 lr = 0.0000358\n",
      "[6/25][3510/9765] Loss_D: 0.1024 Loss_G: 0.0380 Convergence: 0.1068 k= 0.026503 lr = 0.0000358\n",
      "[6/25][3520/9765] Loss_D: 0.0961 Loss_G: 0.0390 Convergence: 0.0973 k= 0.026508 lr = 0.0000358\n",
      "[6/25][3530/9765] Loss_D: 0.0976 Loss_G: 0.0352 Convergence: 0.1028 k= 0.026511 lr = 0.0000358\n",
      "[6/25][3540/9765] Loss_D: 0.1042 Loss_G: 0.0393 Convergence: 0.1080 k= 0.026528 lr = 0.0000358\n",
      "[6/25][3550/9765] Loss_D: 0.0972 Loss_G: 0.0448 Convergence: 0.1038 k= 0.026496 lr = 0.0000358\n",
      "[6/25][3560/9765] Loss_D: 0.1114 Loss_G: 0.0431 Convergence: 0.1145 k= 0.026510 lr = 0.0000358\n",
      "[6/25][3570/9765] Loss_D: 0.0951 Loss_G: 0.0409 Convergence: 0.0985 k= 0.026497 lr = 0.0000358\n",
      "[6/25][3580/9765] Loss_D: 0.1017 Loss_G: 0.0413 Convergence: 0.1029 k= 0.026498 lr = 0.0000358\n",
      "[6/25][3590/9765] Loss_D: 0.0920 Loss_G: 0.0406 Convergence: 0.0964 k= 0.026497 lr = 0.0000358\n",
      "[6/25][3600/9765] Loss_D: 0.1056 Loss_G: 0.0411 Convergence: 0.1082 k= 0.026489 lr = 0.0000358\n",
      "[6/25][3610/9765] Loss_D: 0.1005 Loss_G: 0.0405 Convergence: 0.1015 k= 0.026513 lr = 0.0000358\n",
      "[6/25][3620/9765] Loss_D: 0.1132 Loss_G: 0.0435 Convergence: 0.1165 k= 0.026495 lr = 0.0000358\n",
      "[6/25][3630/9765] Loss_D: 0.1049 Loss_G: 0.0426 Convergence: 0.1062 k= 0.026509 lr = 0.0000358\n",
      "[6/25][3640/9765] Loss_D: 0.1036 Loss_G: 0.0414 Convergence: 0.1051 k= 0.026520 lr = 0.0000358\n",
      "[6/25][3650/9765] Loss_D: 0.0955 Loss_G: 0.0386 Convergence: 0.0965 k= 0.026528 lr = 0.0000358\n",
      "[6/25][3660/9765] Loss_D: 0.1041 Loss_G: 0.0397 Convergence: 0.1075 k= 0.026508 lr = 0.0000358\n",
      "[6/25][3670/9765] Loss_D: 0.1077 Loss_G: 0.0387 Convergence: 0.1135 k= 0.026514 lr = 0.0000358\n",
      "[6/25][3680/9765] Loss_D: 0.0893 Loss_G: 0.0451 Convergence: 0.0994 k= 0.026511 lr = 0.0000358\n",
      "[6/25][3690/9765] Loss_D: 0.1003 Loss_G: 0.0382 Convergence: 0.1037 k= 0.026504 lr = 0.0000358\n",
      "[6/25][3700/9765] Loss_D: 0.0997 Loss_G: 0.0424 Convergence: 0.1029 k= 0.026489 lr = 0.0000358\n",
      "[6/25][3710/9765] Loss_D: 0.1035 Loss_G: 0.0441 Convergence: 0.1069 k= 0.026461 lr = 0.0000358\n",
      "[6/25][3720/9765] Loss_D: 0.0997 Loss_G: 0.0388 Convergence: 0.1023 k= 0.026476 lr = 0.0000358\n",
      "[6/25][3730/9765] Loss_D: 0.0921 Loss_G: 0.0432 Convergence: 0.0991 k= 0.026446 lr = 0.0000358\n",
      "[6/25][3740/9765] Loss_D: 0.1008 Loss_G: 0.0441 Convergence: 0.1053 k= 0.026415 lr = 0.0000358\n",
      "[6/25][3750/9765] Loss_D: 0.1070 Loss_G: 0.0432 Convergence: 0.1081 k= 0.026414 lr = 0.0000358\n",
      "[6/25][3760/9765] Loss_D: 0.1153 Loss_G: 0.0417 Convergence: 0.1211 k= 0.026428 lr = 0.0000358\n",
      "[6/25][3770/9765] Loss_D: 0.1152 Loss_G: 0.0405 Convergence: 0.1223 k= 0.026406 lr = 0.0000358\n",
      "[6/25][3780/9765] Loss_D: 0.1004 Loss_G: 0.0388 Convergence: 0.1033 k= 0.026403 lr = 0.0000358\n",
      "[6/25][3790/9765] Loss_D: 0.1003 Loss_G: 0.0428 Convergence: 0.1036 k= 0.026405 lr = 0.0000358\n",
      "[6/25][3800/9765] Loss_D: 0.1008 Loss_G: 0.0381 Convergence: 0.1043 k= 0.026431 lr = 0.0000358\n",
      "[6/25][3810/9765] Loss_D: 0.0948 Loss_G: 0.0447 Convergence: 0.1022 k= 0.026442 lr = 0.0000358\n",
      "[6/25][3820/9765] Loss_D: 0.0970 Loss_G: 0.0370 Convergence: 0.1002 k= 0.026439 lr = 0.0000358\n",
      "[6/25][3830/9765] Loss_D: 0.0957 Loss_G: 0.0448 Convergence: 0.1029 k= 0.026434 lr = 0.0000358\n",
      "[6/25][3840/9765] Loss_D: 0.1013 Loss_G: 0.0422 Convergence: 0.1036 k= 0.026418 lr = 0.0000358\n",
      "[6/25][3850/9765] Loss_D: 0.1138 Loss_G: 0.0398 Convergence: 0.1211 k= 0.026412 lr = 0.0000358\n",
      "[6/25][3860/9765] Loss_D: 0.0961 Loss_G: 0.0399 Convergence: 0.0982 k= 0.026431 lr = 0.0000358\n",
      "[6/25][3870/9765] Loss_D: 0.1021 Loss_G: 0.0435 Convergence: 0.1054 k= 0.026426 lr = 0.0000358\n",
      "[6/25][3880/9765] Loss_D: 0.0978 Loss_G: 0.0412 Convergence: 0.1005 k= 0.026420 lr = 0.0000358\n",
      "[6/25][3890/9765] Loss_D: 0.0982 Loss_G: 0.0393 Convergence: 0.0997 k= 0.026413 lr = 0.0000358\n",
      "[6/25][3900/9765] Loss_D: 0.0957 Loss_G: 0.0450 Convergence: 0.1031 k= 0.026395 lr = 0.0000358\n",
      "[6/25][3910/9765] Loss_D: 0.1050 Loss_G: 0.0383 Convergence: 0.1102 k= 0.026392 lr = 0.0000358\n",
      "[6/25][3920/9765] Loss_D: 0.1044 Loss_G: 0.0376 Convergence: 0.1099 k= 0.026405 lr = 0.0000358\n",
      "[6/25][3930/9765] Loss_D: 0.1086 Loss_G: 0.0472 Convergence: 0.1131 k= 0.026403 lr = 0.0000358\n",
      "[6/25][3940/9765] Loss_D: 0.1008 Loss_G: 0.0432 Convergence: 0.1043 k= 0.026383 lr = 0.0000358\n",
      "[6/25][3950/9765] Loss_D: 0.1006 Loss_G: 0.0359 Convergence: 0.1063 k= 0.026396 lr = 0.0000358\n",
      "[6/25][3960/9765] Loss_D: 0.1027 Loss_G: 0.0419 Convergence: 0.1041 k= 0.026408 lr = 0.0000358\n",
      "[6/25][3970/9765] Loss_D: 0.0982 Loss_G: 0.0423 Convergence: 0.1018 k= 0.026388 lr = 0.0000358\n",
      "[6/25][3980/9765] Loss_D: 0.1046 Loss_G: 0.0412 Convergence: 0.1067 k= 0.026391 lr = 0.0000358\n",
      "[6/25][3990/9765] Loss_D: 0.1049 Loss_G: 0.0436 Convergence: 0.1072 k= 0.026386 lr = 0.0000358\n",
      "[6/25][4000/9765] Loss_D: 0.0961 Loss_G: 0.0345 Convergence: 0.1014 k= 0.026400 lr = 0.0000358\n",
      "[6/25][4010/9765] Loss_D: 0.0995 Loss_G: 0.0449 Convergence: 0.1052 k= 0.026412 lr = 0.0000358\n",
      "[6/25][4020/9765] Loss_D: 0.0988 Loss_G: 0.0431 Convergence: 0.1031 k= 0.026370 lr = 0.0000358\n",
      "[6/25][4030/9765] Loss_D: 0.0999 Loss_G: 0.0382 Convergence: 0.1030 k= 0.026374 lr = 0.0000358\n",
      "[6/25][4040/9765] Loss_D: 0.0929 Loss_G: 0.0391 Convergence: 0.0955 k= 0.026392 lr = 0.0000358\n",
      "[6/25][4050/9765] Loss_D: 0.0951 Loss_G: 0.0420 Convergence: 0.0997 k= 0.026386 lr = 0.0000358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][4060/9765] Loss_D: 0.1122 Loss_G: 0.0410 Convergence: 0.1175 k= 0.026369 lr = 0.0000358\n",
      "[6/25][4070/9765] Loss_D: 0.1063 Loss_G: 0.0392 Convergence: 0.1110 k= 0.026378 lr = 0.0000358\n",
      "[6/25][4080/9765] Loss_D: 0.0936 Loss_G: 0.0388 Convergence: 0.0957 k= 0.026397 lr = 0.0000358\n",
      "[6/25][4090/9765] Loss_D: 0.1041 Loss_G: 0.0474 Convergence: 0.1107 k= 0.026369 lr = 0.0000358\n",
      "[6/25][4100/9765] Loss_D: 0.0953 Loss_G: 0.0427 Convergence: 0.1005 k= 0.026365 lr = 0.0000358\n",
      "[6/25][4110/9765] Loss_D: 0.1026 Loss_G: 0.0371 Convergence: 0.1078 k= 0.026383 lr = 0.0000358\n",
      "[6/25][4120/9765] Loss_D: 0.1132 Loss_G: 0.0439 Convergence: 0.1161 k= 0.026394 lr = 0.0000358\n",
      "[6/25][4130/9765] Loss_D: 0.1048 Loss_G: 0.0441 Convergence: 0.1077 k= 0.026370 lr = 0.0000358\n",
      "[6/25][4140/9765] Loss_D: 0.1015 Loss_G: 0.0415 Convergence: 0.1031 k= 0.026362 lr = 0.0000358\n",
      "[6/25][4150/9765] Loss_D: 0.0984 Loss_G: 0.0398 Convergence: 0.0995 k= 0.026367 lr = 0.0000358\n",
      "[6/25][4160/9765] Loss_D: 0.0955 Loss_G: 0.0438 Convergence: 0.1018 k= 0.026365 lr = 0.0000358\n",
      "[6/25][4170/9765] Loss_D: 0.0911 Loss_G: 0.0419 Convergence: 0.0972 k= 0.026353 lr = 0.0000358\n",
      "[6/25][4180/9765] Loss_D: 0.1001 Loss_G: 0.0404 Convergence: 0.1013 k= 0.026346 lr = 0.0000358\n",
      "[6/25][4190/9765] Loss_D: 0.0928 Loss_G: 0.0409 Convergence: 0.0972 k= 0.026339 lr = 0.0000358\n",
      "[6/25][4200/9765] Loss_D: 0.1072 Loss_G: 0.0430 Convergence: 0.1085 k= 0.026350 lr = 0.0000358\n",
      "[6/25][4210/9765] Loss_D: 0.0874 Loss_G: 0.0399 Convergence: 0.0931 k= 0.026322 lr = 0.0000358\n",
      "[6/25][4220/9765] Loss_D: 0.1011 Loss_G: 0.0445 Convergence: 0.1058 k= 0.026313 lr = 0.0000358\n",
      "[6/25][4230/9765] Loss_D: 0.1051 Loss_G: 0.0382 Convergence: 0.1104 k= 0.026322 lr = 0.0000358\n",
      "[6/25][4240/9765] Loss_D: 0.1027 Loss_G: 0.0413 Convergence: 0.1040 k= 0.026323 lr = 0.0000358\n",
      "[6/25][4250/9765] Loss_D: 0.0897 Loss_G: 0.0393 Convergence: 0.0938 k= 0.026303 lr = 0.0000358\n",
      "[6/25][4260/9765] Loss_D: 0.0949 Loss_G: 0.0407 Convergence: 0.0983 k= 0.026313 lr = 0.0000358\n",
      "[6/25][4270/9765] Loss_D: 0.1132 Loss_G: 0.0402 Convergence: 0.1197 k= 0.026313 lr = 0.0000358\n",
      "[6/25][4280/9765] Loss_D: 0.1057 Loss_G: 0.0391 Convergence: 0.1103 k= 0.026324 lr = 0.0000358\n",
      "[6/25][4290/9765] Loss_D: 0.0976 Loss_G: 0.0400 Convergence: 0.0992 k= 0.026327 lr = 0.0000358\n",
      "[6/25][4300/9765] Loss_D: 0.0974 Loss_G: 0.0405 Convergence: 0.0996 k= 0.026342 lr = 0.0000358\n",
      "[6/25][4310/9765] Loss_D: 0.0952 Loss_G: 0.0419 Convergence: 0.0997 k= 0.026321 lr = 0.0000358\n",
      "[6/25][4320/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0953 k= 0.026303 lr = 0.0000358\n",
      "[6/25][4330/9765] Loss_D: 0.0957 Loss_G: 0.0382 Convergence: 0.0973 k= 0.026300 lr = 0.0000358\n",
      "[6/25][4340/9765] Loss_D: 0.1119 Loss_G: 0.0397 Convergence: 0.1185 k= 0.026302 lr = 0.0000358\n",
      "[6/25][4350/9765] Loss_D: 0.0982 Loss_G: 0.0411 Convergence: 0.1007 k= 0.026297 lr = 0.0000358\n",
      "[6/25][4360/9765] Loss_D: 0.1027 Loss_G: 0.0420 Convergence: 0.1043 k= 0.026278 lr = 0.0000358\n",
      "[6/25][4370/9765] Loss_D: 0.1116 Loss_G: 0.0415 Convergence: 0.1161 k= 0.026281 lr = 0.0000358\n",
      "[6/25][4380/9765] Loss_D: 0.1081 Loss_G: 0.0465 Convergence: 0.1121 k= 0.026272 lr = 0.0000358\n",
      "[6/25][4390/9765] Loss_D: 0.0938 Loss_G: 0.0386 Convergence: 0.0956 k= 0.026252 lr = 0.0000358\n",
      "[6/25][4400/9765] Loss_D: 0.1016 Loss_G: 0.0380 Convergence: 0.1057 k= 0.026281 lr = 0.0000358\n",
      "[6/25][4410/9765] Loss_D: 0.1111 Loss_G: 0.0437 Convergence: 0.1133 k= 0.026286 lr = 0.0000341\n",
      "[6/25][4420/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0990 k= 0.026271 lr = 0.0000341\n",
      "[6/25][4430/9765] Loss_D: 0.1120 Loss_G: 0.0385 Convergence: 0.1196 k= 0.026286 lr = 0.0000341\n",
      "[6/25][4440/9765] Loss_D: 0.1011 Loss_G: 0.0433 Convergence: 0.1046 k= 0.026285 lr = 0.0000341\n",
      "[6/25][4450/9765] Loss_D: 0.1084 Loss_G: 0.0427 Convergence: 0.1105 k= 0.026297 lr = 0.0000341\n",
      "[6/25][4460/9765] Loss_D: 0.1042 Loss_G: 0.0407 Convergence: 0.1068 k= 0.026273 lr = 0.0000341\n",
      "[6/25][4470/9765] Loss_D: 0.0981 Loss_G: 0.0421 Convergence: 0.1017 k= 0.026271 lr = 0.0000341\n",
      "[6/25][4480/9765] Loss_D: 0.1096 Loss_G: 0.0422 Convergence: 0.1127 k= 0.026273 lr = 0.0000341\n",
      "[6/25][4490/9765] Loss_D: 0.1061 Loss_G: 0.0477 Convergence: 0.1121 k= 0.026265 lr = 0.0000341\n",
      "[6/25][4500/9765] Loss_D: 0.1061 Loss_G: 0.0417 Convergence: 0.1084 k= 0.026251 lr = 0.0000341\n",
      "[6/25][4510/9765] Loss_D: 0.1009 Loss_G: 0.0375 Convergence: 0.1052 k= 0.026257 lr = 0.0000341\n",
      "[6/25][4520/9765] Loss_D: 0.1021 Loss_G: 0.0383 Convergence: 0.1062 k= 0.026293 lr = 0.0000341\n",
      "[6/25][4530/9765] Loss_D: 0.0979 Loss_G: 0.0423 Convergence: 0.1017 k= 0.026284 lr = 0.0000341\n",
      "[6/25][4540/9765] Loss_D: 0.0998 Loss_G: 0.0419 Convergence: 0.1024 k= 0.026264 lr = 0.0000341\n",
      "[6/25][4550/9765] Loss_D: 0.1047 Loss_G: 0.0433 Convergence: 0.1068 k= 0.026280 lr = 0.0000341\n",
      "[6/25][4560/9765] Loss_D: 0.1032 Loss_G: 0.0457 Convergence: 0.1083 k= 0.026248 lr = 0.0000341\n",
      "[6/25][4570/9765] Loss_D: 0.1070 Loss_G: 0.0408 Convergence: 0.1105 k= 0.026203 lr = 0.0000341\n",
      "[6/25][4580/9765] Loss_D: 0.1018 Loss_G: 0.0392 Convergence: 0.1048 k= 0.026207 lr = 0.0000341\n",
      "[6/25][4590/9765] Loss_D: 0.0960 Loss_G: 0.0435 Convergence: 0.1018 k= 0.026201 lr = 0.0000341\n",
      "[6/25][4600/9765] Loss_D: 0.0970 Loss_G: 0.0428 Convergence: 0.1016 k= 0.026202 lr = 0.0000341\n",
      "[6/25][4610/9765] Loss_D: 0.1008 Loss_G: 0.0425 Convergence: 0.1037 k= 0.026192 lr = 0.0000341\n",
      "[6/25][4620/9765] Loss_D: 0.1035 Loss_G: 0.0374 Convergence: 0.1087 k= 0.026209 lr = 0.0000341\n",
      "[6/25][4630/9765] Loss_D: 0.1057 Loss_G: 0.0414 Convergence: 0.1080 k= 0.026203 lr = 0.0000341\n",
      "[6/25][4640/9765] Loss_D: 0.0993 Loss_G: 0.0398 Convergence: 0.1007 k= 0.026206 lr = 0.0000341\n",
      "[6/25][4650/9765] Loss_D: 0.1059 Loss_G: 0.0435 Convergence: 0.1076 k= 0.026224 lr = 0.0000341\n",
      "[6/25][4660/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0967 k= 0.026228 lr = 0.0000341\n",
      "[6/25][4670/9765] Loss_D: 0.1048 Loss_G: 0.0400 Convergence: 0.1082 k= 0.026244 lr = 0.0000341\n",
      "[6/25][4680/9765] Loss_D: 0.1036 Loss_G: 0.0428 Convergence: 0.1055 k= 0.026258 lr = 0.0000341\n",
      "[6/25][4690/9765] Loss_D: 0.0923 Loss_G: 0.0402 Convergence: 0.0961 k= 0.026268 lr = 0.0000341\n",
      "[6/25][4700/9765] Loss_D: 0.1086 Loss_G: 0.0395 Convergence: 0.1138 k= 0.026300 lr = 0.0000341\n",
      "[6/25][4710/9765] Loss_D: 0.0972 Loss_G: 0.0433 Convergence: 0.1022 k= 0.026287 lr = 0.0000341\n",
      "[6/25][4720/9765] Loss_D: 0.1030 Loss_G: 0.0400 Convergence: 0.1057 k= 0.026276 lr = 0.0000341\n",
      "[6/25][4730/9765] Loss_D: 0.1052 Loss_G: 0.0421 Convergence: 0.1067 k= 0.026271 lr = 0.0000341\n",
      "[6/25][4740/9765] Loss_D: 0.0979 Loss_G: 0.0383 Convergence: 0.1002 k= 0.026266 lr = 0.0000341\n",
      "[6/25][4750/9765] Loss_D: 0.0947 Loss_G: 0.0394 Convergence: 0.0968 k= 0.026274 lr = 0.0000341\n",
      "[6/25][4760/9765] Loss_D: 0.1061 Loss_G: 0.0427 Convergence: 0.1074 k= 0.026266 lr = 0.0000341\n",
      "[6/25][4770/9765] Loss_D: 0.1017 Loss_G: 0.0448 Convergence: 0.1064 k= 0.026265 lr = 0.0000341\n",
      "[6/25][4780/9765] Loss_D: 0.1067 Loss_G: 0.0399 Convergence: 0.1109 k= 0.026269 lr = 0.0000341\n",
      "[6/25][4790/9765] Loss_D: 0.0945 Loss_G: 0.0377 Convergence: 0.0960 k= 0.026295 lr = 0.0000341\n",
      "[6/25][4800/9765] Loss_D: 0.0907 Loss_G: 0.0412 Convergence: 0.0963 k= 0.026303 lr = 0.0000341\n",
      "[6/25][4810/9765] Loss_D: 0.0945 Loss_G: 0.0407 Convergence: 0.0980 k= 0.026296 lr = 0.0000341\n",
      "[6/25][4820/9765] Loss_D: 0.1085 Loss_G: 0.0374 Convergence: 0.1159 k= 0.026309 lr = 0.0000341\n",
      "[6/25][4830/9765] Loss_D: 0.0899 Loss_G: 0.0417 Convergence: 0.0963 k= 0.026314 lr = 0.0000341\n",
      "[6/25][4840/9765] Loss_D: 0.1007 Loss_G: 0.0414 Convergence: 0.1025 k= 0.026296 lr = 0.0000341\n",
      "[6/25][4850/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0962 k= 0.026294 lr = 0.0000341\n",
      "[6/25][4860/9765] Loss_D: 0.0929 Loss_G: 0.0440 Convergence: 0.1004 k= 0.026286 lr = 0.0000341\n",
      "[6/25][4870/9765] Loss_D: 0.1072 Loss_G: 0.0422 Convergence: 0.1093 k= 0.026287 lr = 0.0000341\n",
      "[6/25][4880/9765] Loss_D: 0.1096 Loss_G: 0.0475 Convergence: 0.1140 k= 0.026262 lr = 0.0000341\n",
      "[6/25][4890/9765] Loss_D: 0.1048 Loss_G: 0.0384 Convergence: 0.1097 k= 0.026243 lr = 0.0000341\n",
      "[6/25][4900/9765] Loss_D: 0.1014 Loss_G: 0.0408 Convergence: 0.1027 k= 0.026245 lr = 0.0000341\n",
      "[6/25][4910/9765] Loss_D: 0.1016 Loss_G: 0.0408 Convergence: 0.1029 k= 0.026246 lr = 0.0000341\n",
      "[6/25][4920/9765] Loss_D: 0.0967 Loss_G: 0.0415 Convergence: 0.1002 k= 0.026228 lr = 0.0000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][4930/9765] Loss_D: 0.0879 Loss_G: 0.0417 Convergence: 0.0950 k= 0.026236 lr = 0.0000341\n",
      "[6/25][4940/9765] Loss_D: 0.1061 Loss_G: 0.0413 Convergence: 0.1087 k= 0.026245 lr = 0.0000341\n",
      "[6/25][4950/9765] Loss_D: 0.0917 Loss_G: 0.0415 Convergence: 0.0973 k= 0.026243 lr = 0.0000341\n",
      "[6/25][4960/9765] Loss_D: 0.0950 Loss_G: 0.0454 Convergence: 0.1030 k= 0.026212 lr = 0.0000341\n",
      "[6/25][4970/9765] Loss_D: 0.1040 Loss_G: 0.0392 Convergence: 0.1079 k= 0.026239 lr = 0.0000341\n",
      "[6/25][4980/9765] Loss_D: 0.0983 Loss_G: 0.0432 Convergence: 0.1028 k= 0.026246 lr = 0.0000341\n",
      "[6/25][4990/9765] Loss_D: 0.1105 Loss_G: 0.0394 Convergence: 0.1167 k= 0.026249 lr = 0.0000341\n",
      "[6/25][5000/9765] Loss_D: 0.1026 Loss_G: 0.0427 Convergence: 0.1050 k= 0.026245 lr = 0.0000341\n",
      "[6/25][5010/9765] Loss_D: 0.1005 Loss_G: 0.0383 Convergence: 0.1038 k= 0.026264 lr = 0.0000341\n",
      "[6/25][5020/9765] Loss_D: 0.1162 Loss_G: 0.0460 Convergence: 0.1183 k= 0.026250 lr = 0.0000341\n",
      "[6/25][5030/9765] Loss_D: 0.1007 Loss_G: 0.0415 Convergence: 0.1026 k= 0.026227 lr = 0.0000341\n",
      "[6/25][5040/9765] Loss_D: 0.1009 Loss_G: 0.0423 Convergence: 0.1035 k= 0.026237 lr = 0.0000341\n",
      "[6/25][5050/9765] Loss_D: 0.0947 Loss_G: 0.0428 Convergence: 0.1003 k= 0.026214 lr = 0.0000341\n",
      "[6/25][5060/9765] Loss_D: 0.1009 Loss_G: 0.0390 Convergence: 0.1036 k= 0.026211 lr = 0.0000341\n",
      "[6/25][5070/9765] Loss_D: 0.0975 Loss_G: 0.0340 Convergence: 0.1038 k= 0.026246 lr = 0.0000341\n",
      "[6/25][5080/9765] Loss_D: 0.1084 Loss_G: 0.0399 Convergence: 0.1132 k= 0.026282 lr = 0.0000341\n",
      "[6/25][5090/9765] Loss_D: 0.1090 Loss_G: 0.0487 Convergence: 0.1148 k= 0.026248 lr = 0.0000341\n",
      "[6/25][5100/9765] Loss_D: 0.1178 Loss_G: 0.0471 Convergence: 0.1196 k= 0.026199 lr = 0.0000341\n",
      "[6/25][5110/9765] Loss_D: 0.0932 Loss_G: 0.0391 Convergence: 0.0956 k= 0.026200 lr = 0.0000341\n",
      "[6/25][5120/9765] Loss_D: 0.0929 Loss_G: 0.0390 Convergence: 0.0954 k= 0.026213 lr = 0.0000341\n",
      "[6/25][5130/9765] Loss_D: 0.1125 Loss_G: 0.0472 Convergence: 0.1155 k= 0.026180 lr = 0.0000341\n",
      "[6/25][5140/9765] Loss_D: 0.1004 Loss_G: 0.0399 Convergence: 0.1022 k= 0.026150 lr = 0.0000341\n",
      "[6/25][5150/9765] Loss_D: 0.1060 Loss_G: 0.0395 Convergence: 0.1103 k= 0.026150 lr = 0.0000341\n",
      "[6/25][5160/9765] Loss_D: 0.1002 Loss_G: 0.0375 Convergence: 0.1042 k= 0.026161 lr = 0.0000341\n",
      "[6/25][5170/9765] Loss_D: 0.1057 Loss_G: 0.0381 Convergence: 0.1113 k= 0.026193 lr = 0.0000341\n",
      "[6/25][5180/9765] Loss_D: 0.0973 Loss_G: 0.0396 Convergence: 0.0987 k= 0.026187 lr = 0.0000341\n",
      "[6/25][5190/9765] Loss_D: 0.1004 Loss_G: 0.0398 Convergence: 0.1022 k= 0.026172 lr = 0.0000341\n",
      "[6/25][5200/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1005 k= 0.026172 lr = 0.0000341\n",
      "[6/25][5210/9765] Loss_D: 0.1006 Loss_G: 0.0411 Convergence: 0.1021 k= 0.026168 lr = 0.0000341\n",
      "[6/25][5220/9765] Loss_D: 0.0995 Loss_G: 0.0391 Convergence: 0.1015 k= 0.026165 lr = 0.0000341\n",
      "[6/25][5230/9765] Loss_D: 0.0966 Loss_G: 0.0377 Convergence: 0.0987 k= 0.026178 lr = 0.0000341\n",
      "[6/25][5240/9765] Loss_D: 0.0942 Loss_G: 0.0445 Convergence: 0.1017 k= 0.026169 lr = 0.0000341\n",
      "[6/25][5250/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0971 k= 0.026160 lr = 0.0000341\n",
      "[6/25][5260/9765] Loss_D: 0.1064 Loss_G: 0.0391 Convergence: 0.1113 k= 0.026167 lr = 0.0000341\n",
      "[6/25][5270/9765] Loss_D: 0.0962 Loss_G: 0.0414 Convergence: 0.0998 k= 0.026175 lr = 0.0000341\n",
      "[6/25][5280/9765] Loss_D: 0.0949 Loss_G: 0.0393 Convergence: 0.0968 k= 0.026178 lr = 0.0000341\n",
      "[6/25][5290/9765] Loss_D: 0.0996 Loss_G: 0.0372 Convergence: 0.1036 k= 0.026182 lr = 0.0000341\n",
      "[6/25][5300/9765] Loss_D: 0.1042 Loss_G: 0.0443 Convergence: 0.1075 k= 0.026175 lr = 0.0000341\n",
      "[6/25][5310/9765] Loss_D: 0.1029 Loss_G: 0.0377 Convergence: 0.1077 k= 0.026183 lr = 0.0000341\n",
      "[6/25][5320/9765] Loss_D: 0.1013 Loss_G: 0.0423 Convergence: 0.1037 k= 0.026174 lr = 0.0000341\n",
      "[6/25][5330/9765] Loss_D: 0.1107 Loss_G: 0.0403 Convergence: 0.1163 k= 0.026170 lr = 0.0000341\n",
      "[6/25][5340/9765] Loss_D: 0.0999 Loss_G: 0.0403 Convergence: 0.1012 k= 0.026167 lr = 0.0000341\n",
      "[6/25][5350/9765] Loss_D: 0.1021 Loss_G: 0.0410 Convergence: 0.1035 k= 0.026162 lr = 0.0000341\n",
      "[6/25][5360/9765] Loss_D: 0.1009 Loss_G: 0.0397 Convergence: 0.1029 k= 0.026168 lr = 0.0000341\n",
      "[6/25][5370/9765] Loss_D: 0.1108 Loss_G: 0.0462 Convergence: 0.1134 k= 0.026165 lr = 0.0000341\n",
      "[6/25][5380/9765] Loss_D: 0.1051 Loss_G: 0.0428 Convergence: 0.1065 k= 0.026147 lr = 0.0000341\n",
      "[6/25][5390/9765] Loss_D: 0.1062 Loss_G: 0.0404 Convergence: 0.1096 k= 0.026149 lr = 0.0000341\n",
      "[6/25][5400/9765] Loss_D: 0.1029 Loss_G: 0.0433 Convergence: 0.1057 k= 0.026148 lr = 0.0000341\n",
      "[6/25][5410/9765] Loss_D: 0.1010 Loss_G: 0.0419 Convergence: 0.1031 k= 0.026132 lr = 0.0000341\n",
      "[6/25][5420/9765] Loss_D: 0.1162 Loss_G: 0.0405 Convergence: 0.1235 k= 0.026139 lr = 0.0000341\n",
      "[6/25][5430/9765] Loss_D: 0.1050 Loss_G: 0.0403 Convergence: 0.1081 k= 0.026140 lr = 0.0000341\n",
      "[6/25][5440/9765] Loss_D: 0.0892 Loss_G: 0.0383 Convergence: 0.0924 k= 0.026145 lr = 0.0000341\n",
      "[6/25][5450/9765] Loss_D: 0.0996 Loss_G: 0.0397 Convergence: 0.1012 k= 0.026167 lr = 0.0000341\n",
      "[6/25][5460/9765] Loss_D: 0.1051 Loss_G: 0.0420 Convergence: 0.1066 k= 0.026142 lr = 0.0000341\n",
      "[6/25][5470/9765] Loss_D: 0.0923 Loss_G: 0.0396 Convergence: 0.0956 k= 0.026127 lr = 0.0000341\n",
      "[6/25][5480/9765] Loss_D: 0.0988 Loss_G: 0.0377 Convergence: 0.1021 k= 0.026143 lr = 0.0000341\n",
      "[6/25][5490/9765] Loss_D: 0.1021 Loss_G: 0.0473 Convergence: 0.1093 k= 0.026111 lr = 0.0000341\n",
      "[6/25][5500/9765] Loss_D: 0.1037 Loss_G: 0.0416 Convergence: 0.1050 k= 0.026092 lr = 0.0000341\n",
      "[6/25][5510/9765] Loss_D: 0.0931 Loss_G: 0.0396 Convergence: 0.0961 k= 0.026092 lr = 0.0000341\n",
      "[6/25][5520/9765] Loss_D: 0.1004 Loss_G: 0.0359 Convergence: 0.1060 k= 0.026123 lr = 0.0000341\n",
      "[6/25][5530/9765] Loss_D: 0.1007 Loss_G: 0.0391 Convergence: 0.1034 k= 0.026142 lr = 0.0000341\n",
      "[6/25][5540/9765] Loss_D: 0.1067 Loss_G: 0.0394 Convergence: 0.1114 k= 0.026132 lr = 0.0000341\n",
      "[6/25][5550/9765] Loss_D: 0.0915 Loss_G: 0.0388 Convergence: 0.0944 k= 0.026132 lr = 0.0000341\n",
      "[6/25][5560/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1016 k= 0.026136 lr = 0.0000341\n",
      "[6/25][5570/9765] Loss_D: 0.0916 Loss_G: 0.0374 Convergence: 0.0929 k= 0.026152 lr = 0.0000341\n",
      "[6/25][5580/9765] Loss_D: 0.0954 Loss_G: 0.0418 Convergence: 0.0997 k= 0.026164 lr = 0.0000341\n",
      "[6/25][5590/9765] Loss_D: 0.1043 Loss_G: 0.0423 Convergence: 0.1056 k= 0.026153 lr = 0.0000341\n",
      "[6/25][5600/9765] Loss_D: 0.0996 Loss_G: 0.0405 Convergence: 0.1010 k= 0.026155 lr = 0.0000341\n",
      "[6/25][5610/9765] Loss_D: 0.0959 Loss_G: 0.0407 Convergence: 0.0989 k= 0.026142 lr = 0.0000341\n",
      "[6/25][5620/9765] Loss_D: 0.1125 Loss_G: 0.0460 Convergence: 0.1142 k= 0.026114 lr = 0.0000341\n",
      "[6/25][5630/9765] Loss_D: 0.0969 Loss_G: 0.0405 Convergence: 0.0993 k= 0.026085 lr = 0.0000341\n",
      "[6/25][5640/9765] Loss_D: 0.0983 Loss_G: 0.0398 Convergence: 0.0995 k= 0.026093 lr = 0.0000341\n",
      "[6/25][5650/9765] Loss_D: 0.0994 Loss_G: 0.0375 Convergence: 0.1031 k= 0.026095 lr = 0.0000341\n",
      "[6/25][5660/9765] Loss_D: 0.1005 Loss_G: 0.0409 Convergence: 0.1019 k= 0.026104 lr = 0.0000341\n",
      "[6/25][5670/9765] Loss_D: 0.0985 Loss_G: 0.0450 Convergence: 0.1048 k= 0.026083 lr = 0.0000341\n",
      "[6/25][5680/9765] Loss_D: 0.1003 Loss_G: 0.0383 Convergence: 0.1035 k= 0.026095 lr = 0.0000341\n",
      "[6/25][5690/9765] Loss_D: 0.0882 Loss_G: 0.0383 Convergence: 0.0919 k= 0.026112 lr = 0.0000341\n",
      "[6/25][5700/9765] Loss_D: 0.0966 Loss_G: 0.0445 Convergence: 0.1031 k= 0.026100 lr = 0.0000341\n",
      "[6/25][5710/9765] Loss_D: 0.1059 Loss_G: 0.0456 Convergence: 0.1098 k= 0.026067 lr = 0.0000341\n",
      "[6/25][5720/9765] Loss_D: 0.0943 Loss_G: 0.0404 Convergence: 0.0976 k= 0.026060 lr = 0.0000341\n",
      "[6/25][5730/9765] Loss_D: 0.1077 Loss_G: 0.0408 Convergence: 0.1115 k= 0.026065 lr = 0.0000341\n",
      "[6/25][5740/9765] Loss_D: 0.1006 Loss_G: 0.0449 Convergence: 0.1060 k= 0.026061 lr = 0.0000341\n",
      "[6/25][5750/9765] Loss_D: 0.0995 Loss_G: 0.0452 Convergence: 0.1056 k= 0.026030 lr = 0.0000341\n",
      "[6/25][5760/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.1003 k= 0.026030 lr = 0.0000341\n",
      "[6/25][5770/9765] Loss_D: 0.0976 Loss_G: 0.0418 Convergence: 0.1009 k= 0.026046 lr = 0.0000341\n",
      "[6/25][5780/9765] Loss_D: 0.1055 Loss_G: 0.0403 Convergence: 0.1089 k= 0.026047 lr = 0.0000341\n",
      "[6/25][5790/9765] Loss_D: 0.1093 Loss_G: 0.0404 Convergence: 0.1141 k= 0.026048 lr = 0.0000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][5800/9765] Loss_D: 0.0909 Loss_G: 0.0397 Convergence: 0.0949 k= 0.026027 lr = 0.0000341\n",
      "[6/25][5810/9765] Loss_D: 0.0909 Loss_G: 0.0395 Convergence: 0.0946 k= 0.026014 lr = 0.0000341\n",
      "[6/25][5820/9765] Loss_D: 0.0994 Loss_G: 0.0400 Convergence: 0.1008 k= 0.026019 lr = 0.0000341\n",
      "[6/25][5830/9765] Loss_D: 0.0929 Loss_G: 0.0392 Convergence: 0.0956 k= 0.026000 lr = 0.0000341\n",
      "[6/25][5840/9765] Loss_D: 0.1016 Loss_G: 0.0401 Convergence: 0.1036 k= 0.026003 lr = 0.0000341\n",
      "[6/25][5850/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0974 k= 0.026011 lr = 0.0000341\n",
      "[6/25][5860/9765] Loss_D: 0.1023 Loss_G: 0.0405 Convergence: 0.1042 k= 0.026019 lr = 0.0000341\n",
      "[6/25][5870/9765] Loss_D: 0.0979 Loss_G: 0.0424 Convergence: 0.1017 k= 0.026024 lr = 0.0000341\n",
      "[6/25][5880/9765] Loss_D: 0.0985 Loss_G: 0.0432 Convergence: 0.1030 k= 0.026025 lr = 0.0000341\n",
      "[6/25][5890/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0968 k= 0.026015 lr = 0.0000341\n",
      "[6/25][5900/9765] Loss_D: 0.0985 Loss_G: 0.0404 Convergence: 0.1001 k= 0.026012 lr = 0.0000341\n",
      "[6/25][5910/9765] Loss_D: 0.1044 Loss_G: 0.0424 Convergence: 0.1056 k= 0.026015 lr = 0.0000341\n",
      "[6/25][5920/9765] Loss_D: 0.1022 Loss_G: 0.0399 Convergence: 0.1047 k= 0.025997 lr = 0.0000341\n",
      "[6/25][5930/9765] Loss_D: 0.0999 Loss_G: 0.0380 Convergence: 0.1034 k= 0.025990 lr = 0.0000341\n",
      "[6/25][5940/9765] Loss_D: 0.1036 Loss_G: 0.0410 Convergence: 0.1057 k= 0.025978 lr = 0.0000341\n",
      "[6/25][5950/9765] Loss_D: 0.1171 Loss_G: 0.0431 Convergence: 0.1225 k= 0.025957 lr = 0.0000341\n",
      "[6/25][5960/9765] Loss_D: 0.0991 Loss_G: 0.0399 Convergence: 0.1003 k= 0.025922 lr = 0.0000341\n",
      "[6/25][5970/9765] Loss_D: 0.1121 Loss_G: 0.0379 Convergence: 0.1205 k= 0.025932 lr = 0.0000341\n",
      "[6/25][5980/9765] Loss_D: 0.1057 Loss_G: 0.0422 Convergence: 0.1072 k= 0.025953 lr = 0.0000341\n",
      "[6/25][5990/9765] Loss_D: 0.0944 Loss_G: 0.0414 Convergence: 0.0987 k= 0.025916 lr = 0.0000341\n",
      "[6/25][6000/9765] Loss_D: 0.0985 Loss_G: 0.0361 Convergence: 0.1030 k= 0.025929 lr = 0.0000341\n",
      "[6/25][6010/9765] Loss_D: 0.1052 Loss_G: 0.0388 Convergence: 0.1099 k= 0.025955 lr = 0.0000341\n",
      "[6/25][6020/9765] Loss_D: 0.1063 Loss_G: 0.0426 Convergence: 0.1076 k= 0.025973 lr = 0.0000341\n",
      "[6/25][6030/9765] Loss_D: 0.1007 Loss_G: 0.0435 Convergence: 0.1046 k= 0.025937 lr = 0.0000341\n",
      "[6/25][6040/9765] Loss_D: 0.1108 Loss_G: 0.0412 Convergence: 0.1152 k= 0.025943 lr = 0.0000341\n",
      "[6/25][6050/9765] Loss_D: 0.0990 Loss_G: 0.0399 Convergence: 0.1003 k= 0.025940 lr = 0.0000341\n",
      "[6/25][6060/9765] Loss_D: 0.1020 Loss_G: 0.0426 Convergence: 0.1045 k= 0.025919 lr = 0.0000341\n",
      "[6/25][6070/9765] Loss_D: 0.0971 Loss_G: 0.0374 Convergence: 0.0998 k= 0.025927 lr = 0.0000341\n",
      "[6/25][6080/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0985 k= 0.025942 lr = 0.0000341\n",
      "[6/25][6090/9765] Loss_D: 0.0856 Loss_G: 0.0368 Convergence: 0.0888 k= 0.025931 lr = 0.0000341\n",
      "[6/25][6100/9765] Loss_D: 0.0978 Loss_G: 0.0360 Convergence: 0.1023 k= 0.025953 lr = 0.0000341\n",
      "[6/25][6110/9765] Loss_D: 0.1005 Loss_G: 0.0374 Convergence: 0.1047 k= 0.025974 lr = 0.0000341\n",
      "[6/25][6120/9765] Loss_D: 0.1043 Loss_G: 0.0376 Convergence: 0.1098 k= 0.025998 lr = 0.0000341\n",
      "[6/25][6130/9765] Loss_D: 0.1082 Loss_G: 0.0497 Convergence: 0.1153 k= 0.025984 lr = 0.0000341\n",
      "[6/25][6140/9765] Loss_D: 0.1114 Loss_G: 0.0432 Convergence: 0.1142 k= 0.025991 lr = 0.0000341\n",
      "[6/25][6150/9765] Loss_D: 0.0941 Loss_G: 0.0403 Convergence: 0.0975 k= 0.025975 lr = 0.0000341\n",
      "[6/25][6160/9765] Loss_D: 0.0984 Loss_G: 0.0391 Convergence: 0.1000 k= 0.025985 lr = 0.0000341\n",
      "[6/25][6170/9765] Loss_D: 0.1035 Loss_G: 0.0422 Convergence: 0.1050 k= 0.025998 lr = 0.0000341\n",
      "[6/25][6180/9765] Loss_D: 0.1017 Loss_G: 0.0434 Convergence: 0.1051 k= 0.025964 lr = 0.0000341\n",
      "[6/25][6190/9765] Loss_D: 0.1078 Loss_G: 0.0430 Convergence: 0.1094 k= 0.025952 lr = 0.0000341\n",
      "[6/25][6200/9765] Loss_D: 0.0981 Loss_G: 0.0437 Convergence: 0.1031 k= 0.025923 lr = 0.0000341\n",
      "[6/25][6210/9765] Loss_D: 0.0980 Loss_G: 0.0427 Convergence: 0.1021 k= 0.025912 lr = 0.0000341\n",
      "[6/25][6220/9765] Loss_D: 0.0912 Loss_G: 0.0377 Convergence: 0.0930 k= 0.025904 lr = 0.0000341\n",
      "[6/25][6230/9765] Loss_D: 0.1057 Loss_G: 0.0461 Convergence: 0.1103 k= 0.025882 lr = 0.0000341\n",
      "[6/25][6240/9765] Loss_D: 0.0955 Loss_G: 0.0399 Convergence: 0.0978 k= 0.025861 lr = 0.0000341\n",
      "[6/25][6250/9765] Loss_D: 0.1063 Loss_G: 0.0433 Convergence: 0.1077 k= 0.025844 lr = 0.0000341\n",
      "[6/25][6260/9765] Loss_D: 0.0917 Loss_G: 0.0415 Convergence: 0.0972 k= 0.025840 lr = 0.0000341\n",
      "[6/25][6270/9765] Loss_D: 0.0991 Loss_G: 0.0560 Convergence: 0.1163 k= 0.025787 lr = 0.0000341\n",
      "[6/25][6280/9765] Loss_D: 0.1024 Loss_G: 0.0419 Convergence: 0.1041 k= 0.025726 lr = 0.0000341\n",
      "[6/25][6290/9765] Loss_D: 0.1043 Loss_G: 0.0394 Convergence: 0.1080 k= 0.025733 lr = 0.0000341\n",
      "[6/25][6300/9765] Loss_D: 0.1025 Loss_G: 0.0414 Convergence: 0.1036 k= 0.025737 lr = 0.0000341\n",
      "[6/25][6310/9765] Loss_D: 0.1018 Loss_G: 0.0362 Convergence: 0.1077 k= 0.025752 lr = 0.0000341\n",
      "[6/25][6320/9765] Loss_D: 0.0985 Loss_G: 0.0328 Convergence: 0.1064 k= 0.025797 lr = 0.0000341\n",
      "[6/25][6330/9765] Loss_D: 0.0987 Loss_G: 0.0504 Convergence: 0.1104 k= 0.025776 lr = 0.0000341\n",
      "[6/25][6340/9765] Loss_D: 0.0917 Loss_G: 0.0370 Convergence: 0.0928 k= 0.025712 lr = 0.0000341\n",
      "[6/25][6350/9765] Loss_D: 0.0967 Loss_G: 0.0414 Convergence: 0.1000 k= 0.025745 lr = 0.0000341\n",
      "[6/25][6360/9765] Loss_D: 0.1060 Loss_G: 0.0371 Convergence: 0.1126 k= 0.025755 lr = 0.0000341\n",
      "[6/25][6370/9765] Loss_D: 0.1095 Loss_G: 0.0430 Convergence: 0.1117 k= 0.025762 lr = 0.0000341\n",
      "[6/25][6380/9765] Loss_D: 0.0971 Loss_G: 0.0405 Convergence: 0.0994 k= 0.025745 lr = 0.0000341\n",
      "[6/25][6390/9765] Loss_D: 0.1045 Loss_G: 0.0377 Convergence: 0.1100 k= 0.025765 lr = 0.0000341\n",
      "[6/25][6400/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1012 k= 0.025768 lr = 0.0000341\n",
      "[6/25][6410/9765] Loss_D: 0.0919 Loss_G: 0.0413 Convergence: 0.0971 k= 0.025768 lr = 0.0000341\n",
      "[6/25][6420/9765] Loss_D: 0.1184 Loss_G: 0.0415 Convergence: 0.1257 k= 0.025759 lr = 0.0000341\n",
      "[6/25][6430/9765] Loss_D: 0.0951 Loss_G: 0.0380 Convergence: 0.0967 k= 0.025756 lr = 0.0000341\n",
      "[6/25][6440/9765] Loss_D: 0.0946 Loss_G: 0.0405 Convergence: 0.0978 k= 0.025763 lr = 0.0000341\n",
      "[6/25][6450/9765] Loss_D: 0.0981 Loss_G: 0.0382 Convergence: 0.1005 k= 0.025771 lr = 0.0000341\n",
      "[6/25][6460/9765] Loss_D: 0.1003 Loss_G: 0.0432 Convergence: 0.1041 k= 0.025773 lr = 0.0000341\n",
      "[6/25][6470/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1045 k= 0.025788 lr = 0.0000341\n",
      "[6/25][6480/9765] Loss_D: 0.1055 Loss_G: 0.0448 Convergence: 0.1087 k= 0.025778 lr = 0.0000341\n",
      "[6/25][6490/9765] Loss_D: 0.1044 Loss_G: 0.0413 Convergence: 0.1062 k= 0.025761 lr = 0.0000341\n",
      "[6/25][6500/9765] Loss_D: 0.1056 Loss_G: 0.0410 Convergence: 0.1082 k= 0.025754 lr = 0.0000341\n",
      "[6/25][6510/9765] Loss_D: 0.0992 Loss_G: 0.0467 Convergence: 0.1068 k= 0.025748 lr = 0.0000341\n",
      "[6/25][6520/9765] Loss_D: 0.1076 Loss_G: 0.0438 Convergence: 0.1090 k= 0.025733 lr = 0.0000341\n",
      "[6/25][6530/9765] Loss_D: 0.1009 Loss_G: 0.0372 Convergence: 0.1054 k= 0.025735 lr = 0.0000341\n",
      "[6/25][6540/9765] Loss_D: 0.1005 Loss_G: 0.0373 Convergence: 0.1048 k= 0.025757 lr = 0.0000341\n",
      "[6/25][6550/9765] Loss_D: 0.1016 Loss_G: 0.0446 Convergence: 0.1062 k= 0.025780 lr = 0.0000341\n",
      "[6/25][6560/9765] Loss_D: 0.1027 Loss_G: 0.0392 Convergence: 0.1060 k= 0.025752 lr = 0.0000341\n",
      "[6/25][6570/9765] Loss_D: 0.0917 Loss_G: 0.0419 Convergence: 0.0975 k= 0.025746 lr = 0.0000341\n",
      "[6/25][6580/9765] Loss_D: 0.1164 Loss_G: 0.0374 Convergence: 0.1269 k= 0.025765 lr = 0.0000341\n",
      "[6/25][6590/9765] Loss_D: 0.1055 Loss_G: 0.0424 Convergence: 0.1068 k= 0.025762 lr = 0.0000341\n",
      "[6/25][6600/9765] Loss_D: 0.0960 Loss_G: 0.0414 Convergence: 0.0997 k= 0.025752 lr = 0.0000341\n",
      "[6/25][6610/9765] Loss_D: 0.0955 Loss_G: 0.0397 Convergence: 0.0977 k= 0.025744 lr = 0.0000341\n",
      "[6/25][6620/9765] Loss_D: 0.1085 Loss_G: 0.0421 Convergence: 0.1113 k= 0.025759 lr = 0.0000341\n",
      "[6/25][6630/9765] Loss_D: 0.0977 Loss_G: 0.0397 Convergence: 0.0990 k= 0.025764 lr = 0.0000341\n",
      "[6/25][6640/9765] Loss_D: 0.1075 Loss_G: 0.0407 Convergence: 0.1113 k= 0.025768 lr = 0.0000341\n",
      "[6/25][6650/9765] Loss_D: 0.0956 Loss_G: 0.0398 Convergence: 0.0978 k= 0.025748 lr = 0.0000341\n",
      "[6/25][6660/9765] Loss_D: 0.1050 Loss_G: 0.0444 Convergence: 0.1081 k= 0.025753 lr = 0.0000341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][6670/9765] Loss_D: 0.0949 Loss_G: 0.0419 Convergence: 0.0995 k= 0.025739 lr = 0.0000341\n",
      "[6/25][6680/9765] Loss_D: 0.1025 Loss_G: 0.0403 Convergence: 0.1048 k= 0.025730 lr = 0.0000341\n",
      "[6/25][6690/9765] Loss_D: 0.1027 Loss_G: 0.0373 Convergence: 0.1080 k= 0.025719 lr = 0.0000341\n",
      "[6/25][6700/9765] Loss_D: 0.1005 Loss_G: 0.0424 Convergence: 0.1033 k= 0.025717 lr = 0.0000341\n",
      "[6/25][6710/9765] Loss_D: 0.1055 Loss_G: 0.0427 Convergence: 0.1066 k= 0.025710 lr = 0.0000341\n",
      "[6/25][6720/9765] Loss_D: 0.1014 Loss_G: 0.0415 Convergence: 0.1030 k= 0.025701 lr = 0.0000341\n",
      "[6/25][6730/9765] Loss_D: 0.1102 Loss_G: 0.0381 Convergence: 0.1176 k= 0.025725 lr = 0.0000341\n",
      "[6/25][6740/9765] Loss_D: 0.1018 Loss_G: 0.0429 Convergence: 0.1047 k= 0.025711 lr = 0.0000341\n",
      "[6/25][6750/9765] Loss_D: 0.1017 Loss_G: 0.0420 Convergence: 0.1037 k= 0.025687 lr = 0.0000341\n",
      "[6/25][6760/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0997 k= 0.025698 lr = 0.0000341\n",
      "[6/25][6770/9765] Loss_D: 0.0890 Loss_G: 0.0404 Convergence: 0.0943 k= 0.025707 lr = 0.0000341\n",
      "[6/25][6780/9765] Loss_D: 0.1098 Loss_G: 0.0398 Convergence: 0.1153 k= 0.025735 lr = 0.0000341\n",
      "[6/25][6790/9765] Loss_D: 0.1128 Loss_G: 0.0436 Convergence: 0.1157 k= 0.025745 lr = 0.0000341\n",
      "[6/25][6800/9765] Loss_D: 0.1014 Loss_G: 0.0431 Convergence: 0.1046 k= 0.025716 lr = 0.0000341\n",
      "[6/25][6810/9765] Loss_D: 0.0922 Loss_G: 0.0408 Convergence: 0.0967 k= 0.025716 lr = 0.0000341\n",
      "[6/25][6820/9765] Loss_D: 0.1132 Loss_G: 0.0431 Convergence: 0.1169 k= 0.025712 lr = 0.0000341\n",
      "[6/25][6830/9765] Loss_D: 0.1000 Loss_G: 0.0444 Convergence: 0.1052 k= 0.025663 lr = 0.0000341\n",
      "[6/25][6840/9765] Loss_D: 0.0978 Loss_G: 0.0392 Convergence: 0.0992 k= 0.025643 lr = 0.0000341\n",
      "[6/25][6850/9765] Loss_D: 0.1011 Loss_G: 0.0408 Convergence: 0.1022 k= 0.025655 lr = 0.0000341\n",
      "[6/25][6860/9765] Loss_D: 0.0942 Loss_G: 0.0410 Convergence: 0.0982 k= 0.025645 lr = 0.0000341\n",
      "[6/25][6870/9765] Loss_D: 0.1005 Loss_G: 0.0461 Convergence: 0.1071 k= 0.025627 lr = 0.0000341\n",
      "[6/25][6880/9765] Loss_D: 0.0984 Loss_G: 0.0418 Convergence: 0.1015 k= 0.025629 lr = 0.0000341\n",
      "[6/25][6890/9765] Loss_D: 0.0994 Loss_G: 0.0387 Convergence: 0.1017 k= 0.025659 lr = 0.0000341\n",
      "[6/25][6900/9765] Loss_D: 0.0929 Loss_G: 0.0338 Convergence: 0.0974 k= 0.025677 lr = 0.0000341\n",
      "[6/25][6910/9765] Loss_D: 0.1018 Loss_G: 0.0409 Convergence: 0.1031 k= 0.025692 lr = 0.0000341\n",
      "[6/25][6920/9765] Loss_D: 0.1018 Loss_G: 0.0433 Convergence: 0.1051 k= 0.025665 lr = 0.0000341\n",
      "[6/25][6930/9765] Loss_D: 0.1145 Loss_G: 0.0426 Convergence: 0.1193 k= 0.025670 lr = 0.0000341\n",
      "[6/25][6940/9765] Loss_D: 0.0926 Loss_G: 0.0437 Convergence: 0.0999 k= 0.025681 lr = 0.0000341\n",
      "[6/25][6950/9765] Loss_D: 0.0993 Loss_G: 0.0427 Convergence: 0.1030 k= 0.025663 lr = 0.0000341\n",
      "[6/25][6960/9765] Loss_D: 0.1000 Loss_G: 0.0426 Convergence: 0.1033 k= 0.025653 lr = 0.0000341\n",
      "[6/25][6970/9765] Loss_D: 0.1021 Loss_G: 0.0449 Convergence: 0.1067 k= 0.025648 lr = 0.0000341\n",
      "[6/25][6980/9765] Loss_D: 0.1018 Loss_G: 0.0485 Convergence: 0.1102 k= 0.025620 lr = 0.0000341\n",
      "[6/25][6990/9765] Loss_D: 0.1018 Loss_G: 0.0403 Convergence: 0.1036 k= 0.025602 lr = 0.0000341\n",
      "[6/25][7000/9765] Loss_D: 0.1068 Loss_G: 0.0371 Convergence: 0.1137 k= 0.025629 lr = 0.0000341\n",
      "[6/25][7010/9765] Loss_D: 0.0986 Loss_G: 0.0469 Convergence: 0.1068 k= 0.025629 lr = 0.0000341\n",
      "[6/25][7020/9765] Loss_D: 0.0957 Loss_G: 0.0433 Convergence: 0.1014 k= 0.025604 lr = 0.0000341\n",
      "[6/25][7030/9765] Loss_D: 0.1021 Loss_G: 0.0397 Convergence: 0.1048 k= 0.025606 lr = 0.0000341\n",
      "[6/25][7040/9765] Loss_D: 0.1089 Loss_G: 0.0395 Convergence: 0.1144 k= 0.025614 lr = 0.0000341\n",
      "[6/25][7050/9765] Loss_D: 0.1070 Loss_G: 0.0422 Convergence: 0.1092 k= 0.025620 lr = 0.0000341\n",
      "[6/25][7060/9765] Loss_D: 0.1077 Loss_G: 0.0411 Convergence: 0.1110 k= 0.025628 lr = 0.0000341\n",
      "[6/25][7070/9765] Loss_D: 0.0977 Loss_G: 0.0380 Convergence: 0.1001 k= 0.025630 lr = 0.0000341\n",
      "[6/25][7080/9765] Loss_D: 0.1047 Loss_G: 0.0344 Convergence: 0.1135 k= 0.025659 lr = 0.0000341\n",
      "[6/25][7090/9765] Loss_D: 0.1055 Loss_G: 0.0456 Convergence: 0.1095 k= 0.025657 lr = 0.0000341\n",
      "[6/25][7100/9765] Loss_D: 0.0951 Loss_G: 0.0367 Convergence: 0.0977 k= 0.025661 lr = 0.0000341\n",
      "[6/25][7110/9765] Loss_D: 0.1070 Loss_G: 0.0417 Convergence: 0.1096 k= 0.025686 lr = 0.0000341\n",
      "[6/25][7120/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0971 k= 0.025679 lr = 0.0000341\n",
      "[6/25][7130/9765] Loss_D: 0.1050 Loss_G: 0.0400 Convergence: 0.1086 k= 0.025679 lr = 0.0000341\n",
      "[6/25][7140/9765] Loss_D: 0.1040 Loss_G: 0.0414 Convergence: 0.1055 k= 0.025687 lr = 0.0000341\n",
      "[6/25][7150/9765] Loss_D: 0.1060 Loss_G: 0.0441 Convergence: 0.1084 k= 0.025677 lr = 0.0000341\n",
      "[6/25][7160/9765] Loss_D: 0.1081 Loss_G: 0.0431 Convergence: 0.1097 k= 0.025662 lr = 0.0000341\n",
      "[6/25][7170/9765] Loss_D: 0.1031 Loss_G: 0.0402 Convergence: 0.1054 k= 0.025668 lr = 0.0000341\n",
      "[6/25][7180/9765] Loss_D: 0.1016 Loss_G: 0.0433 Convergence: 0.1049 k= 0.025662 lr = 0.0000341\n",
      "[6/25][7190/9765] Loss_D: 0.0951 Loss_G: 0.0399 Convergence: 0.0975 k= 0.025673 lr = 0.0000341\n",
      "[6/25][7200/9765] Loss_D: 0.1135 Loss_G: 0.0429 Convergence: 0.1174 k= 0.025656 lr = 0.0000341\n",
      "[6/25][7210/9765] Loss_D: 0.0921 Loss_G: 0.0406 Convergence: 0.0965 k= 0.025646 lr = 0.0000341\n",
      "[6/25][7220/9765] Loss_D: 0.1034 Loss_G: 0.0400 Convergence: 0.1063 k= 0.025661 lr = 0.0000341\n",
      "[6/25][7230/9765] Loss_D: 0.0998 Loss_G: 0.0429 Convergence: 0.1035 k= 0.025622 lr = 0.0000341\n",
      "[6/25][7240/9765] Loss_D: 0.0981 Loss_G: 0.0402 Convergence: 0.0997 k= 0.025610 lr = 0.0000341\n",
      "[6/25][7250/9765] Loss_D: 0.1026 Loss_G: 0.0427 Convergence: 0.1050 k= 0.025594 lr = 0.0000341\n",
      "[6/25][7260/9765] Loss_D: 0.0980 Loss_G: 0.0436 Convergence: 0.1030 k= 0.025578 lr = 0.0000341\n",
      "[6/25][7270/9765] Loss_D: 0.0972 Loss_G: 0.0436 Convergence: 0.1025 k= 0.025594 lr = 0.0000341\n",
      "[6/25][7280/9765] Loss_D: 0.1038 Loss_G: 0.0393 Convergence: 0.1073 k= 0.025594 lr = 0.0000341\n",
      "[6/25][7290/9765] Loss_D: 0.1071 Loss_G: 0.0471 Convergence: 0.1121 k= 0.025575 lr = 0.0000341\n",
      "[6/25][7300/9765] Loss_D: 0.0936 Loss_G: 0.0395 Convergence: 0.0963 k= 0.025549 lr = 0.0000341\n",
      "[6/25][7310/9765] Loss_D: 0.1019 Loss_G: 0.0415 Convergence: 0.1033 k= 0.025556 lr = 0.0000341\n",
      "[6/25][7320/9765] Loss_D: 0.1105 Loss_G: 0.0432 Convergence: 0.1132 k= 0.025545 lr = 0.0000341\n",
      "[6/25][7330/9765] Loss_D: 0.0947 Loss_G: 0.0398 Convergence: 0.0973 k= 0.025526 lr = 0.0000341\n",
      "[6/25][7340/9765] Loss_D: 0.1026 Loss_G: 0.0400 Convergence: 0.1051 k= 0.025528 lr = 0.0000341\n",
      "[6/25][7350/9765] Loss_D: 0.0941 Loss_G: 0.0394 Convergence: 0.0965 k= 0.025515 lr = 0.0000341\n",
      "[6/25][7360/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1039 k= 0.025506 lr = 0.0000341\n",
      "[6/25][7370/9765] Loss_D: 0.1075 Loss_G: 0.0416 Convergence: 0.1103 k= 0.025513 lr = 0.0000341\n",
      "[6/25][7380/9765] Loss_D: 0.1005 Loss_G: 0.0424 Convergence: 0.1034 k= 0.025475 lr = 0.0000341\n",
      "[6/25][7390/9765] Loss_D: 0.0951 Loss_G: 0.0410 Convergence: 0.0987 k= 0.025475 lr = 0.0000341\n",
      "[6/25][7400/9765] Loss_D: 0.1095 Loss_G: 0.0399 Convergence: 0.1149 k= 0.025504 lr = 0.0000341\n",
      "[6/25][7410/9765] Loss_D: 0.0993 Loss_G: 0.0519 Convergence: 0.1121 k= 0.025494 lr = 0.0000324\n",
      "[6/25][7420/9765] Loss_D: 0.0985 Loss_G: 0.0418 Convergence: 0.1015 k= 0.025478 lr = 0.0000324\n",
      "[6/25][7430/9765] Loss_D: 0.1019 Loss_G: 0.0414 Convergence: 0.1031 k= 0.025486 lr = 0.0000324\n",
      "[6/25][7440/9765] Loss_D: 0.0885 Loss_G: 0.0361 Convergence: 0.0898 k= 0.025486 lr = 0.0000324\n",
      "[6/25][7450/9765] Loss_D: 0.1085 Loss_G: 0.0462 Convergence: 0.1120 k= 0.025486 lr = 0.0000324\n",
      "[6/25][7460/9765] Loss_D: 0.1030 Loss_G: 0.0414 Convergence: 0.1043 k= 0.025470 lr = 0.0000324\n",
      "[6/25][7470/9765] Loss_D: 0.0973 Loss_G: 0.0406 Convergence: 0.0996 k= 0.025461 lr = 0.0000324\n",
      "[6/25][7480/9765] Loss_D: 0.1028 Loss_G: 0.0421 Convergence: 0.1044 k= 0.025481 lr = 0.0000324\n",
      "[6/25][7490/9765] Loss_D: 0.1092 Loss_G: 0.0440 Convergence: 0.1105 k= 0.025478 lr = 0.0000324\n",
      "[6/25][7500/9765] Loss_D: 0.0991 Loss_G: 0.0399 Convergence: 0.1004 k= 0.025443 lr = 0.0000324\n",
      "[6/25][7510/9765] Loss_D: 0.1078 Loss_G: 0.0384 Convergence: 0.1139 k= 0.025463 lr = 0.0000324\n",
      "[6/25][7520/9765] Loss_D: 0.0996 Loss_G: 0.0397 Convergence: 0.1012 k= 0.025458 lr = 0.0000324\n",
      "[6/25][7530/9765] Loss_D: 0.1056 Loss_G: 0.0360 Convergence: 0.1132 k= 0.025466 lr = 0.0000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][7540/9765] Loss_D: 0.1111 Loss_G: 0.0405 Convergence: 0.1165 k= 0.025495 lr = 0.0000324\n",
      "[6/25][7550/9765] Loss_D: 0.0970 Loss_G: 0.0415 Convergence: 0.1003 k= 0.025483 lr = 0.0000324\n",
      "[6/25][7560/9765] Loss_D: 0.1001 Loss_G: 0.0392 Convergence: 0.1025 k= 0.025481 lr = 0.0000324\n",
      "[6/25][7570/9765] Loss_D: 0.0943 Loss_G: 0.0435 Convergence: 0.1008 k= 0.025468 lr = 0.0000324\n",
      "[6/25][7580/9765] Loss_D: 0.1042 Loss_G: 0.0417 Convergence: 0.1057 k= 0.025453 lr = 0.0000324\n",
      "[6/25][7590/9765] Loss_D: 0.1027 Loss_G: 0.0377 Convergence: 0.1074 k= 0.025457 lr = 0.0000324\n",
      "[6/25][7600/9765] Loss_D: 0.1020 Loss_G: 0.0404 Convergence: 0.1039 k= 0.025475 lr = 0.0000324\n",
      "[6/25][7610/9765] Loss_D: 0.0886 Loss_G: 0.0420 Convergence: 0.0958 k= 0.025478 lr = 0.0000324\n",
      "[6/25][7620/9765] Loss_D: 0.1095 Loss_G: 0.0423 Convergence: 0.1126 k= 0.025462 lr = 0.0000324\n",
      "[6/25][7630/9765] Loss_D: 0.1050 Loss_G: 0.0390 Convergence: 0.1095 k= 0.025462 lr = 0.0000324\n",
      "[6/25][7640/9765] Loss_D: 0.0893 Loss_G: 0.0392 Convergence: 0.0934 k= 0.025467 lr = 0.0000324\n",
      "[6/25][7650/9765] Loss_D: 0.1079 Loss_G: 0.0433 Convergence: 0.1092 k= 0.025479 lr = 0.0000324\n",
      "[6/25][7660/9765] Loss_D: 0.1025 Loss_G: 0.0419 Convergence: 0.1041 k= 0.025485 lr = 0.0000324\n",
      "[6/25][7670/9765] Loss_D: 0.1036 Loss_G: 0.0383 Convergence: 0.1081 k= 0.025493 lr = 0.0000324\n",
      "[6/25][7680/9765] Loss_D: 0.1023 Loss_G: 0.0395 Convergence: 0.1051 k= 0.025502 lr = 0.0000324\n",
      "[6/25][7690/9765] Loss_D: 0.1029 Loss_G: 0.0375 Convergence: 0.1079 k= 0.025513 lr = 0.0000324\n",
      "[6/25][7700/9765] Loss_D: 0.1051 Loss_G: 0.0462 Convergence: 0.1099 k= 0.025494 lr = 0.0000324\n",
      "[6/25][7710/9765] Loss_D: 0.1059 Loss_G: 0.0363 Convergence: 0.1133 k= 0.025484 lr = 0.0000324\n",
      "[6/25][7720/9765] Loss_D: 0.1051 Loss_G: 0.0421 Convergence: 0.1064 k= 0.025525 lr = 0.0000324\n",
      "[6/25][7730/9765] Loss_D: 0.1110 Loss_G: 0.0444 Convergence: 0.1125 k= 0.025536 lr = 0.0000324\n",
      "[6/25][7740/9765] Loss_D: 0.0900 Loss_G: 0.0394 Convergence: 0.0941 k= 0.025519 lr = 0.0000324\n",
      "[6/25][7750/9765] Loss_D: 0.1001 Loss_G: 0.0408 Convergence: 0.1015 k= 0.025522 lr = 0.0000324\n",
      "[6/25][7760/9765] Loss_D: 0.0950 Loss_G: 0.0427 Convergence: 0.1003 k= 0.025526 lr = 0.0000324\n",
      "[6/25][7770/9765] Loss_D: 0.0972 Loss_G: 0.0455 Convergence: 0.1045 k= 0.025533 lr = 0.0000324\n",
      "[6/25][7780/9765] Loss_D: 0.1083 Loss_G: 0.0432 Convergence: 0.1098 k= 0.025537 lr = 0.0000324\n",
      "[6/25][7790/9765] Loss_D: 0.0990 Loss_G: 0.0400 Convergence: 0.1000 k= 0.025524 lr = 0.0000324\n",
      "[6/25][7800/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0992 k= 0.025520 lr = 0.0000324\n",
      "[6/25][7810/9765] Loss_D: 0.1038 Loss_G: 0.0440 Convergence: 0.1069 k= 0.025520 lr = 0.0000324\n",
      "[6/25][7820/9765] Loss_D: 0.1037 Loss_G: 0.0417 Convergence: 0.1049 k= 0.025513 lr = 0.0000324\n",
      "[6/25][7830/9765] Loss_D: 0.0940 Loss_G: 0.0394 Convergence: 0.0964 k= 0.025531 lr = 0.0000324\n",
      "[6/25][7840/9765] Loss_D: 0.0947 Loss_G: 0.0400 Convergence: 0.0974 k= 0.025535 lr = 0.0000324\n",
      "[6/25][7850/9765] Loss_D: 0.1054 Loss_G: 0.0409 Convergence: 0.1081 k= 0.025520 lr = 0.0000324\n",
      "[6/25][7860/9765] Loss_D: 0.0994 Loss_G: 0.0404 Convergence: 0.1007 k= 0.025514 lr = 0.0000324\n",
      "[6/25][7870/9765] Loss_D: 0.1029 Loss_G: 0.0440 Convergence: 0.1065 k= 0.025507 lr = 0.0000324\n",
      "[6/25][7880/9765] Loss_D: 0.1100 Loss_G: 0.0387 Convergence: 0.1167 k= 0.025533 lr = 0.0000324\n",
      "[6/25][7890/9765] Loss_D: 0.1046 Loss_G: 0.0456 Convergence: 0.1091 k= 0.025528 lr = 0.0000324\n",
      "[6/25][7900/9765] Loss_D: 0.1025 Loss_G: 0.0402 Convergence: 0.1049 k= 0.025525 lr = 0.0000324\n",
      "[6/25][7910/9765] Loss_D: 0.0988 Loss_G: 0.0431 Convergence: 0.1030 k= 0.025518 lr = 0.0000324\n",
      "[6/25][7920/9765] Loss_D: 0.1042 Loss_G: 0.0385 Convergence: 0.1088 k= 0.025510 lr = 0.0000324\n",
      "[6/25][7930/9765] Loss_D: 0.1038 Loss_G: 0.0418 Convergence: 0.1050 k= 0.025504 lr = 0.0000324\n",
      "[6/25][7940/9765] Loss_D: 0.1041 Loss_G: 0.0387 Convergence: 0.1083 k= 0.025526 lr = 0.0000324\n",
      "[6/25][7950/9765] Loss_D: 0.0949 Loss_G: 0.0346 Convergence: 0.0997 k= 0.025536 lr = 0.0000324\n",
      "[6/25][7960/9765] Loss_D: 0.0938 Loss_G: 0.0395 Convergence: 0.0964 k= 0.025555 lr = 0.0000324\n",
      "[6/25][7970/9765] Loss_D: 0.0944 Loss_G: 0.0373 Convergence: 0.0962 k= 0.025569 lr = 0.0000324\n",
      "[6/25][7980/9765] Loss_D: 0.0997 Loss_G: 0.0400 Convergence: 0.1010 k= 0.025594 lr = 0.0000324\n",
      "[6/25][7990/9765] Loss_D: 0.1042 Loss_G: 0.0383 Convergence: 0.1089 k= 0.025575 lr = 0.0000324\n",
      "[6/25][8000/9765] Loss_D: 0.1009 Loss_G: 0.0415 Convergence: 0.1027 k= 0.025583 lr = 0.0000324\n",
      "[6/25][8010/9765] Loss_D: 0.1049 Loss_G: 0.0444 Convergence: 0.1080 k= 0.025574 lr = 0.0000324\n",
      "[6/25][8020/9765] Loss_D: 0.1012 Loss_G: 0.0444 Convergence: 0.1058 k= 0.025577 lr = 0.0000324\n",
      "[6/25][8030/9765] Loss_D: 0.0940 Loss_G: 0.0381 Convergence: 0.0951 k= 0.025565 lr = 0.0000324\n",
      "[6/25][8040/9765] Loss_D: 0.0952 Loss_G: 0.0407 Convergence: 0.0984 k= 0.025562 lr = 0.0000324\n",
      "[6/25][8050/9765] Loss_D: 0.0972 Loss_G: 0.0371 Convergence: 0.1003 k= 0.025583 lr = 0.0000324\n",
      "[6/25][8060/9765] Loss_D: 0.1027 Loss_G: 0.0391 Convergence: 0.1059 k= 0.025615 lr = 0.0000324\n",
      "[6/25][8070/9765] Loss_D: 0.0941 Loss_G: 0.0450 Convergence: 0.1021 k= 0.025608 lr = 0.0000324\n",
      "[6/25][8080/9765] Loss_D: 0.1001 Loss_G: 0.0411 Convergence: 0.1018 k= 0.025573 lr = 0.0000324\n",
      "[6/25][8090/9765] Loss_D: 0.0965 Loss_G: 0.0395 Convergence: 0.0980 k= 0.025578 lr = 0.0000324\n",
      "[6/25][8100/9765] Loss_D: 0.0959 Loss_G: 0.0399 Convergence: 0.0980 k= 0.025603 lr = 0.0000324\n",
      "[6/25][8110/9765] Loss_D: 0.0993 Loss_G: 0.0436 Convergence: 0.1039 k= 0.025591 lr = 0.0000324\n",
      "[6/25][8120/9765] Loss_D: 0.1044 Loss_G: 0.0440 Convergence: 0.1073 k= 0.025544 lr = 0.0000324\n",
      "[6/25][8130/9765] Loss_D: 0.1062 Loss_G: 0.0389 Convergence: 0.1110 k= 0.025524 lr = 0.0000324\n",
      "[6/25][8140/9765] Loss_D: 0.0971 Loss_G: 0.0394 Convergence: 0.0982 k= 0.025555 lr = 0.0000324\n",
      "[6/25][8150/9765] Loss_D: 0.0988 Loss_G: 0.0464 Convergence: 0.1064 k= 0.025548 lr = 0.0000324\n",
      "[6/25][8160/9765] Loss_D: 0.1078 Loss_G: 0.0441 Convergence: 0.1094 k= 0.025513 lr = 0.0000324\n",
      "[6/25][8170/9765] Loss_D: 0.0983 Loss_G: 0.0361 Convergence: 0.1028 k= 0.025512 lr = 0.0000324\n",
      "[6/25][8180/9765] Loss_D: 0.0932 Loss_G: 0.0375 Convergence: 0.0943 k= 0.025551 lr = 0.0000324\n",
      "[6/25][8190/9765] Loss_D: 0.0997 Loss_G: 0.0432 Convergence: 0.1038 k= 0.025535 lr = 0.0000324\n",
      "[6/25][8200/9765] Loss_D: 0.0916 Loss_G: 0.0411 Convergence: 0.0967 k= 0.025511 lr = 0.0000324\n",
      "[6/25][8210/9765] Loss_D: 0.0999 Loss_G: 0.0389 Convergence: 0.1024 k= 0.025498 lr = 0.0000324\n",
      "[6/25][8220/9765] Loss_D: 0.0962 Loss_G: 0.0439 Convergence: 0.1023 k= 0.025492 lr = 0.0000324\n",
      "[6/25][8230/9765] Loss_D: 0.0994 Loss_G: 0.0385 Convergence: 0.1022 k= 0.025494 lr = 0.0000324\n",
      "[6/25][8240/9765] Loss_D: 0.1103 Loss_G: 0.0436 Convergence: 0.1123 k= 0.025480 lr = 0.0000324\n",
      "[6/25][8250/9765] Loss_D: 0.1072 Loss_G: 0.0385 Convergence: 0.1128 k= 0.025507 lr = 0.0000324\n",
      "[6/25][8260/9765] Loss_D: 0.0956 Loss_G: 0.0408 Convergence: 0.0988 k= 0.025499 lr = 0.0000324\n",
      "[6/25][8270/9765] Loss_D: 0.1015 Loss_G: 0.0403 Convergence: 0.1033 k= 0.025480 lr = 0.0000324\n",
      "[6/25][8280/9765] Loss_D: 0.0998 Loss_G: 0.0375 Convergence: 0.1037 k= 0.025501 lr = 0.0000324\n",
      "[6/25][8290/9765] Loss_D: 0.0926 Loss_G: 0.0362 Convergence: 0.0949 k= 0.025514 lr = 0.0000324\n",
      "[6/25][8300/9765] Loss_D: 0.0948 Loss_G: 0.0449 Convergence: 0.1024 k= 0.025502 lr = 0.0000324\n",
      "[6/25][8310/9765] Loss_D: 0.1027 Loss_G: 0.0401 Convergence: 0.1050 k= 0.025504 lr = 0.0000324\n",
      "[6/25][8320/9765] Loss_D: 0.0949 Loss_G: 0.0403 Convergence: 0.0978 k= 0.025497 lr = 0.0000324\n",
      "[6/25][8330/9765] Loss_D: 0.0975 Loss_G: 0.0395 Convergence: 0.0985 k= 0.025492 lr = 0.0000324\n",
      "[6/25][8340/9765] Loss_D: 0.0975 Loss_G: 0.0405 Convergence: 0.0996 k= 0.025499 lr = 0.0000324\n",
      "[6/25][8350/9765] Loss_D: 0.1002 Loss_G: 0.0408 Convergence: 0.1015 k= 0.025506 lr = 0.0000324\n",
      "[6/25][8360/9765] Loss_D: 0.1015 Loss_G: 0.0410 Convergence: 0.1025 k= 0.025494 lr = 0.0000324\n",
      "[6/25][8370/9765] Loss_D: 0.0997 Loss_G: 0.0425 Convergence: 0.1030 k= 0.025490 lr = 0.0000324\n",
      "[6/25][8380/9765] Loss_D: 0.0965 Loss_G: 0.0431 Convergence: 0.1017 k= 0.025470 lr = 0.0000324\n",
      "[6/25][8390/9765] Loss_D: 0.1009 Loss_G: 0.0407 Convergence: 0.1021 k= 0.025468 lr = 0.0000324\n",
      "[6/25][8400/9765] Loss_D: 0.0956 Loss_G: 0.0375 Convergence: 0.0977 k= 0.025479 lr = 0.0000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][8410/9765] Loss_D: 0.1067 Loss_G: 0.0435 Convergence: 0.1081 k= 0.025493 lr = 0.0000324\n",
      "[6/25][8420/9765] Loss_D: 0.1026 Loss_G: 0.0441 Convergence: 0.1063 k= 0.025482 lr = 0.0000324\n",
      "[6/25][8430/9765] Loss_D: 0.1059 Loss_G: 0.0430 Convergence: 0.1073 k= 0.025454 lr = 0.0000324\n",
      "[6/25][8440/9765] Loss_D: 0.0969 Loss_G: 0.0417 Convergence: 0.1005 k= 0.025420 lr = 0.0000324\n",
      "[6/25][8450/9765] Loss_D: 0.1041 Loss_G: 0.0397 Convergence: 0.1073 k= 0.025410 lr = 0.0000324\n",
      "[6/25][8460/9765] Loss_D: 0.1039 Loss_G: 0.0387 Convergence: 0.1081 k= 0.025435 lr = 0.0000324\n",
      "[6/25][8470/9765] Loss_D: 0.1133 Loss_G: 0.0366 Convergence: 0.1234 k= 0.025444 lr = 0.0000324\n",
      "[6/25][8480/9765] Loss_D: 0.0871 Loss_G: 0.0391 Convergence: 0.0920 k= 0.025461 lr = 0.0000324\n",
      "[6/25][8490/9765] Loss_D: 0.1013 Loss_G: 0.0414 Convergence: 0.1028 k= 0.025478 lr = 0.0000324\n",
      "[6/25][8500/9765] Loss_D: 0.0964 Loss_G: 0.0400 Convergence: 0.0985 k= 0.025439 lr = 0.0000324\n",
      "[6/25][8510/9765] Loss_D: 0.0956 Loss_G: 0.0429 Convergence: 0.1008 k= 0.025442 lr = 0.0000324\n",
      "[6/25][8520/9765] Loss_D: 0.1044 Loss_G: 0.0404 Convergence: 0.1072 k= 0.025462 lr = 0.0000324\n",
      "[6/25][8530/9765] Loss_D: 0.1026 Loss_G: 0.0402 Convergence: 0.1048 k= 0.025472 lr = 0.0000324\n",
      "[6/25][8540/9765] Loss_D: 0.0994 Loss_G: 0.0416 Convergence: 0.1018 k= 0.025445 lr = 0.0000324\n",
      "[6/25][8550/9765] Loss_D: 0.0995 Loss_G: 0.0442 Convergence: 0.1045 k= 0.025433 lr = 0.0000324\n",
      "[6/25][8560/9765] Loss_D: 0.0958 Loss_G: 0.0362 Convergence: 0.0992 k= 0.025465 lr = 0.0000324\n",
      "[6/25][8570/9765] Loss_D: 0.1087 Loss_G: 0.0379 Convergence: 0.1156 k= 0.025448 lr = 0.0000324\n",
      "[6/25][8580/9765] Loss_D: 0.1112 Loss_G: 0.0474 Convergence: 0.1148 k= 0.025433 lr = 0.0000324\n",
      "[6/25][8590/9765] Loss_D: 0.1119 Loss_G: 0.0391 Convergence: 0.1189 k= 0.025420 lr = 0.0000324\n",
      "[6/25][8600/9765] Loss_D: 0.1064 Loss_G: 0.0387 Convergence: 0.1117 k= 0.025440 lr = 0.0000324\n",
      "[6/25][8610/9765] Loss_D: 0.0919 Loss_G: 0.0410 Convergence: 0.0968 k= 0.025435 lr = 0.0000324\n",
      "[6/25][8620/9765] Loss_D: 0.1099 Loss_G: 0.0416 Convergence: 0.1138 k= 0.025421 lr = 0.0000324\n",
      "[6/25][8630/9765] Loss_D: 0.0978 Loss_G: 0.0376 Convergence: 0.1007 k= 0.025445 lr = 0.0000324\n",
      "[6/25][8640/9765] Loss_D: 0.1094 Loss_G: 0.0471 Convergence: 0.1134 k= 0.025454 lr = 0.0000324\n",
      "[6/25][8650/9765] Loss_D: 0.1025 Loss_G: 0.0400 Convergence: 0.1049 k= 0.025447 lr = 0.0000324\n",
      "[6/25][8660/9765] Loss_D: 0.1025 Loss_G: 0.0408 Convergence: 0.1042 k= 0.025433 lr = 0.0000324\n",
      "[6/25][8670/9765] Loss_D: 0.0949 Loss_G: 0.0371 Convergence: 0.0971 k= 0.025445 lr = 0.0000324\n",
      "[6/25][8680/9765] Loss_D: 0.1021 Loss_G: 0.0408 Convergence: 0.1037 k= 0.025457 lr = 0.0000324\n",
      "[6/25][8690/9765] Loss_D: 0.0979 Loss_G: 0.0423 Convergence: 0.1016 k= 0.025458 lr = 0.0000324\n",
      "[6/25][8700/9765] Loss_D: 0.0994 Loss_G: 0.0457 Convergence: 0.1059 k= 0.025461 lr = 0.0000324\n",
      "[6/25][8710/9765] Loss_D: 0.0981 Loss_G: 0.0366 Convergence: 0.1021 k= 0.025463 lr = 0.0000324\n",
      "[6/25][8720/9765] Loss_D: 0.1001 Loss_G: 0.0390 Convergence: 0.1026 k= 0.025501 lr = 0.0000324\n",
      "[6/25][8730/9765] Loss_D: 0.1036 Loss_G: 0.0393 Convergence: 0.1071 k= 0.025484 lr = 0.0000324\n",
      "[6/25][8740/9765] Loss_D: 0.0905 Loss_G: 0.0359 Convergence: 0.0920 k= 0.025499 lr = 0.0000324\n",
      "[6/25][8750/9765] Loss_D: 0.0995 Loss_G: 0.0419 Convergence: 0.1022 k= 0.025491 lr = 0.0000324\n",
      "[6/25][8760/9765] Loss_D: 0.1070 Loss_G: 0.0414 Convergence: 0.1098 k= 0.025485 lr = 0.0000324\n",
      "[6/25][8770/9765] Loss_D: 0.1037 Loss_G: 0.0424 Convergence: 0.1052 k= 0.025468 lr = 0.0000324\n",
      "[6/25][8780/9765] Loss_D: 0.1117 Loss_G: 0.0429 Convergence: 0.1149 k= 0.025459 lr = 0.0000324\n",
      "[6/25][8790/9765] Loss_D: 0.1039 Loss_G: 0.0410 Convergence: 0.1060 k= 0.025468 lr = 0.0000324\n",
      "[6/25][8800/9765] Loss_D: 0.1059 Loss_G: 0.0381 Convergence: 0.1115 k= 0.025473 lr = 0.0000324\n",
      "[6/25][8810/9765] Loss_D: 0.0950 Loss_G: 0.0390 Convergence: 0.0966 k= 0.025480 lr = 0.0000324\n",
      "[6/25][8820/9765] Loss_D: 0.1000 Loss_G: 0.0434 Convergence: 0.1040 k= 0.025480 lr = 0.0000324\n",
      "[6/25][8830/9765] Loss_D: 0.0991 Loss_G: 0.0448 Convergence: 0.1049 k= 0.025465 lr = 0.0000324\n",
      "[6/25][8840/9765] Loss_D: 0.1008 Loss_G: 0.0402 Convergence: 0.1024 k= 0.025464 lr = 0.0000324\n",
      "[6/25][8850/9765] Loss_D: 0.0966 Loss_G: 0.0391 Convergence: 0.0976 k= 0.025470 lr = 0.0000324\n",
      "[6/25][8860/9765] Loss_D: 0.1020 Loss_G: 0.0421 Convergence: 0.1040 k= 0.025456 lr = 0.0000324\n",
      "[6/25][8870/9765] Loss_D: 0.1048 Loss_G: 0.0407 Convergence: 0.1075 k= 0.025433 lr = 0.0000324\n",
      "[6/25][8880/9765] Loss_D: 0.1030 Loss_G: 0.0432 Convergence: 0.1056 k= 0.025439 lr = 0.0000324\n",
      "[6/25][8890/9765] Loss_D: 0.1068 Loss_G: 0.0409 Convergence: 0.1102 k= 0.025438 lr = 0.0000324\n",
      "[6/25][8900/9765] Loss_D: 0.1047 Loss_G: 0.0428 Convergence: 0.1063 k= 0.025417 lr = 0.0000324\n",
      "[6/25][8910/9765] Loss_D: 0.1074 Loss_G: 0.0410 Convergence: 0.1108 k= 0.025427 lr = 0.0000324\n",
      "[6/25][8920/9765] Loss_D: 0.1160 Loss_G: 0.0383 Convergence: 0.1254 k= 0.025446 lr = 0.0000324\n",
      "[6/25][8930/9765] Loss_D: 0.0915 Loss_G: 0.0376 Convergence: 0.0931 k= 0.025451 lr = 0.0000324\n",
      "[6/25][8940/9765] Loss_D: 0.1049 Loss_G: 0.0404 Convergence: 0.1079 k= 0.025464 lr = 0.0000324\n",
      "[6/25][8950/9765] Loss_D: 0.1040 Loss_G: 0.0397 Convergence: 0.1074 k= 0.025463 lr = 0.0000324\n",
      "[6/25][8960/9765] Loss_D: 0.1014 Loss_G: 0.0428 Convergence: 0.1042 k= 0.025480 lr = 0.0000324\n",
      "[6/25][8970/9765] Loss_D: 0.1051 Loss_G: 0.0396 Convergence: 0.1091 k= 0.025477 lr = 0.0000324\n",
      "[6/25][8980/9765] Loss_D: 0.1080 Loss_G: 0.0407 Convergence: 0.1118 k= 0.025477 lr = 0.0000324\n",
      "[6/25][8990/9765] Loss_D: 0.0979 Loss_G: 0.0464 Convergence: 0.1058 k= 0.025473 lr = 0.0000324\n",
      "[6/25][9000/9765] Loss_D: 0.0922 Loss_G: 0.0422 Convergence: 0.0982 k= 0.025442 lr = 0.0000324\n",
      "[6/25][9010/9765] Loss_D: 0.0945 Loss_G: 0.0401 Convergence: 0.0973 k= 0.025451 lr = 0.0000324\n",
      "[6/25][9020/9765] Loss_D: 0.1124 Loss_G: 0.0401 Convergence: 0.1185 k= 0.025455 lr = 0.0000324\n",
      "[6/25][9030/9765] Loss_D: 0.1009 Loss_G: 0.0444 Convergence: 0.1056 k= 0.025408 lr = 0.0000324\n",
      "[6/25][9040/9765] Loss_D: 0.0915 Loss_G: 0.0441 Convergence: 0.0996 k= 0.025359 lr = 0.0000324\n",
      "[6/25][9050/9765] Loss_D: 0.0956 Loss_G: 0.0354 Convergence: 0.0997 k= 0.025378 lr = 0.0000324\n",
      "[6/25][9060/9765] Loss_D: 0.0972 Loss_G: 0.0419 Convergence: 0.1009 k= 0.025389 lr = 0.0000324\n",
      "[6/25][9070/9765] Loss_D: 0.0979 Loss_G: 0.0393 Convergence: 0.0991 k= 0.025399 lr = 0.0000324\n",
      "[6/25][9080/9765] Loss_D: 0.1054 Loss_G: 0.0419 Convergence: 0.1070 k= 0.025399 lr = 0.0000324\n",
      "[6/25][9090/9765] Loss_D: 0.1012 Loss_G: 0.0406 Convergence: 0.1025 k= 0.025395 lr = 0.0000324\n",
      "[6/25][9100/9765] Loss_D: 0.0925 Loss_G: 0.0403 Convergence: 0.0964 k= 0.025395 lr = 0.0000324\n",
      "[6/25][9110/9765] Loss_D: 0.1069 Loss_G: 0.0426 Convergence: 0.1086 k= 0.025383 lr = 0.0000324\n",
      "[6/25][9120/9765] Loss_D: 0.1037 Loss_G: 0.0457 Convergence: 0.1086 k= 0.025357 lr = 0.0000324\n",
      "[6/25][9130/9765] Loss_D: 0.1017 Loss_G: 0.0461 Convergence: 0.1078 k= 0.025341 lr = 0.0000324\n",
      "[6/25][9140/9765] Loss_D: 0.0990 Loss_G: 0.0394 Convergence: 0.1007 k= 0.025343 lr = 0.0000324\n",
      "[6/25][9150/9765] Loss_D: 0.0980 Loss_G: 0.0405 Convergence: 0.0999 k= 0.025331 lr = 0.0000324\n",
      "[6/25][9160/9765] Loss_D: 0.0961 Loss_G: 0.0441 Convergence: 0.1024 k= 0.025324 lr = 0.0000324\n",
      "[6/25][9170/9765] Loss_D: 0.1042 Loss_G: 0.0415 Convergence: 0.1058 k= 0.025331 lr = 0.0000324\n",
      "[6/25][9180/9765] Loss_D: 0.0989 Loss_G: 0.0427 Convergence: 0.1028 k= 0.025309 lr = 0.0000324\n",
      "[6/25][9190/9765] Loss_D: 0.0868 Loss_G: 0.0389 Convergence: 0.0916 k= 0.025281 lr = 0.0000324\n",
      "[6/25][9200/9765] Loss_D: 0.1043 Loss_G: 0.0360 Convergence: 0.1113 k= 0.025320 lr = 0.0000324\n",
      "[6/25][9210/9765] Loss_D: 0.1046 Loss_G: 0.0392 Convergence: 0.1086 k= 0.025363 lr = 0.0000324\n",
      "[6/25][9220/9765] Loss_D: 0.1104 Loss_G: 0.0429 Convergence: 0.1131 k= 0.025338 lr = 0.0000324\n",
      "[6/25][9230/9765] Loss_D: 0.1066 Loss_G: 0.0397 Convergence: 0.1109 k= 0.025329 lr = 0.0000324\n",
      "[6/25][9240/9765] Loss_D: 0.1062 Loss_G: 0.0411 Convergence: 0.1092 k= 0.025334 lr = 0.0000324\n",
      "[6/25][9250/9765] Loss_D: 0.1045 Loss_G: 0.0403 Convergence: 0.1074 k= 0.025342 lr = 0.0000324\n",
      "[6/25][9260/9765] Loss_D: 0.0932 Loss_G: 0.0389 Convergence: 0.0954 k= 0.025337 lr = 0.0000324\n",
      "[6/25][9270/9765] Loss_D: 0.1021 Loss_G: 0.0425 Convergence: 0.1044 k= 0.025335 lr = 0.0000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/25][9280/9765] Loss_D: 0.1036 Loss_G: 0.0432 Convergence: 0.1060 k= 0.025338 lr = 0.0000324\n",
      "[6/25][9290/9765] Loss_D: 0.1046 Loss_G: 0.0383 Convergence: 0.1096 k= 0.025326 lr = 0.0000324\n",
      "[6/25][9300/9765] Loss_D: 0.1063 Loss_G: 0.0401 Convergence: 0.1101 k= 0.025332 lr = 0.0000324\n",
      "[6/25][9310/9765] Loss_D: 0.1071 Loss_G: 0.0424 Convergence: 0.1091 k= 0.025341 lr = 0.0000324\n",
      "[6/25][9320/9765] Loss_D: 0.1017 Loss_G: 0.0401 Convergence: 0.1036 k= 0.025346 lr = 0.0000324\n",
      "[6/25][9330/9765] Loss_D: 0.0966 Loss_G: 0.0403 Convergence: 0.0988 k= 0.025348 lr = 0.0000324\n",
      "[6/25][9340/9765] Loss_D: 0.1057 Loss_G: 0.0423 Convergence: 0.1071 k= 0.025345 lr = 0.0000324\n",
      "[6/25][9350/9765] Loss_D: 0.1010 Loss_G: 0.0380 Convergence: 0.1048 k= 0.025347 lr = 0.0000324\n",
      "[6/25][9360/9765] Loss_D: 0.0975 Loss_G: 0.0413 Convergence: 0.1004 k= 0.025340 lr = 0.0000324\n",
      "[6/25][9370/9765] Loss_D: 0.1023 Loss_G: 0.0378 Convergence: 0.1068 k= 0.025351 lr = 0.0000324\n",
      "[6/25][9380/9765] Loss_D: 0.0991 Loss_G: 0.0401 Convergence: 0.1002 k= 0.025354 lr = 0.0000324\n",
      "[6/25][9390/9765] Loss_D: 0.1069 Loss_G: 0.0427 Convergence: 0.1085 k= 0.025335 lr = 0.0000324\n",
      "[6/25][9400/9765] Loss_D: 0.1007 Loss_G: 0.0450 Convergence: 0.1060 k= 0.025312 lr = 0.0000324\n",
      "[6/25][9410/9765] Loss_D: 0.1016 Loss_G: 0.0439 Convergence: 0.1055 k= 0.025317 lr = 0.0000324\n",
      "[6/25][9420/9765] Loss_D: 0.1060 Loss_G: 0.0411 Convergence: 0.1087 k= 0.025308 lr = 0.0000324\n",
      "[6/25][9430/9765] Loss_D: 0.1025 Loss_G: 0.0442 Convergence: 0.1063 k= 0.025324 lr = 0.0000324\n",
      "[6/25][9440/9765] Loss_D: 0.1067 Loss_G: 0.0422 Convergence: 0.1088 k= 0.025330 lr = 0.0000324\n",
      "[6/25][9450/9765] Loss_D: 0.1133 Loss_G: 0.0443 Convergence: 0.1158 k= 0.025318 lr = 0.0000324\n",
      "[6/25][9460/9765] Loss_D: 0.1070 Loss_G: 0.0433 Convergence: 0.1081 k= 0.025295 lr = 0.0000324\n",
      "[6/25][9470/9765] Loss_D: 0.0936 Loss_G: 0.0422 Convergence: 0.0990 k= 0.025292 lr = 0.0000324\n",
      "[6/25][9480/9765] Loss_D: 0.1014 Loss_G: 0.0392 Convergence: 0.1042 k= 0.025289 lr = 0.0000324\n",
      "[6/25][9490/9765] Loss_D: 0.1000 Loss_G: 0.0420 Convergence: 0.1026 k= 0.025297 lr = 0.0000324\n",
      "[6/25][9500/9765] Loss_D: 0.0953 Loss_G: 0.0385 Convergence: 0.0963 k= 0.025282 lr = 0.0000324\n",
      "[6/25][9510/9765] Loss_D: 0.0942 Loss_G: 0.0381 Convergence: 0.0953 k= 0.025270 lr = 0.0000324\n",
      "[6/25][9520/9765] Loss_D: 0.1048 Loss_G: 0.0369 Convergence: 0.1111 k= 0.025312 lr = 0.0000324\n",
      "[6/25][9530/9765] Loss_D: 0.1061 Loss_G: 0.0496 Convergence: 0.1139 k= 0.025295 lr = 0.0000324\n",
      "[6/25][9540/9765] Loss_D: 0.1018 Loss_G: 0.0431 Convergence: 0.1048 k= 0.025261 lr = 0.0000324\n",
      "[6/25][9550/9765] Loss_D: 0.1007 Loss_G: 0.0398 Convergence: 0.1025 k= 0.025230 lr = 0.0000324\n",
      "[6/25][9560/9765] Loss_D: 0.1000 Loss_G: 0.0424 Convergence: 0.1031 k= 0.025236 lr = 0.0000324\n",
      "[6/25][9570/9765] Loss_D: 0.1063 Loss_G: 0.0386 Convergence: 0.1114 k= 0.025259 lr = 0.0000324\n",
      "[6/25][9580/9765] Loss_D: 0.1011 Loss_G: 0.0475 Convergence: 0.1090 k= 0.025227 lr = 0.0000324\n",
      "[6/25][9590/9765] Loss_D: 0.1046 Loss_G: 0.0420 Convergence: 0.1058 k= 0.025200 lr = 0.0000324\n",
      "[6/25][9600/9765] Loss_D: 0.0985 Loss_G: 0.0439 Convergence: 0.1036 k= 0.025211 lr = 0.0000324\n",
      "[6/25][9610/9765] Loss_D: 0.0999 Loss_G: 0.0395 Convergence: 0.1019 k= 0.025232 lr = 0.0000324\n",
      "[6/25][9620/9765] Loss_D: 0.0961 Loss_G: 0.0407 Convergence: 0.0990 k= 0.025224 lr = 0.0000324\n",
      "[6/25][9630/9765] Loss_D: 0.0954 Loss_G: 0.0405 Convergence: 0.0984 k= 0.025197 lr = 0.0000324\n",
      "[6/25][9640/9765] Loss_D: 0.1000 Loss_G: 0.0405 Convergence: 0.1011 k= 0.025215 lr = 0.0000324\n",
      "[6/25][9650/9765] Loss_D: 0.1082 Loss_G: 0.0416 Convergence: 0.1112 k= 0.025222 lr = 0.0000324\n",
      "[6/25][9660/9765] Loss_D: 0.0997 Loss_G: 0.0392 Convergence: 0.1017 k= 0.025210 lr = 0.0000324\n",
      "[6/25][9670/9765] Loss_D: 0.1126 Loss_G: 0.0381 Convergence: 0.1210 k= 0.025216 lr = 0.0000324\n",
      "[6/25][9680/9765] Loss_D: 0.0996 Loss_G: 0.0356 Convergence: 0.1051 k= 0.025266 lr = 0.0000324\n",
      "[6/25][9690/9765] Loss_D: 0.1021 Loss_G: 0.0458 Convergence: 0.1078 k= 0.025273 lr = 0.0000324\n",
      "[6/25][9700/9765] Loss_D: 0.1032 Loss_G: 0.0382 Convergence: 0.1077 k= 0.025248 lr = 0.0000324\n",
      "[6/25][9710/9765] Loss_D: 0.0964 Loss_G: 0.0400 Convergence: 0.0984 k= 0.025253 lr = 0.0000324\n",
      "[6/25][9720/9765] Loss_D: 0.1014 Loss_G: 0.0410 Convergence: 0.1025 k= 0.025254 lr = 0.0000324\n",
      "[6/25][9730/9765] Loss_D: 0.1039 Loss_G: 0.0394 Convergence: 0.1074 k= 0.025275 lr = 0.0000324\n",
      "[6/25][9740/9765] Loss_D: 0.1076 Loss_G: 0.0393 Convergence: 0.1128 k= 0.025277 lr = 0.0000324\n",
      "[6/25][9750/9765] Loss_D: 0.1015 Loss_G: 0.0500 Convergence: 0.1116 k= 0.025231 lr = 0.0000324\n",
      "[6/25][9760/9765] Loss_D: 0.0994 Loss_G: 0.0374 Convergence: 0.1030 k= 0.025260 lr = 0.0000324\n",
      "[7/25][0/9765] Loss_D: 0.1067 Loss_G: 0.0378 Convergence: 0.1129 k= 0.025272 lr = 0.0000324\n",
      "[7/25][10/9765] Loss_D: 0.0980 Loss_G: 0.0389 Convergence: 0.0998 k= 0.025274 lr = 0.0000324\n",
      "[7/25][20/9765] Loss_D: 0.0970 Loss_G: 0.0376 Convergence: 0.0996 k= 0.025286 lr = 0.0000324\n",
      "[7/25][30/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1036 k= 0.025295 lr = 0.0000324\n",
      "[7/25][40/9765] Loss_D: 0.1078 Loss_G: 0.0394 Convergence: 0.1129 k= 0.025299 lr = 0.0000324\n",
      "[7/25][50/9765] Loss_D: 0.0928 Loss_G: 0.0421 Convergence: 0.0984 k= 0.025277 lr = 0.0000324\n",
      "[7/25][60/9765] Loss_D: 0.0922 Loss_G: 0.0432 Convergence: 0.0991 k= 0.025275 lr = 0.0000324\n",
      "[7/25][70/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1023 k= 0.025293 lr = 0.0000324\n",
      "[7/25][80/9765] Loss_D: 0.1005 Loss_G: 0.0371 Convergence: 0.1048 k= 0.025319 lr = 0.0000324\n",
      "[7/25][90/9765] Loss_D: 0.0933 Loss_G: 0.0451 Convergence: 0.1017 k= 0.025317 lr = 0.0000324\n",
      "[7/25][100/9765] Loss_D: 0.0970 Loss_G: 0.0368 Convergence: 0.1003 k= 0.025308 lr = 0.0000324\n",
      "[7/25][110/9765] Loss_D: 0.1009 Loss_G: 0.0424 Convergence: 0.1036 k= 0.025324 lr = 0.0000324\n",
      "[7/25][120/9765] Loss_D: 0.1040 Loss_G: 0.0431 Convergence: 0.1061 k= 0.025340 lr = 0.0000324\n",
      "[7/25][130/9765] Loss_D: 0.1083 Loss_G: 0.0394 Convergence: 0.1136 k= 0.025337 lr = 0.0000324\n",
      "[7/25][140/9765] Loss_D: 0.1233 Loss_G: 0.0420 Convergence: 0.1323 k= 0.025344 lr = 0.0000324\n",
      "[7/25][150/9765] Loss_D: 0.1016 Loss_G: 0.0413 Convergence: 0.1029 k= 0.025341 lr = 0.0000324\n",
      "[7/25][160/9765] Loss_D: 0.0970 Loss_G: 0.0426 Convergence: 0.1014 k= 0.025332 lr = 0.0000324\n",
      "[7/25][170/9765] Loss_D: 0.0969 Loss_G: 0.0385 Convergence: 0.0985 k= 0.025344 lr = 0.0000324\n",
      "[7/25][180/9765] Loss_D: 0.1094 Loss_G: 0.0405 Convergence: 0.1142 k= 0.025367 lr = 0.0000324\n",
      "[7/25][190/9765] Loss_D: 0.1031 Loss_G: 0.0441 Convergence: 0.1066 k= 0.025372 lr = 0.0000324\n",
      "[7/25][200/9765] Loss_D: 0.0936 Loss_G: 0.0401 Convergence: 0.0969 k= 0.025362 lr = 0.0000324\n",
      "[7/25][210/9765] Loss_D: 0.1007 Loss_G: 0.0416 Convergence: 0.1026 k= 0.025365 lr = 0.0000324\n",
      "[7/25][220/9765] Loss_D: 0.0999 Loss_G: 0.0416 Convergence: 0.1021 k= 0.025370 lr = 0.0000324\n",
      "[7/25][230/9765] Loss_D: 0.0993 Loss_G: 0.0394 Convergence: 0.1009 k= 0.025379 lr = 0.0000324\n",
      "[7/25][240/9765] Loss_D: 0.0948 Loss_G: 0.0413 Convergence: 0.0988 k= 0.025384 lr = 0.0000324\n",
      "[7/25][250/9765] Loss_D: 0.0932 Loss_G: 0.0397 Convergence: 0.0962 k= 0.025367 lr = 0.0000324\n",
      "[7/25][260/9765] Loss_D: 0.1023 Loss_G: 0.0380 Convergence: 0.1067 k= 0.025371 lr = 0.0000324\n",
      "[7/25][270/9765] Loss_D: 0.0945 Loss_G: 0.0388 Convergence: 0.0960 k= 0.025373 lr = 0.0000324\n",
      "[7/25][280/9765] Loss_D: 0.0934 Loss_G: 0.0377 Convergence: 0.0944 k= 0.025400 lr = 0.0000324\n",
      "[7/25][290/9765] Loss_D: 0.0998 Loss_G: 0.0402 Convergence: 0.1011 k= 0.025394 lr = 0.0000324\n",
      "[7/25][300/9765] Loss_D: 0.0930 Loss_G: 0.0406 Convergence: 0.0970 k= 0.025381 lr = 0.0000324\n",
      "[7/25][310/9765] Loss_D: 0.1017 Loss_G: 0.0379 Convergence: 0.1058 k= 0.025384 lr = 0.0000324\n",
      "[7/25][320/9765] Loss_D: 0.1100 Loss_G: 0.0428 Convergence: 0.1126 k= 0.025377 lr = 0.0000324\n",
      "[7/25][330/9765] Loss_D: 0.1045 Loss_G: 0.0382 Convergence: 0.1094 k= 0.025376 lr = 0.0000324\n",
      "[7/25][340/9765] Loss_D: 0.0974 Loss_G: 0.0414 Convergence: 0.1005 k= 0.025358 lr = 0.0000324\n",
      "[7/25][350/9765] Loss_D: 0.1070 Loss_G: 0.0368 Convergence: 0.1142 k= 0.025378 lr = 0.0000324\n",
      "[7/25][360/9765] Loss_D: 0.1102 Loss_G: 0.0420 Convergence: 0.1138 k= 0.025377 lr = 0.0000324\n",
      "[7/25][370/9765] Loss_D: 0.1118 Loss_G: 0.0425 Convergence: 0.1154 k= 0.025371 lr = 0.0000324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][380/9765] Loss_D: 0.1046 Loss_G: 0.0423 Convergence: 0.1057 k= 0.025373 lr = 0.0000324\n",
      "[7/25][390/9765] Loss_D: 0.0950 Loss_G: 0.0396 Convergence: 0.0972 k= 0.025385 lr = 0.0000324\n",
      "[7/25][400/9765] Loss_D: 0.0994 Loss_G: 0.0411 Convergence: 0.1014 k= 0.025386 lr = 0.0000324\n",
      "[7/25][410/9765] Loss_D: 0.1017 Loss_G: 0.0459 Convergence: 0.1075 k= 0.025360 lr = 0.0000324\n",
      "[7/25][420/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1035 k= 0.025362 lr = 0.0000324\n",
      "[7/25][430/9765] Loss_D: 0.0908 Loss_G: 0.0380 Convergence: 0.0932 k= 0.025373 lr = 0.0000324\n",
      "[7/25][440/9765] Loss_D: 0.0952 Loss_G: 0.0402 Convergence: 0.0980 k= 0.025382 lr = 0.0000324\n",
      "[7/25][450/9765] Loss_D: 0.0986 Loss_G: 0.0398 Convergence: 0.0997 k= 0.025376 lr = 0.0000324\n",
      "[7/25][460/9765] Loss_D: 0.1014 Loss_G: 0.0396 Convergence: 0.1038 k= 0.025384 lr = 0.0000324\n",
      "[7/25][470/9765] Loss_D: 0.1149 Loss_G: 0.0410 Convergence: 0.1212 k= 0.025404 lr = 0.0000324\n",
      "[7/25][480/9765] Loss_D: 0.0961 Loss_G: 0.0430 Convergence: 0.1013 k= 0.025370 lr = 0.0000324\n",
      "[7/25][490/9765] Loss_D: 0.0998 Loss_G: 0.0419 Convergence: 0.1024 k= 0.025368 lr = 0.0000324\n",
      "[7/25][500/9765] Loss_D: 0.1020 Loss_G: 0.0400 Convergence: 0.1042 k= 0.025363 lr = 0.0000324\n",
      "[7/25][510/9765] Loss_D: 0.1031 Loss_G: 0.0408 Convergence: 0.1049 k= 0.025368 lr = 0.0000324\n",
      "[7/25][520/9765] Loss_D: 0.0991 Loss_G: 0.0455 Convergence: 0.1056 k= 0.025356 lr = 0.0000324\n",
      "[7/25][530/9765] Loss_D: 0.1073 Loss_G: 0.0429 Convergence: 0.1089 k= 0.025331 lr = 0.0000324\n",
      "[7/25][540/9765] Loss_D: 0.0991 Loss_G: 0.0427 Convergence: 0.1027 k= 0.025342 lr = 0.0000324\n",
      "[7/25][550/9765] Loss_D: 0.1074 Loss_G: 0.0417 Convergence: 0.1100 k= 0.025365 lr = 0.0000324\n",
      "[7/25][560/9765] Loss_D: 0.1000 Loss_G: 0.0382 Convergence: 0.1031 k= 0.025356 lr = 0.0000324\n",
      "[7/25][570/9765] Loss_D: 0.1037 Loss_G: 0.0446 Convergence: 0.1075 k= 0.025349 lr = 0.0000324\n",
      "[7/25][580/9765] Loss_D: 0.0886 Loss_G: 0.0407 Convergence: 0.0945 k= 0.025338 lr = 0.0000324\n",
      "[7/25][590/9765] Loss_D: 0.1002 Loss_G: 0.0394 Convergence: 0.1023 k= 0.025334 lr = 0.0000324\n",
      "[7/25][600/9765] Loss_D: 0.1016 Loss_G: 0.0424 Convergence: 0.1041 k= 0.025341 lr = 0.0000324\n",
      "[7/25][610/9765] Loss_D: 0.1042 Loss_G: 0.0385 Convergence: 0.1088 k= 0.025326 lr = 0.0000324\n",
      "[7/25][620/9765] Loss_D: 0.1026 Loss_G: 0.0400 Convergence: 0.1050 k= 0.025320 lr = 0.0000324\n",
      "[7/25][630/9765] Loss_D: 0.0996 Loss_G: 0.0405 Convergence: 0.1009 k= 0.025322 lr = 0.0000324\n",
      "[7/25][640/9765] Loss_D: 0.1028 Loss_G: 0.0396 Convergence: 0.1057 k= 0.025310 lr = 0.0000324\n",
      "[7/25][650/9765] Loss_D: 0.1022 Loss_G: 0.0384 Convergence: 0.1062 k= 0.025312 lr = 0.0000307\n",
      "[7/25][660/9765] Loss_D: 0.1096 Loss_G: 0.0398 Convergence: 0.1149 k= 0.025313 lr = 0.0000307\n",
      "[7/25][670/9765] Loss_D: 0.0969 Loss_G: 0.0453 Convergence: 0.1041 k= 0.025277 lr = 0.0000307\n",
      "[7/25][680/9765] Loss_D: 0.1110 Loss_G: 0.0430 Convergence: 0.1139 k= 0.025259 lr = 0.0000307\n",
      "[7/25][690/9765] Loss_D: 0.0914 Loss_G: 0.0400 Convergence: 0.0955 k= 0.025279 lr = 0.0000307\n",
      "[7/25][700/9765] Loss_D: 0.0995 Loss_G: 0.0475 Convergence: 0.1078 k= 0.025269 lr = 0.0000307\n",
      "[7/25][710/9765] Loss_D: 0.1007 Loss_G: 0.0440 Convergence: 0.1051 k= 0.025224 lr = 0.0000307\n",
      "[7/25][720/9765] Loss_D: 0.0969 Loss_G: 0.0378 Convergence: 0.0992 k= 0.025213 lr = 0.0000307\n",
      "[7/25][730/9765] Loss_D: 0.1171 Loss_G: 0.0368 Convergence: 0.1284 k= 0.025258 lr = 0.0000307\n",
      "[7/25][740/9765] Loss_D: 0.0968 Loss_G: 0.0456 Convergence: 0.1044 k= 0.025252 lr = 0.0000307\n",
      "[7/25][750/9765] Loss_D: 0.0975 Loss_G: 0.0407 Convergence: 0.0997 k= 0.025259 lr = 0.0000307\n",
      "[7/25][760/9765] Loss_D: 0.0947 Loss_G: 0.0424 Convergence: 0.0999 k= 0.025254 lr = 0.0000307\n",
      "[7/25][770/9765] Loss_D: 0.0939 Loss_G: 0.0423 Convergence: 0.0992 k= 0.025258 lr = 0.0000307\n",
      "[7/25][780/9765] Loss_D: 0.1054 Loss_G: 0.0438 Convergence: 0.1077 k= 0.025237 lr = 0.0000307\n",
      "[7/25][790/9765] Loss_D: 0.1060 Loss_G: 0.0421 Convergence: 0.1077 k= 0.025218 lr = 0.0000307\n",
      "[7/25][800/9765] Loss_D: 0.0972 Loss_G: 0.0404 Convergence: 0.0994 k= 0.025230 lr = 0.0000307\n",
      "[7/25][810/9765] Loss_D: 0.0969 Loss_G: 0.0408 Convergence: 0.0995 k= 0.025213 lr = 0.0000307\n",
      "[7/25][820/9765] Loss_D: 0.1047 Loss_G: 0.0406 Convergence: 0.1073 k= 0.025218 lr = 0.0000307\n",
      "[7/25][830/9765] Loss_D: 0.0991 Loss_G: 0.0409 Convergence: 0.1010 k= 0.025205 lr = 0.0000307\n",
      "[7/25][840/9765] Loss_D: 0.1007 Loss_G: 0.0431 Convergence: 0.1042 k= 0.025202 lr = 0.0000307\n",
      "[7/25][850/9765] Loss_D: 0.0952 Loss_G: 0.0403 Convergence: 0.0980 k= 0.025193 lr = 0.0000307\n",
      "[7/25][860/9765] Loss_D: 0.1055 Loss_G: 0.0391 Convergence: 0.1099 k= 0.025209 lr = 0.0000307\n",
      "[7/25][870/9765] Loss_D: 0.0978 Loss_G: 0.0429 Convergence: 0.1023 k= 0.025193 lr = 0.0000307\n",
      "[7/25][880/9765] Loss_D: 0.1058 Loss_G: 0.0369 Convergence: 0.1124 k= 0.025207 lr = 0.0000307\n",
      "[7/25][890/9765] Loss_D: 0.1003 Loss_G: 0.0411 Convergence: 0.1019 k= 0.025219 lr = 0.0000307\n",
      "[7/25][900/9765] Loss_D: 0.0941 Loss_G: 0.0408 Convergence: 0.0979 k= 0.025195 lr = 0.0000307\n",
      "[7/25][910/9765] Loss_D: 0.1031 Loss_G: 0.0431 Convergence: 0.1056 k= 0.025203 lr = 0.0000307\n",
      "[7/25][920/9765] Loss_D: 0.0997 Loss_G: 0.0382 Convergence: 0.1027 k= 0.025216 lr = 0.0000307\n",
      "[7/25][930/9765] Loss_D: 0.0948 Loss_G: 0.0395 Convergence: 0.0970 k= 0.025225 lr = 0.0000307\n",
      "[7/25][940/9765] Loss_D: 0.1021 Loss_G: 0.0453 Convergence: 0.1071 k= 0.025216 lr = 0.0000307\n",
      "[7/25][950/9765] Loss_D: 0.0999 Loss_G: 0.0414 Convergence: 0.1020 k= 0.025208 lr = 0.0000307\n",
      "[7/25][960/9765] Loss_D: 0.0924 Loss_G: 0.0412 Convergence: 0.0973 k= 0.025206 lr = 0.0000307\n",
      "[7/25][970/9765] Loss_D: 0.0939 Loss_G: 0.0450 Convergence: 0.1021 k= 0.025191 lr = 0.0000307\n",
      "[7/25][980/9765] Loss_D: 0.0999 Loss_G: 0.0413 Convergence: 0.1019 k= 0.025169 lr = 0.0000307\n",
      "[7/25][990/9765] Loss_D: 0.0950 Loss_G: 0.0389 Convergence: 0.0966 k= 0.025173 lr = 0.0000307\n",
      "[7/25][1000/9765] Loss_D: 0.0975 Loss_G: 0.0402 Convergence: 0.0993 k= 0.025195 lr = 0.0000307\n",
      "[7/25][1010/9765] Loss_D: 0.1064 Loss_G: 0.0474 Convergence: 0.1119 k= 0.025164 lr = 0.0000307\n",
      "[7/25][1020/9765] Loss_D: 0.0911 Loss_G: 0.0414 Convergence: 0.0968 k= 0.025073 lr = 0.0000307\n",
      "[7/25][1030/9765] Loss_D: 0.1028 Loss_G: 0.0372 Convergence: 0.1080 k= 0.025097 lr = 0.0000307\n",
      "[7/25][1040/9765] Loss_D: 0.0977 Loss_G: 0.0383 Convergence: 0.0998 k= 0.025119 lr = 0.0000307\n",
      "[7/25][1050/9765] Loss_D: 0.0950 Loss_G: 0.0417 Convergence: 0.0994 k= 0.025128 lr = 0.0000307\n",
      "[7/25][1060/9765] Loss_D: 0.0951 Loss_G: 0.0385 Convergence: 0.0962 k= 0.025104 lr = 0.0000307\n",
      "[7/25][1070/9765] Loss_D: 0.1103 Loss_G: 0.0381 Convergence: 0.1178 k= 0.025100 lr = 0.0000307\n",
      "[7/25][1080/9765] Loss_D: 0.1029 Loss_G: 0.0421 Convergence: 0.1044 k= 0.025118 lr = 0.0000307\n",
      "[7/25][1090/9765] Loss_D: 0.1007 Loss_G: 0.0394 Convergence: 0.1030 k= 0.025106 lr = 0.0000307\n",
      "[7/25][1100/9765] Loss_D: 0.0915 Loss_G: 0.0400 Convergence: 0.0955 k= 0.025089 lr = 0.0000307\n",
      "[7/25][1110/9765] Loss_D: 0.1122 Loss_G: 0.0418 Convergence: 0.1168 k= 0.025098 lr = 0.0000307\n",
      "[7/25][1120/9765] Loss_D: 0.1094 Loss_G: 0.0390 Convergence: 0.1156 k= 0.025100 lr = 0.0000307\n",
      "[7/25][1130/9765] Loss_D: 0.0965 Loss_G: 0.0463 Convergence: 0.1050 k= 0.025096 lr = 0.0000307\n",
      "[7/25][1140/9765] Loss_D: 0.1086 Loss_G: 0.0389 Convergence: 0.1146 k= 0.025082 lr = 0.0000307\n",
      "[7/25][1150/9765] Loss_D: 0.0993 Loss_G: 0.0397 Convergence: 0.1007 k= 0.025075 lr = 0.0000307\n",
      "[7/25][1160/9765] Loss_D: 0.1006 Loss_G: 0.0396 Convergence: 0.1028 k= 0.025073 lr = 0.0000307\n",
      "[7/25][1170/9765] Loss_D: 0.1101 Loss_G: 0.0463 Convergence: 0.1130 k= 0.025061 lr = 0.0000307\n",
      "[7/25][1180/9765] Loss_D: 0.1089 Loss_G: 0.0431 Convergence: 0.1109 k= 0.025052 lr = 0.0000307\n",
      "[7/25][1190/9765] Loss_D: 0.1004 Loss_G: 0.0430 Convergence: 0.1038 k= 0.025064 lr = 0.0000307\n",
      "[7/25][1200/9765] Loss_D: 0.0901 Loss_G: 0.0424 Convergence: 0.0971 k= 0.025038 lr = 0.0000307\n",
      "[7/25][1210/9765] Loss_D: 0.1071 Loss_G: 0.0392 Convergence: 0.1121 k= 0.025051 lr = 0.0000307\n",
      "[7/25][1220/9765] Loss_D: 0.1122 Loss_G: 0.0418 Convergence: 0.1167 k= 0.025054 lr = 0.0000307\n",
      "[7/25][1230/9765] Loss_D: 0.0962 Loss_G: 0.0458 Convergence: 0.1042 k= 0.025036 lr = 0.0000307\n",
      "[7/25][1240/9765] Loss_D: 0.0916 Loss_G: 0.0390 Convergence: 0.0946 k= 0.025042 lr = 0.0000307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][1250/9765] Loss_D: 0.0969 Loss_G: 0.0415 Convergence: 0.1003 k= 0.025070 lr = 0.0000307\n",
      "[7/25][1260/9765] Loss_D: 0.1012 Loss_G: 0.0437 Convergence: 0.1051 k= 0.025038 lr = 0.0000307\n",
      "[7/25][1270/9765] Loss_D: 0.1086 Loss_G: 0.0467 Convergence: 0.1125 k= 0.024986 lr = 0.0000307\n",
      "[7/25][1280/9765] Loss_D: 0.0925 Loss_G: 0.0369 Convergence: 0.0940 k= 0.024996 lr = 0.0000307\n",
      "[7/25][1290/9765] Loss_D: 0.1039 Loss_G: 0.0384 Convergence: 0.1084 k= 0.025033 lr = 0.0000307\n",
      "[7/25][1300/9765] Loss_D: 0.1021 Loss_G: 0.0435 Convergence: 0.1054 k= 0.025026 lr = 0.0000307\n",
      "[7/25][1310/9765] Loss_D: 0.1082 Loss_G: 0.0426 Convergence: 0.1103 k= 0.025042 lr = 0.0000307\n",
      "[7/25][1320/9765] Loss_D: 0.0935 Loss_G: 0.0436 Convergence: 0.1004 k= 0.025024 lr = 0.0000307\n",
      "[7/25][1330/9765] Loss_D: 0.1051 Loss_G: 0.0427 Convergence: 0.1064 k= 0.025010 lr = 0.0000307\n",
      "[7/25][1340/9765] Loss_D: 0.0917 Loss_G: 0.0405 Convergence: 0.0961 k= 0.025018 lr = 0.0000307\n",
      "[7/25][1350/9765] Loss_D: 0.0961 Loss_G: 0.0397 Convergence: 0.0979 k= 0.025020 lr = 0.0000307\n",
      "[7/25][1360/9765] Loss_D: 0.0928 Loss_G: 0.0434 Convergence: 0.0997 k= 0.025011 lr = 0.0000307\n",
      "[7/25][1370/9765] Loss_D: 0.1008 Loss_G: 0.0421 Convergence: 0.1032 k= 0.024989 lr = 0.0000307\n",
      "[7/25][1380/9765] Loss_D: 0.1103 Loss_G: 0.0419 Convergence: 0.1139 k= 0.024981 lr = 0.0000307\n",
      "[7/25][1390/9765] Loss_D: 0.0967 Loss_G: 0.0403 Convergence: 0.0989 k= 0.024983 lr = 0.0000307\n",
      "[7/25][1400/9765] Loss_D: 0.1025 Loss_G: 0.0407 Convergence: 0.1043 k= 0.024989 lr = 0.0000307\n",
      "[7/25][1410/9765] Loss_D: 0.1087 Loss_G: 0.0432 Convergence: 0.1104 k= 0.024983 lr = 0.0000307\n",
      "[7/25][1420/9765] Loss_D: 0.0954 Loss_G: 0.0390 Convergence: 0.0969 k= 0.024968 lr = 0.0000307\n",
      "[7/25][1430/9765] Loss_D: 0.0953 Loss_G: 0.0423 Convergence: 0.1001 k= 0.024977 lr = 0.0000307\n",
      "[7/25][1440/9765] Loss_D: 0.1048 Loss_G: 0.0419 Convergence: 0.1062 k= 0.024971 lr = 0.0000307\n",
      "[7/25][1450/9765] Loss_D: 0.1037 Loss_G: 0.0386 Convergence: 0.1079 k= 0.024980 lr = 0.0000307\n",
      "[7/25][1460/9765] Loss_D: 0.0971 Loss_G: 0.0391 Convergence: 0.0983 k= 0.024986 lr = 0.0000307\n",
      "[7/25][1470/9765] Loss_D: 0.1043 Loss_G: 0.0394 Convergence: 0.1079 k= 0.024995 lr = 0.0000307\n",
      "[7/25][1480/9765] Loss_D: 0.0998 Loss_G: 0.0424 Convergence: 0.1029 k= 0.024994 lr = 0.0000307\n",
      "[7/25][1490/9765] Loss_D: 0.0989 Loss_G: 0.0414 Convergence: 0.1013 k= 0.024981 lr = 0.0000307\n",
      "[7/25][1500/9765] Loss_D: 0.0971 Loss_G: 0.0412 Convergence: 0.1002 k= 0.024979 lr = 0.0000307\n",
      "[7/25][1510/9765] Loss_D: 0.0924 Loss_G: 0.0369 Convergence: 0.0938 k= 0.024983 lr = 0.0000307\n",
      "[7/25][1520/9765] Loss_D: 0.1117 Loss_G: 0.0406 Convergence: 0.1172 k= 0.024989 lr = 0.0000307\n",
      "[7/25][1530/9765] Loss_D: 0.1076 Loss_G: 0.0419 Convergence: 0.1101 k= 0.024991 lr = 0.0000307\n",
      "[7/25][1540/9765] Loss_D: 0.0980 Loss_G: 0.0387 Convergence: 0.0998 k= 0.024980 lr = 0.0000307\n",
      "[7/25][1550/9765] Loss_D: 0.0894 Loss_G: 0.0401 Convergence: 0.0943 k= 0.024982 lr = 0.0000307\n",
      "[7/25][1560/9765] Loss_D: 0.0931 Loss_G: 0.0389 Convergence: 0.0954 k= 0.024985 lr = 0.0000307\n",
      "[7/25][1570/9765] Loss_D: 0.0948 Loss_G: 0.0416 Convergence: 0.0992 k= 0.024974 lr = 0.0000307\n",
      "[7/25][1580/9765] Loss_D: 0.1061 Loss_G: 0.0414 Convergence: 0.1086 k= 0.024981 lr = 0.0000307\n",
      "[7/25][1590/9765] Loss_D: 0.0982 Loss_G: 0.0359 Convergence: 0.1029 k= 0.025001 lr = 0.0000307\n",
      "[7/25][1600/9765] Loss_D: 0.0943 Loss_G: 0.0439 Convergence: 0.1012 k= 0.024998 lr = 0.0000307\n",
      "[7/25][1610/9765] Loss_D: 0.0984 Loss_G: 0.0406 Convergence: 0.1003 k= 0.024973 lr = 0.0000307\n",
      "[7/25][1620/9765] Loss_D: 0.0967 Loss_G: 0.0413 Convergence: 0.0999 k= 0.024971 lr = 0.0000307\n",
      "[7/25][1630/9765] Loss_D: 0.1040 Loss_G: 0.0427 Convergence: 0.1057 k= 0.024987 lr = 0.0000307\n",
      "[7/25][1640/9765] Loss_D: 0.0988 Loss_G: 0.0397 Convergence: 0.1000 k= 0.024975 lr = 0.0000307\n",
      "[7/25][1650/9765] Loss_D: 0.1004 Loss_G: 0.0392 Convergence: 0.1027 k= 0.024993 lr = 0.0000307\n",
      "[7/25][1660/9765] Loss_D: 0.0981 Loss_G: 0.0398 Convergence: 0.0992 k= 0.025001 lr = 0.0000307\n",
      "[7/25][1670/9765] Loss_D: 0.0992 Loss_G: 0.0441 Convergence: 0.1043 k= 0.024985 lr = 0.0000307\n",
      "[7/25][1680/9765] Loss_D: 0.0980 Loss_G: 0.0378 Convergence: 0.1007 k= 0.024970 lr = 0.0000307\n",
      "[7/25][1690/9765] Loss_D: 0.0987 Loss_G: 0.0334 Convergence: 0.1059 k= 0.024986 lr = 0.0000307\n",
      "[7/25][1700/9765] Loss_D: 0.0980 Loss_G: 0.0431 Convergence: 0.1025 k= 0.024993 lr = 0.0000307\n",
      "[7/25][1710/9765] Loss_D: 0.1112 Loss_G: 0.0406 Convergence: 0.1165 k= 0.025003 lr = 0.0000307\n",
      "[7/25][1720/9765] Loss_D: 0.0995 Loss_G: 0.0388 Convergence: 0.1017 k= 0.025011 lr = 0.0000307\n",
      "[7/25][1730/9765] Loss_D: 0.1010 Loss_G: 0.0390 Convergence: 0.1037 k= 0.025006 lr = 0.0000307\n",
      "[7/25][1740/9765] Loss_D: 0.1062 Loss_G: 0.0393 Convergence: 0.1107 k= 0.025016 lr = 0.0000307\n",
      "[7/25][1750/9765] Loss_D: 0.0999 Loss_G: 0.0427 Convergence: 0.1032 k= 0.025013 lr = 0.0000307\n",
      "[7/25][1760/9765] Loss_D: 0.1045 Loss_G: 0.0411 Convergence: 0.1067 k= 0.025011 lr = 0.0000307\n",
      "[7/25][1770/9765] Loss_D: 0.0932 Loss_G: 0.0419 Convergence: 0.0985 k= 0.024981 lr = 0.0000307\n",
      "[7/25][1780/9765] Loss_D: 0.1004 Loss_G: 0.0383 Convergence: 0.1036 k= 0.024970 lr = 0.0000307\n",
      "[7/25][1790/9765] Loss_D: 0.1095 Loss_G: 0.0427 Convergence: 0.1121 k= 0.024966 lr = 0.0000307\n",
      "[7/25][1800/9765] Loss_D: 0.0964 Loss_G: 0.0459 Convergence: 0.1044 k= 0.024942 lr = 0.0000307\n",
      "[7/25][1810/9765] Loss_D: 0.1090 Loss_G: 0.0435 Convergence: 0.1106 k= 0.024931 lr = 0.0000307\n",
      "[7/25][1820/9765] Loss_D: 0.1027 Loss_G: 0.0427 Convergence: 0.1049 k= 0.024942 lr = 0.0000307\n",
      "[7/25][1830/9765] Loss_D: 0.1009 Loss_G: 0.0446 Convergence: 0.1058 k= 0.024944 lr = 0.0000307\n",
      "[7/25][1840/9765] Loss_D: 0.0946 Loss_G: 0.0391 Convergence: 0.0964 k= 0.024930 lr = 0.0000307\n",
      "[7/25][1850/9765] Loss_D: 0.1079 Loss_G: 0.0391 Convergence: 0.1133 k= 0.024928 lr = 0.0000307\n",
      "[7/25][1860/9765] Loss_D: 0.0911 Loss_G: 0.0435 Convergence: 0.0988 k= 0.024910 lr = 0.0000307\n",
      "[7/25][1870/9765] Loss_D: 0.0959 Loss_G: 0.0417 Convergence: 0.0999 k= 0.024904 lr = 0.0000307\n",
      "[7/25][1880/9765] Loss_D: 0.1029 Loss_G: 0.0522 Convergence: 0.1146 k= 0.024852 lr = 0.0000307\n",
      "[7/25][1890/9765] Loss_D: 0.0952 Loss_G: 0.0424 Convergence: 0.1002 k= 0.024781 lr = 0.0000307\n",
      "[7/25][1900/9765] Loss_D: 0.1036 Loss_G: 0.0408 Convergence: 0.1057 k= 0.024767 lr = 0.0000307\n",
      "[7/25][1910/9765] Loss_D: 0.0958 Loss_G: 0.0353 Convergence: 0.1001 k= 0.024804 lr = 0.0000307\n",
      "[7/25][1920/9765] Loss_D: 0.0947 Loss_G: 0.0417 Convergence: 0.0992 k= 0.024796 lr = 0.0000307\n",
      "[7/25][1930/9765] Loss_D: 0.1034 Loss_G: 0.0377 Convergence: 0.1083 k= 0.024805 lr = 0.0000307\n",
      "[7/25][1940/9765] Loss_D: 0.0944 Loss_G: 0.0365 Convergence: 0.0970 k= 0.024833 lr = 0.0000307\n",
      "[7/25][1950/9765] Loss_D: 0.0972 Loss_G: 0.0414 Convergence: 0.1004 k= 0.024866 lr = 0.0000307\n",
      "[7/25][1960/9765] Loss_D: 0.0970 Loss_G: 0.0391 Convergence: 0.0980 k= 0.024862 lr = 0.0000307\n",
      "[7/25][1970/9765] Loss_D: 0.1073 Loss_G: 0.0423 Convergence: 0.1093 k= 0.024853 lr = 0.0000307\n",
      "[7/25][1980/9765] Loss_D: 0.0995 Loss_G: 0.0386 Convergence: 0.1020 k= 0.024866 lr = 0.0000307\n",
      "[7/25][1990/9765] Loss_D: 0.1151 Loss_G: 0.0413 Convergence: 0.1212 k= 0.024874 lr = 0.0000307\n",
      "[7/25][2000/9765] Loss_D: 0.0935 Loss_G: 0.0366 Convergence: 0.0956 k= 0.024861 lr = 0.0000307\n",
      "[7/25][2010/9765] Loss_D: 0.1051 Loss_G: 0.0417 Convergence: 0.1070 k= 0.024873 lr = 0.0000307\n",
      "[7/25][2020/9765] Loss_D: 0.0979 Loss_G: 0.0405 Convergence: 0.0999 k= 0.024864 lr = 0.0000307\n",
      "[7/25][2030/9765] Loss_D: 0.1126 Loss_G: 0.0464 Convergence: 0.1147 k= 0.024848 lr = 0.0000307\n",
      "[7/25][2040/9765] Loss_D: 0.1058 Loss_G: 0.0448 Convergence: 0.1090 k= 0.024853 lr = 0.0000307\n",
      "[7/25][2050/9765] Loss_D: 0.1017 Loss_G: 0.0355 Convergence: 0.1080 k= 0.024883 lr = 0.0000307\n",
      "[7/25][2060/9765] Loss_D: 0.0943 Loss_G: 0.0414 Convergence: 0.0987 k= 0.024891 lr = 0.0000307\n",
      "[7/25][2070/9765] Loss_D: 0.1088 Loss_G: 0.0415 Convergence: 0.1121 k= 0.024885 lr = 0.0000307\n",
      "[7/25][2080/9765] Loss_D: 0.1008 Loss_G: 0.0419 Convergence: 0.1029 k= 0.024870 lr = 0.0000307\n",
      "[7/25][2090/9765] Loss_D: 0.0974 Loss_G: 0.0369 Convergence: 0.1007 k= 0.024865 lr = 0.0000307\n",
      "[7/25][2100/9765] Loss_D: 0.0972 Loss_G: 0.0397 Convergence: 0.0986 k= 0.024879 lr = 0.0000307\n",
      "[7/25][2110/9765] Loss_D: 0.1115 Loss_G: 0.0416 Convergence: 0.1160 k= 0.024874 lr = 0.0000307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][2120/9765] Loss_D: 0.0984 Loss_G: 0.0414 Convergence: 0.1010 k= 0.024859 lr = 0.0000307\n",
      "[7/25][2130/9765] Loss_D: 0.1033 Loss_G: 0.0406 Convergence: 0.1054 k= 0.024880 lr = 0.0000307\n",
      "[7/25][2140/9765] Loss_D: 0.1009 Loss_G: 0.0415 Convergence: 0.1027 k= 0.024893 lr = 0.0000307\n",
      "[7/25][2150/9765] Loss_D: 0.0991 Loss_G: 0.0427 Convergence: 0.1028 k= 0.024889 lr = 0.0000307\n",
      "[7/25][2160/9765] Loss_D: 0.1024 Loss_G: 0.0395 Convergence: 0.1054 k= 0.024869 lr = 0.0000307\n",
      "[7/25][2170/9765] Loss_D: 0.1018 Loss_G: 0.0384 Convergence: 0.1055 k= 0.024887 lr = 0.0000307\n",
      "[7/25][2180/9765] Loss_D: 0.0996 Loss_G: 0.0401 Convergence: 0.1007 k= 0.024876 lr = 0.0000307\n",
      "[7/25][2190/9765] Loss_D: 0.0994 Loss_G: 0.0426 Convergence: 0.1029 k= 0.024849 lr = 0.0000307\n",
      "[7/25][2200/9765] Loss_D: 0.1011 Loss_G: 0.0400 Convergence: 0.1030 k= 0.024844 lr = 0.0000307\n",
      "[7/25][2210/9765] Loss_D: 0.0904 Loss_G: 0.0400 Convergence: 0.0949 k= 0.024853 lr = 0.0000307\n",
      "[7/25][2220/9765] Loss_D: 0.1028 Loss_G: 0.0418 Convergence: 0.1041 k= 0.024836 lr = 0.0000307\n",
      "[7/25][2230/9765] Loss_D: 0.0958 Loss_G: 0.0432 Convergence: 0.1013 k= 0.024786 lr = 0.0000307\n",
      "[7/25][2240/9765] Loss_D: 0.1002 Loss_G: 0.0412 Convergence: 0.1019 k= 0.024783 lr = 0.0000307\n",
      "[7/25][2250/9765] Loss_D: 0.1011 Loss_G: 0.0412 Convergence: 0.1025 k= 0.024773 lr = 0.0000307\n",
      "[7/25][2260/9765] Loss_D: 0.1106 Loss_G: 0.0420 Convergence: 0.1142 k= 0.024766 lr = 0.0000307\n",
      "[7/25][2270/9765] Loss_D: 0.0973 Loss_G: 0.0407 Convergence: 0.0996 k= 0.024770 lr = 0.0000307\n",
      "[7/25][2280/9765] Loss_D: 0.1023 Loss_G: 0.0425 Convergence: 0.1045 k= 0.024777 lr = 0.0000307\n",
      "[7/25][2290/9765] Loss_D: 0.1053 Loss_G: 0.0388 Convergence: 0.1101 k= 0.024778 lr = 0.0000307\n",
      "[7/25][2300/9765] Loss_D: 0.1072 Loss_G: 0.0365 Convergence: 0.1148 k= 0.024821 lr = 0.0000307\n",
      "[7/25][2310/9765] Loss_D: 0.1006 Loss_G: 0.0386 Convergence: 0.1036 k= 0.024837 lr = 0.0000307\n",
      "[7/25][2320/9765] Loss_D: 0.1020 Loss_G: 0.0413 Convergence: 0.1032 k= 0.024845 lr = 0.0000307\n",
      "[7/25][2330/9765] Loss_D: 0.1058 Loss_G: 0.0421 Convergence: 0.1074 k= 0.024846 lr = 0.0000307\n",
      "[7/25][2340/9765] Loss_D: 0.1098 Loss_G: 0.0399 Convergence: 0.1152 k= 0.024856 lr = 0.0000307\n",
      "[7/25][2350/9765] Loss_D: 0.1083 Loss_G: 0.0422 Convergence: 0.1108 k= 0.024843 lr = 0.0000307\n",
      "[7/25][2360/9765] Loss_D: 0.1037 Loss_G: 0.0399 Convergence: 0.1066 k= 0.024845 lr = 0.0000307\n",
      "[7/25][2370/9765] Loss_D: 0.1058 Loss_G: 0.0420 Convergence: 0.1075 k= 0.024856 lr = 0.0000307\n",
      "[7/25][2380/9765] Loss_D: 0.0956 Loss_G: 0.0393 Convergence: 0.0972 k= 0.024865 lr = 0.0000307\n",
      "[7/25][2390/9765] Loss_D: 0.0994 Loss_G: 0.0408 Convergence: 0.1011 k= 0.024871 lr = 0.0000307\n",
      "[7/25][2400/9765] Loss_D: 0.1032 Loss_G: 0.0450 Convergence: 0.1075 k= 0.024844 lr = 0.0000307\n",
      "[7/25][2410/9765] Loss_D: 0.1048 Loss_G: 0.0422 Convergence: 0.1058 k= 0.024849 lr = 0.0000307\n",
      "[7/25][2420/9765] Loss_D: 0.1000 Loss_G: 0.0418 Convergence: 0.1023 k= 0.024874 lr = 0.0000307\n",
      "[7/25][2430/9765] Loss_D: 0.0999 Loss_G: 0.0405 Convergence: 0.1011 k= 0.024857 lr = 0.0000307\n",
      "[7/25][2440/9765] Loss_D: 0.1078 Loss_G: 0.0426 Convergence: 0.1098 k= 0.024855 lr = 0.0000307\n",
      "[7/25][2450/9765] Loss_D: 0.0995 Loss_G: 0.0404 Convergence: 0.1007 k= 0.024847 lr = 0.0000307\n",
      "[7/25][2460/9765] Loss_D: 0.1017 Loss_G: 0.0367 Convergence: 0.1070 k= 0.024872 lr = 0.0000307\n",
      "[7/25][2470/9765] Loss_D: 0.0967 Loss_G: 0.0366 Convergence: 0.1000 k= 0.024894 lr = 0.0000307\n",
      "[7/25][2480/9765] Loss_D: 0.1009 Loss_G: 0.0416 Convergence: 0.1028 k= 0.024887 lr = 0.0000307\n",
      "[7/25][2490/9765] Loss_D: 0.1031 Loss_G: 0.0467 Convergence: 0.1092 k= 0.024893 lr = 0.0000307\n",
      "[7/25][2500/9765] Loss_D: 0.1097 Loss_G: 0.0364 Convergence: 0.1185 k= 0.024866 lr = 0.0000307\n",
      "[7/25][2510/9765] Loss_D: 0.1025 Loss_G: 0.0382 Convergence: 0.1065 k= 0.024902 lr = 0.0000307\n",
      "[7/25][2520/9765] Loss_D: 0.1061 Loss_G: 0.0492 Convergence: 0.1135 k= 0.024887 lr = 0.0000307\n",
      "[7/25][2530/9765] Loss_D: 0.1094 Loss_G: 0.0464 Convergence: 0.1127 k= 0.024835 lr = 0.0000307\n",
      "[7/25][2540/9765] Loss_D: 0.1102 Loss_G: 0.0422 Convergence: 0.1134 k= 0.024834 lr = 0.0000307\n",
      "[7/25][2550/9765] Loss_D: 0.1087 Loss_G: 0.0408 Convergence: 0.1126 k= 0.024844 lr = 0.0000307\n",
      "[7/25][2560/9765] Loss_D: 0.0967 Loss_G: 0.0422 Convergence: 0.1008 k= 0.024829 lr = 0.0000307\n",
      "[7/25][2570/9765] Loss_D: 0.0952 Loss_G: 0.0430 Convergence: 0.1007 k= 0.024817 lr = 0.0000307\n",
      "[7/25][2580/9765] Loss_D: 0.1029 Loss_G: 0.0435 Convergence: 0.1060 k= 0.024805 lr = 0.0000307\n",
      "[7/25][2590/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0979 k= 0.024805 lr = 0.0000307\n",
      "[7/25][2600/9765] Loss_D: 0.1141 Loss_G: 0.0377 Convergence: 0.1233 k= 0.024839 lr = 0.0000307\n",
      "[7/25][2610/9765] Loss_D: 0.1013 Loss_G: 0.0385 Convergence: 0.1048 k= 0.024844 lr = 0.0000307\n",
      "[7/25][2620/9765] Loss_D: 0.0987 Loss_G: 0.0409 Convergence: 0.1008 k= 0.024834 lr = 0.0000307\n",
      "[7/25][2630/9765] Loss_D: 0.0993 Loss_G: 0.0446 Convergence: 0.1047 k= 0.024815 lr = 0.0000307\n",
      "[7/25][2640/9765] Loss_D: 0.1010 Loss_G: 0.0405 Convergence: 0.1022 k= 0.024819 lr = 0.0000307\n",
      "[7/25][2650/9765] Loss_D: 0.0927 Loss_G: 0.0397 Convergence: 0.0959 k= 0.024807 lr = 0.0000307\n",
      "[7/25][2660/9765] Loss_D: 0.0990 Loss_G: 0.0415 Convergence: 0.1015 k= 0.024809 lr = 0.0000307\n",
      "[7/25][2670/9765] Loss_D: 0.1075 Loss_G: 0.0445 Convergence: 0.1096 k= 0.024805 lr = 0.0000307\n",
      "[7/25][2680/9765] Loss_D: 0.0986 Loss_G: 0.0407 Convergence: 0.1004 k= 0.024810 lr = 0.0000307\n",
      "[7/25][2690/9765] Loss_D: 0.0978 Loss_G: 0.0449 Convergence: 0.1042 k= 0.024827 lr = 0.0000307\n",
      "[7/25][2700/9765] Loss_D: 0.1055 Loss_G: 0.0443 Convergence: 0.1083 k= 0.024793 lr = 0.0000307\n",
      "[7/25][2710/9765] Loss_D: 0.1018 Loss_G: 0.0399 Convergence: 0.1040 k= 0.024787 lr = 0.0000307\n",
      "[7/25][2720/9765] Loss_D: 0.1021 Loss_G: 0.0423 Convergence: 0.1042 k= 0.024790 lr = 0.0000307\n",
      "[7/25][2730/9765] Loss_D: 0.0941 Loss_G: 0.0387 Convergence: 0.0958 k= 0.024792 lr = 0.0000307\n",
      "[7/25][2740/9765] Loss_D: 0.1062 Loss_G: 0.0420 Convergence: 0.1082 k= 0.024778 lr = 0.0000307\n",
      "[7/25][2750/9765] Loss_D: 0.1024 Loss_G: 0.0420 Convergence: 0.1040 k= 0.024766 lr = 0.0000307\n",
      "[7/25][2760/9765] Loss_D: 0.1100 Loss_G: 0.0418 Convergence: 0.1136 k= 0.024791 lr = 0.0000307\n",
      "[7/25][2770/9765] Loss_D: 0.0979 Loss_G: 0.0411 Convergence: 0.1005 k= 0.024767 lr = 0.0000307\n",
      "[7/25][2780/9765] Loss_D: 0.1081 Loss_G: 0.0405 Convergence: 0.1122 k= 0.024766 lr = 0.0000307\n",
      "[7/25][2790/9765] Loss_D: 0.1071 Loss_G: 0.0402 Convergence: 0.1112 k= 0.024774 lr = 0.0000307\n",
      "[7/25][2800/9765] Loss_D: 0.1016 Loss_G: 0.0414 Convergence: 0.1030 k= 0.024777 lr = 0.0000307\n",
      "[7/25][2810/9765] Loss_D: 0.1014 Loss_G: 0.0405 Convergence: 0.1029 k= 0.024779 lr = 0.0000307\n",
      "[7/25][2820/9765] Loss_D: 0.1045 Loss_G: 0.0394 Convergence: 0.1083 k= 0.024778 lr = 0.0000307\n",
      "[7/25][2830/9765] Loss_D: 0.0977 Loss_G: 0.0424 Convergence: 0.1016 k= 0.024775 lr = 0.0000307\n",
      "[7/25][2840/9765] Loss_D: 0.0999 Loss_G: 0.0420 Convergence: 0.1026 k= 0.024769 lr = 0.0000307\n",
      "[7/25][2850/9765] Loss_D: 0.0986 Loss_G: 0.0414 Convergence: 0.1012 k= 0.024768 lr = 0.0000307\n",
      "[7/25][2860/9765] Loss_D: 0.0945 Loss_G: 0.0424 Convergence: 0.0997 k= 0.024758 lr = 0.0000307\n",
      "[7/25][2870/9765] Loss_D: 0.1023 Loss_G: 0.0414 Convergence: 0.1033 k= 0.024768 lr = 0.0000307\n",
      "[7/25][2880/9765] Loss_D: 0.0922 Loss_G: 0.0431 Convergence: 0.0991 k= 0.024748 lr = 0.0000307\n",
      "[7/25][2890/9765] Loss_D: 0.1035 Loss_G: 0.0424 Convergence: 0.1051 k= 0.024708 lr = 0.0000307\n",
      "[7/25][2900/9765] Loss_D: 0.1071 Loss_G: 0.0398 Convergence: 0.1116 k= 0.024696 lr = 0.0000307\n",
      "[7/25][2910/9765] Loss_D: 0.0960 Loss_G: 0.0356 Convergence: 0.1001 k= 0.024729 lr = 0.0000307\n",
      "[7/25][2920/9765] Loss_D: 0.1011 Loss_G: 0.0416 Convergence: 0.1028 k= 0.024742 lr = 0.0000307\n",
      "[7/25][2930/9765] Loss_D: 0.1080 Loss_G: 0.0413 Convergence: 0.1113 k= 0.024713 lr = 0.0000307\n",
      "[7/25][2940/9765] Loss_D: 0.0953 Loss_G: 0.0430 Convergence: 0.1008 k= 0.024696 lr = 0.0000307\n",
      "[7/25][2950/9765] Loss_D: 0.1088 Loss_G: 0.0374 Convergence: 0.1162 k= 0.024708 lr = 0.0000307\n",
      "[7/25][2960/9765] Loss_D: 0.1021 Loss_G: 0.0422 Convergence: 0.1040 k= 0.024709 lr = 0.0000307\n",
      "[7/25][2970/9765] Loss_D: 0.1082 Loss_G: 0.0393 Convergence: 0.1135 k= 0.024704 lr = 0.0000307\n",
      "[7/25][2980/9765] Loss_D: 0.1034 Loss_G: 0.0420 Convergence: 0.1047 k= 0.024711 lr = 0.0000307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][2990/9765] Loss_D: 0.0901 Loss_G: 0.0397 Convergence: 0.0944 k= 0.024695 lr = 0.0000307\n",
      "[7/25][3000/9765] Loss_D: 0.0968 Loss_G: 0.0393 Convergence: 0.0980 k= 0.024698 lr = 0.0000307\n",
      "[7/25][3010/9765] Loss_D: 0.1032 Loss_G: 0.0447 Convergence: 0.1073 k= 0.024689 lr = 0.0000307\n",
      "[7/25][3020/9765] Loss_D: 0.0965 Loss_G: 0.0425 Convergence: 0.1010 k= 0.024658 lr = 0.0000307\n",
      "[7/25][3030/9765] Loss_D: 0.0972 Loss_G: 0.0387 Convergence: 0.0987 k= 0.024660 lr = 0.0000307\n",
      "[7/25][3040/9765] Loss_D: 0.0910 Loss_G: 0.0417 Convergence: 0.0969 k= 0.024666 lr = 0.0000307\n",
      "[7/25][3050/9765] Loss_D: 0.1088 Loss_G: 0.0394 Convergence: 0.1143 k= 0.024679 lr = 0.0000307\n",
      "[7/25][3060/9765] Loss_D: 0.1110 Loss_G: 0.0422 Convergence: 0.1146 k= 0.024689 lr = 0.0000307\n",
      "[7/25][3070/9765] Loss_D: 0.0973 Loss_G: 0.0399 Convergence: 0.0989 k= 0.024666 lr = 0.0000307\n",
      "[7/25][3080/9765] Loss_D: 0.1082 Loss_G: 0.0404 Convergence: 0.1125 k= 0.024678 lr = 0.0000307\n",
      "[7/25][3090/9765] Loss_D: 0.0966 Loss_G: 0.0394 Convergence: 0.0979 k= 0.024678 lr = 0.0000307\n",
      "[7/25][3100/9765] Loss_D: 0.0980 Loss_G: 0.0437 Convergence: 0.1031 k= 0.024674 lr = 0.0000307\n",
      "[7/25][3110/9765] Loss_D: 0.1027 Loss_G: 0.0420 Convergence: 0.1042 k= 0.024659 lr = 0.0000307\n",
      "[7/25][3120/9765] Loss_D: 0.0965 Loss_G: 0.0421 Convergence: 0.1007 k= 0.024648 lr = 0.0000307\n",
      "[7/25][3130/9765] Loss_D: 0.0907 Loss_G: 0.0425 Convergence: 0.0975 k= 0.024627 lr = 0.0000307\n",
      "[7/25][3140/9765] Loss_D: 0.0977 Loss_G: 0.0443 Convergence: 0.1035 k= 0.024610 lr = 0.0000307\n",
      "[7/25][3150/9765] Loss_D: 0.1072 Loss_G: 0.0385 Convergence: 0.1129 k= 0.024600 lr = 0.0000307\n",
      "[7/25][3160/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1026 k= 0.024595 lr = 0.0000307\n",
      "[7/25][3170/9765] Loss_D: 0.1001 Loss_G: 0.0409 Convergence: 0.1016 k= 0.024573 lr = 0.0000307\n",
      "[7/25][3180/9765] Loss_D: 0.1099 Loss_G: 0.0422 Convergence: 0.1130 k= 0.024559 lr = 0.0000307\n",
      "[7/25][3190/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0996 k= 0.024567 lr = 0.0000307\n",
      "[7/25][3200/9765] Loss_D: 0.0893 Loss_G: 0.0399 Convergence: 0.0941 k= 0.024567 lr = 0.0000307\n",
      "[7/25][3210/9765] Loss_D: 0.1005 Loss_G: 0.0445 Convergence: 0.1054 k= 0.024560 lr = 0.0000307\n",
      "[7/25][3220/9765] Loss_D: 0.0939 Loss_G: 0.0373 Convergence: 0.0954 k= 0.024559 lr = 0.0000307\n",
      "[7/25][3230/9765] Loss_D: 0.1008 Loss_G: 0.0448 Convergence: 0.1059 k= 0.024562 lr = 0.0000307\n",
      "[7/25][3240/9765] Loss_D: 0.0951 Loss_G: 0.0433 Convergence: 0.1009 k= 0.024532 lr = 0.0000307\n",
      "[7/25][3250/9765] Loss_D: 0.1033 Loss_G: 0.0428 Convergence: 0.1053 k= 0.024535 lr = 0.0000307\n",
      "[7/25][3260/9765] Loss_D: 0.1041 Loss_G: 0.0408 Convergence: 0.1062 k= 0.024534 lr = 0.0000307\n",
      "[7/25][3270/9765] Loss_D: 0.0973 Loss_G: 0.0382 Convergence: 0.0995 k= 0.024523 lr = 0.0000307\n",
      "[7/25][3280/9765] Loss_D: 0.1001 Loss_G: 0.0388 Convergence: 0.1026 k= 0.024529 lr = 0.0000307\n",
      "[7/25][3290/9765] Loss_D: 0.1027 Loss_G: 0.0411 Convergence: 0.1042 k= 0.024527 lr = 0.0000307\n",
      "[7/25][3300/9765] Loss_D: 0.1106 Loss_G: 0.0427 Convergence: 0.1136 k= 0.024502 lr = 0.0000307\n",
      "[7/25][3310/9765] Loss_D: 0.1069 Loss_G: 0.0387 Convergence: 0.1124 k= 0.024514 lr = 0.0000307\n",
      "[7/25][3320/9765] Loss_D: 0.0922 Loss_G: 0.0394 Convergence: 0.0954 k= 0.024517 lr = 0.0000307\n",
      "[7/25][3330/9765] Loss_D: 0.1031 Loss_G: 0.0422 Convergence: 0.1047 k= 0.024522 lr = 0.0000307\n",
      "[7/25][3340/9765] Loss_D: 0.1100 Loss_G: 0.0435 Convergence: 0.1120 k= 0.024492 lr = 0.0000307\n",
      "[7/25][3350/9765] Loss_D: 0.1069 Loss_G: 0.0384 Convergence: 0.1125 k= 0.024477 lr = 0.0000307\n",
      "[7/25][3360/9765] Loss_D: 0.0957 Loss_G: 0.0393 Convergence: 0.0973 k= 0.024503 lr = 0.0000307\n",
      "[7/25][3370/9765] Loss_D: 0.1061 Loss_G: 0.0418 Convergence: 0.1081 k= 0.024491 lr = 0.0000307\n",
      "[7/25][3380/9765] Loss_D: 0.0959 Loss_G: 0.0417 Convergence: 0.0999 k= 0.024467 lr = 0.0000307\n",
      "[7/25][3390/9765] Loss_D: 0.1030 Loss_G: 0.0422 Convergence: 0.1046 k= 0.024455 lr = 0.0000307\n",
      "[7/25][3400/9765] Loss_D: 0.1000 Loss_G: 0.0403 Convergence: 0.1010 k= 0.024455 lr = 0.0000307\n",
      "[7/25][3410/9765] Loss_D: 0.0998 Loss_G: 0.0380 Convergence: 0.1032 k= 0.024448 lr = 0.0000307\n",
      "[7/25][3420/9765] Loss_D: 0.1041 Loss_G: 0.0435 Convergence: 0.1066 k= 0.024445 lr = 0.0000307\n",
      "[7/25][3430/9765] Loss_D: 0.1020 Loss_G: 0.0407 Convergence: 0.1035 k= 0.024411 lr = 0.0000307\n",
      "[7/25][3440/9765] Loss_D: 0.1014 Loss_G: 0.0425 Convergence: 0.1040 k= 0.024390 lr = 0.0000307\n",
      "[7/25][3450/9765] Loss_D: 0.1037 Loss_G: 0.0400 Convergence: 0.1064 k= 0.024386 lr = 0.0000307\n",
      "[7/25][3460/9765] Loss_D: 0.1007 Loss_G: 0.0458 Convergence: 0.1069 k= 0.024371 lr = 0.0000307\n",
      "[7/25][3470/9765] Loss_D: 0.0977 Loss_G: 0.0395 Convergence: 0.0987 k= 0.024374 lr = 0.0000307\n",
      "[7/25][3480/9765] Loss_D: 0.0986 Loss_G: 0.0442 Convergence: 0.1039 k= 0.024380 lr = 0.0000307\n",
      "[7/25][3490/9765] Loss_D: 0.0930 Loss_G: 0.0399 Convergence: 0.0963 k= 0.024384 lr = 0.0000307\n",
      "[7/25][3500/9765] Loss_D: 0.1029 Loss_G: 0.0391 Convergence: 0.1064 k= 0.024402 lr = 0.0000307\n",
      "[7/25][3510/9765] Loss_D: 0.1003 Loss_G: 0.0394 Convergence: 0.1024 k= 0.024415 lr = 0.0000307\n",
      "[7/25][3520/9765] Loss_D: 0.1023 Loss_G: 0.0452 Convergence: 0.1073 k= 0.024400 lr = 0.0000307\n",
      "[7/25][3530/9765] Loss_D: 0.1033 Loss_G: 0.0377 Convergence: 0.1082 k= 0.024396 lr = 0.0000307\n",
      "[7/25][3540/9765] Loss_D: 0.1015 Loss_G: 0.0438 Convergence: 0.1053 k= 0.024410 lr = 0.0000307\n",
      "[7/25][3550/9765] Loss_D: 0.1113 Loss_G: 0.0377 Convergence: 0.1193 k= 0.024460 lr = 0.0000307\n",
      "[7/25][3560/9765] Loss_D: 0.0940 Loss_G: 0.0378 Convergence: 0.0952 k= 0.024462 lr = 0.0000307\n",
      "[7/25][3570/9765] Loss_D: 0.1001 Loss_G: 0.0398 Convergence: 0.1016 k= 0.024454 lr = 0.0000307\n",
      "[7/25][3580/9765] Loss_D: 0.0986 Loss_G: 0.0362 Convergence: 0.1032 k= 0.024468 lr = 0.0000307\n",
      "[7/25][3590/9765] Loss_D: 0.1087 Loss_G: 0.0371 Convergence: 0.1162 k= 0.024477 lr = 0.0000307\n",
      "[7/25][3600/9765] Loss_D: 0.1113 Loss_G: 0.0413 Convergence: 0.1159 k= 0.024471 lr = 0.0000307\n",
      "[7/25][3610/9765] Loss_D: 0.1043 Loss_G: 0.0365 Convergence: 0.1108 k= 0.024483 lr = 0.0000307\n",
      "[7/25][3620/9765] Loss_D: 0.1049 Loss_G: 0.0378 Convergence: 0.1103 k= 0.024507 lr = 0.0000307\n",
      "[7/25][3630/9765] Loss_D: 0.1037 Loss_G: 0.0396 Convergence: 0.1070 k= 0.024513 lr = 0.0000307\n",
      "[7/25][3640/9765] Loss_D: 0.0985 Loss_G: 0.0403 Convergence: 0.1000 k= 0.024516 lr = 0.0000307\n",
      "[7/25][3650/9765] Loss_D: 0.1116 Loss_G: 0.0388 Convergence: 0.1187 k= 0.024504 lr = 0.0000292\n",
      "[7/25][3660/9765] Loss_D: 0.0993 Loss_G: 0.0429 Convergence: 0.1031 k= 0.024494 lr = 0.0000292\n",
      "[7/25][3670/9765] Loss_D: 0.1013 Loss_G: 0.0388 Convergence: 0.1043 k= 0.024487 lr = 0.0000292\n",
      "[7/25][3680/9765] Loss_D: 0.0971 Loss_G: 0.0423 Convergence: 0.1012 k= 0.024492 lr = 0.0000292\n",
      "[7/25][3690/9765] Loss_D: 0.1012 Loss_G: 0.0400 Convergence: 0.1031 k= 0.024493 lr = 0.0000292\n",
      "[7/25][3700/9765] Loss_D: 0.0934 Loss_G: 0.0414 Convergence: 0.0980 k= 0.024487 lr = 0.0000292\n",
      "[7/25][3710/9765] Loss_D: 0.1024 Loss_G: 0.0439 Convergence: 0.1060 k= 0.024463 lr = 0.0000292\n",
      "[7/25][3720/9765] Loss_D: 0.0957 Loss_G: 0.0381 Convergence: 0.0972 k= 0.024453 lr = 0.0000292\n",
      "[7/25][3730/9765] Loss_D: 0.1058 Loss_G: 0.0442 Convergence: 0.1083 k= 0.024458 lr = 0.0000292\n",
      "[7/25][3740/9765] Loss_D: 0.1070 Loss_G: 0.0449 Convergence: 0.1097 k= 0.024421 lr = 0.0000292\n",
      "[7/25][3750/9765] Loss_D: 0.1016 Loss_G: 0.0376 Convergence: 0.1061 k= 0.024412 lr = 0.0000292\n",
      "[7/25][3760/9765] Loss_D: 0.1002 Loss_G: 0.0372 Convergence: 0.1045 k= 0.024459 lr = 0.0000292\n",
      "[7/25][3770/9765] Loss_D: 0.0991 Loss_G: 0.0393 Convergence: 0.1009 k= 0.024471 lr = 0.0000292\n",
      "[7/25][3780/9765] Loss_D: 0.0975 Loss_G: 0.0420 Convergence: 0.1011 k= 0.024462 lr = 0.0000292\n",
      "[7/25][3790/9765] Loss_D: 0.0952 Loss_G: 0.0407 Convergence: 0.0984 k= 0.024448 lr = 0.0000292\n",
      "[7/25][3800/9765] Loss_D: 0.1093 Loss_G: 0.0398 Convergence: 0.1145 k= 0.024450 lr = 0.0000292\n",
      "[7/25][3810/9765] Loss_D: 0.1037 Loss_G: 0.0385 Convergence: 0.1079 k= 0.024451 lr = 0.0000292\n",
      "[7/25][3820/9765] Loss_D: 0.1040 Loss_G: 0.0441 Convergence: 0.1071 k= 0.024449 lr = 0.0000292\n",
      "[7/25][3830/9765] Loss_D: 0.1021 Loss_G: 0.0439 Convergence: 0.1057 k= 0.024423 lr = 0.0000292\n",
      "[7/25][3840/9765] Loss_D: 0.1041 Loss_G: 0.0383 Convergence: 0.1087 k= 0.024440 lr = 0.0000292\n",
      "[7/25][3850/9765] Loss_D: 0.1037 Loss_G: 0.0423 Convergence: 0.1051 k= 0.024463 lr = 0.0000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][3860/9765] Loss_D: 0.1015 Loss_G: 0.0434 Convergence: 0.1049 k= 0.024456 lr = 0.0000292\n",
      "[7/25][3870/9765] Loss_D: 0.1134 Loss_G: 0.0415 Convergence: 0.1185 k= 0.024435 lr = 0.0000292\n",
      "[7/25][3880/9765] Loss_D: 0.0965 Loss_G: 0.0382 Convergence: 0.0982 k= 0.024435 lr = 0.0000292\n",
      "[7/25][3890/9765] Loss_D: 0.0906 Loss_G: 0.0392 Convergence: 0.0941 k= 0.024446 lr = 0.0000292\n",
      "[7/25][3900/9765] Loss_D: 0.1033 Loss_G: 0.0415 Convergence: 0.1045 k= 0.024457 lr = 0.0000292\n",
      "[7/25][3910/9765] Loss_D: 0.1121 Loss_G: 0.0368 Convergence: 0.1215 k= 0.024470 lr = 0.0000292\n",
      "[7/25][3920/9765] Loss_D: 0.1182 Loss_G: 0.0429 Convergence: 0.1239 k= 0.024482 lr = 0.0000292\n",
      "[7/25][3930/9765] Loss_D: 0.1045 Loss_G: 0.0407 Convergence: 0.1069 k= 0.024498 lr = 0.0000292\n",
      "[7/25][3940/9765] Loss_D: 0.1014 Loss_G: 0.0403 Convergence: 0.1031 k= 0.024492 lr = 0.0000292\n",
      "[7/25][3950/9765] Loss_D: 0.0961 Loss_G: 0.0388 Convergence: 0.0972 k= 0.024465 lr = 0.0000292\n",
      "[7/25][3960/9765] Loss_D: 0.0955 Loss_G: 0.0392 Convergence: 0.0971 k= 0.024480 lr = 0.0000292\n",
      "[7/25][3970/9765] Loss_D: 0.1023 Loss_G: 0.0342 Convergence: 0.1103 k= 0.024489 lr = 0.0000292\n",
      "[7/25][3980/9765] Loss_D: 0.1001 Loss_G: 0.0399 Convergence: 0.1017 k= 0.024488 lr = 0.0000292\n",
      "[7/25][3990/9765] Loss_D: 0.0952 Loss_G: 0.0425 Convergence: 0.1003 k= 0.024470 lr = 0.0000292\n",
      "[7/25][4000/9765] Loss_D: 0.1124 Loss_G: 0.0422 Convergence: 0.1166 k= 0.024457 lr = 0.0000292\n",
      "[7/25][4010/9765] Loss_D: 0.0991 Loss_G: 0.0414 Convergence: 0.1014 k= 0.024485 lr = 0.0000292\n",
      "[7/25][4020/9765] Loss_D: 0.0974 Loss_G: 0.0384 Convergence: 0.0992 k= 0.024473 lr = 0.0000292\n",
      "[7/25][4030/9765] Loss_D: 0.0999 Loss_G: 0.0434 Convergence: 0.1040 k= 0.024480 lr = 0.0000292\n",
      "[7/25][4040/9765] Loss_D: 0.0949 Loss_G: 0.0402 Convergence: 0.0978 k= 0.024472 lr = 0.0000292\n",
      "[7/25][4050/9765] Loss_D: 0.0933 Loss_G: 0.0394 Convergence: 0.0960 k= 0.024484 lr = 0.0000292\n",
      "[7/25][4060/9765] Loss_D: 0.1144 Loss_G: 0.0395 Convergence: 0.1220 k= 0.024496 lr = 0.0000292\n",
      "[7/25][4070/9765] Loss_D: 0.0933 Loss_G: 0.0397 Convergence: 0.0962 k= 0.024495 lr = 0.0000292\n",
      "[7/25][4080/9765] Loss_D: 0.0988 Loss_G: 0.0373 Convergence: 0.1023 k= 0.024525 lr = 0.0000292\n",
      "[7/25][4090/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0958 k= 0.024540 lr = 0.0000292\n",
      "[7/25][4100/9765] Loss_D: 0.0982 Loss_G: 0.0393 Convergence: 0.0995 k= 0.024547 lr = 0.0000292\n",
      "[7/25][4110/9765] Loss_D: 0.1032 Loss_G: 0.0428 Convergence: 0.1053 k= 0.024552 lr = 0.0000292\n",
      "[7/25][4120/9765] Loss_D: 0.0946 Loss_G: 0.0415 Convergence: 0.0988 k= 0.024550 lr = 0.0000292\n",
      "[7/25][4130/9765] Loss_D: 0.1035 Loss_G: 0.0426 Convergence: 0.1053 k= 0.024537 lr = 0.0000292\n",
      "[7/25][4140/9765] Loss_D: 0.1049 Loss_G: 0.0394 Convergence: 0.1089 k= 0.024538 lr = 0.0000292\n",
      "[7/25][4150/9765] Loss_D: 0.0992 Loss_G: 0.0392 Convergence: 0.1012 k= 0.024548 lr = 0.0000292\n",
      "[7/25][4160/9765] Loss_D: 0.1003 Loss_G: 0.0426 Convergence: 0.1034 k= 0.024546 lr = 0.0000292\n",
      "[7/25][4170/9765] Loss_D: 0.0928 Loss_G: 0.0408 Convergence: 0.0971 k= 0.024516 lr = 0.0000292\n",
      "[7/25][4180/9765] Loss_D: 0.1034 Loss_G: 0.0399 Convergence: 0.1060 k= 0.024527 lr = 0.0000292\n",
      "[7/25][4190/9765] Loss_D: 0.0983 Loss_G: 0.0394 Convergence: 0.0995 k= 0.024536 lr = 0.0000292\n",
      "[7/25][4200/9765] Loss_D: 0.1050 Loss_G: 0.0434 Convergence: 0.1070 k= 0.024538 lr = 0.0000292\n",
      "[7/25][4210/9765] Loss_D: 0.1025 Loss_G: 0.0373 Convergence: 0.1074 k= 0.024527 lr = 0.0000292\n",
      "[7/25][4220/9765] Loss_D: 0.1014 Loss_G: 0.0332 Convergence: 0.1099 k= 0.024575 lr = 0.0000292\n",
      "[7/25][4230/9765] Loss_D: 0.0996 Loss_G: 0.0422 Convergence: 0.1025 k= 0.024606 lr = 0.0000292\n",
      "[7/25][4240/9765] Loss_D: 0.0995 Loss_G: 0.0434 Convergence: 0.1036 k= 0.024589 lr = 0.0000292\n",
      "[7/25][4250/9765] Loss_D: 0.1027 Loss_G: 0.0444 Convergence: 0.1066 k= 0.024576 lr = 0.0000292\n",
      "[7/25][4260/9765] Loss_D: 0.0917 Loss_G: 0.0391 Convergence: 0.0947 k= 0.024578 lr = 0.0000292\n",
      "[7/25][4270/9765] Loss_D: 0.1037 Loss_G: 0.0391 Convergence: 0.1074 k= 0.024581 lr = 0.0000292\n",
      "[7/25][4280/9765] Loss_D: 0.1092 Loss_G: 0.0418 Convergence: 0.1123 k= 0.024601 lr = 0.0000292\n",
      "[7/25][4290/9765] Loss_D: 0.1008 Loss_G: 0.0413 Convergence: 0.1023 k= 0.024620 lr = 0.0000292\n",
      "[7/25][4300/9765] Loss_D: 0.0972 Loss_G: 0.0430 Convergence: 0.1020 k= 0.024565 lr = 0.0000292\n",
      "[7/25][4310/9765] Loss_D: 0.1003 Loss_G: 0.0407 Convergence: 0.1015 k= 0.024535 lr = 0.0000292\n",
      "[7/25][4320/9765] Loss_D: 0.1030 Loss_G: 0.0385 Convergence: 0.1070 k= 0.024544 lr = 0.0000292\n",
      "[7/25][4330/9765] Loss_D: 0.0972 Loss_G: 0.0386 Convergence: 0.0988 k= 0.024587 lr = 0.0000292\n",
      "[7/25][4340/9765] Loss_D: 0.0981 Loss_G: 0.0432 Convergence: 0.1027 k= 0.024585 lr = 0.0000292\n",
      "[7/25][4350/9765] Loss_D: 0.1057 Loss_G: 0.0425 Convergence: 0.1071 k= 0.024565 lr = 0.0000292\n",
      "[7/25][4360/9765] Loss_D: 0.0974 Loss_G: 0.0421 Convergence: 0.1012 k= 0.024551 lr = 0.0000292\n",
      "[7/25][4370/9765] Loss_D: 0.0969 Loss_G: 0.0382 Convergence: 0.0988 k= 0.024566 lr = 0.0000292\n",
      "[7/25][4380/9765] Loss_D: 0.0980 Loss_G: 0.0409 Convergence: 0.1003 k= 0.024572 lr = 0.0000292\n",
      "[7/25][4390/9765] Loss_D: 0.1011 Loss_G: 0.0353 Convergence: 0.1075 k= 0.024593 lr = 0.0000292\n",
      "[7/25][4400/9765] Loss_D: 0.0995 Loss_G: 0.0429 Convergence: 0.1032 k= 0.024603 lr = 0.0000292\n",
      "[7/25][4410/9765] Loss_D: 0.0978 Loss_G: 0.0385 Convergence: 0.0997 k= 0.024589 lr = 0.0000292\n",
      "[7/25][4420/9765] Loss_D: 0.1003 Loss_G: 0.0406 Convergence: 0.1014 k= 0.024594 lr = 0.0000292\n",
      "[7/25][4430/9765] Loss_D: 0.1022 Loss_G: 0.0389 Convergence: 0.1056 k= 0.024596 lr = 0.0000292\n",
      "[7/25][4440/9765] Loss_D: 0.1116 Loss_G: 0.0423 Convergence: 0.1153 k= 0.024588 lr = 0.0000292\n",
      "[7/25][4450/9765] Loss_D: 0.1035 Loss_G: 0.0448 Convergence: 0.1075 k= 0.024566 lr = 0.0000292\n",
      "[7/25][4460/9765] Loss_D: 0.1028 Loss_G: 0.0426 Convergence: 0.1049 k= 0.024562 lr = 0.0000292\n",
      "[7/25][4470/9765] Loss_D: 0.1120 Loss_G: 0.0403 Convergence: 0.1180 k= 0.024538 lr = 0.0000292\n",
      "[7/25][4480/9765] Loss_D: 0.1142 Loss_G: 0.0392 Convergence: 0.1220 k= 0.024544 lr = 0.0000292\n",
      "[7/25][4490/9765] Loss_D: 0.0899 Loss_G: 0.0366 Convergence: 0.0912 k= 0.024539 lr = 0.0000292\n",
      "[7/25][4500/9765] Loss_D: 0.1056 Loss_G: 0.0394 Convergence: 0.1098 k= 0.024549 lr = 0.0000292\n",
      "[7/25][4510/9765] Loss_D: 0.1015 Loss_G: 0.0391 Convergence: 0.1044 k= 0.024540 lr = 0.0000292\n",
      "[7/25][4520/9765] Loss_D: 0.1004 Loss_G: 0.0409 Convergence: 0.1017 k= 0.024549 lr = 0.0000292\n",
      "[7/25][4530/9765] Loss_D: 0.0972 Loss_G: 0.0399 Convergence: 0.0988 k= 0.024514 lr = 0.0000292\n",
      "[7/25][4540/9765] Loss_D: 0.0911 Loss_G: 0.0403 Convergence: 0.0956 k= 0.024524 lr = 0.0000292\n",
      "[7/25][4550/9765] Loss_D: 0.0929 Loss_G: 0.0419 Convergence: 0.0982 k= 0.024537 lr = 0.0000292\n",
      "[7/25][4560/9765] Loss_D: 0.1042 Loss_G: 0.0454 Convergence: 0.1085 k= 0.024528 lr = 0.0000292\n",
      "[7/25][4570/9765] Loss_D: 0.1091 Loss_G: 0.0403 Convergence: 0.1139 k= 0.024511 lr = 0.0000292\n",
      "[7/25][4580/9765] Loss_D: 0.1020 Loss_G: 0.0393 Convergence: 0.1049 k= 0.024514 lr = 0.0000292\n",
      "[7/25][4590/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0998 k= 0.024517 lr = 0.0000292\n",
      "[7/25][4600/9765] Loss_D: 0.0883 Loss_G: 0.0402 Convergence: 0.0938 k= 0.024510 lr = 0.0000292\n",
      "[7/25][4610/9765] Loss_D: 0.0999 Loss_G: 0.0412 Convergence: 0.1018 k= 0.024497 lr = 0.0000292\n",
      "[7/25][4620/9765] Loss_D: 0.1051 Loss_G: 0.0378 Convergence: 0.1106 k= 0.024504 lr = 0.0000292\n",
      "[7/25][4630/9765] Loss_D: 0.0981 Loss_G: 0.0463 Convergence: 0.1058 k= 0.024506 lr = 0.0000292\n",
      "[7/25][4640/9765] Loss_D: 0.1073 Loss_G: 0.0399 Convergence: 0.1116 k= 0.024499 lr = 0.0000292\n",
      "[7/25][4650/9765] Loss_D: 0.0891 Loss_G: 0.0405 Convergence: 0.0946 k= 0.024505 lr = 0.0000292\n",
      "[7/25][4660/9765] Loss_D: 0.0977 Loss_G: 0.0431 Convergence: 0.1024 k= 0.024459 lr = 0.0000292\n",
      "[7/25][4670/9765] Loss_D: 0.1058 Loss_G: 0.0402 Convergence: 0.1092 k= 0.024470 lr = 0.0000292\n",
      "[7/25][4680/9765] Loss_D: 0.0938 Loss_G: 0.0378 Convergence: 0.0948 k= 0.024484 lr = 0.0000292\n",
      "[7/25][4690/9765] Loss_D: 0.1003 Loss_G: 0.0382 Convergence: 0.1035 k= 0.024500 lr = 0.0000292\n",
      "[7/25][4700/9765] Loss_D: 0.1008 Loss_G: 0.0408 Convergence: 0.1018 k= 0.024517 lr = 0.0000292\n",
      "[7/25][4710/9765] Loss_D: 0.0987 Loss_G: 0.0389 Convergence: 0.1006 k= 0.024516 lr = 0.0000292\n",
      "[7/25][4720/9765] Loss_D: 0.1025 Loss_G: 0.0418 Convergence: 0.1039 k= 0.024508 lr = 0.0000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][4730/9765] Loss_D: 0.0930 Loss_G: 0.0382 Convergence: 0.0947 k= 0.024502 lr = 0.0000292\n",
      "[7/25][4740/9765] Loss_D: 0.1152 Loss_G: 0.0400 Convergence: 0.1226 k= 0.024525 lr = 0.0000292\n",
      "[7/25][4750/9765] Loss_D: 0.1116 Loss_G: 0.0430 Convergence: 0.1147 k= 0.024508 lr = 0.0000292\n",
      "[7/25][4760/9765] Loss_D: 0.1072 Loss_G: 0.0504 Convergence: 0.1153 k= 0.024451 lr = 0.0000292\n",
      "[7/25][4770/9765] Loss_D: 0.0946 Loss_G: 0.0421 Convergence: 0.0995 k= 0.024446 lr = 0.0000292\n",
      "[7/25][4780/9765] Loss_D: 0.0946 Loss_G: 0.0384 Convergence: 0.0957 k= 0.024460 lr = 0.0000292\n",
      "[7/25][4790/9765] Loss_D: 0.1014 Loss_G: 0.0385 Convergence: 0.1047 k= 0.024477 lr = 0.0000292\n",
      "[7/25][4800/9765] Loss_D: 0.0933 Loss_G: 0.0408 Convergence: 0.0974 k= 0.024479 lr = 0.0000292\n",
      "[7/25][4810/9765] Loss_D: 0.0885 Loss_G: 0.0377 Convergence: 0.0913 k= 0.024475 lr = 0.0000292\n",
      "[7/25][4820/9765] Loss_D: 0.1019 Loss_G: 0.0415 Convergence: 0.1033 k= 0.024486 lr = 0.0000292\n",
      "[7/25][4830/9765] Loss_D: 0.1161 Loss_G: 0.0372 Convergence: 0.1266 k= 0.024493 lr = 0.0000292\n",
      "[7/25][4840/9765] Loss_D: 0.0974 Loss_G: 0.0415 Convergence: 0.1005 k= 0.024504 lr = 0.0000292\n",
      "[7/25][4850/9765] Loss_D: 0.0994 Loss_G: 0.0381 Convergence: 0.1024 k= 0.024517 lr = 0.0000292\n",
      "[7/25][4860/9765] Loss_D: 0.0982 Loss_G: 0.0405 Convergence: 0.1000 k= 0.024516 lr = 0.0000292\n",
      "[7/25][4870/9765] Loss_D: 0.0967 Loss_G: 0.0445 Convergence: 0.1031 k= 0.024513 lr = 0.0000292\n",
      "[7/25][4880/9765] Loss_D: 0.1009 Loss_G: 0.0387 Convergence: 0.1038 k= 0.024526 lr = 0.0000292\n",
      "[7/25][4890/9765] Loss_D: 0.0993 Loss_G: 0.0432 Convergence: 0.1033 k= 0.024540 lr = 0.0000292\n",
      "[7/25][4900/9765] Loss_D: 0.1003 Loss_G: 0.0398 Convergence: 0.1021 k= 0.024533 lr = 0.0000292\n",
      "[7/25][4910/9765] Loss_D: 0.0990 Loss_G: 0.0396 Convergence: 0.1003 k= 0.024542 lr = 0.0000292\n",
      "[7/25][4920/9765] Loss_D: 0.1027 Loss_G: 0.0410 Convergence: 0.1041 k= 0.024532 lr = 0.0000292\n",
      "[7/25][4930/9765] Loss_D: 0.1032 Loss_G: 0.0401 Convergence: 0.1058 k= 0.024533 lr = 0.0000292\n",
      "[7/25][4940/9765] Loss_D: 0.0986 Loss_G: 0.0404 Convergence: 0.1001 k= 0.024545 lr = 0.0000292\n",
      "[7/25][4950/9765] Loss_D: 0.1109 Loss_G: 0.0410 Convergence: 0.1157 k= 0.024537 lr = 0.0000292\n",
      "[7/25][4960/9765] Loss_D: 0.1029 Loss_G: 0.0400 Convergence: 0.1054 k= 0.024538 lr = 0.0000292\n",
      "[7/25][4970/9765] Loss_D: 0.1000 Loss_G: 0.0381 Convergence: 0.1033 k= 0.024543 lr = 0.0000292\n",
      "[7/25][4980/9765] Loss_D: 0.0992 Loss_G: 0.0450 Convergence: 0.1052 k= 0.024540 lr = 0.0000292\n",
      "[7/25][4990/9765] Loss_D: 0.1012 Loss_G: 0.0405 Convergence: 0.1026 k= 0.024530 lr = 0.0000292\n",
      "[7/25][5000/9765] Loss_D: 0.0977 Loss_G: 0.0426 Convergence: 0.1019 k= 0.024539 lr = 0.0000292\n",
      "[7/25][5010/9765] Loss_D: 0.1060 Loss_G: 0.0411 Convergence: 0.1086 k= 0.024531 lr = 0.0000292\n",
      "[7/25][5020/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1004 k= 0.024528 lr = 0.0000292\n",
      "[7/25][5030/9765] Loss_D: 0.0994 Loss_G: 0.0433 Convergence: 0.1036 k= 0.024542 lr = 0.0000292\n",
      "[7/25][5040/9765] Loss_D: 0.0843 Loss_G: 0.0381 Convergence: 0.0893 k= 0.024533 lr = 0.0000292\n",
      "[7/25][5050/9765] Loss_D: 0.0937 Loss_G: 0.0398 Convergence: 0.0966 k= 0.024542 lr = 0.0000292\n",
      "[7/25][5060/9765] Loss_D: 0.0964 Loss_G: 0.0395 Convergence: 0.0980 k= 0.024541 lr = 0.0000292\n",
      "[7/25][5070/9765] Loss_D: 0.1012 Loss_G: 0.0403 Convergence: 0.1027 k= 0.024552 lr = 0.0000292\n",
      "[7/25][5080/9765] Loss_D: 0.1032 Loss_G: 0.0396 Convergence: 0.1063 k= 0.024565 lr = 0.0000292\n",
      "[7/25][5090/9765] Loss_D: 0.0992 Loss_G: 0.0448 Convergence: 0.1050 k= 0.024567 lr = 0.0000292\n",
      "[7/25][5100/9765] Loss_D: 0.0915 Loss_G: 0.0401 Convergence: 0.0957 k= 0.024534 lr = 0.0000292\n",
      "[7/25][5110/9765] Loss_D: 0.1112 Loss_G: 0.0409 Convergence: 0.1161 k= 0.024543 lr = 0.0000292\n",
      "[7/25][5120/9765] Loss_D: 0.1082 Loss_G: 0.0422 Convergence: 0.1106 k= 0.024549 lr = 0.0000292\n",
      "[7/25][5130/9765] Loss_D: 0.1074 Loss_G: 0.0440 Convergence: 0.1090 k= 0.024528 lr = 0.0000292\n",
      "[7/25][5140/9765] Loss_D: 0.0975 Loss_G: 0.0372 Convergence: 0.1006 k= 0.024533 lr = 0.0000292\n",
      "[7/25][5150/9765] Loss_D: 0.0999 Loss_G: 0.0435 Convergence: 0.1040 k= 0.024547 lr = 0.0000292\n",
      "[7/25][5160/9765] Loss_D: 0.0994 Loss_G: 0.0426 Convergence: 0.1029 k= 0.024530 lr = 0.0000292\n",
      "[7/25][5170/9765] Loss_D: 0.0994 Loss_G: 0.0440 Convergence: 0.1043 k= 0.024502 lr = 0.0000292\n",
      "[7/25][5180/9765] Loss_D: 0.1110 Loss_G: 0.0411 Convergence: 0.1156 k= 0.024503 lr = 0.0000292\n",
      "[7/25][5190/9765] Loss_D: 0.0952 Loss_G: 0.0365 Convergence: 0.0981 k= 0.024523 lr = 0.0000292\n",
      "[7/25][5200/9765] Loss_D: 0.1051 Loss_G: 0.0474 Convergence: 0.1111 k= 0.024507 lr = 0.0000292\n",
      "[7/25][5210/9765] Loss_D: 0.1037 Loss_G: 0.0505 Convergence: 0.1134 k= 0.024402 lr = 0.0000292\n",
      "[7/25][5220/9765] Loss_D: 0.1115 Loss_G: 0.0401 Convergence: 0.1175 k= 0.024373 lr = 0.0000292\n",
      "[7/25][5230/9765] Loss_D: 0.0932 Loss_G: 0.0373 Convergence: 0.0945 k= 0.024391 lr = 0.0000292\n",
      "[7/25][5240/9765] Loss_D: 0.1027 Loss_G: 0.0411 Convergence: 0.1040 k= 0.024410 lr = 0.0000292\n",
      "[7/25][5250/9765] Loss_D: 0.0972 Loss_G: 0.0458 Convergence: 0.1047 k= 0.024382 lr = 0.0000292\n",
      "[7/25][5260/9765] Loss_D: 0.1053 Loss_G: 0.0402 Convergence: 0.1086 k= 0.024362 lr = 0.0000292\n",
      "[7/25][5270/9765] Loss_D: 0.1088 Loss_G: 0.0398 Convergence: 0.1139 k= 0.024379 lr = 0.0000292\n",
      "[7/25][5280/9765] Loss_D: 0.1116 Loss_G: 0.0433 Convergence: 0.1144 k= 0.024383 lr = 0.0000292\n",
      "[7/25][5290/9765] Loss_D: 0.0975 Loss_G: 0.0421 Convergence: 0.1013 k= 0.024362 lr = 0.0000292\n",
      "[7/25][5300/9765] Loss_D: 0.1004 Loss_G: 0.0403 Convergence: 0.1015 k= 0.024346 lr = 0.0000292\n",
      "[7/25][5310/9765] Loss_D: 0.1018 Loss_G: 0.0421 Convergence: 0.1038 k= 0.024338 lr = 0.0000292\n",
      "[7/25][5320/9765] Loss_D: 0.0955 Loss_G: 0.0399 Convergence: 0.0978 k= 0.024326 lr = 0.0000292\n",
      "[7/25][5330/9765] Loss_D: 0.0965 Loss_G: 0.0400 Convergence: 0.0985 k= 0.024344 lr = 0.0000292\n",
      "[7/25][5340/9765] Loss_D: 0.1048 Loss_G: 0.0410 Convergence: 0.1070 k= 0.024353 lr = 0.0000292\n",
      "[7/25][5350/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0968 k= 0.024349 lr = 0.0000292\n",
      "[7/25][5360/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0979 k= 0.024376 lr = 0.0000292\n",
      "[7/25][5370/9765] Loss_D: 0.0970 Loss_G: 0.0395 Convergence: 0.0983 k= 0.024362 lr = 0.0000292\n",
      "[7/25][5380/9765] Loss_D: 0.1018 Loss_G: 0.0389 Convergence: 0.1048 k= 0.024387 lr = 0.0000292\n",
      "[7/25][5390/9765] Loss_D: 0.0967 Loss_G: 0.0403 Convergence: 0.0989 k= 0.024415 lr = 0.0000292\n",
      "[7/25][5400/9765] Loss_D: 0.1056 Loss_G: 0.0439 Convergence: 0.1079 k= 0.024395 lr = 0.0000292\n",
      "[7/25][5410/9765] Loss_D: 0.0960 Loss_G: 0.0395 Convergence: 0.0977 k= 0.024390 lr = 0.0000292\n",
      "[7/25][5420/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1008 k= 0.024385 lr = 0.0000292\n",
      "[7/25][5430/9765] Loss_D: 0.1034 Loss_G: 0.0417 Convergence: 0.1045 k= 0.024376 lr = 0.0000292\n",
      "[7/25][5440/9765] Loss_D: 0.0901 Loss_G: 0.0367 Convergence: 0.0914 k= 0.024352 lr = 0.0000292\n",
      "[7/25][5450/9765] Loss_D: 0.0963 Loss_G: 0.0416 Convergence: 0.1000 k= 0.024350 lr = 0.0000292\n",
      "[7/25][5460/9765] Loss_D: 0.0982 Loss_G: 0.0421 Convergence: 0.1016 k= 0.024353 lr = 0.0000292\n",
      "[7/25][5470/9765] Loss_D: 0.0969 Loss_G: 0.0393 Convergence: 0.0980 k= 0.024345 lr = 0.0000292\n",
      "[7/25][5480/9765] Loss_D: 0.1007 Loss_G: 0.0484 Convergence: 0.1094 k= 0.024334 lr = 0.0000292\n",
      "[7/25][5490/9765] Loss_D: 0.1062 Loss_G: 0.0463 Convergence: 0.1107 k= 0.024314 lr = 0.0000292\n",
      "[7/25][5500/9765] Loss_D: 0.0972 Loss_G: 0.0402 Convergence: 0.0991 k= 0.024295 lr = 0.0000292\n",
      "[7/25][5510/9765] Loss_D: 0.1007 Loss_G: 0.0413 Convergence: 0.1023 k= 0.024281 lr = 0.0000292\n",
      "[7/25][5520/9765] Loss_D: 0.0957 Loss_G: 0.0419 Convergence: 0.1000 k= 0.024276 lr = 0.0000292\n",
      "[7/25][5530/9765] Loss_D: 0.0969 Loss_G: 0.0376 Convergence: 0.0993 k= 0.024290 lr = 0.0000292\n",
      "[7/25][5540/9765] Loss_D: 0.0991 Loss_G: 0.0415 Convergence: 0.1015 k= 0.024296 lr = 0.0000292\n",
      "[7/25][5550/9765] Loss_D: 0.1043 Loss_G: 0.0407 Convergence: 0.1068 k= 0.024297 lr = 0.0000292\n",
      "[7/25][5560/9765] Loss_D: 0.0998 Loss_G: 0.0387 Convergence: 0.1023 k= 0.024305 lr = 0.0000292\n",
      "[7/25][5570/9765] Loss_D: 0.1012 Loss_G: 0.0434 Convergence: 0.1047 k= 0.024309 lr = 0.0000292\n",
      "[7/25][5580/9765] Loss_D: 0.0967 Loss_G: 0.0450 Convergence: 0.1036 k= 0.024286 lr = 0.0000292\n",
      "[7/25][5590/9765] Loss_D: 0.0963 Loss_G: 0.0450 Convergence: 0.1034 k= 0.024210 lr = 0.0000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][5600/9765] Loss_D: 0.0997 Loss_G: 0.0368 Convergence: 0.1040 k= 0.024228 lr = 0.0000292\n",
      "[7/25][5610/9765] Loss_D: 0.0976 Loss_G: 0.0360 Convergence: 0.1018 k= 0.024262 lr = 0.0000292\n",
      "[7/25][5620/9765] Loss_D: 0.0970 Loss_G: 0.0436 Convergence: 0.1025 k= 0.024263 lr = 0.0000292\n",
      "[7/25][5630/9765] Loss_D: 0.0996 Loss_G: 0.0382 Convergence: 0.1025 k= 0.024252 lr = 0.0000292\n",
      "[7/25][5640/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0968 k= 0.024228 lr = 0.0000292\n",
      "[7/25][5650/9765] Loss_D: 0.0960 Loss_G: 0.0413 Convergence: 0.0996 k= 0.024246 lr = 0.0000292\n",
      "[7/25][5660/9765] Loss_D: 0.1000 Loss_G: 0.0441 Convergence: 0.1047 k= 0.024233 lr = 0.0000292\n",
      "[7/25][5670/9765] Loss_D: 0.0985 Loss_G: 0.0410 Convergence: 0.1007 k= 0.024243 lr = 0.0000292\n",
      "[7/25][5680/9765] Loss_D: 0.1038 Loss_G: 0.0435 Convergence: 0.1063 k= 0.024236 lr = 0.0000292\n",
      "[7/25][5690/9765] Loss_D: 0.0960 Loss_G: 0.0432 Convergence: 0.1014 k= 0.024211 lr = 0.0000292\n",
      "[7/25][5700/9765] Loss_D: 0.1030 Loss_G: 0.0376 Convergence: 0.1079 k= 0.024218 lr = 0.0000292\n",
      "[7/25][5710/9765] Loss_D: 0.0987 Loss_G: 0.0387 Convergence: 0.1008 k= 0.024224 lr = 0.0000292\n",
      "[7/25][5720/9765] Loss_D: 0.1070 Loss_G: 0.0346 Convergence: 0.1163 k= 0.024263 lr = 0.0000292\n",
      "[7/25][5730/9765] Loss_D: 0.1033 Loss_G: 0.0440 Convergence: 0.1066 k= 0.024265 lr = 0.0000292\n",
      "[7/25][5740/9765] Loss_D: 0.0994 Loss_G: 0.0413 Convergence: 0.1016 k= 0.024248 lr = 0.0000292\n",
      "[7/25][5750/9765] Loss_D: 0.1005 Loss_G: 0.0419 Convergence: 0.1028 k= 0.024245 lr = 0.0000292\n",
      "[7/25][5760/9765] Loss_D: 0.0951 Loss_G: 0.0396 Convergence: 0.0972 k= 0.024275 lr = 0.0000292\n",
      "[7/25][5770/9765] Loss_D: 0.0986 Loss_G: 0.0378 Convergence: 0.1015 k= 0.024277 lr = 0.0000292\n",
      "[7/25][5780/9765] Loss_D: 0.1017 Loss_G: 0.0418 Convergence: 0.1034 k= 0.024270 lr = 0.0000292\n",
      "[7/25][5790/9765] Loss_D: 0.0898 Loss_G: 0.0395 Convergence: 0.0940 k= 0.024271 lr = 0.0000292\n",
      "[7/25][5800/9765] Loss_D: 0.1047 Loss_G: 0.0388 Convergence: 0.1091 k= 0.024265 lr = 0.0000292\n",
      "[7/25][5810/9765] Loss_D: 0.0923 Loss_G: 0.0394 Convergence: 0.0954 k= 0.024287 lr = 0.0000292\n",
      "[7/25][5820/9765] Loss_D: 0.1028 Loss_G: 0.0384 Convergence: 0.1067 k= 0.024278 lr = 0.0000292\n",
      "[7/25][5830/9765] Loss_D: 0.0978 Loss_G: 0.0408 Convergence: 0.1001 k= 0.024282 lr = 0.0000292\n",
      "[7/25][5840/9765] Loss_D: 0.0947 Loss_G: 0.0410 Convergence: 0.0984 k= 0.024275 lr = 0.0000292\n",
      "[7/25][5850/9765] Loss_D: 0.0949 Loss_G: 0.0408 Convergence: 0.0984 k= 0.024276 lr = 0.0000292\n",
      "[7/25][5860/9765] Loss_D: 0.0988 Loss_G: 0.0435 Convergence: 0.1034 k= 0.024280 lr = 0.0000292\n",
      "[7/25][5870/9765] Loss_D: 0.0937 Loss_G: 0.0377 Convergence: 0.0946 k= 0.024282 lr = 0.0000292\n",
      "[7/25][5880/9765] Loss_D: 0.1012 Loss_G: 0.0386 Convergence: 0.1045 k= 0.024306 lr = 0.0000292\n",
      "[7/25][5890/9765] Loss_D: 0.0928 Loss_G: 0.0499 Convergence: 0.1063 k= 0.024264 lr = 0.0000292\n",
      "[7/25][5900/9765] Loss_D: 0.1012 Loss_G: 0.0385 Convergence: 0.1044 k= 0.024235 lr = 0.0000292\n",
      "[7/25][5910/9765] Loss_D: 0.1204 Loss_G: 0.0345 Convergence: 0.1352 k= 0.024286 lr = 0.0000292\n",
      "[7/25][5920/9765] Loss_D: 0.0982 Loss_G: 0.0376 Convergence: 0.1012 k= 0.024320 lr = 0.0000292\n",
      "[7/25][5930/9765] Loss_D: 0.1029 Loss_G: 0.0403 Convergence: 0.1052 k= 0.024327 lr = 0.0000292\n",
      "[7/25][5940/9765] Loss_D: 0.1025 Loss_G: 0.0443 Convergence: 0.1064 k= 0.024287 lr = 0.0000292\n",
      "[7/25][5950/9765] Loss_D: 0.0937 Loss_G: 0.0406 Convergence: 0.0975 k= 0.024256 lr = 0.0000292\n",
      "[7/25][5960/9765] Loss_D: 0.0976 Loss_G: 0.0396 Convergence: 0.0988 k= 0.024258 lr = 0.0000292\n",
      "[7/25][5970/9765] Loss_D: 0.1096 Loss_G: 0.0431 Convergence: 0.1118 k= 0.024271 lr = 0.0000292\n",
      "[7/25][5980/9765] Loss_D: 0.0959 Loss_G: 0.0414 Convergence: 0.0995 k= 0.024286 lr = 0.0000292\n",
      "[7/25][5990/9765] Loss_D: 0.0932 Loss_G: 0.0409 Convergence: 0.0974 k= 0.024295 lr = 0.0000292\n",
      "[7/25][6000/9765] Loss_D: 0.1101 Loss_G: 0.0392 Convergence: 0.1163 k= 0.024300 lr = 0.0000292\n",
      "[7/25][6010/9765] Loss_D: 0.0968 Loss_G: 0.0399 Convergence: 0.0986 k= 0.024291 lr = 0.0000292\n",
      "[7/25][6020/9765] Loss_D: 0.1054 Loss_G: 0.0402 Convergence: 0.1088 k= 0.024278 lr = 0.0000292\n",
      "[7/25][6030/9765] Loss_D: 0.1006 Loss_G: 0.0403 Convergence: 0.1020 k= 0.024270 lr = 0.0000292\n",
      "[7/25][6040/9765] Loss_D: 0.1064 Loss_G: 0.0377 Convergence: 0.1125 k= 0.024273 lr = 0.0000292\n",
      "[7/25][6050/9765] Loss_D: 0.1007 Loss_G: 0.0360 Convergence: 0.1063 k= 0.024287 lr = 0.0000292\n",
      "[7/25][6060/9765] Loss_D: 0.1023 Loss_G: 0.0439 Convergence: 0.1059 k= 0.024303 lr = 0.0000292\n",
      "[7/25][6070/9765] Loss_D: 0.1033 Loss_G: 0.0424 Convergence: 0.1050 k= 0.024275 lr = 0.0000292\n",
      "[7/25][6080/9765] Loss_D: 0.1068 Loss_G: 0.0426 Convergence: 0.1084 k= 0.024251 lr = 0.0000292\n",
      "[7/25][6090/9765] Loss_D: 0.0895 Loss_G: 0.0375 Convergence: 0.0917 k= 0.024238 lr = 0.0000292\n",
      "[7/25][6100/9765] Loss_D: 0.0933 Loss_G: 0.0369 Convergence: 0.0950 k= 0.024237 lr = 0.0000292\n",
      "[7/25][6110/9765] Loss_D: 0.1027 Loss_G: 0.0410 Convergence: 0.1041 k= 0.024242 lr = 0.0000292\n",
      "[7/25][6120/9765] Loss_D: 0.0999 Loss_G: 0.0413 Convergence: 0.1017 k= 0.024256 lr = 0.0000292\n",
      "[7/25][6130/9765] Loss_D: 0.0907 Loss_G: 0.0413 Convergence: 0.0964 k= 0.024238 lr = 0.0000292\n",
      "[7/25][6140/9765] Loss_D: 0.1037 Loss_G: 0.0398 Convergence: 0.1067 k= 0.024245 lr = 0.0000292\n",
      "[7/25][6150/9765] Loss_D: 0.0994 Loss_G: 0.0408 Convergence: 0.1011 k= 0.024247 lr = 0.0000292\n",
      "[7/25][6160/9765] Loss_D: 0.0960 Loss_G: 0.0404 Convergence: 0.0986 k= 0.024239 lr = 0.0000292\n",
      "[7/25][6170/9765] Loss_D: 0.0961 Loss_G: 0.0399 Convergence: 0.0982 k= 0.024231 lr = 0.0000292\n",
      "[7/25][6180/9765] Loss_D: 0.0905 Loss_G: 0.0403 Convergence: 0.0953 k= 0.024230 lr = 0.0000292\n",
      "[7/25][6190/9765] Loss_D: 0.0966 Loss_G: 0.0402 Convergence: 0.0987 k= 0.024216 lr = 0.0000292\n",
      "[7/25][6200/9765] Loss_D: 0.0992 Loss_G: 0.0385 Convergence: 0.1017 k= 0.024238 lr = 0.0000292\n",
      "[7/25][6210/9765] Loss_D: 0.1050 Loss_G: 0.0414 Convergence: 0.1070 k= 0.024238 lr = 0.0000292\n",
      "[7/25][6220/9765] Loss_D: 0.1092 Loss_G: 0.0437 Convergence: 0.1106 k= 0.024241 lr = 0.0000292\n",
      "[7/25][6230/9765] Loss_D: 0.1030 Loss_G: 0.0448 Convergence: 0.1072 k= 0.024214 lr = 0.0000292\n",
      "[7/25][6240/9765] Loss_D: 0.1114 Loss_G: 0.0384 Convergence: 0.1189 k= 0.024206 lr = 0.0000292\n",
      "[7/25][6250/9765] Loss_D: 0.1032 Loss_G: 0.0395 Convergence: 0.1063 k= 0.024205 lr = 0.0000292\n",
      "[7/25][6260/9765] Loss_D: 0.0935 Loss_G: 0.0353 Convergence: 0.0968 k= 0.024245 lr = 0.0000292\n",
      "[7/25][6270/9765] Loss_D: 0.1040 Loss_G: 0.0473 Convergence: 0.1103 k= 0.024254 lr = 0.0000292\n",
      "[7/25][6280/9765] Loss_D: 0.0981 Loss_G: 0.0415 Convergence: 0.1009 k= 0.024231 lr = 0.0000292\n",
      "[7/25][6290/9765] Loss_D: 0.0945 Loss_G: 0.0441 Convergence: 0.1014 k= 0.024211 lr = 0.0000292\n",
      "[7/25][6300/9765] Loss_D: 0.1010 Loss_G: 0.0411 Convergence: 0.1023 k= 0.024189 lr = 0.0000292\n",
      "[7/25][6310/9765] Loss_D: 0.0978 Loss_G: 0.0435 Convergence: 0.1027 k= 0.024165 lr = 0.0000292\n",
      "[7/25][6320/9765] Loss_D: 0.0961 Loss_G: 0.0388 Convergence: 0.0971 k= 0.024163 lr = 0.0000292\n",
      "[7/25][6330/9765] Loss_D: 0.0994 Loss_G: 0.0377 Convergence: 0.1027 k= 0.024158 lr = 0.0000292\n",
      "[7/25][6340/9765] Loss_D: 0.1005 Loss_G: 0.0421 Convergence: 0.1030 k= 0.024177 lr = 0.0000292\n",
      "[7/25][6350/9765] Loss_D: 0.0951 Loss_G: 0.0436 Convergence: 0.1013 k= 0.024181 lr = 0.0000292\n",
      "[7/25][6360/9765] Loss_D: 0.0973 Loss_G: 0.0410 Convergence: 0.1000 k= 0.024168 lr = 0.0000292\n",
      "[7/25][6370/9765] Loss_D: 0.0956 Loss_G: 0.0401 Convergence: 0.0981 k= 0.024152 lr = 0.0000292\n",
      "[7/25][6380/9765] Loss_D: 0.1010 Loss_G: 0.0394 Convergence: 0.1033 k= 0.024152 lr = 0.0000292\n",
      "[7/25][6390/9765] Loss_D: 0.1165 Loss_G: 0.0458 Convergence: 0.1188 k= 0.024146 lr = 0.0000292\n",
      "[7/25][6400/9765] Loss_D: 0.0941 Loss_G: 0.0417 Convergence: 0.0987 k= 0.024107 lr = 0.0000292\n",
      "[7/25][6410/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0964 k= 0.024124 lr = 0.0000292\n",
      "[7/25][6420/9765] Loss_D: 0.1135 Loss_G: 0.0406 Convergence: 0.1195 k= 0.024130 lr = 0.0000292\n",
      "[7/25][6430/9765] Loss_D: 0.0991 Loss_G: 0.0397 Convergence: 0.1004 k= 0.024121 lr = 0.0000292\n",
      "[7/25][6440/9765] Loss_D: 0.1012 Loss_G: 0.0439 Convergence: 0.1053 k= 0.024103 lr = 0.0000292\n",
      "[7/25][6450/9765] Loss_D: 0.1077 Loss_G: 0.0426 Convergence: 0.1094 k= 0.024091 lr = 0.0000292\n",
      "[7/25][6460/9765] Loss_D: 0.0902 Loss_G: 0.0385 Convergence: 0.0932 k= 0.024080 lr = 0.0000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][6470/9765] Loss_D: 0.1019 Loss_G: 0.0395 Convergence: 0.1046 k= 0.024095 lr = 0.0000292\n",
      "[7/25][6480/9765] Loss_D: 0.1050 Loss_G: 0.0417 Convergence: 0.1067 k= 0.024083 lr = 0.0000292\n",
      "[7/25][6490/9765] Loss_D: 0.0982 Loss_G: 0.0405 Convergence: 0.1000 k= 0.024089 lr = 0.0000292\n",
      "[7/25][6500/9765] Loss_D: 0.1002 Loss_G: 0.0421 Convergence: 0.1028 k= 0.024075 lr = 0.0000292\n",
      "[7/25][6510/9765] Loss_D: 0.0990 Loss_G: 0.0386 Convergence: 0.1013 k= 0.024069 lr = 0.0000292\n",
      "[7/25][6520/9765] Loss_D: 0.0966 Loss_G: 0.0448 Convergence: 0.1034 k= 0.024065 lr = 0.0000292\n",
      "[7/25][6530/9765] Loss_D: 0.1032 Loss_G: 0.0417 Convergence: 0.1043 k= 0.024054 lr = 0.0000292\n",
      "[7/25][6540/9765] Loss_D: 0.0980 Loss_G: 0.0384 Convergence: 0.1001 k= 0.024066 lr = 0.0000292\n",
      "[7/25][6550/9765] Loss_D: 0.1017 Loss_G: 0.0363 Convergence: 0.1074 k= 0.024101 lr = 0.0000292\n",
      "[7/25][6560/9765] Loss_D: 0.0999 Loss_G: 0.0380 Convergence: 0.1031 k= 0.024117 lr = 0.0000292\n",
      "[7/25][6570/9765] Loss_D: 0.1011 Loss_G: 0.0438 Convergence: 0.1051 k= 0.024102 lr = 0.0000292\n",
      "[7/25][6580/9765] Loss_D: 0.1019 Loss_G: 0.0401 Convergence: 0.1039 k= 0.024110 lr = 0.0000292\n",
      "[7/25][6590/9765] Loss_D: 0.0997 Loss_G: 0.0384 Convergence: 0.1025 k= 0.024121 lr = 0.0000292\n",
      "[7/25][6600/9765] Loss_D: 0.1048 Loss_G: 0.0414 Convergence: 0.1069 k= 0.024121 lr = 0.0000292\n",
      "[7/25][6610/9765] Loss_D: 0.1090 Loss_G: 0.0435 Convergence: 0.1106 k= 0.024106 lr = 0.0000292\n",
      "[7/25][6620/9765] Loss_D: 0.1018 Loss_G: 0.0406 Convergence: 0.1033 k= 0.024088 lr = 0.0000292\n",
      "[7/25][6630/9765] Loss_D: 0.1056 Loss_G: 0.0423 Convergence: 0.1068 k= 0.024096 lr = 0.0000292\n",
      "[7/25][6640/9765] Loss_D: 0.1046 Loss_G: 0.0371 Convergence: 0.1105 k= 0.024111 lr = 0.0000292\n",
      "[7/25][6650/9765] Loss_D: 0.0986 Loss_G: 0.0388 Convergence: 0.1007 k= 0.024133 lr = 0.0000277\n",
      "[7/25][6660/9765] Loss_D: 0.1031 Loss_G: 0.0377 Convergence: 0.1080 k= 0.024134 lr = 0.0000277\n",
      "[7/25][6670/9765] Loss_D: 0.1043 Loss_G: 0.0404 Convergence: 0.1070 k= 0.024144 lr = 0.0000277\n",
      "[7/25][6680/9765] Loss_D: 0.0991 Loss_G: 0.0359 Convergence: 0.1040 k= 0.024157 lr = 0.0000277\n",
      "[7/25][6690/9765] Loss_D: 0.0935 Loss_G: 0.0405 Convergence: 0.0972 k= 0.024165 lr = 0.0000277\n",
      "[7/25][6700/9765] Loss_D: 0.0968 Loss_G: 0.0372 Convergence: 0.0995 k= 0.024171 lr = 0.0000277\n",
      "[7/25][6710/9765] Loss_D: 0.1047 Loss_G: 0.0398 Convergence: 0.1081 k= 0.024201 lr = 0.0000277\n",
      "[7/25][6720/9765] Loss_D: 0.0960 Loss_G: 0.0408 Convergence: 0.0989 k= 0.024197 lr = 0.0000277\n",
      "[7/25][6730/9765] Loss_D: 0.0995 Loss_G: 0.0410 Convergence: 0.1013 k= 0.024198 lr = 0.0000277\n",
      "[7/25][6740/9765] Loss_D: 0.0997 Loss_G: 0.0385 Convergence: 0.1024 k= 0.024184 lr = 0.0000277\n",
      "[7/25][6750/9765] Loss_D: 0.0987 Loss_G: 0.0398 Convergence: 0.0998 k= 0.024196 lr = 0.0000277\n",
      "[7/25][6760/9765] Loss_D: 0.1138 Loss_G: 0.0421 Convergence: 0.1188 k= 0.024205 lr = 0.0000277\n",
      "[7/25][6770/9765] Loss_D: 0.0966 Loss_G: 0.0423 Convergence: 0.1008 k= 0.024192 lr = 0.0000277\n",
      "[7/25][6780/9765] Loss_D: 0.1035 Loss_G: 0.0412 Convergence: 0.1051 k= 0.024185 lr = 0.0000277\n",
      "[7/25][6790/9765] Loss_D: 0.0989 Loss_G: 0.0373 Convergence: 0.1024 k= 0.024206 lr = 0.0000277\n",
      "[7/25][6800/9765] Loss_D: 0.0972 Loss_G: 0.0440 Convergence: 0.1029 k= 0.024208 lr = 0.0000277\n",
      "[7/25][6810/9765] Loss_D: 0.1029 Loss_G: 0.0385 Convergence: 0.1069 k= 0.024221 lr = 0.0000277\n",
      "[7/25][6820/9765] Loss_D: 0.0933 Loss_G: 0.0400 Convergence: 0.0965 k= 0.024237 lr = 0.0000277\n",
      "[7/25][6830/9765] Loss_D: 0.1070 Loss_G: 0.0418 Convergence: 0.1094 k= 0.024256 lr = 0.0000277\n",
      "[7/25][6840/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0973 k= 0.024248 lr = 0.0000277\n",
      "[7/25][6850/9765] Loss_D: 0.1086 Loss_G: 0.0414 Convergence: 0.1121 k= 0.024247 lr = 0.0000277\n",
      "[7/25][6860/9765] Loss_D: 0.1010 Loss_G: 0.0375 Convergence: 0.1052 k= 0.024262 lr = 0.0000277\n",
      "[7/25][6870/9765] Loss_D: 0.1044 Loss_G: 0.0414 Convergence: 0.1061 k= 0.024272 lr = 0.0000277\n",
      "[7/25][6880/9765] Loss_D: 0.0955 Loss_G: 0.0417 Convergence: 0.0996 k= 0.024266 lr = 0.0000277\n",
      "[7/25][6890/9765] Loss_D: 0.1081 Loss_G: 0.0401 Convergence: 0.1125 k= 0.024269 lr = 0.0000277\n",
      "[7/25][6900/9765] Loss_D: 0.0986 Loss_G: 0.0419 Convergence: 0.1016 k= 0.024266 lr = 0.0000277\n",
      "[7/25][6910/9765] Loss_D: 0.0999 Loss_G: 0.0424 Convergence: 0.1030 k= 0.024258 lr = 0.0000277\n",
      "[7/25][6920/9765] Loss_D: 0.1007 Loss_G: 0.0400 Convergence: 0.1023 k= 0.024252 lr = 0.0000277\n",
      "[7/25][6930/9765] Loss_D: 0.1000 Loss_G: 0.0413 Convergence: 0.1019 k= 0.024245 lr = 0.0000277\n",
      "[7/25][6940/9765] Loss_D: 0.1046 Loss_G: 0.0422 Convergence: 0.1056 k= 0.024257 lr = 0.0000277\n",
      "[7/25][6950/9765] Loss_D: 0.0966 Loss_G: 0.0418 Convergence: 0.1003 k= 0.024260 lr = 0.0000277\n",
      "[7/25][6960/9765] Loss_D: 0.0949 Loss_G: 0.0399 Convergence: 0.0975 k= 0.024234 lr = 0.0000277\n",
      "[7/25][6970/9765] Loss_D: 0.0891 Loss_G: 0.0403 Convergence: 0.0944 k= 0.024195 lr = 0.0000277\n",
      "[7/25][6980/9765] Loss_D: 0.1051 Loss_G: 0.0383 Convergence: 0.1102 k= 0.024202 lr = 0.0000277\n",
      "[7/25][6990/9765] Loss_D: 0.0918 Loss_G: 0.0374 Convergence: 0.0930 k= 0.024242 lr = 0.0000277\n",
      "[7/25][7000/9765] Loss_D: 0.1093 Loss_G: 0.0504 Convergence: 0.1168 k= 0.024234 lr = 0.0000277\n",
      "[7/25][7010/9765] Loss_D: 0.0998 Loss_G: 0.0450 Convergence: 0.1055 k= 0.024140 lr = 0.0000277\n",
      "[7/25][7020/9765] Loss_D: 0.0879 Loss_G: 0.0385 Convergence: 0.0918 k= 0.024138 lr = 0.0000277\n",
      "[7/25][7030/9765] Loss_D: 0.1071 Loss_G: 0.0366 Convergence: 0.1145 k= 0.024165 lr = 0.0000277\n",
      "[7/25][7040/9765] Loss_D: 0.0899 Loss_G: 0.0356 Convergence: 0.0914 k= 0.024185 lr = 0.0000277\n",
      "[7/25][7050/9765] Loss_D: 0.0899 Loss_G: 0.0430 Convergence: 0.0976 k= 0.024157 lr = 0.0000277\n",
      "[7/25][7060/9765] Loss_D: 0.1059 Loss_G: 0.0384 Convergence: 0.1112 k= 0.024160 lr = 0.0000277\n",
      "[7/25][7070/9765] Loss_D: 0.0887 Loss_G: 0.0394 Convergence: 0.0932 k= 0.024177 lr = 0.0000277\n",
      "[7/25][7080/9765] Loss_D: 0.0975 Loss_G: 0.0412 Convergence: 0.1003 k= 0.024171 lr = 0.0000277\n",
      "[7/25][7090/9765] Loss_D: 0.1042 Loss_G: 0.0412 Convergence: 0.1060 k= 0.024168 lr = 0.0000277\n",
      "[7/25][7100/9765] Loss_D: 0.1060 Loss_G: 0.0378 Convergence: 0.1118 k= 0.024174 lr = 0.0000277\n",
      "[7/25][7110/9765] Loss_D: 0.0939 Loss_G: 0.0400 Convergence: 0.0969 k= 0.024177 lr = 0.0000277\n",
      "[7/25][7120/9765] Loss_D: 0.0994 Loss_G: 0.0390 Convergence: 0.1015 k= 0.024181 lr = 0.0000277\n",
      "[7/25][7130/9765] Loss_D: 0.0977 Loss_G: 0.0470 Convergence: 0.1062 k= 0.024165 lr = 0.0000277\n",
      "[7/25][7140/9765] Loss_D: 0.1077 Loss_G: 0.0422 Convergence: 0.1099 k= 0.024165 lr = 0.0000277\n",
      "[7/25][7150/9765] Loss_D: 0.0924 Loss_G: 0.0448 Convergence: 0.1008 k= 0.024149 lr = 0.0000277\n",
      "[7/25][7160/9765] Loss_D: 0.0952 Loss_G: 0.0428 Convergence: 0.1006 k= 0.024121 lr = 0.0000277\n",
      "[7/25][7170/9765] Loss_D: 0.0899 Loss_G: 0.0393 Convergence: 0.0937 k= 0.024122 lr = 0.0000277\n",
      "[7/25][7180/9765] Loss_D: 0.0941 Loss_G: 0.0375 Convergence: 0.0955 k= 0.024139 lr = 0.0000277\n",
      "[7/25][7190/9765] Loss_D: 0.0978 Loss_G: 0.0387 Convergence: 0.0995 k= 0.024160 lr = 0.0000277\n",
      "[7/25][7200/9765] Loss_D: 0.0879 Loss_G: 0.0411 Convergence: 0.0945 k= 0.024143 lr = 0.0000277\n",
      "[7/25][7210/9765] Loss_D: 0.1025 Loss_G: 0.0374 Convergence: 0.1074 k= 0.024158 lr = 0.0000277\n",
      "[7/25][7220/9765] Loss_D: 0.1011 Loss_G: 0.0404 Convergence: 0.1024 k= 0.024166 lr = 0.0000277\n",
      "[7/25][7230/9765] Loss_D: 0.1005 Loss_G: 0.0404 Convergence: 0.1016 k= 0.024181 lr = 0.0000277\n",
      "[7/25][7240/9765] Loss_D: 0.1038 Loss_G: 0.0387 Convergence: 0.1080 k= 0.024168 lr = 0.0000277\n",
      "[7/25][7250/9765] Loss_D: 0.0941 Loss_G: 0.0386 Convergence: 0.0956 k= 0.024188 lr = 0.0000277\n",
      "[7/25][7260/9765] Loss_D: 0.0990 Loss_G: 0.0389 Convergence: 0.1010 k= 0.024196 lr = 0.0000277\n",
      "[7/25][7270/9765] Loss_D: 0.1128 Loss_G: 0.0429 Convergence: 0.1164 k= 0.024186 lr = 0.0000277\n",
      "[7/25][7280/9765] Loss_D: 0.1053 Loss_G: 0.0427 Convergence: 0.1065 k= 0.024185 lr = 0.0000277\n",
      "[7/25][7290/9765] Loss_D: 0.0980 Loss_G: 0.0425 Convergence: 0.1018 k= 0.024147 lr = 0.0000277\n",
      "[7/25][7300/9765] Loss_D: 0.1011 Loss_G: 0.0397 Convergence: 0.1032 k= 0.024142 lr = 0.0000277\n",
      "[7/25][7310/9765] Loss_D: 0.0872 Loss_G: 0.0413 Convergence: 0.0942 k= 0.024138 lr = 0.0000277\n",
      "[7/25][7320/9765] Loss_D: 0.1019 Loss_G: 0.0432 Convergence: 0.1049 k= 0.024141 lr = 0.0000277\n",
      "[7/25][7330/9765] Loss_D: 0.0947 Loss_G: 0.0401 Convergence: 0.0974 k= 0.024142 lr = 0.0000277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][7340/9765] Loss_D: 0.1040 Loss_G: 0.0438 Convergence: 0.1069 k= 0.024123 lr = 0.0000277\n",
      "[7/25][7350/9765] Loss_D: 0.1088 Loss_G: 0.0425 Convergence: 0.1112 k= 0.024099 lr = 0.0000277\n",
      "[7/25][7360/9765] Loss_D: 0.0952 Loss_G: 0.0381 Convergence: 0.0965 k= 0.024101 lr = 0.0000277\n",
      "[7/25][7370/9765] Loss_D: 0.1091 Loss_G: 0.0424 Convergence: 0.1118 k= 0.024092 lr = 0.0000277\n",
      "[7/25][7380/9765] Loss_D: 0.1006 Loss_G: 0.0456 Convergence: 0.1066 k= 0.024074 lr = 0.0000277\n",
      "[7/25][7390/9765] Loss_D: 0.1044 Loss_G: 0.0401 Convergence: 0.1073 k= 0.024052 lr = 0.0000277\n",
      "[7/25][7400/9765] Loss_D: 0.1091 Loss_G: 0.0396 Convergence: 0.1144 k= 0.024044 lr = 0.0000277\n",
      "[7/25][7410/9765] Loss_D: 0.0974 Loss_G: 0.0414 Convergence: 0.1004 k= 0.024059 lr = 0.0000277\n",
      "[7/25][7420/9765] Loss_D: 0.0923 Loss_G: 0.0410 Convergence: 0.0970 k= 0.024050 lr = 0.0000277\n",
      "[7/25][7430/9765] Loss_D: 0.1014 Loss_G: 0.0401 Convergence: 0.1032 k= 0.024046 lr = 0.0000277\n",
      "[7/25][7440/9765] Loss_D: 0.0980 Loss_G: 0.0414 Convergence: 0.1007 k= 0.024043 lr = 0.0000277\n",
      "[7/25][7450/9765] Loss_D: 0.1000 Loss_G: 0.0407 Convergence: 0.1012 k= 0.024045 lr = 0.0000277\n",
      "[7/25][7460/9765] Loss_D: 0.1081 Loss_G: 0.0423 Convergence: 0.1103 k= 0.024044 lr = 0.0000277\n",
      "[7/25][7470/9765] Loss_D: 0.1060 Loss_G: 0.0414 Convergence: 0.1084 k= 0.024047 lr = 0.0000277\n",
      "[7/25][7480/9765] Loss_D: 0.1041 Loss_G: 0.0399 Convergence: 0.1072 k= 0.024061 lr = 0.0000277\n",
      "[7/25][7490/9765] Loss_D: 0.1025 Loss_G: 0.0390 Convergence: 0.1059 k= 0.024062 lr = 0.0000277\n",
      "[7/25][7500/9765] Loss_D: 0.1012 Loss_G: 0.0410 Convergence: 0.1023 k= 0.024051 lr = 0.0000277\n",
      "[7/25][7510/9765] Loss_D: 0.1092 Loss_G: 0.0406 Convergence: 0.1136 k= 0.024043 lr = 0.0000277\n",
      "[7/25][7520/9765] Loss_D: 0.0943 Loss_G: 0.0399 Convergence: 0.0971 k= 0.024028 lr = 0.0000277\n",
      "[7/25][7530/9765] Loss_D: 0.0905 Loss_G: 0.0376 Convergence: 0.0925 k= 0.024026 lr = 0.0000277\n",
      "[7/25][7540/9765] Loss_D: 0.1056 Loss_G: 0.0382 Convergence: 0.1110 k= 0.024047 lr = 0.0000277\n",
      "[7/25][7550/9765] Loss_D: 0.0993 Loss_G: 0.0392 Convergence: 0.1012 k= 0.024038 lr = 0.0000277\n",
      "[7/25][7560/9765] Loss_D: 0.0997 Loss_G: 0.0403 Convergence: 0.1007 k= 0.024028 lr = 0.0000277\n",
      "[7/25][7570/9765] Loss_D: 0.1042 Loss_G: 0.0382 Convergence: 0.1089 k= 0.024042 lr = 0.0000277\n",
      "[7/25][7580/9765] Loss_D: 0.1000 Loss_G: 0.0440 Convergence: 0.1046 k= 0.024037 lr = 0.0000277\n",
      "[7/25][7590/9765] Loss_D: 0.0974 Loss_G: 0.0430 Convergence: 0.1021 k= 0.024020 lr = 0.0000277\n",
      "[7/25][7600/9765] Loss_D: 0.0998 Loss_G: 0.0459 Convergence: 0.1064 k= 0.023990 lr = 0.0000277\n",
      "[7/25][7610/9765] Loss_D: 0.0898 Loss_G: 0.0396 Convergence: 0.0940 k= 0.023967 lr = 0.0000277\n",
      "[7/25][7620/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0966 k= 0.023957 lr = 0.0000277\n",
      "[7/25][7630/9765] Loss_D: 0.0988 Loss_G: 0.0411 Convergence: 0.1010 k= 0.023947 lr = 0.0000277\n",
      "[7/25][7640/9765] Loss_D: 0.1053 Loss_G: 0.0396 Convergence: 0.1091 k= 0.023945 lr = 0.0000277\n",
      "[7/25][7650/9765] Loss_D: 0.0990 Loss_G: 0.0454 Convergence: 0.1054 k= 0.023921 lr = 0.0000277\n",
      "[7/25][7660/9765] Loss_D: 0.1109 Loss_G: 0.0375 Convergence: 0.1191 k= 0.023906 lr = 0.0000277\n",
      "[7/25][7670/9765] Loss_D: 0.1069 Loss_G: 0.0421 Convergence: 0.1088 k= 0.023938 lr = 0.0000277\n",
      "[7/25][7680/9765] Loss_D: 0.1016 Loss_G: 0.0394 Convergence: 0.1042 k= 0.023940 lr = 0.0000277\n",
      "[7/25][7690/9765] Loss_D: 0.1005 Loss_G: 0.0436 Convergence: 0.1045 k= 0.023936 lr = 0.0000277\n",
      "[7/25][7700/9765] Loss_D: 0.1004 Loss_G: 0.0394 Convergence: 0.1025 k= 0.023926 lr = 0.0000277\n",
      "[7/25][7710/9765] Loss_D: 0.1023 Loss_G: 0.0394 Convergence: 0.1051 k= 0.023928 lr = 0.0000277\n",
      "[7/25][7720/9765] Loss_D: 0.0955 Loss_G: 0.0394 Convergence: 0.0973 k= 0.023937 lr = 0.0000277\n",
      "[7/25][7730/9765] Loss_D: 0.0974 Loss_G: 0.0418 Convergence: 0.1008 k= 0.023905 lr = 0.0000277\n",
      "[7/25][7740/9765] Loss_D: 0.1109 Loss_G: 0.0451 Convergence: 0.1123 k= 0.023868 lr = 0.0000277\n",
      "[7/25][7750/9765] Loss_D: 0.1080 Loss_G: 0.0409 Convergence: 0.1115 k= 0.023860 lr = 0.0000277\n",
      "[7/25][7760/9765] Loss_D: 0.1050 Loss_G: 0.0395 Convergence: 0.1088 k= 0.023849 lr = 0.0000277\n",
      "[7/25][7770/9765] Loss_D: 0.1007 Loss_G: 0.0442 Convergence: 0.1052 k= 0.023852 lr = 0.0000277\n",
      "[7/25][7780/9765] Loss_D: 0.0947 Loss_G: 0.0432 Convergence: 0.1006 k= 0.023837 lr = 0.0000277\n",
      "[7/25][7790/9765] Loss_D: 0.0981 Loss_G: 0.0403 Convergence: 0.0997 k= 0.023827 lr = 0.0000277\n",
      "[7/25][7800/9765] Loss_D: 0.1145 Loss_G: 0.0411 Convergence: 0.1206 k= 0.023847 lr = 0.0000277\n",
      "[7/25][7810/9765] Loss_D: 0.1003 Loss_G: 0.0404 Convergence: 0.1014 k= 0.023840 lr = 0.0000277\n",
      "[7/25][7820/9765] Loss_D: 0.0939 Loss_G: 0.0423 Convergence: 0.0992 k= 0.023836 lr = 0.0000277\n",
      "[7/25][7830/9765] Loss_D: 0.1006 Loss_G: 0.0381 Convergence: 0.1041 k= 0.023833 lr = 0.0000277\n",
      "[7/25][7840/9765] Loss_D: 0.0940 Loss_G: 0.0395 Convergence: 0.0964 k= 0.023847 lr = 0.0000277\n",
      "[7/25][7850/9765] Loss_D: 0.1015 Loss_G: 0.0388 Convergence: 0.1047 k= 0.023863 lr = 0.0000277\n",
      "[7/25][7860/9765] Loss_D: 0.0965 Loss_G: 0.0402 Convergence: 0.0987 k= 0.023890 lr = 0.0000277\n",
      "[7/25][7870/9765] Loss_D: 0.0997 Loss_G: 0.0400 Convergence: 0.1009 k= 0.023885 lr = 0.0000277\n",
      "[7/25][7880/9765] Loss_D: 0.0942 Loss_G: 0.0449 Convergence: 0.1021 k= 0.023871 lr = 0.0000277\n",
      "[7/25][7890/9765] Loss_D: 0.1003 Loss_G: 0.0403 Convergence: 0.1015 k= 0.023862 lr = 0.0000277\n",
      "[7/25][7900/9765] Loss_D: 0.1071 Loss_G: 0.0402 Convergence: 0.1110 k= 0.023868 lr = 0.0000277\n",
      "[7/25][7910/9765] Loss_D: 0.1049 Loss_G: 0.0413 Convergence: 0.1071 k= 0.023849 lr = 0.0000277\n",
      "[7/25][7920/9765] Loss_D: 0.1001 Loss_G: 0.0407 Convergence: 0.1013 k= 0.023840 lr = 0.0000277\n",
      "[7/25][7930/9765] Loss_D: 0.0896 Loss_G: 0.0368 Convergence: 0.0911 k= 0.023859 lr = 0.0000277\n",
      "[7/25][7940/9765] Loss_D: 0.0993 Loss_G: 0.0466 Convergence: 0.1068 k= 0.023857 lr = 0.0000277\n",
      "[7/25][7950/9765] Loss_D: 0.1103 Loss_G: 0.0370 Convergence: 0.1187 k= 0.023845 lr = 0.0000277\n",
      "[7/25][7960/9765] Loss_D: 0.0973 Loss_G: 0.0393 Convergence: 0.0983 k= 0.023866 lr = 0.0000277\n",
      "[7/25][7970/9765] Loss_D: 0.1084 Loss_G: 0.0412 Convergence: 0.1119 k= 0.023848 lr = 0.0000277\n",
      "[7/25][7980/9765] Loss_D: 0.0944 Loss_G: 0.0384 Convergence: 0.0956 k= 0.023870 lr = 0.0000277\n",
      "[7/25][7990/9765] Loss_D: 0.0941 Loss_G: 0.0389 Convergence: 0.0960 k= 0.023878 lr = 0.0000277\n",
      "[7/25][8000/9765] Loss_D: 0.0927 Loss_G: 0.0419 Convergence: 0.0982 k= 0.023860 lr = 0.0000277\n",
      "[7/25][8010/9765] Loss_D: 0.1062 Loss_G: 0.0374 Convergence: 0.1124 k= 0.023864 lr = 0.0000277\n",
      "[7/25][8020/9765] Loss_D: 0.1017 Loss_G: 0.0400 Convergence: 0.1037 k= 0.023870 lr = 0.0000277\n",
      "[7/25][8030/9765] Loss_D: 0.1024 Loss_G: 0.0436 Convergence: 0.1057 k= 0.023861 lr = 0.0000277\n",
      "[7/25][8040/9765] Loss_D: 0.0948 Loss_G: 0.0395 Convergence: 0.0970 k= 0.023871 lr = 0.0000277\n",
      "[7/25][8050/9765] Loss_D: 0.0985 Loss_G: 0.0391 Convergence: 0.1002 k= 0.023874 lr = 0.0000277\n",
      "[7/25][8060/9765] Loss_D: 0.1079 Loss_G: 0.0452 Convergence: 0.1106 k= 0.023859 lr = 0.0000277\n",
      "[7/25][8070/9765] Loss_D: 0.0998 Loss_G: 0.0375 Convergence: 0.1036 k= 0.023858 lr = 0.0000277\n",
      "[7/25][8080/9765] Loss_D: 0.1042 Loss_G: 0.0405 Convergence: 0.1067 k= 0.023858 lr = 0.0000277\n",
      "[7/25][8090/9765] Loss_D: 0.0957 Loss_G: 0.0412 Convergence: 0.0993 k= 0.023852 lr = 0.0000277\n",
      "[7/25][8100/9765] Loss_D: 0.1031 Loss_G: 0.0394 Convergence: 0.1063 k= 0.023846 lr = 0.0000277\n",
      "[7/25][8110/9765] Loss_D: 0.0982 Loss_G: 0.0379 Convergence: 0.1009 k= 0.023843 lr = 0.0000277\n",
      "[7/25][8120/9765] Loss_D: 0.1076 Loss_G: 0.0415 Convergence: 0.1103 k= 0.023847 lr = 0.0000277\n",
      "[7/25][8130/9765] Loss_D: 0.0984 Loss_G: 0.0415 Convergence: 0.1012 k= 0.023841 lr = 0.0000277\n",
      "[7/25][8140/9765] Loss_D: 0.0987 Loss_G: 0.0430 Convergence: 0.1028 k= 0.023835 lr = 0.0000277\n",
      "[7/25][8150/9765] Loss_D: 0.0979 Loss_G: 0.0417 Convergence: 0.1011 k= 0.023821 lr = 0.0000277\n",
      "[7/25][8160/9765] Loss_D: 0.1054 Loss_G: 0.0402 Convergence: 0.1087 k= 0.023802 lr = 0.0000277\n",
      "[7/25][8170/9765] Loss_D: 0.0949 Loss_G: 0.0403 Convergence: 0.0978 k= 0.023793 lr = 0.0000277\n",
      "[7/25][8180/9765] Loss_D: 0.1000 Loss_G: 0.0414 Convergence: 0.1019 k= 0.023799 lr = 0.0000277\n",
      "[7/25][8190/9765] Loss_D: 0.1074 Loss_G: 0.0457 Convergence: 0.1108 k= 0.023800 lr = 0.0000277\n",
      "[7/25][8200/9765] Loss_D: 0.0970 Loss_G: 0.0362 Convergence: 0.1008 k= 0.023824 lr = 0.0000277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][8210/9765] Loss_D: 0.1072 Loss_G: 0.0434 Convergence: 0.1083 k= 0.023851 lr = 0.0000277\n",
      "[7/25][8220/9765] Loss_D: 0.1011 Loss_G: 0.0416 Convergence: 0.1029 k= 0.023833 lr = 0.0000277\n",
      "[7/25][8230/9765] Loss_D: 0.1022 Loss_G: 0.0425 Convergence: 0.1044 k= 0.023810 lr = 0.0000277\n",
      "[7/25][8240/9765] Loss_D: 0.0962 Loss_G: 0.0414 Convergence: 0.0997 k= 0.023806 lr = 0.0000277\n",
      "[7/25][8250/9765] Loss_D: 0.0942 Loss_G: 0.0410 Convergence: 0.0981 k= 0.023801 lr = 0.0000277\n",
      "[7/25][8260/9765] Loss_D: 0.1000 Loss_G: 0.0412 Convergence: 0.1018 k= 0.023794 lr = 0.0000277\n",
      "[7/25][8270/9765] Loss_D: 0.0999 Loss_G: 0.0406 Convergence: 0.1012 k= 0.023768 lr = 0.0000277\n",
      "[7/25][8280/9765] Loss_D: 0.0969 Loss_G: 0.0381 Convergence: 0.0987 k= 0.023783 lr = 0.0000277\n",
      "[7/25][8290/9765] Loss_D: 0.1040 Loss_G: 0.0378 Convergence: 0.1090 k= 0.023779 lr = 0.0000277\n",
      "[7/25][8300/9765] Loss_D: 0.1163 Loss_G: 0.0360 Convergence: 0.1280 k= 0.023838 lr = 0.0000277\n",
      "[7/25][8310/9765] Loss_D: 0.1026 Loss_G: 0.0412 Convergence: 0.1038 k= 0.023850 lr = 0.0000277\n",
      "[7/25][8320/9765] Loss_D: 0.0953 Loss_G: 0.0405 Convergence: 0.0983 k= 0.023846 lr = 0.0000277\n",
      "[7/25][8330/9765] Loss_D: 0.1037 Loss_G: 0.0473 Convergence: 0.1101 k= 0.023840 lr = 0.0000277\n",
      "[7/25][8340/9765] Loss_D: 0.1000 Loss_G: 0.0397 Convergence: 0.1015 k= 0.023830 lr = 0.0000277\n",
      "[7/25][8350/9765] Loss_D: 0.0920 Loss_G: 0.0422 Convergence: 0.0980 k= 0.023827 lr = 0.0000277\n",
      "[7/25][8360/9765] Loss_D: 0.1004 Loss_G: 0.0438 Convergence: 0.1047 k= 0.023831 lr = 0.0000277\n",
      "[7/25][8370/9765] Loss_D: 0.0946 Loss_G: 0.0397 Convergence: 0.0971 k= 0.023804 lr = 0.0000277\n",
      "[7/25][8380/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0988 k= 0.023795 lr = 0.0000277\n",
      "[7/25][8390/9765] Loss_D: 0.0954 Loss_G: 0.0368 Convergence: 0.0981 k= 0.023796 lr = 0.0000277\n",
      "[7/25][8400/9765] Loss_D: 0.0908 Loss_G: 0.0388 Convergence: 0.0938 k= 0.023816 lr = 0.0000277\n",
      "[7/25][8410/9765] Loss_D: 0.1021 Loss_G: 0.0438 Convergence: 0.1057 k= 0.023819 lr = 0.0000277\n",
      "[7/25][8420/9765] Loss_D: 0.1041 Loss_G: 0.0418 Convergence: 0.1052 k= 0.023799 lr = 0.0000277\n",
      "[7/25][8430/9765] Loss_D: 0.1005 Loss_G: 0.0420 Convergence: 0.1029 k= 0.023790 lr = 0.0000277\n",
      "[7/25][8440/9765] Loss_D: 0.1056 Loss_G: 0.0406 Convergence: 0.1085 k= 0.023798 lr = 0.0000277\n",
      "[7/25][8450/9765] Loss_D: 0.0930 Loss_G: 0.0389 Convergence: 0.0953 k= 0.023808 lr = 0.0000277\n",
      "[7/25][8460/9765] Loss_D: 0.1043 Loss_G: 0.0461 Convergence: 0.1092 k= 0.023802 lr = 0.0000277\n",
      "[7/25][8470/9765] Loss_D: 0.1082 Loss_G: 0.0402 Convergence: 0.1126 k= 0.023787 lr = 0.0000277\n",
      "[7/25][8480/9765] Loss_D: 0.0980 Loss_G: 0.0428 Convergence: 0.1023 k= 0.023763 lr = 0.0000277\n",
      "[7/25][8490/9765] Loss_D: 0.1011 Loss_G: 0.0403 Convergence: 0.1026 k= 0.023763 lr = 0.0000277\n",
      "[7/25][8500/9765] Loss_D: 0.1043 Loss_G: 0.0394 Convergence: 0.1079 k= 0.023788 lr = 0.0000277\n",
      "[7/25][8510/9765] Loss_D: 0.0918 Loss_G: 0.0396 Convergence: 0.0953 k= 0.023781 lr = 0.0000277\n",
      "[7/25][8520/9765] Loss_D: 0.0999 Loss_G: 0.0374 Convergence: 0.1038 k= 0.023785 lr = 0.0000277\n",
      "[7/25][8530/9765] Loss_D: 0.1151 Loss_G: 0.0390 Convergence: 0.1234 k= 0.023801 lr = 0.0000277\n",
      "[7/25][8540/9765] Loss_D: 0.1031 Loss_G: 0.0421 Convergence: 0.1046 k= 0.023818 lr = 0.0000277\n",
      "[7/25][8550/9765] Loss_D: 0.0939 Loss_G: 0.0431 Convergence: 0.1001 k= 0.023790 lr = 0.0000277\n",
      "[7/25][8560/9765] Loss_D: 0.1167 Loss_G: 0.0399 Convergence: 0.1248 k= 0.023773 lr = 0.0000277\n",
      "[7/25][8570/9765] Loss_D: 0.1047 Loss_G: 0.0430 Convergence: 0.1064 k= 0.023777 lr = 0.0000277\n",
      "[7/25][8580/9765] Loss_D: 0.0965 Loss_G: 0.0387 Convergence: 0.0978 k= 0.023785 lr = 0.0000277\n",
      "[7/25][8590/9765] Loss_D: 0.1074 Loss_G: 0.0452 Convergence: 0.1102 k= 0.023768 lr = 0.0000277\n",
      "[7/25][8600/9765] Loss_D: 0.0957 Loss_G: 0.0377 Convergence: 0.0975 k= 0.023740 lr = 0.0000277\n",
      "[7/25][8610/9765] Loss_D: 0.0917 Loss_G: 0.0409 Convergence: 0.0965 k= 0.023745 lr = 0.0000277\n",
      "[7/25][8620/9765] Loss_D: 0.1072 Loss_G: 0.0407 Convergence: 0.1107 k= 0.023744 lr = 0.0000277\n",
      "[7/25][8630/9765] Loss_D: 0.0995 Loss_G: 0.0389 Convergence: 0.1017 k= 0.023733 lr = 0.0000277\n",
      "[7/25][8640/9765] Loss_D: 0.1034 Loss_G: 0.0442 Convergence: 0.1068 k= 0.023737 lr = 0.0000277\n",
      "[7/25][8650/9765] Loss_D: 0.1034 Loss_G: 0.0414 Convergence: 0.1046 k= 0.023733 lr = 0.0000277\n",
      "[7/25][8660/9765] Loss_D: 0.0947 Loss_G: 0.0368 Convergence: 0.0970 k= 0.023728 lr = 0.0000277\n",
      "[7/25][8670/9765] Loss_D: 0.1031 Loss_G: 0.0379 Convergence: 0.1079 k= 0.023755 lr = 0.0000277\n",
      "[7/25][8680/9765] Loss_D: 0.1019 Loss_G: 0.0417 Convergence: 0.1035 k= 0.023731 lr = 0.0000277\n",
      "[7/25][8690/9765] Loss_D: 0.0981 Loss_G: 0.0421 Convergence: 0.1016 k= 0.023699 lr = 0.0000277\n",
      "[7/25][8700/9765] Loss_D: 0.0934 Loss_G: 0.0396 Convergence: 0.0962 k= 0.023704 lr = 0.0000277\n",
      "[7/25][8710/9765] Loss_D: 0.1103 Loss_G: 0.0436 Convergence: 0.1121 k= 0.023733 lr = 0.0000277\n",
      "[7/25][8720/9765] Loss_D: 0.1103 Loss_G: 0.0396 Convergence: 0.1163 k= 0.023719 lr = 0.0000277\n",
      "[7/25][8730/9765] Loss_D: 0.0925 Loss_G: 0.0407 Convergence: 0.0968 k= 0.023700 lr = 0.0000277\n",
      "[7/25][8740/9765] Loss_D: 0.1091 Loss_G: 0.0377 Convergence: 0.1163 k= 0.023707 lr = 0.0000277\n",
      "[7/25][8750/9765] Loss_D: 0.1025 Loss_G: 0.0431 Convergence: 0.1052 k= 0.023719 lr = 0.0000277\n",
      "[7/25][8760/9765] Loss_D: 0.0976 Loss_G: 0.0438 Convergence: 0.1030 k= 0.023689 lr = 0.0000277\n",
      "[7/25][8770/9765] Loss_D: 0.1017 Loss_G: 0.0409 Convergence: 0.1028 k= 0.023660 lr = 0.0000277\n",
      "[7/25][8780/9765] Loss_D: 0.1017 Loss_G: 0.0379 Convergence: 0.1057 k= 0.023655 lr = 0.0000277\n",
      "[7/25][8790/9765] Loss_D: 0.1022 Loss_G: 0.0428 Convergence: 0.1047 k= 0.023655 lr = 0.0000277\n",
      "[7/25][8800/9765] Loss_D: 0.0925 Loss_G: 0.0404 Convergence: 0.0965 k= 0.023625 lr = 0.0000277\n",
      "[7/25][8810/9765] Loss_D: 0.0934 Loss_G: 0.0395 Convergence: 0.0962 k= 0.023634 lr = 0.0000277\n",
      "[7/25][8820/9765] Loss_D: 0.1087 Loss_G: 0.0381 Convergence: 0.1154 k= 0.023645 lr = 0.0000277\n",
      "[7/25][8830/9765] Loss_D: 0.1043 Loss_G: 0.0391 Convergence: 0.1084 k= 0.023652 lr = 0.0000277\n",
      "[7/25][8840/9765] Loss_D: 0.1018 Loss_G: 0.0393 Convergence: 0.1044 k= 0.023675 lr = 0.0000277\n",
      "[7/25][8850/9765] Loss_D: 0.1069 Loss_G: 0.0441 Convergence: 0.1088 k= 0.023668 lr = 0.0000277\n",
      "[7/25][8860/9765] Loss_D: 0.1036 Loss_G: 0.0417 Convergence: 0.1048 k= 0.023658 lr = 0.0000277\n",
      "[7/25][8870/9765] Loss_D: 0.0987 Loss_G: 0.0383 Convergence: 0.1011 k= 0.023670 lr = 0.0000277\n",
      "[7/25][8880/9765] Loss_D: 0.1002 Loss_G: 0.0422 Convergence: 0.1030 k= 0.023679 lr = 0.0000277\n",
      "[7/25][8890/9765] Loss_D: 0.1000 Loss_G: 0.0426 Convergence: 0.1032 k= 0.023679 lr = 0.0000277\n",
      "[7/25][8900/9765] Loss_D: 0.0987 Loss_G: 0.0416 Convergence: 0.1013 k= 0.023681 lr = 0.0000277\n",
      "[7/25][8910/9765] Loss_D: 0.1097 Loss_G: 0.0398 Convergence: 0.1151 k= 0.023685 lr = 0.0000277\n",
      "[7/25][8920/9765] Loss_D: 0.0907 Loss_G: 0.0389 Convergence: 0.0939 k= 0.023661 lr = 0.0000277\n",
      "[7/25][8930/9765] Loss_D: 0.1022 Loss_G: 0.0414 Convergence: 0.1034 k= 0.023667 lr = 0.0000277\n",
      "[7/25][8940/9765] Loss_D: 0.1156 Loss_G: 0.0440 Convergence: 0.1192 k= 0.023655 lr = 0.0000277\n",
      "[7/25][8950/9765] Loss_D: 0.0907 Loss_G: 0.0424 Convergence: 0.0974 k= 0.023635 lr = 0.0000277\n",
      "[7/25][8960/9765] Loss_D: 0.0975 Loss_G: 0.0406 Convergence: 0.0997 k= 0.023639 lr = 0.0000277\n",
      "[7/25][8970/9765] Loss_D: 0.1105 Loss_G: 0.0377 Convergence: 0.1182 k= 0.023665 lr = 0.0000277\n",
      "[7/25][8980/9765] Loss_D: 0.1008 Loss_G: 0.0422 Convergence: 0.1033 k= 0.023641 lr = 0.0000277\n",
      "[7/25][8990/9765] Loss_D: 0.1020 Loss_G: 0.0440 Convergence: 0.1058 k= 0.023600 lr = 0.0000277\n",
      "[7/25][9000/9765] Loss_D: 0.0974 Loss_G: 0.0378 Convergence: 0.0998 k= 0.023589 lr = 0.0000277\n",
      "[7/25][9010/9765] Loss_D: 0.0980 Loss_G: 0.0368 Convergence: 0.1015 k= 0.023613 lr = 0.0000277\n",
      "[7/25][9020/9765] Loss_D: 0.0905 Loss_G: 0.0433 Convergence: 0.0982 k= 0.023624 lr = 0.0000277\n",
      "[7/25][9030/9765] Loss_D: 0.1072 Loss_G: 0.0569 Convergence: 0.1220 k= 0.023518 lr = 0.0000277\n",
      "[7/25][9040/9765] Loss_D: 0.1028 Loss_G: 0.0442 Convergence: 0.1065 k= 0.023414 lr = 0.0000277\n",
      "[7/25][9050/9765] Loss_D: 0.0961 Loss_G: 0.0366 Convergence: 0.0991 k= 0.023446 lr = 0.0000277\n",
      "[7/25][9060/9765] Loss_D: 0.1025 Loss_G: 0.0376 Convergence: 0.1070 k= 0.023485 lr = 0.0000277\n",
      "[7/25][9070/9765] Loss_D: 0.0917 Loss_G: 0.0363 Convergence: 0.0934 k= 0.023495 lr = 0.0000277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/25][9080/9765] Loss_D: 0.0990 Loss_G: 0.0436 Convergence: 0.1036 k= 0.023507 lr = 0.0000277\n",
      "[7/25][9090/9765] Loss_D: 0.0929 Loss_G: 0.0374 Convergence: 0.0940 k= 0.023488 lr = 0.0000277\n",
      "[7/25][9100/9765] Loss_D: 0.0913 Loss_G: 0.0389 Convergence: 0.0942 k= 0.023489 lr = 0.0000277\n",
      "[7/25][9110/9765] Loss_D: 0.1042 Loss_G: 0.0447 Convergence: 0.1078 k= 0.023482 lr = 0.0000277\n",
      "[7/25][9120/9765] Loss_D: 0.0987 Loss_G: 0.0459 Convergence: 0.1058 k= 0.023462 lr = 0.0000277\n",
      "[7/25][9130/9765] Loss_D: 0.0937 Loss_G: 0.0396 Convergence: 0.0963 k= 0.023454 lr = 0.0000277\n",
      "[7/25][9140/9765] Loss_D: 0.0958 Loss_G: 0.0372 Convergence: 0.0982 k= 0.023458 lr = 0.0000277\n",
      "[7/25][9150/9765] Loss_D: 0.1089 Loss_G: 0.0389 Convergence: 0.1148 k= 0.023468 lr = 0.0000277\n",
      "[7/25][9160/9765] Loss_D: 0.0963 Loss_G: 0.0404 Convergence: 0.0987 k= 0.023483 lr = 0.0000277\n",
      "[7/25][9170/9765] Loss_D: 0.1039 Loss_G: 0.0397 Convergence: 0.1070 k= 0.023495 lr = 0.0000277\n",
      "[7/25][9180/9765] Loss_D: 0.0950 Loss_G: 0.0444 Convergence: 0.1020 k= 0.023478 lr = 0.0000277\n",
      "[7/25][9190/9765] Loss_D: 0.0996 Loss_G: 0.0394 Convergence: 0.1013 k= 0.023489 lr = 0.0000277\n",
      "[7/25][9200/9765] Loss_D: 0.1011 Loss_G: 0.0388 Convergence: 0.1041 k= 0.023501 lr = 0.0000277\n",
      "[7/25][9210/9765] Loss_D: 0.0965 Loss_G: 0.0399 Convergence: 0.0984 k= 0.023497 lr = 0.0000277\n",
      "[7/25][9220/9765] Loss_D: 0.0970 Loss_G: 0.0406 Convergence: 0.0994 k= 0.023491 lr = 0.0000277\n",
      "[7/25][9230/9765] Loss_D: 0.1036 Loss_G: 0.0398 Convergence: 0.1065 k= 0.023501 lr = 0.0000277\n",
      "[7/25][9240/9765] Loss_D: 0.0985 Loss_G: 0.0385 Convergence: 0.1009 k= 0.023495 lr = 0.0000277\n",
      "[7/25][9250/9765] Loss_D: 0.0886 Loss_G: 0.0413 Convergence: 0.0950 k= 0.023477 lr = 0.0000277\n",
      "[7/25][9260/9765] Loss_D: 0.1059 Loss_G: 0.0389 Convergence: 0.1107 k= 0.023488 lr = 0.0000277\n",
      "[7/25][9270/9765] Loss_D: 0.1038 Loss_G: 0.0408 Convergence: 0.1059 k= 0.023479 lr = 0.0000277\n",
      "[7/25][9280/9765] Loss_D: 0.1054 Loss_G: 0.0366 Convergence: 0.1122 k= 0.023479 lr = 0.0000277\n",
      "[7/25][9290/9765] Loss_D: 0.1042 Loss_G: 0.0405 Convergence: 0.1066 k= 0.023479 lr = 0.0000277\n",
      "[7/25][9300/9765] Loss_D: 0.1029 Loss_G: 0.0434 Convergence: 0.1058 k= 0.023473 lr = 0.0000277\n",
      "[7/25][9310/9765] Loss_D: 0.0970 Loss_G: 0.0388 Convergence: 0.0983 k= 0.023470 lr = 0.0000277\n",
      "[7/25][9320/9765] Loss_D: 0.0949 Loss_G: 0.0389 Convergence: 0.0964 k= 0.023471 lr = 0.0000277\n",
      "[7/25][9330/9765] Loss_D: 0.1079 Loss_G: 0.0359 Convergence: 0.1165 k= 0.023473 lr = 0.0000277\n",
      "[7/25][9340/9765] Loss_D: 0.1073 Loss_G: 0.0419 Convergence: 0.1096 k= 0.023480 lr = 0.0000277\n",
      "[7/25][9350/9765] Loss_D: 0.1076 Loss_G: 0.0358 Convergence: 0.1159 k= 0.023510 lr = 0.0000277\n",
      "[7/25][9360/9765] Loss_D: 0.1117 Loss_G: 0.0383 Convergence: 0.1193 k= 0.023538 lr = 0.0000277\n",
      "[7/25][9370/9765] Loss_D: 0.0995 Loss_G: 0.0405 Convergence: 0.1007 k= 0.023546 lr = 0.0000277\n",
      "[7/25][9380/9765] Loss_D: 0.1040 Loss_G: 0.0428 Convergence: 0.1058 k= 0.023539 lr = 0.0000277\n",
      "[7/25][9390/9765] Loss_D: 0.1080 Loss_G: 0.0406 Convergence: 0.1120 k= 0.023538 lr = 0.0000277\n",
      "[7/25][9400/9765] Loss_D: 0.1016 Loss_G: 0.0429 Convergence: 0.1045 k= 0.023534 lr = 0.0000277\n",
      "[7/25][9410/9765] Loss_D: 0.0973 Loss_G: 0.0388 Convergence: 0.0987 k= 0.023531 lr = 0.0000277\n",
      "[7/25][9420/9765] Loss_D: 0.0996 Loss_G: 0.0421 Convergence: 0.1025 k= 0.023523 lr = 0.0000277\n",
      "[7/25][9430/9765] Loss_D: 0.0988 Loss_G: 0.0412 Convergence: 0.1011 k= 0.023509 lr = 0.0000277\n",
      "[7/25][9440/9765] Loss_D: 0.0915 Loss_G: 0.0380 Convergence: 0.0934 k= 0.023515 lr = 0.0000277\n",
      "[7/25][9450/9765] Loss_D: 0.0966 Loss_G: 0.0383 Convergence: 0.0981 k= 0.023525 lr = 0.0000277\n",
      "[7/25][9460/9765] Loss_D: 0.1090 Loss_G: 0.0380 Convergence: 0.1159 k= 0.023529 lr = 0.0000277\n",
      "[7/25][9470/9765] Loss_D: 0.1029 Loss_G: 0.0417 Convergence: 0.1040 k= 0.023527 lr = 0.0000277\n",
      "[7/25][9480/9765] Loss_D: 0.1142 Loss_G: 0.0430 Convergence: 0.1183 k= 0.023523 lr = 0.0000277\n",
      "[7/25][9490/9765] Loss_D: 0.0983 Loss_G: 0.0418 Convergence: 0.1013 k= 0.023514 lr = 0.0000277\n",
      "[7/25][9500/9765] Loss_D: 0.0997 Loss_G: 0.0363 Convergence: 0.1045 k= 0.023516 lr = 0.0000277\n",
      "[7/25][9510/9765] Loss_D: 0.1062 Loss_G: 0.0410 Convergence: 0.1090 k= 0.023517 lr = 0.0000277\n",
      "[7/25][9520/9765] Loss_D: 0.1014 Loss_G: 0.0417 Convergence: 0.1032 k= 0.023485 lr = 0.0000277\n",
      "[7/25][9530/9765] Loss_D: 0.0917 Loss_G: 0.0408 Convergence: 0.0964 k= 0.023476 lr = 0.0000277\n",
      "[7/25][9540/9765] Loss_D: 0.1047 Loss_G: 0.0402 Convergence: 0.1077 k= 0.023477 lr = 0.0000277\n",
      "[7/25][9550/9765] Loss_D: 0.1009 Loss_G: 0.0419 Convergence: 0.1030 k= 0.023462 lr = 0.0000277\n",
      "[7/25][9560/9765] Loss_D: 0.0942 Loss_G: 0.0398 Convergence: 0.0970 k= 0.023440 lr = 0.0000277\n",
      "[7/25][9570/9765] Loss_D: 0.0914 Loss_G: 0.0407 Convergence: 0.0961 k= 0.023435 lr = 0.0000277\n",
      "[7/25][9580/9765] Loss_D: 0.0903 Loss_G: 0.0398 Convergence: 0.0946 k= 0.023444 lr = 0.0000277\n",
      "[7/25][9590/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1034 k= 0.023454 lr = 0.0000277\n",
      "[7/25][9600/9765] Loss_D: 0.1008 Loss_G: 0.0399 Convergence: 0.1026 k= 0.023457 lr = 0.0000277\n",
      "[7/25][9610/9765] Loss_D: 0.0957 Loss_G: 0.0399 Convergence: 0.0979 k= 0.023458 lr = 0.0000277\n",
      "[7/25][9620/9765] Loss_D: 0.1047 Loss_G: 0.0454 Convergence: 0.1089 k= 0.023423 lr = 0.0000277\n",
      "[7/25][9630/9765] Loss_D: 0.0966 Loss_G: 0.0399 Convergence: 0.0985 k= 0.023431 lr = 0.0000277\n",
      "[7/25][9640/9765] Loss_D: 0.1007 Loss_G: 0.0400 Convergence: 0.1024 k= 0.023426 lr = 0.0000277\n",
      "[7/25][9650/9765] Loss_D: 0.0982 Loss_G: 0.0394 Convergence: 0.0993 k= 0.023433 lr = 0.0000264\n",
      "[7/25][9660/9765] Loss_D: 0.1014 Loss_G: 0.0422 Convergence: 0.1037 k= 0.023427 lr = 0.0000264\n",
      "[7/25][9670/9765] Loss_D: 0.0966 Loss_G: 0.0365 Convergence: 0.0999 k= 0.023437 lr = 0.0000264\n",
      "[7/25][9680/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0947 k= 0.023424 lr = 0.0000264\n",
      "[7/25][9690/9765] Loss_D: 0.1000 Loss_G: 0.0468 Convergence: 0.1074 k= 0.023385 lr = 0.0000264\n",
      "[7/25][9700/9765] Loss_D: 0.0928 Loss_G: 0.0408 Convergence: 0.0971 k= 0.023370 lr = 0.0000264\n",
      "[7/25][9710/9765] Loss_D: 0.1072 Loss_G: 0.0445 Convergence: 0.1094 k= 0.023366 lr = 0.0000264\n",
      "[7/25][9720/9765] Loss_D: 0.0938 Loss_G: 0.0413 Convergence: 0.0981 k= 0.023360 lr = 0.0000264\n",
      "[7/25][9730/9765] Loss_D: 0.0953 Loss_G: 0.0425 Convergence: 0.1003 k= 0.023354 lr = 0.0000264\n",
      "[7/25][9740/9765] Loss_D: 0.0913 Loss_G: 0.0407 Convergence: 0.0961 k= 0.023347 lr = 0.0000264\n",
      "[7/25][9750/9765] Loss_D: 0.1003 Loss_G: 0.0371 Convergence: 0.1045 k= 0.023334 lr = 0.0000264\n",
      "[7/25][9760/9765] Loss_D: 0.0991 Loss_G: 0.0339 Convergence: 0.1060 k= 0.023373 lr = 0.0000264\n",
      "[8/25][0/9765] Loss_D: 0.1113 Loss_G: 0.0374 Convergence: 0.1196 k= 0.023397 lr = 0.0000264\n",
      "[8/25][10/9765] Loss_D: 0.1012 Loss_G: 0.0436 Convergence: 0.1049 k= 0.023355 lr = 0.0000264\n",
      "[8/25][20/9765] Loss_D: 0.0989 Loss_G: 0.0450 Convergence: 0.1050 k= 0.023340 lr = 0.0000264\n",
      "[8/25][30/9765] Loss_D: 0.0977 Loss_G: 0.0399 Convergence: 0.0991 k= 0.023314 lr = 0.0000264\n",
      "[8/25][40/9765] Loss_D: 0.1093 Loss_G: 0.0427 Convergence: 0.1117 k= 0.023317 lr = 0.0000264\n",
      "[8/25][50/9765] Loss_D: 0.1055 Loss_G: 0.0417 Convergence: 0.1073 k= 0.023320 lr = 0.0000264\n",
      "[8/25][60/9765] Loss_D: 0.1020 Loss_G: 0.0412 Convergence: 0.1030 k= 0.023345 lr = 0.0000264\n",
      "[8/25][70/9765] Loss_D: 0.0960 Loss_G: 0.0430 Convergence: 0.1012 k= 0.023333 lr = 0.0000264\n",
      "[8/25][80/9765] Loss_D: 0.1052 Loss_G: 0.0380 Convergence: 0.1105 k= 0.023339 lr = 0.0000264\n",
      "[8/25][90/9765] Loss_D: 0.1013 Loss_G: 0.0385 Convergence: 0.1047 k= 0.023354 lr = 0.0000264\n",
      "[8/25][100/9765] Loss_D: 0.0992 Loss_G: 0.0410 Convergence: 0.1010 k= 0.023357 lr = 0.0000264\n",
      "[8/25][110/9765] Loss_D: 0.1040 Loss_G: 0.0426 Convergence: 0.1056 k= 0.023351 lr = 0.0000264\n",
      "[8/25][120/9765] Loss_D: 0.1038 Loss_G: 0.0428 Convergence: 0.1056 k= 0.023340 lr = 0.0000264\n",
      "[8/25][130/9765] Loss_D: 0.0955 Loss_G: 0.0411 Convergence: 0.0990 k= 0.023315 lr = 0.0000264\n",
      "[8/25][140/9765] Loss_D: 0.0961 Loss_G: 0.0371 Convergence: 0.0988 k= 0.023314 lr = 0.0000264\n",
      "[8/25][150/9765] Loss_D: 0.1068 Loss_G: 0.0377 Convergence: 0.1131 k= 0.023341 lr = 0.0000264\n",
      "[8/25][160/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0952 k= 0.023332 lr = 0.0000264\n",
      "[8/25][170/9765] Loss_D: 0.1001 Loss_G: 0.0401 Convergence: 0.1013 k= 0.023333 lr = 0.0000264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][180/9765] Loss_D: 0.1004 Loss_G: 0.0397 Convergence: 0.1022 k= 0.023328 lr = 0.0000264\n",
      "[8/25][190/9765] Loss_D: 0.1050 Loss_G: 0.0385 Convergence: 0.1097 k= 0.023357 lr = 0.0000264\n",
      "[8/25][200/9765] Loss_D: 0.0946 Loss_G: 0.0406 Convergence: 0.0980 k= 0.023353 lr = 0.0000264\n",
      "[8/25][210/9765] Loss_D: 0.1023 Loss_G: 0.0384 Convergence: 0.1060 k= 0.023358 lr = 0.0000264\n",
      "[8/25][220/9765] Loss_D: 0.1012 Loss_G: 0.0380 Convergence: 0.1050 k= 0.023350 lr = 0.0000264\n",
      "[8/25][230/9765] Loss_D: 0.1077 Loss_G: 0.0412 Convergence: 0.1108 k= 0.023348 lr = 0.0000264\n",
      "[8/25][240/9765] Loss_D: 0.0903 Loss_G: 0.0359 Convergence: 0.0918 k= 0.023370 lr = 0.0000264\n",
      "[8/25][250/9765] Loss_D: 0.0967 Loss_G: 0.0404 Convergence: 0.0990 k= 0.023383 lr = 0.0000264\n",
      "[8/25][260/9765] Loss_D: 0.1026 Loss_G: 0.0440 Convergence: 0.1062 k= 0.023352 lr = 0.0000264\n",
      "[8/25][270/9765] Loss_D: 0.0996 Loss_G: 0.0384 Convergence: 0.1022 k= 0.023341 lr = 0.0000264\n",
      "[8/25][280/9765] Loss_D: 0.1096 Loss_G: 0.0391 Convergence: 0.1156 k= 0.023346 lr = 0.0000264\n",
      "[8/25][290/9765] Loss_D: 0.1075 Loss_G: 0.0412 Convergence: 0.1107 k= 0.023352 lr = 0.0000264\n",
      "[8/25][300/9765] Loss_D: 0.1012 Loss_G: 0.0401 Convergence: 0.1029 k= 0.023342 lr = 0.0000264\n",
      "[8/25][310/9765] Loss_D: 0.0997 Loss_G: 0.0399 Convergence: 0.1010 k= 0.023336 lr = 0.0000264\n",
      "[8/25][320/9765] Loss_D: 0.0944 Loss_G: 0.0379 Convergence: 0.0956 k= 0.023327 lr = 0.0000264\n",
      "[8/25][330/9765] Loss_D: 0.1006 Loss_G: 0.0375 Convergence: 0.1046 k= 0.023345 lr = 0.0000264\n",
      "[8/25][340/9765] Loss_D: 0.1036 Loss_G: 0.0400 Convergence: 0.1064 k= 0.023366 lr = 0.0000264\n",
      "[8/25][350/9765] Loss_D: 0.1070 Loss_G: 0.0419 Convergence: 0.1093 k= 0.023367 lr = 0.0000264\n",
      "[8/25][360/9765] Loss_D: 0.1034 Loss_G: 0.0383 Convergence: 0.1077 k= 0.023351 lr = 0.0000264\n",
      "[8/25][370/9765] Loss_D: 0.0964 Loss_G: 0.0428 Convergence: 0.1013 k= 0.023333 lr = 0.0000264\n",
      "[8/25][380/9765] Loss_D: 0.1013 Loss_G: 0.0406 Convergence: 0.1025 k= 0.023324 lr = 0.0000264\n",
      "[8/25][390/9765] Loss_D: 0.1055 Loss_G: 0.0379 Convergence: 0.1110 k= 0.023334 lr = 0.0000264\n",
      "[8/25][400/9765] Loss_D: 0.1055 Loss_G: 0.0401 Convergence: 0.1089 k= 0.023349 lr = 0.0000264\n",
      "[8/25][410/9765] Loss_D: 0.1067 Loss_G: 0.0388 Convergence: 0.1118 k= 0.023361 lr = 0.0000264\n",
      "[8/25][420/9765] Loss_D: 0.0980 Loss_G: 0.0447 Convergence: 0.1041 k= 0.023348 lr = 0.0000264\n",
      "[8/25][430/9765] Loss_D: 0.0975 Loss_G: 0.0457 Convergence: 0.1048 k= 0.023332 lr = 0.0000264\n",
      "[8/25][440/9765] Loss_D: 0.0968 Loss_G: 0.0351 Convergence: 0.1016 k= 0.023361 lr = 0.0000264\n",
      "[8/25][450/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0975 k= 0.023383 lr = 0.0000264\n",
      "[8/25][460/9765] Loss_D: 0.0971 Loss_G: 0.0375 Convergence: 0.0996 k= 0.023404 lr = 0.0000264\n",
      "[8/25][470/9765] Loss_D: 0.0951 Loss_G: 0.0488 Convergence: 0.1064 k= 0.023389 lr = 0.0000264\n",
      "[8/25][480/9765] Loss_D: 0.1010 Loss_G: 0.0451 Convergence: 0.1063 k= 0.023320 lr = 0.0000264\n",
      "[8/25][490/9765] Loss_D: 0.1069 Loss_G: 0.0397 Convergence: 0.1113 k= 0.023275 lr = 0.0000264\n",
      "[8/25][500/9765] Loss_D: 0.1056 Loss_G: 0.0370 Convergence: 0.1119 k= 0.023282 lr = 0.0000264\n",
      "[8/25][510/9765] Loss_D: 0.1078 Loss_G: 0.0399 Convergence: 0.1122 k= 0.023297 lr = 0.0000264\n",
      "[8/25][520/9765] Loss_D: 0.0965 Loss_G: 0.0374 Convergence: 0.0989 k= 0.023283 lr = 0.0000264\n",
      "[8/25][530/9765] Loss_D: 0.1009 Loss_G: 0.0416 Convergence: 0.1027 k= 0.023305 lr = 0.0000264\n",
      "[8/25][540/9765] Loss_D: 0.0990 Loss_G: 0.0446 Convergence: 0.1046 k= 0.023285 lr = 0.0000264\n",
      "[8/25][550/9765] Loss_D: 0.0932 Loss_G: 0.0387 Convergence: 0.0952 k= 0.023286 lr = 0.0000264\n",
      "[8/25][560/9765] Loss_D: 0.0974 Loss_G: 0.0411 Convergence: 0.1001 k= 0.023264 lr = 0.0000264\n",
      "[8/25][570/9765] Loss_D: 0.1031 Loss_G: 0.0401 Convergence: 0.1056 k= 0.023274 lr = 0.0000264\n",
      "[8/25][580/9765] Loss_D: 0.1119 Loss_G: 0.0414 Convergence: 0.1166 k= 0.023275 lr = 0.0000264\n",
      "[8/25][590/9765] Loss_D: 0.0999 Loss_G: 0.0443 Convergence: 0.1048 k= 0.023256 lr = 0.0000264\n",
      "[8/25][600/9765] Loss_D: 0.0956 Loss_G: 0.0396 Convergence: 0.0975 k= 0.023220 lr = 0.0000264\n",
      "[8/25][610/9765] Loss_D: 0.0951 Loss_G: 0.0391 Convergence: 0.0968 k= 0.023213 lr = 0.0000264\n",
      "[8/25][620/9765] Loss_D: 0.0960 Loss_G: 0.0420 Convergence: 0.1002 k= 0.023194 lr = 0.0000264\n",
      "[8/25][630/9765] Loss_D: 0.1021 Loss_G: 0.0408 Convergence: 0.1034 k= 0.023200 lr = 0.0000264\n",
      "[8/25][640/9765] Loss_D: 0.1009 Loss_G: 0.0386 Convergence: 0.1041 k= 0.023175 lr = 0.0000264\n",
      "[8/25][650/9765] Loss_D: 0.0990 Loss_G: 0.0420 Convergence: 0.1019 k= 0.023181 lr = 0.0000264\n",
      "[8/25][660/9765] Loss_D: 0.0929 Loss_G: 0.0378 Convergence: 0.0940 k= 0.023189 lr = 0.0000264\n",
      "[8/25][670/9765] Loss_D: 0.0980 Loss_G: 0.0407 Convergence: 0.1001 k= 0.023202 lr = 0.0000264\n",
      "[8/25][680/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0999 k= 0.023171 lr = 0.0000264\n",
      "[8/25][690/9765] Loss_D: 0.1054 Loss_G: 0.0376 Convergence: 0.1112 k= 0.023187 lr = 0.0000264\n",
      "[8/25][700/9765] Loss_D: 0.1058 Loss_G: 0.0409 Convergence: 0.1085 k= 0.023197 lr = 0.0000264\n",
      "[8/25][710/9765] Loss_D: 0.1065 Loss_G: 0.0418 Convergence: 0.1086 k= 0.023180 lr = 0.0000264\n",
      "[8/25][720/9765] Loss_D: 0.1033 Loss_G: 0.0392 Convergence: 0.1067 k= 0.023169 lr = 0.0000264\n",
      "[8/25][730/9765] Loss_D: 0.0966 Loss_G: 0.0384 Convergence: 0.0982 k= 0.023180 lr = 0.0000264\n",
      "[8/25][740/9765] Loss_D: 0.1014 Loss_G: 0.0411 Convergence: 0.1025 k= 0.023166 lr = 0.0000264\n",
      "[8/25][750/9765] Loss_D: 0.1060 Loss_G: 0.0433 Convergence: 0.1075 k= 0.023163 lr = 0.0000264\n",
      "[8/25][760/9765] Loss_D: 0.1086 Loss_G: 0.0430 Convergence: 0.1103 k= 0.023150 lr = 0.0000264\n",
      "[8/25][770/9765] Loss_D: 0.0984 Loss_G: 0.0405 Convergence: 0.1001 k= 0.023156 lr = 0.0000264\n",
      "[8/25][780/9765] Loss_D: 0.1045 Loss_G: 0.0414 Convergence: 0.1063 k= 0.023143 lr = 0.0000264\n",
      "[8/25][790/9765] Loss_D: 0.1054 Loss_G: 0.0424 Convergence: 0.1066 k= 0.023113 lr = 0.0000264\n",
      "[8/25][800/9765] Loss_D: 0.1106 Loss_G: 0.0388 Convergence: 0.1172 k= 0.023113 lr = 0.0000264\n",
      "[8/25][810/9765] Loss_D: 0.0957 Loss_G: 0.0390 Convergence: 0.0969 k= 0.023129 lr = 0.0000264\n",
      "[8/25][820/9765] Loss_D: 0.0925 Loss_G: 0.0442 Convergence: 0.1003 k= 0.023121 lr = 0.0000264\n",
      "[8/25][830/9765] Loss_D: 0.0923 Loss_G: 0.0407 Convergence: 0.0967 k= 0.023077 lr = 0.0000264\n",
      "[8/25][840/9765] Loss_D: 0.1014 Loss_G: 0.0380 Convergence: 0.1052 k= 0.023084 lr = 0.0000264\n",
      "[8/25][850/9765] Loss_D: 0.0989 Loss_G: 0.0431 Convergence: 0.1030 k= 0.023096 lr = 0.0000264\n",
      "[8/25][860/9765] Loss_D: 0.0948 Loss_G: 0.0423 Convergence: 0.0998 k= 0.023075 lr = 0.0000264\n",
      "[8/25][870/9765] Loss_D: 0.0965 Loss_G: 0.0477 Convergence: 0.1062 k= 0.023049 lr = 0.0000264\n",
      "[8/25][880/9765] Loss_D: 0.1096 Loss_G: 0.0422 Convergence: 0.1127 k= 0.023031 lr = 0.0000264\n",
      "[8/25][890/9765] Loss_D: 0.1051 Loss_G: 0.0395 Convergence: 0.1091 k= 0.023015 lr = 0.0000264\n",
      "[8/25][900/9765] Loss_D: 0.1001 Loss_G: 0.0392 Convergence: 0.1023 k= 0.023025 lr = 0.0000264\n",
      "[8/25][910/9765] Loss_D: 0.1083 Loss_G: 0.0449 Convergence: 0.1104 k= 0.023018 lr = 0.0000264\n",
      "[8/25][920/9765] Loss_D: 0.1050 Loss_G: 0.0393 Convergence: 0.1089 k= 0.022997 lr = 0.0000264\n",
      "[8/25][930/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0967 k= 0.023001 lr = 0.0000264\n",
      "[8/25][940/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1017 k= 0.023009 lr = 0.0000264\n",
      "[8/25][950/9765] Loss_D: 0.0949 Loss_G: 0.0405 Convergence: 0.0979 k= 0.023007 lr = 0.0000264\n",
      "[8/25][960/9765] Loss_D: 0.1008 Loss_G: 0.0443 Convergence: 0.1054 k= 0.022980 lr = 0.0000264\n",
      "[8/25][970/9765] Loss_D: 0.0959 Loss_G: 0.0401 Convergence: 0.0982 k= 0.022978 lr = 0.0000264\n",
      "[8/25][980/9765] Loss_D: 0.1095 Loss_G: 0.0397 Convergence: 0.1149 k= 0.022967 lr = 0.0000264\n",
      "[8/25][990/9765] Loss_D: 0.1048 Loss_G: 0.0443 Convergence: 0.1078 k= 0.022952 lr = 0.0000264\n",
      "[8/25][1000/9765] Loss_D: 0.1008 Loss_G: 0.0409 Convergence: 0.1020 k= 0.022939 lr = 0.0000264\n",
      "[8/25][1010/9765] Loss_D: 0.1108 Loss_G: 0.0366 Convergence: 0.1197 k= 0.022938 lr = 0.0000264\n",
      "[8/25][1020/9765] Loss_D: 0.0911 Loss_G: 0.0353 Convergence: 0.0933 k= 0.022977 lr = 0.0000264\n",
      "[8/25][1030/9765] Loss_D: 0.0854 Loss_G: 0.0355 Convergence: 0.0873 k= 0.023008 lr = 0.0000264\n",
      "[8/25][1040/9765] Loss_D: 0.1121 Loss_G: 0.0390 Convergence: 0.1193 k= 0.023029 lr = 0.0000264\n",
      "[8/25][1050/9765] Loss_D: 0.0978 Loss_G: 0.0547 Convergence: 0.1141 k= 0.022963 lr = 0.0000264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][1060/9765] Loss_D: 0.0948 Loss_G: 0.0487 Convergence: 0.1063 k= 0.022837 lr = 0.0000264\n",
      "[8/25][1070/9765] Loss_D: 0.1000 Loss_G: 0.0426 Convergence: 0.1031 k= 0.022850 lr = 0.0000264\n",
      "[8/25][1080/9765] Loss_D: 0.0988 Loss_G: 0.0368 Convergence: 0.1027 k= 0.022848 lr = 0.0000264\n",
      "[8/25][1090/9765] Loss_D: 0.1010 Loss_G: 0.0396 Convergence: 0.1030 k= 0.022865 lr = 0.0000264\n",
      "[8/25][1100/9765] Loss_D: 0.1050 Loss_G: 0.0418 Convergence: 0.1065 k= 0.022859 lr = 0.0000264\n",
      "[8/25][1110/9765] Loss_D: 0.0948 Loss_G: 0.0379 Convergence: 0.0960 k= 0.022852 lr = 0.0000264\n",
      "[8/25][1120/9765] Loss_D: 0.0982 Loss_G: 0.0408 Convergence: 0.1003 k= 0.022872 lr = 0.0000264\n",
      "[8/25][1130/9765] Loss_D: 0.1088 Loss_G: 0.0423 Convergence: 0.1113 k= 0.022872 lr = 0.0000264\n",
      "[8/25][1140/9765] Loss_D: 0.1020 Loss_G: 0.0381 Convergence: 0.1059 k= 0.022861 lr = 0.0000264\n",
      "[8/25][1150/9765] Loss_D: 0.0998 Loss_G: 0.0370 Convergence: 0.1040 k= 0.022876 lr = 0.0000264\n",
      "[8/25][1160/9765] Loss_D: 0.1037 Loss_G: 0.0407 Convergence: 0.1058 k= 0.022880 lr = 0.0000264\n",
      "[8/25][1170/9765] Loss_D: 0.1057 Loss_G: 0.0420 Convergence: 0.1073 k= 0.022884 lr = 0.0000264\n",
      "[8/25][1180/9765] Loss_D: 0.1018 Loss_G: 0.0385 Convergence: 0.1052 k= 0.022878 lr = 0.0000264\n",
      "[8/25][1190/9765] Loss_D: 0.0942 Loss_G: 0.0419 Convergence: 0.0990 k= 0.022883 lr = 0.0000264\n",
      "[8/25][1200/9765] Loss_D: 0.1033 Loss_G: 0.0385 Convergence: 0.1073 k= 0.022887 lr = 0.0000264\n",
      "[8/25][1210/9765] Loss_D: 0.0960 Loss_G: 0.0403 Convergence: 0.0984 k= 0.022901 lr = 0.0000264\n",
      "[8/25][1220/9765] Loss_D: 0.0966 Loss_G: 0.0382 Convergence: 0.0982 k= 0.022904 lr = 0.0000264\n",
      "[8/25][1230/9765] Loss_D: 0.1066 Loss_G: 0.0414 Convergence: 0.1092 k= 0.022909 lr = 0.0000264\n",
      "[8/25][1240/9765] Loss_D: 0.1037 Loss_G: 0.0410 Convergence: 0.1055 k= 0.022900 lr = 0.0000264\n",
      "[8/25][1250/9765] Loss_D: 0.0969 Loss_G: 0.0390 Convergence: 0.0978 k= 0.022901 lr = 0.0000264\n",
      "[8/25][1260/9765] Loss_D: 0.0957 Loss_G: 0.0403 Convergence: 0.0983 k= 0.022904 lr = 0.0000264\n",
      "[8/25][1270/9765] Loss_D: 0.1025 Loss_G: 0.0361 Convergence: 0.1086 k= 0.022904 lr = 0.0000264\n",
      "[8/25][1280/9765] Loss_D: 0.0924 Loss_G: 0.0403 Convergence: 0.0963 k= 0.022906 lr = 0.0000264\n",
      "[8/25][1290/9765] Loss_D: 0.0928 Loss_G: 0.0424 Convergence: 0.0987 k= 0.022898 lr = 0.0000264\n",
      "[8/25][1300/9765] Loss_D: 0.0928 Loss_G: 0.0384 Convergence: 0.0946 k= 0.022888 lr = 0.0000264\n",
      "[8/25][1310/9765] Loss_D: 0.1019 Loss_G: 0.0407 Convergence: 0.1031 k= 0.022905 lr = 0.0000264\n",
      "[8/25][1320/9765] Loss_D: 0.0942 Loss_G: 0.0380 Convergence: 0.0951 k= 0.022924 lr = 0.0000264\n",
      "[8/25][1330/9765] Loss_D: 0.1003 Loss_G: 0.0398 Convergence: 0.1018 k= 0.022935 lr = 0.0000264\n",
      "[8/25][1340/9765] Loss_D: 0.1013 Loss_G: 0.0390 Convergence: 0.1041 k= 0.022935 lr = 0.0000264\n",
      "[8/25][1350/9765] Loss_D: 0.0957 Loss_G: 0.0405 Convergence: 0.0985 k= 0.022934 lr = 0.0000264\n",
      "[8/25][1360/9765] Loss_D: 0.1082 Loss_G: 0.0449 Convergence: 0.1104 k= 0.022937 lr = 0.0000264\n",
      "[8/25][1370/9765] Loss_D: 0.1056 Loss_G: 0.0418 Convergence: 0.1074 k= 0.022930 lr = 0.0000264\n",
      "[8/25][1380/9765] Loss_D: 0.1055 Loss_G: 0.0403 Convergence: 0.1087 k= 0.022918 lr = 0.0000264\n",
      "[8/25][1390/9765] Loss_D: 0.0960 Loss_G: 0.0376 Convergence: 0.0979 k= 0.022913 lr = 0.0000264\n",
      "[8/25][1400/9765] Loss_D: 0.0974 Loss_G: 0.0433 Convergence: 0.1023 k= 0.022901 lr = 0.0000264\n",
      "[8/25][1410/9765] Loss_D: 0.1119 Loss_G: 0.0448 Convergence: 0.1132 k= 0.022861 lr = 0.0000264\n",
      "[8/25][1420/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0992 k= 0.022858 lr = 0.0000264\n",
      "[8/25][1430/9765] Loss_D: 0.1017 Loss_G: 0.0392 Convergence: 0.1045 k= 0.022881 lr = 0.0000264\n",
      "[8/25][1440/9765] Loss_D: 0.0960 Loss_G: 0.0419 Convergence: 0.1001 k= 0.022875 lr = 0.0000264\n",
      "[8/25][1450/9765] Loss_D: 0.1011 Loss_G: 0.0421 Convergence: 0.1034 k= 0.022873 lr = 0.0000264\n",
      "[8/25][1460/9765] Loss_D: 0.0913 Loss_G: 0.0401 Convergence: 0.0954 k= 0.022878 lr = 0.0000264\n",
      "[8/25][1470/9765] Loss_D: 0.1005 Loss_G: 0.0448 Convergence: 0.1056 k= 0.022879 lr = 0.0000264\n",
      "[8/25][1480/9765] Loss_D: 0.0959 Loss_G: 0.0388 Convergence: 0.0969 k= 0.022875 lr = 0.0000264\n",
      "[8/25][1490/9765] Loss_D: 0.0954 Loss_G: 0.0436 Convergence: 0.1015 k= 0.022858 lr = 0.0000264\n",
      "[8/25][1500/9765] Loss_D: 0.1001 Loss_G: 0.0408 Convergence: 0.1014 k= 0.022839 lr = 0.0000264\n",
      "[8/25][1510/9765] Loss_D: 0.0955 Loss_G: 0.0356 Convergence: 0.0993 k= 0.022843 lr = 0.0000264\n",
      "[8/25][1520/9765] Loss_D: 0.0986 Loss_G: 0.0371 Convergence: 0.1023 k= 0.022871 lr = 0.0000264\n",
      "[8/25][1530/9765] Loss_D: 0.0991 Loss_G: 0.0405 Convergence: 0.1005 k= 0.022885 lr = 0.0000264\n",
      "[8/25][1540/9765] Loss_D: 0.1044 Loss_G: 0.0380 Convergence: 0.1094 k= 0.022891 lr = 0.0000264\n",
      "[8/25][1550/9765] Loss_D: 0.1045 Loss_G: 0.0405 Convergence: 0.1070 k= 0.022898 lr = 0.0000264\n",
      "[8/25][1560/9765] Loss_D: 0.0981 Loss_G: 0.0422 Convergence: 0.1016 k= 0.022902 lr = 0.0000264\n",
      "[8/25][1570/9765] Loss_D: 0.1025 Loss_G: 0.0388 Convergence: 0.1059 k= 0.022907 lr = 0.0000264\n",
      "[8/25][1580/9765] Loss_D: 0.0970 Loss_G: 0.0408 Convergence: 0.0996 k= 0.022906 lr = 0.0000264\n",
      "[8/25][1590/9765] Loss_D: 0.0946 Loss_G: 0.0407 Convergence: 0.0980 k= 0.022887 lr = 0.0000264\n",
      "[8/25][1600/9765] Loss_D: 0.1054 Loss_G: 0.0411 Convergence: 0.1077 k= 0.022887 lr = 0.0000264\n",
      "[8/25][1610/9765] Loss_D: 0.0941 Loss_G: 0.0369 Convergence: 0.0961 k= 0.022903 lr = 0.0000264\n",
      "[8/25][1620/9765] Loss_D: 0.0937 Loss_G: 0.0390 Convergence: 0.0957 k= 0.022909 lr = 0.0000264\n",
      "[8/25][1630/9765] Loss_D: 0.0943 Loss_G: 0.0378 Convergence: 0.0954 k= 0.022926 lr = 0.0000264\n",
      "[8/25][1640/9765] Loss_D: 0.1069 Loss_G: 0.0385 Convergence: 0.1123 k= 0.022930 lr = 0.0000264\n",
      "[8/25][1650/9765] Loss_D: 0.1050 Loss_G: 0.0403 Convergence: 0.1079 k= 0.022928 lr = 0.0000264\n",
      "[8/25][1660/9765] Loss_D: 0.0955 Loss_G: 0.0395 Convergence: 0.0974 k= 0.022941 lr = 0.0000264\n",
      "[8/25][1670/9765] Loss_D: 0.1009 Loss_G: 0.0391 Convergence: 0.1035 k= 0.022932 lr = 0.0000264\n",
      "[8/25][1680/9765] Loss_D: 0.1006 Loss_G: 0.0384 Convergence: 0.1037 k= 0.022926 lr = 0.0000264\n",
      "[8/25][1690/9765] Loss_D: 0.1062 Loss_G: 0.0426 Convergence: 0.1076 k= 0.022904 lr = 0.0000264\n",
      "[8/25][1700/9765] Loss_D: 0.1034 Loss_G: 0.0381 Convergence: 0.1080 k= 0.022893 lr = 0.0000264\n",
      "[8/25][1710/9765] Loss_D: 0.0868 Loss_G: 0.0423 Convergence: 0.0949 k= 0.022894 lr = 0.0000264\n",
      "[8/25][1720/9765] Loss_D: 0.0955 Loss_G: 0.0429 Convergence: 0.1008 k= 0.022873 lr = 0.0000264\n",
      "[8/25][1730/9765] Loss_D: 0.1097 Loss_G: 0.0412 Convergence: 0.1137 k= 0.022876 lr = 0.0000264\n",
      "[8/25][1740/9765] Loss_D: 0.1060 Loss_G: 0.0412 Convergence: 0.1085 k= 0.022875 lr = 0.0000264\n",
      "[8/25][1750/9765] Loss_D: 0.1035 Loss_G: 0.0398 Convergence: 0.1063 k= 0.022880 lr = 0.0000264\n",
      "[8/25][1760/9765] Loss_D: 0.1056 Loss_G: 0.0397 Convergence: 0.1093 k= 0.022871 lr = 0.0000264\n",
      "[8/25][1770/9765] Loss_D: 0.0891 Loss_G: 0.0409 Convergence: 0.0949 k= 0.022850 lr = 0.0000264\n",
      "[8/25][1780/9765] Loss_D: 0.1076 Loss_G: 0.0456 Convergence: 0.1108 k= 0.022842 lr = 0.0000264\n",
      "[8/25][1790/9765] Loss_D: 0.0956 Loss_G: 0.0366 Convergence: 0.0983 k= 0.022861 lr = 0.0000264\n",
      "[8/25][1800/9765] Loss_D: 0.1162 Loss_G: 0.0381 Convergence: 0.1258 k= 0.022887 lr = 0.0000264\n",
      "[8/25][1810/9765] Loss_D: 0.0922 Loss_G: 0.0390 Convergence: 0.0948 k= 0.022863 lr = 0.0000264\n",
      "[8/25][1820/9765] Loss_D: 0.0938 Loss_G: 0.0431 Convergence: 0.0999 k= 0.022830 lr = 0.0000264\n",
      "[8/25][1830/9765] Loss_D: 0.1020 Loss_G: 0.0451 Convergence: 0.1069 k= 0.022782 lr = 0.0000264\n",
      "[8/25][1840/9765] Loss_D: 0.0936 Loss_G: 0.0407 Convergence: 0.0975 k= 0.022758 lr = 0.0000264\n",
      "[8/25][1850/9765] Loss_D: 0.1054 Loss_G: 0.0392 Convergence: 0.1096 k= 0.022750 lr = 0.0000264\n",
      "[8/25][1860/9765] Loss_D: 0.0961 Loss_G: 0.0398 Convergence: 0.0979 k= 0.022764 lr = 0.0000264\n",
      "[8/25][1870/9765] Loss_D: 0.0996 Loss_G: 0.0408 Convergence: 0.1011 k= 0.022776 lr = 0.0000264\n",
      "[8/25][1880/9765] Loss_D: 0.1005 Loss_G: 0.0418 Convergence: 0.1027 k= 0.022766 lr = 0.0000264\n",
      "[8/25][1890/9765] Loss_D: 0.0936 Loss_G: 0.0359 Convergence: 0.0963 k= 0.022774 lr = 0.0000264\n",
      "[8/25][1900/9765] Loss_D: 0.1049 Loss_G: 0.0376 Convergence: 0.1105 k= 0.022797 lr = 0.0000264\n",
      "[8/25][1910/9765] Loss_D: 0.1020 Loss_G: 0.0422 Convergence: 0.1040 k= 0.022808 lr = 0.0000264\n",
      "[8/25][1920/9765] Loss_D: 0.0958 Loss_G: 0.0422 Convergence: 0.1002 k= 0.022781 lr = 0.0000264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][1930/9765] Loss_D: 0.1026 Loss_G: 0.0424 Convergence: 0.1046 k= 0.022749 lr = 0.0000264\n",
      "[8/25][1940/9765] Loss_D: 0.1084 Loss_G: 0.0369 Convergence: 0.1160 k= 0.022754 lr = 0.0000264\n",
      "[8/25][1950/9765] Loss_D: 0.0963 Loss_G: 0.0375 Convergence: 0.0984 k= 0.022777 lr = 0.0000264\n",
      "[8/25][1960/9765] Loss_D: 0.1083 Loss_G: 0.0436 Convergence: 0.1094 k= 0.022764 lr = 0.0000264\n",
      "[8/25][1970/9765] Loss_D: 0.1039 Loss_G: 0.0419 Convergence: 0.1050 k= 0.022753 lr = 0.0000264\n",
      "[8/25][1980/9765] Loss_D: 0.0994 Loss_G: 0.0357 Convergence: 0.1046 k= 0.022739 lr = 0.0000264\n",
      "[8/25][1990/9765] Loss_D: 0.0987 Loss_G: 0.0364 Convergence: 0.1029 k= 0.022775 lr = 0.0000264\n",
      "[8/25][2000/9765] Loss_D: 0.0986 Loss_G: 0.0437 Convergence: 0.1034 k= 0.022774 lr = 0.0000264\n",
      "[8/25][2010/9765] Loss_D: 0.0981 Loss_G: 0.0508 Convergence: 0.1103 k= 0.022663 lr = 0.0000264\n",
      "[8/25][2020/9765] Loss_D: 0.0960 Loss_G: 0.0398 Convergence: 0.0979 k= 0.022631 lr = 0.0000264\n",
      "[8/25][2030/9765] Loss_D: 0.0945 Loss_G: 0.0377 Convergence: 0.0958 k= 0.022670 lr = 0.0000264\n",
      "[8/25][2040/9765] Loss_D: 0.0964 Loss_G: 0.0408 Convergence: 0.0992 k= 0.022681 lr = 0.0000264\n",
      "[8/25][2050/9765] Loss_D: 0.1040 Loss_G: 0.0416 Convergence: 0.1053 k= 0.022660 lr = 0.0000264\n",
      "[8/25][2060/9765] Loss_D: 0.0946 Loss_G: 0.0376 Convergence: 0.0959 k= 0.022662 lr = 0.0000264\n",
      "[8/25][2070/9765] Loss_D: 0.1020 Loss_G: 0.0382 Convergence: 0.1057 k= 0.022689 lr = 0.0000264\n",
      "[8/25][2080/9765] Loss_D: 0.1073 Loss_G: 0.0401 Convergence: 0.1113 k= 0.022704 lr = 0.0000264\n",
      "[8/25][2090/9765] Loss_D: 0.0980 Loss_G: 0.0407 Convergence: 0.1001 k= 0.022686 lr = 0.0000264\n",
      "[8/25][2100/9765] Loss_D: 0.1036 Loss_G: 0.0422 Convergence: 0.1049 k= 0.022681 lr = 0.0000264\n",
      "[8/25][2110/9765] Loss_D: 0.0971 Loss_G: 0.0418 Convergence: 0.1007 k= 0.022663 lr = 0.0000264\n",
      "[8/25][2120/9765] Loss_D: 0.0912 Loss_G: 0.0400 Convergence: 0.0953 k= 0.022667 lr = 0.0000264\n",
      "[8/25][2130/9765] Loss_D: 0.0878 Loss_G: 0.0373 Convergence: 0.0905 k= 0.022670 lr = 0.0000264\n",
      "[8/25][2140/9765] Loss_D: 0.1051 Loss_G: 0.0422 Convergence: 0.1062 k= 0.022687 lr = 0.0000264\n",
      "[8/25][2150/9765] Loss_D: 0.0996 Loss_G: 0.0428 Convergence: 0.1031 k= 0.022685 lr = 0.0000264\n",
      "[8/25][2160/9765] Loss_D: 0.1081 Loss_G: 0.0419 Convergence: 0.1108 k= 0.022674 lr = 0.0000264\n",
      "[8/25][2170/9765] Loss_D: 0.1025 Loss_G: 0.0375 Convergence: 0.1073 k= 0.022680 lr = 0.0000264\n",
      "[8/25][2180/9765] Loss_D: 0.0966 Loss_G: 0.0459 Convergence: 0.1045 k= 0.022667 lr = 0.0000264\n",
      "[8/25][2190/9765] Loss_D: 0.0966 Loss_G: 0.0407 Convergence: 0.0992 k= 0.022658 lr = 0.0000264\n",
      "[8/25][2200/9765] Loss_D: 0.1030 Loss_G: 0.0400 Convergence: 0.1054 k= 0.022643 lr = 0.0000264\n",
      "[8/25][2210/9765] Loss_D: 0.0942 Loss_G: 0.0394 Convergence: 0.0964 k= 0.022648 lr = 0.0000264\n",
      "[8/25][2220/9765] Loss_D: 0.0983 Loss_G: 0.0387 Convergence: 0.1001 k= 0.022656 lr = 0.0000264\n",
      "[8/25][2230/9765] Loss_D: 0.1026 Loss_G: 0.0401 Convergence: 0.1049 k= 0.022674 lr = 0.0000264\n",
      "[8/25][2240/9765] Loss_D: 0.1024 Loss_G: 0.0412 Convergence: 0.1036 k= 0.022657 lr = 0.0000264\n",
      "[8/25][2250/9765] Loss_D: 0.0929 Loss_G: 0.0406 Convergence: 0.0969 k= 0.022638 lr = 0.0000264\n",
      "[8/25][2260/9765] Loss_D: 0.1057 Loss_G: 0.0417 Convergence: 0.1078 k= 0.022622 lr = 0.0000264\n",
      "[8/25][2270/9765] Loss_D: 0.1011 Loss_G: 0.0403 Convergence: 0.1025 k= 0.022636 lr = 0.0000264\n",
      "[8/25][2280/9765] Loss_D: 0.1040 Loss_G: 0.0389 Convergence: 0.1079 k= 0.022637 lr = 0.0000264\n",
      "[8/25][2290/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0967 k= 0.022631 lr = 0.0000264\n",
      "[8/25][2300/9765] Loss_D: 0.0989 Loss_G: 0.0421 Convergence: 0.1019 k= 0.022629 lr = 0.0000264\n",
      "[8/25][2310/9765] Loss_D: 0.0982 Loss_G: 0.0405 Convergence: 0.1000 k= 0.022603 lr = 0.0000264\n",
      "[8/25][2320/9765] Loss_D: 0.1029 Loss_G: 0.0389 Convergence: 0.1065 k= 0.022621 lr = 0.0000264\n",
      "[8/25][2330/9765] Loss_D: 0.0979 Loss_G: 0.0427 Convergence: 0.1019 k= 0.022609 lr = 0.0000264\n",
      "[8/25][2340/9765] Loss_D: 0.1083 Loss_G: 0.0386 Convergence: 0.1141 k= 0.022621 lr = 0.0000264\n",
      "[8/25][2350/9765] Loss_D: 0.1102 Loss_G: 0.0407 Convergence: 0.1147 k= 0.022632 lr = 0.0000264\n",
      "[8/25][2360/9765] Loss_D: 0.1004 Loss_G: 0.0361 Convergence: 0.1056 k= 0.022641 lr = 0.0000264\n",
      "[8/25][2370/9765] Loss_D: 0.0932 Loss_G: 0.0435 Convergence: 0.0999 k= 0.022637 lr = 0.0000264\n",
      "[8/25][2380/9765] Loss_D: 0.0998 Loss_G: 0.0421 Convergence: 0.1026 k= 0.022614 lr = 0.0000264\n",
      "[8/25][2390/9765] Loss_D: 0.1002 Loss_G: 0.0446 Convergence: 0.1053 k= 0.022608 lr = 0.0000264\n",
      "[8/25][2400/9765] Loss_D: 0.1010 Loss_G: 0.0414 Convergence: 0.1026 k= 0.022596 lr = 0.0000264\n",
      "[8/25][2410/9765] Loss_D: 0.1097 Loss_G: 0.0381 Convergence: 0.1167 k= 0.022605 lr = 0.0000264\n",
      "[8/25][2420/9765] Loss_D: 0.0972 Loss_G: 0.0403 Convergence: 0.0992 k= 0.022608 lr = 0.0000264\n",
      "[8/25][2430/9765] Loss_D: 0.1024 Loss_G: 0.0406 Convergence: 0.1040 k= 0.022602 lr = 0.0000264\n",
      "[8/25][2440/9765] Loss_D: 0.0911 Loss_G: 0.0417 Convergence: 0.0970 k= 0.022574 lr = 0.0000264\n",
      "[8/25][2450/9765] Loss_D: 0.0965 Loss_G: 0.0386 Convergence: 0.0978 k= 0.022573 lr = 0.0000264\n",
      "[8/25][2460/9765] Loss_D: 0.0994 Loss_G: 0.0409 Convergence: 0.1011 k= 0.022555 lr = 0.0000264\n",
      "[8/25][2470/9765] Loss_D: 0.1091 Loss_G: 0.0434 Convergence: 0.1106 k= 0.022550 lr = 0.0000264\n",
      "[8/25][2480/9765] Loss_D: 0.1002 Loss_G: 0.0436 Convergence: 0.1042 k= 0.022535 lr = 0.0000264\n",
      "[8/25][2490/9765] Loss_D: 0.1040 Loss_G: 0.0412 Convergence: 0.1057 k= 0.022533 lr = 0.0000264\n",
      "[8/25][2500/9765] Loss_D: 0.0982 Loss_G: 0.0374 Convergence: 0.1013 k= 0.022544 lr = 0.0000264\n",
      "[8/25][2510/9765] Loss_D: 0.1030 Loss_G: 0.0379 Convergence: 0.1075 k= 0.022584 lr = 0.0000264\n",
      "[8/25][2520/9765] Loss_D: 0.1119 Loss_G: 0.0438 Convergence: 0.1142 k= 0.022582 lr = 0.0000264\n",
      "[8/25][2530/9765] Loss_D: 0.1064 Loss_G: 0.0420 Convergence: 0.1083 k= 0.022542 lr = 0.0000264\n",
      "[8/25][2540/9765] Loss_D: 0.0922 Loss_G: 0.0359 Convergence: 0.0944 k= 0.022543 lr = 0.0000264\n",
      "[8/25][2550/9765] Loss_D: 0.0956 Loss_G: 0.0419 Convergence: 0.0998 k= 0.022541 lr = 0.0000264\n",
      "[8/25][2560/9765] Loss_D: 0.1038 Loss_G: 0.0403 Convergence: 0.1063 k= 0.022547 lr = 0.0000264\n",
      "[8/25][2570/9765] Loss_D: 0.0932 Loss_G: 0.0402 Convergence: 0.0966 k= 0.022547 lr = 0.0000264\n",
      "[8/25][2580/9765] Loss_D: 0.1064 Loss_G: 0.0493 Convergence: 0.1137 k= 0.022505 lr = 0.0000264\n",
      "[8/25][2590/9765] Loss_D: 0.0971 Loss_G: 0.0380 Convergence: 0.0991 k= 0.022501 lr = 0.0000264\n",
      "[8/25][2600/9765] Loss_D: 0.0953 Loss_G: 0.0410 Convergence: 0.0987 k= 0.022494 lr = 0.0000264\n",
      "[8/25][2610/9765] Loss_D: 0.1041 Loss_G: 0.0384 Convergence: 0.1086 k= 0.022516 lr = 0.0000264\n",
      "[8/25][2620/9765] Loss_D: 0.1073 Loss_G: 0.0443 Convergence: 0.1092 k= 0.022507 lr = 0.0000264\n",
      "[8/25][2630/9765] Loss_D: 0.1015 Loss_G: 0.0409 Convergence: 0.1025 k= 0.022482 lr = 0.0000264\n",
      "[8/25][2640/9765] Loss_D: 0.1041 Loss_G: 0.0384 Convergence: 0.1086 k= 0.022493 lr = 0.0000264\n",
      "[8/25][2650/9765] Loss_D: 0.1032 Loss_G: 0.0379 Convergence: 0.1077 k= 0.022514 lr = 0.0000264\n",
      "[8/25][2660/9765] Loss_D: 0.1010 Loss_G: 0.0422 Convergence: 0.1034 k= 0.022510 lr = 0.0000264\n",
      "[8/25][2670/9765] Loss_D: 0.1008 Loss_G: 0.0439 Convergence: 0.1049 k= 0.022499 lr = 0.0000264\n",
      "[8/25][2680/9765] Loss_D: 0.1106 Loss_G: 0.0398 Convergence: 0.1164 k= 0.022470 lr = 0.0000264\n",
      "[8/25][2690/9765] Loss_D: 0.0958 Loss_G: 0.0363 Convergence: 0.0989 k= 0.022480 lr = 0.0000264\n",
      "[8/25][2700/9765] Loss_D: 0.0903 Loss_G: 0.0363 Convergence: 0.0914 k= 0.022525 lr = 0.0000264\n",
      "[8/25][2710/9765] Loss_D: 0.1019 Loss_G: 0.0426 Convergence: 0.1042 k= 0.022570 lr = 0.0000264\n",
      "[8/25][2720/9765] Loss_D: 0.1041 Loss_G: 0.0431 Convergence: 0.1061 k= 0.022527 lr = 0.0000264\n",
      "[8/25][2730/9765] Loss_D: 0.1029 Loss_G: 0.0394 Convergence: 0.1058 k= 0.022530 lr = 0.0000264\n",
      "[8/25][2740/9765] Loss_D: 0.1163 Loss_G: 0.0379 Convergence: 0.1261 k= 0.022546 lr = 0.0000264\n",
      "[8/25][2750/9765] Loss_D: 0.0905 Loss_G: 0.0373 Convergence: 0.0922 k= 0.022553 lr = 0.0000264\n",
      "[8/25][2760/9765] Loss_D: 0.0973 Loss_G: 0.0408 Convergence: 0.0997 k= 0.022567 lr = 0.0000264\n",
      "[8/25][2770/9765] Loss_D: 0.0930 Loss_G: 0.0388 Convergence: 0.0951 k= 0.022540 lr = 0.0000264\n",
      "[8/25][2780/9765] Loss_D: 0.0925 Loss_G: 0.0388 Convergence: 0.0949 k= 0.022524 lr = 0.0000264\n",
      "[8/25][2790/9765] Loss_D: 0.0940 Loss_G: 0.0365 Convergence: 0.0964 k= 0.022533 lr = 0.0000264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][2800/9765] Loss_D: 0.1065 Loss_G: 0.0371 Convergence: 0.1131 k= 0.022563 lr = 0.0000264\n",
      "[8/25][2810/9765] Loss_D: 0.0934 Loss_G: 0.0412 Convergence: 0.0978 k= 0.022552 lr = 0.0000264\n",
      "[8/25][2820/9765] Loss_D: 0.1047 Loss_G: 0.0425 Convergence: 0.1059 k= 0.022545 lr = 0.0000264\n",
      "[8/25][2830/9765] Loss_D: 0.1062 Loss_G: 0.0412 Convergence: 0.1086 k= 0.022552 lr = 0.0000264\n",
      "[8/25][2840/9765] Loss_D: 0.0971 Loss_G: 0.0405 Convergence: 0.0993 k= 0.022551 lr = 0.0000264\n",
      "[8/25][2850/9765] Loss_D: 0.0931 Loss_G: 0.0380 Convergence: 0.0944 k= 0.022546 lr = 0.0000264\n",
      "[8/25][2860/9765] Loss_D: 0.0965 Loss_G: 0.0424 Convergence: 0.1009 k= 0.022550 lr = 0.0000264\n",
      "[8/25][2870/9765] Loss_D: 0.0944 Loss_G: 0.0414 Convergence: 0.0986 k= 0.022529 lr = 0.0000264\n",
      "[8/25][2880/9765] Loss_D: 0.1064 Loss_G: 0.0412 Convergence: 0.1088 k= 0.022548 lr = 0.0000250\n",
      "[8/25][2890/9765] Loss_D: 0.1043 Loss_G: 0.0389 Convergence: 0.1084 k= 0.022557 lr = 0.0000250\n",
      "[8/25][2900/9765] Loss_D: 0.0960 Loss_G: 0.0399 Convergence: 0.0980 k= 0.022582 lr = 0.0000250\n",
      "[8/25][2910/9765] Loss_D: 0.1039 Loss_G: 0.0443 Convergence: 0.1072 k= 0.022557 lr = 0.0000250\n",
      "[8/25][2920/9765] Loss_D: 0.0904 Loss_G: 0.0369 Convergence: 0.0917 k= 0.022550 lr = 0.0000250\n",
      "[8/25][2930/9765] Loss_D: 0.1062 Loss_G: 0.0379 Convergence: 0.1120 k= 0.022571 lr = 0.0000250\n",
      "[8/25][2940/9765] Loss_D: 0.0972 Loss_G: 0.0356 Convergence: 0.1015 k= 0.022593 lr = 0.0000250\n",
      "[8/25][2950/9765] Loss_D: 0.0976 Loss_G: 0.0429 Convergence: 0.1020 k= 0.022603 lr = 0.0000250\n",
      "[8/25][2960/9765] Loss_D: 0.0918 Loss_G: 0.0395 Convergence: 0.0951 k= 0.022563 lr = 0.0000250\n",
      "[8/25][2970/9765] Loss_D: 0.0966 Loss_G: 0.0404 Convergence: 0.0989 k= 0.022570 lr = 0.0000250\n",
      "[8/25][2980/9765] Loss_D: 0.0979 Loss_G: 0.0376 Convergence: 0.1007 k= 0.022569 lr = 0.0000250\n",
      "[8/25][2990/9765] Loss_D: 0.0928 Loss_G: 0.0449 Convergence: 0.1011 k= 0.022573 lr = 0.0000250\n",
      "[8/25][3000/9765] Loss_D: 0.0937 Loss_G: 0.0409 Convergence: 0.0976 k= 0.022561 lr = 0.0000250\n",
      "[8/25][3010/9765] Loss_D: 0.0993 Loss_G: 0.0385 Convergence: 0.1017 k= 0.022574 lr = 0.0000250\n",
      "[8/25][3020/9765] Loss_D: 0.0959 Loss_G: 0.0428 Convergence: 0.1009 k= 0.022567 lr = 0.0000250\n",
      "[8/25][3030/9765] Loss_D: 0.0975 Loss_G: 0.0423 Convergence: 0.1013 k= 0.022563 lr = 0.0000250\n",
      "[8/25][3040/9765] Loss_D: 0.0976 Loss_G: 0.0424 Convergence: 0.1015 k= 0.022542 lr = 0.0000250\n",
      "[8/25][3050/9765] Loss_D: 0.1091 Loss_G: 0.0395 Convergence: 0.1145 k= 0.022551 lr = 0.0000250\n",
      "[8/25][3060/9765] Loss_D: 0.1079 Loss_G: 0.0393 Convergence: 0.1130 k= 0.022562 lr = 0.0000250\n",
      "[8/25][3070/9765] Loss_D: 0.1011 Loss_G: 0.0388 Convergence: 0.1040 k= 0.022558 lr = 0.0000250\n",
      "[8/25][3080/9765] Loss_D: 0.1005 Loss_G: 0.0431 Convergence: 0.1040 k= 0.022548 lr = 0.0000250\n",
      "[8/25][3090/9765] Loss_D: 0.1053 Loss_G: 0.0428 Convergence: 0.1066 k= 0.022519 lr = 0.0000250\n",
      "[8/25][3100/9765] Loss_D: 0.1006 Loss_G: 0.0417 Convergence: 0.1025 k= 0.022489 lr = 0.0000250\n",
      "[8/25][3110/9765] Loss_D: 0.1051 Loss_G: 0.0387 Convergence: 0.1096 k= 0.022505 lr = 0.0000250\n",
      "[8/25][3120/9765] Loss_D: 0.0943 Loss_G: 0.0346 Convergence: 0.0985 k= 0.022527 lr = 0.0000250\n",
      "[8/25][3130/9765] Loss_D: 0.1079 Loss_G: 0.0438 Convergence: 0.1091 k= 0.022544 lr = 0.0000250\n",
      "[8/25][3140/9765] Loss_D: 0.0910 Loss_G: 0.0429 Convergence: 0.0982 k= 0.022512 lr = 0.0000250\n",
      "[8/25][3150/9765] Loss_D: 0.1010 Loss_G: 0.0418 Convergence: 0.1030 k= 0.022512 lr = 0.0000250\n",
      "[8/25][3160/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.1000 k= 0.022522 lr = 0.0000250\n",
      "[8/25][3170/9765] Loss_D: 0.0999 Loss_G: 0.0364 Convergence: 0.1046 k= 0.022539 lr = 0.0000250\n",
      "[8/25][3180/9765] Loss_D: 0.0957 Loss_G: 0.0406 Convergence: 0.0986 k= 0.022540 lr = 0.0000250\n",
      "[8/25][3190/9765] Loss_D: 0.1034 Loss_G: 0.0434 Convergence: 0.1060 k= 0.022520 lr = 0.0000250\n",
      "[8/25][3200/9765] Loss_D: 0.0991 Loss_G: 0.0367 Convergence: 0.1032 k= 0.022530 lr = 0.0000250\n",
      "[8/25][3210/9765] Loss_D: 0.1013 Loss_G: 0.0376 Convergence: 0.1054 k= 0.022558 lr = 0.0000250\n",
      "[8/25][3220/9765] Loss_D: 0.0933 Loss_G: 0.0418 Convergence: 0.0983 k= 0.022563 lr = 0.0000250\n",
      "[8/25][3230/9765] Loss_D: 0.1012 Loss_G: 0.0391 Convergence: 0.1037 k= 0.022566 lr = 0.0000250\n",
      "[8/25][3240/9765] Loss_D: 0.1009 Loss_G: 0.0398 Convergence: 0.1028 k= 0.022569 lr = 0.0000250\n",
      "[8/25][3250/9765] Loss_D: 0.0885 Loss_G: 0.0359 Convergence: 0.0895 k= 0.022579 lr = 0.0000250\n",
      "[8/25][3260/9765] Loss_D: 0.0965 Loss_G: 0.0368 Convergence: 0.0995 k= 0.022591 lr = 0.0000250\n",
      "[8/25][3270/9765] Loss_D: 0.1076 Loss_G: 0.0430 Convergence: 0.1089 k= 0.022602 lr = 0.0000250\n",
      "[8/25][3280/9765] Loss_D: 0.0893 Loss_G: 0.0378 Convergence: 0.0920 k= 0.022609 lr = 0.0000250\n",
      "[8/25][3290/9765] Loss_D: 0.1060 Loss_G: 0.0411 Convergence: 0.1086 k= 0.022596 lr = 0.0000250\n",
      "[8/25][3300/9765] Loss_D: 0.0985 Loss_G: 0.0413 Convergence: 0.1010 k= 0.022590 lr = 0.0000250\n",
      "[8/25][3310/9765] Loss_D: 0.0957 Loss_G: 0.0390 Convergence: 0.0969 k= 0.022588 lr = 0.0000250\n",
      "[8/25][3320/9765] Loss_D: 0.1050 Loss_G: 0.0393 Convergence: 0.1089 k= 0.022582 lr = 0.0000250\n",
      "[8/25][3330/9765] Loss_D: 0.0963 Loss_G: 0.0389 Convergence: 0.0973 k= 0.022581 lr = 0.0000250\n",
      "[8/25][3340/9765] Loss_D: 0.0994 Loss_G: 0.0424 Convergence: 0.1026 k= 0.022599 lr = 0.0000250\n",
      "[8/25][3350/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0956 k= 0.022607 lr = 0.0000250\n",
      "[8/25][3360/9765] Loss_D: 0.0891 Loss_G: 0.0396 Convergence: 0.0936 k= 0.022603 lr = 0.0000250\n",
      "[8/25][3370/9765] Loss_D: 0.0972 Loss_G: 0.0400 Convergence: 0.0988 k= 0.022607 lr = 0.0000250\n",
      "[8/25][3380/9765] Loss_D: 0.0910 Loss_G: 0.0421 Convergence: 0.0973 k= 0.022596 lr = 0.0000250\n",
      "[8/25][3390/9765] Loss_D: 0.0931 Loss_G: 0.0396 Convergence: 0.0960 k= 0.022584 lr = 0.0000250\n",
      "[8/25][3400/9765] Loss_D: 0.0940 Loss_G: 0.0404 Convergence: 0.0974 k= 0.022558 lr = 0.0000250\n",
      "[8/25][3410/9765] Loss_D: 0.0960 Loss_G: 0.0383 Convergence: 0.0972 k= 0.022571 lr = 0.0000250\n",
      "[8/25][3420/9765] Loss_D: 0.1053 Loss_G: 0.0419 Convergence: 0.1069 k= 0.022602 lr = 0.0000250\n",
      "[8/25][3430/9765] Loss_D: 0.0907 Loss_G: 0.0411 Convergence: 0.0961 k= 0.022583 lr = 0.0000250\n",
      "[8/25][3440/9765] Loss_D: 0.0988 Loss_G: 0.0400 Convergence: 0.0998 k= 0.022566 lr = 0.0000250\n",
      "[8/25][3450/9765] Loss_D: 0.1036 Loss_G: 0.0433 Convergence: 0.1061 k= 0.022554 lr = 0.0000250\n",
      "[8/25][3460/9765] Loss_D: 0.0985 Loss_G: 0.0433 Convergence: 0.1030 k= 0.022523 lr = 0.0000250\n",
      "[8/25][3470/9765] Loss_D: 0.0938 Loss_G: 0.0392 Convergence: 0.0960 k= 0.022519 lr = 0.0000250\n",
      "[8/25][3480/9765] Loss_D: 0.1002 Loss_G: 0.0371 Convergence: 0.1044 k= 0.022539 lr = 0.0000250\n",
      "[8/25][3490/9765] Loss_D: 0.1000 Loss_G: 0.0380 Convergence: 0.1033 k= 0.022542 lr = 0.0000250\n",
      "[8/25][3500/9765] Loss_D: 0.0952 Loss_G: 0.0374 Convergence: 0.0971 k= 0.022559 lr = 0.0000250\n",
      "[8/25][3510/9765] Loss_D: 0.0995 Loss_G: 0.0399 Convergence: 0.1006 k= 0.022572 lr = 0.0000250\n",
      "[8/25][3520/9765] Loss_D: 0.0942 Loss_G: 0.0383 Convergence: 0.0953 k= 0.022591 lr = 0.0000250\n",
      "[8/25][3530/9765] Loss_D: 0.1007 Loss_G: 0.0396 Convergence: 0.1026 k= 0.022618 lr = 0.0000250\n",
      "[8/25][3540/9765] Loss_D: 0.1002 Loss_G: 0.0442 Convergence: 0.1049 k= 0.022598 lr = 0.0000250\n",
      "[8/25][3550/9765] Loss_D: 0.0910 Loss_G: 0.0381 Convergence: 0.0932 k= 0.022557 lr = 0.0000250\n",
      "[8/25][3560/9765] Loss_D: 0.0983 Loss_G: 0.0384 Convergence: 0.1004 k= 0.022574 lr = 0.0000250\n",
      "[8/25][3570/9765] Loss_D: 0.1060 Loss_G: 0.0422 Convergence: 0.1075 k= 0.022595 lr = 0.0000250\n",
      "[8/25][3580/9765] Loss_D: 0.0938 Loss_G: 0.0431 Convergence: 0.0999 k= 0.022557 lr = 0.0000250\n",
      "[8/25][3590/9765] Loss_D: 0.0978 Loss_G: 0.0394 Convergence: 0.0987 k= 0.022537 lr = 0.0000250\n",
      "[8/25][3600/9765] Loss_D: 0.1122 Loss_G: 0.0378 Convergence: 0.1205 k= 0.022544 lr = 0.0000250\n",
      "[8/25][3610/9765] Loss_D: 0.0920 Loss_G: 0.0353 Convergence: 0.0946 k= 0.022563 lr = 0.0000250\n",
      "[8/25][3620/9765] Loss_D: 0.0974 Loss_G: 0.0389 Convergence: 0.0987 k= 0.022579 lr = 0.0000250\n",
      "[8/25][3630/9765] Loss_D: 0.0945 Loss_G: 0.0445 Convergence: 0.1018 k= 0.022554 lr = 0.0000250\n",
      "[8/25][3640/9765] Loss_D: 0.0995 Loss_G: 0.0425 Convergence: 0.1028 k= 0.022535 lr = 0.0000250\n",
      "[8/25][3650/9765] Loss_D: 0.0926 Loss_G: 0.0433 Convergence: 0.0994 k= 0.022515 lr = 0.0000250\n",
      "[8/25][3660/9765] Loss_D: 0.0941 Loss_G: 0.0392 Convergence: 0.0962 k= 0.022516 lr = 0.0000250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][3670/9765] Loss_D: 0.0988 Loss_G: 0.0387 Convergence: 0.1009 k= 0.022527 lr = 0.0000250\n",
      "[8/25][3680/9765] Loss_D: 0.0980 Loss_G: 0.0394 Convergence: 0.0991 k= 0.022517 lr = 0.0000250\n",
      "[8/25][3690/9765] Loss_D: 0.0922 Loss_G: 0.0394 Convergence: 0.0953 k= 0.022520 lr = 0.0000250\n",
      "[8/25][3700/9765] Loss_D: 0.0971 Loss_G: 0.0371 Convergence: 0.1000 k= 0.022537 lr = 0.0000250\n",
      "[8/25][3710/9765] Loss_D: 0.0985 Loss_G: 0.0423 Convergence: 0.1020 k= 0.022537 lr = 0.0000250\n",
      "[8/25][3720/9765] Loss_D: 0.0923 Loss_G: 0.0393 Convergence: 0.0952 k= 0.022544 lr = 0.0000250\n",
      "[8/25][3730/9765] Loss_D: 0.1001 Loss_G: 0.0392 Convergence: 0.1021 k= 0.022534 lr = 0.0000250\n",
      "[8/25][3740/9765] Loss_D: 0.1041 Loss_G: 0.0413 Convergence: 0.1056 k= 0.022532 lr = 0.0000250\n",
      "[8/25][3750/9765] Loss_D: 0.0939 Loss_G: 0.0407 Convergence: 0.0976 k= 0.022514 lr = 0.0000250\n",
      "[8/25][3760/9765] Loss_D: 0.0987 Loss_G: 0.0410 Convergence: 0.1007 k= 0.022519 lr = 0.0000250\n",
      "[8/25][3770/9765] Loss_D: 0.0878 Loss_G: 0.0373 Convergence: 0.0905 k= 0.022525 lr = 0.0000250\n",
      "[8/25][3780/9765] Loss_D: 0.1078 Loss_G: 0.0432 Convergence: 0.1091 k= 0.022519 lr = 0.0000250\n",
      "[8/25][3790/9765] Loss_D: 0.1021 Loss_G: 0.0410 Convergence: 0.1033 k= 0.022502 lr = 0.0000250\n",
      "[8/25][3800/9765] Loss_D: 0.0995 Loss_G: 0.0399 Convergence: 0.1006 k= 0.022492 lr = 0.0000250\n",
      "[8/25][3810/9765] Loss_D: 0.1055 Loss_G: 0.0374 Convergence: 0.1114 k= 0.022518 lr = 0.0000250\n",
      "[8/25][3820/9765] Loss_D: 0.0953 Loss_G: 0.0423 Convergence: 0.1000 k= 0.022521 lr = 0.0000250\n",
      "[8/25][3830/9765] Loss_D: 0.1025 Loss_G: 0.0370 Convergence: 0.1078 k= 0.022510 lr = 0.0000250\n",
      "[8/25][3840/9765] Loss_D: 0.0920 Loss_G: 0.0412 Convergence: 0.0969 k= 0.022504 lr = 0.0000250\n",
      "[8/25][3850/9765] Loss_D: 0.0934 Loss_G: 0.0421 Convergence: 0.0987 k= 0.022499 lr = 0.0000250\n",
      "[8/25][3860/9765] Loss_D: 0.0951 Loss_G: 0.0367 Convergence: 0.0976 k= 0.022495 lr = 0.0000250\n",
      "[8/25][3870/9765] Loss_D: 0.1004 Loss_G: 0.0398 Convergence: 0.1020 k= 0.022495 lr = 0.0000250\n",
      "[8/25][3880/9765] Loss_D: 0.0923 Loss_G: 0.0400 Convergence: 0.0959 k= 0.022488 lr = 0.0000250\n",
      "[8/25][3890/9765] Loss_D: 0.0976 Loss_G: 0.0390 Convergence: 0.0988 k= 0.022487 lr = 0.0000250\n",
      "[8/25][3900/9765] Loss_D: 0.1012 Loss_G: 0.0354 Convergence: 0.1074 k= 0.022524 lr = 0.0000250\n",
      "[8/25][3910/9765] Loss_D: 0.1019 Loss_G: 0.0435 Convergence: 0.1052 k= 0.022515 lr = 0.0000250\n",
      "[8/25][3920/9765] Loss_D: 0.0972 Loss_G: 0.0430 Convergence: 0.1018 k= 0.022470 lr = 0.0000250\n",
      "[8/25][3930/9765] Loss_D: 0.1061 Loss_G: 0.0389 Convergence: 0.1109 k= 0.022476 lr = 0.0000250\n",
      "[8/25][3940/9765] Loss_D: 0.0984 Loss_G: 0.0374 Convergence: 0.1016 k= 0.022477 lr = 0.0000250\n",
      "[8/25][3950/9765] Loss_D: 0.1004 Loss_G: 0.0368 Convergence: 0.1048 k= 0.022501 lr = 0.0000250\n",
      "[8/25][3960/9765] Loss_D: 0.0949 Loss_G: 0.0378 Convergence: 0.0964 k= 0.022514 lr = 0.0000250\n",
      "[8/25][3970/9765] Loss_D: 0.0925 Loss_G: 0.0421 Convergence: 0.0982 k= 0.022519 lr = 0.0000250\n",
      "[8/25][3980/9765] Loss_D: 0.0969 Loss_G: 0.0425 Convergence: 0.1013 k= 0.022489 lr = 0.0000250\n",
      "[8/25][3990/9765] Loss_D: 0.1030 Loss_G: 0.0428 Convergence: 0.1052 k= 0.022452 lr = 0.0000250\n",
      "[8/25][4000/9765] Loss_D: 0.1017 Loss_G: 0.0426 Convergence: 0.1041 k= 0.022453 lr = 0.0000250\n",
      "[8/25][4010/9765] Loss_D: 0.1011 Loss_G: 0.0394 Convergence: 0.1034 k= 0.022447 lr = 0.0000250\n",
      "[8/25][4020/9765] Loss_D: 0.0981 Loss_G: 0.0415 Convergence: 0.1009 k= 0.022451 lr = 0.0000250\n",
      "[8/25][4030/9765] Loss_D: 0.0900 Loss_G: 0.0403 Convergence: 0.0948 k= 0.022436 lr = 0.0000250\n",
      "[8/25][4040/9765] Loss_D: 0.1082 Loss_G: 0.0378 Convergence: 0.1149 k= 0.022460 lr = 0.0000250\n",
      "[8/25][4050/9765] Loss_D: 0.1037 Loss_G: 0.0410 Convergence: 0.1054 k= 0.022493 lr = 0.0000250\n",
      "[8/25][4060/9765] Loss_D: 0.0983 Loss_G: 0.0434 Convergence: 0.1029 k= 0.022493 lr = 0.0000250\n",
      "[8/25][4070/9765] Loss_D: 0.1099 Loss_G: 0.0417 Convergence: 0.1134 k= 0.022475 lr = 0.0000250\n",
      "[8/25][4080/9765] Loss_D: 0.1019 Loss_G: 0.0435 Convergence: 0.1052 k= 0.022473 lr = 0.0000250\n",
      "[8/25][4090/9765] Loss_D: 0.1084 Loss_G: 0.0403 Convergence: 0.1126 k= 0.022462 lr = 0.0000250\n",
      "[8/25][4100/9765] Loss_D: 0.1000 Loss_G: 0.0394 Convergence: 0.1018 k= 0.022448 lr = 0.0000250\n",
      "[8/25][4110/9765] Loss_D: 0.0950 Loss_G: 0.0416 Convergence: 0.0992 k= 0.022432 lr = 0.0000250\n",
      "[8/25][4120/9765] Loss_D: 0.1059 Loss_G: 0.0406 Convergence: 0.1090 k= 0.022418 lr = 0.0000250\n",
      "[8/25][4130/9765] Loss_D: 0.1054 Loss_G: 0.0392 Convergence: 0.1096 k= 0.022426 lr = 0.0000250\n",
      "[8/25][4140/9765] Loss_D: 0.1011 Loss_G: 0.0427 Convergence: 0.1039 k= 0.022435 lr = 0.0000250\n",
      "[8/25][4150/9765] Loss_D: 0.0955 Loss_G: 0.0433 Convergence: 0.1011 k= 0.022422 lr = 0.0000250\n",
      "[8/25][4160/9765] Loss_D: 0.1009 Loss_G: 0.0428 Convergence: 0.1039 k= 0.022417 lr = 0.0000250\n",
      "[8/25][4170/9765] Loss_D: 0.1010 Loss_G: 0.0362 Convergence: 0.1064 k= 0.022434 lr = 0.0000250\n",
      "[8/25][4180/9765] Loss_D: 0.0966 Loss_G: 0.0357 Convergence: 0.1006 k= 0.022450 lr = 0.0000250\n",
      "[8/25][4190/9765] Loss_D: 0.1048 Loss_G: 0.0393 Convergence: 0.1086 k= 0.022493 lr = 0.0000250\n",
      "[8/25][4200/9765] Loss_D: 0.1055 Loss_G: 0.0469 Convergence: 0.1109 k= 0.022452 lr = 0.0000250\n",
      "[8/25][4210/9765] Loss_D: 0.1000 Loss_G: 0.0490 Convergence: 0.1097 k= 0.022349 lr = 0.0000250\n",
      "[8/25][4220/9765] Loss_D: 0.0911 Loss_G: 0.0398 Convergence: 0.0951 k= 0.022295 lr = 0.0000250\n",
      "[8/25][4230/9765] Loss_D: 0.1035 Loss_G: 0.0340 Convergence: 0.1120 k= 0.022344 lr = 0.0000250\n",
      "[8/25][4240/9765] Loss_D: 0.1051 Loss_G: 0.0361 Convergence: 0.1121 k= 0.022408 lr = 0.0000250\n",
      "[8/25][4250/9765] Loss_D: 0.1126 Loss_G: 0.0434 Convergence: 0.1155 k= 0.022419 lr = 0.0000250\n",
      "[8/25][4260/9765] Loss_D: 0.1010 Loss_G: 0.0473 Convergence: 0.1085 k= 0.022394 lr = 0.0000250\n",
      "[8/25][4270/9765] Loss_D: 0.0972 Loss_G: 0.0429 Convergence: 0.1018 k= 0.022387 lr = 0.0000250\n",
      "[8/25][4280/9765] Loss_D: 0.1044 Loss_G: 0.0397 Convergence: 0.1077 k= 0.022384 lr = 0.0000250\n",
      "[8/25][4290/9765] Loss_D: 0.1077 Loss_G: 0.0389 Convergence: 0.1131 k= 0.022390 lr = 0.0000250\n",
      "[8/25][4300/9765] Loss_D: 0.1033 Loss_G: 0.0412 Convergence: 0.1047 k= 0.022397 lr = 0.0000250\n",
      "[8/25][4310/9765] Loss_D: 0.0970 Loss_G: 0.0414 Convergence: 0.1001 k= 0.022355 lr = 0.0000250\n",
      "[8/25][4320/9765] Loss_D: 0.1056 Loss_G: 0.0430 Convergence: 0.1069 k= 0.022341 lr = 0.0000250\n",
      "[8/25][4330/9765] Loss_D: 0.0946 Loss_G: 0.0397 Convergence: 0.0970 k= 0.022347 lr = 0.0000250\n",
      "[8/25][4340/9765] Loss_D: 0.0973 Loss_G: 0.0395 Convergence: 0.0984 k= 0.022353 lr = 0.0000250\n",
      "[8/25][4350/9765] Loss_D: 0.0965 Loss_G: 0.0409 Convergence: 0.0994 k= 0.022357 lr = 0.0000250\n",
      "[8/25][4360/9765] Loss_D: 0.1016 Loss_G: 0.0393 Convergence: 0.1042 k= 0.022358 lr = 0.0000250\n",
      "[8/25][4370/9765] Loss_D: 0.1042 Loss_G: 0.0415 Convergence: 0.1056 k= 0.022340 lr = 0.0000250\n",
      "[8/25][4380/9765] Loss_D: 0.1058 Loss_G: 0.0394 Convergence: 0.1099 k= 0.022347 lr = 0.0000250\n",
      "[8/25][4390/9765] Loss_D: 0.1006 Loss_G: 0.0386 Convergence: 0.1035 k= 0.022372 lr = 0.0000250\n",
      "[8/25][4400/9765] Loss_D: 0.0921 Loss_G: 0.0381 Convergence: 0.0938 k= 0.022369 lr = 0.0000250\n",
      "[8/25][4410/9765] Loss_D: 0.1035 Loss_G: 0.0415 Convergence: 0.1047 k= 0.022373 lr = 0.0000250\n",
      "[8/25][4420/9765] Loss_D: 0.1050 Loss_G: 0.0395 Convergence: 0.1086 k= 0.022370 lr = 0.0000250\n",
      "[8/25][4430/9765] Loss_D: 0.0950 Loss_G: 0.0384 Convergence: 0.0959 k= 0.022384 lr = 0.0000250\n",
      "[8/25][4440/9765] Loss_D: 0.0994 Loss_G: 0.0357 Convergence: 0.1047 k= 0.022409 lr = 0.0000250\n",
      "[8/25][4450/9765] Loss_D: 0.1014 Loss_G: 0.0393 Convergence: 0.1038 k= 0.022425 lr = 0.0000250\n",
      "[8/25][4460/9765] Loss_D: 0.0967 Loss_G: 0.0471 Convergence: 0.1057 k= 0.022393 lr = 0.0000250\n",
      "[8/25][4470/9765] Loss_D: 0.1031 Loss_G: 0.0443 Convergence: 0.1067 k= 0.022364 lr = 0.0000250\n",
      "[8/25][4480/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1012 k= 0.022367 lr = 0.0000250\n",
      "[8/25][4490/9765] Loss_D: 0.0930 Loss_G: 0.0428 Convergence: 0.0991 k= 0.022379 lr = 0.0000250\n",
      "[8/25][4500/9765] Loss_D: 0.1040 Loss_G: 0.0407 Convergence: 0.1061 k= 0.022381 lr = 0.0000250\n",
      "[8/25][4510/9765] Loss_D: 0.1030 Loss_G: 0.0465 Convergence: 0.1089 k= 0.022357 lr = 0.0000250\n",
      "[8/25][4520/9765] Loss_D: 0.1135 Loss_G: 0.0431 Convergence: 0.1171 k= 0.022358 lr = 0.0000250\n",
      "[8/25][4530/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1009 k= 0.022369 lr = 0.0000250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][4540/9765] Loss_D: 0.1000 Loss_G: 0.0399 Convergence: 0.1013 k= 0.022387 lr = 0.0000250\n",
      "[8/25][4550/9765] Loss_D: 0.0986 Loss_G: 0.0427 Convergence: 0.1024 k= 0.022379 lr = 0.0000250\n",
      "[8/25][4560/9765] Loss_D: 0.0919 Loss_G: 0.0367 Convergence: 0.0932 k= 0.022360 lr = 0.0000250\n",
      "[8/25][4570/9765] Loss_D: 0.0930 Loss_G: 0.0408 Convergence: 0.0971 k= 0.022370 lr = 0.0000250\n",
      "[8/25][4580/9765] Loss_D: 0.0966 Loss_G: 0.0437 Convergence: 0.1023 k= 0.022364 lr = 0.0000250\n",
      "[8/25][4590/9765] Loss_D: 0.1082 Loss_G: 0.0415 Convergence: 0.1113 k= 0.022343 lr = 0.0000250\n",
      "[8/25][4600/9765] Loss_D: 0.1016 Loss_G: 0.0404 Convergence: 0.1031 k= 0.022345 lr = 0.0000250\n",
      "[8/25][4610/9765] Loss_D: 0.1024 Loss_G: 0.0384 Convergence: 0.1062 k= 0.022337 lr = 0.0000250\n",
      "[8/25][4620/9765] Loss_D: 0.1039 Loss_G: 0.0413 Convergence: 0.1055 k= 0.022334 lr = 0.0000250\n",
      "[8/25][4630/9765] Loss_D: 0.1008 Loss_G: 0.0441 Convergence: 0.1051 k= 0.022307 lr = 0.0000250\n",
      "[8/25][4640/9765] Loss_D: 0.1041 Loss_G: 0.0427 Convergence: 0.1057 k= 0.022303 lr = 0.0000250\n",
      "[8/25][4650/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0981 k= 0.022299 lr = 0.0000250\n",
      "[8/25][4660/9765] Loss_D: 0.0955 Loss_G: 0.0425 Convergence: 0.1004 k= 0.022290 lr = 0.0000250\n",
      "[8/25][4670/9765] Loss_D: 0.0959 Loss_G: 0.0433 Convergence: 0.1014 k= 0.022274 lr = 0.0000250\n",
      "[8/25][4680/9765] Loss_D: 0.1025 Loss_G: 0.0369 Convergence: 0.1078 k= 0.022269 lr = 0.0000250\n",
      "[8/25][4690/9765] Loss_D: 0.0953 Loss_G: 0.0430 Convergence: 0.1007 k= 0.022263 lr = 0.0000250\n",
      "[8/25][4700/9765] Loss_D: 0.0970 Loss_G: 0.0393 Convergence: 0.0981 k= 0.022252 lr = 0.0000250\n",
      "[8/25][4710/9765] Loss_D: 0.1088 Loss_G: 0.0406 Convergence: 0.1130 k= 0.022259 lr = 0.0000250\n",
      "[8/25][4720/9765] Loss_D: 0.1105 Loss_G: 0.0380 Convergence: 0.1179 k= 0.022274 lr = 0.0000250\n",
      "[8/25][4730/9765] Loss_D: 0.0999 Loss_G: 0.0400 Convergence: 0.1011 k= 0.022281 lr = 0.0000250\n",
      "[8/25][4740/9765] Loss_D: 0.1040 Loss_G: 0.0374 Convergence: 0.1093 k= 0.022292 lr = 0.0000250\n",
      "[8/25][4750/9765] Loss_D: 0.0934 Loss_G: 0.0417 Convergence: 0.0983 k= 0.022289 lr = 0.0000250\n",
      "[8/25][4760/9765] Loss_D: 0.0940 Loss_G: 0.0354 Convergence: 0.0973 k= 0.022309 lr = 0.0000250\n",
      "[8/25][4770/9765] Loss_D: 0.0930 Loss_G: 0.0396 Convergence: 0.0959 k= 0.022331 lr = 0.0000250\n",
      "[8/25][4780/9765] Loss_D: 0.1021 Loss_G: 0.0447 Convergence: 0.1065 k= 0.022316 lr = 0.0000250\n",
      "[8/25][4790/9765] Loss_D: 0.0972 Loss_G: 0.0413 Convergence: 0.1002 k= 0.022280 lr = 0.0000250\n",
      "[8/25][4800/9765] Loss_D: 0.0961 Loss_G: 0.0420 Convergence: 0.1002 k= 0.022265 lr = 0.0000250\n",
      "[8/25][4810/9765] Loss_D: 0.0929 Loss_G: 0.0427 Convergence: 0.0990 k= 0.022262 lr = 0.0000250\n",
      "[8/25][4820/9765] Loss_D: 0.0981 Loss_G: 0.0420 Convergence: 0.1015 k= 0.022256 lr = 0.0000250\n",
      "[8/25][4830/9765] Loss_D: 0.0969 Loss_G: 0.0399 Convergence: 0.0986 k= 0.022249 lr = 0.0000250\n",
      "[8/25][4840/9765] Loss_D: 0.1034 Loss_G: 0.0382 Convergence: 0.1077 k= 0.022246 lr = 0.0000250\n",
      "[8/25][4850/9765] Loss_D: 0.0969 Loss_G: 0.0414 Convergence: 0.1001 k= 0.022250 lr = 0.0000250\n",
      "[8/25][4860/9765] Loss_D: 0.1017 Loss_G: 0.0422 Convergence: 0.1039 k= 0.022250 lr = 0.0000250\n",
      "[8/25][4870/9765] Loss_D: 0.1006 Loss_G: 0.0394 Convergence: 0.1028 k= 0.022246 lr = 0.0000250\n",
      "[8/25][4880/9765] Loss_D: 0.0844 Loss_G: 0.0363 Convergence: 0.0875 k= 0.022250 lr = 0.0000250\n",
      "[8/25][4890/9765] Loss_D: 0.0992 Loss_G: 0.0384 Convergence: 0.1017 k= 0.022273 lr = 0.0000250\n",
      "[8/25][4900/9765] Loss_D: 0.0960 Loss_G: 0.0407 Convergence: 0.0988 k= 0.022270 lr = 0.0000250\n",
      "[8/25][4910/9765] Loss_D: 0.1049 Loss_G: 0.0405 Convergence: 0.1076 k= 0.022271 lr = 0.0000250\n",
      "[8/25][4920/9765] Loss_D: 0.1080 Loss_G: 0.0377 Convergence: 0.1146 k= 0.022269 lr = 0.0000250\n",
      "[8/25][4930/9765] Loss_D: 0.0924 Loss_G: 0.0371 Convergence: 0.0934 k= 0.022283 lr = 0.0000250\n",
      "[8/25][4940/9765] Loss_D: 0.0935 Loss_G: 0.0402 Convergence: 0.0969 k= 0.022289 lr = 0.0000250\n",
      "[8/25][4950/9765] Loss_D: 0.1005 Loss_G: 0.0457 Convergence: 0.1066 k= 0.022267 lr = 0.0000250\n",
      "[8/25][4960/9765] Loss_D: 0.0949 Loss_G: 0.0411 Convergence: 0.0986 k= 0.022227 lr = 0.0000250\n",
      "[8/25][4970/9765] Loss_D: 0.1029 Loss_G: 0.0385 Convergence: 0.1067 k= 0.022241 lr = 0.0000250\n",
      "[8/25][4980/9765] Loss_D: 0.1024 Loss_G: 0.0404 Convergence: 0.1042 k= 0.022250 lr = 0.0000250\n",
      "[8/25][4990/9765] Loss_D: 0.0998 Loss_G: 0.0411 Convergence: 0.1015 k= 0.022245 lr = 0.0000250\n",
      "[8/25][5000/9765] Loss_D: 0.0956 Loss_G: 0.0397 Convergence: 0.0976 k= 0.022233 lr = 0.0000250\n",
      "[8/25][5010/9765] Loss_D: 0.0925 Loss_G: 0.0411 Convergence: 0.0972 k= 0.022236 lr = 0.0000250\n",
      "[8/25][5020/9765] Loss_D: 0.0960 Loss_G: 0.0427 Convergence: 0.1009 k= 0.022201 lr = 0.0000250\n",
      "[8/25][5030/9765] Loss_D: 0.0970 Loss_G: 0.0371 Convergence: 0.0999 k= 0.022203 lr = 0.0000250\n",
      "[8/25][5040/9765] Loss_D: 0.0950 Loss_G: 0.0379 Convergence: 0.0964 k= 0.022232 lr = 0.0000250\n",
      "[8/25][5050/9765] Loss_D: 0.0967 Loss_G: 0.0383 Convergence: 0.0984 k= 0.022232 lr = 0.0000250\n",
      "[8/25][5060/9765] Loss_D: 0.1031 Loss_G: 0.0424 Convergence: 0.1048 k= 0.022232 lr = 0.0000250\n",
      "[8/25][5070/9765] Loss_D: 0.1014 Loss_G: 0.0413 Convergence: 0.1027 k= 0.022225 lr = 0.0000250\n",
      "[8/25][5080/9765] Loss_D: 0.0896 Loss_G: 0.0380 Convergence: 0.0922 k= 0.022224 lr = 0.0000250\n",
      "[8/25][5090/9765] Loss_D: 0.1040 Loss_G: 0.0415 Convergence: 0.1054 k= 0.022236 lr = 0.0000250\n",
      "[8/25][5100/9765] Loss_D: 0.0930 Loss_G: 0.0382 Convergence: 0.0946 k= 0.022244 lr = 0.0000250\n",
      "[8/25][5110/9765] Loss_D: 0.0933 Loss_G: 0.0402 Convergence: 0.0966 k= 0.022243 lr = 0.0000250\n",
      "[8/25][5120/9765] Loss_D: 0.1033 Loss_G: 0.0447 Convergence: 0.1073 k= 0.022216 lr = 0.0000250\n",
      "[8/25][5130/9765] Loss_D: 0.0857 Loss_G: 0.0450 Convergence: 0.0970 k= 0.022191 lr = 0.0000250\n",
      "[8/25][5140/9765] Loss_D: 0.0901 Loss_G: 0.0421 Convergence: 0.0968 k= 0.022165 lr = 0.0000250\n",
      "[8/25][5150/9765] Loss_D: 0.0874 Loss_G: 0.0346 Convergence: 0.0888 k= 0.022198 lr = 0.0000250\n",
      "[8/25][5160/9765] Loss_D: 0.1019 Loss_G: 0.0363 Convergence: 0.1075 k= 0.022231 lr = 0.0000250\n",
      "[8/25][5170/9765] Loss_D: 0.1070 Loss_G: 0.0453 Convergence: 0.1100 k= 0.022231 lr = 0.0000250\n",
      "[8/25][5180/9765] Loss_D: 0.1061 Loss_G: 0.0396 Convergence: 0.1103 k= 0.022206 lr = 0.0000250\n",
      "[8/25][5190/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1057 k= 0.022202 lr = 0.0000250\n",
      "[8/25][5200/9765] Loss_D: 0.1009 Loss_G: 0.0370 Convergence: 0.1054 k= 0.022196 lr = 0.0000250\n",
      "[8/25][5210/9765] Loss_D: 0.1121 Loss_G: 0.0412 Convergence: 0.1169 k= 0.022192 lr = 0.0000250\n",
      "[8/25][5220/9765] Loss_D: 0.0996 Loss_G: 0.0370 Convergence: 0.1035 k= 0.022200 lr = 0.0000250\n",
      "[8/25][5230/9765] Loss_D: 0.1003 Loss_G: 0.0377 Convergence: 0.1039 k= 0.022233 lr = 0.0000250\n",
      "[8/25][5240/9765] Loss_D: 0.1113 Loss_G: 0.0456 Convergence: 0.1129 k= 0.022240 lr = 0.0000250\n",
      "[8/25][5250/9765] Loss_D: 0.0922 Loss_G: 0.0397 Convergence: 0.0955 k= 0.022222 lr = 0.0000250\n",
      "[8/25][5260/9765] Loss_D: 0.0934 Loss_G: 0.0401 Convergence: 0.0967 k= 0.022222 lr = 0.0000250\n",
      "[8/25][5270/9765] Loss_D: 0.1002 Loss_G: 0.0412 Convergence: 0.1018 k= 0.022222 lr = 0.0000250\n",
      "[8/25][5280/9765] Loss_D: 0.0926 Loss_G: 0.0398 Convergence: 0.0958 k= 0.022214 lr = 0.0000250\n",
      "[8/25][5290/9765] Loss_D: 0.0945 Loss_G: 0.0415 Convergence: 0.0987 k= 0.022237 lr = 0.0000250\n",
      "[8/25][5300/9765] Loss_D: 0.1044 Loss_G: 0.0438 Convergence: 0.1070 k= 0.022224 lr = 0.0000250\n",
      "[8/25][5310/9765] Loss_D: 0.0964 Loss_G: 0.0348 Convergence: 0.1013 k= 0.022221 lr = 0.0000250\n",
      "[8/25][5320/9765] Loss_D: 0.0947 Loss_G: 0.0365 Convergence: 0.0973 k= 0.022237 lr = 0.0000250\n",
      "[8/25][5330/9765] Loss_D: 0.0953 Loss_G: 0.0340 Convergence: 0.1006 k= 0.022254 lr = 0.0000250\n",
      "[8/25][5340/9765] Loss_D: 0.1006 Loss_G: 0.0414 Convergence: 0.1023 k= 0.022266 lr = 0.0000250\n",
      "[8/25][5350/9765] Loss_D: 0.0951 Loss_G: 0.0397 Convergence: 0.0973 k= 0.022254 lr = 0.0000250\n",
      "[8/25][5360/9765] Loss_D: 0.1045 Loss_G: 0.0387 Convergence: 0.1087 k= 0.022258 lr = 0.0000250\n",
      "[8/25][5370/9765] Loss_D: 0.0993 Loss_G: 0.0390 Convergence: 0.1012 k= 0.022266 lr = 0.0000250\n",
      "[8/25][5380/9765] Loss_D: 0.1019 Loss_G: 0.0414 Convergence: 0.1031 k= 0.022261 lr = 0.0000250\n",
      "[8/25][5390/9765] Loss_D: 0.0982 Loss_G: 0.0413 Convergence: 0.1008 k= 0.022237 lr = 0.0000250\n",
      "[8/25][5400/9765] Loss_D: 0.0956 Loss_G: 0.0395 Convergence: 0.0974 k= 0.022238 lr = 0.0000250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][5410/9765] Loss_D: 0.0960 Loss_G: 0.0377 Convergence: 0.0979 k= 0.022246 lr = 0.0000250\n",
      "[8/25][5420/9765] Loss_D: 0.0991 Loss_G: 0.0383 Convergence: 0.1016 k= 0.022268 lr = 0.0000250\n",
      "[8/25][5430/9765] Loss_D: 0.1048 Loss_G: 0.0410 Convergence: 0.1070 k= 0.022270 lr = 0.0000250\n",
      "[8/25][5440/9765] Loss_D: 0.1042 Loss_G: 0.0407 Convergence: 0.1063 k= 0.022269 lr = 0.0000250\n",
      "[8/25][5450/9765] Loss_D: 0.1088 Loss_G: 0.0405 Convergence: 0.1130 k= 0.022242 lr = 0.0000250\n",
      "[8/25][5460/9765] Loss_D: 0.1035 Loss_G: 0.0365 Convergence: 0.1095 k= 0.022246 lr = 0.0000250\n",
      "[8/25][5470/9765] Loss_D: 0.0970 Loss_G: 0.0385 Convergence: 0.0986 k= 0.022259 lr = 0.0000250\n",
      "[8/25][5480/9765] Loss_D: 0.0959 Loss_G: 0.0451 Convergence: 0.1033 k= 0.022242 lr = 0.0000250\n",
      "[8/25][5490/9765] Loss_D: 0.0974 Loss_G: 0.0368 Convergence: 0.1008 k= 0.022259 lr = 0.0000250\n",
      "[8/25][5500/9765] Loss_D: 0.0916 Loss_G: 0.0365 Convergence: 0.0930 k= 0.022262 lr = 0.0000250\n",
      "[8/25][5510/9765] Loss_D: 0.0915 Loss_G: 0.0396 Convergence: 0.0950 k= 0.022278 lr = 0.0000250\n",
      "[8/25][5520/9765] Loss_D: 0.1026 Loss_G: 0.0390 Convergence: 0.1059 k= 0.022285 lr = 0.0000250\n",
      "[8/25][5530/9765] Loss_D: 0.1045 Loss_G: 0.0398 Convergence: 0.1076 k= 0.022286 lr = 0.0000250\n",
      "[8/25][5540/9765] Loss_D: 0.0929 Loss_G: 0.0427 Convergence: 0.0990 k= 0.022268 lr = 0.0000250\n",
      "[8/25][5550/9765] Loss_D: 0.1017 Loss_G: 0.0445 Convergence: 0.1061 k= 0.022211 lr = 0.0000250\n",
      "[8/25][5560/9765] Loss_D: 0.0979 Loss_G: 0.0386 Convergence: 0.0997 k= 0.022191 lr = 0.0000250\n",
      "[8/25][5570/9765] Loss_D: 0.1079 Loss_G: 0.0396 Convergence: 0.1125 k= 0.022225 lr = 0.0000250\n",
      "[8/25][5580/9765] Loss_D: 0.0914 Loss_G: 0.0364 Convergence: 0.0926 k= 0.022247 lr = 0.0000250\n",
      "[8/25][5590/9765] Loss_D: 0.1008 Loss_G: 0.0445 Convergence: 0.1055 k= 0.022223 lr = 0.0000250\n",
      "[8/25][5600/9765] Loss_D: 0.1050 Loss_G: 0.0433 Convergence: 0.1068 k= 0.022194 lr = 0.0000250\n",
      "[8/25][5610/9765] Loss_D: 0.0972 Loss_G: 0.0437 Convergence: 0.1026 k= 0.022165 lr = 0.0000250\n",
      "[8/25][5620/9765] Loss_D: 0.0989 Loss_G: 0.0422 Convergence: 0.1020 k= 0.022151 lr = 0.0000250\n",
      "[8/25][5630/9765] Loss_D: 0.0951 Loss_G: 0.0368 Convergence: 0.0976 k= 0.022143 lr = 0.0000250\n",
      "[8/25][5640/9765] Loss_D: 0.0990 Loss_G: 0.0411 Convergence: 0.1010 k= 0.022165 lr = 0.0000250\n",
      "[8/25][5650/9765] Loss_D: 0.0935 Loss_G: 0.0429 Convergence: 0.0996 k= 0.022147 lr = 0.0000250\n",
      "[8/25][5660/9765] Loss_D: 0.1072 Loss_G: 0.0419 Convergence: 0.1094 k= 0.022128 lr = 0.0000250\n",
      "[8/25][5670/9765] Loss_D: 0.1073 Loss_G: 0.0438 Convergence: 0.1087 k= 0.022117 lr = 0.0000250\n",
      "[8/25][5680/9765] Loss_D: 0.0938 Loss_G: 0.0349 Convergence: 0.0975 k= 0.022130 lr = 0.0000250\n",
      "[8/25][5690/9765] Loss_D: 0.1007 Loss_G: 0.0393 Convergence: 0.1029 k= 0.022164 lr = 0.0000250\n",
      "[8/25][5700/9765] Loss_D: 0.1045 Loss_G: 0.0493 Convergence: 0.1126 k= 0.022143 lr = 0.0000250\n",
      "[8/25][5710/9765] Loss_D: 0.1030 Loss_G: 0.0495 Convergence: 0.1119 k= 0.022054 lr = 0.0000250\n",
      "[8/25][5720/9765] Loss_D: 0.1023 Loss_G: 0.0382 Convergence: 0.1063 k= 0.022022 lr = 0.0000250\n",
      "[8/25][5730/9765] Loss_D: 0.0862 Loss_G: 0.0358 Convergence: 0.0879 k= 0.022042 lr = 0.0000250\n",
      "[8/25][5740/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1039 k= 0.022058 lr = 0.0000250\n",
      "[8/25][5750/9765] Loss_D: 0.0950 Loss_G: 0.0381 Convergence: 0.0961 k= 0.022093 lr = 0.0000250\n",
      "[8/25][5760/9765] Loss_D: 0.1071 Loss_G: 0.0476 Convergence: 0.1125 k= 0.022061 lr = 0.0000250\n",
      "[8/25][5770/9765] Loss_D: 0.1094 Loss_G: 0.0410 Convergence: 0.1134 k= 0.022031 lr = 0.0000250\n",
      "[8/25][5780/9765] Loss_D: 0.1107 Loss_G: 0.0426 Convergence: 0.1135 k= 0.022035 lr = 0.0000250\n",
      "[8/25][5790/9765] Loss_D: 0.1080 Loss_G: 0.0422 Convergence: 0.1103 k= 0.022032 lr = 0.0000250\n",
      "[8/25][5800/9765] Loss_D: 0.0992 Loss_G: 0.0407 Convergence: 0.1008 k= 0.022031 lr = 0.0000250\n",
      "[8/25][5810/9765] Loss_D: 0.1021 Loss_G: 0.0397 Convergence: 0.1043 k= 0.022039 lr = 0.0000250\n",
      "[8/25][5820/9765] Loss_D: 0.0982 Loss_G: 0.0413 Convergence: 0.1007 k= 0.022036 lr = 0.0000250\n",
      "[8/25][5830/9765] Loss_D: 0.0974 Loss_G: 0.0367 Convergence: 0.1008 k= 0.022048 lr = 0.0000250\n",
      "[8/25][5840/9765] Loss_D: 0.1094 Loss_G: 0.0375 Convergence: 0.1169 k= 0.022075 lr = 0.0000250\n",
      "[8/25][5850/9765] Loss_D: 0.0930 Loss_G: 0.0386 Convergence: 0.0949 k= 0.022072 lr = 0.0000250\n",
      "[8/25][5860/9765] Loss_D: 0.0986 Loss_G: 0.0407 Convergence: 0.1005 k= 0.022048 lr = 0.0000250\n",
      "[8/25][5870/9765] Loss_D: 0.1111 Loss_G: 0.0433 Convergence: 0.1135 k= 0.022036 lr = 0.0000250\n",
      "[8/25][5880/9765] Loss_D: 0.1031 Loss_G: 0.0452 Convergence: 0.1075 k= 0.022017 lr = 0.0000238\n",
      "[8/25][5890/9765] Loss_D: 0.0988 Loss_G: 0.0389 Convergence: 0.1006 k= 0.022021 lr = 0.0000238\n",
      "[8/25][5900/9765] Loss_D: 0.1044 Loss_G: 0.0378 Convergence: 0.1094 k= 0.022033 lr = 0.0000238\n",
      "[8/25][5910/9765] Loss_D: 0.0861 Loss_G: 0.0394 Convergence: 0.0916 k= 0.022031 lr = 0.0000238\n",
      "[8/25][5920/9765] Loss_D: 0.1028 Loss_G: 0.0378 Convergence: 0.1073 k= 0.022052 lr = 0.0000238\n",
      "[8/25][5930/9765] Loss_D: 0.0978 Loss_G: 0.0363 Convergence: 0.1019 k= 0.022073 lr = 0.0000238\n",
      "[8/25][5940/9765] Loss_D: 0.1030 Loss_G: 0.0422 Convergence: 0.1045 k= 0.022098 lr = 0.0000238\n",
      "[8/25][5950/9765] Loss_D: 0.1026 Loss_G: 0.0372 Convergence: 0.1075 k= 0.022083 lr = 0.0000238\n",
      "[8/25][5960/9765] Loss_D: 0.0981 Loss_G: 0.0403 Convergence: 0.0997 k= 0.022082 lr = 0.0000238\n",
      "[8/25][5970/9765] Loss_D: 0.1030 Loss_G: 0.0402 Convergence: 0.1053 k= 0.022088 lr = 0.0000238\n",
      "[8/25][5980/9765] Loss_D: 0.1066 Loss_G: 0.0373 Convergence: 0.1130 k= 0.022107 lr = 0.0000238\n",
      "[8/25][5990/9765] Loss_D: 0.1010 Loss_G: 0.0421 Convergence: 0.1032 k= 0.022112 lr = 0.0000238\n",
      "[8/25][6000/9765] Loss_D: 0.1062 Loss_G: 0.0406 Convergence: 0.1094 k= 0.022104 lr = 0.0000238\n",
      "[8/25][6010/9765] Loss_D: 0.0928 Loss_G: 0.0394 Convergence: 0.0956 k= 0.022087 lr = 0.0000238\n",
      "[8/25][6020/9765] Loss_D: 0.1040 Loss_G: 0.0402 Convergence: 0.1066 k= 0.022087 lr = 0.0000238\n",
      "[8/25][6030/9765] Loss_D: 0.0917 Loss_G: 0.0394 Convergence: 0.0950 k= 0.022069 lr = 0.0000238\n",
      "[8/25][6040/9765] Loss_D: 0.1027 Loss_G: 0.0402 Convergence: 0.1048 k= 0.022069 lr = 0.0000238\n",
      "[8/25][6050/9765] Loss_D: 0.1050 Loss_G: 0.0395 Convergence: 0.1087 k= 0.022064 lr = 0.0000238\n",
      "[8/25][6060/9765] Loss_D: 0.1030 Loss_G: 0.0399 Convergence: 0.1055 k= 0.022072 lr = 0.0000238\n",
      "[8/25][6070/9765] Loss_D: 0.0924 Loss_G: 0.0417 Convergence: 0.0976 k= 0.022074 lr = 0.0000238\n",
      "[8/25][6080/9765] Loss_D: 0.1063 Loss_G: 0.0387 Convergence: 0.1113 k= 0.022097 lr = 0.0000238\n",
      "[8/25][6090/9765] Loss_D: 0.0940 Loss_G: 0.0447 Convergence: 0.1016 k= 0.022089 lr = 0.0000238\n",
      "[8/25][6100/9765] Loss_D: 0.1012 Loss_G: 0.0436 Convergence: 0.1050 k= 0.022056 lr = 0.0000238\n",
      "[8/25][6110/9765] Loss_D: 0.0973 Loss_G: 0.0396 Convergence: 0.0985 k= 0.022030 lr = 0.0000238\n",
      "[8/25][6120/9765] Loss_D: 0.0928 Loss_G: 0.0377 Convergence: 0.0939 k= 0.022046 lr = 0.0000238\n",
      "[8/25][6130/9765] Loss_D: 0.0918 Loss_G: 0.0395 Convergence: 0.0951 k= 0.022057 lr = 0.0000238\n",
      "[8/25][6140/9765] Loss_D: 0.0989 Loss_G: 0.0432 Convergence: 0.1031 k= 0.022034 lr = 0.0000238\n",
      "[8/25][6150/9765] Loss_D: 0.1052 Loss_G: 0.0391 Convergence: 0.1094 k= 0.022015 lr = 0.0000238\n",
      "[8/25][6160/9765] Loss_D: 0.1020 Loss_G: 0.0353 Convergence: 0.1086 k= 0.022028 lr = 0.0000238\n",
      "[8/25][6170/9765] Loss_D: 0.1036 Loss_G: 0.0365 Convergence: 0.1097 k= 0.022077 lr = 0.0000238\n",
      "[8/25][6180/9765] Loss_D: 0.0964 Loss_G: 0.0396 Convergence: 0.0980 k= 0.022082 lr = 0.0000238\n",
      "[8/25][6190/9765] Loss_D: 0.0946 Loss_G: 0.0380 Convergence: 0.0956 k= 0.022072 lr = 0.0000238\n",
      "[8/25][6200/9765] Loss_D: 0.0984 Loss_G: 0.0402 Convergence: 0.0998 k= 0.022083 lr = 0.0000238\n",
      "[8/25][6210/9765] Loss_D: 0.0868 Loss_G: 0.0391 Convergence: 0.0917 k= 0.022107 lr = 0.0000238\n",
      "[8/25][6220/9765] Loss_D: 0.1058 Loss_G: 0.0398 Convergence: 0.1094 k= 0.022111 lr = 0.0000238\n",
      "[8/25][6230/9765] Loss_D: 0.0982 Loss_G: 0.0428 Convergence: 0.1023 k= 0.022078 lr = 0.0000238\n",
      "[8/25][6240/9765] Loss_D: 0.0942 Loss_G: 0.0400 Convergence: 0.0971 k= 0.022071 lr = 0.0000238\n",
      "[8/25][6250/9765] Loss_D: 0.0908 Loss_G: 0.0386 Convergence: 0.0936 k= 0.022077 lr = 0.0000238\n",
      "[8/25][6260/9765] Loss_D: 0.0982 Loss_G: 0.0390 Convergence: 0.0996 k= 0.022092 lr = 0.0000238\n",
      "[8/25][6270/9765] Loss_D: 0.0977 Loss_G: 0.0426 Convergence: 0.1017 k= 0.022122 lr = 0.0000238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][6280/9765] Loss_D: 0.1029 Loss_G: 0.0399 Convergence: 0.1054 k= 0.022116 lr = 0.0000238\n",
      "[8/25][6290/9765] Loss_D: 0.1056 Loss_G: 0.0389 Convergence: 0.1102 k= 0.022136 lr = 0.0000238\n",
      "[8/25][6300/9765] Loss_D: 0.1058 Loss_G: 0.0430 Convergence: 0.1070 k= 0.022131 lr = 0.0000238\n",
      "[8/25][6310/9765] Loss_D: 0.0980 Loss_G: 0.0397 Convergence: 0.0990 k= 0.022116 lr = 0.0000238\n",
      "[8/25][6320/9765] Loss_D: 0.0949 Loss_G: 0.0383 Convergence: 0.0957 k= 0.022118 lr = 0.0000238\n",
      "[8/25][6330/9765] Loss_D: 0.0963 Loss_G: 0.0360 Convergence: 0.0999 k= 0.022149 lr = 0.0000238\n",
      "[8/25][6340/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0990 k= 0.022172 lr = 0.0000238\n",
      "[8/25][6350/9765] Loss_D: 0.1100 Loss_G: 0.0452 Convergence: 0.1118 k= 0.022190 lr = 0.0000238\n",
      "[8/25][6360/9765] Loss_D: 0.0965 Loss_G: 0.0379 Convergence: 0.0985 k= 0.022172 lr = 0.0000238\n",
      "[8/25][6370/9765] Loss_D: 0.0922 Loss_G: 0.0375 Convergence: 0.0934 k= 0.022193 lr = 0.0000238\n",
      "[8/25][6380/9765] Loss_D: 0.0979 Loss_G: 0.0375 Convergence: 0.1008 k= 0.022210 lr = 0.0000238\n",
      "[8/25][6390/9765] Loss_D: 0.0943 Loss_G: 0.0359 Convergence: 0.0973 k= 0.022218 lr = 0.0000238\n",
      "[8/25][6400/9765] Loss_D: 0.0953 Loss_G: 0.0366 Convergence: 0.0980 k= 0.022220 lr = 0.0000238\n",
      "[8/25][6410/9765] Loss_D: 0.0981 Loss_G: 0.0418 Convergence: 0.1012 k= 0.022224 lr = 0.0000238\n",
      "[8/25][6420/9765] Loss_D: 0.0994 Loss_G: 0.0412 Convergence: 0.1014 k= 0.022209 lr = 0.0000238\n",
      "[8/25][6430/9765] Loss_D: 0.1022 Loss_G: 0.0393 Convergence: 0.1049 k= 0.022203 lr = 0.0000238\n",
      "[8/25][6440/9765] Loss_D: 0.0935 Loss_G: 0.0363 Convergence: 0.0956 k= 0.022237 lr = 0.0000238\n",
      "[8/25][6450/9765] Loss_D: 0.1018 Loss_G: 0.0404 Convergence: 0.1033 k= 0.022246 lr = 0.0000238\n",
      "[8/25][6460/9765] Loss_D: 0.0954 Loss_G: 0.0412 Convergence: 0.0990 k= 0.022225 lr = 0.0000238\n",
      "[8/25][6470/9765] Loss_D: 0.1012 Loss_G: 0.0437 Convergence: 0.1049 k= 0.022213 lr = 0.0000238\n",
      "[8/25][6480/9765] Loss_D: 0.1086 Loss_G: 0.0391 Convergence: 0.1141 k= 0.022222 lr = 0.0000238\n",
      "[8/25][6490/9765] Loss_D: 0.1030 Loss_G: 0.0382 Convergence: 0.1072 k= 0.022218 lr = 0.0000238\n",
      "[8/25][6500/9765] Loss_D: 0.0896 Loss_G: 0.0389 Convergence: 0.0931 k= 0.022227 lr = 0.0000238\n",
      "[8/25][6510/9765] Loss_D: 0.0918 Loss_G: 0.0415 Convergence: 0.0970 k= 0.022225 lr = 0.0000238\n",
      "[8/25][6520/9765] Loss_D: 0.0960 Loss_G: 0.0439 Convergence: 0.1021 k= 0.022186 lr = 0.0000238\n",
      "[8/25][6530/9765] Loss_D: 0.0926 Loss_G: 0.0391 Convergence: 0.0951 k= 0.022170 lr = 0.0000238\n",
      "[8/25][6540/9765] Loss_D: 0.0862 Loss_G: 0.0371 Convergence: 0.0892 k= 0.022195 lr = 0.0000238\n",
      "[8/25][6550/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0993 k= 0.022217 lr = 0.0000238\n",
      "[8/25][6560/9765] Loss_D: 0.0913 Loss_G: 0.0405 Convergence: 0.0958 k= 0.022214 lr = 0.0000238\n",
      "[8/25][6570/9765] Loss_D: 0.0956 Loss_G: 0.0432 Convergence: 0.1011 k= 0.022184 lr = 0.0000238\n",
      "[8/25][6580/9765] Loss_D: 0.0956 Loss_G: 0.0411 Convergence: 0.0989 k= 0.022185 lr = 0.0000238\n",
      "[8/25][6590/9765] Loss_D: 0.0959 Loss_G: 0.0370 Convergence: 0.0984 k= 0.022186 lr = 0.0000238\n",
      "[8/25][6600/9765] Loss_D: 0.0948 Loss_G: 0.0401 Convergence: 0.0975 k= 0.022179 lr = 0.0000238\n",
      "[8/25][6610/9765] Loss_D: 0.1006 Loss_G: 0.0428 Convergence: 0.1037 k= 0.022168 lr = 0.0000238\n",
      "[8/25][6620/9765] Loss_D: 0.0993 Loss_G: 0.0439 Convergence: 0.1041 k= 0.022147 lr = 0.0000238\n",
      "[8/25][6630/9765] Loss_D: 0.1021 Loss_G: 0.0388 Convergence: 0.1054 k= 0.022132 lr = 0.0000238\n",
      "[8/25][6640/9765] Loss_D: 0.0990 Loss_G: 0.0532 Convergence: 0.1132 k= 0.022065 lr = 0.0000238\n",
      "[8/25][6650/9765] Loss_D: 0.1001 Loss_G: 0.0394 Convergence: 0.1019 k= 0.022025 lr = 0.0000238\n",
      "[8/25][6660/9765] Loss_D: 0.0971 Loss_G: 0.0350 Convergence: 0.1020 k= 0.022049 lr = 0.0000238\n",
      "[8/25][6670/9765] Loss_D: 0.1028 Loss_G: 0.0395 Convergence: 0.1056 k= 0.022085 lr = 0.0000238\n",
      "[8/25][6680/9765] Loss_D: 0.0935 Loss_G: 0.0382 Convergence: 0.0948 k= 0.022095 lr = 0.0000238\n",
      "[8/25][6690/9765] Loss_D: 0.1026 Loss_G: 0.0450 Convergence: 0.1071 k= 0.022107 lr = 0.0000238\n",
      "[8/25][6700/9765] Loss_D: 0.1066 Loss_G: 0.0421 Convergence: 0.1085 k= 0.022090 lr = 0.0000238\n",
      "[8/25][6710/9765] Loss_D: 0.1145 Loss_G: 0.0387 Convergence: 0.1228 k= 0.022119 lr = 0.0000238\n",
      "[8/25][6720/9765] Loss_D: 0.0881 Loss_G: 0.0393 Convergence: 0.0927 k= 0.022099 lr = 0.0000238\n",
      "[8/25][6730/9765] Loss_D: 0.0940 Loss_G: 0.0387 Convergence: 0.0957 k= 0.022123 lr = 0.0000238\n",
      "[8/25][6740/9765] Loss_D: 0.1012 Loss_G: 0.0404 Convergence: 0.1025 k= 0.022156 lr = 0.0000238\n",
      "[8/25][6750/9765] Loss_D: 0.1038 Loss_G: 0.0412 Convergence: 0.1053 k= 0.022172 lr = 0.0000238\n",
      "[8/25][6760/9765] Loss_D: 0.0938 Loss_G: 0.0370 Convergence: 0.0955 k= 0.022186 lr = 0.0000238\n",
      "[8/25][6770/9765] Loss_D: 0.0910 Loss_G: 0.0389 Convergence: 0.0940 k= 0.022205 lr = 0.0000238\n",
      "[8/25][6780/9765] Loss_D: 0.1003 Loss_G: 0.0398 Convergence: 0.1018 k= 0.022215 lr = 0.0000238\n",
      "[8/25][6790/9765] Loss_D: 0.1042 Loss_G: 0.0397 Convergence: 0.1074 k= 0.022223 lr = 0.0000238\n",
      "[8/25][6800/9765] Loss_D: 0.0974 Loss_G: 0.0389 Convergence: 0.0987 k= 0.022210 lr = 0.0000238\n",
      "[8/25][6810/9765] Loss_D: 0.1024 Loss_G: 0.0364 Convergence: 0.1081 k= 0.022236 lr = 0.0000238\n",
      "[8/25][6820/9765] Loss_D: 0.0949 Loss_G: 0.0397 Convergence: 0.0972 k= 0.022254 lr = 0.0000238\n",
      "[8/25][6830/9765] Loss_D: 0.1062 Loss_G: 0.0414 Convergence: 0.1086 k= 0.022262 lr = 0.0000238\n",
      "[8/25][6840/9765] Loss_D: 0.1000 Loss_G: 0.0411 Convergence: 0.1016 k= 0.022258 lr = 0.0000238\n",
      "[8/25][6850/9765] Loss_D: 0.0969 Loss_G: 0.0378 Convergence: 0.0990 k= 0.022263 lr = 0.0000238\n",
      "[8/25][6860/9765] Loss_D: 0.0904 Loss_G: 0.0380 Convergence: 0.0928 k= 0.022276 lr = 0.0000238\n",
      "[8/25][6870/9765] Loss_D: 0.0870 Loss_G: 0.0377 Convergence: 0.0904 k= 0.022285 lr = 0.0000238\n",
      "[8/25][6880/9765] Loss_D: 0.1014 Loss_G: 0.0376 Convergence: 0.1055 k= 0.022299 lr = 0.0000238\n",
      "[8/25][6890/9765] Loss_D: 0.0991 Loss_G: 0.0384 Convergence: 0.1016 k= 0.022313 lr = 0.0000238\n",
      "[8/25][6900/9765] Loss_D: 0.0991 Loss_G: 0.0362 Convergence: 0.1038 k= 0.022341 lr = 0.0000238\n",
      "[8/25][6910/9765] Loss_D: 0.0949 Loss_G: 0.0371 Convergence: 0.0969 k= 0.022362 lr = 0.0000238\n",
      "[8/25][6920/9765] Loss_D: 0.1069 Loss_G: 0.0395 Convergence: 0.1114 k= 0.022381 lr = 0.0000238\n",
      "[8/25][6930/9765] Loss_D: 0.1011 Loss_G: 0.0432 Convergence: 0.1044 k= 0.022372 lr = 0.0000238\n",
      "[8/25][6940/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0995 k= 0.022362 lr = 0.0000238\n",
      "[8/25][6950/9765] Loss_D: 0.1091 Loss_G: 0.0405 Convergence: 0.1135 k= 0.022363 lr = 0.0000238\n",
      "[8/25][6960/9765] Loss_D: 0.0973 Loss_G: 0.0409 Convergence: 0.0998 k= 0.022359 lr = 0.0000238\n",
      "[8/25][6970/9765] Loss_D: 0.0972 Loss_G: 0.0402 Convergence: 0.0991 k= 0.022351 lr = 0.0000238\n",
      "[8/25][6980/9765] Loss_D: 0.1011 Loss_G: 0.0401 Convergence: 0.1027 k= 0.022353 lr = 0.0000238\n",
      "[8/25][6990/9765] Loss_D: 0.0962 Loss_G: 0.0406 Convergence: 0.0989 k= 0.022336 lr = 0.0000238\n",
      "[8/25][7000/9765] Loss_D: 0.1037 Loss_G: 0.0413 Convergence: 0.1050 k= 0.022331 lr = 0.0000238\n",
      "[8/25][7010/9765] Loss_D: 0.0908 Loss_G: 0.0380 Convergence: 0.0930 k= 0.022320 lr = 0.0000238\n",
      "[8/25][7020/9765] Loss_D: 0.0939 Loss_G: 0.0382 Convergence: 0.0950 k= 0.022339 lr = 0.0000238\n",
      "[8/25][7030/9765] Loss_D: 0.0994 Loss_G: 0.0407 Convergence: 0.1008 k= 0.022362 lr = 0.0000238\n",
      "[8/25][7040/9765] Loss_D: 0.1019 Loss_G: 0.0418 Convergence: 0.1035 k= 0.022357 lr = 0.0000238\n",
      "[8/25][7050/9765] Loss_D: 0.1030 Loss_G: 0.0412 Convergence: 0.1043 k= 0.022343 lr = 0.0000238\n",
      "[8/25][7060/9765] Loss_D: 0.1041 Loss_G: 0.0363 Convergence: 0.1106 k= 0.022342 lr = 0.0000238\n",
      "[8/25][7070/9765] Loss_D: 0.0971 Loss_G: 0.0391 Convergence: 0.0980 k= 0.022358 lr = 0.0000238\n",
      "[8/25][7080/9765] Loss_D: 0.0968 Loss_G: 0.0397 Convergence: 0.0983 k= 0.022358 lr = 0.0000238\n",
      "[8/25][7090/9765] Loss_D: 0.1056 Loss_G: 0.0388 Convergence: 0.1102 k= 0.022357 lr = 0.0000238\n",
      "[8/25][7100/9765] Loss_D: 0.0922 Loss_G: 0.0453 Convergence: 0.1012 k= 0.022325 lr = 0.0000238\n",
      "[8/25][7110/9765] Loss_D: 0.1011 Loss_G: 0.0399 Convergence: 0.1028 k= 0.022312 lr = 0.0000238\n",
      "[8/25][7120/9765] Loss_D: 0.0986 Loss_G: 0.0410 Convergence: 0.1007 k= 0.022340 lr = 0.0000238\n",
      "[8/25][7130/9765] Loss_D: 0.0952 Loss_G: 0.0393 Convergence: 0.0970 k= 0.022349 lr = 0.0000238\n",
      "[8/25][7140/9765] Loss_D: 0.0984 Loss_G: 0.0419 Convergence: 0.1014 k= 0.022336 lr = 0.0000238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][7150/9765] Loss_D: 0.0959 Loss_G: 0.0455 Convergence: 0.1037 k= 0.022284 lr = 0.0000238\n",
      "[8/25][7160/9765] Loss_D: 0.1031 Loss_G: 0.0411 Convergence: 0.1045 k= 0.022264 lr = 0.0000238\n",
      "[8/25][7170/9765] Loss_D: 0.1054 Loss_G: 0.0383 Convergence: 0.1105 k= 0.022298 lr = 0.0000238\n",
      "[8/25][7180/9765] Loss_D: 0.1142 Loss_G: 0.0414 Convergence: 0.1197 k= 0.022322 lr = 0.0000238\n",
      "[8/25][7190/9765] Loss_D: 0.0883 Loss_G: 0.0369 Convergence: 0.0904 k= 0.022309 lr = 0.0000238\n",
      "[8/25][7200/9765] Loss_D: 0.1021 Loss_G: 0.0414 Convergence: 0.1032 k= 0.022319 lr = 0.0000238\n",
      "[8/25][7210/9765] Loss_D: 0.1029 Loss_G: 0.0436 Convergence: 0.1059 k= 0.022313 lr = 0.0000238\n",
      "[8/25][7220/9765] Loss_D: 0.0992 Loss_G: 0.0370 Convergence: 0.1030 k= 0.022318 lr = 0.0000238\n",
      "[8/25][7230/9765] Loss_D: 0.1021 Loss_G: 0.0389 Convergence: 0.1053 k= 0.022346 lr = 0.0000238\n",
      "[8/25][7240/9765] Loss_D: 0.1069 Loss_G: 0.0396 Convergence: 0.1113 k= 0.022358 lr = 0.0000238\n",
      "[8/25][7250/9765] Loss_D: 0.0951 Loss_G: 0.0376 Convergence: 0.0967 k= 0.022351 lr = 0.0000238\n",
      "[8/25][7260/9765] Loss_D: 0.0903 Loss_G: 0.0371 Convergence: 0.0919 k= 0.022359 lr = 0.0000238\n",
      "[8/25][7270/9765] Loss_D: 0.1053 Loss_G: 0.0385 Convergence: 0.1101 k= 0.022363 lr = 0.0000238\n",
      "[8/25][7280/9765] Loss_D: 0.1008 Loss_G: 0.0363 Convergence: 0.1060 k= 0.022367 lr = 0.0000238\n",
      "[8/25][7290/9765] Loss_D: 0.0891 Loss_G: 0.0378 Convergence: 0.0918 k= 0.022370 lr = 0.0000238\n",
      "[8/25][7300/9765] Loss_D: 0.1041 Loss_G: 0.0405 Convergence: 0.1065 k= 0.022364 lr = 0.0000238\n",
      "[8/25][7310/9765] Loss_D: 0.0973 Loss_G: 0.0405 Convergence: 0.0995 k= 0.022340 lr = 0.0000238\n",
      "[8/25][7320/9765] Loss_D: 0.0927 Loss_G: 0.0387 Convergence: 0.0948 k= 0.022336 lr = 0.0000238\n",
      "[8/25][7330/9765] Loss_D: 0.1065 Loss_G: 0.0396 Convergence: 0.1108 k= 0.022357 lr = 0.0000238\n",
      "[8/25][7340/9765] Loss_D: 0.1089 Loss_G: 0.0380 Convergence: 0.1156 k= 0.022363 lr = 0.0000238\n",
      "[8/25][7350/9765] Loss_D: 0.0989 Loss_G: 0.0419 Convergence: 0.1018 k= 0.022358 lr = 0.0000238\n",
      "[8/25][7360/9765] Loss_D: 0.0971 Loss_G: 0.0390 Convergence: 0.0982 k= 0.022338 lr = 0.0000238\n",
      "[8/25][7370/9765] Loss_D: 0.1021 Loss_G: 0.0369 Convergence: 0.1072 k= 0.022363 lr = 0.0000238\n",
      "[8/25][7380/9765] Loss_D: 0.0976 Loss_G: 0.0397 Convergence: 0.0988 k= 0.022378 lr = 0.0000238\n",
      "[8/25][7390/9765] Loss_D: 0.0979 Loss_G: 0.0395 Convergence: 0.0990 k= 0.022383 lr = 0.0000238\n",
      "[8/25][7400/9765] Loss_D: 0.0973 Loss_G: 0.0389 Convergence: 0.0985 k= 0.022392 lr = 0.0000238\n",
      "[8/25][7410/9765] Loss_D: 0.1092 Loss_G: 0.0417 Convergence: 0.1124 k= 0.022415 lr = 0.0000238\n",
      "[8/25][7420/9765] Loss_D: 0.0957 Loss_G: 0.0392 Convergence: 0.0971 k= 0.022404 lr = 0.0000238\n",
      "[8/25][7430/9765] Loss_D: 0.1012 Loss_G: 0.0401 Convergence: 0.1028 k= 0.022420 lr = 0.0000238\n",
      "[8/25][7440/9765] Loss_D: 0.0929 Loss_G: 0.0374 Convergence: 0.0938 k= 0.022433 lr = 0.0000238\n",
      "[8/25][7450/9765] Loss_D: 0.1002 Loss_G: 0.0379 Convergence: 0.1035 k= 0.022456 lr = 0.0000238\n",
      "[8/25][7460/9765] Loss_D: 0.0947 Loss_G: 0.0402 Convergence: 0.0975 k= 0.022477 lr = 0.0000238\n",
      "[8/25][7470/9765] Loss_D: 0.1044 Loss_G: 0.0378 Convergence: 0.1095 k= 0.022500 lr = 0.0000238\n",
      "[8/25][7480/9765] Loss_D: 0.1042 Loss_G: 0.0396 Convergence: 0.1076 k= 0.022494 lr = 0.0000238\n",
      "[8/25][7490/9765] Loss_D: 0.1021 Loss_G: 0.0423 Convergence: 0.1041 k= 0.022501 lr = 0.0000238\n",
      "[8/25][7500/9765] Loss_D: 0.1090 Loss_G: 0.0403 Convergence: 0.1135 k= 0.022485 lr = 0.0000238\n",
      "[8/25][7510/9765] Loss_D: 0.1022 Loss_G: 0.0381 Convergence: 0.1062 k= 0.022483 lr = 0.0000238\n",
      "[8/25][7520/9765] Loss_D: 0.1001 Loss_G: 0.0427 Convergence: 0.1032 k= 0.022482 lr = 0.0000238\n",
      "[8/25][7530/9765] Loss_D: 0.0952 Loss_G: 0.0395 Convergence: 0.0971 k= 0.022487 lr = 0.0000238\n",
      "[8/25][7540/9765] Loss_D: 0.1007 Loss_G: 0.0446 Convergence: 0.1055 k= 0.022480 lr = 0.0000238\n",
      "[8/25][7550/9765] Loss_D: 0.0949 Loss_G: 0.0442 Convergence: 0.1017 k= 0.022452 lr = 0.0000238\n",
      "[8/25][7560/9765] Loss_D: 0.1012 Loss_G: 0.0407 Convergence: 0.1022 k= 0.022446 lr = 0.0000238\n",
      "[8/25][7570/9765] Loss_D: 0.0985 Loss_G: 0.0431 Convergence: 0.1027 k= 0.022442 lr = 0.0000238\n",
      "[8/25][7580/9765] Loss_D: 0.0960 Loss_G: 0.0396 Convergence: 0.0977 k= 0.022450 lr = 0.0000238\n",
      "[8/25][7590/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1006 k= 0.022453 lr = 0.0000238\n",
      "[8/25][7600/9765] Loss_D: 0.0940 Loss_G: 0.0370 Convergence: 0.0957 k= 0.022470 lr = 0.0000238\n",
      "[8/25][7610/9765] Loss_D: 0.1023 Loss_G: 0.0398 Convergence: 0.1047 k= 0.022486 lr = 0.0000238\n",
      "[8/25][7620/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0992 k= 0.022476 lr = 0.0000238\n",
      "[8/25][7630/9765] Loss_D: 0.0983 Loss_G: 0.0432 Convergence: 0.1028 k= 0.022488 lr = 0.0000238\n",
      "[8/25][7640/9765] Loss_D: 0.1125 Loss_G: 0.0441 Convergence: 0.1149 k= 0.022478 lr = 0.0000238\n",
      "[8/25][7650/9765] Loss_D: 0.1003 Loss_G: 0.0373 Convergence: 0.1043 k= 0.022471 lr = 0.0000238\n",
      "[8/25][7660/9765] Loss_D: 0.1050 Loss_G: 0.0411 Convergence: 0.1073 k= 0.022471 lr = 0.0000238\n",
      "[8/25][7670/9765] Loss_D: 0.1038 Loss_G: 0.0403 Convergence: 0.1063 k= 0.022477 lr = 0.0000238\n",
      "[8/25][7680/9765] Loss_D: 0.1000 Loss_G: 0.0419 Convergence: 0.1024 k= 0.022471 lr = 0.0000238\n",
      "[8/25][7690/9765] Loss_D: 0.0965 Loss_G: 0.0381 Convergence: 0.0982 k= 0.022467 lr = 0.0000238\n",
      "[8/25][7700/9765] Loss_D: 0.0888 Loss_G: 0.0378 Convergence: 0.0915 k= 0.022491 lr = 0.0000238\n",
      "[8/25][7710/9765] Loss_D: 0.0929 Loss_G: 0.0376 Convergence: 0.0938 k= 0.022521 lr = 0.0000238\n",
      "[8/25][7720/9765] Loss_D: 0.0956 Loss_G: 0.0453 Convergence: 0.1032 k= 0.022476 lr = 0.0000238\n",
      "[8/25][7730/9765] Loss_D: 0.1111 Loss_G: 0.0370 Convergence: 0.1197 k= 0.022458 lr = 0.0000238\n",
      "[8/25][7740/9765] Loss_D: 0.0937 Loss_G: 0.0379 Convergence: 0.0947 k= 0.022456 lr = 0.0000238\n",
      "[8/25][7750/9765] Loss_D: 0.0976 Loss_G: 0.0332 Convergence: 0.1045 k= 0.022509 lr = 0.0000238\n",
      "[8/25][7760/9765] Loss_D: 0.1076 Loss_G: 0.0445 Convergence: 0.1097 k= 0.022536 lr = 0.0000238\n",
      "[8/25][7770/9765] Loss_D: 0.1060 Loss_G: 0.0425 Convergence: 0.1073 k= 0.022512 lr = 0.0000238\n",
      "[8/25][7780/9765] Loss_D: 0.1083 Loss_G: 0.0385 Convergence: 0.1143 k= 0.022514 lr = 0.0000238\n",
      "[8/25][7790/9765] Loss_D: 0.1049 Loss_G: 0.0391 Convergence: 0.1089 k= 0.022549 lr = 0.0000238\n",
      "[8/25][7800/9765] Loss_D: 0.0993 Loss_G: 0.0399 Convergence: 0.1004 k= 0.022555 lr = 0.0000238\n",
      "[8/25][7810/9765] Loss_D: 0.1076 Loss_G: 0.0435 Convergence: 0.1086 k= 0.022561 lr = 0.0000238\n",
      "[8/25][7820/9765] Loss_D: 0.0932 Loss_G: 0.0412 Convergence: 0.0977 k= 0.022556 lr = 0.0000238\n",
      "[8/25][7830/9765] Loss_D: 0.1008 Loss_G: 0.0398 Convergence: 0.1027 k= 0.022562 lr = 0.0000238\n",
      "[8/25][7840/9765] Loss_D: 0.0955 Loss_G: 0.0363 Convergence: 0.0986 k= 0.022573 lr = 0.0000238\n",
      "[8/25][7850/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1032 k= 0.022595 lr = 0.0000238\n",
      "[8/25][7860/9765] Loss_D: 0.0921 Loss_G: 0.0416 Convergence: 0.0974 k= 0.022582 lr = 0.0000238\n",
      "[8/25][7870/9765] Loss_D: 0.0943 Loss_G: 0.0409 Convergence: 0.0981 k= 0.022577 lr = 0.0000238\n",
      "[8/25][7880/9765] Loss_D: 0.1055 Loss_G: 0.0402 Convergence: 0.1088 k= 0.022593 lr = 0.0000238\n",
      "[8/25][7890/9765] Loss_D: 0.1059 Loss_G: 0.0416 Convergence: 0.1079 k= 0.022610 lr = 0.0000238\n",
      "[8/25][7900/9765] Loss_D: 0.1021 Loss_G: 0.0404 Convergence: 0.1038 k= 0.022614 lr = 0.0000238\n",
      "[8/25][7910/9765] Loss_D: 0.0963 Loss_G: 0.0421 Convergence: 0.1004 k= 0.022590 lr = 0.0000238\n",
      "[8/25][7920/9765] Loss_D: 0.0916 Loss_G: 0.0380 Convergence: 0.0935 k= 0.022578 lr = 0.0000238\n",
      "[8/25][7930/9765] Loss_D: 0.0979 Loss_G: 0.0399 Convergence: 0.0991 k= 0.022605 lr = 0.0000238\n",
      "[8/25][7940/9765] Loss_D: 0.0916 Loss_G: 0.0397 Convergence: 0.0951 k= 0.022604 lr = 0.0000238\n",
      "[8/25][7950/9765] Loss_D: 0.1029 Loss_G: 0.0406 Convergence: 0.1048 k= 0.022596 lr = 0.0000238\n",
      "[8/25][7960/9765] Loss_D: 0.0992 Loss_G: 0.0415 Convergence: 0.1016 k= 0.022587 lr = 0.0000238\n",
      "[8/25][7970/9765] Loss_D: 0.1064 Loss_G: 0.0401 Convergence: 0.1101 k= 0.022597 lr = 0.0000238\n",
      "[8/25][7980/9765] Loss_D: 0.1052 Loss_G: 0.0409 Convergence: 0.1078 k= 0.022597 lr = 0.0000238\n",
      "[8/25][7990/9765] Loss_D: 0.0990 Loss_G: 0.0424 Convergence: 0.1024 k= 0.022591 lr = 0.0000238\n",
      "[8/25][8000/9765] Loss_D: 0.1063 Loss_G: 0.0404 Convergence: 0.1097 k= 0.022589 lr = 0.0000238\n",
      "[8/25][8010/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.022595 lr = 0.0000238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][8020/9765] Loss_D: 0.1026 Loss_G: 0.0381 Convergence: 0.1067 k= 0.022618 lr = 0.0000238\n",
      "[8/25][8030/9765] Loss_D: 0.0992 Loss_G: 0.0518 Convergence: 0.1120 k= 0.022591 lr = 0.0000238\n",
      "[8/25][8040/9765] Loss_D: 0.1040 Loss_G: 0.0523 Convergence: 0.1154 k= 0.022414 lr = 0.0000238\n",
      "[8/25][8050/9765] Loss_D: 0.0977 Loss_G: 0.0343 Convergence: 0.1036 k= 0.022387 lr = 0.0000238\n",
      "[8/25][8060/9765] Loss_D: 0.1009 Loss_G: 0.0335 Convergence: 0.1087 k= 0.022442 lr = 0.0000238\n",
      "[8/25][8070/9765] Loss_D: 0.1093 Loss_G: 0.0373 Convergence: 0.1168 k= 0.022502 lr = 0.0000238\n",
      "[8/25][8080/9765] Loss_D: 0.1058 Loss_G: 0.0442 Convergence: 0.1082 k= 0.022498 lr = 0.0000238\n",
      "[8/25][8090/9765] Loss_D: 0.0922 Loss_G: 0.0416 Convergence: 0.0975 k= 0.022440 lr = 0.0000238\n",
      "[8/25][8100/9765] Loss_D: 0.0929 Loss_G: 0.0384 Convergence: 0.0947 k= 0.022443 lr = 0.0000238\n",
      "[8/25][8110/9765] Loss_D: 0.0954 Loss_G: 0.0365 Convergence: 0.0982 k= 0.022447 lr = 0.0000238\n",
      "[8/25][8120/9765] Loss_D: 0.0875 Loss_G: 0.0407 Convergence: 0.0937 k= 0.022463 lr = 0.0000238\n",
      "[8/25][8130/9765] Loss_D: 0.0946 Loss_G: 0.0398 Convergence: 0.0972 k= 0.022447 lr = 0.0000238\n",
      "[8/25][8140/9765] Loss_D: 0.0943 Loss_G: 0.0422 Convergence: 0.0992 k= 0.022434 lr = 0.0000238\n",
      "[8/25][8150/9765] Loss_D: 0.1026 Loss_G: 0.0414 Convergence: 0.1035 k= 0.022422 lr = 0.0000238\n",
      "[8/25][8160/9765] Loss_D: 0.0924 Loss_G: 0.0405 Convergence: 0.0964 k= 0.022409 lr = 0.0000238\n",
      "[8/25][8170/9765] Loss_D: 0.0956 Loss_G: 0.0418 Convergence: 0.0997 k= 0.022418 lr = 0.0000238\n",
      "[8/25][8180/9765] Loss_D: 0.0989 Loss_G: 0.0412 Convergence: 0.1011 k= 0.022397 lr = 0.0000238\n",
      "[8/25][8190/9765] Loss_D: 0.0892 Loss_G: 0.0369 Convergence: 0.0909 k= 0.022388 lr = 0.0000238\n",
      "[8/25][8200/9765] Loss_D: 0.1051 Loss_G: 0.0378 Convergence: 0.1105 k= 0.022414 lr = 0.0000238\n",
      "[8/25][8210/9765] Loss_D: 0.0952 Loss_G: 0.0399 Convergence: 0.0976 k= 0.022400 lr = 0.0000238\n",
      "[8/25][8220/9765] Loss_D: 0.1002 Loss_G: 0.0408 Convergence: 0.1015 k= 0.022378 lr = 0.0000238\n",
      "[8/25][8230/9765] Loss_D: 0.1020 Loss_G: 0.0365 Convergence: 0.1075 k= 0.022378 lr = 0.0000238\n",
      "[8/25][8240/9765] Loss_D: 0.0983 Loss_G: 0.0387 Convergence: 0.1001 k= 0.022382 lr = 0.0000238\n",
      "[8/25][8250/9765] Loss_D: 0.1071 Loss_G: 0.0411 Convergence: 0.1100 k= 0.022391 lr = 0.0000238\n",
      "[8/25][8260/9765] Loss_D: 0.1122 Loss_G: 0.0411 Convergence: 0.1173 k= 0.022413 lr = 0.0000238\n",
      "[8/25][8270/9765] Loss_D: 0.1009 Loss_G: 0.0421 Convergence: 0.1032 k= 0.022395 lr = 0.0000238\n",
      "[8/25][8280/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0985 k= 0.022399 lr = 0.0000238\n",
      "[8/25][8290/9765] Loss_D: 0.0982 Loss_G: 0.0412 Convergence: 0.1007 k= 0.022383 lr = 0.0000238\n",
      "[8/25][8300/9765] Loss_D: 0.1020 Loss_G: 0.0361 Convergence: 0.1077 k= 0.022407 lr = 0.0000238\n",
      "[8/25][8310/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1043 k= 0.022412 lr = 0.0000238\n",
      "[8/25][8320/9765] Loss_D: 0.1006 Loss_G: 0.0375 Convergence: 0.1044 k= 0.022428 lr = 0.0000238\n",
      "[8/25][8330/9765] Loss_D: 0.1038 Loss_G: 0.0413 Convergence: 0.1054 k= 0.022437 lr = 0.0000238\n",
      "[8/25][8340/9765] Loss_D: 0.0956 Loss_G: 0.0408 Convergence: 0.0988 k= 0.022411 lr = 0.0000238\n",
      "[8/25][8350/9765] Loss_D: 0.1024 Loss_G: 0.0406 Convergence: 0.1040 k= 0.022384 lr = 0.0000238\n",
      "[8/25][8360/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0974 k= 0.022380 lr = 0.0000238\n",
      "[8/25][8370/9765] Loss_D: 0.0911 Loss_G: 0.0407 Convergence: 0.0959 k= 0.022367 lr = 0.0000238\n",
      "[8/25][8380/9765] Loss_D: 0.0990 Loss_G: 0.0395 Convergence: 0.1004 k= 0.022363 lr = 0.0000238\n",
      "[8/25][8390/9765] Loss_D: 0.0949 Loss_G: 0.0391 Convergence: 0.0966 k= 0.022369 lr = 0.0000238\n",
      "[8/25][8400/9765] Loss_D: 0.1004 Loss_G: 0.0379 Convergence: 0.1039 k= 0.022379 lr = 0.0000238\n",
      "[8/25][8410/9765] Loss_D: 0.0996 Loss_G: 0.0426 Convergence: 0.1029 k= 0.022383 lr = 0.0000238\n",
      "[8/25][8420/9765] Loss_D: 0.0959 Loss_G: 0.0431 Convergence: 0.1012 k= 0.022360 lr = 0.0000238\n",
      "[8/25][8430/9765] Loss_D: 0.1003 Loss_G: 0.0378 Convergence: 0.1039 k= 0.022342 lr = 0.0000238\n",
      "[8/25][8440/9765] Loss_D: 0.0967 Loss_G: 0.0422 Convergence: 0.1007 k= 0.022335 lr = 0.0000238\n",
      "[8/25][8450/9765] Loss_D: 0.0991 Loss_G: 0.0406 Convergence: 0.1006 k= 0.022333 lr = 0.0000238\n",
      "[8/25][8460/9765] Loss_D: 0.0958 Loss_G: 0.0412 Convergence: 0.0993 k= 0.022329 lr = 0.0000238\n",
      "[8/25][8470/9765] Loss_D: 0.0965 Loss_G: 0.0421 Convergence: 0.1006 k= 0.022298 lr = 0.0000238\n",
      "[8/25][8480/9765] Loss_D: 0.0934 Loss_G: 0.0416 Convergence: 0.0982 k= 0.022282 lr = 0.0000238\n",
      "[8/25][8490/9765] Loss_D: 0.0918 Loss_G: 0.0410 Convergence: 0.0966 k= 0.022292 lr = 0.0000238\n",
      "[8/25][8500/9765] Loss_D: 0.0911 Loss_G: 0.0398 Convergence: 0.0950 k= 0.022288 lr = 0.0000238\n",
      "[8/25][8510/9765] Loss_D: 0.0962 Loss_G: 0.0401 Convergence: 0.0983 k= 0.022300 lr = 0.0000238\n",
      "[8/25][8520/9765] Loss_D: 0.1002 Loss_G: 0.0406 Convergence: 0.1012 k= 0.022298 lr = 0.0000238\n",
      "[8/25][8530/9765] Loss_D: 0.0878 Loss_G: 0.0389 Convergence: 0.0921 k= 0.022291 lr = 0.0000238\n",
      "[8/25][8540/9765] Loss_D: 0.1018 Loss_G: 0.0397 Convergence: 0.1040 k= 0.022284 lr = 0.0000238\n",
      "[8/25][8550/9765] Loss_D: 0.0933 Loss_G: 0.0402 Convergence: 0.0967 k= 0.022296 lr = 0.0000238\n",
      "[8/25][8560/9765] Loss_D: 0.0944 Loss_G: 0.0390 Convergence: 0.0962 k= 0.022294 lr = 0.0000238\n",
      "[8/25][8570/9765] Loss_D: 0.1033 Loss_G: 0.0420 Convergence: 0.1045 k= 0.022303 lr = 0.0000238\n",
      "[8/25][8580/9765] Loss_D: 0.1067 Loss_G: 0.0409 Convergence: 0.1098 k= 0.022301 lr = 0.0000238\n",
      "[8/25][8590/9765] Loss_D: 0.1023 Loss_G: 0.0404 Convergence: 0.1040 k= 0.022299 lr = 0.0000238\n",
      "[8/25][8600/9765] Loss_D: 0.0913 Loss_G: 0.0400 Convergence: 0.0952 k= 0.022320 lr = 0.0000238\n",
      "[8/25][8610/9765] Loss_D: 0.1077 Loss_G: 0.0381 Convergence: 0.1139 k= 0.022350 lr = 0.0000238\n",
      "[8/25][8620/9765] Loss_D: 0.0971 Loss_G: 0.0397 Convergence: 0.0985 k= 0.022356 lr = 0.0000238\n",
      "[8/25][8630/9765] Loss_D: 0.0959 Loss_G: 0.0417 Convergence: 0.0998 k= 0.022355 lr = 0.0000238\n",
      "[8/25][8640/9765] Loss_D: 0.0939 Loss_G: 0.0413 Convergence: 0.0982 k= 0.022338 lr = 0.0000238\n",
      "[8/25][8650/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1034 k= 0.022338 lr = 0.0000238\n",
      "[8/25][8660/9765] Loss_D: 0.0991 Loss_G: 0.0378 Convergence: 0.1021 k= 0.022335 lr = 0.0000238\n",
      "[8/25][8670/9765] Loss_D: 0.0948 Loss_G: 0.0368 Convergence: 0.0972 k= 0.022327 lr = 0.0000238\n",
      "[8/25][8680/9765] Loss_D: 0.1023 Loss_G: 0.0395 Convergence: 0.1049 k= 0.022356 lr = 0.0000238\n",
      "[8/25][8690/9765] Loss_D: 0.0965 Loss_G: 0.0410 Convergence: 0.0995 k= 0.022354 lr = 0.0000238\n",
      "[8/25][8700/9765] Loss_D: 0.1041 Loss_G: 0.0408 Convergence: 0.1063 k= 0.022377 lr = 0.0000238\n",
      "[8/25][8710/9765] Loss_D: 0.1018 Loss_G: 0.0446 Convergence: 0.1062 k= 0.022358 lr = 0.0000238\n",
      "[8/25][8720/9765] Loss_D: 0.1054 Loss_G: 0.0406 Convergence: 0.1082 k= 0.022348 lr = 0.0000238\n",
      "[8/25][8730/9765] Loss_D: 0.1052 Loss_G: 0.0403 Convergence: 0.1081 k= 0.022353 lr = 0.0000238\n",
      "[8/25][8740/9765] Loss_D: 0.0997 Loss_G: 0.0377 Convergence: 0.1031 k= 0.022354 lr = 0.0000238\n",
      "[8/25][8750/9765] Loss_D: 0.1026 Loss_G: 0.0399 Convergence: 0.1049 k= 0.022380 lr = 0.0000238\n",
      "[8/25][8760/9765] Loss_D: 0.0991 Loss_G: 0.0445 Convergence: 0.1045 k= 0.022360 lr = 0.0000238\n",
      "[8/25][8770/9765] Loss_D: 0.1010 Loss_G: 0.0402 Convergence: 0.1025 k= 0.022348 lr = 0.0000238\n",
      "[8/25][8780/9765] Loss_D: 0.0963 Loss_G: 0.0423 Convergence: 0.1006 k= 0.022345 lr = 0.0000238\n",
      "[8/25][8790/9765] Loss_D: 0.0941 Loss_G: 0.0426 Convergence: 0.0997 k= 0.022328 lr = 0.0000238\n",
      "[8/25][8800/9765] Loss_D: 0.1047 Loss_G: 0.0423 Convergence: 0.1057 k= 0.022319 lr = 0.0000238\n",
      "[8/25][8810/9765] Loss_D: 0.1052 Loss_G: 0.0432 Convergence: 0.1069 k= 0.022301 lr = 0.0000238\n",
      "[8/25][8820/9765] Loss_D: 0.1001 Loss_G: 0.0416 Convergence: 0.1022 k= 0.022277 lr = 0.0000238\n",
      "[8/25][8830/9765] Loss_D: 0.1060 Loss_G: 0.0419 Convergence: 0.1079 k= 0.022268 lr = 0.0000238\n",
      "[8/25][8840/9765] Loss_D: 0.1039 Loss_G: 0.0364 Convergence: 0.1102 k= 0.022285 lr = 0.0000238\n",
      "[8/25][8850/9765] Loss_D: 0.0927 Loss_G: 0.0364 Convergence: 0.0945 k= 0.022334 lr = 0.0000238\n",
      "[8/25][8860/9765] Loss_D: 0.1041 Loss_G: 0.0407 Convergence: 0.1062 k= 0.022359 lr = 0.0000238\n",
      "[8/25][8870/9765] Loss_D: 0.1072 Loss_G: 0.0423 Convergence: 0.1090 k= 0.022331 lr = 0.0000238\n",
      "[8/25][8880/9765] Loss_D: 0.0955 Loss_G: 0.0431 Convergence: 0.1009 k= 0.022328 lr = 0.0000226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][8890/9765] Loss_D: 0.1027 Loss_G: 0.0402 Convergence: 0.1048 k= 0.022351 lr = 0.0000226\n",
      "[8/25][8900/9765] Loss_D: 0.0979 Loss_G: 0.0400 Convergence: 0.0992 k= 0.022358 lr = 0.0000226\n",
      "[8/25][8910/9765] Loss_D: 0.0911 Loss_G: 0.0372 Convergence: 0.0924 k= 0.022368 lr = 0.0000226\n",
      "[8/25][8920/9765] Loss_D: 0.0949 Loss_G: 0.0374 Convergence: 0.0966 k= 0.022400 lr = 0.0000226\n",
      "[8/25][8930/9765] Loss_D: 0.1002 Loss_G: 0.0409 Convergence: 0.1016 k= 0.022397 lr = 0.0000226\n",
      "[8/25][8940/9765] Loss_D: 0.0982 Loss_G: 0.0420 Convergence: 0.1014 k= 0.022392 lr = 0.0000226\n",
      "[8/25][8950/9765] Loss_D: 0.0920 Loss_G: 0.0367 Convergence: 0.0934 k= 0.022400 lr = 0.0000226\n",
      "[8/25][8960/9765] Loss_D: 0.0978 Loss_G: 0.0365 Convergence: 0.1017 k= 0.022428 lr = 0.0000226\n",
      "[8/25][8970/9765] Loss_D: 0.0988 Loss_G: 0.0383 Convergence: 0.1014 k= 0.022426 lr = 0.0000226\n",
      "[8/25][8980/9765] Loss_D: 0.0959 Loss_G: 0.0421 Convergence: 0.1001 k= 0.022432 lr = 0.0000226\n",
      "[8/25][8990/9765] Loss_D: 0.0990 Loss_G: 0.0406 Convergence: 0.1005 k= 0.022432 lr = 0.0000226\n",
      "[8/25][9000/9765] Loss_D: 0.0908 Loss_G: 0.0361 Convergence: 0.0922 k= 0.022437 lr = 0.0000226\n",
      "[8/25][9010/9765] Loss_D: 0.0995 Loss_G: 0.0390 Convergence: 0.1016 k= 0.022453 lr = 0.0000226\n",
      "[8/25][9020/9765] Loss_D: 0.1079 Loss_G: 0.0438 Convergence: 0.1091 k= 0.022463 lr = 0.0000226\n",
      "[8/25][9030/9765] Loss_D: 0.1008 Loss_G: 0.0412 Convergence: 0.1022 k= 0.022440 lr = 0.0000226\n",
      "[8/25][9040/9765] Loss_D: 0.0849 Loss_G: 0.0384 Convergence: 0.0899 k= 0.022415 lr = 0.0000226\n",
      "[8/25][9050/9765] Loss_D: 0.0976 Loss_G: 0.0375 Convergence: 0.1005 k= 0.022431 lr = 0.0000226\n",
      "[8/25][9060/9765] Loss_D: 0.1005 Loss_G: 0.0395 Convergence: 0.1024 k= 0.022457 lr = 0.0000226\n",
      "[8/25][9070/9765] Loss_D: 0.0959 Loss_G: 0.0397 Convergence: 0.0978 k= 0.022452 lr = 0.0000226\n",
      "[8/25][9080/9765] Loss_D: 0.0956 Loss_G: 0.0411 Convergence: 0.0990 k= 0.022438 lr = 0.0000226\n",
      "[8/25][9090/9765] Loss_D: 0.1019 Loss_G: 0.0367 Convergence: 0.1071 k= 0.022449 lr = 0.0000226\n",
      "[8/25][9100/9765] Loss_D: 0.0980 Loss_G: 0.0385 Convergence: 0.0999 k= 0.022469 lr = 0.0000226\n",
      "[8/25][9110/9765] Loss_D: 0.0966 Loss_G: 0.0385 Convergence: 0.0980 k= 0.022485 lr = 0.0000226\n",
      "[8/25][9120/9765] Loss_D: 0.0949 Loss_G: 0.0422 Convergence: 0.0998 k= 0.022472 lr = 0.0000226\n",
      "[8/25][9130/9765] Loss_D: 0.0987 Loss_G: 0.0417 Convergence: 0.1014 k= 0.022446 lr = 0.0000226\n",
      "[8/25][9140/9765] Loss_D: 0.1008 Loss_G: 0.0394 Convergence: 0.1030 k= 0.022450 lr = 0.0000226\n",
      "[8/25][9150/9765] Loss_D: 0.0972 Loss_G: 0.0385 Convergence: 0.0989 k= 0.022457 lr = 0.0000226\n",
      "[8/25][9160/9765] Loss_D: 0.1011 Loss_G: 0.0402 Convergence: 0.1026 k= 0.022466 lr = 0.0000226\n",
      "[8/25][9170/9765] Loss_D: 0.1001 Loss_G: 0.0453 Convergence: 0.1059 k= 0.022453 lr = 0.0000226\n",
      "[8/25][9180/9765] Loss_D: 0.1043 Loss_G: 0.0382 Convergence: 0.1090 k= 0.022432 lr = 0.0000226\n",
      "[8/25][9190/9765] Loss_D: 0.0940 Loss_G: 0.0383 Convergence: 0.0951 k= 0.022447 lr = 0.0000226\n",
      "[8/25][9200/9765] Loss_D: 0.1081 Loss_G: 0.0389 Convergence: 0.1136 k= 0.022477 lr = 0.0000226\n",
      "[8/25][9210/9765] Loss_D: 0.0945 Loss_G: 0.0368 Convergence: 0.0966 k= 0.022505 lr = 0.0000226\n",
      "[8/25][9220/9765] Loss_D: 0.1039 Loss_G: 0.0454 Convergence: 0.1083 k= 0.022504 lr = 0.0000226\n",
      "[8/25][9230/9765] Loss_D: 0.1029 Loss_G: 0.0405 Convergence: 0.1046 k= 0.022499 lr = 0.0000226\n",
      "[8/25][9240/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0996 k= 0.022501 lr = 0.0000226\n",
      "[8/25][9250/9765] Loss_D: 0.0926 Loss_G: 0.0373 Convergence: 0.0934 k= 0.022505 lr = 0.0000226\n",
      "[8/25][9260/9765] Loss_D: 0.0986 Loss_G: 0.0412 Convergence: 0.1009 k= 0.022523 lr = 0.0000226\n",
      "[8/25][9270/9765] Loss_D: 0.1040 Loss_G: 0.0385 Convergence: 0.1084 k= 0.022533 lr = 0.0000226\n",
      "[8/25][9280/9765] Loss_D: 0.0954 Loss_G: 0.0376 Convergence: 0.0971 k= 0.022538 lr = 0.0000226\n",
      "[8/25][9290/9765] Loss_D: 0.1005 Loss_G: 0.0423 Convergence: 0.1032 k= 0.022542 lr = 0.0000226\n",
      "[8/25][9300/9765] Loss_D: 0.1089 Loss_G: 0.0404 Convergence: 0.1133 k= 0.022539 lr = 0.0000226\n",
      "[8/25][9310/9765] Loss_D: 0.1056 Loss_G: 0.0429 Convergence: 0.1068 k= 0.022528 lr = 0.0000226\n",
      "[8/25][9320/9765] Loss_D: 0.0995 Loss_G: 0.0387 Convergence: 0.1018 k= 0.022523 lr = 0.0000226\n",
      "[8/25][9330/9765] Loss_D: 0.0993 Loss_G: 0.0415 Convergence: 0.1016 k= 0.022522 lr = 0.0000226\n",
      "[8/25][9340/9765] Loss_D: 0.0948 Loss_G: 0.0412 Convergence: 0.0986 k= 0.022513 lr = 0.0000226\n",
      "[8/25][9350/9765] Loss_D: 0.0927 Loss_G: 0.0402 Convergence: 0.0963 k= 0.022506 lr = 0.0000226\n",
      "[8/25][9360/9765] Loss_D: 0.0984 Loss_G: 0.0350 Convergence: 0.1038 k= 0.022530 lr = 0.0000226\n",
      "[8/25][9370/9765] Loss_D: 0.1004 Loss_G: 0.0368 Convergence: 0.1048 k= 0.022570 lr = 0.0000226\n",
      "[8/25][9380/9765] Loss_D: 0.1004 Loss_G: 0.0421 Convergence: 0.1029 k= 0.022560 lr = 0.0000226\n",
      "[8/25][9390/9765] Loss_D: 0.1061 Loss_G: 0.0410 Convergence: 0.1088 k= 0.022543 lr = 0.0000226\n",
      "[8/25][9400/9765] Loss_D: 0.1055 Loss_G: 0.0373 Convergence: 0.1117 k= 0.022549 lr = 0.0000226\n",
      "[8/25][9410/9765] Loss_D: 0.1072 Loss_G: 0.0374 Convergence: 0.1138 k= 0.022564 lr = 0.0000226\n",
      "[8/25][9420/9765] Loss_D: 0.0817 Loss_G: 0.0403 Convergence: 0.0898 k= 0.022561 lr = 0.0000226\n",
      "[8/25][9430/9765] Loss_D: 0.1046 Loss_G: 0.0394 Convergence: 0.1082 k= 0.022561 lr = 0.0000226\n",
      "[8/25][9440/9765] Loss_D: 0.0942 Loss_G: 0.0377 Convergence: 0.0955 k= 0.022568 lr = 0.0000226\n",
      "[8/25][9450/9765] Loss_D: 0.0966 Loss_G: 0.0423 Convergence: 0.1008 k= 0.022553 lr = 0.0000226\n",
      "[8/25][9460/9765] Loss_D: 0.0899 Loss_G: 0.0400 Convergence: 0.0945 k= 0.022575 lr = 0.0000226\n",
      "[8/25][9470/9765] Loss_D: 0.0911 Loss_G: 0.0393 Convergence: 0.0946 k= 0.022589 lr = 0.0000226\n",
      "[8/25][9480/9765] Loss_D: 0.0916 Loss_G: 0.0404 Convergence: 0.0959 k= 0.022598 lr = 0.0000226\n",
      "[8/25][9490/9765] Loss_D: 0.0951 Loss_G: 0.0390 Convergence: 0.0966 k= 0.022595 lr = 0.0000226\n",
      "[8/25][9500/9765] Loss_D: 0.0976 Loss_G: 0.0403 Convergence: 0.0993 k= 0.022599 lr = 0.0000226\n",
      "[8/25][9510/9765] Loss_D: 0.1064 Loss_G: 0.0407 Convergence: 0.1094 k= 0.022622 lr = 0.0000226\n",
      "[8/25][9520/9765] Loss_D: 0.0994 Loss_G: 0.0385 Convergence: 0.1018 k= 0.022637 lr = 0.0000226\n",
      "[8/25][9530/9765] Loss_D: 0.0993 Loss_G: 0.0389 Convergence: 0.1014 k= 0.022654 lr = 0.0000226\n",
      "[8/25][9540/9765] Loss_D: 0.0988 Loss_G: 0.0418 Convergence: 0.1017 k= 0.022651 lr = 0.0000226\n",
      "[8/25][9550/9765] Loss_D: 0.1026 Loss_G: 0.0427 Convergence: 0.1048 k= 0.022616 lr = 0.0000226\n",
      "[8/25][9560/9765] Loss_D: 0.0981 Loss_G: 0.0373 Convergence: 0.1013 k= 0.022620 lr = 0.0000226\n",
      "[8/25][9570/9765] Loss_D: 0.1001 Loss_G: 0.0404 Convergence: 0.1010 k= 0.022639 lr = 0.0000226\n",
      "[8/25][9580/9765] Loss_D: 0.0971 Loss_G: 0.0441 Convergence: 0.1030 k= 0.022623 lr = 0.0000226\n",
      "[8/25][9590/9765] Loss_D: 0.0954 Loss_G: 0.0428 Convergence: 0.1006 k= 0.022571 lr = 0.0000226\n",
      "[8/25][9600/9765] Loss_D: 0.1018 Loss_G: 0.0386 Convergence: 0.1050 k= 0.022558 lr = 0.0000226\n",
      "[8/25][9610/9765] Loss_D: 0.1036 Loss_G: 0.0363 Convergence: 0.1098 k= 0.022591 lr = 0.0000226\n",
      "[8/25][9620/9765] Loss_D: 0.0958 Loss_G: 0.0364 Convergence: 0.0988 k= 0.022615 lr = 0.0000226\n",
      "[8/25][9630/9765] Loss_D: 0.0931 Loss_G: 0.0395 Convergence: 0.0959 k= 0.022603 lr = 0.0000226\n",
      "[8/25][9640/9765] Loss_D: 0.0943 Loss_G: 0.0427 Convergence: 0.0999 k= 0.022590 lr = 0.0000226\n",
      "[8/25][9650/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0966 k= 0.022592 lr = 0.0000226\n",
      "[8/25][9660/9765] Loss_D: 0.1037 Loss_G: 0.0403 Convergence: 0.1061 k= 0.022602 lr = 0.0000226\n",
      "[8/25][9670/9765] Loss_D: 0.1000 Loss_G: 0.0421 Convergence: 0.1027 k= 0.022602 lr = 0.0000226\n",
      "[8/25][9680/9765] Loss_D: 0.0968 Loss_G: 0.0346 Convergence: 0.1020 k= 0.022626 lr = 0.0000226\n",
      "[8/25][9690/9765] Loss_D: 0.0914 Loss_G: 0.0380 Convergence: 0.0935 k= 0.022628 lr = 0.0000226\n",
      "[8/25][9700/9765] Loss_D: 0.1044 Loss_G: 0.0356 Convergence: 0.1116 k= 0.022672 lr = 0.0000226\n",
      "[8/25][9710/9765] Loss_D: 0.1020 Loss_G: 0.0438 Convergence: 0.1055 k= 0.022667 lr = 0.0000226\n",
      "[8/25][9720/9765] Loss_D: 0.1021 Loss_G: 0.0379 Convergence: 0.1063 k= 0.022675 lr = 0.0000226\n",
      "[8/25][9730/9765] Loss_D: 0.0958 Loss_G: 0.0388 Convergence: 0.0968 k= 0.022670 lr = 0.0000226\n",
      "[8/25][9740/9765] Loss_D: 0.0955 Loss_G: 0.0354 Convergence: 0.0994 k= 0.022676 lr = 0.0000226\n",
      "[8/25][9750/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0993 k= 0.022688 lr = 0.0000226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/25][9760/9765] Loss_D: 0.1071 Loss_G: 0.0432 Convergence: 0.1081 k= 0.022660 lr = 0.0000226\n",
      "[9/25][0/9765] Loss_D: 0.1010 Loss_G: 0.0419 Convergence: 0.1030 k= 0.022649 lr = 0.0000226\n",
      "[9/25][10/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0962 k= 0.022644 lr = 0.0000226\n",
      "[9/25][20/9765] Loss_D: 0.1018 Loss_G: 0.0366 Convergence: 0.1070 k= 0.022659 lr = 0.0000226\n",
      "[9/25][30/9765] Loss_D: 0.1015 Loss_G: 0.0380 Convergence: 0.1052 k= 0.022664 lr = 0.0000226\n",
      "[9/25][40/9765] Loss_D: 0.1061 Loss_G: 0.0407 Convergence: 0.1091 k= 0.022674 lr = 0.0000226\n",
      "[9/25][50/9765] Loss_D: 0.1012 Loss_G: 0.0399 Convergence: 0.1031 k= 0.022669 lr = 0.0000226\n",
      "[9/25][60/9765] Loss_D: 0.1016 Loss_G: 0.0373 Convergence: 0.1061 k= 0.022670 lr = 0.0000226\n",
      "[9/25][70/9765] Loss_D: 0.1051 Loss_G: 0.0369 Convergence: 0.1115 k= 0.022699 lr = 0.0000226\n",
      "[9/25][80/9765] Loss_D: 0.1051 Loss_G: 0.0408 Convergence: 0.1076 k= 0.022691 lr = 0.0000226\n",
      "[9/25][90/9765] Loss_D: 0.0943 Loss_G: 0.0407 Convergence: 0.0978 k= 0.022688 lr = 0.0000226\n",
      "[9/25][100/9765] Loss_D: 0.0989 Loss_G: 0.0400 Convergence: 0.0999 k= 0.022679 lr = 0.0000226\n",
      "[9/25][110/9765] Loss_D: 0.1023 Loss_G: 0.0421 Convergence: 0.1040 k= 0.022683 lr = 0.0000226\n",
      "[9/25][120/9765] Loss_D: 0.1012 Loss_G: 0.0427 Convergence: 0.1040 k= 0.022685 lr = 0.0000226\n",
      "[9/25][130/9765] Loss_D: 0.1013 Loss_G: 0.0400 Convergence: 0.1030 k= 0.022668 lr = 0.0000226\n",
      "[9/25][140/9765] Loss_D: 0.0950 Loss_G: 0.0417 Convergence: 0.0993 k= 0.022671 lr = 0.0000226\n",
      "[9/25][150/9765] Loss_D: 0.0903 Loss_G: 0.0400 Convergence: 0.0947 k= 0.022675 lr = 0.0000226\n",
      "[9/25][160/9765] Loss_D: 0.0961 Loss_G: 0.0396 Convergence: 0.0978 k= 0.022682 lr = 0.0000226\n",
      "[9/25][170/9765] Loss_D: 0.0931 Loss_G: 0.0430 Convergence: 0.0994 k= 0.022651 lr = 0.0000226\n",
      "[9/25][180/9765] Loss_D: 0.0930 Loss_G: 0.0400 Convergence: 0.0963 k= 0.022628 lr = 0.0000226\n",
      "[9/25][190/9765] Loss_D: 0.0986 Loss_G: 0.0371 Convergence: 0.1020 k= 0.022651 lr = 0.0000226\n",
      "[9/25][200/9765] Loss_D: 0.1061 Loss_G: 0.0357 Convergence: 0.1140 k= 0.022687 lr = 0.0000226\n",
      "[9/25][210/9765] Loss_D: 0.1021 Loss_G: 0.0419 Convergence: 0.1037 k= 0.022700 lr = 0.0000226\n",
      "[9/25][220/9765] Loss_D: 0.0899 Loss_G: 0.0529 Convergence: 0.1075 k= 0.022601 lr = 0.0000226\n",
      "[9/25][230/9765] Loss_D: 0.0967 Loss_G: 0.0474 Convergence: 0.1060 k= 0.022492 lr = 0.0000226\n",
      "[9/25][240/9765] Loss_D: 0.0895 Loss_G: 0.0383 Convergence: 0.0925 k= 0.022494 lr = 0.0000226\n",
      "[9/25][250/9765] Loss_D: 0.1037 Loss_G: 0.0398 Convergence: 0.1065 k= 0.022516 lr = 0.0000226\n",
      "[9/25][260/9765] Loss_D: 0.1107 Loss_G: 0.0392 Convergence: 0.1171 k= 0.022538 lr = 0.0000226\n",
      "[9/25][270/9765] Loss_D: 0.1061 Loss_G: 0.0402 Convergence: 0.1095 k= 0.022532 lr = 0.0000226\n",
      "[9/25][280/9765] Loss_D: 0.1060 Loss_G: 0.0411 Convergence: 0.1086 k= 0.022536 lr = 0.0000226\n",
      "[9/25][290/9765] Loss_D: 0.0979 Loss_G: 0.0382 Convergence: 0.1001 k= 0.022515 lr = 0.0000226\n",
      "[9/25][300/9765] Loss_D: 0.0973 Loss_G: 0.0416 Convergence: 0.1005 k= 0.022526 lr = 0.0000226\n",
      "[9/25][310/9765] Loss_D: 0.0953 Loss_G: 0.0410 Convergence: 0.0987 k= 0.022522 lr = 0.0000226\n",
      "[9/25][320/9765] Loss_D: 0.0970 Loss_G: 0.0433 Convergence: 0.1021 k= 0.022512 lr = 0.0000226\n",
      "[9/25][330/9765] Loss_D: 0.1035 Loss_G: 0.0434 Convergence: 0.1061 k= 0.022486 lr = 0.0000226\n",
      "[9/25][340/9765] Loss_D: 0.0891 Loss_G: 0.0392 Convergence: 0.0932 k= 0.022457 lr = 0.0000226\n",
      "[9/25][350/9765] Loss_D: 0.1142 Loss_G: 0.0396 Convergence: 0.1214 k= 0.022482 lr = 0.0000226\n",
      "[9/25][360/9765] Loss_D: 0.1022 Loss_G: 0.0406 Convergence: 0.1038 k= 0.022496 lr = 0.0000226\n",
      "[9/25][370/9765] Loss_D: 0.0986 Loss_G: 0.0424 Convergence: 0.1022 k= 0.022470 lr = 0.0000226\n",
      "[9/25][380/9765] Loss_D: 0.1053 Loss_G: 0.0414 Convergence: 0.1073 k= 0.022457 lr = 0.0000226\n",
      "[9/25][390/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0924 k= 0.022471 lr = 0.0000226\n",
      "[9/25][400/9765] Loss_D: 0.0972 Loss_G: 0.0446 Convergence: 0.1035 k= 0.022481 lr = 0.0000226\n",
      "[9/25][410/9765] Loss_D: 0.0941 Loss_G: 0.0413 Convergence: 0.0982 k= 0.022460 lr = 0.0000226\n",
      "[9/25][420/9765] Loss_D: 0.0972 Loss_G: 0.0418 Convergence: 0.1006 k= 0.022449 lr = 0.0000226\n",
      "[9/25][430/9765] Loss_D: 0.0984 Loss_G: 0.0371 Convergence: 0.1019 k= 0.022426 lr = 0.0000226\n",
      "[9/25][440/9765] Loss_D: 0.0930 Loss_G: 0.0381 Convergence: 0.0944 k= 0.022425 lr = 0.0000226\n",
      "[9/25][450/9765] Loss_D: 0.0933 Loss_G: 0.0395 Convergence: 0.0960 k= 0.022435 lr = 0.0000226\n",
      "[9/25][460/9765] Loss_D: 0.1058 Loss_G: 0.0370 Convergence: 0.1123 k= 0.022461 lr = 0.0000226\n",
      "[9/25][470/9765] Loss_D: 0.0985 Loss_G: 0.0385 Convergence: 0.1006 k= 0.022476 lr = 0.0000226\n",
      "[9/25][480/9765] Loss_D: 0.1008 Loss_G: 0.0422 Convergence: 0.1032 k= 0.022469 lr = 0.0000226\n",
      "[9/25][490/9765] Loss_D: 0.1014 Loss_G: 0.0375 Convergence: 0.1058 k= 0.022479 lr = 0.0000226\n",
      "[9/25][500/9765] Loss_D: 0.1035 Loss_G: 0.0344 Convergence: 0.1116 k= 0.022510 lr = 0.0000226\n",
      "[9/25][510/9765] Loss_D: 0.1025 Loss_G: 0.0421 Convergence: 0.1042 k= 0.022509 lr = 0.0000226\n",
      "[9/25][520/9765] Loss_D: 0.0996 Loss_G: 0.0450 Convergence: 0.1054 k= 0.022448 lr = 0.0000226\n",
      "[9/25][530/9765] Loss_D: 0.0978 Loss_G: 0.0374 Convergence: 0.1008 k= 0.022439 lr = 0.0000226\n",
      "[9/25][540/9765] Loss_D: 0.0970 Loss_G: 0.0375 Convergence: 0.0995 k= 0.022450 lr = 0.0000226\n",
      "[9/25][550/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.022472 lr = 0.0000226\n",
      "[9/25][560/9765] Loss_D: 0.0991 Loss_G: 0.0404 Convergence: 0.1004 k= 0.022471 lr = 0.0000226\n",
      "[9/25][570/9765] Loss_D: 0.1030 Loss_G: 0.0432 Convergence: 0.1055 k= 0.022446 lr = 0.0000226\n",
      "[9/25][580/9765] Loss_D: 0.0865 Loss_G: 0.0383 Convergence: 0.0907 k= 0.022441 lr = 0.0000226\n",
      "[9/25][590/9765] Loss_D: 0.0932 Loss_G: 0.0395 Convergence: 0.0958 k= 0.022454 lr = 0.0000226\n",
      "[9/25][600/9765] Loss_D: 0.0981 Loss_G: 0.0376 Convergence: 0.1009 k= 0.022476 lr = 0.0000226\n",
      "[9/25][610/9765] Loss_D: 0.1054 Loss_G: 0.0452 Convergence: 0.1091 k= 0.022461 lr = 0.0000226\n",
      "[9/25][620/9765] Loss_D: 0.0991 Loss_G: 0.0448 Convergence: 0.1050 k= 0.022379 lr = 0.0000226\n",
      "[9/25][630/9765] Loss_D: 0.0894 Loss_G: 0.0365 Convergence: 0.0906 k= 0.022373 lr = 0.0000226\n",
      "[9/25][640/9765] Loss_D: 0.0916 Loss_G: 0.0353 Convergence: 0.0940 k= 0.022401 lr = 0.0000226\n",
      "[9/25][650/9765] Loss_D: 0.0955 Loss_G: 0.0408 Convergence: 0.0986 k= 0.022411 lr = 0.0000226\n",
      "[9/25][660/9765] Loss_D: 0.1005 Loss_G: 0.0379 Convergence: 0.1040 k= 0.022407 lr = 0.0000226\n",
      "[9/25][670/9765] Loss_D: 0.0994 Loss_G: 0.0367 Convergence: 0.1036 k= 0.022417 lr = 0.0000226\n",
      "[9/25][680/9765] Loss_D: 0.0963 Loss_G: 0.0396 Convergence: 0.0979 k= 0.022414 lr = 0.0000226\n",
      "[9/25][690/9765] Loss_D: 0.0985 Loss_G: 0.0382 Convergence: 0.1009 k= 0.022431 lr = 0.0000226\n",
      "[9/25][700/9765] Loss_D: 0.0952 Loss_G: 0.0385 Convergence: 0.0961 k= 0.022433 lr = 0.0000226\n",
      "[9/25][710/9765] Loss_D: 0.0931 Loss_G: 0.0382 Convergence: 0.0946 k= 0.022449 lr = 0.0000226\n",
      "[9/25][720/9765] Loss_D: 0.0941 Loss_G: 0.0377 Convergence: 0.0952 k= 0.022448 lr = 0.0000226\n",
      "[9/25][730/9765] Loss_D: 0.0905 Loss_G: 0.0344 Convergence: 0.0935 k= 0.022479 lr = 0.0000226\n",
      "[9/25][740/9765] Loss_D: 0.0977 Loss_G: 0.0378 Convergence: 0.1001 k= 0.022491 lr = 0.0000226\n",
      "[9/25][750/9765] Loss_D: 0.0992 Loss_G: 0.0400 Convergence: 0.1002 k= 0.022482 lr = 0.0000226\n",
      "[9/25][760/9765] Loss_D: 0.0909 Loss_G: 0.0394 Convergence: 0.0945 k= 0.022462 lr = 0.0000226\n",
      "[9/25][770/9765] Loss_D: 0.1083 Loss_G: 0.0385 Convergence: 0.1142 k= 0.022480 lr = 0.0000226\n",
      "[9/25][780/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1026 k= 0.022481 lr = 0.0000226\n",
      "[9/25][790/9765] Loss_D: 0.0982 Loss_G: 0.0406 Convergence: 0.1001 k= 0.022478 lr = 0.0000226\n",
      "[9/25][800/9765] Loss_D: 0.0981 Loss_G: 0.0380 Convergence: 0.1005 k= 0.022481 lr = 0.0000226\n",
      "[9/25][810/9765] Loss_D: 0.1048 Loss_G: 0.0376 Convergence: 0.1103 k= 0.022487 lr = 0.0000226\n",
      "[9/25][820/9765] Loss_D: 0.0975 Loss_G: 0.0391 Convergence: 0.0987 k= 0.022503 lr = 0.0000226\n",
      "[9/25][830/9765] Loss_D: 0.0933 Loss_G: 0.0392 Convergence: 0.0957 k= 0.022501 lr = 0.0000226\n",
      "[9/25][840/9765] Loss_D: 0.0890 Loss_G: 0.0401 Convergence: 0.0941 k= 0.022501 lr = 0.0000226\n",
      "[9/25][850/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.0999 k= 0.022489 lr = 0.0000226\n",
      "[9/25][860/9765] Loss_D: 0.0995 Loss_G: 0.0384 Convergence: 0.1021 k= 0.022497 lr = 0.0000226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][870/9765] Loss_D: 0.1005 Loss_G: 0.0395 Convergence: 0.1025 k= 0.022508 lr = 0.0000226\n",
      "[9/25][880/9765] Loss_D: 0.1012 Loss_G: 0.0389 Convergence: 0.1040 k= 0.022503 lr = 0.0000226\n",
      "[9/25][890/9765] Loss_D: 0.1067 Loss_G: 0.0401 Convergence: 0.1106 k= 0.022500 lr = 0.0000226\n",
      "[9/25][900/9765] Loss_D: 0.1054 Loss_G: 0.0372 Convergence: 0.1115 k= 0.022508 lr = 0.0000226\n",
      "[9/25][910/9765] Loss_D: 0.0944 Loss_G: 0.0381 Convergence: 0.0954 k= 0.022498 lr = 0.0000226\n",
      "[9/25][920/9765] Loss_D: 0.1010 Loss_G: 0.0395 Convergence: 0.1032 k= 0.022501 lr = 0.0000226\n",
      "[9/25][930/9765] Loss_D: 0.0929 Loss_G: 0.0369 Convergence: 0.0943 k= 0.022508 lr = 0.0000226\n",
      "[9/25][940/9765] Loss_D: 0.0967 Loss_G: 0.0362 Convergence: 0.1006 k= 0.022518 lr = 0.0000226\n",
      "[9/25][950/9765] Loss_D: 0.1012 Loss_G: 0.0399 Convergence: 0.1031 k= 0.022532 lr = 0.0000226\n",
      "[9/25][960/9765] Loss_D: 0.0977 Loss_G: 0.0417 Convergence: 0.1008 k= 0.022500 lr = 0.0000226\n",
      "[9/25][970/9765] Loss_D: 0.0938 Loss_G: 0.0395 Convergence: 0.0963 k= 0.022495 lr = 0.0000226\n",
      "[9/25][980/9765] Loss_D: 0.1062 Loss_G: 0.0450 Convergence: 0.1093 k= 0.022484 lr = 0.0000226\n",
      "[9/25][990/9765] Loss_D: 0.0941 Loss_G: 0.0417 Convergence: 0.0987 k= 0.022459 lr = 0.0000226\n",
      "[9/25][1000/9765] Loss_D: 0.0997 Loss_G: 0.0377 Convergence: 0.1030 k= 0.022461 lr = 0.0000226\n",
      "[9/25][1010/9765] Loss_D: 0.0941 Loss_G: 0.0407 Convergence: 0.0977 k= 0.022479 lr = 0.0000226\n",
      "[9/25][1020/9765] Loss_D: 0.0958 Loss_G: 0.0427 Convergence: 0.1007 k= 0.022460 lr = 0.0000226\n",
      "[9/25][1030/9765] Loss_D: 0.0929 Loss_G: 0.0368 Convergence: 0.0944 k= 0.022453 lr = 0.0000226\n",
      "[9/25][1040/9765] Loss_D: 0.0988 Loss_G: 0.0432 Convergence: 0.1030 k= 0.022462 lr = 0.0000226\n",
      "[9/25][1050/9765] Loss_D: 0.0983 Loss_G: 0.0394 Convergence: 0.0994 k= 0.022472 lr = 0.0000226\n",
      "[9/25][1060/9765] Loss_D: 0.0985 Loss_G: 0.0411 Convergence: 0.1008 k= 0.022434 lr = 0.0000226\n",
      "[9/25][1070/9765] Loss_D: 0.1078 Loss_G: 0.0448 Convergence: 0.1100 k= 0.022425 lr = 0.0000226\n",
      "[9/25][1080/9765] Loss_D: 0.1046 Loss_G: 0.0384 Convergence: 0.1092 k= 0.022451 lr = 0.0000226\n",
      "[9/25][1090/9765] Loss_D: 0.0944 Loss_G: 0.0401 Convergence: 0.0973 k= 0.022456 lr = 0.0000226\n",
      "[9/25][1100/9765] Loss_D: 0.1109 Loss_G: 0.0436 Convergence: 0.1130 k= 0.022434 lr = 0.0000226\n",
      "[9/25][1110/9765] Loss_D: 0.0974 Loss_G: 0.0391 Convergence: 0.0985 k= 0.022427 lr = 0.0000226\n",
      "[9/25][1120/9765] Loss_D: 0.0921 Loss_G: 0.0385 Convergence: 0.0943 k= 0.022428 lr = 0.0000226\n",
      "[9/25][1130/9765] Loss_D: 0.0935 Loss_G: 0.0403 Convergence: 0.0969 k= 0.022429 lr = 0.0000226\n",
      "[9/25][1140/9765] Loss_D: 0.0949 Loss_G: 0.0430 Convergence: 0.1005 k= 0.022415 lr = 0.0000226\n",
      "[9/25][1150/9765] Loss_D: 0.1062 Loss_G: 0.0391 Convergence: 0.1108 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1160/9765] Loss_D: 0.1073 Loss_G: 0.0395 Convergence: 0.1119 k= 0.022400 lr = 0.0000226\n",
      "[9/25][1170/9765] Loss_D: 0.1039 Loss_G: 0.0413 Convergence: 0.1053 k= 0.022407 lr = 0.0000226\n",
      "[9/25][1180/9765] Loss_D: 0.0869 Loss_G: 0.0372 Convergence: 0.0898 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1190/9765] Loss_D: 0.1021 Loss_G: 0.0414 Convergence: 0.1032 k= 0.022397 lr = 0.0000226\n",
      "[9/25][1200/9765] Loss_D: 0.0962 Loss_G: 0.0365 Convergence: 0.0994 k= 0.022422 lr = 0.0000226\n",
      "[9/25][1210/9765] Loss_D: 0.1078 Loss_G: 0.0414 Convergence: 0.1107 k= 0.022444 lr = 0.0000226\n",
      "[9/25][1220/9765] Loss_D: 0.1081 Loss_G: 0.0403 Convergence: 0.1124 k= 0.022440 lr = 0.0000226\n",
      "[9/25][1230/9765] Loss_D: 0.0958 Loss_G: 0.0399 Convergence: 0.0978 k= 0.022442 lr = 0.0000226\n",
      "[9/25][1240/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1033 k= 0.022420 lr = 0.0000226\n",
      "[9/25][1250/9765] Loss_D: 0.0958 Loss_G: 0.0398 Convergence: 0.0978 k= 0.022404 lr = 0.0000226\n",
      "[9/25][1260/9765] Loss_D: 0.0989 Loss_G: 0.0407 Convergence: 0.1006 k= 0.022389 lr = 0.0000226\n",
      "[9/25][1270/9765] Loss_D: 0.1069 Loss_G: 0.0390 Convergence: 0.1120 k= 0.022394 lr = 0.0000226\n",
      "[9/25][1280/9765] Loss_D: 0.0967 Loss_G: 0.0376 Convergence: 0.0991 k= 0.022396 lr = 0.0000226\n",
      "[9/25][1290/9765] Loss_D: 0.0939 Loss_G: 0.0403 Convergence: 0.0972 k= 0.022398 lr = 0.0000226\n",
      "[9/25][1300/9765] Loss_D: 0.1017 Loss_G: 0.0381 Convergence: 0.1054 k= 0.022423 lr = 0.0000226\n",
      "[9/25][1310/9765] Loss_D: 0.1019 Loss_G: 0.0409 Convergence: 0.1030 k= 0.022433 lr = 0.0000226\n",
      "[9/25][1320/9765] Loss_D: 0.1037 Loss_G: 0.0450 Convergence: 0.1078 k= 0.022406 lr = 0.0000226\n",
      "[9/25][1330/9765] Loss_D: 0.1011 Loss_G: 0.0421 Convergence: 0.1033 k= 0.022377 lr = 0.0000226\n",
      "[9/25][1340/9765] Loss_D: 0.1166 Loss_G: 0.0412 Convergence: 0.1232 k= 0.022377 lr = 0.0000226\n",
      "[9/25][1350/9765] Loss_D: 0.1002 Loss_G: 0.0400 Convergence: 0.1016 k= 0.022377 lr = 0.0000226\n",
      "[9/25][1360/9765] Loss_D: 0.1075 Loss_G: 0.0426 Convergence: 0.1092 k= 0.022375 lr = 0.0000226\n",
      "[9/25][1370/9765] Loss_D: 0.0962 Loss_G: 0.0426 Convergence: 0.1009 k= 0.022340 lr = 0.0000226\n",
      "[9/25][1380/9765] Loss_D: 0.1094 Loss_G: 0.0420 Convergence: 0.1125 k= 0.022315 lr = 0.0000226\n",
      "[9/25][1390/9765] Loss_D: 0.0960 Loss_G: 0.0383 Convergence: 0.0973 k= 0.022305 lr = 0.0000226\n",
      "[9/25][1400/9765] Loss_D: 0.0946 Loss_G: 0.0386 Convergence: 0.0959 k= 0.022314 lr = 0.0000226\n",
      "[9/25][1410/9765] Loss_D: 0.0996 Loss_G: 0.0386 Convergence: 0.1021 k= 0.022330 lr = 0.0000226\n",
      "[9/25][1420/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0972 k= 0.022356 lr = 0.0000226\n",
      "[9/25][1430/9765] Loss_D: 0.1035 Loss_G: 0.0420 Convergence: 0.1046 k= 0.022350 lr = 0.0000226\n",
      "[9/25][1440/9765] Loss_D: 0.1050 Loss_G: 0.0429 Convergence: 0.1064 k= 0.022333 lr = 0.0000226\n",
      "[9/25][1450/9765] Loss_D: 0.1003 Loss_G: 0.0402 Convergence: 0.1015 k= 0.022336 lr = 0.0000226\n",
      "[9/25][1460/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1007 k= 0.022333 lr = 0.0000226\n",
      "[9/25][1470/9765] Loss_D: 0.0962 Loss_G: 0.0396 Convergence: 0.0979 k= 0.022334 lr = 0.0000226\n",
      "[9/25][1480/9765] Loss_D: 0.1034 Loss_G: 0.0437 Convergence: 0.1063 k= 0.022314 lr = 0.0000226\n",
      "[9/25][1490/9765] Loss_D: 0.1004 Loss_G: 0.0387 Convergence: 0.1031 k= 0.022314 lr = 0.0000226\n",
      "[9/25][1500/9765] Loss_D: 0.1015 Loss_G: 0.0375 Convergence: 0.1058 k= 0.022323 lr = 0.0000226\n",
      "[9/25][1510/9765] Loss_D: 0.0949 Loss_G: 0.0395 Convergence: 0.0970 k= 0.022325 lr = 0.0000226\n",
      "[9/25][1520/9765] Loss_D: 0.0995 Loss_G: 0.0375 Convergence: 0.1029 k= 0.022339 lr = 0.0000226\n",
      "[9/25][1530/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0969 k= 0.022321 lr = 0.0000226\n",
      "[9/25][1540/9765] Loss_D: 0.0999 Loss_G: 0.0436 Convergence: 0.1042 k= 0.022307 lr = 0.0000226\n",
      "[9/25][1550/9765] Loss_D: 0.1018 Loss_G: 0.0399 Convergence: 0.1039 k= 0.022288 lr = 0.0000226\n",
      "[9/25][1560/9765] Loss_D: 0.0903 Loss_G: 0.0363 Convergence: 0.0914 k= 0.022290 lr = 0.0000226\n",
      "[9/25][1570/9765] Loss_D: 0.0978 Loss_G: 0.0389 Convergence: 0.0992 k= 0.022337 lr = 0.0000226\n",
      "[9/25][1580/9765] Loss_D: 0.1034 Loss_G: 0.0468 Convergence: 0.1094 k= 0.022321 lr = 0.0000226\n",
      "[9/25][1590/9765] Loss_D: 0.1071 Loss_G: 0.0383 Convergence: 0.1128 k= 0.022335 lr = 0.0000226\n",
      "[9/25][1600/9765] Loss_D: 0.1005 Loss_G: 0.0368 Convergence: 0.1050 k= 0.022344 lr = 0.0000226\n",
      "[9/25][1610/9765] Loss_D: 0.1047 Loss_G: 0.0373 Convergence: 0.1104 k= 0.022366 lr = 0.0000226\n",
      "[9/25][1620/9765] Loss_D: 0.1026 Loss_G: 0.0369 Convergence: 0.1079 k= 0.022398 lr = 0.0000226\n",
      "[9/25][1630/9765] Loss_D: 0.0938 Loss_G: 0.0408 Convergence: 0.0976 k= 0.022410 lr = 0.0000226\n",
      "[9/25][1640/9765] Loss_D: 0.1106 Loss_G: 0.0402 Convergence: 0.1158 k= 0.022407 lr = 0.0000226\n",
      "[9/25][1650/9765] Loss_D: 0.0923 Loss_G: 0.0410 Convergence: 0.0969 k= 0.022396 lr = 0.0000226\n",
      "[9/25][1660/9765] Loss_D: 0.1089 Loss_G: 0.0458 Convergence: 0.1117 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1670/9765] Loss_D: 0.1063 Loss_G: 0.0409 Convergence: 0.1092 k= 0.022383 lr = 0.0000226\n",
      "[9/25][1680/9765] Loss_D: 0.0962 Loss_G: 0.0390 Convergence: 0.0973 k= 0.022384 lr = 0.0000226\n",
      "[9/25][1690/9765] Loss_D: 0.0987 Loss_G: 0.0410 Convergence: 0.1008 k= 0.022385 lr = 0.0000226\n",
      "[9/25][1700/9765] Loss_D: 0.0928 Loss_G: 0.0407 Convergence: 0.0970 k= 0.022357 lr = 0.0000226\n",
      "[9/25][1710/9765] Loss_D: 0.0964 Loss_G: 0.0364 Convergence: 0.0998 k= 0.022370 lr = 0.0000226\n",
      "[9/25][1720/9765] Loss_D: 0.0903 Loss_G: 0.0406 Convergence: 0.0953 k= 0.022366 lr = 0.0000226\n",
      "[9/25][1730/9765] Loss_D: 0.1024 Loss_G: 0.0411 Convergence: 0.1036 k= 0.022371 lr = 0.0000226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][1740/9765] Loss_D: 0.1029 Loss_G: 0.0432 Convergence: 0.1055 k= 0.022366 lr = 0.0000226\n",
      "[9/25][1750/9765] Loss_D: 0.0935 Loss_G: 0.0397 Convergence: 0.0963 k= 0.022342 lr = 0.0000226\n",
      "[9/25][1760/9765] Loss_D: 0.1089 Loss_G: 0.0403 Convergence: 0.1135 k= 0.022351 lr = 0.0000226\n",
      "[9/25][1770/9765] Loss_D: 0.0957 Loss_G: 0.0409 Convergence: 0.0989 k= 0.022328 lr = 0.0000226\n",
      "[9/25][1780/9765] Loss_D: 0.1001 Loss_G: 0.0421 Convergence: 0.1027 k= 0.022336 lr = 0.0000226\n",
      "[9/25][1790/9765] Loss_D: 0.0962 Loss_G: 0.0396 Convergence: 0.0978 k= 0.022323 lr = 0.0000226\n",
      "[9/25][1800/9765] Loss_D: 0.0975 Loss_G: 0.0405 Convergence: 0.0996 k= 0.022330 lr = 0.0000226\n",
      "[9/25][1810/9765] Loss_D: 0.1054 Loss_G: 0.0402 Convergence: 0.1087 k= 0.022340 lr = 0.0000226\n",
      "[9/25][1820/9765] Loss_D: 0.0973 Loss_G: 0.0398 Convergence: 0.0987 k= 0.022347 lr = 0.0000226\n",
      "[9/25][1830/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0965 k= 0.022333 lr = 0.0000226\n",
      "[9/25][1840/9765] Loss_D: 0.0938 Loss_G: 0.0364 Convergence: 0.0961 k= 0.022356 lr = 0.0000226\n",
      "[9/25][1850/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0993 k= 0.022371 lr = 0.0000226\n",
      "[9/25][1860/9765] Loss_D: 0.1101 Loss_G: 0.0405 Convergence: 0.1148 k= 0.022376 lr = 0.0000226\n",
      "[9/25][1870/9765] Loss_D: 0.1018 Loss_G: 0.0384 Convergence: 0.1054 k= 0.022391 lr = 0.0000226\n",
      "[9/25][1880/9765] Loss_D: 0.0918 Loss_G: 0.0378 Convergence: 0.0933 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1890/9765] Loss_D: 0.1022 Loss_G: 0.0398 Convergence: 0.1045 k= 0.022397 lr = 0.0000226\n",
      "[9/25][1900/9765] Loss_D: 0.0994 Loss_G: 0.0396 Convergence: 0.1007 k= 0.022399 lr = 0.0000226\n",
      "[9/25][1910/9765] Loss_D: 0.1054 Loss_G: 0.0387 Convergence: 0.1101 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1920/9765] Loss_D: 0.0888 Loss_G: 0.0398 Convergence: 0.0936 k= 0.022393 lr = 0.0000226\n",
      "[9/25][1930/9765] Loss_D: 0.0914 Loss_G: 0.0385 Convergence: 0.0939 k= 0.022387 lr = 0.0000226\n",
      "[9/25][1940/9765] Loss_D: 0.0996 Loss_G: 0.0396 Convergence: 0.1010 k= 0.022397 lr = 0.0000226\n",
      "[9/25][1950/9765] Loss_D: 0.1017 Loss_G: 0.0460 Convergence: 0.1076 k= 0.022374 lr = 0.0000226\n",
      "[9/25][1960/9765] Loss_D: 0.1072 Loss_G: 0.0428 Convergence: 0.1086 k= 0.022331 lr = 0.0000226\n",
      "[9/25][1970/9765] Loss_D: 0.0960 Loss_G: 0.0386 Convergence: 0.0969 k= 0.022329 lr = 0.0000226\n",
      "[9/25][1980/9765] Loss_D: 0.0991 Loss_G: 0.0341 Convergence: 0.1058 k= 0.022357 lr = 0.0000226\n",
      "[9/25][1990/9765] Loss_D: 0.0956 Loss_G: 0.0426 Convergence: 0.1005 k= 0.022362 lr = 0.0000226\n",
      "[9/25][2000/9765] Loss_D: 0.0961 Loss_G: 0.0408 Convergence: 0.0991 k= 0.022332 lr = 0.0000226\n",
      "[9/25][2010/9765] Loss_D: 0.0958 Loss_G: 0.0428 Convergence: 0.1009 k= 0.022281 lr = 0.0000226\n",
      "[9/25][2020/9765] Loss_D: 0.1022 Loss_G: 0.0364 Convergence: 0.1078 k= 0.022286 lr = 0.0000226\n",
      "[9/25][2030/9765] Loss_D: 0.1068 Loss_G: 0.0404 Convergence: 0.1103 k= 0.022331 lr = 0.0000226\n",
      "[9/25][2040/9765] Loss_D: 0.0980 Loss_G: 0.0424 Convergence: 0.1017 k= 0.022312 lr = 0.0000226\n",
      "[9/25][2050/9765] Loss_D: 0.0988 Loss_G: 0.0386 Convergence: 0.1009 k= 0.022322 lr = 0.0000226\n",
      "[9/25][2060/9765] Loss_D: 0.0977 Loss_G: 0.0415 Convergence: 0.1006 k= 0.022327 lr = 0.0000226\n",
      "[9/25][2070/9765] Loss_D: 0.0996 Loss_G: 0.0382 Convergence: 0.1024 k= 0.022338 lr = 0.0000226\n",
      "[9/25][2080/9765] Loss_D: 0.0974 Loss_G: 0.0355 Convergence: 0.1020 k= 0.022351 lr = 0.0000226\n",
      "[9/25][2090/9765] Loss_D: 0.0906 Loss_G: 0.0395 Convergence: 0.0944 k= 0.022366 lr = 0.0000226\n",
      "[9/25][2100/9765] Loss_D: 0.0908 Loss_G: 0.0405 Convergence: 0.0955 k= 0.022334 lr = 0.0000226\n",
      "[9/25][2110/9765] Loss_D: 0.0995 Loss_G: 0.0397 Convergence: 0.1008 k= 0.022335 lr = 0.0000226\n",
      "[9/25][2120/9765] Loss_D: 0.0925 Loss_G: 0.0376 Convergence: 0.0936 k= 0.022323 lr = 0.0000215\n",
      "[9/25][2130/9765] Loss_D: 0.0981 Loss_G: 0.0396 Convergence: 0.0991 k= 0.022321 lr = 0.0000215\n",
      "[9/25][2140/9765] Loss_D: 0.1005 Loss_G: 0.0374 Convergence: 0.1045 k= 0.022334 lr = 0.0000215\n",
      "[9/25][2150/9765] Loss_D: 0.0962 Loss_G: 0.0379 Convergence: 0.0980 k= 0.022344 lr = 0.0000215\n",
      "[9/25][2160/9765] Loss_D: 0.0831 Loss_G: 0.0375 Convergence: 0.0878 k= 0.022336 lr = 0.0000215\n",
      "[9/25][2170/9765] Loss_D: 0.1008 Loss_G: 0.0384 Convergence: 0.1040 k= 0.022335 lr = 0.0000215\n",
      "[9/25][2180/9765] Loss_D: 0.0996 Loss_G: 0.0418 Convergence: 0.1021 k= 0.022330 lr = 0.0000215\n",
      "[9/25][2190/9765] Loss_D: 0.0942 Loss_G: 0.0397 Convergence: 0.0968 k= 0.022315 lr = 0.0000215\n",
      "[9/25][2200/9765] Loss_D: 0.1010 Loss_G: 0.0393 Convergence: 0.1033 k= 0.022310 lr = 0.0000215\n",
      "[9/25][2210/9765] Loss_D: 0.0985 Loss_G: 0.0409 Convergence: 0.1005 k= 0.022319 lr = 0.0000215\n",
      "[9/25][2220/9765] Loss_D: 0.0919 Loss_G: 0.0396 Convergence: 0.0953 k= 0.022314 lr = 0.0000215\n",
      "[9/25][2230/9765] Loss_D: 0.1086 Loss_G: 0.0423 Convergence: 0.1110 k= 0.022316 lr = 0.0000215\n",
      "[9/25][2240/9765] Loss_D: 0.1000 Loss_G: 0.0396 Convergence: 0.1017 k= 0.022308 lr = 0.0000215\n",
      "[9/25][2250/9765] Loss_D: 0.0904 Loss_G: 0.0365 Convergence: 0.0913 k= 0.022348 lr = 0.0000215\n",
      "[9/25][2260/9765] Loss_D: 0.1042 Loss_G: 0.0413 Convergence: 0.1058 k= 0.022350 lr = 0.0000215\n",
      "[9/25][2270/9765] Loss_D: 0.0986 Loss_G: 0.0450 Convergence: 0.1048 k= 0.022326 lr = 0.0000215\n",
      "[9/25][2280/9765] Loss_D: 0.1021 Loss_G: 0.0365 Convergence: 0.1077 k= 0.022317 lr = 0.0000215\n",
      "[9/25][2290/9765] Loss_D: 0.0998 Loss_G: 0.0393 Convergence: 0.1016 k= 0.022338 lr = 0.0000215\n",
      "[9/25][2300/9765] Loss_D: 0.0933 Loss_G: 0.0434 Convergence: 0.0999 k= 0.022335 lr = 0.0000215\n",
      "[9/25][2310/9765] Loss_D: 0.0917 Loss_G: 0.0411 Convergence: 0.0966 k= 0.022313 lr = 0.0000215\n",
      "[9/25][2320/9765] Loss_D: 0.1140 Loss_G: 0.0414 Convergence: 0.1195 k= 0.022300 lr = 0.0000215\n",
      "[9/25][2330/9765] Loss_D: 0.0979 Loss_G: 0.0441 Convergence: 0.1034 k= 0.022270 lr = 0.0000215\n",
      "[9/25][2340/9765] Loss_D: 0.1052 Loss_G: 0.0412 Convergence: 0.1073 k= 0.022255 lr = 0.0000215\n",
      "[9/25][2350/9765] Loss_D: 0.0919 Loss_G: 0.0376 Convergence: 0.0933 k= 0.022269 lr = 0.0000215\n",
      "[9/25][2360/9765] Loss_D: 0.1101 Loss_G: 0.0408 Convergence: 0.1145 k= 0.022274 lr = 0.0000215\n",
      "[9/25][2370/9765] Loss_D: 0.0871 Loss_G: 0.0514 Convergence: 0.1043 k= 0.022190 lr = 0.0000215\n",
      "[9/25][2380/9765] Loss_D: 0.0976 Loss_G: 0.0458 Convergence: 0.1049 k= 0.022143 lr = 0.0000215\n",
      "[9/25][2390/9765] Loss_D: 0.0978 Loss_G: 0.0379 Convergence: 0.1001 k= 0.022147 lr = 0.0000215\n",
      "[9/25][2400/9765] Loss_D: 0.1010 Loss_G: 0.0359 Convergence: 0.1065 k= 0.022189 lr = 0.0000215\n",
      "[9/25][2410/9765] Loss_D: 0.0987 Loss_G: 0.0401 Convergence: 0.0999 k= 0.022222 lr = 0.0000215\n",
      "[9/25][2420/9765] Loss_D: 0.1029 Loss_G: 0.0407 Convergence: 0.1046 k= 0.022208 lr = 0.0000215\n",
      "[9/25][2430/9765] Loss_D: 0.0922 Loss_G: 0.0422 Convergence: 0.0981 k= 0.022192 lr = 0.0000215\n",
      "[9/25][2440/9765] Loss_D: 0.0950 Loss_G: 0.0385 Convergence: 0.0960 k= 0.022186 lr = 0.0000215\n",
      "[9/25][2450/9765] Loss_D: 0.0996 Loss_G: 0.0388 Convergence: 0.1019 k= 0.022191 lr = 0.0000215\n",
      "[9/25][2460/9765] Loss_D: 0.0957 Loss_G: 0.0393 Convergence: 0.0972 k= 0.022213 lr = 0.0000215\n",
      "[9/25][2470/9765] Loss_D: 0.1014 Loss_G: 0.0438 Convergence: 0.1051 k= 0.022213 lr = 0.0000215\n",
      "[9/25][2480/9765] Loss_D: 0.0971 Loss_G: 0.0405 Convergence: 0.0993 k= 0.022207 lr = 0.0000215\n",
      "[9/25][2490/9765] Loss_D: 0.0902 Loss_G: 0.0394 Convergence: 0.0940 k= 0.022193 lr = 0.0000215\n",
      "[9/25][2500/9765] Loss_D: 0.0865 Loss_G: 0.0378 Convergence: 0.0902 k= 0.022207 lr = 0.0000215\n",
      "[9/25][2510/9765] Loss_D: 0.0955 Loss_G: 0.0401 Convergence: 0.0979 k= 0.022202 lr = 0.0000215\n",
      "[9/25][2520/9765] Loss_D: 0.0947 Loss_G: 0.0404 Convergence: 0.0978 k= 0.022196 lr = 0.0000215\n",
      "[9/25][2530/9765] Loss_D: 0.1011 Loss_G: 0.0422 Convergence: 0.1035 k= 0.022186 lr = 0.0000215\n",
      "[9/25][2540/9765] Loss_D: 0.0954 Loss_G: 0.0421 Convergence: 0.0998 k= 0.022177 lr = 0.0000215\n",
      "[9/25][2550/9765] Loss_D: 0.0969 Loss_G: 0.0403 Convergence: 0.0989 k= 0.022163 lr = 0.0000215\n",
      "[9/25][2560/9765] Loss_D: 0.1094 Loss_G: 0.0385 Convergence: 0.1158 k= 0.022169 lr = 0.0000215\n",
      "[9/25][2570/9765] Loss_D: 0.0938 Loss_G: 0.0364 Convergence: 0.0961 k= 0.022184 lr = 0.0000215\n",
      "[9/25][2580/9765] Loss_D: 0.0904 Loss_G: 0.0341 Convergence: 0.0935 k= 0.022209 lr = 0.0000215\n",
      "[9/25][2590/9765] Loss_D: 0.0938 Loss_G: 0.0405 Convergence: 0.0973 k= 0.022227 lr = 0.0000215\n",
      "[9/25][2600/9765] Loss_D: 0.1027 Loss_G: 0.0396 Convergence: 0.1053 k= 0.022228 lr = 0.0000215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][2610/9765] Loss_D: 0.0945 Loss_G: 0.0413 Convergence: 0.0985 k= 0.022225 lr = 0.0000215\n",
      "[9/25][2620/9765] Loss_D: 0.0918 Loss_G: 0.0378 Convergence: 0.0935 k= 0.022222 lr = 0.0000215\n",
      "[9/25][2630/9765] Loss_D: 0.1010 Loss_G: 0.0392 Convergence: 0.1033 k= 0.022224 lr = 0.0000215\n",
      "[9/25][2640/9765] Loss_D: 0.0979 Loss_G: 0.0383 Convergence: 0.0999 k= 0.022226 lr = 0.0000215\n",
      "[9/25][2650/9765] Loss_D: 0.1074 Loss_G: 0.0405 Convergence: 0.1111 k= 0.022239 lr = 0.0000215\n",
      "[9/25][2660/9765] Loss_D: 0.0946 Loss_G: 0.0410 Convergence: 0.0983 k= 0.022239 lr = 0.0000215\n",
      "[9/25][2670/9765] Loss_D: 0.1031 Loss_G: 0.0381 Convergence: 0.1074 k= 0.022251 lr = 0.0000215\n",
      "[9/25][2680/9765] Loss_D: 0.1016 Loss_G: 0.0420 Convergence: 0.1035 k= 0.022242 lr = 0.0000215\n",
      "[9/25][2690/9765] Loss_D: 0.0941 Loss_G: 0.0414 Convergence: 0.0984 k= 0.022229 lr = 0.0000215\n",
      "[9/25][2700/9765] Loss_D: 0.0984 Loss_G: 0.0361 Convergence: 0.1027 k= 0.022238 lr = 0.0000215\n",
      "[9/25][2710/9765] Loss_D: 0.0997 Loss_G: 0.0422 Convergence: 0.1025 k= 0.022260 lr = 0.0000215\n",
      "[9/25][2720/9765] Loss_D: 0.1044 Loss_G: 0.0386 Convergence: 0.1087 k= 0.022256 lr = 0.0000215\n",
      "[9/25][2730/9765] Loss_D: 0.0972 Loss_G: 0.0429 Convergence: 0.1018 k= 0.022244 lr = 0.0000215\n",
      "[9/25][2740/9765] Loss_D: 0.0966 Loss_G: 0.0381 Convergence: 0.0984 k= 0.022237 lr = 0.0000215\n",
      "[9/25][2750/9765] Loss_D: 0.0976 Loss_G: 0.0381 Convergence: 0.0998 k= 0.022246 lr = 0.0000215\n",
      "[9/25][2760/9765] Loss_D: 0.0989 Loss_G: 0.0412 Convergence: 0.1011 k= 0.022243 lr = 0.0000215\n",
      "[9/25][2770/9765] Loss_D: 0.1005 Loss_G: 0.0412 Convergence: 0.1021 k= 0.022239 lr = 0.0000215\n",
      "[9/25][2780/9765] Loss_D: 0.0965 Loss_G: 0.0399 Convergence: 0.0983 k= 0.022237 lr = 0.0000215\n",
      "[9/25][2790/9765] Loss_D: 0.1000 Loss_G: 0.0409 Convergence: 0.1015 k= 0.022238 lr = 0.0000215\n",
      "[9/25][2800/9765] Loss_D: 0.1008 Loss_G: 0.0376 Convergence: 0.1047 k= 0.022245 lr = 0.0000215\n",
      "[9/25][2810/9765] Loss_D: 0.1006 Loss_G: 0.0349 Convergence: 0.1069 k= 0.022259 lr = 0.0000215\n",
      "[9/25][2820/9765] Loss_D: 0.1000 Loss_G: 0.0414 Convergence: 0.1020 k= 0.022268 lr = 0.0000215\n",
      "[9/25][2830/9765] Loss_D: 0.0994 Loss_G: 0.0382 Convergence: 0.1022 k= 0.022275 lr = 0.0000215\n",
      "[9/25][2840/9765] Loss_D: 0.0958 Loss_G: 0.0431 Convergence: 0.1012 k= 0.022235 lr = 0.0000215\n",
      "[9/25][2850/9765] Loss_D: 0.0977 Loss_G: 0.0395 Convergence: 0.0987 k= 0.022238 lr = 0.0000215\n",
      "[9/25][2860/9765] Loss_D: 0.1045 Loss_G: 0.0383 Convergence: 0.1091 k= 0.022279 lr = 0.0000215\n",
      "[9/25][2870/9765] Loss_D: 0.1052 Loss_G: 0.0353 Convergence: 0.1132 k= 0.022321 lr = 0.0000215\n",
      "[9/25][2880/9765] Loss_D: 0.1019 Loss_G: 0.0780 Convergence: 0.1401 k= 0.022215 lr = 0.0000215\n",
      "[9/25][2890/9765] Loss_D: 0.1051 Loss_G: 0.0463 Convergence: 0.1100 k= 0.022035 lr = 0.0000215\n",
      "[9/25][2900/9765] Loss_D: 0.0902 Loss_G: 0.0374 Convergence: 0.0921 k= 0.022023 lr = 0.0000215\n",
      "[9/25][2910/9765] Loss_D: 0.0910 Loss_G: 0.0343 Convergence: 0.0941 k= 0.022059 lr = 0.0000215\n",
      "[9/25][2920/9765] Loss_D: 0.0947 Loss_G: 0.0375 Convergence: 0.0963 k= 0.022081 lr = 0.0000215\n",
      "[9/25][2930/9765] Loss_D: 0.0952 Loss_G: 0.0414 Convergence: 0.0991 k= 0.022047 lr = 0.0000215\n",
      "[9/25][2940/9765] Loss_D: 0.0968 Loss_G: 0.0400 Convergence: 0.0987 k= 0.022038 lr = 0.0000215\n",
      "[9/25][2950/9765] Loss_D: 0.1026 Loss_G: 0.0374 Convergence: 0.1073 k= 0.022062 lr = 0.0000215\n",
      "[9/25][2960/9765] Loss_D: 0.1018 Loss_G: 0.0409 Convergence: 0.1029 k= 0.022082 lr = 0.0000215\n",
      "[9/25][2970/9765] Loss_D: 0.1012 Loss_G: 0.0383 Convergence: 0.1046 k= 0.022063 lr = 0.0000215\n",
      "[9/25][2980/9765] Loss_D: 0.1097 Loss_G: 0.0422 Convergence: 0.1127 k= 0.022057 lr = 0.0000215\n",
      "[9/25][2990/9765] Loss_D: 0.0903 Loss_G: 0.0370 Convergence: 0.0916 k= 0.022052 lr = 0.0000215\n",
      "[9/25][3000/9765] Loss_D: 0.1034 Loss_G: 0.0359 Convergence: 0.1099 k= 0.022094 lr = 0.0000215\n",
      "[9/25][3010/9765] Loss_D: 0.0916 Loss_G: 0.0423 Convergence: 0.0978 k= 0.022099 lr = 0.0000215\n",
      "[9/25][3020/9765] Loss_D: 0.0945 Loss_G: 0.0386 Convergence: 0.0958 k= 0.022068 lr = 0.0000215\n",
      "[9/25][3030/9765] Loss_D: 0.1033 Loss_G: 0.0417 Convergence: 0.1042 k= 0.022063 lr = 0.0000215\n",
      "[9/25][3040/9765] Loss_D: 0.1023 Loss_G: 0.0382 Convergence: 0.1063 k= 0.022077 lr = 0.0000215\n",
      "[9/25][3050/9765] Loss_D: 0.1010 Loss_G: 0.0425 Convergence: 0.1036 k= 0.022083 lr = 0.0000215\n",
      "[9/25][3060/9765] Loss_D: 0.0980 Loss_G: 0.0395 Convergence: 0.0989 k= 0.022064 lr = 0.0000215\n",
      "[9/25][3070/9765] Loss_D: 0.1028 Loss_G: 0.0382 Convergence: 0.1068 k= 0.022074 lr = 0.0000215\n",
      "[9/25][3080/9765] Loss_D: 0.1062 Loss_G: 0.0385 Convergence: 0.1115 k= 0.022075 lr = 0.0000215\n",
      "[9/25][3090/9765] Loss_D: 0.1047 Loss_G: 0.0369 Convergence: 0.1107 k= 0.022095 lr = 0.0000215\n",
      "[9/25][3100/9765] Loss_D: 0.1036 Loss_G: 0.0413 Convergence: 0.1050 k= 0.022112 lr = 0.0000215\n",
      "[9/25][3110/9765] Loss_D: 0.1076 Loss_G: 0.0431 Convergence: 0.1088 k= 0.022088 lr = 0.0000215\n",
      "[9/25][3120/9765] Loss_D: 0.1053 Loss_G: 0.0401 Convergence: 0.1086 k= 0.022077 lr = 0.0000215\n",
      "[9/25][3130/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.022065 lr = 0.0000215\n",
      "[9/25][3140/9765] Loss_D: 0.0956 Loss_G: 0.0379 Convergence: 0.0970 k= 0.022082 lr = 0.0000215\n",
      "[9/25][3150/9765] Loss_D: 0.1109 Loss_G: 0.0423 Convergence: 0.1143 k= 0.022089 lr = 0.0000215\n",
      "[9/25][3160/9765] Loss_D: 0.1026 Loss_G: 0.0416 Convergence: 0.1037 k= 0.022084 lr = 0.0000215\n",
      "[9/25][3170/9765] Loss_D: 0.0978 Loss_G: 0.0390 Convergence: 0.0992 k= 0.022078 lr = 0.0000215\n",
      "[9/25][3180/9765] Loss_D: 0.0981 Loss_G: 0.0422 Convergence: 0.1016 k= 0.022085 lr = 0.0000215\n",
      "[9/25][3190/9765] Loss_D: 0.1023 Loss_G: 0.0422 Convergence: 0.1041 k= 0.022059 lr = 0.0000215\n",
      "[9/25][3200/9765] Loss_D: 0.0953 Loss_G: 0.0355 Convergence: 0.0991 k= 0.022074 lr = 0.0000215\n",
      "[9/25][3210/9765] Loss_D: 0.0953 Loss_G: 0.0376 Convergence: 0.0969 k= 0.022099 lr = 0.0000215\n",
      "[9/25][3220/9765] Loss_D: 0.0951 Loss_G: 0.0402 Convergence: 0.0978 k= 0.022100 lr = 0.0000215\n",
      "[9/25][3230/9765] Loss_D: 0.1019 Loss_G: 0.0434 Convergence: 0.1052 k= 0.022074 lr = 0.0000215\n",
      "[9/25][3240/9765] Loss_D: 0.0918 Loss_G: 0.0404 Convergence: 0.0960 k= 0.022060 lr = 0.0000215\n",
      "[9/25][3250/9765] Loss_D: 0.0964 Loss_G: 0.0417 Convergence: 0.1002 k= 0.022064 lr = 0.0000215\n",
      "[9/25][3260/9765] Loss_D: 0.0993 Loss_G: 0.0370 Convergence: 0.1033 k= 0.022072 lr = 0.0000215\n",
      "[9/25][3270/9765] Loss_D: 0.1053 Loss_G: 0.0393 Convergence: 0.1093 k= 0.022085 lr = 0.0000215\n",
      "[9/25][3280/9765] Loss_D: 0.0976 Loss_G: 0.0414 Convergence: 0.1005 k= 0.022078 lr = 0.0000215\n",
      "[9/25][3290/9765] Loss_D: 0.0979 Loss_G: 0.0417 Convergence: 0.1010 k= 0.022064 lr = 0.0000215\n",
      "[9/25][3300/9765] Loss_D: 0.0985 Loss_G: 0.0398 Convergence: 0.0994 k= 0.022040 lr = 0.0000215\n",
      "[9/25][3310/9765] Loss_D: 0.1030 Loss_G: 0.0365 Convergence: 0.1087 k= 0.022076 lr = 0.0000215\n",
      "[9/25][3320/9765] Loss_D: 0.0963 Loss_G: 0.0363 Convergence: 0.0997 k= 0.022102 lr = 0.0000215\n",
      "[9/25][3330/9765] Loss_D: 0.0874 Loss_G: 0.0403 Convergence: 0.0933 k= 0.022104 lr = 0.0000215\n",
      "[9/25][3340/9765] Loss_D: 0.1039 Loss_G: 0.0440 Convergence: 0.1068 k= 0.022081 lr = 0.0000215\n",
      "[9/25][3350/9765] Loss_D: 0.1115 Loss_G: 0.0377 Convergence: 0.1196 k= 0.022069 lr = 0.0000215\n",
      "[9/25][3360/9765] Loss_D: 0.0978 Loss_G: 0.0369 Convergence: 0.1011 k= 0.022084 lr = 0.0000215\n",
      "[9/25][3370/9765] Loss_D: 0.1023 Loss_G: 0.0350 Convergence: 0.1092 k= 0.022126 lr = 0.0000215\n",
      "[9/25][3380/9765] Loss_D: 0.0986 Loss_G: 0.0398 Convergence: 0.0994 k= 0.022154 lr = 0.0000215\n",
      "[9/25][3390/9765] Loss_D: 0.1051 Loss_G: 0.0430 Convergence: 0.1066 k= 0.022126 lr = 0.0000215\n",
      "[9/25][3400/9765] Loss_D: 0.0935 Loss_G: 0.0436 Convergence: 0.1003 k= 0.022092 lr = 0.0000215\n",
      "[9/25][3410/9765] Loss_D: 0.1070 Loss_G: 0.0391 Convergence: 0.1120 k= 0.022093 lr = 0.0000215\n",
      "[9/25][3420/9765] Loss_D: 0.0926 Loss_G: 0.0390 Convergence: 0.0951 k= 0.022083 lr = 0.0000215\n",
      "[9/25][3430/9765] Loss_D: 0.0993 Loss_G: 0.0433 Convergence: 0.1034 k= 0.022065 lr = 0.0000215\n",
      "[9/25][3440/9765] Loss_D: 0.0912 Loss_G: 0.0419 Convergence: 0.0971 k= 0.022036 lr = 0.0000215\n",
      "[9/25][3450/9765] Loss_D: 0.0976 Loss_G: 0.0371 Convergence: 0.1006 k= 0.022053 lr = 0.0000215\n",
      "[9/25][3460/9765] Loss_D: 0.1046 Loss_G: 0.0386 Convergence: 0.1090 k= 0.022076 lr = 0.0000215\n",
      "[9/25][3470/9765] Loss_D: 0.0911 Loss_G: 0.0393 Convergence: 0.0945 k= 0.022077 lr = 0.0000215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][3480/9765] Loss_D: 0.1003 Loss_G: 0.0436 Convergence: 0.1044 k= 0.022075 lr = 0.0000215\n",
      "[9/25][3490/9765] Loss_D: 0.1036 Loss_G: 0.0394 Convergence: 0.1069 k= 0.022086 lr = 0.0000215\n",
      "[9/25][3500/9765] Loss_D: 0.1026 Loss_G: 0.0415 Convergence: 0.1036 k= 0.022089 lr = 0.0000215\n",
      "[9/25][3510/9765] Loss_D: 0.1038 Loss_G: 0.0385 Convergence: 0.1080 k= 0.022101 lr = 0.0000215\n",
      "[9/25][3520/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1003 k= 0.022116 lr = 0.0000215\n",
      "[9/25][3530/9765] Loss_D: 0.1059 Loss_G: 0.0391 Convergence: 0.1104 k= 0.022121 lr = 0.0000215\n",
      "[9/25][3540/9765] Loss_D: 0.0981 Loss_G: 0.0422 Convergence: 0.1016 k= 0.022113 lr = 0.0000215\n",
      "[9/25][3550/9765] Loss_D: 0.0995 Loss_G: 0.0423 Convergence: 0.1025 k= 0.022085 lr = 0.0000215\n",
      "[9/25][3560/9765] Loss_D: 0.0959 Loss_G: 0.0395 Convergence: 0.0975 k= 0.022059 lr = 0.0000215\n",
      "[9/25][3570/9765] Loss_D: 0.0970 Loss_G: 0.0375 Convergence: 0.0994 k= 0.022071 lr = 0.0000215\n",
      "[9/25][3580/9765] Loss_D: 0.1022 Loss_G: 0.0386 Convergence: 0.1056 k= 0.022098 lr = 0.0000215\n",
      "[9/25][3590/9765] Loss_D: 0.0997 Loss_G: 0.0381 Convergence: 0.1027 k= 0.022117 lr = 0.0000215\n",
      "[9/25][3600/9765] Loss_D: 0.1019 Loss_G: 0.0401 Convergence: 0.1039 k= 0.022144 lr = 0.0000215\n",
      "[9/25][3610/9765] Loss_D: 0.0971 Loss_G: 0.0410 Convergence: 0.0998 k= 0.022130 lr = 0.0000215\n",
      "[9/25][3620/9765] Loss_D: 0.0937 Loss_G: 0.0370 Convergence: 0.0953 k= 0.022133 lr = 0.0000215\n",
      "[9/25][3630/9765] Loss_D: 0.1021 Loss_G: 0.0412 Convergence: 0.1029 k= 0.022145 lr = 0.0000215\n",
      "[9/25][3640/9765] Loss_D: 0.1037 Loss_G: 0.0397 Convergence: 0.1068 k= 0.022143 lr = 0.0000215\n",
      "[9/25][3650/9765] Loss_D: 0.0906 Loss_G: 0.0378 Convergence: 0.0927 k= 0.022155 lr = 0.0000215\n",
      "[9/25][3660/9765] Loss_D: 0.0995 Loss_G: 0.0432 Convergence: 0.1035 k= 0.022155 lr = 0.0000215\n",
      "[9/25][3670/9765] Loss_D: 0.0937 Loss_G: 0.0400 Convergence: 0.0968 k= 0.022151 lr = 0.0000215\n",
      "[9/25][3680/9765] Loss_D: 0.1029 Loss_G: 0.0373 Convergence: 0.1079 k= 0.022168 lr = 0.0000215\n",
      "[9/25][3690/9765] Loss_D: 0.0988 Loss_G: 0.0419 Convergence: 0.1017 k= 0.022177 lr = 0.0000215\n",
      "[9/25][3700/9765] Loss_D: 0.0903 Loss_G: 0.0419 Convergence: 0.0967 k= 0.022162 lr = 0.0000215\n",
      "[9/25][3710/9765] Loss_D: 0.0954 Loss_G: 0.0398 Convergence: 0.0976 k= 0.022127 lr = 0.0000215\n",
      "[9/25][3720/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0961 k= 0.022134 lr = 0.0000215\n",
      "[9/25][3730/9765] Loss_D: 0.1027 Loss_G: 0.0384 Convergence: 0.1066 k= 0.022150 lr = 0.0000215\n",
      "[9/25][3740/9765] Loss_D: 0.0887 Loss_G: 0.0405 Convergence: 0.0942 k= 0.022140 lr = 0.0000215\n",
      "[9/25][3750/9765] Loss_D: 0.0997 Loss_G: 0.0372 Convergence: 0.1035 k= 0.022150 lr = 0.0000215\n",
      "[9/25][3760/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.1001 k= 0.022141 lr = 0.0000215\n",
      "[9/25][3770/9765] Loss_D: 0.0972 Loss_G: 0.0412 Convergence: 0.1000 k= 0.022121 lr = 0.0000215\n",
      "[9/25][3780/9765] Loss_D: 0.0964 Loss_G: 0.0399 Convergence: 0.0982 k= 0.022106 lr = 0.0000215\n",
      "[9/25][3790/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0981 k= 0.022119 lr = 0.0000215\n",
      "[9/25][3800/9765] Loss_D: 0.0989 Loss_G: 0.0405 Convergence: 0.1004 k= 0.022138 lr = 0.0000215\n",
      "[9/25][3810/9765] Loss_D: 0.0965 Loss_G: 0.0374 Convergence: 0.0988 k= 0.022148 lr = 0.0000215\n",
      "[9/25][3820/9765] Loss_D: 0.1043 Loss_G: 0.0400 Convergence: 0.1071 k= 0.022156 lr = 0.0000215\n",
      "[9/25][3830/9765] Loss_D: 0.1001 Loss_G: 0.0405 Convergence: 0.1011 k= 0.022148 lr = 0.0000215\n",
      "[9/25][3840/9765] Loss_D: 0.1100 Loss_G: 0.0386 Convergence: 0.1167 k= 0.022133 lr = 0.0000215\n",
      "[9/25][3850/9765] Loss_D: 0.0919 Loss_G: 0.0399 Convergence: 0.0955 k= 0.022134 lr = 0.0000215\n",
      "[9/25][3860/9765] Loss_D: 0.1125 Loss_G: 0.0380 Convergence: 0.1206 k= 0.022164 lr = 0.0000215\n",
      "[9/25][3870/9765] Loss_D: 0.0967 Loss_G: 0.0389 Convergence: 0.0977 k= 0.022164 lr = 0.0000215\n",
      "[9/25][3880/9765] Loss_D: 0.1069 Loss_G: 0.0465 Convergence: 0.1112 k= 0.022142 lr = 0.0000215\n",
      "[9/25][3890/9765] Loss_D: 0.1047 Loss_G: 0.0423 Convergence: 0.1057 k= 0.022113 lr = 0.0000215\n",
      "[9/25][3900/9765] Loss_D: 0.1100 Loss_G: 0.0393 Convergence: 0.1159 k= 0.022118 lr = 0.0000215\n",
      "[9/25][3910/9765] Loss_D: 0.0976 Loss_G: 0.0384 Convergence: 0.0994 k= 0.022117 lr = 0.0000215\n",
      "[9/25][3920/9765] Loss_D: 0.1033 Loss_G: 0.0379 Convergence: 0.1079 k= 0.022142 lr = 0.0000215\n",
      "[9/25][3930/9765] Loss_D: 0.0885 Loss_G: 0.0387 Convergence: 0.0923 k= 0.022157 lr = 0.0000215\n",
      "[9/25][3940/9765] Loss_D: 0.1051 Loss_G: 0.0382 Convergence: 0.1102 k= 0.022181 lr = 0.0000215\n",
      "[9/25][3950/9765] Loss_D: 0.1007 Loss_G: 0.0387 Convergence: 0.1034 k= 0.022195 lr = 0.0000215\n",
      "[9/25][3960/9765] Loss_D: 0.0876 Loss_G: 0.0386 Convergence: 0.0916 k= 0.022192 lr = 0.0000215\n",
      "[9/25][3970/9765] Loss_D: 0.1069 Loss_G: 0.0392 Convergence: 0.1116 k= 0.022211 lr = 0.0000215\n",
      "[9/25][3980/9765] Loss_D: 0.0987 Loss_G: 0.0373 Convergence: 0.1020 k= 0.022214 lr = 0.0000215\n",
      "[9/25][3990/9765] Loss_D: 0.1056 Loss_G: 0.0390 Convergence: 0.1101 k= 0.022223 lr = 0.0000215\n",
      "[9/25][4000/9765] Loss_D: 0.1018 Loss_G: 0.0415 Convergence: 0.1030 k= 0.022224 lr = 0.0000215\n",
      "[9/25][4010/9765] Loss_D: 0.1022 Loss_G: 0.0384 Convergence: 0.1058 k= 0.022218 lr = 0.0000215\n",
      "[9/25][4020/9765] Loss_D: 0.0971 Loss_G: 0.0447 Convergence: 0.1036 k= 0.022217 lr = 0.0000215\n",
      "[9/25][4030/9765] Loss_D: 0.1008 Loss_G: 0.0416 Convergence: 0.1026 k= 0.022180 lr = 0.0000215\n",
      "[9/25][4040/9765] Loss_D: 0.0940 Loss_G: 0.0385 Convergence: 0.0955 k= 0.022176 lr = 0.0000215\n",
      "[9/25][4050/9765] Loss_D: 0.1013 Loss_G: 0.0423 Convergence: 0.1037 k= 0.022174 lr = 0.0000215\n",
      "[9/25][4060/9765] Loss_D: 0.1010 Loss_G: 0.0406 Convergence: 0.1022 k= 0.022161 lr = 0.0000215\n",
      "[9/25][4070/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1004 k= 0.022156 lr = 0.0000215\n",
      "[9/25][4080/9765] Loss_D: 0.1019 Loss_G: 0.0401 Convergence: 0.1038 k= 0.022180 lr = 0.0000215\n",
      "[9/25][4090/9765] Loss_D: 0.0972 Loss_G: 0.0380 Convergence: 0.0993 k= 0.022204 lr = 0.0000215\n",
      "[9/25][4100/9765] Loss_D: 0.1068 Loss_G: 0.0396 Convergence: 0.1112 k= 0.022222 lr = 0.0000215\n",
      "[9/25][4110/9765] Loss_D: 0.1013 Loss_G: 0.0400 Convergence: 0.1032 k= 0.022219 lr = 0.0000215\n",
      "[9/25][4120/9765] Loss_D: 0.0985 Loss_G: 0.0429 Convergence: 0.1025 k= 0.022201 lr = 0.0000215\n",
      "[9/25][4130/9765] Loss_D: 0.0983 Loss_G: 0.0401 Convergence: 0.0996 k= 0.022181 lr = 0.0000215\n",
      "[9/25][4140/9765] Loss_D: 0.0933 Loss_G: 0.0386 Convergence: 0.0952 k= 0.022198 lr = 0.0000215\n",
      "[9/25][4150/9765] Loss_D: 0.0900 Loss_G: 0.0400 Convergence: 0.0946 k= 0.022200 lr = 0.0000215\n",
      "[9/25][4160/9765] Loss_D: 0.0973 Loss_G: 0.0428 Convergence: 0.1018 k= 0.022184 lr = 0.0000215\n",
      "[9/25][4170/9765] Loss_D: 0.0938 Loss_G: 0.0386 Convergence: 0.0954 k= 0.022169 lr = 0.0000215\n",
      "[9/25][4180/9765] Loss_D: 0.1160 Loss_G: 0.0401 Convergence: 0.1235 k= 0.022195 lr = 0.0000215\n",
      "[9/25][4190/9765] Loss_D: 0.1016 Loss_G: 0.0415 Convergence: 0.1030 k= 0.022197 lr = 0.0000215\n",
      "[9/25][4200/9765] Loss_D: 0.1059 Loss_G: 0.0386 Convergence: 0.1108 k= 0.022209 lr = 0.0000215\n",
      "[9/25][4210/9765] Loss_D: 0.0998 Loss_G: 0.0415 Convergence: 0.1019 k= 0.022216 lr = 0.0000215\n",
      "[9/25][4220/9765] Loss_D: 0.1072 Loss_G: 0.0393 Convergence: 0.1120 k= 0.022225 lr = 0.0000215\n",
      "[9/25][4230/9765] Loss_D: 0.0921 Loss_G: 0.0405 Convergence: 0.0963 k= 0.022218 lr = 0.0000215\n",
      "[9/25][4240/9765] Loss_D: 0.0967 Loss_G: 0.0431 Convergence: 0.1017 k= 0.022200 lr = 0.0000215\n",
      "[9/25][4250/9765] Loss_D: 0.1031 Loss_G: 0.0407 Convergence: 0.1049 k= 0.022182 lr = 0.0000215\n",
      "[9/25][4260/9765] Loss_D: 0.0928 Loss_G: 0.0408 Convergence: 0.0970 k= 0.022181 lr = 0.0000215\n",
      "[9/25][4270/9765] Loss_D: 0.0950 Loss_G: 0.0409 Convergence: 0.0984 k= 0.022169 lr = 0.0000215\n",
      "[9/25][4280/9765] Loss_D: 0.1004 Loss_G: 0.0407 Convergence: 0.1015 k= 0.022176 lr = 0.0000215\n",
      "[9/25][4290/9765] Loss_D: 0.0921 Loss_G: 0.0358 Convergence: 0.0943 k= 0.022163 lr = 0.0000215\n",
      "[9/25][4300/9765] Loss_D: 0.1086 Loss_G: 0.0415 Convergence: 0.1118 k= 0.022187 lr = 0.0000215\n",
      "[9/25][4310/9765] Loss_D: 0.1033 Loss_G: 0.0398 Convergence: 0.1060 k= 0.022181 lr = 0.0000215\n",
      "[9/25][4320/9765] Loss_D: 0.1035 Loss_G: 0.0375 Convergence: 0.1087 k= 0.022179 lr = 0.0000215\n",
      "[9/25][4330/9765] Loss_D: 0.0919 Loss_G: 0.0402 Convergence: 0.0959 k= 0.022190 lr = 0.0000215\n",
      "[9/25][4340/9765] Loss_D: 0.0966 Loss_G: 0.0431 Convergence: 0.1016 k= 0.022189 lr = 0.0000215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][4350/9765] Loss_D: 0.1056 Loss_G: 0.0420 Convergence: 0.1073 k= 0.022178 lr = 0.0000215\n",
      "[9/25][4360/9765] Loss_D: 0.1143 Loss_G: 0.0404 Convergence: 0.1208 k= 0.022197 lr = 0.0000215\n",
      "[9/25][4370/9765] Loss_D: 0.1060 Loss_G: 0.0404 Convergence: 0.1093 k= 0.022183 lr = 0.0000215\n",
      "[9/25][4380/9765] Loss_D: 0.0919 Loss_G: 0.0416 Convergence: 0.0973 k= 0.022178 lr = 0.0000215\n",
      "[9/25][4390/9765] Loss_D: 0.0996 Loss_G: 0.0395 Convergence: 0.1012 k= 0.022176 lr = 0.0000215\n",
      "[9/25][4400/9765] Loss_D: 0.0907 Loss_G: 0.0372 Convergence: 0.0921 k= 0.022173 lr = 0.0000215\n",
      "[9/25][4410/9765] Loss_D: 0.1060 Loss_G: 0.0413 Convergence: 0.1082 k= 0.022187 lr = 0.0000215\n",
      "[9/25][4420/9765] Loss_D: 0.1063 Loss_G: 0.0413 Convergence: 0.1088 k= 0.022163 lr = 0.0000215\n",
      "[9/25][4430/9765] Loss_D: 0.0910 Loss_G: 0.0392 Convergence: 0.0943 k= 0.022162 lr = 0.0000215\n",
      "[9/25][4440/9765] Loss_D: 0.0915 Loss_G: 0.0389 Convergence: 0.0944 k= 0.022152 lr = 0.0000215\n",
      "[9/25][4450/9765] Loss_D: 0.1003 Loss_G: 0.0401 Convergence: 0.1016 k= 0.022149 lr = 0.0000215\n",
      "[9/25][4460/9765] Loss_D: 0.0922 Loss_G: 0.0372 Convergence: 0.0931 k= 0.022154 lr = 0.0000215\n",
      "[9/25][4470/9765] Loss_D: 0.1018 Loss_G: 0.0401 Convergence: 0.1035 k= 0.022158 lr = 0.0000215\n",
      "[9/25][4480/9765] Loss_D: 0.0970 Loss_G: 0.0431 Convergence: 0.1019 k= 0.022147 lr = 0.0000215\n",
      "[9/25][4490/9765] Loss_D: 0.0911 Loss_G: 0.0385 Convergence: 0.0937 k= 0.022147 lr = 0.0000215\n",
      "[9/25][4500/9765] Loss_D: 0.0932 Loss_G: 0.0403 Convergence: 0.0968 k= 0.022153 lr = 0.0000215\n",
      "[9/25][4510/9765] Loss_D: 0.1001 Loss_G: 0.0404 Convergence: 0.1010 k= 0.022154 lr = 0.0000215\n",
      "[9/25][4520/9765] Loss_D: 0.1070 Loss_G: 0.0446 Convergence: 0.1094 k= 0.022136 lr = 0.0000215\n",
      "[9/25][4530/9765] Loss_D: 0.0911 Loss_G: 0.0359 Convergence: 0.0929 k= 0.022130 lr = 0.0000215\n",
      "[9/25][4540/9765] Loss_D: 0.1112 Loss_G: 0.0390 Convergence: 0.1178 k= 0.022180 lr = 0.0000215\n",
      "[9/25][4550/9765] Loss_D: 0.0968 Loss_G: 0.0617 Convergence: 0.1204 k= 0.022120 lr = 0.0000215\n",
      "[9/25][4560/9765] Loss_D: 0.1012 Loss_G: 0.0507 Convergence: 0.1121 k= 0.021929 lr = 0.0000215\n",
      "[9/25][4570/9765] Loss_D: 0.0919 Loss_G: 0.0354 Convergence: 0.0944 k= 0.021915 lr = 0.0000215\n",
      "[9/25][4580/9765] Loss_D: 0.1022 Loss_G: 0.0383 Convergence: 0.1059 k= 0.021955 lr = 0.0000215\n",
      "[9/25][4590/9765] Loss_D: 0.1013 Loss_G: 0.0377 Convergence: 0.1053 k= 0.021993 lr = 0.0000215\n",
      "[9/25][4600/9765] Loss_D: 0.1067 Loss_G: 0.0437 Convergence: 0.1082 k= 0.021995 lr = 0.0000215\n",
      "[9/25][4610/9765] Loss_D: 0.0963 Loss_G: 0.0413 Convergence: 0.0996 k= 0.021970 lr = 0.0000215\n",
      "[9/25][4620/9765] Loss_D: 0.1042 Loss_G: 0.0395 Convergence: 0.1076 k= 0.021947 lr = 0.0000215\n",
      "[9/25][4630/9765] Loss_D: 0.1075 Loss_G: 0.0404 Convergence: 0.1113 k= 0.021945 lr = 0.0000215\n",
      "[9/25][4640/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0966 k= 0.021953 lr = 0.0000215\n",
      "[9/25][4650/9765] Loss_D: 0.0980 Loss_G: 0.0399 Convergence: 0.0992 k= 0.021957 lr = 0.0000215\n",
      "[9/25][4660/9765] Loss_D: 0.1034 Loss_G: 0.0397 Convergence: 0.1063 k= 0.021950 lr = 0.0000215\n",
      "[9/25][4670/9765] Loss_D: 0.0988 Loss_G: 0.0396 Convergence: 0.0999 k= 0.021933 lr = 0.0000215\n",
      "[9/25][4680/9765] Loss_D: 0.0944 Loss_G: 0.0353 Convergence: 0.0980 k= 0.021958 lr = 0.0000215\n",
      "[9/25][4690/9765] Loss_D: 0.0951 Loss_G: 0.0365 Convergence: 0.0978 k= 0.021983 lr = 0.0000215\n",
      "[9/25][4700/9765] Loss_D: 0.1001 Loss_G: 0.0397 Convergence: 0.1017 k= 0.022008 lr = 0.0000215\n",
      "[9/25][4710/9765] Loss_D: 0.0957 Loss_G: 0.0404 Convergence: 0.0984 k= 0.022018 lr = 0.0000215\n",
      "[9/25][4720/9765] Loss_D: 0.1018 Loss_G: 0.0405 Convergence: 0.1033 k= 0.022015 lr = 0.0000215\n",
      "[9/25][4730/9765] Loss_D: 0.0955 Loss_G: 0.0369 Convergence: 0.0979 k= 0.022023 lr = 0.0000215\n",
      "[9/25][4740/9765] Loss_D: 0.1022 Loss_G: 0.0403 Convergence: 0.1039 k= 0.022052 lr = 0.0000215\n",
      "[9/25][4750/9765] Loss_D: 0.0955 Loss_G: 0.0384 Convergence: 0.0963 k= 0.022062 lr = 0.0000215\n",
      "[9/25][4760/9765] Loss_D: 0.1081 Loss_G: 0.0421 Convergence: 0.1105 k= 0.022065 lr = 0.0000215\n",
      "[9/25][4770/9765] Loss_D: 0.1018 Loss_G: 0.0443 Convergence: 0.1060 k= 0.022024 lr = 0.0000215\n",
      "[9/25][4780/9765] Loss_D: 0.1053 Loss_G: 0.0385 Convergence: 0.1101 k= 0.022028 lr = 0.0000215\n",
      "[9/25][4790/9765] Loss_D: 0.0924 Loss_G: 0.0368 Convergence: 0.0937 k= 0.022039 lr = 0.0000215\n",
      "[9/25][4800/9765] Loss_D: 0.1048 Loss_G: 0.0417 Convergence: 0.1063 k= 0.022050 lr = 0.0000215\n",
      "[9/25][4810/9765] Loss_D: 0.0930 Loss_G: 0.0400 Convergence: 0.0963 k= 0.022046 lr = 0.0000215\n",
      "[9/25][4820/9765] Loss_D: 0.0941 Loss_G: 0.0414 Convergence: 0.0984 k= 0.022057 lr = 0.0000215\n",
      "[9/25][4830/9765] Loss_D: 0.1098 Loss_G: 0.0431 Convergence: 0.1119 k= 0.022058 lr = 0.0000215\n",
      "[9/25][4840/9765] Loss_D: 0.0960 Loss_G: 0.0422 Convergence: 0.1004 k= 0.022052 lr = 0.0000215\n",
      "[9/25][4850/9765] Loss_D: 0.1060 Loss_G: 0.0387 Convergence: 0.1110 k= 0.022063 lr = 0.0000215\n",
      "[9/25][4860/9765] Loss_D: 0.0895 Loss_G: 0.0366 Convergence: 0.0909 k= 0.022063 lr = 0.0000215\n",
      "[9/25][4870/9765] Loss_D: 0.0967 Loss_G: 0.0368 Convergence: 0.0997 k= 0.022081 lr = 0.0000215\n",
      "[9/25][4880/9765] Loss_D: 0.1097 Loss_G: 0.0396 Convergence: 0.1153 k= 0.022103 lr = 0.0000215\n",
      "[9/25][4890/9765] Loss_D: 0.0974 Loss_G: 0.0370 Convergence: 0.1006 k= 0.022124 lr = 0.0000215\n",
      "[9/25][4900/9765] Loss_D: 0.0965 Loss_G: 0.0419 Convergence: 0.1003 k= 0.022138 lr = 0.0000215\n",
      "[9/25][4910/9765] Loss_D: 0.0939 Loss_G: 0.0387 Convergence: 0.0956 k= 0.022128 lr = 0.0000215\n",
      "[9/25][4920/9765] Loss_D: 0.0961 Loss_G: 0.0378 Convergence: 0.0980 k= 0.022147 lr = 0.0000215\n",
      "[9/25][4930/9765] Loss_D: 0.1008 Loss_G: 0.0367 Convergence: 0.1055 k= 0.022153 lr = 0.0000215\n",
      "[9/25][4940/9765] Loss_D: 0.0933 Loss_G: 0.0370 Convergence: 0.0947 k= 0.022190 lr = 0.0000215\n",
      "[9/25][4950/9765] Loss_D: 0.1030 Loss_G: 0.0395 Convergence: 0.1060 k= 0.022202 lr = 0.0000215\n",
      "[9/25][4960/9765] Loss_D: 0.1001 Loss_G: 0.0433 Convergence: 0.1039 k= 0.022197 lr = 0.0000215\n",
      "[9/25][4970/9765] Loss_D: 0.1059 Loss_G: 0.0373 Convergence: 0.1121 k= 0.022214 lr = 0.0000215\n",
      "[9/25][4980/9765] Loss_D: 0.1052 Loss_G: 0.0386 Convergence: 0.1099 k= 0.022231 lr = 0.0000215\n",
      "[9/25][4990/9765] Loss_D: 0.1049 Loss_G: 0.0360 Convergence: 0.1119 k= 0.022269 lr = 0.0000215\n",
      "[9/25][5000/9765] Loss_D: 0.1011 Loss_G: 0.0383 Convergence: 0.1044 k= 0.022296 lr = 0.0000215\n",
      "[9/25][5010/9765] Loss_D: 0.0989 Loss_G: 0.0425 Convergence: 0.1024 k= 0.022293 lr = 0.0000215\n",
      "[9/25][5020/9765] Loss_D: 0.0984 Loss_G: 0.0416 Convergence: 0.1012 k= 0.022277 lr = 0.0000215\n",
      "[9/25][5030/9765] Loss_D: 0.0920 Loss_G: 0.0399 Convergence: 0.0956 k= 0.022260 lr = 0.0000215\n",
      "[9/25][5040/9765] Loss_D: 0.0900 Loss_G: 0.0367 Convergence: 0.0911 k= 0.022268 lr = 0.0000215\n",
      "[9/25][5050/9765] Loss_D: 0.1061 Loss_G: 0.0384 Convergence: 0.1113 k= 0.022295 lr = 0.0000215\n",
      "[9/25][5060/9765] Loss_D: 0.1082 Loss_G: 0.0391 Convergence: 0.1135 k= 0.022321 lr = 0.0000215\n",
      "[9/25][5070/9765] Loss_D: 0.0917 Loss_G: 0.0382 Convergence: 0.0937 k= 0.022344 lr = 0.0000215\n",
      "[9/25][5080/9765] Loss_D: 0.0884 Loss_G: 0.0395 Convergence: 0.0931 k= 0.022334 lr = 0.0000215\n",
      "[9/25][5090/9765] Loss_D: 0.1008 Loss_G: 0.0402 Convergence: 0.1022 k= 0.022328 lr = 0.0000215\n",
      "[9/25][5100/9765] Loss_D: 0.0958 Loss_G: 0.0389 Convergence: 0.0968 k= 0.022338 lr = 0.0000215\n",
      "[9/25][5110/9765] Loss_D: 0.0936 Loss_G: 0.0384 Convergence: 0.0951 k= 0.022323 lr = 0.0000215\n",
      "[9/25][5120/9765] Loss_D: 0.0975 Loss_G: 0.0401 Convergence: 0.0991 k= 0.022325 lr = 0.0000204\n",
      "[9/25][5130/9765] Loss_D: 0.0915 Loss_G: 0.0401 Convergence: 0.0955 k= 0.022313 lr = 0.0000204\n",
      "[9/25][5140/9765] Loss_D: 0.0894 Loss_G: 0.0393 Convergence: 0.0935 k= 0.022299 lr = 0.0000204\n",
      "[9/25][5150/9765] Loss_D: 0.1012 Loss_G: 0.0398 Convergence: 0.1032 k= 0.022300 lr = 0.0000204\n",
      "[9/25][5160/9765] Loss_D: 0.0960 Loss_G: 0.0379 Convergence: 0.0978 k= 0.022302 lr = 0.0000204\n",
      "[9/25][5170/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0924 k= 0.022320 lr = 0.0000204\n",
      "[9/25][5180/9765] Loss_D: 0.1000 Loss_G: 0.0423 Convergence: 0.1028 k= 0.022323 lr = 0.0000204\n",
      "[9/25][5190/9765] Loss_D: 0.1044 Loss_G: 0.0411 Convergence: 0.1062 k= 0.022327 lr = 0.0000204\n",
      "[9/25][5200/9765] Loss_D: 0.0944 Loss_G: 0.0393 Convergence: 0.0964 k= 0.022329 lr = 0.0000204\n",
      "[9/25][5210/9765] Loss_D: 0.1050 Loss_G: 0.0395 Convergence: 0.1087 k= 0.022348 lr = 0.0000204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][5220/9765] Loss_D: 0.1013 Loss_G: 0.0401 Convergence: 0.1029 k= 0.022355 lr = 0.0000204\n",
      "[9/25][5230/9765] Loss_D: 0.1009 Loss_G: 0.0417 Convergence: 0.1028 k= 0.022361 lr = 0.0000204\n",
      "[9/25][5240/9765] Loss_D: 0.0982 Loss_G: 0.0409 Convergence: 0.1003 k= 0.022365 lr = 0.0000204\n",
      "[9/25][5250/9765] Loss_D: 0.0937 Loss_G: 0.0385 Convergence: 0.0953 k= 0.022378 lr = 0.0000204\n",
      "[9/25][5260/9765] Loss_D: 0.0873 Loss_G: 0.0412 Convergence: 0.0941 k= 0.022387 lr = 0.0000204\n",
      "[9/25][5270/9765] Loss_D: 0.0983 Loss_G: 0.0410 Convergence: 0.1005 k= 0.022366 lr = 0.0000204\n",
      "[9/25][5280/9765] Loss_D: 0.1042 Loss_G: 0.0395 Convergence: 0.1077 k= 0.022354 lr = 0.0000204\n",
      "[9/25][5290/9765] Loss_D: 0.1085 Loss_G: 0.0412 Convergence: 0.1119 k= 0.022363 lr = 0.0000204\n",
      "[9/25][5300/9765] Loss_D: 0.1009 Loss_G: 0.0390 Convergence: 0.1033 k= 0.022386 lr = 0.0000204\n",
      "[9/25][5310/9765] Loss_D: 0.1105 Loss_G: 0.0416 Convergence: 0.1145 k= 0.022385 lr = 0.0000204\n",
      "[9/25][5320/9765] Loss_D: 0.0926 Loss_G: 0.0409 Convergence: 0.0971 k= 0.022365 lr = 0.0000204\n",
      "[9/25][5330/9765] Loss_D: 0.1114 Loss_G: 0.0437 Convergence: 0.1136 k= 0.022342 lr = 0.0000204\n",
      "[9/25][5340/9765] Loss_D: 0.0936 Loss_G: 0.0379 Convergence: 0.0946 k= 0.022328 lr = 0.0000204\n",
      "[9/25][5350/9765] Loss_D: 0.1045 Loss_G: 0.0380 Convergence: 0.1094 k= 0.022332 lr = 0.0000204\n",
      "[9/25][5360/9765] Loss_D: 0.0959 Loss_G: 0.0389 Convergence: 0.0970 k= 0.022356 lr = 0.0000204\n",
      "[9/25][5370/9765] Loss_D: 0.1070 Loss_G: 0.0390 Convergence: 0.1119 k= 0.022373 lr = 0.0000204\n",
      "[9/25][5380/9765] Loss_D: 0.0974 Loss_G: 0.0429 Convergence: 0.1019 k= 0.022367 lr = 0.0000204\n",
      "[9/25][5390/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0952 k= 0.022368 lr = 0.0000204\n",
      "[9/25][5400/9765] Loss_D: 0.0992 Loss_G: 0.0418 Convergence: 0.1019 k= 0.022370 lr = 0.0000204\n",
      "[9/25][5410/9765] Loss_D: 0.0940 Loss_G: 0.0385 Convergence: 0.0954 k= 0.022369 lr = 0.0000204\n",
      "[9/25][5420/9765] Loss_D: 0.1034 Loss_G: 0.0384 Convergence: 0.1076 k= 0.022366 lr = 0.0000204\n",
      "[9/25][5430/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0987 k= 0.022393 lr = 0.0000204\n",
      "[9/25][5440/9765] Loss_D: 0.0971 Loss_G: 0.0408 Convergence: 0.0996 k= 0.022401 lr = 0.0000204\n",
      "[9/25][5450/9765] Loss_D: 0.0983 Loss_G: 0.0405 Convergence: 0.1000 k= 0.022396 lr = 0.0000204\n",
      "[9/25][5460/9765] Loss_D: 0.1025 Loss_G: 0.0381 Convergence: 0.1066 k= 0.022419 lr = 0.0000204\n",
      "[9/25][5470/9765] Loss_D: 0.0977 Loss_G: 0.0378 Convergence: 0.1002 k= 0.022431 lr = 0.0000204\n",
      "[9/25][5480/9765] Loss_D: 0.0942 Loss_G: 0.0392 Convergence: 0.0962 k= 0.022423 lr = 0.0000204\n",
      "[9/25][5490/9765] Loss_D: 0.1032 Loss_G: 0.0367 Convergence: 0.1090 k= 0.022426 lr = 0.0000204\n",
      "[9/25][5500/9765] Loss_D: 0.1052 Loss_G: 0.0377 Convergence: 0.1108 k= 0.022449 lr = 0.0000204\n",
      "[9/25][5510/9765] Loss_D: 0.0931 Loss_G: 0.0389 Convergence: 0.0953 k= 0.022453 lr = 0.0000204\n",
      "[9/25][5520/9765] Loss_D: 0.0907 Loss_G: 0.0385 Convergence: 0.0934 k= 0.022451 lr = 0.0000204\n",
      "[9/25][5530/9765] Loss_D: 0.1035 Loss_G: 0.0400 Convergence: 0.1061 k= 0.022464 lr = 0.0000204\n",
      "[9/25][5540/9765] Loss_D: 0.0898 Loss_G: 0.0396 Convergence: 0.0940 k= 0.022457 lr = 0.0000204\n",
      "[9/25][5550/9765] Loss_D: 0.1022 Loss_G: 0.0431 Convergence: 0.1049 k= 0.022472 lr = 0.0000204\n",
      "[9/25][5560/9765] Loss_D: 0.0996 Loss_G: 0.0394 Convergence: 0.1012 k= 0.022468 lr = 0.0000204\n",
      "[9/25][5570/9765] Loss_D: 0.0946 Loss_G: 0.0366 Convergence: 0.0970 k= 0.022482 lr = 0.0000204\n",
      "[9/25][5580/9765] Loss_D: 0.0996 Loss_G: 0.0386 Convergence: 0.1021 k= 0.022494 lr = 0.0000204\n",
      "[9/25][5590/9765] Loss_D: 0.0923 Loss_G: 0.0395 Convergence: 0.0954 k= 0.022481 lr = 0.0000204\n",
      "[9/25][5600/9765] Loss_D: 0.1054 Loss_G: 0.0412 Convergence: 0.1076 k= 0.022459 lr = 0.0000204\n",
      "[9/25][5610/9765] Loss_D: 0.1032 Loss_G: 0.0421 Convergence: 0.1046 k= 0.022456 lr = 0.0000204\n",
      "[9/25][5620/9765] Loss_D: 0.1041 Loss_G: 0.0396 Convergence: 0.1074 k= 0.022456 lr = 0.0000204\n",
      "[9/25][5630/9765] Loss_D: 0.1022 Loss_G: 0.0393 Convergence: 0.1050 k= 0.022446 lr = 0.0000204\n",
      "[9/25][5640/9765] Loss_D: 0.0930 Loss_G: 0.0382 Convergence: 0.0946 k= 0.022451 lr = 0.0000204\n",
      "[9/25][5650/9765] Loss_D: 0.1077 Loss_G: 0.0383 Convergence: 0.1137 k= 0.022447 lr = 0.0000204\n",
      "[9/25][5660/9765] Loss_D: 0.1028 Loss_G: 0.0386 Convergence: 0.1065 k= 0.022452 lr = 0.0000204\n",
      "[9/25][5670/9765] Loss_D: 0.0928 Loss_G: 0.0376 Convergence: 0.0939 k= 0.022457 lr = 0.0000204\n",
      "[9/25][5680/9765] Loss_D: 0.0881 Loss_G: 0.0376 Convergence: 0.0910 k= 0.022472 lr = 0.0000204\n",
      "[9/25][5690/9765] Loss_D: 0.0946 Loss_G: 0.0338 Convergence: 0.0997 k= 0.022507 lr = 0.0000204\n",
      "[9/25][5700/9765] Loss_D: 0.0924 Loss_G: 0.0412 Convergence: 0.0971 k= 0.022511 lr = 0.0000204\n",
      "[9/25][5710/9765] Loss_D: 0.1027 Loss_G: 0.0432 Convergence: 0.1054 k= 0.022477 lr = 0.0000204\n",
      "[9/25][5720/9765] Loss_D: 0.0972 Loss_G: 0.0391 Convergence: 0.0982 k= 0.022467 lr = 0.0000204\n",
      "[9/25][5730/9765] Loss_D: 0.0970 Loss_G: 0.0375 Convergence: 0.0995 k= 0.022473 lr = 0.0000204\n",
      "[9/25][5740/9765] Loss_D: 0.1045 Loss_G: 0.0389 Convergence: 0.1085 k= 0.022492 lr = 0.0000204\n",
      "[9/25][5750/9765] Loss_D: 0.0978 Loss_G: 0.0433 Convergence: 0.1026 k= 0.022466 lr = 0.0000204\n",
      "[9/25][5760/9765] Loss_D: 0.0909 Loss_G: 0.0404 Convergence: 0.0955 k= 0.022450 lr = 0.0000204\n",
      "[9/25][5770/9765] Loss_D: 0.0918 Loss_G: 0.0391 Convergence: 0.0946 k= 0.022475 lr = 0.0000204\n",
      "[9/25][5780/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0949 k= 0.022469 lr = 0.0000204\n",
      "[9/25][5790/9765] Loss_D: 0.1011 Loss_G: 0.0391 Convergence: 0.1036 k= 0.022480 lr = 0.0000204\n",
      "[9/25][5800/9765] Loss_D: 0.1034 Loss_G: 0.0362 Convergence: 0.1097 k= 0.022500 lr = 0.0000204\n",
      "[9/25][5810/9765] Loss_D: 0.0947 Loss_G: 0.0397 Convergence: 0.0971 k= 0.022526 lr = 0.0000204\n",
      "[9/25][5820/9765] Loss_D: 0.1002 Loss_G: 0.0437 Convergence: 0.1044 k= 0.022506 lr = 0.0000204\n",
      "[9/25][5830/9765] Loss_D: 0.0973 Loss_G: 0.0422 Convergence: 0.1012 k= 0.022483 lr = 0.0000204\n",
      "[9/25][5840/9765] Loss_D: 0.0959 Loss_G: 0.0366 Convergence: 0.0988 k= 0.022486 lr = 0.0000204\n",
      "[9/25][5850/9765] Loss_D: 0.0975 Loss_G: 0.0391 Convergence: 0.0985 k= 0.022506 lr = 0.0000204\n",
      "[9/25][5860/9765] Loss_D: 0.0966 Loss_G: 0.0398 Convergence: 0.0983 k= 0.022523 lr = 0.0000204\n",
      "[9/25][5870/9765] Loss_D: 0.0925 Loss_G: 0.0411 Convergence: 0.0971 k= 0.022486 lr = 0.0000204\n",
      "[9/25][5880/9765] Loss_D: 0.0973 Loss_G: 0.0385 Convergence: 0.0990 k= 0.022484 lr = 0.0000204\n",
      "[9/25][5890/9765] Loss_D: 0.1036 Loss_G: 0.0377 Convergence: 0.1085 k= 0.022529 lr = 0.0000204\n",
      "[9/25][5900/9765] Loss_D: 0.0970 Loss_G: 0.0373 Convergence: 0.0997 k= 0.022549 lr = 0.0000204\n",
      "[9/25][5910/9765] Loss_D: 0.1015 Loss_G: 0.0410 Convergence: 0.1024 k= 0.022555 lr = 0.0000204\n",
      "[9/25][5920/9765] Loss_D: 0.1008 Loss_G: 0.0411 Convergence: 0.1021 k= 0.022547 lr = 0.0000204\n",
      "[9/25][5930/9765] Loss_D: 0.0997 Loss_G: 0.0409 Convergence: 0.1014 k= 0.022537 lr = 0.0000204\n",
      "[9/25][5940/9765] Loss_D: 0.0953 Loss_G: 0.0405 Convergence: 0.0982 k= 0.022536 lr = 0.0000204\n",
      "[9/25][5950/9765] Loss_D: 0.1043 Loss_G: 0.0396 Convergence: 0.1075 k= 0.022546 lr = 0.0000204\n",
      "[9/25][5960/9765] Loss_D: 0.0938 Loss_G: 0.0363 Convergence: 0.0963 k= 0.022569 lr = 0.0000204\n",
      "[9/25][5970/9765] Loss_D: 0.1024 Loss_G: 0.0438 Convergence: 0.1058 k= 0.022572 lr = 0.0000204\n",
      "[9/25][5980/9765] Loss_D: 0.0912 Loss_G: 0.0379 Convergence: 0.0931 k= 0.022570 lr = 0.0000204\n",
      "[9/25][5990/9765] Loss_D: 0.1063 Loss_G: 0.0388 Convergence: 0.1112 k= 0.022568 lr = 0.0000204\n",
      "[9/25][6000/9765] Loss_D: 0.1008 Loss_G: 0.0389 Convergence: 0.1034 k= 0.022564 lr = 0.0000204\n",
      "[9/25][6010/9765] Loss_D: 0.1018 Loss_G: 0.0369 Convergence: 0.1067 k= 0.022565 lr = 0.0000204\n",
      "[9/25][6020/9765] Loss_D: 0.1042 Loss_G: 0.0380 Convergence: 0.1090 k= 0.022590 lr = 0.0000204\n",
      "[9/25][6030/9765] Loss_D: 0.1054 Loss_G: 0.0412 Convergence: 0.1077 k= 0.022601 lr = 0.0000204\n",
      "[9/25][6040/9765] Loss_D: 0.1067 Loss_G: 0.0409 Convergence: 0.1098 k= 0.022611 lr = 0.0000204\n",
      "[9/25][6050/9765] Loss_D: 0.0894 Loss_G: 0.0387 Convergence: 0.0929 k= 0.022599 lr = 0.0000204\n",
      "[9/25][6060/9765] Loss_D: 0.0938 Loss_G: 0.0385 Convergence: 0.0954 k= 0.022607 lr = 0.0000204\n",
      "[9/25][6070/9765] Loss_D: 0.1072 Loss_G: 0.0404 Convergence: 0.1110 k= 0.022613 lr = 0.0000204\n",
      "[9/25][6080/9765] Loss_D: 0.0968 Loss_G: 0.0408 Convergence: 0.0994 k= 0.022637 lr = 0.0000204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][6090/9765] Loss_D: 0.0960 Loss_G: 0.0429 Convergence: 0.1011 k= 0.022643 lr = 0.0000204\n",
      "[9/25][6100/9765] Loss_D: 0.0964 Loss_G: 0.0419 Convergence: 0.1003 k= 0.022628 lr = 0.0000204\n",
      "[9/25][6110/9765] Loss_D: 0.0909 Loss_G: 0.0417 Convergence: 0.0968 k= 0.022586 lr = 0.0000204\n",
      "[9/25][6120/9765] Loss_D: 0.1052 Loss_G: 0.0413 Convergence: 0.1073 k= 0.022577 lr = 0.0000204\n",
      "[9/25][6130/9765] Loss_D: 0.1060 Loss_G: 0.0374 Convergence: 0.1122 k= 0.022588 lr = 0.0000204\n",
      "[9/25][6140/9765] Loss_D: 0.1015 Loss_G: 0.0386 Convergence: 0.1046 k= 0.022608 lr = 0.0000204\n",
      "[9/25][6150/9765] Loss_D: 0.0969 Loss_G: 0.0415 Convergence: 0.1002 k= 0.022596 lr = 0.0000204\n",
      "[9/25][6160/9765] Loss_D: 0.1060 Loss_G: 0.0404 Convergence: 0.1093 k= 0.022586 lr = 0.0000204\n",
      "[9/25][6170/9765] Loss_D: 0.0994 Loss_G: 0.0397 Convergence: 0.1007 k= 0.022570 lr = 0.0000204\n",
      "[9/25][6180/9765] Loss_D: 0.0987 Loss_G: 0.0393 Convergence: 0.1000 k= 0.022580 lr = 0.0000204\n",
      "[9/25][6190/9765] Loss_D: 0.0941 Loss_G: 0.0421 Convergence: 0.0991 k= 0.022577 lr = 0.0000204\n",
      "[9/25][6200/9765] Loss_D: 0.0984 Loss_G: 0.0392 Convergence: 0.0998 k= 0.022563 lr = 0.0000204\n",
      "[9/25][6210/9765] Loss_D: 0.0890 Loss_G: 0.0378 Convergence: 0.0917 k= 0.022559 lr = 0.0000204\n",
      "[9/25][6220/9765] Loss_D: 0.1038 Loss_G: 0.0370 Convergence: 0.1095 k= 0.022564 lr = 0.0000204\n",
      "[9/25][6230/9765] Loss_D: 0.1022 Loss_G: 0.0371 Convergence: 0.1072 k= 0.022583 lr = 0.0000204\n",
      "[9/25][6240/9765] Loss_D: 0.1011 Loss_G: 0.0377 Convergence: 0.1050 k= 0.022605 lr = 0.0000204\n",
      "[9/25][6250/9765] Loss_D: 0.0894 Loss_G: 0.0382 Convergence: 0.0923 k= 0.022626 lr = 0.0000204\n",
      "[9/25][6260/9765] Loss_D: 0.0945 Loss_G: 0.0375 Convergence: 0.0961 k= 0.022635 lr = 0.0000204\n",
      "[9/25][6270/9765] Loss_D: 0.0949 Loss_G: 0.0410 Convergence: 0.0985 k= 0.022647 lr = 0.0000204\n",
      "[9/25][6280/9765] Loss_D: 0.0920 Loss_G: 0.0385 Convergence: 0.0942 k= 0.022663 lr = 0.0000204\n",
      "[9/25][6290/9765] Loss_D: 0.0975 Loss_G: 0.0405 Convergence: 0.0995 k= 0.022673 lr = 0.0000204\n",
      "[9/25][6300/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1021 k= 0.022678 lr = 0.0000204\n",
      "[9/25][6310/9765] Loss_D: 0.0881 Loss_G: 0.0358 Convergence: 0.0892 k= 0.022684 lr = 0.0000204\n",
      "[9/25][6320/9765] Loss_D: 0.1018 Loss_G: 0.0376 Convergence: 0.1062 k= 0.022698 lr = 0.0000204\n",
      "[9/25][6330/9765] Loss_D: 0.1011 Loss_G: 0.0432 Convergence: 0.1045 k= 0.022685 lr = 0.0000204\n",
      "[9/25][6340/9765] Loss_D: 0.1049 Loss_G: 0.0391 Convergence: 0.1090 k= 0.022662 lr = 0.0000204\n",
      "[9/25][6350/9765] Loss_D: 0.1048 Loss_G: 0.0409 Convergence: 0.1071 k= 0.022671 lr = 0.0000204\n",
      "[9/25][6360/9765] Loss_D: 0.1007 Loss_G: 0.0389 Convergence: 0.1033 k= 0.022690 lr = 0.0000204\n",
      "[9/25][6370/9765] Loss_D: 0.0969 Loss_G: 0.0417 Convergence: 0.1004 k= 0.022672 lr = 0.0000204\n",
      "[9/25][6380/9765] Loss_D: 0.0991 Loss_G: 0.0407 Convergence: 0.1007 k= 0.022662 lr = 0.0000204\n",
      "[9/25][6390/9765] Loss_D: 0.1009 Loss_G: 0.0393 Convergence: 0.1031 k= 0.022671 lr = 0.0000204\n",
      "[9/25][6400/9765] Loss_D: 0.0917 Loss_G: 0.0389 Convergence: 0.0945 k= 0.022658 lr = 0.0000204\n",
      "[9/25][6410/9765] Loss_D: 0.1049 Loss_G: 0.0388 Convergence: 0.1092 k= 0.022669 lr = 0.0000204\n",
      "[9/25][6420/9765] Loss_D: 0.0971 Loss_G: 0.0386 Convergence: 0.0985 k= 0.022675 lr = 0.0000204\n",
      "[9/25][6430/9765] Loss_D: 0.0875 Loss_G: 0.0390 Convergence: 0.0921 k= 0.022682 lr = 0.0000204\n",
      "[9/25][6440/9765] Loss_D: 0.0916 Loss_G: 0.0389 Convergence: 0.0944 k= 0.022693 lr = 0.0000204\n",
      "[9/25][6450/9765] Loss_D: 0.0998 Loss_G: 0.0466 Convergence: 0.1071 k= 0.022670 lr = 0.0000204\n",
      "[9/25][6460/9765] Loss_D: 0.1015 Loss_G: 0.0413 Convergence: 0.1028 k= 0.022640 lr = 0.0000204\n",
      "[9/25][6470/9765] Loss_D: 0.0998 Loss_G: 0.0385 Convergence: 0.1024 k= 0.022642 lr = 0.0000204\n",
      "[9/25][6480/9765] Loss_D: 0.0975 Loss_G: 0.0404 Convergence: 0.0994 k= 0.022638 lr = 0.0000204\n",
      "[9/25][6490/9765] Loss_D: 0.0945 Loss_G: 0.0417 Convergence: 0.0990 k= 0.022641 lr = 0.0000204\n",
      "[9/25][6500/9765] Loss_D: 0.1035 Loss_G: 0.0392 Convergence: 0.1070 k= 0.022621 lr = 0.0000204\n",
      "[9/25][6510/9765] Loss_D: 0.0940 Loss_G: 0.0379 Convergence: 0.0950 k= 0.022623 lr = 0.0000204\n",
      "[9/25][6520/9765] Loss_D: 0.0998 Loss_G: 0.0391 Convergence: 0.1018 k= 0.022617 lr = 0.0000204\n",
      "[9/25][6530/9765] Loss_D: 0.0980 Loss_G: 0.0383 Convergence: 0.1000 k= 0.022632 lr = 0.0000204\n",
      "[9/25][6540/9765] Loss_D: 0.1057 Loss_G: 0.0413 Convergence: 0.1079 k= 0.022640 lr = 0.0000204\n",
      "[9/25][6550/9765] Loss_D: 0.0980 Loss_G: 0.0407 Convergence: 0.1001 k= 0.022633 lr = 0.0000204\n",
      "[9/25][6560/9765] Loss_D: 0.1032 Loss_G: 0.0411 Convergence: 0.1047 k= 0.022622 lr = 0.0000204\n",
      "[9/25][6570/9765] Loss_D: 0.0971 Loss_G: 0.0396 Convergence: 0.0985 k= 0.022611 lr = 0.0000204\n",
      "[9/25][6580/9765] Loss_D: 0.1039 Loss_G: 0.0369 Convergence: 0.1097 k= 0.022628 lr = 0.0000204\n",
      "[9/25][6590/9765] Loss_D: 0.1037 Loss_G: 0.0375 Convergence: 0.1088 k= 0.022648 lr = 0.0000204\n",
      "[9/25][6600/9765] Loss_D: 0.1013 Loss_G: 0.0385 Convergence: 0.1045 k= 0.022669 lr = 0.0000204\n",
      "[9/25][6610/9765] Loss_D: 0.1067 Loss_G: 0.0428 Convergence: 0.1079 k= 0.022651 lr = 0.0000204\n",
      "[9/25][6620/9765] Loss_D: 0.0913 Loss_G: 0.0399 Convergence: 0.0952 k= 0.022623 lr = 0.0000204\n",
      "[9/25][6630/9765] Loss_D: 0.0944 Loss_G: 0.0396 Convergence: 0.0967 k= 0.022611 lr = 0.0000204\n",
      "[9/25][6640/9765] Loss_D: 0.0977 Loss_G: 0.0365 Convergence: 0.1014 k= 0.022620 lr = 0.0000204\n",
      "[9/25][6650/9765] Loss_D: 0.1058 Loss_G: 0.0409 Convergence: 0.1086 k= 0.022637 lr = 0.0000204\n",
      "[9/25][6660/9765] Loss_D: 0.0960 Loss_G: 0.0397 Convergence: 0.0979 k= 0.022632 lr = 0.0000204\n",
      "[9/25][6670/9765] Loss_D: 0.0977 Loss_G: 0.0404 Convergence: 0.0996 k= 0.022628 lr = 0.0000204\n",
      "[9/25][6680/9765] Loss_D: 0.0962 Loss_G: 0.0413 Convergence: 0.0996 k= 0.022609 lr = 0.0000204\n",
      "[9/25][6690/9765] Loss_D: 0.0994 Loss_G: 0.0385 Convergence: 0.1019 k= 0.022602 lr = 0.0000204\n",
      "[9/25][6700/9765] Loss_D: 0.1028 Loss_G: 0.0419 Convergence: 0.1041 k= 0.022604 lr = 0.0000204\n",
      "[9/25][6710/9765] Loss_D: 0.0925 Loss_G: 0.0382 Convergence: 0.0942 k= 0.022622 lr = 0.0000204\n",
      "[9/25][6720/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0966 k= 0.022633 lr = 0.0000204\n",
      "[9/25][6730/9765] Loss_D: 0.1065 Loss_G: 0.0393 Convergence: 0.1110 k= 0.022635 lr = 0.0000204\n",
      "[9/25][6740/9765] Loss_D: 0.0972 Loss_G: 0.0379 Convergence: 0.0994 k= 0.022656 lr = 0.0000204\n",
      "[9/25][6750/9765] Loss_D: 0.0954 Loss_G: 0.0403 Convergence: 0.0981 k= 0.022669 lr = 0.0000204\n",
      "[9/25][6760/9765] Loss_D: 0.1034 Loss_G: 0.0423 Convergence: 0.1049 k= 0.022693 lr = 0.0000204\n",
      "[9/25][6770/9765] Loss_D: 0.1089 Loss_G: 0.0435 Convergence: 0.1103 k= 0.022677 lr = 0.0000204\n",
      "[9/25][6780/9765] Loss_D: 0.0933 Loss_G: 0.0410 Convergence: 0.0976 k= 0.022652 lr = 0.0000204\n",
      "[9/25][6790/9765] Loss_D: 0.1001 Loss_G: 0.0381 Convergence: 0.1032 k= 0.022659 lr = 0.0000204\n",
      "[9/25][6800/9765] Loss_D: 0.0924 Loss_G: 0.0397 Convergence: 0.0957 k= 0.022650 lr = 0.0000204\n",
      "[9/25][6810/9765] Loss_D: 0.1021 Loss_G: 0.0373 Convergence: 0.1067 k= 0.022675 lr = 0.0000204\n",
      "[9/25][6820/9765] Loss_D: 0.1042 Loss_G: 0.0419 Convergence: 0.1054 k= 0.022686 lr = 0.0000204\n",
      "[9/25][6830/9765] Loss_D: 0.0956 Loss_G: 0.0380 Convergence: 0.0970 k= 0.022667 lr = 0.0000204\n",
      "[9/25][6840/9765] Loss_D: 0.0906 Loss_G: 0.0403 Convergence: 0.0952 k= 0.022672 lr = 0.0000204\n",
      "[9/25][6850/9765] Loss_D: 0.0931 Loss_G: 0.0407 Convergence: 0.0971 k= 0.022679 lr = 0.0000204\n",
      "[9/25][6860/9765] Loss_D: 0.1010 Loss_G: 0.0386 Convergence: 0.1040 k= 0.022683 lr = 0.0000204\n",
      "[9/25][6870/9765] Loss_D: 0.0975 Loss_G: 0.0434 Convergence: 0.1025 k= 0.022651 lr = 0.0000204\n",
      "[9/25][6880/9765] Loss_D: 0.0987 Loss_G: 0.0404 Convergence: 0.1002 k= 0.022636 lr = 0.0000204\n",
      "[9/25][6890/9765] Loss_D: 0.1026 Loss_G: 0.0419 Convergence: 0.1040 k= 0.022641 lr = 0.0000204\n",
      "[9/25][6900/9765] Loss_D: 0.1049 Loss_G: 0.0371 Convergence: 0.1110 k= 0.022627 lr = 0.0000204\n",
      "[9/25][6910/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1007 k= 0.022622 lr = 0.0000204\n",
      "[9/25][6920/9765] Loss_D: 0.0903 Loss_G: 0.0396 Convergence: 0.0944 k= 0.022604 lr = 0.0000204\n",
      "[9/25][6930/9765] Loss_D: 0.1050 Loss_G: 0.0448 Convergence: 0.1084 k= 0.022563 lr = 0.0000204\n",
      "[9/25][6940/9765] Loss_D: 0.0959 Loss_G: 0.0398 Convergence: 0.0979 k= 0.022509 lr = 0.0000204\n",
      "[9/25][6950/9765] Loss_D: 0.1059 Loss_G: 0.0356 Convergence: 0.1137 k= 0.022536 lr = 0.0000204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][6960/9765] Loss_D: 0.1007 Loss_G: 0.0327 Convergence: 0.1092 k= 0.022617 lr = 0.0000204\n",
      "[9/25][6970/9765] Loss_D: 0.0988 Loss_G: 0.0404 Convergence: 0.1002 k= 0.022667 lr = 0.0000204\n",
      "[9/25][6980/9765] Loss_D: 0.0981 Loss_G: 0.0500 Convergence: 0.1094 k= 0.022652 lr = 0.0000204\n",
      "[9/25][6990/9765] Loss_D: 0.1024 Loss_G: 0.0398 Convergence: 0.1048 k= 0.022582 lr = 0.0000204\n",
      "[9/25][7000/9765] Loss_D: 0.1022 Loss_G: 0.0408 Convergence: 0.1035 k= 0.022591 lr = 0.0000204\n",
      "[9/25][7010/9765] Loss_D: 0.1031 Loss_G: 0.0362 Convergence: 0.1093 k= 0.022612 lr = 0.0000204\n",
      "[9/25][7020/9765] Loss_D: 0.0942 Loss_G: 0.0424 Convergence: 0.0995 k= 0.022609 lr = 0.0000204\n",
      "[9/25][7030/9765] Loss_D: 0.1043 Loss_G: 0.0440 Convergence: 0.1072 k= 0.022581 lr = 0.0000204\n",
      "[9/25][7040/9765] Loss_D: 0.0980 Loss_G: 0.0434 Convergence: 0.1027 k= 0.022556 lr = 0.0000204\n",
      "[9/25][7050/9765] Loss_D: 0.1053 Loss_G: 0.0421 Convergence: 0.1067 k= 0.022548 lr = 0.0000204\n",
      "[9/25][7060/9765] Loss_D: 0.0991 Loss_G: 0.0390 Convergence: 0.1010 k= 0.022544 lr = 0.0000204\n",
      "[9/25][7070/9765] Loss_D: 0.1071 Loss_G: 0.0414 Convergence: 0.1098 k= 0.022564 lr = 0.0000204\n",
      "[9/25][7080/9765] Loss_D: 0.1101 Loss_G: 0.0424 Convergence: 0.1129 k= 0.022574 lr = 0.0000204\n",
      "[9/25][7090/9765] Loss_D: 0.1018 Loss_G: 0.0357 Convergence: 0.1080 k= 0.022576 lr = 0.0000204\n",
      "[9/25][7100/9765] Loss_D: 0.1034 Loss_G: 0.0423 Convergence: 0.1049 k= 0.022606 lr = 0.0000204\n",
      "[9/25][7110/9765] Loss_D: 0.0932 Loss_G: 0.0401 Convergence: 0.0965 k= 0.022606 lr = 0.0000204\n",
      "[9/25][7120/9765] Loss_D: 0.1025 Loss_G: 0.0435 Convergence: 0.1056 k= 0.022572 lr = 0.0000204\n",
      "[9/25][7130/9765] Loss_D: 0.0903 Loss_G: 0.0356 Convergence: 0.0920 k= 0.022564 lr = 0.0000204\n",
      "[9/25][7140/9765] Loss_D: 0.1002 Loss_G: 0.0424 Convergence: 0.1031 k= 0.022580 lr = 0.0000204\n",
      "[9/25][7150/9765] Loss_D: 0.0955 Loss_G: 0.0368 Convergence: 0.0980 k= 0.022581 lr = 0.0000204\n",
      "[9/25][7160/9765] Loss_D: 0.0968 Loss_G: 0.0393 Convergence: 0.0979 k= 0.022591 lr = 0.0000204\n",
      "[9/25][7170/9765] Loss_D: 0.0900 Loss_G: 0.0402 Convergence: 0.0948 k= 0.022595 lr = 0.0000204\n",
      "[9/25][7180/9765] Loss_D: 0.0958 Loss_G: 0.0459 Convergence: 0.1040 k= 0.022552 lr = 0.0000204\n",
      "[9/25][7190/9765] Loss_D: 0.1092 Loss_G: 0.0386 Convergence: 0.1153 k= 0.022572 lr = 0.0000204\n",
      "[9/25][7200/9765] Loss_D: 0.0888 Loss_G: 0.0363 Convergence: 0.0901 k= 0.022593 lr = 0.0000204\n",
      "[9/25][7210/9765] Loss_D: 0.0909 Loss_G: 0.0382 Convergence: 0.0932 k= 0.022599 lr = 0.0000204\n",
      "[9/25][7220/9765] Loss_D: 0.1052 Loss_G: 0.0399 Convergence: 0.1085 k= 0.022618 lr = 0.0000204\n",
      "[9/25][7230/9765] Loss_D: 0.0990 Loss_G: 0.0375 Convergence: 0.1024 k= 0.022618 lr = 0.0000204\n",
      "[9/25][7240/9765] Loss_D: 0.1078 Loss_G: 0.0394 Convergence: 0.1127 k= 0.022625 lr = 0.0000204\n",
      "[9/25][7250/9765] Loss_D: 0.0933 Loss_G: 0.0408 Convergence: 0.0974 k= 0.022619 lr = 0.0000204\n",
      "[9/25][7260/9765] Loss_D: 0.0968 Loss_G: 0.0378 Convergence: 0.0989 k= 0.022608 lr = 0.0000204\n",
      "[9/25][7270/9765] Loss_D: 0.0893 Loss_G: 0.0410 Convergence: 0.0952 k= 0.022601 lr = 0.0000204\n",
      "[9/25][7280/9765] Loss_D: 0.0959 Loss_G: 0.0393 Convergence: 0.0974 k= 0.022609 lr = 0.0000204\n",
      "[9/25][7290/9765] Loss_D: 0.0951 Loss_G: 0.0395 Convergence: 0.0970 k= 0.022605 lr = 0.0000204\n",
      "[9/25][7300/9765] Loss_D: 0.0977 Loss_G: 0.0394 Convergence: 0.0987 k= 0.022607 lr = 0.0000204\n",
      "[9/25][7310/9765] Loss_D: 0.1075 Loss_G: 0.0403 Convergence: 0.1116 k= 0.022595 lr = 0.0000204\n",
      "[9/25][7320/9765] Loss_D: 0.0904 Loss_G: 0.0403 Convergence: 0.0951 k= 0.022579 lr = 0.0000204\n",
      "[9/25][7330/9765] Loss_D: 0.1044 Loss_G: 0.0382 Convergence: 0.1092 k= 0.022573 lr = 0.0000204\n",
      "[9/25][7340/9765] Loss_D: 0.1027 Loss_G: 0.0375 Convergence: 0.1074 k= 0.022585 lr = 0.0000204\n",
      "[9/25][7350/9765] Loss_D: 0.0993 Loss_G: 0.0419 Convergence: 0.1020 k= 0.022581 lr = 0.0000204\n",
      "[9/25][7360/9765] Loss_D: 0.0995 Loss_G: 0.0413 Convergence: 0.1015 k= 0.022578 lr = 0.0000204\n",
      "[9/25][7370/9765] Loss_D: 0.0957 Loss_G: 0.0400 Convergence: 0.0979 k= 0.022586 lr = 0.0000204\n",
      "[9/25][7380/9765] Loss_D: 0.1031 Loss_G: 0.0397 Convergence: 0.1059 k= 0.022574 lr = 0.0000204\n",
      "[9/25][7390/9765] Loss_D: 0.1029 Loss_G: 0.0399 Convergence: 0.1054 k= 0.022576 lr = 0.0000204\n",
      "[9/25][7400/9765] Loss_D: 0.0945 Loss_G: 0.0417 Convergence: 0.0989 k= 0.022561 lr = 0.0000204\n",
      "[9/25][7410/9765] Loss_D: 0.0930 Loss_G: 0.0406 Convergence: 0.0970 k= 0.022547 lr = 0.0000204\n",
      "[9/25][7420/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0967 k= 0.022555 lr = 0.0000204\n",
      "[9/25][7430/9765] Loss_D: 0.1012 Loss_G: 0.0394 Convergence: 0.1034 k= 0.022570 lr = 0.0000204\n",
      "[9/25][7440/9765] Loss_D: 0.0918 Loss_G: 0.0367 Convergence: 0.0930 k= 0.022577 lr = 0.0000204\n",
      "[9/25][7450/9765] Loss_D: 0.0919 Loss_G: 0.0384 Convergence: 0.0940 k= 0.022597 lr = 0.0000204\n",
      "[9/25][7460/9765] Loss_D: 0.1015 Loss_G: 0.0442 Convergence: 0.1056 k= 0.022604 lr = 0.0000204\n",
      "[9/25][7470/9765] Loss_D: 0.0974 Loss_G: 0.0406 Convergence: 0.0996 k= 0.022581 lr = 0.0000204\n",
      "[9/25][7480/9765] Loss_D: 0.0941 Loss_G: 0.0389 Convergence: 0.0959 k= 0.022567 lr = 0.0000204\n",
      "[9/25][7490/9765] Loss_D: 0.0895 Loss_G: 0.0359 Convergence: 0.0906 k= 0.022569 lr = 0.0000204\n",
      "[9/25][7500/9765] Loss_D: 0.0965 Loss_G: 0.0373 Convergence: 0.0989 k= 0.022598 lr = 0.0000204\n",
      "[9/25][7510/9765] Loss_D: 0.0952 Loss_G: 0.0423 Convergence: 0.1000 k= 0.022595 lr = 0.0000204\n",
      "[9/25][7520/9765] Loss_D: 0.1003 Loss_G: 0.0447 Convergence: 0.1054 k= 0.022569 lr = 0.0000204\n",
      "[9/25][7530/9765] Loss_D: 0.0910 Loss_G: 0.0429 Convergence: 0.0980 k= 0.022521 lr = 0.0000204\n",
      "[9/25][7540/9765] Loss_D: 0.1058 Loss_G: 0.0371 Convergence: 0.1122 k= 0.022525 lr = 0.0000204\n",
      "[9/25][7550/9765] Loss_D: 0.0958 Loss_G: 0.0382 Convergence: 0.0972 k= 0.022549 lr = 0.0000204\n",
      "[9/25][7560/9765] Loss_D: 0.0974 Loss_G: 0.0396 Convergence: 0.0985 k= 0.022552 lr = 0.0000204\n",
      "[9/25][7570/9765] Loss_D: 0.1122 Loss_G: 0.0379 Convergence: 0.1204 k= 0.022538 lr = 0.0000204\n",
      "[9/25][7580/9765] Loss_D: 0.1034 Loss_G: 0.0432 Convergence: 0.1059 k= 0.022530 lr = 0.0000204\n",
      "[9/25][7590/9765] Loss_D: 0.1057 Loss_G: 0.0391 Convergence: 0.1101 k= 0.022521 lr = 0.0000204\n",
      "[9/25][7600/9765] Loss_D: 0.0998 Loss_G: 0.0425 Convergence: 0.1030 k= 0.022506 lr = 0.0000204\n",
      "[9/25][7610/9765] Loss_D: 0.0980 Loss_G: 0.0367 Convergence: 0.1017 k= 0.022510 lr = 0.0000204\n",
      "[9/25][7620/9765] Loss_D: 0.0959 Loss_G: 0.0406 Convergence: 0.0986 k= 0.022526 lr = 0.0000204\n",
      "[9/25][7630/9765] Loss_D: 0.0993 Loss_G: 0.0373 Convergence: 0.1028 k= 0.022531 lr = 0.0000204\n",
      "[9/25][7640/9765] Loss_D: 0.0972 Loss_G: 0.0392 Convergence: 0.0981 k= 0.022536 lr = 0.0000204\n",
      "[9/25][7650/9765] Loss_D: 0.0991 Loss_G: 0.0384 Convergence: 0.1017 k= 0.022531 lr = 0.0000204\n",
      "[9/25][7660/9765] Loss_D: 0.1065 Loss_G: 0.0365 Convergence: 0.1137 k= 0.022546 lr = 0.0000204\n",
      "[9/25][7670/9765] Loss_D: 0.0997 Loss_G: 0.0422 Convergence: 0.1025 k= 0.022542 lr = 0.0000204\n",
      "[9/25][7680/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0978 k= 0.022541 lr = 0.0000204\n",
      "[9/25][7690/9765] Loss_D: 0.0929 Loss_G: 0.0399 Convergence: 0.0963 k= 0.022546 lr = 0.0000204\n",
      "[9/25][7700/9765] Loss_D: 0.1113 Loss_G: 0.0379 Convergence: 0.1191 k= 0.022574 lr = 0.0000204\n",
      "[9/25][7710/9765] Loss_D: 0.1026 Loss_G: 0.0418 Convergence: 0.1040 k= 0.022568 lr = 0.0000204\n",
      "[9/25][7720/9765] Loss_D: 0.0872 Loss_G: 0.0449 Convergence: 0.0978 k= 0.022516 lr = 0.0000204\n",
      "[9/25][7730/9765] Loss_D: 0.0998 Loss_G: 0.0424 Convergence: 0.1028 k= 0.022477 lr = 0.0000204\n",
      "[9/25][7740/9765] Loss_D: 0.1047 Loss_G: 0.0378 Convergence: 0.1099 k= 0.022464 lr = 0.0000204\n",
      "[9/25][7750/9765] Loss_D: 0.0991 Loss_G: 0.0348 Convergence: 0.1049 k= 0.022521 lr = 0.0000204\n",
      "[9/25][7760/9765] Loss_D: 0.0999 Loss_G: 0.0411 Convergence: 0.1015 k= 0.022537 lr = 0.0000204\n",
      "[9/25][7770/9765] Loss_D: 0.0898 Loss_G: 0.0363 Convergence: 0.0907 k= 0.022543 lr = 0.0000204\n",
      "[9/25][7780/9765] Loss_D: 0.1022 Loss_G: 0.0391 Convergence: 0.1052 k= 0.022563 lr = 0.0000204\n",
      "[9/25][7790/9765] Loss_D: 0.0991 Loss_G: 0.0415 Convergence: 0.1015 k= 0.022559 lr = 0.0000204\n",
      "[9/25][7800/9765] Loss_D: 0.0918 Loss_G: 0.0399 Convergence: 0.0955 k= 0.022575 lr = 0.0000204\n",
      "[9/25][7810/9765] Loss_D: 0.1025 Loss_G: 0.0402 Convergence: 0.1045 k= 0.022579 lr = 0.0000204\n",
      "[9/25][7820/9765] Loss_D: 0.0906 Loss_G: 0.0365 Convergence: 0.0915 k= 0.022595 lr = 0.0000204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][7830/9765] Loss_D: 0.0921 Loss_G: 0.0371 Convergence: 0.0930 k= 0.022604 lr = 0.0000204\n",
      "[9/25][7840/9765] Loss_D: 0.0967 Loss_G: 0.0407 Convergence: 0.0993 k= 0.022606 lr = 0.0000204\n",
      "[9/25][7850/9765] Loss_D: 0.1002 Loss_G: 0.0409 Convergence: 0.1016 k= 0.022602 lr = 0.0000204\n",
      "[9/25][7860/9765] Loss_D: 0.0922 Loss_G: 0.0393 Convergence: 0.0952 k= 0.022609 lr = 0.0000204\n",
      "[9/25][7870/9765] Loss_D: 0.0980 Loss_G: 0.0389 Convergence: 0.0995 k= 0.022625 lr = 0.0000204\n",
      "[9/25][7880/9765] Loss_D: 0.1016 Loss_G: 0.0405 Convergence: 0.1030 k= 0.022619 lr = 0.0000204\n",
      "[9/25][7890/9765] Loss_D: 0.0901 Loss_G: 0.0400 Convergence: 0.0946 k= 0.022604 lr = 0.0000204\n",
      "[9/25][7900/9765] Loss_D: 0.1044 Loss_G: 0.0438 Convergence: 0.1070 k= 0.022621 lr = 0.0000204\n",
      "[9/25][7910/9765] Loss_D: 0.0906 Loss_G: 0.0389 Convergence: 0.0939 k= 0.022602 lr = 0.0000204\n",
      "[9/25][7920/9765] Loss_D: 0.0989 Loss_G: 0.0395 Convergence: 0.1002 k= 0.022606 lr = 0.0000204\n",
      "[9/25][7930/9765] Loss_D: 0.0956 Loss_G: 0.0407 Convergence: 0.0986 k= 0.022604 lr = 0.0000204\n",
      "[9/25][7940/9765] Loss_D: 0.0993 Loss_G: 0.0366 Convergence: 0.1036 k= 0.022628 lr = 0.0000204\n",
      "[9/25][7950/9765] Loss_D: 0.0908 Loss_G: 0.0395 Convergence: 0.0945 k= 0.022655 lr = 0.0000204\n",
      "[9/25][7960/9765] Loss_D: 0.1046 Loss_G: 0.0399 Convergence: 0.1077 k= 0.022675 lr = 0.0000204\n",
      "[9/25][7970/9765] Loss_D: 0.1037 Loss_G: 0.0391 Convergence: 0.1074 k= 0.022678 lr = 0.0000204\n",
      "[9/25][7980/9765] Loss_D: 0.0976 Loss_G: 0.0414 Convergence: 0.1005 k= 0.022671 lr = 0.0000204\n",
      "[9/25][7990/9765] Loss_D: 0.1076 Loss_G: 0.0412 Convergence: 0.1107 k= 0.022672 lr = 0.0000204\n",
      "[9/25][8000/9765] Loss_D: 0.0935 Loss_G: 0.0424 Convergence: 0.0991 k= 0.022662 lr = 0.0000204\n",
      "[9/25][8010/9765] Loss_D: 0.0968 Loss_G: 0.0416 Convergence: 0.1002 k= 0.022660 lr = 0.0000204\n",
      "[9/25][8020/9765] Loss_D: 0.0955 Loss_G: 0.0393 Convergence: 0.0972 k= 0.022641 lr = 0.0000204\n",
      "[9/25][8030/9765] Loss_D: 0.0962 Loss_G: 0.0396 Convergence: 0.0979 k= 0.022628 lr = 0.0000204\n",
      "[9/25][8040/9765] Loss_D: 0.0973 Loss_G: 0.0362 Convergence: 0.1013 k= 0.022618 lr = 0.0000204\n",
      "[9/25][8050/9765] Loss_D: 0.0915 Loss_G: 0.0381 Convergence: 0.0935 k= 0.022648 lr = 0.0000204\n",
      "[9/25][8060/9765] Loss_D: 0.0997 Loss_G: 0.0420 Convergence: 0.1023 k= 0.022654 lr = 0.0000204\n",
      "[9/25][8070/9765] Loss_D: 0.0980 Loss_G: 0.0385 Convergence: 0.1001 k= 0.022632 lr = 0.0000204\n",
      "[9/25][8080/9765] Loss_D: 0.1146 Loss_G: 0.0389 Convergence: 0.1228 k= 0.022644 lr = 0.0000204\n",
      "[9/25][8090/9765] Loss_D: 0.0988 Loss_G: 0.0436 Convergence: 0.1035 k= 0.022649 lr = 0.0000204\n",
      "[9/25][8100/9765] Loss_D: 0.1019 Loss_G: 0.0411 Convergence: 0.1028 k= 0.022634 lr = 0.0000204\n",
      "[9/25][8110/9765] Loss_D: 0.1041 Loss_G: 0.0379 Convergence: 0.1091 k= 0.022622 lr = 0.0000204\n",
      "[9/25][8120/9765] Loss_D: 0.0995 Loss_G: 0.0386 Convergence: 0.1019 k= 0.022609 lr = 0.0000194\n",
      "[9/25][8130/9765] Loss_D: 0.0987 Loss_G: 0.0411 Convergence: 0.1009 k= 0.022613 lr = 0.0000194\n",
      "[9/25][8140/9765] Loss_D: 0.0970 Loss_G: 0.0399 Convergence: 0.0986 k= 0.022619 lr = 0.0000194\n",
      "[9/25][8150/9765] Loss_D: 0.0914 Loss_G: 0.0373 Convergence: 0.0927 k= 0.022637 lr = 0.0000194\n",
      "[9/25][8160/9765] Loss_D: 0.1116 Loss_G: 0.0403 Convergence: 0.1172 k= 0.022655 lr = 0.0000194\n",
      "[9/25][8170/9765] Loss_D: 0.1168 Loss_G: 0.0413 Convergence: 0.1235 k= 0.022667 lr = 0.0000194\n",
      "[9/25][8180/9765] Loss_D: 0.1010 Loss_G: 0.0391 Convergence: 0.1036 k= 0.022672 lr = 0.0000194\n",
      "[9/25][8190/9765] Loss_D: 0.0930 Loss_G: 0.0367 Convergence: 0.0946 k= 0.022679 lr = 0.0000194\n",
      "[9/25][8200/9765] Loss_D: 0.0917 Loss_G: 0.0390 Convergence: 0.0946 k= 0.022686 lr = 0.0000194\n",
      "[9/25][8210/9765] Loss_D: 0.0908 Loss_G: 0.0374 Convergence: 0.0924 k= 0.022686 lr = 0.0000194\n",
      "[9/25][8220/9765] Loss_D: 0.0924 Loss_G: 0.0393 Convergence: 0.0953 k= 0.022687 lr = 0.0000194\n",
      "[9/25][8230/9765] Loss_D: 0.0970 Loss_G: 0.0374 Convergence: 0.0996 k= 0.022689 lr = 0.0000194\n",
      "[9/25][8240/9765] Loss_D: 0.0968 Loss_G: 0.0395 Convergence: 0.0981 k= 0.022698 lr = 0.0000194\n",
      "[9/25][8250/9765] Loss_D: 0.0921 Loss_G: 0.0391 Convergence: 0.0949 k= 0.022703 lr = 0.0000194\n",
      "[9/25][8260/9765] Loss_D: 0.0986 Loss_G: 0.0423 Convergence: 0.1020 k= 0.022714 lr = 0.0000194\n",
      "[9/25][8270/9765] Loss_D: 0.1028 Loss_G: 0.0444 Convergence: 0.1066 k= 0.022681 lr = 0.0000194\n",
      "[9/25][8280/9765] Loss_D: 0.0919 Loss_G: 0.0364 Convergence: 0.0935 k= 0.022679 lr = 0.0000194\n",
      "[9/25][8290/9765] Loss_D: 0.0993 Loss_G: 0.0376 Convergence: 0.1026 k= 0.022701 lr = 0.0000194\n",
      "[9/25][8300/9765] Loss_D: 0.1074 Loss_G: 0.0417 Convergence: 0.1100 k= 0.022714 lr = 0.0000194\n",
      "[9/25][8310/9765] Loss_D: 0.1012 Loss_G: 0.0451 Convergence: 0.1064 k= 0.022708 lr = 0.0000194\n",
      "[9/25][8320/9765] Loss_D: 0.0912 Loss_G: 0.0409 Convergence: 0.0962 k= 0.022669 lr = 0.0000194\n",
      "[9/25][8330/9765] Loss_D: 0.1057 Loss_G: 0.0398 Convergence: 0.1094 k= 0.022670 lr = 0.0000194\n",
      "[9/25][8340/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0941 k= 0.022680 lr = 0.0000194\n",
      "[9/25][8350/9765] Loss_D: 0.0957 Loss_G: 0.0412 Convergence: 0.0992 k= 0.022690 lr = 0.0000194\n",
      "[9/25][8360/9765] Loss_D: 0.0998 Loss_G: 0.0406 Convergence: 0.1010 k= 0.022690 lr = 0.0000194\n",
      "[9/25][8370/9765] Loss_D: 0.0983 Loss_G: 0.0424 Convergence: 0.1020 k= 0.022675 lr = 0.0000194\n",
      "[9/25][8380/9765] Loss_D: 0.0978 Loss_G: 0.0373 Convergence: 0.1008 k= 0.022670 lr = 0.0000194\n",
      "[9/25][8390/9765] Loss_D: 0.0946 Loss_G: 0.0369 Convergence: 0.0967 k= 0.022679 lr = 0.0000194\n",
      "[9/25][8400/9765] Loss_D: 0.1025 Loss_G: 0.0356 Convergence: 0.1091 k= 0.022711 lr = 0.0000194\n",
      "[9/25][8410/9765] Loss_D: 0.0903 Loss_G: 0.0404 Convergence: 0.0952 k= 0.022704 lr = 0.0000194\n",
      "[9/25][8420/9765] Loss_D: 0.0953 Loss_G: 0.0441 Convergence: 0.1019 k= 0.022656 lr = 0.0000194\n",
      "[9/25][8430/9765] Loss_D: 0.0998 Loss_G: 0.0386 Convergence: 0.1024 k= 0.022640 lr = 0.0000194\n",
      "[9/25][8440/9765] Loss_D: 0.0975 Loss_G: 0.0379 Convergence: 0.0997 k= 0.022669 lr = 0.0000194\n",
      "[9/25][8450/9765] Loss_D: 0.0973 Loss_G: 0.0397 Convergence: 0.0986 k= 0.022671 lr = 0.0000194\n",
      "[9/25][8460/9765] Loss_D: 0.1056 Loss_G: 0.0396 Convergence: 0.1094 k= 0.022680 lr = 0.0000194\n",
      "[9/25][8470/9765] Loss_D: 0.1016 Loss_G: 0.0429 Convergence: 0.1044 k= 0.022654 lr = 0.0000194\n",
      "[9/25][8480/9765] Loss_D: 0.0907 Loss_G: 0.0365 Convergence: 0.0917 k= 0.022658 lr = 0.0000194\n",
      "[9/25][8490/9765] Loss_D: 0.1002 Loss_G: 0.0429 Convergence: 0.1036 k= 0.022660 lr = 0.0000194\n",
      "[9/25][8500/9765] Loss_D: 0.0912 Loss_G: 0.0411 Convergence: 0.0964 k= 0.022616 lr = 0.0000194\n",
      "[9/25][8510/9765] Loss_D: 0.1079 Loss_G: 0.0393 Convergence: 0.1130 k= 0.022625 lr = 0.0000194\n",
      "[9/25][8520/9765] Loss_D: 0.0951 Loss_G: 0.0387 Convergence: 0.0963 k= 0.022654 lr = 0.0000194\n",
      "[9/25][8530/9765] Loss_D: 0.1027 Loss_G: 0.0392 Convergence: 0.1058 k= 0.022669 lr = 0.0000194\n",
      "[9/25][8540/9765] Loss_D: 0.1047 Loss_G: 0.0426 Convergence: 0.1060 k= 0.022659 lr = 0.0000194\n",
      "[9/25][8550/9765] Loss_D: 0.0949 Loss_G: 0.0397 Convergence: 0.0972 k= 0.022637 lr = 0.0000194\n",
      "[9/25][8560/9765] Loss_D: 0.0972 Loss_G: 0.0399 Convergence: 0.0988 k= 0.022624 lr = 0.0000194\n",
      "[9/25][8570/9765] Loss_D: 0.0925 Loss_G: 0.0415 Convergence: 0.0975 k= 0.022609 lr = 0.0000194\n",
      "[9/25][8580/9765] Loss_D: 0.0993 Loss_G: 0.0389 Convergence: 0.1012 k= 0.022604 lr = 0.0000194\n",
      "[9/25][8590/9765] Loss_D: 0.0968 Loss_G: 0.0377 Convergence: 0.0990 k= 0.022629 lr = 0.0000194\n",
      "[9/25][8600/9765] Loss_D: 0.0933 Loss_G: 0.0401 Convergence: 0.0966 k= 0.022618 lr = 0.0000194\n",
      "[9/25][8610/9765] Loss_D: 0.0946 Loss_G: 0.0468 Convergence: 0.1041 k= 0.022577 lr = 0.0000194\n",
      "[9/25][8620/9765] Loss_D: 0.0955 Loss_G: 0.0374 Convergence: 0.0974 k= 0.022545 lr = 0.0000194\n",
      "[9/25][8630/9765] Loss_D: 0.0931 Loss_G: 0.0398 Convergence: 0.0962 k= 0.022556 lr = 0.0000194\n",
      "[9/25][8640/9765] Loss_D: 0.0977 Loss_G: 0.0400 Convergence: 0.0992 k= 0.022549 lr = 0.0000194\n",
      "[9/25][8650/9765] Loss_D: 0.1065 Loss_G: 0.0394 Convergence: 0.1109 k= 0.022562 lr = 0.0000194\n",
      "[9/25][8660/9765] Loss_D: 0.0990 Loss_G: 0.0403 Convergence: 0.1002 k= 0.022563 lr = 0.0000194\n",
      "[9/25][8670/9765] Loss_D: 0.0981 Loss_G: 0.0389 Convergence: 0.0996 k= 0.022563 lr = 0.0000194\n",
      "[9/25][8680/9765] Loss_D: 0.0988 Loss_G: 0.0387 Convergence: 0.1009 k= 0.022570 lr = 0.0000194\n",
      "[9/25][8690/9765] Loss_D: 0.0933 Loss_G: 0.0387 Convergence: 0.0952 k= 0.022576 lr = 0.0000194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][8700/9765] Loss_D: 0.0975 Loss_G: 0.0360 Convergence: 0.1016 k= 0.022601 lr = 0.0000194\n",
      "[9/25][8710/9765] Loss_D: 0.1094 Loss_G: 0.0388 Convergence: 0.1155 k= 0.022621 lr = 0.0000194\n",
      "[9/25][8720/9765] Loss_D: 0.1025 Loss_G: 0.0423 Convergence: 0.1044 k= 0.022640 lr = 0.0000194\n",
      "[9/25][8730/9765] Loss_D: 0.0993 Loss_G: 0.0406 Convergence: 0.1007 k= 0.022639 lr = 0.0000194\n",
      "[9/25][8740/9765] Loss_D: 0.0986 Loss_G: 0.0408 Convergence: 0.1004 k= 0.022642 lr = 0.0000194\n",
      "[9/25][8750/9765] Loss_D: 0.0940 Loss_G: 0.0396 Convergence: 0.0965 k= 0.022645 lr = 0.0000194\n",
      "[9/25][8760/9765] Loss_D: 0.1025 Loss_G: 0.0404 Convergence: 0.1044 k= 0.022653 lr = 0.0000194\n",
      "[9/25][8770/9765] Loss_D: 0.1003 Loss_G: 0.0396 Convergence: 0.1021 k= 0.022648 lr = 0.0000194\n",
      "[9/25][8780/9765] Loss_D: 0.1052 Loss_G: 0.0405 Convergence: 0.1080 k= 0.022656 lr = 0.0000194\n",
      "[9/25][8790/9765] Loss_D: 0.1045 Loss_G: 0.0391 Convergence: 0.1084 k= 0.022662 lr = 0.0000194\n",
      "[9/25][8800/9765] Loss_D: 0.0961 Loss_G: 0.0412 Convergence: 0.0994 k= 0.022657 lr = 0.0000194\n",
      "[9/25][8810/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0980 k= 0.022650 lr = 0.0000194\n",
      "[9/25][8820/9765] Loss_D: 0.0980 Loss_G: 0.0407 Convergence: 0.1000 k= 0.022643 lr = 0.0000194\n",
      "[9/25][8830/9765] Loss_D: 0.0926 Loss_G: 0.0383 Convergence: 0.0944 k= 0.022663 lr = 0.0000194\n",
      "[9/25][8840/9765] Loss_D: 0.0961 Loss_G: 0.0376 Convergence: 0.0982 k= 0.022669 lr = 0.0000194\n",
      "[9/25][8850/9765] Loss_D: 0.1007 Loss_G: 0.0411 Convergence: 0.1021 k= 0.022672 lr = 0.0000194\n",
      "[9/25][8860/9765] Loss_D: 0.1039 Loss_G: 0.0430 Convergence: 0.1059 k= 0.022648 lr = 0.0000194\n",
      "[9/25][8870/9765] Loss_D: 0.1097 Loss_G: 0.0400 Convergence: 0.1148 k= 0.022637 lr = 0.0000194\n",
      "[9/25][8880/9765] Loss_D: 0.1029 Loss_G: 0.0407 Convergence: 0.1045 k= 0.022638 lr = 0.0000194\n",
      "[9/25][8890/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0991 k= 0.022651 lr = 0.0000194\n",
      "[9/25][8900/9765] Loss_D: 0.1061 Loss_G: 0.0457 Convergence: 0.1100 k= 0.022637 lr = 0.0000194\n",
      "[9/25][8910/9765] Loss_D: 0.0936 Loss_G: 0.0458 Convergence: 0.1026 k= 0.022581 lr = 0.0000194\n",
      "[9/25][8920/9765] Loss_D: 0.1046 Loss_G: 0.0398 Convergence: 0.1079 k= 0.022552 lr = 0.0000194\n",
      "[9/25][8930/9765] Loss_D: 0.1032 Loss_G: 0.0391 Convergence: 0.1066 k= 0.022571 lr = 0.0000194\n",
      "[9/25][8940/9765] Loss_D: 0.0935 Loss_G: 0.0363 Convergence: 0.0958 k= 0.022577 lr = 0.0000194\n",
      "[9/25][8950/9765] Loss_D: 0.0925 Loss_G: 0.0403 Convergence: 0.0963 k= 0.022591 lr = 0.0000194\n",
      "[9/25][8960/9765] Loss_D: 0.0976 Loss_G: 0.0383 Convergence: 0.0996 k= 0.022575 lr = 0.0000194\n",
      "[9/25][8970/9765] Loss_D: 0.0990 Loss_G: 0.0417 Convergence: 0.1016 k= 0.022575 lr = 0.0000194\n",
      "[9/25][8980/9765] Loss_D: 0.1116 Loss_G: 0.0412 Convergence: 0.1162 k= 0.022573 lr = 0.0000194\n",
      "[9/25][8990/9765] Loss_D: 0.0932 Loss_G: 0.0385 Convergence: 0.0949 k= 0.022563 lr = 0.0000194\n",
      "[9/25][9000/9765] Loss_D: 0.0993 Loss_G: 0.0380 Convergence: 0.1022 k= 0.022576 lr = 0.0000194\n",
      "[9/25][9010/9765] Loss_D: 0.0914 Loss_G: 0.0416 Convergence: 0.0970 k= 0.022555 lr = 0.0000194\n",
      "[9/25][9020/9765] Loss_D: 0.0937 Loss_G: 0.0376 Convergence: 0.0949 k= 0.022549 lr = 0.0000194\n",
      "[9/25][9030/9765] Loss_D: 0.0988 Loss_G: 0.0414 Convergence: 0.1012 k= 0.022535 lr = 0.0000194\n",
      "[9/25][9040/9765] Loss_D: 0.1002 Loss_G: 0.0379 Convergence: 0.1036 k= 0.022546 lr = 0.0000194\n",
      "[9/25][9050/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0964 k= 0.022575 lr = 0.0000194\n",
      "[9/25][9060/9765] Loss_D: 0.0941 Loss_G: 0.0392 Convergence: 0.0962 k= 0.022586 lr = 0.0000194\n",
      "[9/25][9070/9765] Loss_D: 0.1045 Loss_G: 0.0413 Convergence: 0.1062 k= 0.022563 lr = 0.0000194\n",
      "[9/25][9080/9765] Loss_D: 0.1014 Loss_G: 0.0387 Convergence: 0.1045 k= 0.022557 lr = 0.0000194\n",
      "[9/25][9090/9765] Loss_D: 0.0949 Loss_G: 0.0374 Convergence: 0.0966 k= 0.022568 lr = 0.0000194\n",
      "[9/25][9100/9765] Loss_D: 0.0967 Loss_G: 0.0368 Convergence: 0.0998 k= 0.022574 lr = 0.0000194\n",
      "[9/25][9110/9765] Loss_D: 0.0870 Loss_G: 0.0375 Convergence: 0.0902 k= 0.022584 lr = 0.0000194\n",
      "[9/25][9120/9765] Loss_D: 0.1145 Loss_G: 0.0414 Convergence: 0.1202 k= 0.022589 lr = 0.0000194\n",
      "[9/25][9130/9765] Loss_D: 0.1007 Loss_G: 0.0416 Convergence: 0.1026 k= 0.022580 lr = 0.0000194\n",
      "[9/25][9140/9765] Loss_D: 0.1041 Loss_G: 0.0376 Convergence: 0.1093 k= 0.022571 lr = 0.0000194\n",
      "[9/25][9150/9765] Loss_D: 0.0918 Loss_G: 0.0420 Convergence: 0.0976 k= 0.022572 lr = 0.0000194\n",
      "[9/25][9160/9765] Loss_D: 0.1115 Loss_G: 0.0403 Convergence: 0.1171 k= 0.022565 lr = 0.0000194\n",
      "[9/25][9170/9765] Loss_D: 0.1005 Loss_G: 0.0390 Convergence: 0.1030 k= 0.022565 lr = 0.0000194\n",
      "[9/25][9180/9765] Loss_D: 0.0958 Loss_G: 0.0419 Convergence: 0.1000 k= 0.022565 lr = 0.0000194\n",
      "[9/25][9190/9765] Loss_D: 0.0871 Loss_G: 0.0373 Convergence: 0.0901 k= 0.022551 lr = 0.0000194\n",
      "[9/25][9200/9765] Loss_D: 0.0864 Loss_G: 0.0388 Convergence: 0.0912 k= 0.022565 lr = 0.0000194\n",
      "[9/25][9210/9765] Loss_D: 0.0936 Loss_G: 0.0408 Convergence: 0.0976 k= 0.022550 lr = 0.0000194\n",
      "[9/25][9220/9765] Loss_D: 0.0894 Loss_G: 0.0408 Convergence: 0.0951 k= 0.022535 lr = 0.0000194\n",
      "[9/25][9230/9765] Loss_D: 0.1044 Loss_G: 0.0396 Convergence: 0.1078 k= 0.022530 lr = 0.0000194\n",
      "[9/25][9240/9765] Loss_D: 0.0968 Loss_G: 0.0408 Convergence: 0.0994 k= 0.022520 lr = 0.0000194\n",
      "[9/25][9250/9765] Loss_D: 0.1044 Loss_G: 0.0408 Convergence: 0.1065 k= 0.022537 lr = 0.0000194\n",
      "[9/25][9260/9765] Loss_D: 0.0968 Loss_G: 0.0423 Convergence: 0.1008 k= 0.022537 lr = 0.0000194\n",
      "[9/25][9270/9765] Loss_D: 0.0966 Loss_G: 0.0406 Convergence: 0.0990 k= 0.022532 lr = 0.0000194\n",
      "[9/25][9280/9765] Loss_D: 0.0975 Loss_G: 0.0382 Convergence: 0.0997 k= 0.022518 lr = 0.0000194\n",
      "[9/25][9290/9765] Loss_D: 0.0988 Loss_G: 0.0404 Convergence: 0.1002 k= 0.022513 lr = 0.0000194\n",
      "[9/25][9300/9765] Loss_D: 0.0993 Loss_G: 0.0369 Convergence: 0.1032 k= 0.022521 lr = 0.0000194\n",
      "[9/25][9310/9765] Loss_D: 0.0996 Loss_G: 0.0391 Convergence: 0.1015 k= 0.022535 lr = 0.0000194\n",
      "[9/25][9320/9765] Loss_D: 0.1052 Loss_G: 0.0392 Convergence: 0.1094 k= 0.022557 lr = 0.0000194\n",
      "[9/25][9330/9765] Loss_D: 0.0985 Loss_G: 0.0386 Convergence: 0.1005 k= 0.022561 lr = 0.0000194\n",
      "[9/25][9340/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0974 k= 0.022576 lr = 0.0000194\n",
      "[9/25][9350/9765] Loss_D: 0.1007 Loss_G: 0.0443 Convergence: 0.1053 k= 0.022568 lr = 0.0000194\n",
      "[9/25][9360/9765] Loss_D: 0.0953 Loss_G: 0.0386 Convergence: 0.0963 k= 0.022533 lr = 0.0000194\n",
      "[9/25][9370/9765] Loss_D: 0.0994 Loss_G: 0.0377 Convergence: 0.1026 k= 0.022553 lr = 0.0000194\n",
      "[9/25][9380/9765] Loss_D: 0.1014 Loss_G: 0.0382 Convergence: 0.1050 k= 0.022567 lr = 0.0000194\n",
      "[9/25][9390/9765] Loss_D: 0.0962 Loss_G: 0.0404 Convergence: 0.0987 k= 0.022575 lr = 0.0000194\n",
      "[9/25][9400/9765] Loss_D: 0.1052 Loss_G: 0.0394 Convergence: 0.1092 k= 0.022551 lr = 0.0000194\n",
      "[9/25][9410/9765] Loss_D: 0.0976 Loss_G: 0.0462 Convergence: 0.1054 k= 0.022471 lr = 0.0000194\n",
      "[9/25][9420/9765] Loss_D: 0.1049 Loss_G: 0.0398 Convergence: 0.1083 k= 0.022415 lr = 0.0000194\n",
      "[9/25][9430/9765] Loss_D: 0.0932 Loss_G: 0.0390 Convergence: 0.0954 k= 0.022406 lr = 0.0000194\n",
      "[9/25][9440/9765] Loss_D: 0.0932 Loss_G: 0.0371 Convergence: 0.0946 k= 0.022424 lr = 0.0000194\n",
      "[9/25][9450/9765] Loss_D: 0.1163 Loss_G: 0.0411 Convergence: 0.1230 k= 0.022440 lr = 0.0000194\n",
      "[9/25][9460/9765] Loss_D: 0.0974 Loss_G: 0.0366 Convergence: 0.1008 k= 0.022461 lr = 0.0000194\n",
      "[9/25][9470/9765] Loss_D: 0.0935 Loss_G: 0.0394 Convergence: 0.0961 k= 0.022494 lr = 0.0000194\n",
      "[9/25][9480/9765] Loss_D: 0.0921 Loss_G: 0.0394 Convergence: 0.0952 k= 0.022479 lr = 0.0000194\n",
      "[9/25][9490/9765] Loss_D: 0.0957 Loss_G: 0.0380 Convergence: 0.0972 k= 0.022473 lr = 0.0000194\n",
      "[9/25][9500/9765] Loss_D: 0.0965 Loss_G: 0.0394 Convergence: 0.0978 k= 0.022482 lr = 0.0000194\n",
      "[9/25][9510/9765] Loss_D: 0.0950 Loss_G: 0.0408 Convergence: 0.0983 k= 0.022489 lr = 0.0000194\n",
      "[9/25][9520/9765] Loss_D: 0.0951 Loss_G: 0.0400 Convergence: 0.0976 k= 0.022493 lr = 0.0000194\n",
      "[9/25][9530/9765] Loss_D: 0.0990 Loss_G: 0.0402 Convergence: 0.1001 k= 0.022478 lr = 0.0000194\n",
      "[9/25][9540/9765] Loss_D: 0.0988 Loss_G: 0.0403 Convergence: 0.1002 k= 0.022486 lr = 0.0000194\n",
      "[9/25][9550/9765] Loss_D: 0.0992 Loss_G: 0.0360 Convergence: 0.1039 k= 0.022496 lr = 0.0000194\n",
      "[9/25][9560/9765] Loss_D: 0.1002 Loss_G: 0.0377 Convergence: 0.1038 k= 0.022527 lr = 0.0000194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/25][9570/9765] Loss_D: 0.0975 Loss_G: 0.0430 Convergence: 0.1021 k= 0.022535 lr = 0.0000194\n",
      "[9/25][9580/9765] Loss_D: 0.1044 Loss_G: 0.0404 Convergence: 0.1070 k= 0.022526 lr = 0.0000194\n",
      "[9/25][9590/9765] Loss_D: 0.0923 Loss_G: 0.0390 Convergence: 0.0949 k= 0.022540 lr = 0.0000194\n",
      "[9/25][9600/9765] Loss_D: 0.0935 Loss_G: 0.0391 Convergence: 0.0958 k= 0.022557 lr = 0.0000194\n",
      "[9/25][9610/9765] Loss_D: 0.0941 Loss_G: 0.0440 Convergence: 0.1010 k= 0.022526 lr = 0.0000194\n",
      "[9/25][9620/9765] Loss_D: 0.1051 Loss_G: 0.0417 Convergence: 0.1067 k= 0.022511 lr = 0.0000194\n",
      "[9/25][9630/9765] Loss_D: 0.0913 Loss_G: 0.0402 Convergence: 0.0955 k= 0.022501 lr = 0.0000194\n",
      "[9/25][9640/9765] Loss_D: 0.1051 Loss_G: 0.0362 Convergence: 0.1121 k= 0.022521 lr = 0.0000194\n",
      "[9/25][9650/9765] Loss_D: 0.0970 Loss_G: 0.0394 Convergence: 0.0981 k= 0.022536 lr = 0.0000194\n",
      "[9/25][9660/9765] Loss_D: 0.0903 Loss_G: 0.0390 Convergence: 0.0937 k= 0.022525 lr = 0.0000194\n",
      "[9/25][9670/9765] Loss_D: 0.0982 Loss_G: 0.0409 Convergence: 0.1004 k= 0.022522 lr = 0.0000194\n",
      "[9/25][9680/9765] Loss_D: 0.0956 Loss_G: 0.0388 Convergence: 0.0967 k= 0.022531 lr = 0.0000194\n",
      "[9/25][9690/9765] Loss_D: 0.1072 Loss_G: 0.0417 Convergence: 0.1097 k= 0.022523 lr = 0.0000194\n",
      "[9/25][9700/9765] Loss_D: 0.0985 Loss_G: 0.0420 Convergence: 0.1017 k= 0.022500 lr = 0.0000194\n",
      "[9/25][9710/9765] Loss_D: 0.0972 Loss_G: 0.0402 Convergence: 0.0990 k= 0.022493 lr = 0.0000194\n",
      "[9/25][9720/9765] Loss_D: 0.0956 Loss_G: 0.0415 Convergence: 0.0994 k= 0.022499 lr = 0.0000194\n",
      "[9/25][9730/9765] Loss_D: 0.1036 Loss_G: 0.0366 Convergence: 0.1096 k= 0.022501 lr = 0.0000194\n",
      "[9/25][9740/9765] Loss_D: 0.1047 Loss_G: 0.0404 Convergence: 0.1075 k= 0.022516 lr = 0.0000194\n",
      "[9/25][9750/9765] Loss_D: 0.0937 Loss_G: 0.0383 Convergence: 0.0950 k= 0.022522 lr = 0.0000194\n",
      "[9/25][9760/9765] Loss_D: 0.1094 Loss_G: 0.0423 Convergence: 0.1122 k= 0.022515 lr = 0.0000194\n",
      "[10/25][0/9765] Loss_D: 0.0951 Loss_G: 0.0446 Convergence: 0.1023 k= 0.022498 lr = 0.0000194\n",
      "[10/25][10/9765] Loss_D: 0.0976 Loss_G: 0.0404 Convergence: 0.0994 k= 0.022498 lr = 0.0000194\n",
      "[10/25][20/9765] Loss_D: 0.1005 Loss_G: 0.0383 Convergence: 0.1036 k= 0.022498 lr = 0.0000194\n",
      "[10/25][30/9765] Loss_D: 0.1004 Loss_G: 0.0402 Convergence: 0.1017 k= 0.022500 lr = 0.0000194\n",
      "[10/25][40/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0960 k= 0.022488 lr = 0.0000194\n",
      "[10/25][50/9765] Loss_D: 0.1011 Loss_G: 0.0400 Convergence: 0.1028 k= 0.022477 lr = 0.0000194\n",
      "[10/25][60/9765] Loss_D: 0.1023 Loss_G: 0.0417 Convergence: 0.1036 k= 0.022470 lr = 0.0000194\n",
      "[10/25][70/9765] Loss_D: 0.0958 Loss_G: 0.0365 Convergence: 0.0988 k= 0.022464 lr = 0.0000194\n",
      "[10/25][80/9765] Loss_D: 0.0980 Loss_G: 0.0371 Convergence: 0.1013 k= 0.022483 lr = 0.0000194\n",
      "[10/25][90/9765] Loss_D: 0.1022 Loss_G: 0.0410 Convergence: 0.1034 k= 0.022504 lr = 0.0000194\n",
      "[10/25][100/9765] Loss_D: 0.0960 Loss_G: 0.0365 Convergence: 0.0991 k= 0.022502 lr = 0.0000194\n",
      "[10/25][110/9765] Loss_D: 0.0990 Loss_G: 0.0389 Convergence: 0.1008 k= 0.022504 lr = 0.0000194\n",
      "[10/25][120/9765] Loss_D: 0.1044 Loss_G: 0.0402 Convergence: 0.1071 k= 0.022506 lr = 0.0000194\n",
      "[10/25][130/9765] Loss_D: 0.0993 Loss_G: 0.0374 Convergence: 0.1029 k= 0.022495 lr = 0.0000194\n",
      "[10/25][140/9765] Loss_D: 0.0908 Loss_G: 0.0374 Convergence: 0.0924 k= 0.022494 lr = 0.0000194\n",
      "[10/25][150/9765] Loss_D: 0.0921 Loss_G: 0.0379 Convergence: 0.0936 k= 0.022489 lr = 0.0000194\n",
      "[10/25][160/9765] Loss_D: 0.0963 Loss_G: 0.0416 Convergence: 0.0999 k= 0.022492 lr = 0.0000194\n",
      "[10/25][170/9765] Loss_D: 0.1009 Loss_G: 0.0405 Convergence: 0.1022 k= 0.022475 lr = 0.0000194\n",
      "[10/25][180/9765] Loss_D: 0.1001 Loss_G: 0.0384 Convergence: 0.1030 k= 0.022469 lr = 0.0000194\n",
      "[10/25][190/9765] Loss_D: 0.0881 Loss_G: 0.0358 Convergence: 0.0891 k= 0.022482 lr = 0.0000194\n",
      "[10/25][200/9765] Loss_D: 0.1091 Loss_G: 0.0408 Convergence: 0.1132 k= 0.022489 lr = 0.0000194\n",
      "[10/25][210/9765] Loss_D: 0.0988 Loss_G: 0.0391 Convergence: 0.1005 k= 0.022488 lr = 0.0000194\n",
      "[10/25][220/9765] Loss_D: 0.0990 Loss_G: 0.0394 Convergence: 0.1003 k= 0.022489 lr = 0.0000194\n",
      "[10/25][230/9765] Loss_D: 0.0921 Loss_G: 0.0420 Convergence: 0.0978 k= 0.022465 lr = 0.0000194\n",
      "[10/25][240/9765] Loss_D: 0.0923 Loss_G: 0.0410 Convergence: 0.0969 k= 0.022459 lr = 0.0000194\n",
      "[10/25][250/9765] Loss_D: 0.1008 Loss_G: 0.0357 Convergence: 0.1066 k= 0.022482 lr = 0.0000194\n",
      "[10/25][260/9765] Loss_D: 0.0908 Loss_G: 0.0367 Convergence: 0.0917 k= 0.022518 lr = 0.0000194\n",
      "[10/25][270/9765] Loss_D: 0.1032 Loss_G: 0.0443 Convergence: 0.1068 k= 0.022520 lr = 0.0000194\n",
      "[10/25][280/9765] Loss_D: 0.0902 Loss_G: 0.0389 Convergence: 0.0936 k= 0.022507 lr = 0.0000194\n",
      "[10/25][290/9765] Loss_D: 0.1020 Loss_G: 0.0405 Convergence: 0.1036 k= 0.022491 lr = 0.0000194\n",
      "[10/25][300/9765] Loss_D: 0.0912 Loss_G: 0.0417 Convergence: 0.0970 k= 0.022486 lr = 0.0000194\n",
      "[10/25][310/9765] Loss_D: 0.1083 Loss_G: 0.0408 Convergence: 0.1122 k= 0.022478 lr = 0.0000194\n",
      "[10/25][320/9765] Loss_D: 0.1058 Loss_G: 0.0408 Convergence: 0.1087 k= 0.022474 lr = 0.0000194\n",
      "[10/25][330/9765] Loss_D: 0.0979 Loss_G: 0.0416 Convergence: 0.1009 k= 0.022467 lr = 0.0000194\n",
      "[10/25][340/9765] Loss_D: 0.0985 Loss_G: 0.0363 Convergence: 0.1026 k= 0.022470 lr = 0.0000194\n",
      "[10/25][350/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0935 k= 0.022466 lr = 0.0000194\n",
      "[10/25][360/9765] Loss_D: 0.0985 Loss_G: 0.0388 Convergence: 0.1002 k= 0.022500 lr = 0.0000194\n",
      "[10/25][370/9765] Loss_D: 0.1025 Loss_G: 0.0385 Convergence: 0.1062 k= 0.022500 lr = 0.0000194\n",
      "[10/25][380/9765] Loss_D: 0.0976 Loss_G: 0.0393 Convergence: 0.0986 k= 0.022493 lr = 0.0000194\n",
      "[10/25][390/9765] Loss_D: 0.0933 Loss_G: 0.0365 Convergence: 0.0954 k= 0.022513 lr = 0.0000194\n",
      "[10/25][400/9765] Loss_D: 0.0940 Loss_G: 0.0396 Convergence: 0.0965 k= 0.022522 lr = 0.0000194\n",
      "[10/25][410/9765] Loss_D: 0.0968 Loss_G: 0.0418 Convergence: 0.1005 k= 0.022511 lr = 0.0000194\n",
      "[10/25][420/9765] Loss_D: 0.1022 Loss_G: 0.0387 Convergence: 0.1056 k= 0.022491 lr = 0.0000194\n",
      "[10/25][430/9765] Loss_D: 0.1114 Loss_G: 0.0382 Convergence: 0.1189 k= 0.022523 lr = 0.0000194\n",
      "[10/25][440/9765] Loss_D: 0.0952 Loss_G: 0.0378 Convergence: 0.0967 k= 0.022522 lr = 0.0000194\n",
      "[10/25][450/9765] Loss_D: 0.0999 Loss_G: 0.0413 Convergence: 0.1017 k= 0.022525 lr = 0.0000194\n",
      "[10/25][460/9765] Loss_D: 0.0968 Loss_G: 0.0381 Convergence: 0.0986 k= 0.022535 lr = 0.0000194\n",
      "[10/25][470/9765] Loss_D: 0.1035 Loss_G: 0.0368 Convergence: 0.1092 k= 0.022551 lr = 0.0000194\n",
      "[10/25][480/9765] Loss_D: 0.1172 Loss_G: 0.0398 Convergence: 0.1256 k= 0.022582 lr = 0.0000194\n",
      "[10/25][490/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0994 k= 0.022576 lr = 0.0000194\n",
      "[10/25][500/9765] Loss_D: 0.1030 Loss_G: 0.0411 Convergence: 0.1044 k= 0.022575 lr = 0.0000194\n",
      "[10/25][510/9765] Loss_D: 0.1005 Loss_G: 0.0435 Convergence: 0.1044 k= 0.022567 lr = 0.0000194\n",
      "[10/25][520/9765] Loss_D: 0.1008 Loss_G: 0.0385 Convergence: 0.1038 k= 0.022564 lr = 0.0000194\n",
      "[10/25][530/9765] Loss_D: 0.0901 Loss_G: 0.0385 Convergence: 0.0931 k= 0.022561 lr = 0.0000194\n",
      "[10/25][540/9765] Loss_D: 0.1072 Loss_G: 0.0401 Convergence: 0.1112 k= 0.022562 lr = 0.0000194\n",
      "[10/25][550/9765] Loss_D: 0.0991 Loss_G: 0.0400 Convergence: 0.1000 k= 0.022549 lr = 0.0000194\n",
      "[10/25][560/9765] Loss_D: 0.0937 Loss_G: 0.0383 Convergence: 0.0951 k= 0.022544 lr = 0.0000194\n",
      "[10/25][570/9765] Loss_D: 0.1004 Loss_G: 0.0369 Convergence: 0.1048 k= 0.022557 lr = 0.0000194\n",
      "[10/25][580/9765] Loss_D: 0.1023 Loss_G: 0.0435 Convergence: 0.1054 k= 0.022559 lr = 0.0000194\n",
      "[10/25][590/9765] Loss_D: 0.0995 Loss_G: 0.0404 Convergence: 0.1006 k= 0.022524 lr = 0.0000194\n",
      "[10/25][600/9765] Loss_D: 0.0973 Loss_G: 0.0398 Convergence: 0.0987 k= 0.022505 lr = 0.0000194\n",
      "[10/25][610/9765] Loss_D: 0.0976 Loss_G: 0.0375 Convergence: 0.1003 k= 0.022527 lr = 0.0000194\n",
      "[10/25][620/9765] Loss_D: 0.0966 Loss_G: 0.0401 Convergence: 0.0986 k= 0.022552 lr = 0.0000194\n",
      "[10/25][630/9765] Loss_D: 0.0997 Loss_G: 0.0418 Convergence: 0.1021 k= 0.022531 lr = 0.0000194\n",
      "[10/25][640/9765] Loss_D: 0.0994 Loss_G: 0.0421 Convergence: 0.1022 k= 0.022513 lr = 0.0000194\n",
      "[10/25][650/9765] Loss_D: 0.1032 Loss_G: 0.0393 Convergence: 0.1063 k= 0.022527 lr = 0.0000194\n",
      "[10/25][660/9765] Loss_D: 0.1072 Loss_G: 0.0388 Convergence: 0.1125 k= 0.022538 lr = 0.0000194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][670/9765] Loss_D: 0.0914 Loss_G: 0.0386 Convergence: 0.0940 k= 0.022533 lr = 0.0000194\n",
      "[10/25][680/9765] Loss_D: 0.1049 Loss_G: 0.0346 Convergence: 0.1134 k= 0.022537 lr = 0.0000194\n",
      "[10/25][690/9765] Loss_D: 0.0884 Loss_G: 0.0386 Convergence: 0.0922 k= 0.022550 lr = 0.0000194\n",
      "[10/25][700/9765] Loss_D: 0.0903 Loss_G: 0.0373 Convergence: 0.0920 k= 0.022556 lr = 0.0000194\n",
      "[10/25][710/9765] Loss_D: 0.0888 Loss_G: 0.0402 Convergence: 0.0941 k= 0.022545 lr = 0.0000194\n",
      "[10/25][720/9765] Loss_D: 0.1000 Loss_G: 0.0376 Convergence: 0.1037 k= 0.022549 lr = 0.0000194\n",
      "[10/25][730/9765] Loss_D: 0.1003 Loss_G: 0.0393 Convergence: 0.1024 k= 0.022553 lr = 0.0000194\n",
      "[10/25][740/9765] Loss_D: 0.0877 Loss_G: 0.0379 Convergence: 0.0911 k= 0.022552 lr = 0.0000194\n",
      "[10/25][750/9765] Loss_D: 0.0937 Loss_G: 0.0367 Convergence: 0.0956 k= 0.022573 lr = 0.0000194\n",
      "[10/25][760/9765] Loss_D: 0.1055 Loss_G: 0.0406 Convergence: 0.1083 k= 0.022565 lr = 0.0000194\n",
      "[10/25][770/9765] Loss_D: 0.0993 Loss_G: 0.0399 Convergence: 0.1004 k= 0.022574 lr = 0.0000194\n",
      "[10/25][780/9765] Loss_D: 0.1021 Loss_G: 0.0426 Convergence: 0.1044 k= 0.022554 lr = 0.0000194\n",
      "[10/25][790/9765] Loss_D: 0.0961 Loss_G: 0.0405 Convergence: 0.0987 k= 0.022544 lr = 0.0000194\n",
      "[10/25][800/9765] Loss_D: 0.0960 Loss_G: 0.0408 Convergence: 0.0989 k= 0.022537 lr = 0.0000194\n",
      "[10/25][810/9765] Loss_D: 0.1014 Loss_G: 0.0417 Convergence: 0.1031 k= 0.022518 lr = 0.0000194\n",
      "[10/25][820/9765] Loss_D: 0.0975 Loss_G: 0.0406 Convergence: 0.0996 k= 0.022504 lr = 0.0000194\n",
      "[10/25][830/9765] Loss_D: 0.0979 Loss_G: 0.0395 Convergence: 0.0988 k= 0.022502 lr = 0.0000194\n",
      "[10/25][840/9765] Loss_D: 0.1062 Loss_G: 0.0385 Convergence: 0.1114 k= 0.022517 lr = 0.0000194\n",
      "[10/25][850/9765] Loss_D: 0.1021 Loss_G: 0.0408 Convergence: 0.1035 k= 0.022506 lr = 0.0000194\n",
      "[10/25][860/9765] Loss_D: 0.0946 Loss_G: 0.0391 Convergence: 0.0964 k= 0.022495 lr = 0.0000194\n",
      "[10/25][870/9765] Loss_D: 0.0999 Loss_G: 0.0418 Convergence: 0.1024 k= 0.022487 lr = 0.0000194\n",
      "[10/25][880/9765] Loss_D: 0.1028 Loss_G: 0.0414 Convergence: 0.1038 k= 0.022459 lr = 0.0000194\n",
      "[10/25][890/9765] Loss_D: 0.1021 Loss_G: 0.0365 Convergence: 0.1075 k= 0.022450 lr = 0.0000194\n",
      "[10/25][900/9765] Loss_D: 0.1086 Loss_G: 0.0374 Convergence: 0.1157 k= 0.022482 lr = 0.0000194\n",
      "[10/25][910/9765] Loss_D: 0.0973 Loss_G: 0.0403 Convergence: 0.0993 k= 0.022500 lr = 0.0000194\n",
      "[10/25][920/9765] Loss_D: 0.1038 Loss_G: 0.0425 Convergence: 0.1054 k= 0.022470 lr = 0.0000194\n",
      "[10/25][930/9765] Loss_D: 0.0998 Loss_G: 0.0390 Convergence: 0.1019 k= 0.022447 lr = 0.0000194\n",
      "[10/25][940/9765] Loss_D: 0.0937 Loss_G: 0.0378 Convergence: 0.0946 k= 0.022448 lr = 0.0000194\n",
      "[10/25][950/9765] Loss_D: 0.0996 Loss_G: 0.0396 Convergence: 0.1011 k= 0.022436 lr = 0.0000194\n",
      "[10/25][960/9765] Loss_D: 0.0927 Loss_G: 0.0364 Convergence: 0.0945 k= 0.022458 lr = 0.0000194\n",
      "[10/25][970/9765] Loss_D: 0.1009 Loss_G: 0.0379 Convergence: 0.1045 k= 0.022480 lr = 0.0000194\n",
      "[10/25][980/9765] Loss_D: 0.0974 Loss_G: 0.0400 Convergence: 0.0990 k= 0.022484 lr = 0.0000194\n",
      "[10/25][990/9765] Loss_D: 0.1039 Loss_G: 0.0402 Convergence: 0.1064 k= 0.022456 lr = 0.0000194\n",
      "[10/25][1000/9765] Loss_D: 0.0944 Loss_G: 0.0395 Convergence: 0.0967 k= 0.022443 lr = 0.0000194\n",
      "[10/25][1010/9765] Loss_D: 0.1027 Loss_G: 0.0492 Convergence: 0.1115 k= 0.022409 lr = 0.0000194\n",
      "[10/25][1020/9765] Loss_D: 0.0992 Loss_G: 0.0492 Convergence: 0.1094 k= 0.022324 lr = 0.0000194\n",
      "[10/25][1030/9765] Loss_D: 0.0991 Loss_G: 0.0366 Convergence: 0.1032 k= 0.022318 lr = 0.0000194\n",
      "[10/25][1040/9765] Loss_D: 0.1004 Loss_G: 0.0345 Convergence: 0.1072 k= 0.022373 lr = 0.0000194\n",
      "[10/25][1050/9765] Loss_D: 0.0986 Loss_G: 0.0367 Convergence: 0.1024 k= 0.022433 lr = 0.0000194\n",
      "[10/25][1060/9765] Loss_D: 0.0935 Loss_G: 0.0442 Convergence: 0.1009 k= 0.022419 lr = 0.0000194\n",
      "[10/25][1070/9765] Loss_D: 0.0956 Loss_G: 0.0433 Convergence: 0.1013 k= 0.022366 lr = 0.0000194\n",
      "[10/25][1080/9765] Loss_D: 0.0986 Loss_G: 0.0387 Convergence: 0.1007 k= 0.022346 lr = 0.0000194\n",
      "[10/25][1090/9765] Loss_D: 0.1021 Loss_G: 0.0410 Convergence: 0.1032 k= 0.022351 lr = 0.0000194\n",
      "[10/25][1100/9765] Loss_D: 0.1133 Loss_G: 0.0489 Convergence: 0.1175 k= 0.022332 lr = 0.0000194\n",
      "[10/25][1110/9765] Loss_D: 0.1046 Loss_G: 0.0405 Convergence: 0.1072 k= 0.022321 lr = 0.0000194\n",
      "[10/25][1120/9765] Loss_D: 0.1021 Loss_G: 0.0376 Convergence: 0.1065 k= 0.022326 lr = 0.0000194\n",
      "[10/25][1130/9765] Loss_D: 0.0952 Loss_G: 0.0413 Convergence: 0.0990 k= 0.022335 lr = 0.0000194\n",
      "[10/25][1140/9765] Loss_D: 0.0971 Loss_G: 0.0443 Convergence: 0.1032 k= 0.022315 lr = 0.0000194\n",
      "[10/25][1150/9765] Loss_D: 0.0958 Loss_G: 0.0401 Convergence: 0.0981 k= 0.022300 lr = 0.0000194\n",
      "[10/25][1160/9765] Loss_D: 0.0957 Loss_G: 0.0417 Convergence: 0.0997 k= 0.022310 lr = 0.0000194\n",
      "[10/25][1170/9765] Loss_D: 0.1063 Loss_G: 0.0420 Convergence: 0.1080 k= 0.022325 lr = 0.0000194\n",
      "[10/25][1180/9765] Loss_D: 0.1018 Loss_G: 0.0376 Convergence: 0.1061 k= 0.022324 lr = 0.0000194\n",
      "[10/25][1190/9765] Loss_D: 0.0906 Loss_G: 0.0391 Convergence: 0.0940 k= 0.022319 lr = 0.0000194\n",
      "[10/25][1200/9765] Loss_D: 0.0948 Loss_G: 0.0393 Convergence: 0.0967 k= 0.022330 lr = 0.0000194\n",
      "[10/25][1210/9765] Loss_D: 0.1081 Loss_G: 0.0413 Convergence: 0.1114 k= 0.022331 lr = 0.0000194\n",
      "[10/25][1220/9765] Loss_D: 0.0900 Loss_G: 0.0438 Convergence: 0.0984 k= 0.022311 lr = 0.0000194\n",
      "[10/25][1230/9765] Loss_D: 0.0921 Loss_G: 0.0371 Convergence: 0.0930 k= 0.022304 lr = 0.0000194\n",
      "[10/25][1240/9765] Loss_D: 0.0928 Loss_G: 0.0353 Convergence: 0.0958 k= 0.022315 lr = 0.0000194\n",
      "[10/25][1250/9765] Loss_D: 0.0967 Loss_G: 0.0371 Convergence: 0.0993 k= 0.022343 lr = 0.0000194\n",
      "[10/25][1260/9765] Loss_D: 0.1052 Loss_G: 0.0390 Convergence: 0.1095 k= 0.022349 lr = 0.0000194\n",
      "[10/25][1270/9765] Loss_D: 0.1022 Loss_G: 0.0387 Convergence: 0.1057 k= 0.022368 lr = 0.0000194\n",
      "[10/25][1280/9765] Loss_D: 0.1002 Loss_G: 0.0394 Convergence: 0.1021 k= 0.022368 lr = 0.0000194\n",
      "[10/25][1290/9765] Loss_D: 0.0955 Loss_G: 0.0377 Convergence: 0.0972 k= 0.022373 lr = 0.0000194\n",
      "[10/25][1300/9765] Loss_D: 0.1080 Loss_G: 0.0394 Convergence: 0.1129 k= 0.022382 lr = 0.0000194\n",
      "[10/25][1310/9765] Loss_D: 0.0973 Loss_G: 0.0379 Convergence: 0.0995 k= 0.022390 lr = 0.0000194\n",
      "[10/25][1320/9765] Loss_D: 0.1021 Loss_G: 0.0408 Convergence: 0.1034 k= 0.022382 lr = 0.0000194\n",
      "[10/25][1330/9765] Loss_D: 0.1019 Loss_G: 0.0393 Convergence: 0.1046 k= 0.022387 lr = 0.0000194\n",
      "[10/25][1340/9765] Loss_D: 0.0891 Loss_G: 0.0406 Convergence: 0.0946 k= 0.022373 lr = 0.0000194\n",
      "[10/25][1350/9765] Loss_D: 0.1005 Loss_G: 0.0445 Convergence: 0.1053 k= 0.022359 lr = 0.0000184\n",
      "[10/25][1360/9765] Loss_D: 0.0981 Loss_G: 0.0403 Convergence: 0.0998 k= 0.022350 lr = 0.0000184\n",
      "[10/25][1370/9765] Loss_D: 0.1014 Loss_G: 0.0396 Convergence: 0.1037 k= 0.022354 lr = 0.0000184\n",
      "[10/25][1380/9765] Loss_D: 0.1063 Loss_G: 0.0386 Convergence: 0.1114 k= 0.022363 lr = 0.0000184\n",
      "[10/25][1390/9765] Loss_D: 0.1087 Loss_G: 0.0368 Convergence: 0.1166 k= 0.022391 lr = 0.0000184\n",
      "[10/25][1400/9765] Loss_D: 0.1033 Loss_G: 0.0409 Convergence: 0.1051 k= 0.022414 lr = 0.0000184\n",
      "[10/25][1410/9765] Loss_D: 0.1065 Loss_G: 0.0439 Convergence: 0.1084 k= 0.022407 lr = 0.0000184\n",
      "[10/25][1420/9765] Loss_D: 0.0962 Loss_G: 0.0411 Convergence: 0.0994 k= 0.022384 lr = 0.0000184\n",
      "[10/25][1430/9765] Loss_D: 0.0894 Loss_G: 0.0359 Convergence: 0.0904 k= 0.022379 lr = 0.0000184\n",
      "[10/25][1440/9765] Loss_D: 0.0994 Loss_G: 0.0383 Convergence: 0.1021 k= 0.022399 lr = 0.0000184\n",
      "[10/25][1450/9765] Loss_D: 0.0907 Loss_G: 0.0392 Convergence: 0.0941 k= 0.022410 lr = 0.0000184\n",
      "[10/25][1460/9765] Loss_D: 0.0969 Loss_G: 0.0416 Convergence: 0.1003 k= 0.022392 lr = 0.0000184\n",
      "[10/25][1470/9765] Loss_D: 0.0952 Loss_G: 0.0440 Convergence: 0.1017 k= 0.022372 lr = 0.0000184\n",
      "[10/25][1480/9765] Loss_D: 0.1007 Loss_G: 0.0406 Convergence: 0.1017 k= 0.022342 lr = 0.0000184\n",
      "[10/25][1490/9765] Loss_D: 0.0976 Loss_G: 0.0377 Convergence: 0.1001 k= 0.022346 lr = 0.0000184\n",
      "[10/25][1500/9765] Loss_D: 0.1088 Loss_G: 0.0383 Convergence: 0.1152 k= 0.022367 lr = 0.0000184\n",
      "[10/25][1510/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1024 k= 0.022372 lr = 0.0000184\n",
      "[10/25][1520/9765] Loss_D: 0.1044 Loss_G: 0.0415 Convergence: 0.1058 k= 0.022367 lr = 0.0000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][1530/9765] Loss_D: 0.0917 Loss_G: 0.0383 Convergence: 0.0938 k= 0.022352 lr = 0.0000184\n",
      "[10/25][1540/9765] Loss_D: 0.0890 Loss_G: 0.0377 Convergence: 0.0916 k= 0.022354 lr = 0.0000184\n",
      "[10/25][1550/9765] Loss_D: 0.1071 Loss_G: 0.0382 Convergence: 0.1129 k= 0.022381 lr = 0.0000184\n",
      "[10/25][1560/9765] Loss_D: 0.1075 Loss_G: 0.0388 Convergence: 0.1129 k= 0.022399 lr = 0.0000184\n",
      "[10/25][1570/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0991 k= 0.022408 lr = 0.0000184\n",
      "[10/25][1580/9765] Loss_D: 0.0987 Loss_G: 0.0388 Convergence: 0.1005 k= 0.022403 lr = 0.0000184\n",
      "[10/25][1590/9765] Loss_D: 0.0975 Loss_G: 0.0426 Convergence: 0.1016 k= 0.022392 lr = 0.0000184\n",
      "[10/25][1600/9765] Loss_D: 0.0982 Loss_G: 0.0384 Convergence: 0.1002 k= 0.022385 lr = 0.0000184\n",
      "[10/25][1610/9765] Loss_D: 0.0938 Loss_G: 0.0416 Convergence: 0.0984 k= 0.022379 lr = 0.0000184\n",
      "[10/25][1620/9765] Loss_D: 0.0905 Loss_G: 0.0350 Convergence: 0.0928 k= 0.022401 lr = 0.0000184\n",
      "[10/25][1630/9765] Loss_D: 0.0927 Loss_G: 0.0341 Convergence: 0.0968 k= 0.022444 lr = 0.0000184\n",
      "[10/25][1640/9765] Loss_D: 0.0867 Loss_G: 0.0359 Convergence: 0.0884 k= 0.022476 lr = 0.0000184\n",
      "[10/25][1650/9765] Loss_D: 0.0976 Loss_G: 0.0405 Convergence: 0.0996 k= 0.022479 lr = 0.0000184\n",
      "[10/25][1660/9765] Loss_D: 0.0944 Loss_G: 0.0420 Convergence: 0.0992 k= 0.022465 lr = 0.0000184\n",
      "[10/25][1670/9765] Loss_D: 0.1012 Loss_G: 0.0411 Convergence: 0.1024 k= 0.022453 lr = 0.0000184\n",
      "[10/25][1680/9765] Loss_D: 0.0920 Loss_G: 0.0397 Convergence: 0.0954 k= 0.022450 lr = 0.0000184\n",
      "[10/25][1690/9765] Loss_D: 0.0956 Loss_G: 0.0387 Convergence: 0.0966 k= 0.022438 lr = 0.0000184\n",
      "[10/25][1700/9765] Loss_D: 0.1059 Loss_G: 0.0376 Convergence: 0.1118 k= 0.022462 lr = 0.0000184\n",
      "[10/25][1710/9765] Loss_D: 0.0971 Loss_G: 0.0389 Convergence: 0.0982 k= 0.022457 lr = 0.0000184\n",
      "[10/25][1720/9765] Loss_D: 0.1001 Loss_G: 0.0401 Convergence: 0.1013 k= 0.022479 lr = 0.0000184\n",
      "[10/25][1730/9765] Loss_D: 0.0909 Loss_G: 0.0396 Convergence: 0.0946 k= 0.022488 lr = 0.0000184\n",
      "[10/25][1740/9765] Loss_D: 0.1059 Loss_G: 0.0377 Convergence: 0.1117 k= 0.022492 lr = 0.0000184\n",
      "[10/25][1750/9765] Loss_D: 0.1023 Loss_G: 0.0400 Convergence: 0.1045 k= 0.022501 lr = 0.0000184\n",
      "[10/25][1760/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0993 k= 0.022498 lr = 0.0000184\n",
      "[10/25][1770/9765] Loss_D: 0.0937 Loss_G: 0.0383 Convergence: 0.0951 k= 0.022500 lr = 0.0000184\n",
      "[10/25][1780/9765] Loss_D: 0.0997 Loss_G: 0.0379 Convergence: 0.1028 k= 0.022507 lr = 0.0000184\n",
      "[10/25][1790/9765] Loss_D: 0.1016 Loss_G: 0.0413 Convergence: 0.1028 k= 0.022496 lr = 0.0000184\n",
      "[10/25][1800/9765] Loss_D: 0.1003 Loss_G: 0.0392 Convergence: 0.1025 k= 0.022492 lr = 0.0000184\n",
      "[10/25][1810/9765] Loss_D: 0.0923 Loss_G: 0.0394 Convergence: 0.0953 k= 0.022490 lr = 0.0000184\n",
      "[10/25][1820/9765] Loss_D: 0.1029 Loss_G: 0.0381 Convergence: 0.1071 k= 0.022498 lr = 0.0000184\n",
      "[10/25][1830/9765] Loss_D: 0.0927 Loss_G: 0.0397 Convergence: 0.0958 k= 0.022526 lr = 0.0000184\n",
      "[10/25][1840/9765] Loss_D: 0.0901 Loss_G: 0.0399 Convergence: 0.0945 k= 0.022526 lr = 0.0000184\n",
      "[10/25][1850/9765] Loss_D: 0.1052 Loss_G: 0.0395 Convergence: 0.1090 k= 0.022532 lr = 0.0000184\n",
      "[10/25][1860/9765] Loss_D: 0.0919 Loss_G: 0.0411 Convergence: 0.0967 k= 0.022511 lr = 0.0000184\n",
      "[10/25][1870/9765] Loss_D: 0.1027 Loss_G: 0.0405 Convergence: 0.1044 k= 0.022515 lr = 0.0000184\n",
      "[10/25][1880/9765] Loss_D: 0.0967 Loss_G: 0.0354 Convergence: 0.1011 k= 0.022514 lr = 0.0000184\n",
      "[10/25][1890/9765] Loss_D: 0.0832 Loss_G: 0.0376 Convergence: 0.0880 k= 0.022543 lr = 0.0000184\n",
      "[10/25][1900/9765] Loss_D: 0.0935 Loss_G: 0.0364 Convergence: 0.0957 k= 0.022553 lr = 0.0000184\n",
      "[10/25][1910/9765] Loss_D: 0.0950 Loss_G: 0.0389 Convergence: 0.0965 k= 0.022555 lr = 0.0000184\n",
      "[10/25][1920/9765] Loss_D: 0.0979 Loss_G: 0.0374 Convergence: 0.1008 k= 0.022566 lr = 0.0000184\n",
      "[10/25][1930/9765] Loss_D: 0.0915 Loss_G: 0.0379 Convergence: 0.0933 k= 0.022552 lr = 0.0000184\n",
      "[10/25][1940/9765] Loss_D: 0.0976 Loss_G: 0.0392 Convergence: 0.0986 k= 0.022565 lr = 0.0000184\n",
      "[10/25][1950/9765] Loss_D: 0.0992 Loss_G: 0.0370 Convergence: 0.1031 k= 0.022602 lr = 0.0000184\n",
      "[10/25][1960/9765] Loss_D: 0.1023 Loss_G: 0.0413 Convergence: 0.1033 k= 0.022605 lr = 0.0000184\n",
      "[10/25][1970/9765] Loss_D: 0.1019 Loss_G: 0.0426 Convergence: 0.1043 k= 0.022616 lr = 0.0000184\n",
      "[10/25][1980/9765] Loss_D: 0.1007 Loss_G: 0.0403 Convergence: 0.1019 k= 0.022590 lr = 0.0000184\n",
      "[10/25][1990/9765] Loss_D: 0.1089 Loss_G: 0.0385 Convergence: 0.1151 k= 0.022584 lr = 0.0000184\n",
      "[10/25][2000/9765] Loss_D: 0.0987 Loss_G: 0.0378 Convergence: 0.1017 k= 0.022609 lr = 0.0000184\n",
      "[10/25][2010/9765] Loss_D: 0.0877 Loss_G: 0.0366 Convergence: 0.0897 k= 0.022633 lr = 0.0000184\n",
      "[10/25][2020/9765] Loss_D: 0.0885 Loss_G: 0.0378 Convergence: 0.0914 k= 0.022646 lr = 0.0000184\n",
      "[10/25][2030/9765] Loss_D: 0.0988 Loss_G: 0.0401 Convergence: 0.0999 k= 0.022647 lr = 0.0000184\n",
      "[10/25][2040/9765] Loss_D: 0.0941 Loss_G: 0.0440 Convergence: 0.1010 k= 0.022630 lr = 0.0000184\n",
      "[10/25][2050/9765] Loss_D: 0.0965 Loss_G: 0.0392 Convergence: 0.0977 k= 0.022601 lr = 0.0000184\n",
      "[10/25][2060/9765] Loss_D: 0.0999 Loss_G: 0.0371 Convergence: 0.1038 k= 0.022615 lr = 0.0000184\n",
      "[10/25][2070/9765] Loss_D: 0.0919 Loss_G: 0.0370 Convergence: 0.0929 k= 0.022651 lr = 0.0000184\n",
      "[10/25][2080/9765] Loss_D: 0.0880 Loss_G: 0.0368 Convergence: 0.0902 k= 0.022682 lr = 0.0000184\n",
      "[10/25][2090/9765] Loss_D: 0.1052 Loss_G: 0.0443 Convergence: 0.1080 k= 0.022664 lr = 0.0000184\n",
      "[10/25][2100/9765] Loss_D: 0.0943 Loss_G: 0.0406 Convergence: 0.0978 k= 0.022626 lr = 0.0000184\n",
      "[10/25][2110/9765] Loss_D: 0.0926 Loss_G: 0.0432 Convergence: 0.0993 k= 0.022619 lr = 0.0000184\n",
      "[10/25][2120/9765] Loss_D: 0.1002 Loss_G: 0.0352 Convergence: 0.1063 k= 0.022633 lr = 0.0000184\n",
      "[10/25][2130/9765] Loss_D: 0.0905 Loss_G: 0.0390 Convergence: 0.0939 k= 0.022653 lr = 0.0000184\n",
      "[10/25][2140/9765] Loss_D: 0.1041 Loss_G: 0.0423 Convergence: 0.1053 k= 0.022634 lr = 0.0000184\n",
      "[10/25][2150/9765] Loss_D: 0.1029 Loss_G: 0.0379 Convergence: 0.1074 k= 0.022628 lr = 0.0000184\n",
      "[10/25][2160/9765] Loss_D: 0.0856 Loss_G: 0.0384 Convergence: 0.0902 k= 0.022639 lr = 0.0000184\n",
      "[10/25][2170/9765] Loss_D: 0.0976 Loss_G: 0.0387 Convergence: 0.0992 k= 0.022640 lr = 0.0000184\n",
      "[10/25][2180/9765] Loss_D: 0.0937 Loss_G: 0.0374 Convergence: 0.0949 k= 0.022648 lr = 0.0000184\n",
      "[10/25][2190/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.0998 k= 0.022648 lr = 0.0000184\n",
      "[10/25][2200/9765] Loss_D: 0.0914 Loss_G: 0.0407 Convergence: 0.0961 k= 0.022666 lr = 0.0000184\n",
      "[10/25][2210/9765] Loss_D: 0.1082 Loss_G: 0.0392 Convergence: 0.1135 k= 0.022672 lr = 0.0000184\n",
      "[10/25][2220/9765] Loss_D: 0.1041 Loss_G: 0.0383 Convergence: 0.1087 k= 0.022694 lr = 0.0000184\n",
      "[10/25][2230/9765] Loss_D: 0.1000 Loss_G: 0.0417 Convergence: 0.1023 k= 0.022703 lr = 0.0000184\n",
      "[10/25][2240/9765] Loss_D: 0.0973 Loss_G: 0.0403 Convergence: 0.0993 k= 0.022687 lr = 0.0000184\n",
      "[10/25][2250/9765] Loss_D: 0.1055 Loss_G: 0.0397 Convergence: 0.1093 k= 0.022697 lr = 0.0000184\n",
      "[10/25][2260/9765] Loss_D: 0.0936 Loss_G: 0.0419 Convergence: 0.0987 k= 0.022687 lr = 0.0000184\n",
      "[10/25][2270/9765] Loss_D: 0.0918 Loss_G: 0.0405 Convergence: 0.0961 k= 0.022651 lr = 0.0000184\n",
      "[10/25][2280/9765] Loss_D: 0.0880 Loss_G: 0.0394 Convergence: 0.0927 k= 0.022649 lr = 0.0000184\n",
      "[10/25][2290/9765] Loss_D: 0.0928 Loss_G: 0.0409 Convergence: 0.0971 k= 0.022632 lr = 0.0000184\n",
      "[10/25][2300/9765] Loss_D: 0.0967 Loss_G: 0.0372 Convergence: 0.0994 k= 0.022636 lr = 0.0000184\n",
      "[10/25][2310/9765] Loss_D: 0.0964 Loss_G: 0.0393 Convergence: 0.0977 k= 0.022651 lr = 0.0000184\n",
      "[10/25][2320/9765] Loss_D: 0.0972 Loss_G: 0.0402 Convergence: 0.0990 k= 0.022659 lr = 0.0000184\n",
      "[10/25][2330/9765] Loss_D: 0.0925 Loss_G: 0.0380 Convergence: 0.0940 k= 0.022663 lr = 0.0000184\n",
      "[10/25][2340/9765] Loss_D: 0.1001 Loss_G: 0.0417 Convergence: 0.1023 k= 0.022674 lr = 0.0000184\n",
      "[10/25][2350/9765] Loss_D: 0.0909 Loss_G: 0.0406 Convergence: 0.0957 k= 0.022645 lr = 0.0000184\n",
      "[10/25][2360/9765] Loss_D: 0.1098 Loss_G: 0.0395 Convergence: 0.1155 k= 0.022642 lr = 0.0000184\n",
      "[10/25][2370/9765] Loss_D: 0.0846 Loss_G: 0.0359 Convergence: 0.0872 k= 0.022639 lr = 0.0000184\n",
      "[10/25][2380/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0995 k= 0.022655 lr = 0.0000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][2390/9765] Loss_D: 0.0977 Loss_G: 0.0421 Convergence: 0.1013 k= 0.022665 lr = 0.0000184\n",
      "[10/25][2400/9765] Loss_D: 0.0995 Loss_G: 0.0376 Convergence: 0.1030 k= 0.022656 lr = 0.0000184\n",
      "[10/25][2410/9765] Loss_D: 0.0957 Loss_G: 0.0387 Convergence: 0.0966 k= 0.022640 lr = 0.0000184\n",
      "[10/25][2420/9765] Loss_D: 0.0964 Loss_G: 0.0365 Convergence: 0.0996 k= 0.022650 lr = 0.0000184\n",
      "[10/25][2430/9765] Loss_D: 0.1053 Loss_G: 0.0382 Convergence: 0.1104 k= 0.022661 lr = 0.0000184\n",
      "[10/25][2440/9765] Loss_D: 0.1078 Loss_G: 0.0431 Convergence: 0.1092 k= 0.022666 lr = 0.0000184\n",
      "[10/25][2450/9765] Loss_D: 0.0994 Loss_G: 0.0411 Convergence: 0.1013 k= 0.022670 lr = 0.0000184\n",
      "[10/25][2460/9765] Loss_D: 0.0914 Loss_G: 0.0425 Convergence: 0.0979 k= 0.022655 lr = 0.0000184\n",
      "[10/25][2470/9765] Loss_D: 0.0969 Loss_G: 0.0411 Convergence: 0.0998 k= 0.022634 lr = 0.0000184\n",
      "[10/25][2480/9765] Loss_D: 0.1048 Loss_G: 0.0420 Convergence: 0.1061 k= 0.022608 lr = 0.0000184\n",
      "[10/25][2490/9765] Loss_D: 0.0967 Loss_G: 0.0389 Convergence: 0.0978 k= 0.022599 lr = 0.0000184\n",
      "[10/25][2500/9765] Loss_D: 0.0970 Loss_G: 0.0402 Convergence: 0.0989 k= 0.022614 lr = 0.0000184\n",
      "[10/25][2510/9765] Loss_D: 0.0952 Loss_G: 0.0377 Convergence: 0.0968 k= 0.022627 lr = 0.0000184\n",
      "[10/25][2520/9765] Loss_D: 0.0860 Loss_G: 0.0354 Convergence: 0.0875 k= 0.022637 lr = 0.0000184\n",
      "[10/25][2530/9765] Loss_D: 0.0969 Loss_G: 0.0386 Convergence: 0.0983 k= 0.022663 lr = 0.0000184\n",
      "[10/25][2540/9765] Loss_D: 0.0920 Loss_G: 0.0408 Convergence: 0.0965 k= 0.022642 lr = 0.0000184\n",
      "[10/25][2550/9765] Loss_D: 0.0950 Loss_G: 0.0416 Convergence: 0.0992 k= 0.022627 lr = 0.0000184\n",
      "[10/25][2560/9765] Loss_D: 0.0905 Loss_G: 0.0388 Convergence: 0.0936 k= 0.022613 lr = 0.0000184\n",
      "[10/25][2570/9765] Loss_D: 0.1099 Loss_G: 0.0392 Convergence: 0.1159 k= 0.022615 lr = 0.0000184\n",
      "[10/25][2580/9765] Loss_D: 0.0932 Loss_G: 0.0399 Convergence: 0.0964 k= 0.022606 lr = 0.0000184\n",
      "[10/25][2590/9765] Loss_D: 0.0906 Loss_G: 0.0392 Convergence: 0.0942 k= 0.022597 lr = 0.0000184\n",
      "[10/25][2600/9765] Loss_D: 0.0960 Loss_G: 0.0384 Convergence: 0.0973 k= 0.022610 lr = 0.0000184\n",
      "[10/25][2610/9765] Loss_D: 0.0869 Loss_G: 0.0383 Convergence: 0.0909 k= 0.022606 lr = 0.0000184\n",
      "[10/25][2620/9765] Loss_D: 0.1054 Loss_G: 0.0393 Convergence: 0.1095 k= 0.022613 lr = 0.0000184\n",
      "[10/25][2630/9765] Loss_D: 0.1089 Loss_G: 0.0412 Convergence: 0.1124 k= 0.022608 lr = 0.0000184\n",
      "[10/25][2640/9765] Loss_D: 0.0995 Loss_G: 0.0392 Convergence: 0.1013 k= 0.022600 lr = 0.0000184\n",
      "[10/25][2650/9765] Loss_D: 0.0934 Loss_G: 0.0373 Convergence: 0.0947 k= 0.022605 lr = 0.0000184\n",
      "[10/25][2660/9765] Loss_D: 0.1071 Loss_G: 0.0369 Convergence: 0.1143 k= 0.022639 lr = 0.0000184\n",
      "[10/25][2670/9765] Loss_D: 0.0967 Loss_G: 0.0393 Convergence: 0.0979 k= 0.022660 lr = 0.0000184\n",
      "[10/25][2680/9765] Loss_D: 0.0987 Loss_G: 0.0453 Convergence: 0.1051 k= 0.022632 lr = 0.0000184\n",
      "[10/25][2690/9765] Loss_D: 0.0979 Loss_G: 0.0412 Convergence: 0.1005 k= 0.022593 lr = 0.0000184\n",
      "[10/25][2700/9765] Loss_D: 0.0973 Loss_G: 0.0396 Convergence: 0.0986 k= 0.022586 lr = 0.0000184\n",
      "[10/25][2710/9765] Loss_D: 0.0998 Loss_G: 0.0350 Convergence: 0.1058 k= 0.022608 lr = 0.0000184\n",
      "[10/25][2720/9765] Loss_D: 0.0933 Loss_G: 0.0352 Convergence: 0.0965 k= 0.022659 lr = 0.0000184\n",
      "[10/25][2730/9765] Loss_D: 0.0970 Loss_G: 0.0463 Convergence: 0.1050 k= 0.022653 lr = 0.0000184\n",
      "[10/25][2740/9765] Loss_D: 0.0994 Loss_G: 0.0481 Convergence: 0.1083 k= 0.022591 lr = 0.0000184\n",
      "[10/25][2750/9765] Loss_D: 0.0971 Loss_G: 0.0413 Convergence: 0.1001 k= 0.022561 lr = 0.0000184\n",
      "[10/25][2760/9765] Loss_D: 0.0881 Loss_G: 0.0404 Convergence: 0.0938 k= 0.022541 lr = 0.0000184\n",
      "[10/25][2770/9765] Loss_D: 0.0888 Loss_G: 0.0390 Convergence: 0.0928 k= 0.022536 lr = 0.0000184\n",
      "[10/25][2780/9765] Loss_D: 0.1000 Loss_G: 0.0409 Convergence: 0.1014 k= 0.022546 lr = 0.0000184\n",
      "[10/25][2790/9765] Loss_D: 0.0997 Loss_G: 0.0415 Convergence: 0.1019 k= 0.022557 lr = 0.0000184\n",
      "[10/25][2800/9765] Loss_D: 0.0963 Loss_G: 0.0383 Convergence: 0.0978 k= 0.022576 lr = 0.0000184\n",
      "[10/25][2810/9765] Loss_D: 0.0995 Loss_G: 0.0424 Convergence: 0.1027 k= 0.022569 lr = 0.0000184\n",
      "[10/25][2820/9765] Loss_D: 0.1018 Loss_G: 0.0361 Convergence: 0.1076 k= 0.022563 lr = 0.0000184\n",
      "[10/25][2830/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0956 k= 0.022557 lr = 0.0000184\n",
      "[10/25][2840/9765] Loss_D: 0.1038 Loss_G: 0.0371 Convergence: 0.1093 k= 0.022558 lr = 0.0000184\n",
      "[10/25][2850/9765] Loss_D: 0.0952 Loss_G: 0.0369 Convergence: 0.0975 k= 0.022568 lr = 0.0000184\n",
      "[10/25][2860/9765] Loss_D: 0.1011 Loss_G: 0.0416 Convergence: 0.1028 k= 0.022576 lr = 0.0000184\n",
      "[10/25][2870/9765] Loss_D: 0.0911 Loss_G: 0.0413 Convergence: 0.0966 k= 0.022551 lr = 0.0000184\n",
      "[10/25][2880/9765] Loss_D: 0.1061 Loss_G: 0.0360 Convergence: 0.1137 k= 0.022576 lr = 0.0000184\n",
      "[10/25][2890/9765] Loss_D: 0.0884 Loss_G: 0.0387 Convergence: 0.0922 k= 0.022589 lr = 0.0000184\n",
      "[10/25][2900/9765] Loss_D: 0.0941 Loss_G: 0.0419 Convergence: 0.0989 k= 0.022584 lr = 0.0000184\n",
      "[10/25][2910/9765] Loss_D: 0.0915 Loss_G: 0.0369 Convergence: 0.0924 k= 0.022584 lr = 0.0000184\n",
      "[10/25][2920/9765] Loss_D: 0.0883 Loss_G: 0.0379 Convergence: 0.0915 k= 0.022585 lr = 0.0000184\n",
      "[10/25][2930/9765] Loss_D: 0.0964 Loss_G: 0.0416 Convergence: 0.0999 k= 0.022591 lr = 0.0000184\n",
      "[10/25][2940/9765] Loss_D: 0.0974 Loss_G: 0.0375 Convergence: 0.1001 k= 0.022595 lr = 0.0000184\n",
      "[10/25][2950/9765] Loss_D: 0.0874 Loss_G: 0.0383 Convergence: 0.0913 k= 0.022613 lr = 0.0000184\n",
      "[10/25][2960/9765] Loss_D: 0.1016 Loss_G: 0.0393 Convergence: 0.1043 k= 0.022617 lr = 0.0000184\n",
      "[10/25][2970/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1007 k= 0.022617 lr = 0.0000184\n",
      "[10/25][2980/9765] Loss_D: 0.0975 Loss_G: 0.0381 Convergence: 0.0996 k= 0.022629 lr = 0.0000184\n",
      "[10/25][2990/9765] Loss_D: 0.0928 Loss_G: 0.0361 Convergence: 0.0950 k= 0.022651 lr = 0.0000184\n",
      "[10/25][3000/9765] Loss_D: 0.0936 Loss_G: 0.0358 Convergence: 0.0964 k= 0.022671 lr = 0.0000184\n",
      "[10/25][3010/9765] Loss_D: 0.0920 Loss_G: 0.0434 Convergence: 0.0992 k= 0.022686 lr = 0.0000184\n",
      "[10/25][3020/9765] Loss_D: 0.0945 Loss_G: 0.0403 Convergence: 0.0975 k= 0.022671 lr = 0.0000184\n",
      "[10/25][3030/9765] Loss_D: 0.0992 Loss_G: 0.0404 Convergence: 0.1004 k= 0.022663 lr = 0.0000184\n",
      "[10/25][3040/9765] Loss_D: 0.0912 Loss_G: 0.0388 Convergence: 0.0940 k= 0.022670 lr = 0.0000184\n",
      "[10/25][3050/9765] Loss_D: 0.0961 Loss_G: 0.0400 Convergence: 0.0982 k= 0.022670 lr = 0.0000184\n",
      "[10/25][3060/9765] Loss_D: 0.0918 Loss_G: 0.0434 Convergence: 0.0990 k= 0.022645 lr = 0.0000184\n",
      "[10/25][3070/9765] Loss_D: 0.0929 Loss_G: 0.0396 Convergence: 0.0959 k= 0.022631 lr = 0.0000184\n",
      "[10/25][3080/9765] Loss_D: 0.0971 Loss_G: 0.0387 Convergence: 0.0985 k= 0.022633 lr = 0.0000184\n",
      "[10/25][3090/9765] Loss_D: 0.0986 Loss_G: 0.0408 Convergence: 0.1005 k= 0.022637 lr = 0.0000184\n",
      "[10/25][3100/9765] Loss_D: 0.0950 Loss_G: 0.0428 Convergence: 0.1003 k= 0.022623 lr = 0.0000184\n",
      "[10/25][3110/9765] Loss_D: 0.0933 Loss_G: 0.0378 Convergence: 0.0942 k= 0.022623 lr = 0.0000184\n",
      "[10/25][3120/9765] Loss_D: 0.1094 Loss_G: 0.0382 Convergence: 0.1162 k= 0.022635 lr = 0.0000184\n",
      "[10/25][3130/9765] Loss_D: 0.1056 Loss_G: 0.0427 Convergence: 0.1066 k= 0.022627 lr = 0.0000184\n",
      "[10/25][3140/9765] Loss_D: 0.0955 Loss_G: 0.0398 Convergence: 0.0976 k= 0.022606 lr = 0.0000184\n",
      "[10/25][3150/9765] Loss_D: 0.0983 Loss_G: 0.0395 Convergence: 0.0993 k= 0.022594 lr = 0.0000184\n",
      "[10/25][3160/9765] Loss_D: 0.0926 Loss_G: 0.0406 Convergence: 0.0967 k= 0.022601 lr = 0.0000184\n",
      "[10/25][3170/9765] Loss_D: 0.0947 Loss_G: 0.0372 Convergence: 0.0965 k= 0.022641 lr = 0.0000184\n",
      "[10/25][3180/9765] Loss_D: 0.0886 Loss_G: 0.0425 Convergence: 0.0963 k= 0.022647 lr = 0.0000184\n",
      "[10/25][3190/9765] Loss_D: 0.0877 Loss_G: 0.0391 Convergence: 0.0923 k= 0.022644 lr = 0.0000184\n",
      "[10/25][3200/9765] Loss_D: 0.1004 Loss_G: 0.0425 Convergence: 0.1033 k= 0.022630 lr = 0.0000184\n",
      "[10/25][3210/9765] Loss_D: 0.0979 Loss_G: 0.0401 Convergence: 0.0994 k= 0.022617 lr = 0.0000184\n",
      "[10/25][3220/9765] Loss_D: 0.0956 Loss_G: 0.0394 Convergence: 0.0973 k= 0.022603 lr = 0.0000184\n",
      "[10/25][3230/9765] Loss_D: 0.1038 Loss_G: 0.0374 Convergence: 0.1090 k= 0.022622 lr = 0.0000184\n",
      "[10/25][3240/9765] Loss_D: 0.0962 Loss_G: 0.0394 Convergence: 0.0977 k= 0.022623 lr = 0.0000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][3250/9765] Loss_D: 0.0985 Loss_G: 0.0422 Convergence: 0.1019 k= 0.022605 lr = 0.0000184\n",
      "[10/25][3260/9765] Loss_D: 0.1028 Loss_G: 0.0395 Convergence: 0.1058 k= 0.022575 lr = 0.0000184\n",
      "[10/25][3270/9765] Loss_D: 0.0979 Loss_G: 0.0378 Convergence: 0.1005 k= 0.022570 lr = 0.0000184\n",
      "[10/25][3280/9765] Loss_D: 0.1018 Loss_G: 0.0427 Convergence: 0.1044 k= 0.022558 lr = 0.0000184\n",
      "[10/25][3290/9765] Loss_D: 0.0969 Loss_G: 0.0375 Convergence: 0.0993 k= 0.022567 lr = 0.0000184\n",
      "[10/25][3300/9765] Loss_D: 0.1038 Loss_G: 0.0396 Convergence: 0.1070 k= 0.022579 lr = 0.0000184\n",
      "[10/25][3310/9765] Loss_D: 0.0986 Loss_G: 0.0392 Convergence: 0.1002 k= 0.022581 lr = 0.0000184\n",
      "[10/25][3320/9765] Loss_D: 0.0954 Loss_G: 0.0427 Convergence: 0.1006 k= 0.022556 lr = 0.0000184\n",
      "[10/25][3330/9765] Loss_D: 0.1067 Loss_G: 0.0367 Convergence: 0.1139 k= 0.022560 lr = 0.0000184\n",
      "[10/25][3340/9765] Loss_D: 0.0977 Loss_G: 0.0333 Convergence: 0.1045 k= 0.022603 lr = 0.0000184\n",
      "[10/25][3350/9765] Loss_D: 0.0928 Loss_G: 0.0387 Convergence: 0.0950 k= 0.022612 lr = 0.0000184\n",
      "[10/25][3360/9765] Loss_D: 0.0921 Loss_G: 0.0432 Convergence: 0.0990 k= 0.022600 lr = 0.0000184\n",
      "[10/25][3370/9765] Loss_D: 0.0974 Loss_G: 0.0389 Convergence: 0.0987 k= 0.022598 lr = 0.0000184\n",
      "[10/25][3380/9765] Loss_D: 0.0948 Loss_G: 0.0367 Convergence: 0.0971 k= 0.022627 lr = 0.0000184\n",
      "[10/25][3390/9765] Loss_D: 0.0939 Loss_G: 0.0383 Convergence: 0.0951 k= 0.022626 lr = 0.0000184\n",
      "[10/25][3400/9765] Loss_D: 0.0910 Loss_G: 0.0368 Convergence: 0.0919 k= 0.022630 lr = 0.0000184\n",
      "[10/25][3410/9765] Loss_D: 0.1032 Loss_G: 0.0362 Convergence: 0.1094 k= 0.022654 lr = 0.0000184\n",
      "[10/25][3420/9765] Loss_D: 0.0932 Loss_G: 0.0393 Convergence: 0.0957 k= 0.022666 lr = 0.0000184\n",
      "[10/25][3430/9765] Loss_D: 0.0976 Loss_G: 0.0434 Convergence: 0.1025 k= 0.022662 lr = 0.0000184\n",
      "[10/25][3440/9765] Loss_D: 0.1073 Loss_G: 0.0402 Convergence: 0.1112 k= 0.022650 lr = 0.0000184\n",
      "[10/25][3450/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0979 k= 0.022643 lr = 0.0000184\n",
      "[10/25][3460/9765] Loss_D: 0.0937 Loss_G: 0.0401 Convergence: 0.0969 k= 0.022636 lr = 0.0000184\n",
      "[10/25][3470/9765] Loss_D: 0.1006 Loss_G: 0.0412 Convergence: 0.1021 k= 0.022619 lr = 0.0000184\n",
      "[10/25][3480/9765] Loss_D: 0.1148 Loss_G: 0.0393 Convergence: 0.1226 k= 0.022621 lr = 0.0000184\n",
      "[10/25][3490/9765] Loss_D: 0.1013 Loss_G: 0.0392 Convergence: 0.1039 k= 0.022630 lr = 0.0000184\n",
      "[10/25][3500/9765] Loss_D: 0.0893 Loss_G: 0.0378 Convergence: 0.0919 k= 0.022618 lr = 0.0000184\n",
      "[10/25][3510/9765] Loss_D: 0.0986 Loss_G: 0.0393 Convergence: 0.0999 k= 0.022617 lr = 0.0000184\n",
      "[10/25][3520/9765] Loss_D: 0.0999 Loss_G: 0.0377 Convergence: 0.1034 k= 0.022610 lr = 0.0000184\n",
      "[10/25][3530/9765] Loss_D: 0.1003 Loss_G: 0.0367 Convergence: 0.1050 k= 0.022636 lr = 0.0000184\n",
      "[10/25][3540/9765] Loss_D: 0.0991 Loss_G: 0.0398 Convergence: 0.1002 k= 0.022621 lr = 0.0000184\n",
      "[10/25][3550/9765] Loss_D: 0.0987 Loss_G: 0.0417 Convergence: 0.1014 k= 0.022591 lr = 0.0000184\n",
      "[10/25][3560/9765] Loss_D: 0.0912 Loss_G: 0.0414 Convergence: 0.0967 k= 0.022560 lr = 0.0000184\n",
      "[10/25][3570/9765] Loss_D: 0.0963 Loss_G: 0.0417 Convergence: 0.1001 k= 0.022552 lr = 0.0000184\n",
      "[10/25][3580/9765] Loss_D: 0.1059 Loss_G: 0.0400 Convergence: 0.1095 k= 0.022545 lr = 0.0000184\n",
      "[10/25][3590/9765] Loss_D: 0.1009 Loss_G: 0.0391 Convergence: 0.1034 k= 0.022535 lr = 0.0000184\n",
      "[10/25][3600/9765] Loss_D: 0.0992 Loss_G: 0.0391 Convergence: 0.1010 k= 0.022542 lr = 0.0000184\n",
      "[10/25][3610/9765] Loss_D: 0.0998 Loss_G: 0.0419 Convergence: 0.1024 k= 0.022534 lr = 0.0000184\n",
      "[10/25][3620/9765] Loss_D: 0.0953 Loss_G: 0.0411 Convergence: 0.0988 k= 0.022539 lr = 0.0000184\n",
      "[10/25][3630/9765] Loss_D: 0.1002 Loss_G: 0.0406 Convergence: 0.1012 k= 0.022535 lr = 0.0000184\n",
      "[10/25][3640/9765] Loss_D: 0.1063 Loss_G: 0.0444 Convergence: 0.1087 k= 0.022515 lr = 0.0000184\n",
      "[10/25][3650/9765] Loss_D: 0.0994 Loss_G: 0.0382 Convergence: 0.1021 k= 0.022519 lr = 0.0000184\n",
      "[10/25][3660/9765] Loss_D: 0.0921 Loss_G: 0.0381 Convergence: 0.0939 k= 0.022536 lr = 0.0000184\n",
      "[10/25][3670/9765] Loss_D: 0.0930 Loss_G: 0.0393 Convergence: 0.0957 k= 0.022556 lr = 0.0000184\n",
      "[10/25][3680/9765] Loss_D: 0.1035 Loss_G: 0.0401 Convergence: 0.1059 k= 0.022556 lr = 0.0000184\n",
      "[10/25][3690/9765] Loss_D: 0.0883 Loss_G: 0.0369 Convergence: 0.0903 k= 0.022557 lr = 0.0000184\n",
      "[10/25][3700/9765] Loss_D: 0.0873 Loss_G: 0.0399 Convergence: 0.0928 k= 0.022583 lr = 0.0000184\n",
      "[10/25][3710/9765] Loss_D: 0.0984 Loss_G: 0.0391 Convergence: 0.0999 k= 0.022585 lr = 0.0000184\n",
      "[10/25][3720/9765] Loss_D: 0.0961 Loss_G: 0.0422 Convergence: 0.1004 k= 0.022574 lr = 0.0000184\n",
      "[10/25][3730/9765] Loss_D: 0.1000 Loss_G: 0.0416 Convergence: 0.1022 k= 0.022566 lr = 0.0000184\n",
      "[10/25][3740/9765] Loss_D: 0.0898 Loss_G: 0.0379 Convergence: 0.0923 k= 0.022557 lr = 0.0000184\n",
      "[10/25][3750/9765] Loss_D: 0.0988 Loss_G: 0.0365 Convergence: 0.1031 k= 0.022589 lr = 0.0000184\n",
      "[10/25][3760/9765] Loss_D: 0.0894 Loss_G: 0.0379 Convergence: 0.0920 k= 0.022611 lr = 0.0000184\n",
      "[10/25][3770/9765] Loss_D: 0.0976 Loss_G: 0.0423 Convergence: 0.1013 k= 0.022598 lr = 0.0000184\n",
      "[10/25][3780/9765] Loss_D: 0.0933 Loss_G: 0.0398 Convergence: 0.0963 k= 0.022572 lr = 0.0000184\n",
      "[10/25][3790/9765] Loss_D: 0.0945 Loss_G: 0.0401 Convergence: 0.0973 k= 0.022575 lr = 0.0000184\n",
      "[10/25][3800/9765] Loss_D: 0.1049 Loss_G: 0.0403 Convergence: 0.1078 k= 0.022576 lr = 0.0000184\n",
      "[10/25][3810/9765] Loss_D: 0.1005 Loss_G: 0.0416 Convergence: 0.1024 k= 0.022592 lr = 0.0000184\n",
      "[10/25][3820/9765] Loss_D: 0.0983 Loss_G: 0.0396 Convergence: 0.0993 k= 0.022571 lr = 0.0000184\n",
      "[10/25][3830/9765] Loss_D: 0.0961 Loss_G: 0.0409 Convergence: 0.0991 k= 0.022570 lr = 0.0000184\n",
      "[10/25][3840/9765] Loss_D: 0.1140 Loss_G: 0.0375 Convergence: 0.1233 k= 0.022569 lr = 0.0000184\n",
      "[10/25][3850/9765] Loss_D: 0.1008 Loss_G: 0.0414 Convergence: 0.1024 k= 0.022570 lr = 0.0000184\n",
      "[10/25][3860/9765] Loss_D: 0.1064 Loss_G: 0.0426 Convergence: 0.1077 k= 0.022536 lr = 0.0000184\n",
      "[10/25][3870/9765] Loss_D: 0.0919 Loss_G: 0.0419 Convergence: 0.0977 k= 0.022520 lr = 0.0000184\n",
      "[10/25][3880/9765] Loss_D: 0.0971 Loss_G: 0.0391 Convergence: 0.0981 k= 0.022506 lr = 0.0000184\n",
      "[10/25][3890/9765] Loss_D: 0.0906 Loss_G: 0.0403 Convergence: 0.0952 k= 0.022507 lr = 0.0000184\n",
      "[10/25][3900/9765] Loss_D: 0.0981 Loss_G: 0.0384 Convergence: 0.1002 k= 0.022508 lr = 0.0000184\n",
      "[10/25][3910/9765] Loss_D: 0.0836 Loss_G: 0.0391 Convergence: 0.0898 k= 0.022502 lr = 0.0000184\n",
      "[10/25][3920/9765] Loss_D: 0.0927 Loss_G: 0.0427 Convergence: 0.0989 k= 0.022484 lr = 0.0000184\n",
      "[10/25][3930/9765] Loss_D: 0.0933 Loss_G: 0.0406 Convergence: 0.0971 k= 0.022460 lr = 0.0000184\n",
      "[10/25][3940/9765] Loss_D: 0.1002 Loss_G: 0.0373 Convergence: 0.1042 k= 0.022475 lr = 0.0000184\n",
      "[10/25][3950/9765] Loss_D: 0.1000 Loss_G: 0.0418 Convergence: 0.1023 k= 0.022499 lr = 0.0000184\n",
      "[10/25][3960/9765] Loss_D: 0.0986 Loss_G: 0.0407 Convergence: 0.1004 k= 0.022488 lr = 0.0000184\n",
      "[10/25][3970/9765] Loss_D: 0.0901 Loss_G: 0.0435 Convergence: 0.0981 k= 0.022458 lr = 0.0000184\n",
      "[10/25][3980/9765] Loss_D: 0.1039 Loss_G: 0.0423 Convergence: 0.1052 k= 0.022456 lr = 0.0000184\n",
      "[10/25][3990/9765] Loss_D: 0.1110 Loss_G: 0.0367 Convergence: 0.1200 k= 0.022461 lr = 0.0000184\n",
      "[10/25][4000/9765] Loss_D: 0.0962 Loss_G: 0.0352 Convergence: 0.1006 k= 0.022497 lr = 0.0000184\n",
      "[10/25][4010/9765] Loss_D: 0.0906 Loss_G: 0.0354 Convergence: 0.0926 k= 0.022527 lr = 0.0000184\n",
      "[10/25][4020/9765] Loss_D: 0.1006 Loss_G: 0.0429 Convergence: 0.1038 k= 0.022537 lr = 0.0000184\n",
      "[10/25][4030/9765] Loss_D: 0.1023 Loss_G: 0.0416 Convergence: 0.1036 k= 0.022527 lr = 0.0000184\n",
      "[10/25][4040/9765] Loss_D: 0.0969 Loss_G: 0.0375 Convergence: 0.0993 k= 0.022509 lr = 0.0000184\n",
      "[10/25][4050/9765] Loss_D: 0.1036 Loss_G: 0.0395 Convergence: 0.1067 k= 0.022520 lr = 0.0000184\n",
      "[10/25][4060/9765] Loss_D: 0.0939 Loss_G: 0.0390 Convergence: 0.0958 k= 0.022506 lr = 0.0000184\n",
      "[10/25][4070/9765] Loss_D: 0.1077 Loss_G: 0.0387 Convergence: 0.1133 k= 0.022505 lr = 0.0000184\n",
      "[10/25][4080/9765] Loss_D: 0.0945 Loss_G: 0.0379 Convergence: 0.0958 k= 0.022484 lr = 0.0000184\n",
      "[10/25][4090/9765] Loss_D: 0.1041 Loss_G: 0.0418 Convergence: 0.1052 k= 0.022479 lr = 0.0000184\n",
      "[10/25][4100/9765] Loss_D: 0.0874 Loss_G: 0.0416 Convergence: 0.0946 k= 0.022450 lr = 0.0000184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][4110/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.022438 lr = 0.0000184\n",
      "[10/25][4120/9765] Loss_D: 0.0923 Loss_G: 0.0391 Convergence: 0.0950 k= 0.022456 lr = 0.0000184\n",
      "[10/25][4130/9765] Loss_D: 0.0968 Loss_G: 0.0416 Convergence: 0.1002 k= 0.022458 lr = 0.0000184\n",
      "[10/25][4140/9765] Loss_D: 0.0947 Loss_G: 0.0418 Convergence: 0.0992 k= 0.022468 lr = 0.0000184\n",
      "[10/25][4150/9765] Loss_D: 0.1019 Loss_G: 0.0409 Convergence: 0.1030 k= 0.022466 lr = 0.0000184\n",
      "[10/25][4160/9765] Loss_D: 0.0942 Loss_G: 0.0364 Convergence: 0.0966 k= 0.022471 lr = 0.0000184\n",
      "[10/25][4170/9765] Loss_D: 0.0970 Loss_G: 0.0395 Convergence: 0.0982 k= 0.022475 lr = 0.0000184\n",
      "[10/25][4180/9765] Loss_D: 0.0973 Loss_G: 0.0400 Convergence: 0.0989 k= 0.022468 lr = 0.0000184\n",
      "[10/25][4190/9765] Loss_D: 0.0986 Loss_G: 0.0371 Convergence: 0.1021 k= 0.022474 lr = 0.0000184\n",
      "[10/25][4200/9765] Loss_D: 0.1008 Loss_G: 0.0383 Convergence: 0.1040 k= 0.022475 lr = 0.0000184\n",
      "[10/25][4210/9765] Loss_D: 0.1004 Loss_G: 0.0417 Convergence: 0.1025 k= 0.022465 lr = 0.0000184\n",
      "[10/25][4220/9765] Loss_D: 0.0907 Loss_G: 0.0360 Convergence: 0.0920 k= 0.022444 lr = 0.0000184\n",
      "[10/25][4230/9765] Loss_D: 0.0987 Loss_G: 0.0421 Convergence: 0.1019 k= 0.022455 lr = 0.0000184\n",
      "[10/25][4240/9765] Loss_D: 0.0839 Loss_G: 0.0388 Convergence: 0.0897 k= 0.022460 lr = 0.0000184\n",
      "[10/25][4250/9765] Loss_D: 0.1033 Loss_G: 0.0388 Convergence: 0.1071 k= 0.022460 lr = 0.0000184\n",
      "[10/25][4260/9765] Loss_D: 0.0940 Loss_G: 0.0406 Convergence: 0.0975 k= 0.022465 lr = 0.0000184\n",
      "[10/25][4270/9765] Loss_D: 0.1021 Loss_G: 0.0410 Convergence: 0.1033 k= 0.022456 lr = 0.0000184\n",
      "[10/25][4280/9765] Loss_D: 0.0997 Loss_G: 0.0374 Convergence: 0.1033 k= 0.022455 lr = 0.0000184\n",
      "[10/25][4290/9765] Loss_D: 0.1027 Loss_G: 0.0385 Convergence: 0.1064 k= 0.022464 lr = 0.0000184\n",
      "[10/25][4300/9765] Loss_D: 0.0896 Loss_G: 0.0380 Convergence: 0.0923 k= 0.022455 lr = 0.0000184\n",
      "[10/25][4310/9765] Loss_D: 0.0932 Loss_G: 0.0381 Convergence: 0.0946 k= 0.022466 lr = 0.0000184\n",
      "[10/25][4320/9765] Loss_D: 0.1045 Loss_G: 0.0421 Convergence: 0.1054 k= 0.022458 lr = 0.0000184\n",
      "[10/25][4330/9765] Loss_D: 0.1026 Loss_G: 0.0400 Convergence: 0.1049 k= 0.022448 lr = 0.0000184\n",
      "[10/25][4340/9765] Loss_D: 0.0914 Loss_G: 0.0394 Convergence: 0.0947 k= 0.022444 lr = 0.0000184\n",
      "[10/25][4350/9765] Loss_D: 0.1052 Loss_G: 0.0446 Convergence: 0.1082 k= 0.022443 lr = 0.0000175\n",
      "[10/25][4360/9765] Loss_D: 0.0909 Loss_G: 0.0378 Convergence: 0.0929 k= 0.022448 lr = 0.0000175\n",
      "[10/25][4370/9765] Loss_D: 0.0979 Loss_G: 0.0383 Convergence: 0.0999 k= 0.022459 lr = 0.0000175\n",
      "[10/25][4380/9765] Loss_D: 0.1053 Loss_G: 0.0403 Convergence: 0.1083 k= 0.022460 lr = 0.0000175\n",
      "[10/25][4390/9765] Loss_D: 0.0879 Loss_G: 0.0373 Convergence: 0.0906 k= 0.022467 lr = 0.0000175\n",
      "[10/25][4400/9765] Loss_D: 0.1047 Loss_G: 0.0439 Convergence: 0.1073 k= 0.022465 lr = 0.0000175\n",
      "[10/25][4410/9765] Loss_D: 0.0910 Loss_G: 0.0448 Convergence: 0.0999 k= 0.022436 lr = 0.0000175\n",
      "[10/25][4420/9765] Loss_D: 0.1000 Loss_G: 0.0414 Convergence: 0.1019 k= 0.022407 lr = 0.0000175\n",
      "[10/25][4430/9765] Loss_D: 0.0965 Loss_G: 0.0364 Convergence: 0.1000 k= 0.022398 lr = 0.0000175\n",
      "[10/25][4440/9765] Loss_D: 0.0982 Loss_G: 0.0384 Convergence: 0.1002 k= 0.022425 lr = 0.0000175\n",
      "[10/25][4450/9765] Loss_D: 0.0967 Loss_G: 0.0387 Convergence: 0.0979 k= 0.022444 lr = 0.0000175\n",
      "[10/25][4460/9765] Loss_D: 0.0983 Loss_G: 0.0438 Convergence: 0.1033 k= 0.022418 lr = 0.0000175\n",
      "[10/25][4470/9765] Loss_D: 0.1030 Loss_G: 0.0407 Convergence: 0.1048 k= 0.022399 lr = 0.0000175\n",
      "[10/25][4480/9765] Loss_D: 0.1069 Loss_G: 0.0397 Convergence: 0.1113 k= 0.022389 lr = 0.0000175\n",
      "[10/25][4490/9765] Loss_D: 0.0980 Loss_G: 0.0372 Convergence: 0.1012 k= 0.022399 lr = 0.0000175\n",
      "[10/25][4500/9765] Loss_D: 0.1000 Loss_G: 0.0360 Convergence: 0.1051 k= 0.022438 lr = 0.0000175\n",
      "[10/25][4510/9765] Loss_D: 0.0983 Loss_G: 0.0386 Convergence: 0.1001 k= 0.022455 lr = 0.0000175\n",
      "[10/25][4520/9765] Loss_D: 0.1020 Loss_G: 0.0424 Convergence: 0.1041 k= 0.022431 lr = 0.0000175\n",
      "[10/25][4530/9765] Loss_D: 0.1021 Loss_G: 0.0426 Convergence: 0.1045 k= 0.022379 lr = 0.0000175\n",
      "[10/25][4540/9765] Loss_D: 0.0995 Loss_G: 0.0358 Convergence: 0.1047 k= 0.022379 lr = 0.0000175\n",
      "[10/25][4550/9765] Loss_D: 0.1076 Loss_G: 0.0349 Convergence: 0.1170 k= 0.022388 lr = 0.0000175\n",
      "[10/25][4560/9765] Loss_D: 0.0931 Loss_G: 0.0370 Convergence: 0.0945 k= 0.022404 lr = 0.0000175\n",
      "[10/25][4570/9765] Loss_D: 0.0984 Loss_G: 0.0394 Convergence: 0.0996 k= 0.022399 lr = 0.0000175\n",
      "[10/25][4580/9765] Loss_D: 0.0968 Loss_G: 0.0480 Convergence: 0.1067 k= 0.022360 lr = 0.0000175\n",
      "[10/25][4590/9765] Loss_D: 0.0970 Loss_G: 0.0467 Convergence: 0.1055 k= 0.022278 lr = 0.0000175\n",
      "[10/25][4600/9765] Loss_D: 0.0974 Loss_G: 0.0411 Convergence: 0.1001 k= 0.022258 lr = 0.0000175\n",
      "[10/25][4610/9765] Loss_D: 0.0929 Loss_G: 0.0381 Convergence: 0.0943 k= 0.022252 lr = 0.0000175\n",
      "[10/25][4620/9765] Loss_D: 0.0972 Loss_G: 0.0366 Convergence: 0.1005 k= 0.022273 lr = 0.0000175\n",
      "[10/25][4630/9765] Loss_D: 0.0826 Loss_G: 0.0348 Convergence: 0.0849 k= 0.022293 lr = 0.0000175\n",
      "[10/25][4640/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.022334 lr = 0.0000175\n",
      "[10/25][4650/9765] Loss_D: 0.0978 Loss_G: 0.0426 Convergence: 0.1018 k= 0.022332 lr = 0.0000175\n",
      "[10/25][4660/9765] Loss_D: 0.0989 Loss_G: 0.0413 Convergence: 0.1011 k= 0.022314 lr = 0.0000175\n",
      "[10/25][4670/9765] Loss_D: 0.0999 Loss_G: 0.0415 Convergence: 0.1020 k= 0.022291 lr = 0.0000175\n",
      "[10/25][4680/9765] Loss_D: 0.0899 Loss_G: 0.0388 Convergence: 0.0932 k= 0.022276 lr = 0.0000175\n",
      "[10/25][4690/9765] Loss_D: 0.0975 Loss_G: 0.0376 Convergence: 0.0999 k= 0.022278 lr = 0.0000175\n",
      "[10/25][4700/9765] Loss_D: 0.0965 Loss_G: 0.0404 Convergence: 0.0989 k= 0.022279 lr = 0.0000175\n",
      "[10/25][4710/9765] Loss_D: 0.1018 Loss_G: 0.0412 Convergence: 0.1028 k= 0.022280 lr = 0.0000175\n",
      "[10/25][4720/9765] Loss_D: 0.0926 Loss_G: 0.0386 Convergence: 0.0948 k= 0.022268 lr = 0.0000175\n",
      "[10/25][4730/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.0989 k= 0.022279 lr = 0.0000175\n",
      "[10/25][4740/9765] Loss_D: 0.1006 Loss_G: 0.0376 Convergence: 0.1044 k= 0.022291 lr = 0.0000175\n",
      "[10/25][4750/9765] Loss_D: 0.0989 Loss_G: 0.0408 Convergence: 0.1006 k= 0.022294 lr = 0.0000175\n",
      "[10/25][4760/9765] Loss_D: 0.1010 Loss_G: 0.0413 Convergence: 0.1025 k= 0.022281 lr = 0.0000175\n",
      "[10/25][4770/9765] Loss_D: 0.1014 Loss_G: 0.0366 Convergence: 0.1064 k= 0.022289 lr = 0.0000175\n",
      "[10/25][4780/9765] Loss_D: 0.1022 Loss_G: 0.0385 Convergence: 0.1059 k= 0.022300 lr = 0.0000175\n",
      "[10/25][4790/9765] Loss_D: 0.0931 Loss_G: 0.0393 Convergence: 0.0957 k= 0.022310 lr = 0.0000175\n",
      "[10/25][4800/9765] Loss_D: 0.1073 Loss_G: 0.0367 Convergence: 0.1147 k= 0.022326 lr = 0.0000175\n",
      "[10/25][4810/9765] Loss_D: 0.0968 Loss_G: 0.0373 Convergence: 0.0995 k= 0.022341 lr = 0.0000175\n",
      "[10/25][4820/9765] Loss_D: 0.0914 Loss_G: 0.0385 Convergence: 0.0939 k= 0.022351 lr = 0.0000175\n",
      "[10/25][4830/9765] Loss_D: 0.1041 Loss_G: 0.0389 Convergence: 0.1080 k= 0.022347 lr = 0.0000175\n",
      "[10/25][4840/9765] Loss_D: 0.0976 Loss_G: 0.0393 Convergence: 0.0985 k= 0.022351 lr = 0.0000175\n",
      "[10/25][4850/9765] Loss_D: 0.1024 Loss_G: 0.0403 Convergence: 0.1043 k= 0.022346 lr = 0.0000175\n",
      "[10/25][4860/9765] Loss_D: 0.0952 Loss_G: 0.0383 Convergence: 0.0962 k= 0.022366 lr = 0.0000175\n",
      "[10/25][4870/9765] Loss_D: 0.0921 Loss_G: 0.0419 Convergence: 0.0977 k= 0.022352 lr = 0.0000175\n",
      "[10/25][4880/9765] Loss_D: 0.0939 Loss_G: 0.0410 Convergence: 0.0978 k= 0.022329 lr = 0.0000175\n",
      "[10/25][4890/9765] Loss_D: 0.1040 Loss_G: 0.0423 Convergence: 0.1052 k= 0.022321 lr = 0.0000175\n",
      "[10/25][4900/9765] Loss_D: 0.0907 Loss_G: 0.0419 Convergence: 0.0968 k= 0.022310 lr = 0.0000175\n",
      "[10/25][4910/9765] Loss_D: 0.1001 Loss_G: 0.0387 Convergence: 0.1026 k= 0.022297 lr = 0.0000175\n",
      "[10/25][4920/9765] Loss_D: 0.0913 Loss_G: 0.0341 Convergence: 0.0950 k= 0.022318 lr = 0.0000175\n",
      "[10/25][4930/9765] Loss_D: 0.0915 Loss_G: 0.0379 Convergence: 0.0933 k= 0.022343 lr = 0.0000175\n",
      "[10/25][4940/9765] Loss_D: 0.0907 Loss_G: 0.0409 Convergence: 0.0958 k= 0.022345 lr = 0.0000175\n",
      "[10/25][4950/9765] Loss_D: 0.1042 Loss_G: 0.0414 Convergence: 0.1058 k= 0.022338 lr = 0.0000175\n",
      "[10/25][4960/9765] Loss_D: 0.0961 Loss_G: 0.0411 Convergence: 0.0993 k= 0.022314 lr = 0.0000175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][4970/9765] Loss_D: 0.0981 Loss_G: 0.0421 Convergence: 0.1015 k= 0.022294 lr = 0.0000175\n",
      "[10/25][4980/9765] Loss_D: 0.0999 Loss_G: 0.0407 Convergence: 0.1012 k= 0.022295 lr = 0.0000175\n",
      "[10/25][4990/9765] Loss_D: 0.1084 Loss_G: 0.0409 Convergence: 0.1119 k= 0.022303 lr = 0.0000175\n",
      "[10/25][5000/9765] Loss_D: 0.0996 Loss_G: 0.0415 Convergence: 0.1018 k= 0.022290 lr = 0.0000175\n",
      "[10/25][5010/9765] Loss_D: 0.0892 Loss_G: 0.0392 Convergence: 0.0932 k= 0.022276 lr = 0.0000175\n",
      "[10/25][5020/9765] Loss_D: 0.1026 Loss_G: 0.0401 Convergence: 0.1047 k= 0.022275 lr = 0.0000175\n",
      "[10/25][5030/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0965 k= 0.022287 lr = 0.0000175\n",
      "[10/25][5040/9765] Loss_D: 0.0980 Loss_G: 0.0398 Convergence: 0.0992 k= 0.022294 lr = 0.0000175\n",
      "[10/25][5050/9765] Loss_D: 0.0949 Loss_G: 0.0394 Convergence: 0.0969 k= 0.022308 lr = 0.0000175\n",
      "[10/25][5060/9765] Loss_D: 0.1012 Loss_G: 0.0409 Convergence: 0.1022 k= 0.022306 lr = 0.0000175\n",
      "[10/25][5070/9765] Loss_D: 0.0916 Loss_G: 0.0399 Convergence: 0.0954 k= 0.022297 lr = 0.0000175\n",
      "[10/25][5080/9765] Loss_D: 0.0860 Loss_G: 0.0378 Convergence: 0.0899 k= 0.022284 lr = 0.0000175\n",
      "[10/25][5090/9765] Loss_D: 0.0983 Loss_G: 0.0376 Convergence: 0.1011 k= 0.022280 lr = 0.0000175\n",
      "[10/25][5100/9765] Loss_D: 0.0940 Loss_G: 0.0375 Convergence: 0.0953 k= 0.022300 lr = 0.0000175\n",
      "[10/25][5110/9765] Loss_D: 0.0996 Loss_G: 0.0415 Convergence: 0.1018 k= 0.022302 lr = 0.0000175\n",
      "[10/25][5120/9765] Loss_D: 0.0918 Loss_G: 0.0408 Convergence: 0.0964 k= 0.022265 lr = 0.0000175\n",
      "[10/25][5130/9765] Loss_D: 0.1081 Loss_G: 0.0410 Convergence: 0.1116 k= 0.022259 lr = 0.0000175\n",
      "[10/25][5140/9765] Loss_D: 0.0964 Loss_G: 0.0375 Convergence: 0.0987 k= 0.022274 lr = 0.0000175\n",
      "[10/25][5150/9765] Loss_D: 0.1019 Loss_G: 0.0384 Convergence: 0.1055 k= 0.022286 lr = 0.0000175\n",
      "[10/25][5160/9765] Loss_D: 0.0978 Loss_G: 0.0373 Convergence: 0.1009 k= 0.022311 lr = 0.0000175\n",
      "[10/25][5170/9765] Loss_D: 0.0974 Loss_G: 0.0426 Convergence: 0.1016 k= 0.022321 lr = 0.0000175\n",
      "[10/25][5180/9765] Loss_D: 0.0970 Loss_G: 0.0468 Convergence: 0.1056 k= 0.022253 lr = 0.0000175\n",
      "[10/25][5190/9765] Loss_D: 0.1048 Loss_G: 0.0374 Convergence: 0.1104 k= 0.022227 lr = 0.0000175\n",
      "[10/25][5200/9765] Loss_D: 0.0982 Loss_G: 0.0397 Convergence: 0.0991 k= 0.022233 lr = 0.0000175\n",
      "[10/25][5210/9765] Loss_D: 0.0936 Loss_G: 0.0397 Convergence: 0.0964 k= 0.022230 lr = 0.0000175\n",
      "[10/25][5220/9765] Loss_D: 0.1060 Loss_G: 0.0420 Convergence: 0.1076 k= 0.022230 lr = 0.0000175\n",
      "[10/25][5230/9765] Loss_D: 0.1008 Loss_G: 0.0375 Convergence: 0.1048 k= 0.022229 lr = 0.0000175\n",
      "[10/25][5240/9765] Loss_D: 0.0942 Loss_G: 0.0382 Convergence: 0.0953 k= 0.022228 lr = 0.0000175\n",
      "[10/25][5250/9765] Loss_D: 0.0871 Loss_G: 0.0377 Convergence: 0.0906 k= 0.022224 lr = 0.0000175\n",
      "[10/25][5260/9765] Loss_D: 0.0962 Loss_G: 0.0381 Convergence: 0.0977 k= 0.022213 lr = 0.0000175\n",
      "[10/25][5270/9765] Loss_D: 0.0991 Loss_G: 0.0361 Convergence: 0.1037 k= 0.022233 lr = 0.0000175\n",
      "[10/25][5280/9765] Loss_D: 0.0928 Loss_G: 0.0374 Convergence: 0.0937 k= 0.022243 lr = 0.0000175\n",
      "[10/25][5290/9765] Loss_D: 0.0941 Loss_G: 0.0382 Convergence: 0.0952 k= 0.022240 lr = 0.0000175\n",
      "[10/25][5300/9765] Loss_D: 0.1038 Loss_G: 0.0432 Convergence: 0.1060 k= 0.022224 lr = 0.0000175\n",
      "[10/25][5310/9765] Loss_D: 0.0959 Loss_G: 0.0379 Convergence: 0.0976 k= 0.022226 lr = 0.0000175\n",
      "[10/25][5320/9765] Loss_D: 0.1004 Loss_G: 0.0386 Convergence: 0.1032 k= 0.022251 lr = 0.0000175\n",
      "[10/25][5330/9765] Loss_D: 0.0894 Loss_G: 0.0375 Convergence: 0.0916 k= 0.022266 lr = 0.0000175\n",
      "[10/25][5340/9765] Loss_D: 0.1016 Loss_G: 0.0403 Convergence: 0.1032 k= 0.022267 lr = 0.0000175\n",
      "[10/25][5350/9765] Loss_D: 0.0929 Loss_G: 0.0422 Convergence: 0.0986 k= 0.022239 lr = 0.0000175\n",
      "[10/25][5360/9765] Loss_D: 0.1046 Loss_G: 0.0406 Convergence: 0.1071 k= 0.022220 lr = 0.0000175\n",
      "[10/25][5370/9765] Loss_D: 0.0941 Loss_G: 0.0403 Convergence: 0.0972 k= 0.022222 lr = 0.0000175\n",
      "[10/25][5380/9765] Loss_D: 0.1011 Loss_G: 0.0396 Convergence: 0.1031 k= 0.022232 lr = 0.0000175\n",
      "[10/25][5390/9765] Loss_D: 0.0948 Loss_G: 0.0384 Convergence: 0.0958 k= 0.022242 lr = 0.0000175\n",
      "[10/25][5400/9765] Loss_D: 0.1015 Loss_G: 0.0403 Convergence: 0.1031 k= 0.022256 lr = 0.0000175\n",
      "[10/25][5410/9765] Loss_D: 0.1055 Loss_G: 0.0425 Convergence: 0.1064 k= 0.022226 lr = 0.0000175\n",
      "[10/25][5420/9765] Loss_D: 0.0949 Loss_G: 0.0390 Convergence: 0.0964 k= 0.022207 lr = 0.0000175\n",
      "[10/25][5430/9765] Loss_D: 0.0966 Loss_G: 0.0391 Convergence: 0.0975 k= 0.022217 lr = 0.0000175\n",
      "[10/25][5440/9765] Loss_D: 0.0965 Loss_G: 0.0372 Convergence: 0.0990 k= 0.022230 lr = 0.0000175\n",
      "[10/25][5450/9765] Loss_D: 0.0993 Loss_G: 0.0424 Convergence: 0.1026 k= 0.022224 lr = 0.0000175\n",
      "[10/25][5460/9765] Loss_D: 0.1020 Loss_G: 0.0436 Convergence: 0.1054 k= 0.022212 lr = 0.0000175\n",
      "[10/25][5470/9765] Loss_D: 0.0940 Loss_G: 0.0415 Convergence: 0.0984 k= 0.022189 lr = 0.0000175\n",
      "[10/25][5480/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0959 k= 0.022196 lr = 0.0000175\n",
      "[10/25][5490/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0994 k= 0.022187 lr = 0.0000175\n",
      "[10/25][5500/9765] Loss_D: 0.0956 Loss_G: 0.0442 Convergence: 0.1021 k= 0.022161 lr = 0.0000175\n",
      "[10/25][5510/9765] Loss_D: 0.0968 Loss_G: 0.0391 Convergence: 0.0977 k= 0.022154 lr = 0.0000175\n",
      "[10/25][5520/9765] Loss_D: 0.0999 Loss_G: 0.0393 Convergence: 0.1018 k= 0.022162 lr = 0.0000175\n",
      "[10/25][5530/9765] Loss_D: 0.0979 Loss_G: 0.0419 Convergence: 0.1012 k= 0.022162 lr = 0.0000175\n",
      "[10/25][5540/9765] Loss_D: 0.1042 Loss_G: 0.0380 Convergence: 0.1091 k= 0.022162 lr = 0.0000175\n",
      "[10/25][5550/9765] Loss_D: 0.0983 Loss_G: 0.0501 Convergence: 0.1097 k= 0.022130 lr = 0.0000175\n",
      "[10/25][5560/9765] Loss_D: 0.0964 Loss_G: 0.0451 Convergence: 0.1035 k= 0.021968 lr = 0.0000175\n",
      "[10/25][5570/9765] Loss_D: 0.0912 Loss_G: 0.0401 Convergence: 0.0954 k= 0.021935 lr = 0.0000175\n",
      "[10/25][5580/9765] Loss_D: 0.0994 Loss_G: 0.0355 Convergence: 0.1047 k= 0.021958 lr = 0.0000175\n",
      "[10/25][5590/9765] Loss_D: 0.0974 Loss_G: 0.0353 Convergence: 0.1022 k= 0.022004 lr = 0.0000175\n",
      "[10/25][5600/9765] Loss_D: 0.0956 Loss_G: 0.0351 Convergence: 0.0998 k= 0.022042 lr = 0.0000175\n",
      "[10/25][5610/9765] Loss_D: 0.0954 Loss_G: 0.0423 Convergence: 0.1001 k= 0.022062 lr = 0.0000175\n",
      "[10/25][5620/9765] Loss_D: 0.0942 Loss_G: 0.0435 Convergence: 0.1006 k= 0.022030 lr = 0.0000175\n",
      "[10/25][5630/9765] Loss_D: 0.1058 Loss_G: 0.0409 Convergence: 0.1085 k= 0.022018 lr = 0.0000175\n",
      "[10/25][5640/9765] Loss_D: 0.1022 Loss_G: 0.0383 Convergence: 0.1061 k= 0.022029 lr = 0.0000175\n",
      "[10/25][5650/9765] Loss_D: 0.0958 Loss_G: 0.0390 Convergence: 0.0971 k= 0.022030 lr = 0.0000175\n",
      "[10/25][5660/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0967 k= 0.022027 lr = 0.0000175\n",
      "[10/25][5670/9765] Loss_D: 0.1026 Loss_G: 0.0410 Convergence: 0.1039 k= 0.022049 lr = 0.0000175\n",
      "[10/25][5680/9765] Loss_D: 0.1090 Loss_G: 0.0413 Convergence: 0.1125 k= 0.022052 lr = 0.0000175\n",
      "[10/25][5690/9765] Loss_D: 0.1079 Loss_G: 0.0385 Convergence: 0.1138 k= 0.022054 lr = 0.0000175\n",
      "[10/25][5700/9765] Loss_D: 0.0909 Loss_G: 0.0394 Convergence: 0.0945 k= 0.022038 lr = 0.0000175\n",
      "[10/25][5710/9765] Loss_D: 0.0915 Loss_G: 0.0370 Convergence: 0.0924 k= 0.022030 lr = 0.0000175\n",
      "[10/25][5720/9765] Loss_D: 0.0991 Loss_G: 0.0346 Convergence: 0.1053 k= 0.022075 lr = 0.0000175\n",
      "[10/25][5730/9765] Loss_D: 0.0992 Loss_G: 0.0431 Convergence: 0.1032 k= 0.022079 lr = 0.0000175\n",
      "[10/25][5740/9765] Loss_D: 0.0925 Loss_G: 0.0432 Convergence: 0.0993 k= 0.022045 lr = 0.0000175\n",
      "[10/25][5750/9765] Loss_D: 0.0941 Loss_G: 0.0403 Convergence: 0.0973 k= 0.022003 lr = 0.0000175\n",
      "[10/25][5760/9765] Loss_D: 0.0925 Loss_G: 0.0374 Convergence: 0.0934 k= 0.022014 lr = 0.0000175\n",
      "[10/25][5770/9765] Loss_D: 0.1040 Loss_G: 0.0387 Convergence: 0.1082 k= 0.022012 lr = 0.0000175\n",
      "[10/25][5780/9765] Loss_D: 0.0910 Loss_G: 0.0395 Convergence: 0.0946 k= 0.022016 lr = 0.0000175\n",
      "[10/25][5790/9765] Loss_D: 0.1003 Loss_G: 0.0424 Convergence: 0.1032 k= 0.021986 lr = 0.0000175\n",
      "[10/25][5800/9765] Loss_D: 0.1063 Loss_G: 0.0402 Convergence: 0.1098 k= 0.021979 lr = 0.0000175\n",
      "[10/25][5810/9765] Loss_D: 0.0968 Loss_G: 0.0420 Convergence: 0.1006 k= 0.021956 lr = 0.0000175\n",
      "[10/25][5820/9765] Loss_D: 0.0979 Loss_G: 0.0426 Convergence: 0.1019 k= 0.021943 lr = 0.0000175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][5830/9765] Loss_D: 0.0965 Loss_G: 0.0387 Convergence: 0.0976 k= 0.021940 lr = 0.0000175\n",
      "[10/25][5840/9765] Loss_D: 0.0953 Loss_G: 0.0377 Convergence: 0.0969 k= 0.021935 lr = 0.0000175\n",
      "[10/25][5850/9765] Loss_D: 0.0884 Loss_G: 0.0382 Convergence: 0.0918 k= 0.021925 lr = 0.0000175\n",
      "[10/25][5860/9765] Loss_D: 0.1009 Loss_G: 0.0395 Convergence: 0.1029 k= 0.021935 lr = 0.0000175\n",
      "[10/25][5870/9765] Loss_D: 0.0885 Loss_G: 0.0386 Convergence: 0.0922 k= 0.021943 lr = 0.0000175\n",
      "[10/25][5880/9765] Loss_D: 0.1049 Loss_G: 0.0400 Convergence: 0.1082 k= 0.021951 lr = 0.0000175\n",
      "[10/25][5890/9765] Loss_D: 0.1007 Loss_G: 0.0403 Convergence: 0.1018 k= 0.021939 lr = 0.0000175\n",
      "[10/25][5900/9765] Loss_D: 0.1015 Loss_G: 0.0421 Convergence: 0.1036 k= 0.021918 lr = 0.0000175\n",
      "[10/25][5910/9765] Loss_D: 0.0858 Loss_G: 0.0410 Convergence: 0.0930 k= 0.021912 lr = 0.0000175\n",
      "[10/25][5920/9765] Loss_D: 0.1056 Loss_G: 0.0374 Convergence: 0.1114 k= 0.021938 lr = 0.0000175\n",
      "[10/25][5930/9765] Loss_D: 0.1066 Loss_G: 0.0412 Convergence: 0.1092 k= 0.021938 lr = 0.0000175\n",
      "[10/25][5940/9765] Loss_D: 0.0969 Loss_G: 0.0407 Convergence: 0.0993 k= 0.021940 lr = 0.0000175\n",
      "[10/25][5950/9765] Loss_D: 0.1028 Loss_G: 0.0376 Convergence: 0.1074 k= 0.021963 lr = 0.0000175\n",
      "[10/25][5960/9765] Loss_D: 0.0942 Loss_G: 0.0390 Convergence: 0.0961 k= 0.021962 lr = 0.0000175\n",
      "[10/25][5970/9765] Loss_D: 0.0981 Loss_G: 0.0392 Convergence: 0.0993 k= 0.021966 lr = 0.0000175\n",
      "[10/25][5980/9765] Loss_D: 0.0955 Loss_G: 0.0376 Convergence: 0.0973 k= 0.021970 lr = 0.0000175\n",
      "[10/25][5990/9765] Loss_D: 0.0974 Loss_G: 0.0402 Convergence: 0.0992 k= 0.021963 lr = 0.0000175\n",
      "[10/25][6000/9765] Loss_D: 0.1053 Loss_G: 0.0394 Convergence: 0.1091 k= 0.021969 lr = 0.0000175\n",
      "[10/25][6010/9765] Loss_D: 0.0903 Loss_G: 0.0377 Convergence: 0.0924 k= 0.021968 lr = 0.0000175\n",
      "[10/25][6020/9765] Loss_D: 0.1094 Loss_G: 0.0404 Convergence: 0.1140 k= 0.021972 lr = 0.0000175\n",
      "[10/25][6030/9765] Loss_D: 0.1020 Loss_G: 0.0413 Convergence: 0.1030 k= 0.021959 lr = 0.0000175\n",
      "[10/25][6040/9765] Loss_D: 0.1101 Loss_G: 0.0419 Convergence: 0.1134 k= 0.021943 lr = 0.0000175\n",
      "[10/25][6050/9765] Loss_D: 0.1051 Loss_G: 0.0389 Convergence: 0.1095 k= 0.021952 lr = 0.0000175\n",
      "[10/25][6060/9765] Loss_D: 0.1120 Loss_G: 0.0369 Convergence: 0.1210 k= 0.021995 lr = 0.0000175\n",
      "[10/25][6070/9765] Loss_D: 0.1020 Loss_G: 0.0421 Convergence: 0.1039 k= 0.021994 lr = 0.0000175\n",
      "[10/25][6080/9765] Loss_D: 0.1072 Loss_G: 0.0371 Convergence: 0.1141 k= 0.021975 lr = 0.0000175\n",
      "[10/25][6090/9765] Loss_D: 0.0908 Loss_G: 0.0402 Convergence: 0.0952 k= 0.021973 lr = 0.0000175\n",
      "[10/25][6100/9765] Loss_D: 0.0976 Loss_G: 0.0400 Convergence: 0.0991 k= 0.021970 lr = 0.0000175\n",
      "[10/25][6110/9765] Loss_D: 0.1034 Loss_G: 0.0368 Convergence: 0.1090 k= 0.021986 lr = 0.0000175\n",
      "[10/25][6120/9765] Loss_D: 0.0919 Loss_G: 0.0371 Convergence: 0.0927 k= 0.022007 lr = 0.0000175\n",
      "[10/25][6130/9765] Loss_D: 0.1023 Loss_G: 0.0372 Convergence: 0.1072 k= 0.022031 lr = 0.0000175\n",
      "[10/25][6140/9765] Loss_D: 0.0954 Loss_G: 0.0412 Convergence: 0.0990 k= 0.022026 lr = 0.0000175\n",
      "[10/25][6150/9765] Loss_D: 0.0953 Loss_G: 0.0379 Convergence: 0.0967 k= 0.022024 lr = 0.0000175\n",
      "[10/25][6160/9765] Loss_D: 0.0922 Loss_G: 0.0366 Convergence: 0.0937 k= 0.022025 lr = 0.0000175\n",
      "[10/25][6170/9765] Loss_D: 0.1057 Loss_G: 0.0374 Convergence: 0.1117 k= 0.022040 lr = 0.0000175\n",
      "[10/25][6180/9765] Loss_D: 0.0909 Loss_G: 0.0359 Convergence: 0.0926 k= 0.022058 lr = 0.0000175\n",
      "[10/25][6190/9765] Loss_D: 0.0968 Loss_G: 0.0400 Convergence: 0.0986 k= 0.022063 lr = 0.0000175\n",
      "[10/25][6200/9765] Loss_D: 0.0893 Loss_G: 0.0375 Convergence: 0.0915 k= 0.022051 lr = 0.0000175\n",
      "[10/25][6210/9765] Loss_D: 0.0985 Loss_G: 0.0406 Convergence: 0.1002 k= 0.022059 lr = 0.0000175\n",
      "[10/25][6220/9765] Loss_D: 0.1089 Loss_G: 0.0424 Convergence: 0.1113 k= 0.022059 lr = 0.0000175\n",
      "[10/25][6230/9765] Loss_D: 0.0977 Loss_G: 0.0383 Convergence: 0.0997 k= 0.022077 lr = 0.0000175\n",
      "[10/25][6240/9765] Loss_D: 0.0930 Loss_G: 0.0394 Convergence: 0.0957 k= 0.022082 lr = 0.0000175\n",
      "[10/25][6250/9765] Loss_D: 0.0986 Loss_G: 0.0412 Convergence: 0.1009 k= 0.022088 lr = 0.0000175\n",
      "[10/25][6260/9765] Loss_D: 0.1044 Loss_G: 0.0413 Convergence: 0.1060 k= 0.022088 lr = 0.0000175\n",
      "[10/25][6270/9765] Loss_D: 0.0965 Loss_G: 0.0408 Convergence: 0.0992 k= 0.022066 lr = 0.0000175\n",
      "[10/25][6280/9765] Loss_D: 0.1004 Loss_G: 0.0406 Convergence: 0.1014 k= 0.022063 lr = 0.0000175\n",
      "[10/25][6290/9765] Loss_D: 0.0966 Loss_G: 0.0391 Convergence: 0.0976 k= 0.022081 lr = 0.0000175\n",
      "[10/25][6300/9765] Loss_D: 0.0912 Loss_G: 0.0417 Convergence: 0.0970 k= 0.022077 lr = 0.0000175\n",
      "[10/25][6310/9765] Loss_D: 0.1072 Loss_G: 0.0412 Convergence: 0.1102 k= 0.022068 lr = 0.0000175\n",
      "[10/25][6320/9765] Loss_D: 0.0936 Loss_G: 0.0394 Convergence: 0.0961 k= 0.022054 lr = 0.0000175\n",
      "[10/25][6330/9765] Loss_D: 0.0937 Loss_G: 0.0391 Convergence: 0.0959 k= 0.022049 lr = 0.0000175\n",
      "[10/25][6340/9765] Loss_D: 0.1071 Loss_G: 0.0395 Convergence: 0.1116 k= 0.022071 lr = 0.0000175\n",
      "[10/25][6350/9765] Loss_D: 0.1000 Loss_G: 0.0389 Convergence: 0.1023 k= 0.022096 lr = 0.0000175\n",
      "[10/25][6360/9765] Loss_D: 0.0981 Loss_G: 0.0394 Convergence: 0.0992 k= 0.022103 lr = 0.0000175\n",
      "[10/25][6370/9765] Loss_D: 0.0952 Loss_G: 0.0425 Convergence: 0.1002 k= 0.022079 lr = 0.0000175\n",
      "[10/25][6380/9765] Loss_D: 0.0962 Loss_G: 0.0410 Convergence: 0.0993 k= 0.022063 lr = 0.0000175\n",
      "[10/25][6390/9765] Loss_D: 0.1013 Loss_G: 0.0393 Convergence: 0.1037 k= 0.022054 lr = 0.0000175\n",
      "[10/25][6400/9765] Loss_D: 0.1029 Loss_G: 0.0399 Convergence: 0.1053 k= 0.022055 lr = 0.0000175\n",
      "[10/25][6410/9765] Loss_D: 0.0976 Loss_G: 0.0401 Convergence: 0.0992 k= 0.022060 lr = 0.0000175\n",
      "[10/25][6420/9765] Loss_D: 0.1058 Loss_G: 0.0379 Convergence: 0.1114 k= 0.022054 lr = 0.0000175\n",
      "[10/25][6430/9765] Loss_D: 0.1044 Loss_G: 0.0393 Convergence: 0.1080 k= 0.022079 lr = 0.0000175\n",
      "[10/25][6440/9765] Loss_D: 0.1111 Loss_G: 0.0420 Convergence: 0.1148 k= 0.022051 lr = 0.0000175\n",
      "[10/25][6450/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0954 k= 0.022041 lr = 0.0000175\n",
      "[10/25][6460/9765] Loss_D: 0.0965 Loss_G: 0.0410 Convergence: 0.0995 k= 0.022039 lr = 0.0000175\n",
      "[10/25][6470/9765] Loss_D: 0.0934 Loss_G: 0.0381 Convergence: 0.0946 k= 0.022029 lr = 0.0000175\n",
      "[10/25][6480/9765] Loss_D: 0.0945 Loss_G: 0.0395 Convergence: 0.0967 k= 0.022029 lr = 0.0000175\n",
      "[10/25][6490/9765] Loss_D: 0.0984 Loss_G: 0.0417 Convergence: 0.1013 k= 0.022029 lr = 0.0000175\n",
      "[10/25][6500/9765] Loss_D: 0.0896 Loss_G: 0.0422 Convergence: 0.0965 k= 0.022021 lr = 0.0000175\n",
      "[10/25][6510/9765] Loss_D: 0.0976 Loss_G: 0.0427 Convergence: 0.1018 k= 0.022024 lr = 0.0000175\n",
      "[10/25][6520/9765] Loss_D: 0.1098 Loss_G: 0.0405 Convergence: 0.1144 k= 0.022046 lr = 0.0000175\n",
      "[10/25][6530/9765] Loss_D: 0.0957 Loss_G: 0.0394 Convergence: 0.0974 k= 0.022053 lr = 0.0000175\n",
      "[10/25][6540/9765] Loss_D: 0.0891 Loss_G: 0.0416 Convergence: 0.0956 k= 0.022029 lr = 0.0000175\n",
      "[10/25][6550/9765] Loss_D: 0.1070 Loss_G: 0.0424 Convergence: 0.1086 k= 0.022033 lr = 0.0000175\n",
      "[10/25][6560/9765] Loss_D: 0.1021 Loss_G: 0.0399 Convergence: 0.1042 k= 0.022020 lr = 0.0000175\n",
      "[10/25][6570/9765] Loss_D: 0.0892 Loss_G: 0.0404 Convergence: 0.0944 k= 0.022026 lr = 0.0000175\n",
      "[10/25][6580/9765] Loss_D: 0.0977 Loss_G: 0.0370 Convergence: 0.1009 k= 0.022032 lr = 0.0000175\n",
      "[10/25][6590/9765] Loss_D: 0.0957 Loss_G: 0.0381 Convergence: 0.0972 k= 0.022041 lr = 0.0000175\n",
      "[10/25][6600/9765] Loss_D: 0.0963 Loss_G: 0.0423 Convergence: 0.1006 k= 0.022015 lr = 0.0000175\n",
      "[10/25][6610/9765] Loss_D: 0.1014 Loss_G: 0.0420 Convergence: 0.1034 k= 0.021993 lr = 0.0000175\n",
      "[10/25][6620/9765] Loss_D: 0.1017 Loss_G: 0.0400 Convergence: 0.1035 k= 0.021994 lr = 0.0000175\n",
      "[10/25][6630/9765] Loss_D: 0.0994 Loss_G: 0.0357 Convergence: 0.1046 k= 0.022007 lr = 0.0000175\n",
      "[10/25][6640/9765] Loss_D: 0.1129 Loss_G: 0.0407 Convergence: 0.1185 k= 0.022023 lr = 0.0000175\n",
      "[10/25][6650/9765] Loss_D: 0.0926 Loss_G: 0.0405 Convergence: 0.0966 k= 0.022020 lr = 0.0000175\n",
      "[10/25][6660/9765] Loss_D: 0.1029 Loss_G: 0.0421 Convergence: 0.1043 k= 0.022009 lr = 0.0000175\n",
      "[10/25][6670/9765] Loss_D: 0.0921 Loss_G: 0.0364 Convergence: 0.0938 k= 0.022010 lr = 0.0000175\n",
      "[10/25][6680/9765] Loss_D: 0.0942 Loss_G: 0.0372 Convergence: 0.0958 k= 0.022021 lr = 0.0000175\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][6690/9765] Loss_D: 0.1018 Loss_G: 0.0396 Convergence: 0.1040 k= 0.022039 lr = 0.0000175\n",
      "[10/25][6700/9765] Loss_D: 0.0976 Loss_G: 0.0407 Convergence: 0.0998 k= 0.022039 lr = 0.0000175\n",
      "[10/25][6710/9765] Loss_D: 0.1014 Loss_G: 0.0383 Convergence: 0.1048 k= 0.022056 lr = 0.0000175\n",
      "[10/25][6720/9765] Loss_D: 0.0954 Loss_G: 0.0437 Convergence: 0.1015 k= 0.022046 lr = 0.0000175\n",
      "[10/25][6730/9765] Loss_D: 0.1030 Loss_G: 0.0384 Convergence: 0.1070 k= 0.022038 lr = 0.0000175\n",
      "[10/25][6740/9765] Loss_D: 0.1144 Loss_G: 0.0384 Convergence: 0.1229 k= 0.022051 lr = 0.0000175\n",
      "[10/25][6750/9765] Loss_D: 0.0953 Loss_G: 0.0365 Convergence: 0.0980 k= 0.022062 lr = 0.0000175\n",
      "[10/25][6760/9765] Loss_D: 0.0869 Loss_G: 0.0360 Convergence: 0.0887 k= 0.022060 lr = 0.0000175\n",
      "[10/25][6770/9765] Loss_D: 0.1021 Loss_G: 0.0384 Convergence: 0.1058 k= 0.022066 lr = 0.0000175\n",
      "[10/25][6780/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1021 k= 0.022079 lr = 0.0000175\n",
      "[10/25][6790/9765] Loss_D: 0.0987 Loss_G: 0.0406 Convergence: 0.1004 k= 0.022071 lr = 0.0000175\n",
      "[10/25][6800/9765] Loss_D: 0.1062 Loss_G: 0.0444 Convergence: 0.1087 k= 0.022056 lr = 0.0000175\n",
      "[10/25][6810/9765] Loss_D: 0.1095 Loss_G: 0.0388 Convergence: 0.1157 k= 0.022056 lr = 0.0000175\n",
      "[10/25][6820/9765] Loss_D: 0.1002 Loss_G: 0.0389 Convergence: 0.1026 k= 0.022062 lr = 0.0000175\n",
      "[10/25][6830/9765] Loss_D: 0.1062 Loss_G: 0.0405 Convergence: 0.1095 k= 0.022067 lr = 0.0000175\n",
      "[10/25][6840/9765] Loss_D: 0.0991 Loss_G: 0.0387 Convergence: 0.1013 k= 0.022063 lr = 0.0000175\n",
      "[10/25][6850/9765] Loss_D: 0.0949 Loss_G: 0.0377 Convergence: 0.0964 k= 0.022070 lr = 0.0000175\n",
      "[10/25][6860/9765] Loss_D: 0.0954 Loss_G: 0.0380 Convergence: 0.0967 k= 0.022072 lr = 0.0000175\n",
      "[10/25][6870/9765] Loss_D: 0.1010 Loss_G: 0.0396 Convergence: 0.1030 k= 0.022057 lr = 0.0000175\n",
      "[10/25][6880/9765] Loss_D: 0.1016 Loss_G: 0.0380 Convergence: 0.1055 k= 0.022069 lr = 0.0000175\n",
      "[10/25][6890/9765] Loss_D: 0.0968 Loss_G: 0.0427 Convergence: 0.1014 k= 0.022060 lr = 0.0000175\n",
      "[10/25][6900/9765] Loss_D: 0.1003 Loss_G: 0.0431 Convergence: 0.1038 k= 0.022022 lr = 0.0000175\n",
      "[10/25][6910/9765] Loss_D: 0.0999 Loss_G: 0.0396 Convergence: 0.1015 k= 0.022003 lr = 0.0000175\n",
      "[10/25][6920/9765] Loss_D: 0.0983 Loss_G: 0.0415 Convergence: 0.1010 k= 0.022000 lr = 0.0000175\n",
      "[10/25][6930/9765] Loss_D: 0.0882 Loss_G: 0.0370 Convergence: 0.0904 k= 0.022011 lr = 0.0000175\n",
      "[10/25][6940/9765] Loss_D: 0.1010 Loss_G: 0.0428 Convergence: 0.1040 k= 0.022015 lr = 0.0000175\n",
      "[10/25][6950/9765] Loss_D: 0.0905 Loss_G: 0.0394 Convergence: 0.0943 k= 0.021992 lr = 0.0000175\n",
      "[10/25][6960/9765] Loss_D: 0.0937 Loss_G: 0.0403 Convergence: 0.0971 k= 0.021981 lr = 0.0000175\n",
      "[10/25][6970/9765] Loss_D: 0.0959 Loss_G: 0.0402 Convergence: 0.0983 k= 0.021963 lr = 0.0000175\n",
      "[10/25][6980/9765] Loss_D: 0.0920 Loss_G: 0.0400 Convergence: 0.0957 k= 0.021959 lr = 0.0000175\n",
      "[10/25][6990/9765] Loss_D: 0.0989 Loss_G: 0.0409 Convergence: 0.1007 k= 0.021932 lr = 0.0000175\n",
      "[10/25][7000/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1003 k= 0.021933 lr = 0.0000175\n",
      "[10/25][7010/9765] Loss_D: 0.0956 Loss_G: 0.0410 Convergence: 0.0988 k= 0.021913 lr = 0.0000175\n",
      "[10/25][7020/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1003 k= 0.021909 lr = 0.0000175\n",
      "[10/25][7030/9765] Loss_D: 0.0926 Loss_G: 0.0404 Convergence: 0.0964 k= 0.021910 lr = 0.0000175\n",
      "[10/25][7040/9765] Loss_D: 0.0996 Loss_G: 0.0393 Convergence: 0.1013 k= 0.021941 lr = 0.0000175\n",
      "[10/25][7050/9765] Loss_D: 0.0919 Loss_G: 0.0407 Convergence: 0.0964 k= 0.021939 lr = 0.0000175\n",
      "[10/25][7060/9765] Loss_D: 0.0982 Loss_G: 0.0429 Convergence: 0.1024 k= 0.021915 lr = 0.0000175\n",
      "[10/25][7070/9765] Loss_D: 0.0914 Loss_G: 0.0423 Convergence: 0.0977 k= 0.021891 lr = 0.0000175\n",
      "[10/25][7080/9765] Loss_D: 0.0996 Loss_G: 0.0375 Convergence: 0.1030 k= 0.021902 lr = 0.0000175\n",
      "[10/25][7090/9765] Loss_D: 0.1152 Loss_G: 0.0385 Convergence: 0.1239 k= 0.021923 lr = 0.0000175\n",
      "[10/25][7100/9765] Loss_D: 0.1015 Loss_G: 0.0353 Convergence: 0.1079 k= 0.021961 lr = 0.0000175\n",
      "[10/25][7110/9765] Loss_D: 0.1015 Loss_G: 0.0400 Convergence: 0.1032 k= 0.021982 lr = 0.0000175\n",
      "[10/25][7120/9765] Loss_D: 0.0939 Loss_G: 0.0509 Convergence: 0.1078 k= 0.021903 lr = 0.0000175\n",
      "[10/25][7130/9765] Loss_D: 0.0966 Loss_G: 0.0404 Convergence: 0.0990 k= 0.021814 lr = 0.0000175\n",
      "[10/25][7140/9765] Loss_D: 0.0913 Loss_G: 0.0371 Convergence: 0.0923 k= 0.021812 lr = 0.0000175\n",
      "[10/25][7150/9765] Loss_D: 0.1062 Loss_G: 0.0348 Convergence: 0.1150 k= 0.021858 lr = 0.0000175\n",
      "[10/25][7160/9765] Loss_D: 0.1001 Loss_G: 0.0365 Convergence: 0.1048 k= 0.021897 lr = 0.0000175\n",
      "[10/25][7170/9765] Loss_D: 0.0987 Loss_G: 0.0395 Convergence: 0.0999 k= 0.021899 lr = 0.0000175\n",
      "[10/25][7180/9765] Loss_D: 0.0941 Loss_G: 0.0407 Convergence: 0.0978 k= 0.021890 lr = 0.0000175\n",
      "[10/25][7190/9765] Loss_D: 0.0944 Loss_G: 0.0422 Convergence: 0.0994 k= 0.021880 lr = 0.0000175\n",
      "[10/25][7200/9765] Loss_D: 0.0950 Loss_G: 0.0412 Convergence: 0.0987 k= 0.021882 lr = 0.0000175\n",
      "[10/25][7210/9765] Loss_D: 0.0909 Loss_G: 0.0369 Convergence: 0.0919 k= 0.021910 lr = 0.0000175\n",
      "[10/25][7220/9765] Loss_D: 0.0967 Loss_G: 0.0420 Convergence: 0.1005 k= 0.021923 lr = 0.0000175\n",
      "[10/25][7230/9765] Loss_D: 0.0862 Loss_G: 0.0414 Convergence: 0.0936 k= 0.021895 lr = 0.0000175\n",
      "[10/25][7240/9765] Loss_D: 0.0908 Loss_G: 0.0397 Convergence: 0.0947 k= 0.021888 lr = 0.0000175\n",
      "[10/25][7250/9765] Loss_D: 0.0977 Loss_G: 0.0382 Convergence: 0.0998 k= 0.021885 lr = 0.0000175\n",
      "[10/25][7260/9765] Loss_D: 0.0948 Loss_G: 0.0393 Convergence: 0.0967 k= 0.021898 lr = 0.0000175\n",
      "[10/25][7270/9765] Loss_D: 0.1023 Loss_G: 0.0394 Convergence: 0.1049 k= 0.021892 lr = 0.0000175\n",
      "[10/25][7280/9765] Loss_D: 0.0988 Loss_G: 0.0391 Convergence: 0.1005 k= 0.021884 lr = 0.0000175\n",
      "[10/25][7290/9765] Loss_D: 0.1004 Loss_G: 0.0398 Convergence: 0.1020 k= 0.021890 lr = 0.0000175\n",
      "[10/25][7300/9765] Loss_D: 0.1060 Loss_G: 0.0377 Convergence: 0.1120 k= 0.021903 lr = 0.0000175\n",
      "[10/25][7310/9765] Loss_D: 0.0940 Loss_G: 0.0364 Convergence: 0.0963 k= 0.021943 lr = 0.0000175\n",
      "[10/25][7320/9765] Loss_D: 0.0904 Loss_G: 0.0402 Convergence: 0.0950 k= 0.021940 lr = 0.0000175\n",
      "[10/25][7330/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0988 k= 0.021938 lr = 0.0000175\n",
      "[10/25][7340/9765] Loss_D: 0.0956 Loss_G: 0.0359 Convergence: 0.0990 k= 0.021955 lr = 0.0000175\n",
      "[10/25][7350/9765] Loss_D: 0.1036 Loss_G: 0.0390 Convergence: 0.1073 k= 0.021960 lr = 0.0000166\n",
      "[10/25][7360/9765] Loss_D: 0.1016 Loss_G: 0.0419 Convergence: 0.1035 k= 0.021943 lr = 0.0000166\n",
      "[10/25][7370/9765] Loss_D: 0.0876 Loss_G: 0.0396 Convergence: 0.0927 k= 0.021918 lr = 0.0000166\n",
      "[10/25][7380/9765] Loss_D: 0.0972 Loss_G: 0.0392 Convergence: 0.0981 k= 0.021928 lr = 0.0000166\n",
      "[10/25][7390/9765] Loss_D: 0.0989 Loss_G: 0.0378 Convergence: 0.1018 k= 0.021936 lr = 0.0000166\n",
      "[10/25][7400/9765] Loss_D: 0.0897 Loss_G: 0.0398 Convergence: 0.0942 k= 0.021938 lr = 0.0000166\n",
      "[10/25][7410/9765] Loss_D: 0.0987 Loss_G: 0.0387 Convergence: 0.1007 k= 0.021953 lr = 0.0000166\n",
      "[10/25][7420/9765] Loss_D: 0.0958 Loss_G: 0.0362 Convergence: 0.0992 k= 0.021949 lr = 0.0000166\n",
      "[10/25][7430/9765] Loss_D: 0.0939 Loss_G: 0.0390 Convergence: 0.0959 k= 0.021970 lr = 0.0000166\n",
      "[10/25][7440/9765] Loss_D: 0.1015 Loss_G: 0.0389 Convergence: 0.1043 k= 0.021952 lr = 0.0000166\n",
      "[10/25][7450/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0976 k= 0.021961 lr = 0.0000166\n",
      "[10/25][7460/9765] Loss_D: 0.0951 Loss_G: 0.0415 Convergence: 0.0991 k= 0.021956 lr = 0.0000166\n",
      "[10/25][7470/9765] Loss_D: 0.0955 Loss_G: 0.0361 Convergence: 0.0988 k= 0.021971 lr = 0.0000166\n",
      "[10/25][7480/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1032 k= 0.021986 lr = 0.0000166\n",
      "[10/25][7490/9765] Loss_D: 0.0955 Loss_G: 0.0413 Convergence: 0.0992 k= 0.021974 lr = 0.0000166\n",
      "[10/25][7500/9765] Loss_D: 0.0869 Loss_G: 0.0401 Convergence: 0.0928 k= 0.021954 lr = 0.0000166\n",
      "[10/25][7510/9765] Loss_D: 0.1061 Loss_G: 0.0408 Convergence: 0.1089 k= 0.021955 lr = 0.0000166\n",
      "[10/25][7520/9765] Loss_D: 0.0990 Loss_G: 0.0399 Convergence: 0.1000 k= 0.021955 lr = 0.0000166\n",
      "[10/25][7530/9765] Loss_D: 0.1013 Loss_G: 0.0391 Convergence: 0.1039 k= 0.021942 lr = 0.0000166\n",
      "[10/25][7540/9765] Loss_D: 0.1083 Loss_G: 0.0413 Convergence: 0.1116 k= 0.021954 lr = 0.0000166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][7550/9765] Loss_D: 0.1011 Loss_G: 0.0406 Convergence: 0.1022 k= 0.021956 lr = 0.0000166\n",
      "[10/25][7560/9765] Loss_D: 0.0905 Loss_G: 0.0387 Convergence: 0.0935 k= 0.021955 lr = 0.0000166\n",
      "[10/25][7570/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0946 k= 0.021963 lr = 0.0000166\n",
      "[10/25][7580/9765] Loss_D: 0.0992 Loss_G: 0.0385 Convergence: 0.1016 k= 0.021973 lr = 0.0000166\n",
      "[10/25][7590/9765] Loss_D: 0.0916 Loss_G: 0.0393 Convergence: 0.0948 k= 0.021967 lr = 0.0000166\n",
      "[10/25][7600/9765] Loss_D: 0.0945 Loss_G: 0.0400 Convergence: 0.0973 k= 0.021963 lr = 0.0000166\n",
      "[10/25][7610/9765] Loss_D: 0.0997 Loss_G: 0.0418 Convergence: 0.1022 k= 0.021950 lr = 0.0000166\n",
      "[10/25][7620/9765] Loss_D: 0.0997 Loss_G: 0.0384 Convergence: 0.1024 k= 0.021958 lr = 0.0000166\n",
      "[10/25][7630/9765] Loss_D: 0.1050 Loss_G: 0.0366 Convergence: 0.1115 k= 0.021966 lr = 0.0000166\n",
      "[10/25][7640/9765] Loss_D: 0.0926 Loss_G: 0.0388 Convergence: 0.0949 k= 0.021987 lr = 0.0000166\n",
      "[10/25][7650/9765] Loss_D: 0.0906 Loss_G: 0.0384 Convergence: 0.0933 k= 0.022005 lr = 0.0000166\n",
      "[10/25][7660/9765] Loss_D: 0.0983 Loss_G: 0.0413 Convergence: 0.1008 k= 0.021997 lr = 0.0000166\n",
      "[10/25][7670/9765] Loss_D: 0.0920 Loss_G: 0.0398 Convergence: 0.0955 k= 0.022017 lr = 0.0000166\n",
      "[10/25][7680/9765] Loss_D: 0.0991 Loss_G: 0.0387 Convergence: 0.1012 k= 0.022024 lr = 0.0000166\n",
      "[10/25][7690/9765] Loss_D: 0.0949 Loss_G: 0.0422 Convergence: 0.0997 k= 0.022004 lr = 0.0000166\n",
      "[10/25][7700/9765] Loss_D: 0.1033 Loss_G: 0.0389 Convergence: 0.1070 k= 0.022003 lr = 0.0000166\n",
      "[10/25][7710/9765] Loss_D: 0.0991 Loss_G: 0.0417 Convergence: 0.1017 k= 0.022003 lr = 0.0000166\n",
      "[10/25][7720/9765] Loss_D: 0.0953 Loss_G: 0.0406 Convergence: 0.0983 k= 0.021990 lr = 0.0000166\n",
      "[10/25][7730/9765] Loss_D: 0.0984 Loss_G: 0.0428 Convergence: 0.1024 k= 0.021991 lr = 0.0000166\n",
      "[10/25][7740/9765] Loss_D: 0.0941 Loss_G: 0.0415 Convergence: 0.0985 k= 0.021974 lr = 0.0000166\n",
      "[10/25][7750/9765] Loss_D: 0.1021 Loss_G: 0.0374 Convergence: 0.1066 k= 0.021994 lr = 0.0000166\n",
      "[10/25][7760/9765] Loss_D: 0.0939 Loss_G: 0.0381 Convergence: 0.0949 k= 0.022012 lr = 0.0000166\n",
      "[10/25][7770/9765] Loss_D: 0.1021 Loss_G: 0.0398 Convergence: 0.1044 k= 0.022013 lr = 0.0000166\n",
      "[10/25][7780/9765] Loss_D: 0.1026 Loss_G: 0.0403 Convergence: 0.1046 k= 0.022017 lr = 0.0000166\n",
      "[10/25][7790/9765] Loss_D: 0.0948 Loss_G: 0.0400 Convergence: 0.0974 k= 0.022017 lr = 0.0000166\n",
      "[10/25][7800/9765] Loss_D: 0.0969 Loss_G: 0.0384 Convergence: 0.0985 k= 0.022027 lr = 0.0000166\n",
      "[10/25][7810/9765] Loss_D: 0.1031 Loss_G: 0.0425 Convergence: 0.1049 k= 0.022038 lr = 0.0000166\n",
      "[10/25][7820/9765] Loss_D: 0.0989 Loss_G: 0.0395 Convergence: 0.1001 k= 0.022048 lr = 0.0000166\n",
      "[10/25][7830/9765] Loss_D: 0.0995 Loss_G: 0.0395 Convergence: 0.1010 k= 0.022074 lr = 0.0000166\n",
      "[10/25][7840/9765] Loss_D: 0.0988 Loss_G: 0.0374 Convergence: 0.1021 k= 0.022083 lr = 0.0000166\n",
      "[10/25][7850/9765] Loss_D: 0.1024 Loss_G: 0.0395 Convergence: 0.1050 k= 0.022085 lr = 0.0000166\n",
      "[10/25][7860/9765] Loss_D: 0.1033 Loss_G: 0.0419 Convergence: 0.1044 k= 0.022073 lr = 0.0000166\n",
      "[10/25][7870/9765] Loss_D: 0.0905 Loss_G: 0.0402 Convergence: 0.0950 k= 0.022065 lr = 0.0000166\n",
      "[10/25][7880/9765] Loss_D: 0.0985 Loss_G: 0.0405 Convergence: 0.1001 k= 0.022054 lr = 0.0000166\n",
      "[10/25][7890/9765] Loss_D: 0.0931 Loss_G: 0.0402 Convergence: 0.0966 k= 0.022037 lr = 0.0000166\n",
      "[10/25][7900/9765] Loss_D: 0.1027 Loss_G: 0.0418 Convergence: 0.1040 k= 0.022035 lr = 0.0000166\n",
      "[10/25][7910/9765] Loss_D: 0.0946 Loss_G: 0.0440 Convergence: 0.1013 k= 0.021996 lr = 0.0000166\n",
      "[10/25][7920/9765] Loss_D: 0.0967 Loss_G: 0.0410 Convergence: 0.0995 k= 0.021974 lr = 0.0000166\n",
      "[10/25][7930/9765] Loss_D: 0.1010 Loss_G: 0.0410 Convergence: 0.1021 k= 0.021968 lr = 0.0000166\n",
      "[10/25][7940/9765] Loss_D: 0.1066 Loss_G: 0.0387 Convergence: 0.1118 k= 0.021970 lr = 0.0000166\n",
      "[10/25][7950/9765] Loss_D: 0.0860 Loss_G: 0.0383 Convergence: 0.0904 k= 0.021964 lr = 0.0000166\n",
      "[10/25][7960/9765] Loss_D: 0.1036 Loss_G: 0.0465 Convergence: 0.1092 k= 0.021948 lr = 0.0000166\n",
      "[10/25][7970/9765] Loss_D: 0.0937 Loss_G: 0.0422 Convergence: 0.0990 k= 0.021910 lr = 0.0000166\n",
      "[10/25][7980/9765] Loss_D: 0.1017 Loss_G: 0.0368 Convergence: 0.1068 k= 0.021911 lr = 0.0000166\n",
      "[10/25][7990/9765] Loss_D: 0.1032 Loss_G: 0.0393 Convergence: 0.1062 k= 0.021940 lr = 0.0000166\n",
      "[10/25][8000/9765] Loss_D: 0.0980 Loss_G: 0.0402 Convergence: 0.0995 k= 0.021943 lr = 0.0000166\n",
      "[10/25][8010/9765] Loss_D: 0.0983 Loss_G: 0.0433 Convergence: 0.1028 k= 0.021929 lr = 0.0000166\n",
      "[10/25][8020/9765] Loss_D: 0.1146 Loss_G: 0.0414 Convergence: 0.1203 k= 0.021908 lr = 0.0000166\n",
      "[10/25][8030/9765] Loss_D: 0.1025 Loss_G: 0.0379 Convergence: 0.1068 k= 0.021905 lr = 0.0000166\n",
      "[10/25][8040/9765] Loss_D: 0.1055 Loss_G: 0.0353 Convergence: 0.1134 k= 0.021924 lr = 0.0000166\n",
      "[10/25][8050/9765] Loss_D: 0.0959 Loss_G: 0.0381 Convergence: 0.0973 k= 0.021952 lr = 0.0000166\n",
      "[10/25][8060/9765] Loss_D: 0.0932 Loss_G: 0.0382 Convergence: 0.0947 k= 0.021957 lr = 0.0000166\n",
      "[10/25][8070/9765] Loss_D: 0.0998 Loss_G: 0.0380 Convergence: 0.1029 k= 0.021963 lr = 0.0000166\n",
      "[10/25][8080/9765] Loss_D: 0.1071 Loss_G: 0.0388 Convergence: 0.1122 k= 0.021956 lr = 0.0000166\n",
      "[10/25][8090/9765] Loss_D: 0.1042 Loss_G: 0.0393 Convergence: 0.1077 k= 0.021959 lr = 0.0000166\n",
      "[10/25][8100/9765] Loss_D: 0.1007 Loss_G: 0.0413 Convergence: 0.1023 k= 0.021962 lr = 0.0000166\n",
      "[10/25][8110/9765] Loss_D: 0.0989 Loss_G: 0.0380 Convergence: 0.1016 k= 0.021983 lr = 0.0000166\n",
      "[10/25][8120/9765] Loss_D: 0.0991 Loss_G: 0.0406 Convergence: 0.1006 k= 0.021983 lr = 0.0000166\n",
      "[10/25][8130/9765] Loss_D: 0.1036 Loss_G: 0.0436 Convergence: 0.1063 k= 0.021963 lr = 0.0000166\n",
      "[10/25][8140/9765] Loss_D: 0.0932 Loss_G: 0.0360 Convergence: 0.0956 k= 0.021958 lr = 0.0000166\n",
      "[10/25][8150/9765] Loss_D: 0.1003 Loss_G: 0.0370 Convergence: 0.1046 k= 0.021988 lr = 0.0000166\n",
      "[10/25][8160/9765] Loss_D: 0.1039 Loss_G: 0.0417 Convergence: 0.1051 k= 0.021994 lr = 0.0000166\n",
      "[10/25][8170/9765] Loss_D: 0.1012 Loss_G: 0.0404 Convergence: 0.1025 k= 0.021999 lr = 0.0000166\n",
      "[10/25][8180/9765] Loss_D: 0.1093 Loss_G: 0.0417 Convergence: 0.1127 k= 0.022008 lr = 0.0000166\n",
      "[10/25][8190/9765] Loss_D: 0.0946 Loss_G: 0.0427 Convergence: 0.1000 k= 0.021993 lr = 0.0000166\n",
      "[10/25][8200/9765] Loss_D: 0.1053 Loss_G: 0.0378 Convergence: 0.1108 k= 0.022002 lr = 0.0000166\n",
      "[10/25][8210/9765] Loss_D: 0.0937 Loss_G: 0.0374 Convergence: 0.0950 k= 0.022015 lr = 0.0000166\n",
      "[10/25][8220/9765] Loss_D: 0.0946 Loss_G: 0.0362 Convergence: 0.0974 k= 0.022036 lr = 0.0000166\n",
      "[10/25][8230/9765] Loss_D: 0.1084 Loss_G: 0.0396 Convergence: 0.1134 k= 0.022038 lr = 0.0000166\n",
      "[10/25][8240/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1010 k= 0.022032 lr = 0.0000166\n",
      "[10/25][8250/9765] Loss_D: 0.0961 Loss_G: 0.0400 Convergence: 0.0981 k= 0.022019 lr = 0.0000166\n",
      "[10/25][8260/9765] Loss_D: 0.1076 Loss_G: 0.0409 Convergence: 0.1110 k= 0.022030 lr = 0.0000166\n",
      "[10/25][8270/9765] Loss_D: 0.0960 Loss_G: 0.0377 Convergence: 0.0978 k= 0.022020 lr = 0.0000166\n",
      "[10/25][8280/9765] Loss_D: 0.1013 Loss_G: 0.0417 Convergence: 0.1030 k= 0.022002 lr = 0.0000166\n",
      "[10/25][8290/9765] Loss_D: 0.1021 Loss_G: 0.0418 Convergence: 0.1036 k= 0.021998 lr = 0.0000166\n",
      "[10/25][8300/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0956 k= 0.021977 lr = 0.0000166\n",
      "[10/25][8310/9765] Loss_D: 0.1009 Loss_G: 0.0408 Convergence: 0.1019 k= 0.021977 lr = 0.0000166\n",
      "[10/25][8320/9765] Loss_D: 0.0903 Loss_G: 0.0425 Convergence: 0.0972 k= 0.021960 lr = 0.0000166\n",
      "[10/25][8330/9765] Loss_D: 0.0955 Loss_G: 0.0385 Convergence: 0.0965 k= 0.021928 lr = 0.0000166\n",
      "[10/25][8340/9765] Loss_D: 0.0996 Loss_G: 0.0385 Convergence: 0.1021 k= 0.021938 lr = 0.0000166\n",
      "[10/25][8350/9765] Loss_D: 0.1007 Loss_G: 0.0393 Convergence: 0.1029 k= 0.021942 lr = 0.0000166\n",
      "[10/25][8360/9765] Loss_D: 0.1046 Loss_G: 0.0386 Convergence: 0.1090 k= 0.021954 lr = 0.0000166\n",
      "[10/25][8370/9765] Loss_D: 0.1102 Loss_G: 0.0358 Convergence: 0.1195 k= 0.021980 lr = 0.0000166\n",
      "[10/25][8380/9765] Loss_D: 0.0945 Loss_G: 0.0404 Convergence: 0.0976 k= 0.021980 lr = 0.0000166\n",
      "[10/25][8390/9765] Loss_D: 0.0979 Loss_G: 0.0390 Convergence: 0.0992 k= 0.021963 lr = 0.0000166\n",
      "[10/25][8400/9765] Loss_D: 0.0950 Loss_G: 0.0423 Convergence: 0.0998 k= 0.021942 lr = 0.0000166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][8410/9765] Loss_D: 0.1088 Loss_G: 0.0389 Convergence: 0.1146 k= 0.021944 lr = 0.0000166\n",
      "[10/25][8420/9765] Loss_D: 0.0969 Loss_G: 0.0348 Convergence: 0.1019 k= 0.021973 lr = 0.0000166\n",
      "[10/25][8430/9765] Loss_D: 0.1063 Loss_G: 0.0355 Convergence: 0.1144 k= 0.022007 lr = 0.0000166\n",
      "[10/25][8440/9765] Loss_D: 0.1113 Loss_G: 0.0433 Convergence: 0.1138 k= 0.022007 lr = 0.0000166\n",
      "[10/25][8450/9765] Loss_D: 0.0915 Loss_G: 0.0411 Convergence: 0.0965 k= 0.021953 lr = 0.0000166\n",
      "[10/25][8460/9765] Loss_D: 0.0964 Loss_G: 0.0364 Convergence: 0.0997 k= 0.021957 lr = 0.0000166\n",
      "[10/25][8470/9765] Loss_D: 0.1057 Loss_G: 0.0379 Convergence: 0.1112 k= 0.021985 lr = 0.0000166\n",
      "[10/25][8480/9765] Loss_D: 0.1018 Loss_G: 0.0390 Convergence: 0.1046 k= 0.022011 lr = 0.0000166\n",
      "[10/25][8490/9765] Loss_D: 0.0960 Loss_G: 0.0398 Convergence: 0.0979 k= 0.022003 lr = 0.0000166\n",
      "[10/25][8500/9765] Loss_D: 0.0967 Loss_G: 0.0439 Convergence: 0.1025 k= 0.021987 lr = 0.0000166\n",
      "[10/25][8510/9765] Loss_D: 0.0986 Loss_G: 0.0395 Convergence: 0.0998 k= 0.021974 lr = 0.0000166\n",
      "[10/25][8520/9765] Loss_D: 0.1065 Loss_G: 0.0383 Convergence: 0.1120 k= 0.021980 lr = 0.0000166\n",
      "[10/25][8530/9765] Loss_D: 0.0973 Loss_G: 0.0379 Convergence: 0.0995 k= 0.021991 lr = 0.0000166\n",
      "[10/25][8540/9765] Loss_D: 0.0990 Loss_G: 0.0388 Convergence: 0.1011 k= 0.022009 lr = 0.0000166\n",
      "[10/25][8550/9765] Loss_D: 0.1041 Loss_G: 0.0382 Convergence: 0.1088 k= 0.022012 lr = 0.0000166\n",
      "[10/25][8560/9765] Loss_D: 0.0922 Loss_G: 0.0384 Convergence: 0.0942 k= 0.022014 lr = 0.0000166\n",
      "[10/25][8570/9765] Loss_D: 0.0922 Loss_G: 0.0396 Convergence: 0.0955 k= 0.022019 lr = 0.0000166\n",
      "[10/25][8580/9765] Loss_D: 0.0914 Loss_G: 0.0400 Convergence: 0.0954 k= 0.022012 lr = 0.0000166\n",
      "[10/25][8590/9765] Loss_D: 0.1016 Loss_G: 0.0397 Convergence: 0.1037 k= 0.022011 lr = 0.0000166\n",
      "[10/25][8600/9765] Loss_D: 0.1058 Loss_G: 0.0361 Convergence: 0.1131 k= 0.022013 lr = 0.0000166\n",
      "[10/25][8610/9765] Loss_D: 0.0953 Loss_G: 0.0388 Convergence: 0.0965 k= 0.022030 lr = 0.0000166\n",
      "[10/25][8620/9765] Loss_D: 0.0982 Loss_G: 0.0378 Convergence: 0.1009 k= 0.022031 lr = 0.0000166\n",
      "[10/25][8630/9765] Loss_D: 0.0967 Loss_G: 0.0396 Convergence: 0.0981 k= 0.022035 lr = 0.0000166\n",
      "[10/25][8640/9765] Loss_D: 0.1020 Loss_G: 0.0393 Convergence: 0.1047 k= 0.022054 lr = 0.0000166\n",
      "[10/25][8650/9765] Loss_D: 0.0924 Loss_G: 0.0424 Convergence: 0.0983 k= 0.022038 lr = 0.0000166\n",
      "[10/25][8660/9765] Loss_D: 0.1004 Loss_G: 0.0412 Convergence: 0.1020 k= 0.022020 lr = 0.0000166\n",
      "[10/25][8670/9765] Loss_D: 0.0909 Loss_G: 0.0388 Convergence: 0.0939 k= 0.022011 lr = 0.0000166\n",
      "[10/25][8680/9765] Loss_D: 0.0985 Loss_G: 0.0387 Convergence: 0.1003 k= 0.022012 lr = 0.0000166\n",
      "[10/25][8690/9765] Loss_D: 0.0952 Loss_G: 0.0391 Convergence: 0.0968 k= 0.022008 lr = 0.0000166\n",
      "[10/25][8700/9765] Loss_D: 0.0960 Loss_G: 0.0446 Convergence: 0.1027 k= 0.021999 lr = 0.0000166\n",
      "[10/25][8710/9765] Loss_D: 0.1014 Loss_G: 0.0436 Convergence: 0.1050 k= 0.021981 lr = 0.0000166\n",
      "[10/25][8720/9765] Loss_D: 0.0989 Loss_G: 0.0401 Convergence: 0.1000 k= 0.021965 lr = 0.0000166\n",
      "[10/25][8730/9765] Loss_D: 0.0957 Loss_G: 0.0364 Convergence: 0.0987 k= 0.021958 lr = 0.0000166\n",
      "[10/25][8740/9765] Loss_D: 0.0965 Loss_G: 0.0386 Convergence: 0.0976 k= 0.021966 lr = 0.0000166\n",
      "[10/25][8750/9765] Loss_D: 0.0916 Loss_G: 0.0373 Convergence: 0.0928 k= 0.021964 lr = 0.0000166\n",
      "[10/25][8760/9765] Loss_D: 0.0966 Loss_G: 0.0416 Convergence: 0.1001 k= 0.021974 lr = 0.0000166\n",
      "[10/25][8770/9765] Loss_D: 0.1081 Loss_G: 0.0405 Convergence: 0.1121 k= 0.021981 lr = 0.0000166\n",
      "[10/25][8780/9765] Loss_D: 0.0995 Loss_G: 0.0407 Convergence: 0.1010 k= 0.021970 lr = 0.0000166\n",
      "[10/25][8790/9765] Loss_D: 0.0985 Loss_G: 0.0387 Convergence: 0.1004 k= 0.021961 lr = 0.0000166\n",
      "[10/25][8800/9765] Loss_D: 0.0950 Loss_G: 0.0414 Convergence: 0.0989 k= 0.021969 lr = 0.0000166\n",
      "[10/25][8810/9765] Loss_D: 0.0920 Loss_G: 0.0365 Convergence: 0.0934 k= 0.021969 lr = 0.0000166\n",
      "[10/25][8820/9765] Loss_D: 0.1013 Loss_G: 0.0413 Convergence: 0.1026 k= 0.021962 lr = 0.0000166\n",
      "[10/25][8830/9765] Loss_D: 0.0977 Loss_G: 0.0401 Convergence: 0.0993 k= 0.021945 lr = 0.0000166\n",
      "[10/25][8840/9765] Loss_D: 0.0932 Loss_G: 0.0433 Convergence: 0.0998 k= 0.021929 lr = 0.0000166\n",
      "[10/25][8850/9765] Loss_D: 0.0948 Loss_G: 0.0401 Convergence: 0.0975 k= 0.021914 lr = 0.0000166\n",
      "[10/25][8860/9765] Loss_D: 0.0965 Loss_G: 0.0387 Convergence: 0.0977 k= 0.021905 lr = 0.0000166\n",
      "[10/25][8870/9765] Loss_D: 0.0944 Loss_G: 0.0395 Convergence: 0.0967 k= 0.021917 lr = 0.0000166\n",
      "[10/25][8880/9765] Loss_D: 0.0908 Loss_G: 0.0373 Convergence: 0.0923 k= 0.021933 lr = 0.0000166\n",
      "[10/25][8890/9765] Loss_D: 0.1023 Loss_G: 0.0398 Convergence: 0.1046 k= 0.021932 lr = 0.0000166\n",
      "[10/25][8900/9765] Loss_D: 0.0930 Loss_G: 0.0385 Convergence: 0.0948 k= 0.021937 lr = 0.0000166\n",
      "[10/25][8910/9765] Loss_D: 0.0894 Loss_G: 0.0388 Convergence: 0.0930 k= 0.021958 lr = 0.0000166\n",
      "[10/25][8920/9765] Loss_D: 0.0993 Loss_G: 0.0400 Convergence: 0.1003 k= 0.021974 lr = 0.0000166\n",
      "[10/25][8930/9765] Loss_D: 0.0996 Loss_G: 0.0428 Convergence: 0.1032 k= 0.021968 lr = 0.0000166\n",
      "[10/25][8940/9765] Loss_D: 0.0882 Loss_G: 0.0380 Convergence: 0.0914 k= 0.021978 lr = 0.0000166\n",
      "[10/25][8950/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0985 k= 0.021971 lr = 0.0000166\n",
      "[10/25][8960/9765] Loss_D: 0.0936 Loss_G: 0.0392 Convergence: 0.0959 k= 0.021949 lr = 0.0000166\n",
      "[10/25][8970/9765] Loss_D: 0.1027 Loss_G: 0.0355 Convergence: 0.1094 k= 0.021988 lr = 0.0000166\n",
      "[10/25][8980/9765] Loss_D: 0.0948 Loss_G: 0.0344 Convergence: 0.0994 k= 0.022017 lr = 0.0000166\n",
      "[10/25][8990/9765] Loss_D: 0.1037 Loss_G: 0.0405 Convergence: 0.1058 k= 0.022032 lr = 0.0000166\n",
      "[10/25][9000/9765] Loss_D: 0.0958 Loss_G: 0.0423 Convergence: 0.1004 k= 0.021999 lr = 0.0000166\n",
      "[10/25][9010/9765] Loss_D: 0.0925 Loss_G: 0.0432 Convergence: 0.0993 k= 0.021969 lr = 0.0000166\n",
      "[10/25][9020/9765] Loss_D: 0.1048 Loss_G: 0.0402 Convergence: 0.1078 k= 0.021939 lr = 0.0000166\n",
      "[10/25][9030/9765] Loss_D: 0.0954 Loss_G: 0.0377 Convergence: 0.0970 k= 0.021932 lr = 0.0000166\n",
      "[10/25][9040/9765] Loss_D: 0.0979 Loss_G: 0.0387 Convergence: 0.0996 k= 0.021941 lr = 0.0000166\n",
      "[10/25][9050/9765] Loss_D: 0.1106 Loss_G: 0.0428 Convergence: 0.1133 k= 0.021956 lr = 0.0000166\n",
      "[10/25][9060/9765] Loss_D: 0.1013 Loss_G: 0.0409 Convergence: 0.1022 k= 0.021942 lr = 0.0000166\n",
      "[10/25][9070/9765] Loss_D: 0.1023 Loss_G: 0.0415 Convergence: 0.1034 k= 0.021928 lr = 0.0000166\n",
      "[10/25][9080/9765] Loss_D: 0.0961 Loss_G: 0.0403 Convergence: 0.0985 k= 0.021916 lr = 0.0000166\n",
      "[10/25][9090/9765] Loss_D: 0.0980 Loss_G: 0.0375 Convergence: 0.1009 k= 0.021904 lr = 0.0000166\n",
      "[10/25][9100/9765] Loss_D: 0.0925 Loss_G: 0.0364 Convergence: 0.0943 k= 0.021923 lr = 0.0000166\n",
      "[10/25][9110/9765] Loss_D: 0.1059 Loss_G: 0.0431 Convergence: 0.1072 k= 0.021940 lr = 0.0000166\n",
      "[10/25][9120/9765] Loss_D: 0.0961 Loss_G: 0.0385 Convergence: 0.0971 k= 0.021945 lr = 0.0000166\n",
      "[10/25][9130/9765] Loss_D: 0.0974 Loss_G: 0.0382 Convergence: 0.0994 k= 0.021959 lr = 0.0000166\n",
      "[10/25][9140/9765] Loss_D: 0.1090 Loss_G: 0.0379 Convergence: 0.1159 k= 0.021955 lr = 0.0000166\n",
      "[10/25][9150/9765] Loss_D: 0.0994 Loss_G: 0.0391 Convergence: 0.1012 k= 0.021981 lr = 0.0000166\n",
      "[10/25][9160/9765] Loss_D: 0.0986 Loss_G: 0.0364 Convergence: 0.1028 k= 0.021999 lr = 0.0000166\n",
      "[10/25][9170/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1057 k= 0.022013 lr = 0.0000166\n",
      "[10/25][9180/9765] Loss_D: 0.0895 Loss_G: 0.0413 Convergence: 0.0955 k= 0.022008 lr = 0.0000166\n",
      "[10/25][9190/9765] Loss_D: 0.0899 Loss_G: 0.0380 Convergence: 0.0924 k= 0.021999 lr = 0.0000166\n",
      "[10/25][9200/9765] Loss_D: 0.1005 Loss_G: 0.0385 Convergence: 0.1035 k= 0.022008 lr = 0.0000166\n",
      "[10/25][9210/9765] Loss_D: 0.0966 Loss_G: 0.0393 Convergence: 0.0977 k= 0.021996 lr = 0.0000166\n",
      "[10/25][9220/9765] Loss_D: 0.0940 Loss_G: 0.0388 Convergence: 0.0956 k= 0.022010 lr = 0.0000166\n",
      "[10/25][9230/9765] Loss_D: 0.0930 Loss_G: 0.0397 Convergence: 0.0961 k= 0.021995 lr = 0.0000166\n",
      "[10/25][9240/9765] Loss_D: 0.0931 Loss_G: 0.0385 Convergence: 0.0949 k= 0.022008 lr = 0.0000166\n",
      "[10/25][9250/9765] Loss_D: 0.0972 Loss_G: 0.0392 Convergence: 0.0982 k= 0.022015 lr = 0.0000166\n",
      "[10/25][9260/9765] Loss_D: 0.0936 Loss_G: 0.0385 Convergence: 0.0952 k= 0.022019 lr = 0.0000166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/25][9270/9765] Loss_D: 0.0985 Loss_G: 0.0386 Convergence: 0.1005 k= 0.022026 lr = 0.0000166\n",
      "[10/25][9280/9765] Loss_D: 0.1004 Loss_G: 0.0388 Convergence: 0.1029 k= 0.022033 lr = 0.0000166\n",
      "[10/25][9290/9765] Loss_D: 0.0943 Loss_G: 0.0424 Convergence: 0.0995 k= 0.022015 lr = 0.0000166\n",
      "[10/25][9300/9765] Loss_D: 0.1015 Loss_G: 0.0417 Convergence: 0.1031 k= 0.022001 lr = 0.0000166\n",
      "[10/25][9310/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0978 k= 0.021979 lr = 0.0000166\n",
      "[10/25][9320/9765] Loss_D: 0.0871 Loss_G: 0.0382 Convergence: 0.0910 k= 0.021972 lr = 0.0000166\n",
      "[10/25][9330/9765] Loss_D: 0.0981 Loss_G: 0.0398 Convergence: 0.0992 k= 0.021975 lr = 0.0000166\n",
      "[10/25][9340/9765] Loss_D: 0.1042 Loss_G: 0.0390 Convergence: 0.1081 k= 0.021967 lr = 0.0000166\n",
      "[10/25][9350/9765] Loss_D: 0.0989 Loss_G: 0.0381 Convergence: 0.1016 k= 0.021971 lr = 0.0000166\n",
      "[10/25][9360/9765] Loss_D: 0.1036 Loss_G: 0.0395 Convergence: 0.1068 k= 0.021983 lr = 0.0000166\n",
      "[10/25][9370/9765] Loss_D: 0.0945 Loss_G: 0.0386 Convergence: 0.0957 k= 0.021997 lr = 0.0000166\n",
      "[10/25][9380/9765] Loss_D: 0.1001 Loss_G: 0.0390 Convergence: 0.1024 k= 0.022012 lr = 0.0000166\n",
      "[10/25][9390/9765] Loss_D: 0.0927 Loss_G: 0.0388 Convergence: 0.0950 k= 0.022010 lr = 0.0000166\n",
      "[10/25][9400/9765] Loss_D: 0.1008 Loss_G: 0.0391 Convergence: 0.1032 k= 0.022003 lr = 0.0000166\n",
      "[10/25][9410/9765] Loss_D: 0.1107 Loss_G: 0.0404 Convergence: 0.1159 k= 0.022012 lr = 0.0000166\n",
      "[10/25][9420/9765] Loss_D: 0.0969 Loss_G: 0.0373 Convergence: 0.0996 k= 0.022015 lr = 0.0000166\n",
      "[10/25][9430/9765] Loss_D: 0.1136 Loss_G: 0.0384 Convergence: 0.1218 k= 0.022016 lr = 0.0000166\n",
      "[10/25][9440/9765] Loss_D: 0.0960 Loss_G: 0.0397 Convergence: 0.0978 k= 0.022007 lr = 0.0000166\n",
      "[10/25][9450/9765] Loss_D: 0.0973 Loss_G: 0.0403 Convergence: 0.0992 k= 0.021990 lr = 0.0000166\n",
      "[10/25][9460/9765] Loss_D: 0.1000 Loss_G: 0.0372 Convergence: 0.1040 k= 0.021996 lr = 0.0000166\n",
      "[10/25][9470/9765] Loss_D: 0.0941 Loss_G: 0.0393 Convergence: 0.0962 k= 0.022010 lr = 0.0000166\n",
      "[10/25][9480/9765] Loss_D: 0.0933 Loss_G: 0.0372 Convergence: 0.0946 k= 0.022029 lr = 0.0000166\n",
      "[10/25][9490/9765] Loss_D: 0.1032 Loss_G: 0.0395 Convergence: 0.1062 k= 0.022033 lr = 0.0000166\n",
      "[10/25][9500/9765] Loss_D: 0.1015 Loss_G: 0.0407 Convergence: 0.1026 k= 0.022026 lr = 0.0000166\n",
      "[10/25][9510/9765] Loss_D: 0.0981 Loss_G: 0.0419 Convergence: 0.1014 k= 0.022007 lr = 0.0000166\n",
      "[10/25][9520/9765] Loss_D: 0.0949 Loss_G: 0.0416 Convergence: 0.0990 k= 0.021994 lr = 0.0000166\n",
      "[10/25][9530/9765] Loss_D: 0.0948 Loss_G: 0.0386 Convergence: 0.0960 k= 0.021997 lr = 0.0000166\n",
      "[10/25][9540/9765] Loss_D: 0.0982 Loss_G: 0.0390 Convergence: 0.0997 k= 0.022000 lr = 0.0000166\n",
      "[10/25][9550/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1004 k= 0.021999 lr = 0.0000166\n",
      "[10/25][9560/9765] Loss_D: 0.1036 Loss_G: 0.0406 Convergence: 0.1057 k= 0.021988 lr = 0.0000166\n",
      "[10/25][9570/9765] Loss_D: 0.0925 Loss_G: 0.0410 Convergence: 0.0970 k= 0.021968 lr = 0.0000166\n",
      "[10/25][9580/9765] Loss_D: 0.0889 Loss_G: 0.0397 Convergence: 0.0935 k= 0.021944 lr = 0.0000166\n",
      "[10/25][9590/9765] Loss_D: 0.0912 Loss_G: 0.0408 Convergence: 0.0960 k= 0.021963 lr = 0.0000166\n",
      "[10/25][9600/9765] Loss_D: 0.1061 Loss_G: 0.0420 Convergence: 0.1077 k= 0.021959 lr = 0.0000166\n",
      "[10/25][9610/9765] Loss_D: 0.0914 Loss_G: 0.0395 Convergence: 0.0949 k= 0.021963 lr = 0.0000166\n",
      "[10/25][9620/9765] Loss_D: 0.1046 Loss_G: 0.0403 Convergence: 0.1075 k= 0.021939 lr = 0.0000166\n",
      "[10/25][9630/9765] Loss_D: 0.0866 Loss_G: 0.0367 Convergence: 0.0892 k= 0.021924 lr = 0.0000166\n",
      "[10/25][9640/9765] Loss_D: 0.1010 Loss_G: 0.0389 Convergence: 0.1037 k= 0.021945 lr = 0.0000166\n",
      "[10/25][9650/9765] Loss_D: 0.0965 Loss_G: 0.0381 Convergence: 0.0981 k= 0.021949 lr = 0.0000166\n",
      "[10/25][9660/9765] Loss_D: 0.1012 Loss_G: 0.0383 Convergence: 0.1046 k= 0.021943 lr = 0.0000166\n",
      "[10/25][9670/9765] Loss_D: 0.0951 Loss_G: 0.0417 Convergence: 0.0992 k= 0.021950 lr = 0.0000166\n",
      "[10/25][9680/9765] Loss_D: 0.0990 Loss_G: 0.0404 Convergence: 0.1004 k= 0.021928 lr = 0.0000166\n",
      "[10/25][9690/9765] Loss_D: 0.0894 Loss_G: 0.0396 Convergence: 0.0938 k= 0.021923 lr = 0.0000166\n",
      "[10/25][9700/9765] Loss_D: 0.1018 Loss_G: 0.0413 Convergence: 0.1029 k= 0.021919 lr = 0.0000166\n",
      "[10/25][9710/9765] Loss_D: 0.0977 Loss_G: 0.0406 Convergence: 0.0998 k= 0.021910 lr = 0.0000166\n",
      "[10/25][9720/9765] Loss_D: 0.0984 Loss_G: 0.0364 Convergence: 0.1025 k= 0.021905 lr = 0.0000166\n",
      "[10/25][9730/9765] Loss_D: 0.0826 Loss_G: 0.0403 Convergence: 0.0904 k= 0.021909 lr = 0.0000166\n",
      "[10/25][9740/9765] Loss_D: 0.0886 Loss_G: 0.0404 Convergence: 0.0941 k= 0.021895 lr = 0.0000166\n",
      "[10/25][9750/9765] Loss_D: 0.1025 Loss_G: 0.0396 Convergence: 0.1053 k= 0.021893 lr = 0.0000166\n",
      "[10/25][9760/9765] Loss_D: 0.1111 Loss_G: 0.0382 Convergence: 0.1185 k= 0.021909 lr = 0.0000166\n",
      "[11/25][0/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0986 k= 0.021906 lr = 0.0000166\n",
      "[11/25][10/9765] Loss_D: 0.1076 Loss_G: 0.0391 Convergence: 0.1127 k= 0.021910 lr = 0.0000166\n",
      "[11/25][20/9765] Loss_D: 0.0962 Loss_G: 0.0407 Convergence: 0.0990 k= 0.021896 lr = 0.0000166\n",
      "[11/25][30/9765] Loss_D: 0.0954 Loss_G: 0.0398 Convergence: 0.0975 k= 0.021882 lr = 0.0000166\n",
      "[11/25][40/9765] Loss_D: 0.0974 Loss_G: 0.0416 Convergence: 0.1007 k= 0.021884 lr = 0.0000166\n",
      "[11/25][50/9765] Loss_D: 0.1046 Loss_G: 0.0411 Convergence: 0.1066 k= 0.021875 lr = 0.0000166\n",
      "[11/25][60/9765] Loss_D: 0.1040 Loss_G: 0.0387 Convergence: 0.1081 k= 0.021860 lr = 0.0000166\n",
      "[11/25][70/9765] Loss_D: 0.0930 Loss_G: 0.0397 Convergence: 0.0960 k= 0.021864 lr = 0.0000166\n",
      "[11/25][80/9765] Loss_D: 0.0997 Loss_G: 0.0375 Convergence: 0.1032 k= 0.021892 lr = 0.0000166\n",
      "[11/25][90/9765] Loss_D: 0.0867 Loss_G: 0.0388 Convergence: 0.0913 k= 0.021873 lr = 0.0000166\n",
      "[11/25][100/9765] Loss_D: 0.0951 Loss_G: 0.0393 Convergence: 0.0968 k= 0.021882 lr = 0.0000166\n",
      "[11/25][110/9765] Loss_D: 0.1036 Loss_G: 0.0418 Convergence: 0.1046 k= 0.021859 lr = 0.0000166\n",
      "[11/25][120/9765] Loss_D: 0.1095 Loss_G: 0.0419 Convergence: 0.1126 k= 0.021847 lr = 0.0000166\n",
      "[11/25][130/9765] Loss_D: 0.0962 Loss_G: 0.0346 Convergence: 0.1012 k= 0.021863 lr = 0.0000166\n",
      "[11/25][140/9765] Loss_D: 0.0883 Loss_G: 0.0370 Convergence: 0.0905 k= 0.021883 lr = 0.0000166\n",
      "[11/25][150/9765] Loss_D: 0.0914 Loss_G: 0.0382 Convergence: 0.0936 k= 0.021890 lr = 0.0000166\n",
      "[11/25][160/9765] Loss_D: 0.0937 Loss_G: 0.0386 Convergence: 0.0954 k= 0.021899 lr = 0.0000166\n",
      "[11/25][170/9765] Loss_D: 0.1085 Loss_G: 0.0395 Convergence: 0.1136 k= 0.021892 lr = 0.0000166\n",
      "[11/25][180/9765] Loss_D: 0.1075 Loss_G: 0.0416 Convergence: 0.1102 k= 0.021902 lr = 0.0000166\n",
      "[11/25][190/9765] Loss_D: 0.1015 Loss_G: 0.0376 Convergence: 0.1055 k= 0.021905 lr = 0.0000166\n",
      "[11/25][200/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.021915 lr = 0.0000166\n",
      "[11/25][210/9765] Loss_D: 0.0974 Loss_G: 0.0399 Convergence: 0.0988 k= 0.021916 lr = 0.0000166\n",
      "[11/25][220/9765] Loss_D: 0.0939 Loss_G: 0.0459 Convergence: 0.1028 k= 0.021873 lr = 0.0000166\n",
      "[11/25][230/9765] Loss_D: 0.0948 Loss_G: 0.0442 Convergence: 0.1017 k= 0.021808 lr = 0.0000166\n",
      "[11/25][240/9765] Loss_D: 0.0963 Loss_G: 0.0415 Convergence: 0.0998 k= 0.021777 lr = 0.0000166\n",
      "[11/25][250/9765] Loss_D: 0.1001 Loss_G: 0.0368 Convergence: 0.1045 k= 0.021767 lr = 0.0000166\n",
      "[11/25][260/9765] Loss_D: 0.1000 Loss_G: 0.0389 Convergence: 0.1022 k= 0.021798 lr = 0.0000166\n",
      "[11/25][270/9765] Loss_D: 0.1058 Loss_G: 0.0397 Convergence: 0.1096 k= 0.021811 lr = 0.0000166\n",
      "[11/25][280/9765] Loss_D: 0.1026 Loss_G: 0.0368 Convergence: 0.1080 k= 0.021808 lr = 0.0000166\n",
      "[11/25][290/9765] Loss_D: 0.0991 Loss_G: 0.0394 Convergence: 0.1005 k= 0.021825 lr = 0.0000166\n",
      "[11/25][300/9765] Loss_D: 0.1054 Loss_G: 0.0433 Convergence: 0.1071 k= 0.021809 lr = 0.0000166\n",
      "[11/25][310/9765] Loss_D: 0.0937 Loss_G: 0.0403 Convergence: 0.0970 k= 0.021791 lr = 0.0000166\n",
      "[11/25][320/9765] Loss_D: 0.0950 Loss_G: 0.0417 Convergence: 0.0993 k= 0.021770 lr = 0.0000166\n",
      "[11/25][330/9765] Loss_D: 0.0923 Loss_G: 0.0375 Convergence: 0.0934 k= 0.021770 lr = 0.0000166\n",
      "[11/25][340/9765] Loss_D: 0.1010 Loss_G: 0.0427 Convergence: 0.1038 k= 0.021777 lr = 0.0000166\n",
      "[11/25][350/9765] Loss_D: 0.0971 Loss_G: 0.0434 Convergence: 0.1023 k= 0.021764 lr = 0.0000166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][360/9765] Loss_D: 0.0913 Loss_G: 0.0397 Convergence: 0.0950 k= 0.021737 lr = 0.0000166\n",
      "[11/25][370/9765] Loss_D: 0.1069 Loss_G: 0.0379 Convergence: 0.1129 k= 0.021760 lr = 0.0000166\n",
      "[11/25][380/9765] Loss_D: 0.0919 Loss_G: 0.0361 Convergence: 0.0937 k= 0.021781 lr = 0.0000166\n",
      "[11/25][390/9765] Loss_D: 0.1017 Loss_G: 0.0367 Convergence: 0.1067 k= 0.021807 lr = 0.0000166\n",
      "[11/25][400/9765] Loss_D: 0.0947 Loss_G: 0.0374 Convergence: 0.0963 k= 0.021823 lr = 0.0000166\n",
      "[11/25][410/9765] Loss_D: 0.0958 Loss_G: 0.0389 Convergence: 0.0968 k= 0.021830 lr = 0.0000166\n",
      "[11/25][420/9765] Loss_D: 0.0897 Loss_G: 0.0375 Convergence: 0.0918 k= 0.021823 lr = 0.0000166\n",
      "[11/25][430/9765] Loss_D: 0.0976 Loss_G: 0.0397 Convergence: 0.0988 k= 0.021825 lr = 0.0000166\n",
      "[11/25][440/9765] Loss_D: 0.1126 Loss_G: 0.0420 Convergence: 0.1169 k= 0.021815 lr = 0.0000166\n",
      "[11/25][450/9765] Loss_D: 0.0943 Loss_G: 0.0395 Convergence: 0.0966 k= 0.021802 lr = 0.0000166\n",
      "[11/25][460/9765] Loss_D: 0.0865 Loss_G: 0.0379 Convergence: 0.0904 k= 0.021808 lr = 0.0000166\n",
      "[11/25][470/9765] Loss_D: 0.0963 Loss_G: 0.0389 Convergence: 0.0972 k= 0.021812 lr = 0.0000166\n",
      "[11/25][480/9765] Loss_D: 0.1061 Loss_G: 0.0380 Convergence: 0.1116 k= 0.021820 lr = 0.0000166\n",
      "[11/25][490/9765] Loss_D: 0.1002 Loss_G: 0.0406 Convergence: 0.1012 k= 0.021822 lr = 0.0000166\n",
      "[11/25][500/9765] Loss_D: 0.0974 Loss_G: 0.0418 Convergence: 0.1008 k= 0.021807 lr = 0.0000166\n",
      "[11/25][510/9765] Loss_D: 0.1020 Loss_G: 0.0434 Convergence: 0.1051 k= 0.021782 lr = 0.0000166\n",
      "[11/25][520/9765] Loss_D: 0.0913 Loss_G: 0.0408 Convergence: 0.0961 k= 0.021755 lr = 0.0000166\n",
      "[11/25][530/9765] Loss_D: 0.0946 Loss_G: 0.0391 Convergence: 0.0964 k= 0.021746 lr = 0.0000166\n",
      "[11/25][540/9765] Loss_D: 0.0971 Loss_G: 0.0412 Convergence: 0.1000 k= 0.021754 lr = 0.0000166\n",
      "[11/25][550/9765] Loss_D: 0.0975 Loss_G: 0.0387 Convergence: 0.0989 k= 0.021745 lr = 0.0000166\n",
      "[11/25][560/9765] Loss_D: 0.0965 Loss_G: 0.0355 Convergence: 0.1007 k= 0.021751 lr = 0.0000166\n",
      "[11/25][570/9765] Loss_D: 0.0924 Loss_G: 0.0391 Convergence: 0.0950 k= 0.021768 lr = 0.0000166\n",
      "[11/25][580/9765] Loss_D: 0.0897 Loss_G: 0.0406 Convergence: 0.0950 k= 0.021757 lr = 0.0000166\n",
      "[11/25][590/9765] Loss_D: 0.1026 Loss_G: 0.0423 Convergence: 0.1043 k= 0.021743 lr = 0.0000158\n",
      "[11/25][600/9765] Loss_D: 0.0938 Loss_G: 0.0396 Convergence: 0.0964 k= 0.021730 lr = 0.0000158\n",
      "[11/25][610/9765] Loss_D: 0.0973 Loss_G: 0.0388 Convergence: 0.0987 k= 0.021728 lr = 0.0000158\n",
      "[11/25][620/9765] Loss_D: 0.1076 Loss_G: 0.0395 Convergence: 0.1122 k= 0.021737 lr = 0.0000158\n",
      "[11/25][630/9765] Loss_D: 0.0921 Loss_G: 0.0402 Convergence: 0.0959 k= 0.021750 lr = 0.0000158\n",
      "[11/25][640/9765] Loss_D: 0.0974 Loss_G: 0.0399 Convergence: 0.0988 k= 0.021759 lr = 0.0000158\n",
      "[11/25][650/9765] Loss_D: 0.1033 Loss_G: 0.0402 Convergence: 0.1057 k= 0.021761 lr = 0.0000158\n",
      "[11/25][660/9765] Loss_D: 0.0903 Loss_G: 0.0396 Convergence: 0.0943 k= 0.021755 lr = 0.0000158\n",
      "[11/25][670/9765] Loss_D: 0.0983 Loss_G: 0.0395 Convergence: 0.0993 k= 0.021750 lr = 0.0000158\n",
      "[11/25][680/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.021759 lr = 0.0000158\n",
      "[11/25][690/9765] Loss_D: 0.1065 Loss_G: 0.0391 Convergence: 0.1112 k= 0.021755 lr = 0.0000158\n",
      "[11/25][700/9765] Loss_D: 0.0902 Loss_G: 0.0374 Convergence: 0.0921 k= 0.021756 lr = 0.0000158\n",
      "[11/25][710/9765] Loss_D: 0.1016 Loss_G: 0.0384 Convergence: 0.1050 k= 0.021766 lr = 0.0000158\n",
      "[11/25][720/9765] Loss_D: 0.0982 Loss_G: 0.0369 Convergence: 0.1017 k= 0.021770 lr = 0.0000158\n",
      "[11/25][730/9765] Loss_D: 0.1037 Loss_G: 0.0388 Convergence: 0.1075 k= 0.021782 lr = 0.0000158\n",
      "[11/25][740/9765] Loss_D: 0.1010 Loss_G: 0.0401 Convergence: 0.1025 k= 0.021778 lr = 0.0000158\n",
      "[11/25][750/9765] Loss_D: 0.0954 Loss_G: 0.0401 Convergence: 0.0978 k= 0.021766 lr = 0.0000158\n",
      "[11/25][760/9765] Loss_D: 0.1015 Loss_G: 0.0391 Convergence: 0.1042 k= 0.021768 lr = 0.0000158\n",
      "[11/25][770/9765] Loss_D: 0.0949 Loss_G: 0.0370 Convergence: 0.0969 k= 0.021780 lr = 0.0000158\n",
      "[11/25][780/9765] Loss_D: 0.0946 Loss_G: 0.0393 Convergence: 0.0966 k= 0.021787 lr = 0.0000158\n",
      "[11/25][790/9765] Loss_D: 0.0888 Loss_G: 0.0384 Convergence: 0.0922 k= 0.021792 lr = 0.0000158\n",
      "[11/25][800/9765] Loss_D: 0.0985 Loss_G: 0.0451 Convergence: 0.1048 k= 0.021777 lr = 0.0000158\n",
      "[11/25][810/9765] Loss_D: 0.0948 Loss_G: 0.0414 Convergence: 0.0988 k= 0.021770 lr = 0.0000158\n",
      "[11/25][820/9765] Loss_D: 0.0955 Loss_G: 0.0363 Convergence: 0.0984 k= 0.021770 lr = 0.0000158\n",
      "[11/25][830/9765] Loss_D: 0.0963 Loss_G: 0.0360 Convergence: 0.0999 k= 0.021805 lr = 0.0000158\n",
      "[11/25][840/9765] Loss_D: 0.0972 Loss_G: 0.0360 Convergence: 0.1011 k= 0.021836 lr = 0.0000158\n",
      "[11/25][850/9765] Loss_D: 0.1022 Loss_G: 0.0452 Convergence: 0.1071 k= 0.021820 lr = 0.0000158\n",
      "[11/25][860/9765] Loss_D: 0.0905 Loss_G: 0.0389 Convergence: 0.0937 k= 0.021813 lr = 0.0000158\n",
      "[11/25][870/9765] Loss_D: 0.1035 Loss_G: 0.0406 Convergence: 0.1055 k= 0.021813 lr = 0.0000158\n",
      "[11/25][880/9765] Loss_D: 0.0962 Loss_G: 0.0408 Convergence: 0.0991 k= 0.021804 lr = 0.0000158\n",
      "[11/25][890/9765] Loss_D: 0.0869 Loss_G: 0.0401 Convergence: 0.0928 k= 0.021797 lr = 0.0000158\n",
      "[11/25][900/9765] Loss_D: 0.0931 Loss_G: 0.0401 Convergence: 0.0965 k= 0.021789 lr = 0.0000158\n",
      "[11/25][910/9765] Loss_D: 0.0981 Loss_G: 0.0372 Convergence: 0.1013 k= 0.021816 lr = 0.0000158\n",
      "[11/25][920/9765] Loss_D: 0.0906 Loss_G: 0.0376 Convergence: 0.0925 k= 0.021827 lr = 0.0000158\n",
      "[11/25][930/9765] Loss_D: 0.1063 Loss_G: 0.0407 Convergence: 0.1093 k= 0.021843 lr = 0.0000158\n",
      "[11/25][940/9765] Loss_D: 0.0959 Loss_G: 0.0408 Convergence: 0.0989 k= 0.021831 lr = 0.0000158\n",
      "[11/25][950/9765] Loss_D: 0.0945 Loss_G: 0.0394 Convergence: 0.0967 k= 0.021810 lr = 0.0000158\n",
      "[11/25][960/9765] Loss_D: 0.0979 Loss_G: 0.0384 Convergence: 0.0998 k= 0.021813 lr = 0.0000158\n",
      "[11/25][970/9765] Loss_D: 0.1057 Loss_G: 0.0402 Convergence: 0.1090 k= 0.021803 lr = 0.0000158\n",
      "[11/25][980/9765] Loss_D: 0.0981 Loss_G: 0.0388 Convergence: 0.0998 k= 0.021816 lr = 0.0000158\n",
      "[11/25][990/9765] Loss_D: 0.1018 Loss_G: 0.0399 Convergence: 0.1039 k= 0.021816 lr = 0.0000158\n",
      "[11/25][1000/9765] Loss_D: 0.0886 Loss_G: 0.0376 Convergence: 0.0913 k= 0.021820 lr = 0.0000158\n",
      "[11/25][1010/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.0998 k= 0.021824 lr = 0.0000158\n",
      "[11/25][1020/9765] Loss_D: 0.0989 Loss_G: 0.0384 Convergence: 0.1011 k= 0.021823 lr = 0.0000158\n",
      "[11/25][1030/9765] Loss_D: 0.1014 Loss_G: 0.0375 Convergence: 0.1056 k= 0.021850 lr = 0.0000158\n",
      "[11/25][1040/9765] Loss_D: 0.1024 Loss_G: 0.0390 Convergence: 0.1055 k= 0.021859 lr = 0.0000158\n",
      "[11/25][1050/9765] Loss_D: 0.1010 Loss_G: 0.0377 Convergence: 0.1049 k= 0.021874 lr = 0.0000158\n",
      "[11/25][1060/9765] Loss_D: 0.0913 Loss_G: 0.0443 Convergence: 0.0997 k= 0.021863 lr = 0.0000158\n",
      "[11/25][1070/9765] Loss_D: 0.0972 Loss_G: 0.0419 Convergence: 0.1007 k= 0.021818 lr = 0.0000158\n",
      "[11/25][1080/9765] Loss_D: 0.0963 Loss_G: 0.0391 Convergence: 0.0975 k= 0.021818 lr = 0.0000158\n",
      "[11/25][1090/9765] Loss_D: 0.0937 Loss_G: 0.0406 Convergence: 0.0974 k= 0.021808 lr = 0.0000158\n",
      "[11/25][1100/9765] Loss_D: 0.1023 Loss_G: 0.0390 Convergence: 0.1054 k= 0.021809 lr = 0.0000158\n",
      "[11/25][1110/9765] Loss_D: 0.0911 Loss_G: 0.0400 Convergence: 0.0952 k= 0.021803 lr = 0.0000158\n",
      "[11/25][1120/9765] Loss_D: 0.1040 Loss_G: 0.0388 Convergence: 0.1080 k= 0.021804 lr = 0.0000158\n",
      "[11/25][1130/9765] Loss_D: 0.0920 Loss_G: 0.0399 Convergence: 0.0955 k= 0.021803 lr = 0.0000158\n",
      "[11/25][1140/9765] Loss_D: 0.0968 Loss_G: 0.0378 Convergence: 0.0990 k= 0.021808 lr = 0.0000158\n",
      "[11/25][1150/9765] Loss_D: 0.0946 Loss_G: 0.0378 Convergence: 0.0958 k= 0.021812 lr = 0.0000158\n",
      "[11/25][1160/9765] Loss_D: 0.0840 Loss_G: 0.0364 Convergence: 0.0873 k= 0.021815 lr = 0.0000158\n",
      "[11/25][1170/9765] Loss_D: 0.0957 Loss_G: 0.0384 Convergence: 0.0966 k= 0.021841 lr = 0.0000158\n",
      "[11/25][1180/9765] Loss_D: 0.1009 Loss_G: 0.0401 Convergence: 0.1022 k= 0.021839 lr = 0.0000158\n",
      "[11/25][1190/9765] Loss_D: 0.0970 Loss_G: 0.0392 Convergence: 0.0979 k= 0.021832 lr = 0.0000158\n",
      "[11/25][1200/9765] Loss_D: 0.1023 Loss_G: 0.0416 Convergence: 0.1035 k= 0.021838 lr = 0.0000158\n",
      "[11/25][1210/9765] Loss_D: 0.0961 Loss_G: 0.0418 Convergence: 0.1000 k= 0.021811 lr = 0.0000158\n",
      "[11/25][1220/9765] Loss_D: 0.0920 Loss_G: 0.0398 Convergence: 0.0956 k= 0.021805 lr = 0.0000158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][1230/9765] Loss_D: 0.1005 Loss_G: 0.0381 Convergence: 0.1037 k= 0.021812 lr = 0.0000158\n",
      "[11/25][1240/9765] Loss_D: 0.0925 Loss_G: 0.0353 Convergence: 0.0952 k= 0.021844 lr = 0.0000158\n",
      "[11/25][1250/9765] Loss_D: 0.1006 Loss_G: 0.0391 Convergence: 0.1029 k= 0.021883 lr = 0.0000158\n",
      "[11/25][1260/9765] Loss_D: 0.1063 Loss_G: 0.0392 Convergence: 0.1108 k= 0.021890 lr = 0.0000158\n",
      "[11/25][1270/9765] Loss_D: 0.1011 Loss_G: 0.0403 Convergence: 0.1024 k= 0.021887 lr = 0.0000158\n",
      "[11/25][1280/9765] Loss_D: 0.0930 Loss_G: 0.0341 Convergence: 0.0971 k= 0.021901 lr = 0.0000158\n",
      "[11/25][1290/9765] Loss_D: 0.0958 Loss_G: 0.0380 Convergence: 0.0973 k= 0.021919 lr = 0.0000158\n",
      "[11/25][1300/9765] Loss_D: 0.0953 Loss_G: 0.0394 Convergence: 0.0972 k= 0.021916 lr = 0.0000158\n",
      "[11/25][1310/9765] Loss_D: 0.0968 Loss_G: 0.0401 Convergence: 0.0987 k= 0.021914 lr = 0.0000158\n",
      "[11/25][1320/9765] Loss_D: 0.0924 Loss_G: 0.0402 Convergence: 0.0962 k= 0.021910 lr = 0.0000158\n",
      "[11/25][1330/9765] Loss_D: 0.0949 Loss_G: 0.0421 Convergence: 0.0996 k= 0.021893 lr = 0.0000158\n",
      "[11/25][1340/9765] Loss_D: 0.0965 Loss_G: 0.0414 Convergence: 0.0999 k= 0.021860 lr = 0.0000158\n",
      "[11/25][1350/9765] Loss_D: 0.0864 Loss_G: 0.0386 Convergence: 0.0909 k= 0.021847 lr = 0.0000158\n",
      "[11/25][1360/9765] Loss_D: 0.1081 Loss_G: 0.0384 Convergence: 0.1141 k= 0.021871 lr = 0.0000158\n",
      "[11/25][1370/9765] Loss_D: 0.0989 Loss_G: 0.0367 Convergence: 0.1029 k= 0.021886 lr = 0.0000158\n",
      "[11/25][1380/9765] Loss_D: 0.1013 Loss_G: 0.0378 Convergence: 0.1051 k= 0.021912 lr = 0.0000158\n",
      "[11/25][1390/9765] Loss_D: 0.1013 Loss_G: 0.0431 Convergence: 0.1044 k= 0.021889 lr = 0.0000158\n",
      "[11/25][1400/9765] Loss_D: 0.0949 Loss_G: 0.0425 Convergence: 0.1000 k= 0.021866 lr = 0.0000158\n",
      "[11/25][1410/9765] Loss_D: 0.0896 Loss_G: 0.0375 Convergence: 0.0918 k= 0.021873 lr = 0.0000158\n",
      "[11/25][1420/9765] Loss_D: 0.0923 Loss_G: 0.0394 Convergence: 0.0953 k= 0.021888 lr = 0.0000158\n",
      "[11/25][1430/9765] Loss_D: 0.0914 Loss_G: 0.0382 Convergence: 0.0936 k= 0.021884 lr = 0.0000158\n",
      "[11/25][1440/9765] Loss_D: 0.0938 Loss_G: 0.0407 Convergence: 0.0975 k= 0.021896 lr = 0.0000158\n",
      "[11/25][1450/9765] Loss_D: 0.0934 Loss_G: 0.0435 Convergence: 0.1001 k= 0.021875 lr = 0.0000158\n",
      "[11/25][1460/9765] Loss_D: 0.0853 Loss_G: 0.0388 Convergence: 0.0905 k= 0.021849 lr = 0.0000158\n",
      "[11/25][1470/9765] Loss_D: 0.0927 Loss_G: 0.0415 Convergence: 0.0976 k= 0.021864 lr = 0.0000158\n",
      "[11/25][1480/9765] Loss_D: 0.0999 Loss_G: 0.0417 Convergence: 0.1022 k= 0.021847 lr = 0.0000158\n",
      "[11/25][1490/9765] Loss_D: 0.0955 Loss_G: 0.0394 Convergence: 0.0972 k= 0.021847 lr = 0.0000158\n",
      "[11/25][1500/9765] Loss_D: 0.0997 Loss_G: 0.0375 Convergence: 0.1033 k= 0.021851 lr = 0.0000158\n",
      "[11/25][1510/9765] Loss_D: 0.0921 Loss_G: 0.0412 Convergence: 0.0970 k= 0.021850 lr = 0.0000158\n",
      "[11/25][1520/9765] Loss_D: 0.0935 Loss_G: 0.0395 Convergence: 0.0962 k= 0.021843 lr = 0.0000158\n",
      "[11/25][1530/9765] Loss_D: 0.1025 Loss_G: 0.0402 Convergence: 0.1046 k= 0.021841 lr = 0.0000158\n",
      "[11/25][1540/9765] Loss_D: 0.0951 Loss_G: 0.0426 Convergence: 0.1002 k= 0.021837 lr = 0.0000158\n",
      "[11/25][1550/9765] Loss_D: 0.0875 Loss_G: 0.0391 Convergence: 0.0921 k= 0.021811 lr = 0.0000158\n",
      "[11/25][1560/9765] Loss_D: 0.1050 Loss_G: 0.0420 Convergence: 0.1063 k= 0.021806 lr = 0.0000158\n",
      "[11/25][1570/9765] Loss_D: 0.0926 Loss_G: 0.0401 Convergence: 0.0962 k= 0.021793 lr = 0.0000158\n",
      "[11/25][1580/9765] Loss_D: 0.1001 Loss_G: 0.0380 Convergence: 0.1033 k= 0.021807 lr = 0.0000158\n",
      "[11/25][1590/9765] Loss_D: 0.0890 Loss_G: 0.0408 Convergence: 0.0947 k= 0.021803 lr = 0.0000158\n",
      "[11/25][1600/9765] Loss_D: 0.1019 Loss_G: 0.0396 Convergence: 0.1042 k= 0.021799 lr = 0.0000158\n",
      "[11/25][1610/9765] Loss_D: 0.0907 Loss_G: 0.0394 Convergence: 0.0943 k= 0.021799 lr = 0.0000158\n",
      "[11/25][1620/9765] Loss_D: 0.0960 Loss_G: 0.0385 Convergence: 0.0971 k= 0.021799 lr = 0.0000158\n",
      "[11/25][1630/9765] Loss_D: 0.0904 Loss_G: 0.0389 Convergence: 0.0936 k= 0.021793 lr = 0.0000158\n",
      "[11/25][1640/9765] Loss_D: 0.1000 Loss_G: 0.0412 Convergence: 0.1017 k= 0.021794 lr = 0.0000158\n",
      "[11/25][1650/9765] Loss_D: 0.1024 Loss_G: 0.0393 Convergence: 0.1052 k= 0.021797 lr = 0.0000158\n",
      "[11/25][1660/9765] Loss_D: 0.0886 Loss_G: 0.0396 Convergence: 0.0932 k= 0.021804 lr = 0.0000158\n",
      "[11/25][1670/9765] Loss_D: 0.0966 Loss_G: 0.0388 Convergence: 0.0977 k= 0.021806 lr = 0.0000158\n",
      "[11/25][1680/9765] Loss_D: 0.0926 Loss_G: 0.0391 Convergence: 0.0952 k= 0.021825 lr = 0.0000158\n",
      "[11/25][1690/9765] Loss_D: 0.0880 Loss_G: 0.0394 Convergence: 0.0928 k= 0.021809 lr = 0.0000158\n",
      "[11/25][1700/9765] Loss_D: 0.0909 Loss_G: 0.0402 Convergence: 0.0953 k= 0.021780 lr = 0.0000158\n",
      "[11/25][1710/9765] Loss_D: 0.0914 Loss_G: 0.0416 Convergence: 0.0969 k= 0.021775 lr = 0.0000158\n",
      "[11/25][1720/9765] Loss_D: 0.0944 Loss_G: 0.0406 Convergence: 0.0977 k= 0.021779 lr = 0.0000158\n",
      "[11/25][1730/9765] Loss_D: 0.1072 Loss_G: 0.0394 Convergence: 0.1119 k= 0.021771 lr = 0.0000158\n",
      "[11/25][1740/9765] Loss_D: 0.0912 Loss_G: 0.0359 Convergence: 0.0929 k= 0.021784 lr = 0.0000158\n",
      "[11/25][1750/9765] Loss_D: 0.0992 Loss_G: 0.0434 Convergence: 0.1034 k= 0.021789 lr = 0.0000158\n",
      "[11/25][1760/9765] Loss_D: 0.1012 Loss_G: 0.0426 Convergence: 0.1040 k= 0.021741 lr = 0.0000158\n",
      "[11/25][1770/9765] Loss_D: 0.0988 Loss_G: 0.0403 Convergence: 0.1001 k= 0.021698 lr = 0.0000158\n",
      "[11/25][1780/9765] Loss_D: 0.1040 Loss_G: 0.0386 Convergence: 0.1082 k= 0.021695 lr = 0.0000158\n",
      "[11/25][1790/9765] Loss_D: 0.0948 Loss_G: 0.0368 Convergence: 0.0970 k= 0.021713 lr = 0.0000158\n",
      "[11/25][1800/9765] Loss_D: 0.0874 Loss_G: 0.0356 Convergence: 0.0885 k= 0.021730 lr = 0.0000158\n",
      "[11/25][1810/9765] Loss_D: 0.0938 Loss_G: 0.0351 Convergence: 0.0972 k= 0.021746 lr = 0.0000158\n",
      "[11/25][1820/9765] Loss_D: 0.0982 Loss_G: 0.0394 Convergence: 0.0991 k= 0.021772 lr = 0.0000158\n",
      "[11/25][1830/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1006 k= 0.021792 lr = 0.0000158\n",
      "[11/25][1840/9765] Loss_D: 0.0890 Loss_G: 0.0388 Convergence: 0.0927 k= 0.021786 lr = 0.0000158\n",
      "[11/25][1850/9765] Loss_D: 0.0992 Loss_G: 0.0400 Convergence: 0.1001 k= 0.021784 lr = 0.0000158\n",
      "[11/25][1860/9765] Loss_D: 0.0937 Loss_G: 0.0393 Convergence: 0.0960 k= 0.021776 lr = 0.0000158\n",
      "[11/25][1870/9765] Loss_D: 0.0945 Loss_G: 0.0408 Convergence: 0.0980 k= 0.021775 lr = 0.0000158\n",
      "[11/25][1880/9765] Loss_D: 0.1013 Loss_G: 0.0335 Convergence: 0.1093 k= 0.021795 lr = 0.0000158\n",
      "[11/25][1890/9765] Loss_D: 0.0912 Loss_G: 0.0398 Convergence: 0.0950 k= 0.021822 lr = 0.0000158\n",
      "[11/25][1900/9765] Loss_D: 0.0987 Loss_G: 0.0399 Convergence: 0.0996 k= 0.021804 lr = 0.0000158\n",
      "[11/25][1910/9765] Loss_D: 0.1001 Loss_G: 0.0371 Convergence: 0.1042 k= 0.021791 lr = 0.0000158\n",
      "[11/25][1920/9765] Loss_D: 0.0943 Loss_G: 0.0346 Convergence: 0.0986 k= 0.021822 lr = 0.0000158\n",
      "[11/25][1930/9765] Loss_D: 0.0936 Loss_G: 0.0354 Convergence: 0.0967 k= 0.021863 lr = 0.0000158\n",
      "[11/25][1940/9765] Loss_D: 0.0911 Loss_G: 0.0394 Convergence: 0.0945 k= 0.021883 lr = 0.0000158\n",
      "[11/25][1950/9765] Loss_D: 0.0892 Loss_G: 0.0393 Convergence: 0.0934 k= 0.021872 lr = 0.0000158\n",
      "[11/25][1960/9765] Loss_D: 0.0965 Loss_G: 0.0374 Convergence: 0.0989 k= 0.021868 lr = 0.0000158\n",
      "[11/25][1970/9765] Loss_D: 0.0941 Loss_G: 0.0387 Convergence: 0.0956 k= 0.021873 lr = 0.0000158\n",
      "[11/25][1980/9765] Loss_D: 0.1009 Loss_G: 0.0396 Convergence: 0.1029 k= 0.021884 lr = 0.0000158\n",
      "[11/25][1990/9765] Loss_D: 0.0973 Loss_G: 0.0392 Convergence: 0.0981 k= 0.021907 lr = 0.0000158\n",
      "[11/25][2000/9765] Loss_D: 0.1001 Loss_G: 0.0399 Convergence: 0.1016 k= 0.021902 lr = 0.0000158\n",
      "[11/25][2010/9765] Loss_D: 0.0916 Loss_G: 0.0374 Convergence: 0.0929 k= 0.021902 lr = 0.0000158\n",
      "[11/25][2020/9765] Loss_D: 0.0946 Loss_G: 0.0356 Convergence: 0.0979 k= 0.021924 lr = 0.0000158\n",
      "[11/25][2030/9765] Loss_D: 0.1015 Loss_G: 0.0393 Convergence: 0.1039 k= 0.021935 lr = 0.0000158\n",
      "[11/25][2040/9765] Loss_D: 0.1013 Loss_G: 0.0394 Convergence: 0.1037 k= 0.021937 lr = 0.0000158\n",
      "[11/25][2050/9765] Loss_D: 0.1004 Loss_G: 0.0400 Convergence: 0.1019 k= 0.021935 lr = 0.0000158\n",
      "[11/25][2060/9765] Loss_D: 0.1003 Loss_G: 0.0399 Convergence: 0.1018 k= 0.021939 lr = 0.0000158\n",
      "[11/25][2070/9765] Loss_D: 0.0972 Loss_G: 0.0387 Convergence: 0.0985 k= 0.021931 lr = 0.0000158\n",
      "[11/25][2080/9765] Loss_D: 0.0907 Loss_G: 0.0404 Convergence: 0.0953 k= 0.021923 lr = 0.0000158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][2090/9765] Loss_D: 0.0927 Loss_G: 0.0417 Convergence: 0.0978 k= 0.021902 lr = 0.0000158\n",
      "[11/25][2100/9765] Loss_D: 0.0956 Loss_G: 0.0380 Convergence: 0.0970 k= 0.021921 lr = 0.0000158\n",
      "[11/25][2110/9765] Loss_D: 0.0956 Loss_G: 0.0374 Convergence: 0.0976 k= 0.021923 lr = 0.0000158\n",
      "[11/25][2120/9765] Loss_D: 0.0994 Loss_G: 0.0391 Convergence: 0.1013 k= 0.021942 lr = 0.0000158\n",
      "[11/25][2130/9765] Loss_D: 0.1019 Loss_G: 0.0398 Convergence: 0.1041 k= 0.021932 lr = 0.0000158\n",
      "[11/25][2140/9765] Loss_D: 0.1097 Loss_G: 0.0444 Convergence: 0.1108 k= 0.021924 lr = 0.0000158\n",
      "[11/25][2150/9765] Loss_D: 0.0901 Loss_G: 0.0374 Convergence: 0.0920 k= 0.021903 lr = 0.0000158\n",
      "[11/25][2160/9765] Loss_D: 0.0909 Loss_G: 0.0381 Convergence: 0.0931 k= 0.021917 lr = 0.0000158\n",
      "[11/25][2170/9765] Loss_D: 0.1015 Loss_G: 0.0365 Convergence: 0.1068 k= 0.021908 lr = 0.0000158\n",
      "[11/25][2180/9765] Loss_D: 0.1033 Loss_G: 0.0418 Convergence: 0.1043 k= 0.021907 lr = 0.0000158\n",
      "[11/25][2190/9765] Loss_D: 0.1018 Loss_G: 0.0382 Convergence: 0.1054 k= 0.021909 lr = 0.0000158\n",
      "[11/25][2200/9765] Loss_D: 0.0999 Loss_G: 0.0363 Convergence: 0.1046 k= 0.021919 lr = 0.0000158\n",
      "[11/25][2210/9765] Loss_D: 0.0963 Loss_G: 0.0364 Convergence: 0.0996 k= 0.021953 lr = 0.0000158\n",
      "[11/25][2220/9765] Loss_D: 0.0924 Loss_G: 0.0355 Convergence: 0.0950 k= 0.021982 lr = 0.0000158\n",
      "[11/25][2230/9765] Loss_D: 0.0998 Loss_G: 0.0367 Convergence: 0.1041 k= 0.022027 lr = 0.0000158\n",
      "[11/25][2240/9765] Loss_D: 0.1058 Loss_G: 0.0415 Convergence: 0.1079 k= 0.022020 lr = 0.0000158\n",
      "[11/25][2250/9765] Loss_D: 0.1057 Loss_G: 0.0390 Convergence: 0.1101 k= 0.022004 lr = 0.0000158\n",
      "[11/25][2260/9765] Loss_D: 0.1059 Loss_G: 0.0398 Convergence: 0.1096 k= 0.021996 lr = 0.0000158\n",
      "[11/25][2270/9765] Loss_D: 0.1014 Loss_G: 0.0391 Convergence: 0.1041 k= 0.021989 lr = 0.0000158\n",
      "[11/25][2280/9765] Loss_D: 0.0967 Loss_G: 0.0397 Convergence: 0.0982 k= 0.022000 lr = 0.0000158\n",
      "[11/25][2290/9765] Loss_D: 0.1006 Loss_G: 0.0415 Convergence: 0.1025 k= 0.021988 lr = 0.0000158\n",
      "[11/25][2300/9765] Loss_D: 0.0933 Loss_G: 0.0391 Convergence: 0.0956 k= 0.021971 lr = 0.0000158\n",
      "[11/25][2310/9765] Loss_D: 0.0933 Loss_G: 0.0396 Convergence: 0.0961 k= 0.021971 lr = 0.0000158\n",
      "[11/25][2320/9765] Loss_D: 0.1002 Loss_G: 0.0388 Convergence: 0.1027 k= 0.021978 lr = 0.0000158\n",
      "[11/25][2330/9765] Loss_D: 0.0952 Loss_G: 0.0415 Convergence: 0.0991 k= 0.021967 lr = 0.0000158\n",
      "[11/25][2340/9765] Loss_D: 0.0975 Loss_G: 0.0400 Convergence: 0.0990 k= 0.021955 lr = 0.0000158\n",
      "[11/25][2350/9765] Loss_D: 0.0938 Loss_G: 0.0405 Convergence: 0.0973 k= 0.021936 lr = 0.0000158\n",
      "[11/25][2360/9765] Loss_D: 0.1100 Loss_G: 0.0395 Convergence: 0.1158 k= 0.021943 lr = 0.0000158\n",
      "[11/25][2370/9765] Loss_D: 0.0975 Loss_G: 0.0414 Convergence: 0.1004 k= 0.021934 lr = 0.0000158\n",
      "[11/25][2380/9765] Loss_D: 0.0931 Loss_G: 0.0394 Convergence: 0.0958 k= 0.021934 lr = 0.0000158\n",
      "[11/25][2390/9765] Loss_D: 0.0979 Loss_G: 0.0426 Convergence: 0.1019 k= 0.021917 lr = 0.0000158\n",
      "[11/25][2400/9765] Loss_D: 0.0972 Loss_G: 0.0396 Convergence: 0.0985 k= 0.021907 lr = 0.0000158\n",
      "[11/25][2410/9765] Loss_D: 0.0953 Loss_G: 0.0396 Convergence: 0.0973 k= 0.021908 lr = 0.0000158\n",
      "[11/25][2420/9765] Loss_D: 0.1019 Loss_G: 0.0389 Convergence: 0.1050 k= 0.021895 lr = 0.0000158\n",
      "[11/25][2430/9765] Loss_D: 0.1014 Loss_G: 0.0408 Convergence: 0.1024 k= 0.021900 lr = 0.0000158\n",
      "[11/25][2440/9765] Loss_D: 0.0960 Loss_G: 0.0403 Convergence: 0.0984 k= 0.021903 lr = 0.0000158\n",
      "[11/25][2450/9765] Loss_D: 0.0997 Loss_G: 0.0391 Convergence: 0.1017 k= 0.021921 lr = 0.0000158\n",
      "[11/25][2460/9765] Loss_D: 0.0934 Loss_G: 0.0384 Convergence: 0.0950 k= 0.021921 lr = 0.0000158\n",
      "[11/25][2470/9765] Loss_D: 0.0905 Loss_G: 0.0389 Convergence: 0.0937 k= 0.021948 lr = 0.0000158\n",
      "[11/25][2480/9765] Loss_D: 0.0939 Loss_G: 0.0373 Convergence: 0.0952 k= 0.021939 lr = 0.0000158\n",
      "[11/25][2490/9765] Loss_D: 0.0875 Loss_G: 0.0383 Convergence: 0.0913 k= 0.021942 lr = 0.0000158\n",
      "[11/25][2500/9765] Loss_D: 0.1019 Loss_G: 0.0377 Convergence: 0.1061 k= 0.021950 lr = 0.0000158\n",
      "[11/25][2510/9765] Loss_D: 0.0990 Loss_G: 0.0415 Convergence: 0.1014 k= 0.021942 lr = 0.0000158\n",
      "[11/25][2520/9765] Loss_D: 0.1011 Loss_G: 0.0412 Convergence: 0.1024 k= 0.021928 lr = 0.0000158\n",
      "[11/25][2530/9765] Loss_D: 0.0996 Loss_G: 0.0392 Convergence: 0.1014 k= 0.021913 lr = 0.0000158\n",
      "[11/25][2540/9765] Loss_D: 0.0978 Loss_G: 0.0366 Convergence: 0.1014 k= 0.021909 lr = 0.0000158\n",
      "[11/25][2550/9765] Loss_D: 0.0974 Loss_G: 0.0392 Convergence: 0.0984 k= 0.021925 lr = 0.0000158\n",
      "[11/25][2560/9765] Loss_D: 0.0948 Loss_G: 0.0398 Convergence: 0.0972 k= 0.021939 lr = 0.0000158\n",
      "[11/25][2570/9765] Loss_D: 0.0952 Loss_G: 0.0424 Convergence: 0.1001 k= 0.021911 lr = 0.0000158\n",
      "[11/25][2580/9765] Loss_D: 0.0961 Loss_G: 0.0417 Convergence: 0.0999 k= 0.021865 lr = 0.0000158\n",
      "[11/25][2590/9765] Loss_D: 0.0866 Loss_G: 0.0403 Convergence: 0.0928 k= 0.021845 lr = 0.0000158\n",
      "[11/25][2600/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1016 k= 0.021834 lr = 0.0000158\n",
      "[11/25][2610/9765] Loss_D: 0.0907 Loss_G: 0.0363 Convergence: 0.0918 k= 0.021850 lr = 0.0000158\n",
      "[11/25][2620/9765] Loss_D: 0.1052 Loss_G: 0.0385 Convergence: 0.1099 k= 0.021872 lr = 0.0000158\n",
      "[11/25][2630/9765] Loss_D: 0.1027 Loss_G: 0.0381 Convergence: 0.1068 k= 0.021901 lr = 0.0000158\n",
      "[11/25][2640/9765] Loss_D: 0.0989 Loss_G: 0.0395 Convergence: 0.1003 k= 0.021929 lr = 0.0000158\n",
      "[11/25][2650/9765] Loss_D: 0.1021 Loss_G: 0.0403 Convergence: 0.1039 k= 0.021920 lr = 0.0000158\n",
      "[11/25][2660/9765] Loss_D: 0.1001 Loss_G: 0.0391 Convergence: 0.1023 k= 0.021891 lr = 0.0000158\n",
      "[11/25][2670/9765] Loss_D: 0.0969 Loss_G: 0.0390 Convergence: 0.0979 k= 0.021885 lr = 0.0000158\n",
      "[11/25][2680/9765] Loss_D: 0.0964 Loss_G: 0.0407 Convergence: 0.0991 k= 0.021884 lr = 0.0000158\n",
      "[11/25][2690/9765] Loss_D: 0.1093 Loss_G: 0.0394 Convergence: 0.1148 k= 0.021889 lr = 0.0000158\n",
      "[11/25][2700/9765] Loss_D: 0.0987 Loss_G: 0.0408 Convergence: 0.1006 k= 0.021894 lr = 0.0000158\n",
      "[11/25][2710/9765] Loss_D: 0.0969 Loss_G: 0.0386 Convergence: 0.0983 k= 0.021883 lr = 0.0000158\n",
      "[11/25][2720/9765] Loss_D: 0.0980 Loss_G: 0.0394 Convergence: 0.0990 k= 0.021871 lr = 0.0000158\n",
      "[11/25][2730/9765] Loss_D: 0.1083 Loss_G: 0.0415 Convergence: 0.1113 k= 0.021867 lr = 0.0000158\n",
      "[11/25][2740/9765] Loss_D: 0.1090 Loss_G: 0.0402 Convergence: 0.1137 k= 0.021861 lr = 0.0000158\n",
      "[11/25][2750/9765] Loss_D: 0.1015 Loss_G: 0.0403 Convergence: 0.1030 k= 0.021853 lr = 0.0000158\n",
      "[11/25][2760/9765] Loss_D: 0.0979 Loss_G: 0.0419 Convergence: 0.1011 k= 0.021836 lr = 0.0000158\n",
      "[11/25][2770/9765] Loss_D: 0.1047 Loss_G: 0.0396 Convergence: 0.1083 k= 0.021835 lr = 0.0000158\n",
      "[11/25][2780/9765] Loss_D: 0.0995 Loss_G: 0.0407 Convergence: 0.1009 k= 0.021846 lr = 0.0000158\n",
      "[11/25][2790/9765] Loss_D: 0.1031 Loss_G: 0.0396 Convergence: 0.1059 k= 0.021829 lr = 0.0000158\n",
      "[11/25][2800/9765] Loss_D: 0.1036 Loss_G: 0.0405 Convergence: 0.1057 k= 0.021826 lr = 0.0000158\n",
      "[11/25][2810/9765] Loss_D: 0.0982 Loss_G: 0.0354 Convergence: 0.1031 k= 0.021853 lr = 0.0000158\n",
      "[11/25][2820/9765] Loss_D: 0.0921 Loss_G: 0.0351 Convergence: 0.0949 k= 0.021875 lr = 0.0000158\n",
      "[11/25][2830/9765] Loss_D: 0.0972 Loss_G: 0.0362 Convergence: 0.1011 k= 0.021883 lr = 0.0000158\n",
      "[11/25][2840/9765] Loss_D: 0.0909 Loss_G: 0.0377 Convergence: 0.0927 k= 0.021888 lr = 0.0000158\n",
      "[11/25][2850/9765] Loss_D: 0.1059 Loss_G: 0.0388 Convergence: 0.1105 k= 0.021888 lr = 0.0000158\n",
      "[11/25][2860/9765] Loss_D: 0.0954 Loss_G: 0.0391 Convergence: 0.0969 k= 0.021878 lr = 0.0000158\n",
      "[11/25][2870/9765] Loss_D: 0.0949 Loss_G: 0.0407 Convergence: 0.0982 k= 0.021855 lr = 0.0000158\n",
      "[11/25][2880/9765] Loss_D: 0.1055 Loss_G: 0.0414 Convergence: 0.1075 k= 0.021856 lr = 0.0000158\n",
      "[11/25][2890/9765] Loss_D: 0.0938 Loss_G: 0.0393 Convergence: 0.0961 k= 0.021858 lr = 0.0000158\n",
      "[11/25][2900/9765] Loss_D: 0.0904 Loss_G: 0.0379 Convergence: 0.0927 k= 0.021852 lr = 0.0000158\n",
      "[11/25][2910/9765] Loss_D: 0.0866 Loss_G: 0.0399 Convergence: 0.0923 k= 0.021851 lr = 0.0000158\n",
      "[11/25][2920/9765] Loss_D: 0.0987 Loss_G: 0.0383 Convergence: 0.1010 k= 0.021862 lr = 0.0000158\n",
      "[11/25][2930/9765] Loss_D: 0.0931 Loss_G: 0.0375 Convergence: 0.0939 k= 0.021865 lr = 0.0000158\n",
      "[11/25][2940/9765] Loss_D: 0.1041 Loss_G: 0.0401 Convergence: 0.1068 k= 0.021871 lr = 0.0000158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][2950/9765] Loss_D: 0.1019 Loss_G: 0.0391 Convergence: 0.1047 k= 0.021862 lr = 0.0000158\n",
      "[11/25][2960/9765] Loss_D: 0.0951 Loss_G: 0.0375 Convergence: 0.0967 k= 0.021865 lr = 0.0000158\n",
      "[11/25][2970/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.021860 lr = 0.0000158\n",
      "[11/25][2980/9765] Loss_D: 0.0988 Loss_G: 0.0415 Convergence: 0.1013 k= 0.021847 lr = 0.0000158\n",
      "[11/25][2990/9765] Loss_D: 0.0975 Loss_G: 0.0401 Convergence: 0.0991 k= 0.021838 lr = 0.0000158\n",
      "[11/25][3000/9765] Loss_D: 0.1065 Loss_G: 0.0385 Convergence: 0.1118 k= 0.021820 lr = 0.0000158\n",
      "[11/25][3010/9765] Loss_D: 0.0947 Loss_G: 0.0422 Convergence: 0.0996 k= 0.021805 lr = 0.0000158\n",
      "[11/25][3020/9765] Loss_D: 0.1000 Loss_G: 0.0400 Convergence: 0.1013 k= 0.021800 lr = 0.0000158\n",
      "[11/25][3030/9765] Loss_D: 0.0941 Loss_G: 0.0407 Convergence: 0.0977 k= 0.021773 lr = 0.0000158\n",
      "[11/25][3040/9765] Loss_D: 0.0969 Loss_G: 0.0402 Convergence: 0.0990 k= 0.021752 lr = 0.0000158\n",
      "[11/25][3050/9765] Loss_D: 0.0868 Loss_G: 0.0382 Convergence: 0.0908 k= 0.021756 lr = 0.0000158\n",
      "[11/25][3060/9765] Loss_D: 0.0943 Loss_G: 0.0372 Convergence: 0.0959 k= 0.021775 lr = 0.0000158\n",
      "[11/25][3070/9765] Loss_D: 0.0984 Loss_G: 0.0370 Convergence: 0.1019 k= 0.021774 lr = 0.0000158\n",
      "[11/25][3080/9765] Loss_D: 0.1025 Loss_G: 0.0420 Convergence: 0.1041 k= 0.021766 lr = 0.0000158\n",
      "[11/25][3090/9765] Loss_D: 0.0967 Loss_G: 0.0407 Convergence: 0.0993 k= 0.021732 lr = 0.0000158\n",
      "[11/25][3100/9765] Loss_D: 0.0952 Loss_G: 0.0413 Convergence: 0.0990 k= 0.021702 lr = 0.0000158\n",
      "[11/25][3110/9765] Loss_D: 0.1044 Loss_G: 0.0372 Convergence: 0.1100 k= 0.021733 lr = 0.0000158\n",
      "[11/25][3120/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.0997 k= 0.021749 lr = 0.0000158\n",
      "[11/25][3130/9765] Loss_D: 0.0975 Loss_G: 0.0365 Convergence: 0.1011 k= 0.021742 lr = 0.0000158\n",
      "[11/25][3140/9765] Loss_D: 0.0997 Loss_G: 0.0384 Convergence: 0.1024 k= 0.021750 lr = 0.0000158\n",
      "[11/25][3150/9765] Loss_D: 0.0949 Loss_G: 0.0381 Convergence: 0.0959 k= 0.021755 lr = 0.0000158\n",
      "[11/25][3160/9765] Loss_D: 0.0990 Loss_G: 0.0390 Convergence: 0.1008 k= 0.021763 lr = 0.0000158\n",
      "[11/25][3170/9765] Loss_D: 0.0914 Loss_G: 0.0376 Convergence: 0.0929 k= 0.021764 lr = 0.0000158\n",
      "[11/25][3180/9765] Loss_D: 0.0869 Loss_G: 0.0428 Convergence: 0.0955 k= 0.021742 lr = 0.0000158\n",
      "[11/25][3190/9765] Loss_D: 0.1012 Loss_G: 0.0381 Convergence: 0.1047 k= 0.021749 lr = 0.0000158\n",
      "[11/25][3200/9765] Loss_D: 0.1038 Loss_G: 0.0370 Convergence: 0.1094 k= 0.021765 lr = 0.0000158\n",
      "[11/25][3210/9765] Loss_D: 0.1044 Loss_G: 0.0385 Convergence: 0.1087 k= 0.021791 lr = 0.0000158\n",
      "[11/25][3220/9765] Loss_D: 0.1040 Loss_G: 0.0405 Convergence: 0.1063 k= 0.021777 lr = 0.0000158\n",
      "[11/25][3230/9765] Loss_D: 0.1018 Loss_G: 0.0398 Convergence: 0.1039 k= 0.021767 lr = 0.0000158\n",
      "[11/25][3240/9765] Loss_D: 0.0929 Loss_G: 0.0388 Convergence: 0.0951 k= 0.021777 lr = 0.0000158\n",
      "[11/25][3250/9765] Loss_D: 0.0956 Loss_G: 0.0401 Convergence: 0.0980 k= 0.021776 lr = 0.0000158\n",
      "[11/25][3260/9765] Loss_D: 0.1031 Loss_G: 0.0416 Convergence: 0.1040 k= 0.021772 lr = 0.0000158\n",
      "[11/25][3270/9765] Loss_D: 0.1083 Loss_G: 0.0368 Convergence: 0.1158 k= 0.021792 lr = 0.0000158\n",
      "[11/25][3280/9765] Loss_D: 0.1009 Loss_G: 0.0408 Convergence: 0.1019 k= 0.021780 lr = 0.0000158\n",
      "[11/25][3290/9765] Loss_D: 0.0968 Loss_G: 0.0396 Convergence: 0.0982 k= 0.021782 lr = 0.0000158\n",
      "[11/25][3300/9765] Loss_D: 0.0919 Loss_G: 0.0391 Convergence: 0.0948 k= 0.021780 lr = 0.0000158\n",
      "[11/25][3310/9765] Loss_D: 0.0945 Loss_G: 0.0388 Convergence: 0.0960 k= 0.021793 lr = 0.0000158\n",
      "[11/25][3320/9765] Loss_D: 0.1006 Loss_G: 0.0369 Convergence: 0.1050 k= 0.021814 lr = 0.0000158\n",
      "[11/25][3330/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0974 k= 0.021827 lr = 0.0000158\n",
      "[11/25][3340/9765] Loss_D: 0.0961 Loss_G: 0.0393 Convergence: 0.0975 k= 0.021818 lr = 0.0000158\n",
      "[11/25][3350/9765] Loss_D: 0.1007 Loss_G: 0.0384 Convergence: 0.1037 k= 0.021807 lr = 0.0000158\n",
      "[11/25][3360/9765] Loss_D: 0.0916 Loss_G: 0.0427 Convergence: 0.0982 k= 0.021799 lr = 0.0000158\n",
      "[11/25][3370/9765] Loss_D: 0.0858 Loss_G: 0.0373 Convergence: 0.0893 k= 0.021804 lr = 0.0000158\n",
      "[11/25][3380/9765] Loss_D: 0.0941 Loss_G: 0.0419 Convergence: 0.0989 k= 0.021798 lr = 0.0000158\n",
      "[11/25][3390/9765] Loss_D: 0.1090 Loss_G: 0.0381 Convergence: 0.1156 k= 0.021794 lr = 0.0000158\n",
      "[11/25][3400/9765] Loss_D: 0.0929 Loss_G: 0.0398 Convergence: 0.0960 k= 0.021793 lr = 0.0000158\n",
      "[11/25][3410/9765] Loss_D: 0.0976 Loss_G: 0.0427 Convergence: 0.1018 k= 0.021785 lr = 0.0000158\n",
      "[11/25][3420/9765] Loss_D: 0.0943 Loss_G: 0.0401 Convergence: 0.0972 k= 0.021760 lr = 0.0000158\n",
      "[11/25][3430/9765] Loss_D: 0.1027 Loss_G: 0.0383 Convergence: 0.1066 k= 0.021751 lr = 0.0000158\n",
      "[11/25][3440/9765] Loss_D: 0.0902 Loss_G: 0.0394 Convergence: 0.0941 k= 0.021764 lr = 0.0000158\n",
      "[11/25][3450/9765] Loss_D: 0.0964 Loss_G: 0.0396 Convergence: 0.0979 k= 0.021755 lr = 0.0000158\n",
      "[11/25][3460/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0991 k= 0.021764 lr = 0.0000158\n",
      "[11/25][3470/9765] Loss_D: 0.0891 Loss_G: 0.0365 Convergence: 0.0904 k= 0.021780 lr = 0.0000158\n",
      "[11/25][3480/9765] Loss_D: 0.0970 Loss_G: 0.0407 Convergence: 0.0995 k= 0.021779 lr = 0.0000158\n",
      "[11/25][3490/9765] Loss_D: 0.0998 Loss_G: 0.0392 Convergence: 0.1017 k= 0.021767 lr = 0.0000158\n",
      "[11/25][3500/9765] Loss_D: 0.1088 Loss_G: 0.0393 Convergence: 0.1141 k= 0.021757 lr = 0.0000158\n",
      "[11/25][3510/9765] Loss_D: 0.0927 Loss_G: 0.0384 Convergence: 0.0945 k= 0.021756 lr = 0.0000158\n",
      "[11/25][3520/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0942 k= 0.021764 lr = 0.0000158\n",
      "[11/25][3530/9765] Loss_D: 0.0850 Loss_G: 0.0411 Convergence: 0.0927 k= 0.021757 lr = 0.0000158\n",
      "[11/25][3540/9765] Loss_D: 0.0916 Loss_G: 0.0426 Convergence: 0.0981 k= 0.021732 lr = 0.0000158\n",
      "[11/25][3550/9765] Loss_D: 0.0943 Loss_G: 0.0402 Convergence: 0.0973 k= 0.021717 lr = 0.0000158\n",
      "[11/25][3560/9765] Loss_D: 0.1051 Loss_G: 0.0390 Convergence: 0.1093 k= 0.021722 lr = 0.0000158\n",
      "[11/25][3570/9765] Loss_D: 0.0998 Loss_G: 0.0394 Convergence: 0.1015 k= 0.021727 lr = 0.0000158\n",
      "[11/25][3580/9765] Loss_D: 0.1075 Loss_G: 0.0404 Convergence: 0.1112 k= 0.021735 lr = 0.0000158\n",
      "[11/25][3590/9765] Loss_D: 0.1001 Loss_G: 0.0406 Convergence: 0.1012 k= 0.021736 lr = 0.0000150\n",
      "[11/25][3600/9765] Loss_D: 0.1043 Loss_G: 0.0402 Convergence: 0.1070 k= 0.021753 lr = 0.0000150\n",
      "[11/25][3610/9765] Loss_D: 0.0967 Loss_G: 0.0387 Convergence: 0.0980 k= 0.021753 lr = 0.0000150\n",
      "[11/25][3620/9765] Loss_D: 0.0995 Loss_G: 0.0384 Convergence: 0.1021 k= 0.021747 lr = 0.0000150\n",
      "[11/25][3630/9765] Loss_D: 0.0994 Loss_G: 0.0393 Convergence: 0.1011 k= 0.021751 lr = 0.0000150\n",
      "[11/25][3640/9765] Loss_D: 0.0987 Loss_G: 0.0375 Convergence: 0.1019 k= 0.021758 lr = 0.0000150\n",
      "[11/25][3650/9765] Loss_D: 0.0937 Loss_G: 0.0394 Convergence: 0.0961 k= 0.021783 lr = 0.0000150\n",
      "[11/25][3660/9765] Loss_D: 0.0995 Loss_G: 0.0388 Convergence: 0.1017 k= 0.021793 lr = 0.0000150\n",
      "[11/25][3670/9765] Loss_D: 0.0919 Loss_G: 0.0385 Convergence: 0.0942 k= 0.021794 lr = 0.0000150\n",
      "[11/25][3680/9765] Loss_D: 0.0933 Loss_G: 0.0382 Convergence: 0.0947 k= 0.021800 lr = 0.0000150\n",
      "[11/25][3690/9765] Loss_D: 0.0975 Loss_G: 0.0370 Convergence: 0.1006 k= 0.021802 lr = 0.0000150\n",
      "[11/25][3700/9765] Loss_D: 0.0987 Loss_G: 0.0367 Convergence: 0.1026 k= 0.021824 lr = 0.0000150\n",
      "[11/25][3710/9765] Loss_D: 0.1077 Loss_G: 0.0395 Convergence: 0.1125 k= 0.021827 lr = 0.0000150\n",
      "[11/25][3720/9765] Loss_D: 0.0973 Loss_G: 0.0385 Convergence: 0.0989 k= 0.021826 lr = 0.0000150\n",
      "[11/25][3730/9765] Loss_D: 0.0988 Loss_G: 0.0384 Convergence: 0.1010 k= 0.021831 lr = 0.0000150\n",
      "[11/25][3740/9765] Loss_D: 0.1032 Loss_G: 0.0389 Convergence: 0.1068 k= 0.021842 lr = 0.0000150\n",
      "[11/25][3750/9765] Loss_D: 0.1003 Loss_G: 0.0388 Convergence: 0.1029 k= 0.021840 lr = 0.0000150\n",
      "[11/25][3760/9765] Loss_D: 0.0982 Loss_G: 0.0368 Convergence: 0.1018 k= 0.021852 lr = 0.0000150\n",
      "[11/25][3770/9765] Loss_D: 0.0989 Loss_G: 0.0378 Convergence: 0.1017 k= 0.021873 lr = 0.0000150\n",
      "[11/25][3780/9765] Loss_D: 0.0939 Loss_G: 0.0386 Convergence: 0.0955 k= 0.021877 lr = 0.0000150\n",
      "[11/25][3790/9765] Loss_D: 0.1004 Loss_G: 0.0398 Convergence: 0.1020 k= 0.021878 lr = 0.0000150\n",
      "[11/25][3800/9765] Loss_D: 0.0992 Loss_G: 0.0389 Convergence: 0.1011 k= 0.021869 lr = 0.0000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][3810/9765] Loss_D: 0.0922 Loss_G: 0.0380 Convergence: 0.0939 k= 0.021878 lr = 0.0000150\n",
      "[11/25][3820/9765] Loss_D: 0.1082 Loss_G: 0.0404 Convergence: 0.1121 k= 0.021885 lr = 0.0000150\n",
      "[11/25][3830/9765] Loss_D: 0.0933 Loss_G: 0.0381 Convergence: 0.0947 k= 0.021891 lr = 0.0000150\n",
      "[11/25][3840/9765] Loss_D: 0.1039 Loss_G: 0.0418 Convergence: 0.1049 k= 0.021876 lr = 0.0000150\n",
      "[11/25][3850/9765] Loss_D: 0.0949 Loss_G: 0.0422 Convergence: 0.0997 k= 0.021854 lr = 0.0000150\n",
      "[11/25][3860/9765] Loss_D: 0.1016 Loss_G: 0.0389 Convergence: 0.1045 k= 0.021843 lr = 0.0000150\n",
      "[11/25][3870/9765] Loss_D: 0.0963 Loss_G: 0.0367 Convergence: 0.0992 k= 0.021874 lr = 0.0000150\n",
      "[11/25][3880/9765] Loss_D: 0.0911 Loss_G: 0.0369 Convergence: 0.0921 k= 0.021890 lr = 0.0000150\n",
      "[11/25][3890/9765] Loss_D: 0.1081 Loss_G: 0.0380 Convergence: 0.1146 k= 0.021907 lr = 0.0000150\n",
      "[11/25][3900/9765] Loss_D: 0.1020 Loss_G: 0.0375 Convergence: 0.1064 k= 0.021928 lr = 0.0000150\n",
      "[11/25][3910/9765] Loss_D: 0.1066 Loss_G: 0.0433 Convergence: 0.1078 k= 0.021930 lr = 0.0000150\n",
      "[11/25][3920/9765] Loss_D: 0.1099 Loss_G: 0.0397 Convergence: 0.1154 k= 0.021932 lr = 0.0000150\n",
      "[11/25][3930/9765] Loss_D: 0.1048 Loss_G: 0.0416 Convergence: 0.1063 k= 0.021930 lr = 0.0000150\n",
      "[11/25][3940/9765] Loss_D: 0.1044 Loss_G: 0.0381 Convergence: 0.1092 k= 0.021945 lr = 0.0000150\n",
      "[11/25][3950/9765] Loss_D: 0.0995 Loss_G: 0.0389 Convergence: 0.1016 k= 0.021971 lr = 0.0000150\n",
      "[11/25][3960/9765] Loss_D: 0.1015 Loss_G: 0.0409 Convergence: 0.1024 k= 0.021993 lr = 0.0000150\n",
      "[11/25][3970/9765] Loss_D: 0.1022 Loss_G: 0.0462 Convergence: 0.1082 k= 0.021967 lr = 0.0000150\n",
      "[11/25][3980/9765] Loss_D: 0.1051 Loss_G: 0.0406 Convergence: 0.1077 k= 0.021926 lr = 0.0000150\n",
      "[11/25][3990/9765] Loss_D: 0.0949 Loss_G: 0.0369 Convergence: 0.0971 k= 0.021925 lr = 0.0000150\n",
      "[11/25][4000/9765] Loss_D: 0.1054 Loss_G: 0.0402 Convergence: 0.1086 k= 0.021939 lr = 0.0000150\n",
      "[11/25][4010/9765] Loss_D: 0.0923 Loss_G: 0.0418 Convergence: 0.0977 k= 0.021923 lr = 0.0000150\n",
      "[11/25][4020/9765] Loss_D: 0.1017 Loss_G: 0.0404 Convergence: 0.1032 k= 0.021903 lr = 0.0000150\n",
      "[11/25][4030/9765] Loss_D: 0.0982 Loss_G: 0.0382 Convergence: 0.1005 k= 0.021918 lr = 0.0000150\n",
      "[11/25][4040/9765] Loss_D: 0.0939 Loss_G: 0.0392 Convergence: 0.0961 k= 0.021914 lr = 0.0000150\n",
      "[11/25][4050/9765] Loss_D: 0.0926 Loss_G: 0.0400 Convergence: 0.0961 k= 0.021930 lr = 0.0000150\n",
      "[11/25][4060/9765] Loss_D: 0.0923 Loss_G: 0.0375 Convergence: 0.0934 k= 0.021926 lr = 0.0000150\n",
      "[11/25][4070/9765] Loss_D: 0.0944 Loss_G: 0.0411 Convergence: 0.0982 k= 0.021940 lr = 0.0000150\n",
      "[11/25][4080/9765] Loss_D: 0.1016 Loss_G: 0.0389 Convergence: 0.1046 k= 0.021925 lr = 0.0000150\n",
      "[11/25][4090/9765] Loss_D: 0.0888 Loss_G: 0.0378 Convergence: 0.0915 k= 0.021924 lr = 0.0000150\n",
      "[11/25][4100/9765] Loss_D: 0.0954 Loss_G: 0.0404 Convergence: 0.0982 k= 0.021923 lr = 0.0000150\n",
      "[11/25][4110/9765] Loss_D: 0.0938 Loss_G: 0.0403 Convergence: 0.0971 k= 0.021917 lr = 0.0000150\n",
      "[11/25][4120/9765] Loss_D: 0.1007 Loss_G: 0.0409 Convergence: 0.1019 k= 0.021909 lr = 0.0000150\n",
      "[11/25][4130/9765] Loss_D: 0.0958 Loss_G: 0.0385 Convergence: 0.0968 k= 0.021911 lr = 0.0000150\n",
      "[11/25][4140/9765] Loss_D: 0.1081 Loss_G: 0.0409 Convergence: 0.1115 k= 0.021926 lr = 0.0000150\n",
      "[11/25][4150/9765] Loss_D: 0.0968 Loss_G: 0.0403 Convergence: 0.0989 k= 0.021914 lr = 0.0000150\n",
      "[11/25][4160/9765] Loss_D: 0.1059 Loss_G: 0.0374 Convergence: 0.1120 k= 0.021909 lr = 0.0000150\n",
      "[11/25][4170/9765] Loss_D: 0.1008 Loss_G: 0.0425 Convergence: 0.1035 k= 0.021899 lr = 0.0000150\n",
      "[11/25][4180/9765] Loss_D: 0.0954 Loss_G: 0.0392 Convergence: 0.0969 k= 0.021893 lr = 0.0000150\n",
      "[11/25][4190/9765] Loss_D: 0.0893 Loss_G: 0.0370 Convergence: 0.0911 k= 0.021909 lr = 0.0000150\n",
      "[11/25][4200/9765] Loss_D: 0.0857 Loss_G: 0.0363 Convergence: 0.0882 k= 0.021927 lr = 0.0000150\n",
      "[11/25][4210/9765] Loss_D: 0.0936 Loss_G: 0.0394 Convergence: 0.0960 k= 0.021938 lr = 0.0000150\n",
      "[11/25][4220/9765] Loss_D: 0.0945 Loss_G: 0.0398 Convergence: 0.0971 k= 0.021927 lr = 0.0000150\n",
      "[11/25][4230/9765] Loss_D: 0.0980 Loss_G: 0.0400 Convergence: 0.0993 k= 0.021930 lr = 0.0000150\n",
      "[11/25][4240/9765] Loss_D: 0.0901 Loss_G: 0.0377 Convergence: 0.0922 k= 0.021933 lr = 0.0000150\n",
      "[11/25][4250/9765] Loss_D: 0.1020 Loss_G: 0.0421 Convergence: 0.1038 k= 0.021927 lr = 0.0000150\n",
      "[11/25][4260/9765] Loss_D: 0.0921 Loss_G: 0.0383 Convergence: 0.0940 k= 0.021924 lr = 0.0000150\n",
      "[11/25][4270/9765] Loss_D: 0.0955 Loss_G: 0.0370 Convergence: 0.0979 k= 0.021934 lr = 0.0000150\n",
      "[11/25][4280/9765] Loss_D: 0.0922 Loss_G: 0.0370 Convergence: 0.0931 k= 0.021956 lr = 0.0000150\n",
      "[11/25][4290/9765] Loss_D: 0.1025 Loss_G: 0.0398 Convergence: 0.1049 k= 0.021975 lr = 0.0000150\n",
      "[11/25][4300/9765] Loss_D: 0.1029 Loss_G: 0.0411 Convergence: 0.1042 k= 0.021955 lr = 0.0000150\n",
      "[11/25][4310/9765] Loss_D: 0.1038 Loss_G: 0.0395 Convergence: 0.1071 k= 0.021942 lr = 0.0000150\n",
      "[11/25][4320/9765] Loss_D: 0.1007 Loss_G: 0.0397 Convergence: 0.1026 k= 0.021945 lr = 0.0000150\n",
      "[11/25][4330/9765] Loss_D: 0.0939 Loss_G: 0.0366 Convergence: 0.0960 k= 0.021946 lr = 0.0000150\n",
      "[11/25][4340/9765] Loss_D: 0.0971 Loss_G: 0.0402 Convergence: 0.0990 k= 0.021962 lr = 0.0000150\n",
      "[11/25][4350/9765] Loss_D: 0.0954 Loss_G: 0.0423 Convergence: 0.1001 k= 0.021932 lr = 0.0000150\n",
      "[11/25][4360/9765] Loss_D: 0.0890 Loss_G: 0.0421 Convergence: 0.0961 k= 0.021905 lr = 0.0000150\n",
      "[11/25][4370/9765] Loss_D: 0.1043 Loss_G: 0.0438 Convergence: 0.1070 k= 0.021872 lr = 0.0000150\n",
      "[11/25][4380/9765] Loss_D: 0.1048 Loss_G: 0.0395 Convergence: 0.1084 k= 0.021877 lr = 0.0000150\n",
      "[11/25][4390/9765] Loss_D: 0.0943 Loss_G: 0.0363 Convergence: 0.0969 k= 0.021911 lr = 0.0000150\n",
      "[11/25][4400/9765] Loss_D: 0.0856 Loss_G: 0.0372 Convergence: 0.0890 k= 0.021933 lr = 0.0000150\n",
      "[11/25][4410/9765] Loss_D: 0.0918 Loss_G: 0.0410 Convergence: 0.0966 k= 0.021934 lr = 0.0000150\n",
      "[11/25][4420/9765] Loss_D: 0.0931 Loss_G: 0.0437 Convergence: 0.1001 k= 0.021896 lr = 0.0000150\n",
      "[11/25][4430/9765] Loss_D: 0.0966 Loss_G: 0.0419 Convergence: 0.1004 k= 0.021867 lr = 0.0000150\n",
      "[11/25][4440/9765] Loss_D: 0.1042 Loss_G: 0.0381 Convergence: 0.1089 k= 0.021888 lr = 0.0000150\n",
      "[11/25][4450/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0945 k= 0.021888 lr = 0.0000150\n",
      "[11/25][4460/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0971 k= 0.021886 lr = 0.0000150\n",
      "[11/25][4470/9765] Loss_D: 0.1050 Loss_G: 0.0420 Convergence: 0.1063 k= 0.021880 lr = 0.0000150\n",
      "[11/25][4480/9765] Loss_D: 0.1036 Loss_G: 0.0401 Convergence: 0.1063 k= 0.021852 lr = 0.0000150\n",
      "[11/25][4490/9765] Loss_D: 0.1060 Loss_G: 0.0388 Convergence: 0.1108 k= 0.021846 lr = 0.0000150\n",
      "[11/25][4500/9765] Loss_D: 0.0941 Loss_G: 0.0422 Convergence: 0.0991 k= 0.021837 lr = 0.0000150\n",
      "[11/25][4510/9765] Loss_D: 0.0920 Loss_G: 0.0384 Convergence: 0.0941 k= 0.021813 lr = 0.0000150\n",
      "[11/25][4520/9765] Loss_D: 0.1025 Loss_G: 0.0395 Convergence: 0.1053 k= 0.021817 lr = 0.0000150\n",
      "[11/25][4530/9765] Loss_D: 0.1013 Loss_G: 0.0389 Convergence: 0.1041 k= 0.021831 lr = 0.0000150\n",
      "[11/25][4540/9765] Loss_D: 0.0991 Loss_G: 0.0398 Convergence: 0.1001 k= 0.021824 lr = 0.0000150\n",
      "[11/25][4550/9765] Loss_D: 0.0945 Loss_G: 0.0398 Convergence: 0.0971 k= 0.021809 lr = 0.0000150\n",
      "[11/25][4560/9765] Loss_D: 0.0985 Loss_G: 0.0424 Convergence: 0.1020 k= 0.021787 lr = 0.0000150\n",
      "[11/25][4570/9765] Loss_D: 0.0959 Loss_G: 0.0369 Convergence: 0.0986 k= 0.021786 lr = 0.0000150\n",
      "[11/25][4580/9765] Loss_D: 0.0977 Loss_G: 0.0405 Convergence: 0.0996 k= 0.021806 lr = 0.0000150\n",
      "[11/25][4590/9765] Loss_D: 0.0992 Loss_G: 0.0387 Convergence: 0.1013 k= 0.021801 lr = 0.0000150\n",
      "[11/25][4600/9765] Loss_D: 0.0932 Loss_G: 0.0423 Convergence: 0.0987 k= 0.021791 lr = 0.0000150\n",
      "[11/25][4610/9765] Loss_D: 0.0953 Loss_G: 0.0389 Convergence: 0.0966 k= 0.021788 lr = 0.0000150\n",
      "[11/25][4620/9765] Loss_D: 0.1036 Loss_G: 0.0401 Convergence: 0.1061 k= 0.021785 lr = 0.0000150\n",
      "[11/25][4630/9765] Loss_D: 0.1045 Loss_G: 0.0410 Convergence: 0.1066 k= 0.021782 lr = 0.0000150\n",
      "[11/25][4640/9765] Loss_D: 0.0982 Loss_G: 0.0392 Convergence: 0.0994 k= 0.021766 lr = 0.0000150\n",
      "[11/25][4650/9765] Loss_D: 0.1031 Loss_G: 0.0411 Convergence: 0.1045 k= 0.021762 lr = 0.0000150\n",
      "[11/25][4660/9765] Loss_D: 0.1025 Loss_G: 0.0360 Convergence: 0.1086 k= 0.021764 lr = 0.0000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][4670/9765] Loss_D: 0.0968 Loss_G: 0.0377 Convergence: 0.0989 k= 0.021780 lr = 0.0000150\n",
      "[11/25][4680/9765] Loss_D: 0.0844 Loss_G: 0.0381 Convergence: 0.0893 k= 0.021782 lr = 0.0000150\n",
      "[11/25][4690/9765] Loss_D: 0.1045 Loss_G: 0.0381 Convergence: 0.1093 k= 0.021777 lr = 0.0000150\n",
      "[11/25][4700/9765] Loss_D: 0.0963 Loss_G: 0.0398 Convergence: 0.0981 k= 0.021771 lr = 0.0000150\n",
      "[11/25][4710/9765] Loss_D: 0.0933 Loss_G: 0.0386 Convergence: 0.0951 k= 0.021763 lr = 0.0000150\n",
      "[11/25][4720/9765] Loss_D: 0.0927 Loss_G: 0.0400 Convergence: 0.0961 k= 0.021775 lr = 0.0000150\n",
      "[11/25][4730/9765] Loss_D: 0.0927 Loss_G: 0.0377 Convergence: 0.0938 k= 0.021791 lr = 0.0000150\n",
      "[11/25][4740/9765] Loss_D: 0.0934 Loss_G: 0.0387 Convergence: 0.0953 k= 0.021817 lr = 0.0000150\n",
      "[11/25][4750/9765] Loss_D: 0.0989 Loss_G: 0.0382 Convergence: 0.1013 k= 0.021823 lr = 0.0000150\n",
      "[11/25][4760/9765] Loss_D: 0.1017 Loss_G: 0.0372 Convergence: 0.1063 k= 0.021834 lr = 0.0000150\n",
      "[11/25][4770/9765] Loss_D: 0.0927 Loss_G: 0.0384 Convergence: 0.0946 k= 0.021839 lr = 0.0000150\n",
      "[11/25][4780/9765] Loss_D: 0.0996 Loss_G: 0.0421 Convergence: 0.1024 k= 0.021846 lr = 0.0000150\n",
      "[11/25][4790/9765] Loss_D: 0.1045 Loss_G: 0.0408 Convergence: 0.1068 k= 0.021837 lr = 0.0000150\n",
      "[11/25][4800/9765] Loss_D: 0.0955 Loss_G: 0.0402 Convergence: 0.0980 k= 0.021840 lr = 0.0000150\n",
      "[11/25][4810/9765] Loss_D: 0.1003 Loss_G: 0.0363 Convergence: 0.1052 k= 0.021853 lr = 0.0000150\n",
      "[11/25][4820/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0962 k= 0.021845 lr = 0.0000150\n",
      "[11/25][4830/9765] Loss_D: 0.1019 Loss_G: 0.0431 Convergence: 0.1048 k= 0.021836 lr = 0.0000150\n",
      "[11/25][4840/9765] Loss_D: 0.0939 Loss_G: 0.0369 Convergence: 0.0956 k= 0.021824 lr = 0.0000150\n",
      "[11/25][4850/9765] Loss_D: 0.0953 Loss_G: 0.0427 Convergence: 0.1004 k= 0.021836 lr = 0.0000150\n",
      "[11/25][4860/9765] Loss_D: 0.0972 Loss_G: 0.0421 Convergence: 0.1009 k= 0.021818 lr = 0.0000150\n",
      "[11/25][4870/9765] Loss_D: 0.0927 Loss_G: 0.0392 Convergence: 0.0954 k= 0.021799 lr = 0.0000150\n",
      "[11/25][4880/9765] Loss_D: 0.0910 Loss_G: 0.0416 Convergence: 0.0967 k= 0.021799 lr = 0.0000150\n",
      "[11/25][4890/9765] Loss_D: 0.0982 Loss_G: 0.0395 Convergence: 0.0992 k= 0.021783 lr = 0.0000150\n",
      "[11/25][4900/9765] Loss_D: 0.1065 Loss_G: 0.0420 Convergence: 0.1083 k= 0.021783 lr = 0.0000150\n",
      "[11/25][4910/9765] Loss_D: 0.0978 Loss_G: 0.0381 Convergence: 0.1000 k= 0.021795 lr = 0.0000150\n",
      "[11/25][4920/9765] Loss_D: 0.1039 Loss_G: 0.0414 Convergence: 0.1054 k= 0.021784 lr = 0.0000150\n",
      "[11/25][4930/9765] Loss_D: 0.1094 Loss_G: 0.0429 Convergence: 0.1115 k= 0.021766 lr = 0.0000150\n",
      "[11/25][4940/9765] Loss_D: 0.0917 Loss_G: 0.0388 Convergence: 0.0944 k= 0.021757 lr = 0.0000150\n",
      "[11/25][4950/9765] Loss_D: 0.0942 Loss_G: 0.0398 Convergence: 0.0969 k= 0.021753 lr = 0.0000150\n",
      "[11/25][4960/9765] Loss_D: 0.1014 Loss_G: 0.0372 Convergence: 0.1059 k= 0.021755 lr = 0.0000150\n",
      "[11/25][4970/9765] Loss_D: 0.1034 Loss_G: 0.0429 Convergence: 0.1055 k= 0.021755 lr = 0.0000150\n",
      "[11/25][4980/9765] Loss_D: 0.1035 Loss_G: 0.0409 Convergence: 0.1053 k= 0.021733 lr = 0.0000150\n",
      "[11/25][4990/9765] Loss_D: 0.1045 Loss_G: 0.0385 Convergence: 0.1090 k= 0.021741 lr = 0.0000150\n",
      "[11/25][5000/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0991 k= 0.021751 lr = 0.0000150\n",
      "[11/25][5010/9765] Loss_D: 0.1034 Loss_G: 0.0425 Convergence: 0.1050 k= 0.021749 lr = 0.0000150\n",
      "[11/25][5020/9765] Loss_D: 0.1047 Loss_G: 0.0616 Convergence: 0.1251 k= 0.021691 lr = 0.0000150\n",
      "[11/25][5030/9765] Loss_D: 0.1012 Loss_G: 0.0586 Convergence: 0.1201 k= 0.021490 lr = 0.0000150\n",
      "[11/25][5040/9765] Loss_D: 0.0916 Loss_G: 0.0393 Convergence: 0.0948 k= 0.021419 lr = 0.0000150\n",
      "[11/25][5050/9765] Loss_D: 0.0991 Loss_G: 0.0342 Convergence: 0.1055 k= 0.021453 lr = 0.0000150\n",
      "[11/25][5060/9765] Loss_D: 0.1008 Loss_G: 0.0346 Convergence: 0.1075 k= 0.021522 lr = 0.0000150\n",
      "[11/25][5070/9765] Loss_D: 0.1032 Loss_G: 0.0398 Convergence: 0.1058 k= 0.021563 lr = 0.0000150\n",
      "[11/25][5080/9765] Loss_D: 0.0957 Loss_G: 0.0410 Convergence: 0.0990 k= 0.021556 lr = 0.0000150\n",
      "[11/25][5090/9765] Loss_D: 0.0965 Loss_G: 0.0457 Convergence: 0.1042 k= 0.021513 lr = 0.0000150\n",
      "[11/25][5100/9765] Loss_D: 0.0925 Loss_G: 0.0397 Convergence: 0.0957 k= 0.021488 lr = 0.0000150\n",
      "[11/25][5110/9765] Loss_D: 0.1058 Loss_G: 0.0404 Convergence: 0.1090 k= 0.021486 lr = 0.0000150\n",
      "[11/25][5120/9765] Loss_D: 0.0923 Loss_G: 0.0384 Convergence: 0.0943 k= 0.021478 lr = 0.0000150\n",
      "[11/25][5130/9765] Loss_D: 0.0952 Loss_G: 0.0399 Convergence: 0.0976 k= 0.021480 lr = 0.0000150\n",
      "[11/25][5140/9765] Loss_D: 0.0950 Loss_G: 0.0411 Convergence: 0.0986 k= 0.021474 lr = 0.0000150\n",
      "[11/25][5150/9765] Loss_D: 0.0921 Loss_G: 0.0351 Convergence: 0.0950 k= 0.021491 lr = 0.0000150\n",
      "[11/25][5160/9765] Loss_D: 0.0973 Loss_G: 0.0377 Convergence: 0.0997 k= 0.021499 lr = 0.0000150\n",
      "[11/25][5170/9765] Loss_D: 0.0943 Loss_G: 0.0400 Convergence: 0.0971 k= 0.021498 lr = 0.0000150\n",
      "[11/25][5180/9765] Loss_D: 0.0942 Loss_G: 0.0369 Convergence: 0.0961 k= 0.021498 lr = 0.0000150\n",
      "[11/25][5190/9765] Loss_D: 0.0969 Loss_G: 0.0414 Convergence: 0.1000 k= 0.021497 lr = 0.0000150\n",
      "[11/25][5200/9765] Loss_D: 0.0888 Loss_G: 0.0404 Convergence: 0.0941 k= 0.021511 lr = 0.0000150\n",
      "[11/25][5210/9765] Loss_D: 0.0905 Loss_G: 0.0373 Convergence: 0.0921 k= 0.021510 lr = 0.0000150\n",
      "[11/25][5220/9765] Loss_D: 0.0960 Loss_G: 0.0399 Convergence: 0.0980 k= 0.021524 lr = 0.0000150\n",
      "[11/25][5230/9765] Loss_D: 0.0943 Loss_G: 0.0384 Convergence: 0.0955 k= 0.021502 lr = 0.0000150\n",
      "[11/25][5240/9765] Loss_D: 0.1004 Loss_G: 0.0389 Convergence: 0.1029 k= 0.021509 lr = 0.0000150\n",
      "[11/25][5250/9765] Loss_D: 0.1000 Loss_G: 0.0374 Convergence: 0.1037 k= 0.021512 lr = 0.0000150\n",
      "[11/25][5260/9765] Loss_D: 0.1140 Loss_G: 0.0395 Convergence: 0.1212 k= 0.021523 lr = 0.0000150\n",
      "[11/25][5270/9765] Loss_D: 0.1000 Loss_G: 0.0395 Convergence: 0.1017 k= 0.021515 lr = 0.0000150\n",
      "[11/25][5280/9765] Loss_D: 0.0992 Loss_G: 0.0407 Convergence: 0.1007 k= 0.021520 lr = 0.0000150\n",
      "[11/25][5290/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0968 k= 0.021492 lr = 0.0000150\n",
      "[11/25][5300/9765] Loss_D: 0.0903 Loss_G: 0.0384 Convergence: 0.0930 k= 0.021489 lr = 0.0000150\n",
      "[11/25][5310/9765] Loss_D: 0.0896 Loss_G: 0.0394 Convergence: 0.0937 k= 0.021481 lr = 0.0000150\n",
      "[11/25][5320/9765] Loss_D: 0.0872 Loss_G: 0.0382 Convergence: 0.0910 k= 0.021473 lr = 0.0000150\n",
      "[11/25][5330/9765] Loss_D: 0.0942 Loss_G: 0.0412 Convergence: 0.0982 k= 0.021470 lr = 0.0000150\n",
      "[11/25][5340/9765] Loss_D: 0.0918 Loss_G: 0.0391 Convergence: 0.0946 k= 0.021459 lr = 0.0000150\n",
      "[11/25][5350/9765] Loss_D: 0.0889 Loss_G: 0.0378 Convergence: 0.0916 k= 0.021449 lr = 0.0000150\n",
      "[11/25][5360/9765] Loss_D: 0.1085 Loss_G: 0.0402 Convergence: 0.1129 k= 0.021460 lr = 0.0000150\n",
      "[11/25][5370/9765] Loss_D: 0.1062 Loss_G: 0.0422 Convergence: 0.1078 k= 0.021450 lr = 0.0000150\n",
      "[11/25][5380/9765] Loss_D: 0.0990 Loss_G: 0.0381 Convergence: 0.1017 k= 0.021437 lr = 0.0000150\n",
      "[11/25][5390/9765] Loss_D: 0.1038 Loss_G: 0.0374 Convergence: 0.1090 k= 0.021445 lr = 0.0000150\n",
      "[11/25][5400/9765] Loss_D: 0.1000 Loss_G: 0.0344 Convergence: 0.1067 k= 0.021480 lr = 0.0000150\n",
      "[11/25][5410/9765] Loss_D: 0.0963 Loss_G: 0.0379 Convergence: 0.0981 k= 0.021503 lr = 0.0000150\n",
      "[11/25][5420/9765] Loss_D: 0.1048 Loss_G: 0.0428 Convergence: 0.1062 k= 0.021506 lr = 0.0000150\n",
      "[11/25][5430/9765] Loss_D: 0.1025 Loss_G: 0.0414 Convergence: 0.1034 k= 0.021491 lr = 0.0000150\n",
      "[11/25][5440/9765] Loss_D: 0.1030 Loss_G: 0.0442 Convergence: 0.1065 k= 0.021461 lr = 0.0000150\n",
      "[11/25][5450/9765] Loss_D: 0.1017 Loss_G: 0.0407 Convergence: 0.1029 k= 0.021439 lr = 0.0000150\n",
      "[11/25][5460/9765] Loss_D: 0.0919 Loss_G: 0.0390 Convergence: 0.0947 k= 0.021412 lr = 0.0000150\n",
      "[11/25][5470/9765] Loss_D: 0.0919 Loss_G: 0.0391 Convergence: 0.0948 k= 0.021419 lr = 0.0000150\n",
      "[11/25][5480/9765] Loss_D: 0.0958 Loss_G: 0.0369 Convergence: 0.0982 k= 0.021443 lr = 0.0000150\n",
      "[11/25][5490/9765] Loss_D: 0.0965 Loss_G: 0.0417 Convergence: 0.1002 k= 0.021437 lr = 0.0000150\n",
      "[11/25][5500/9765] Loss_D: 0.0891 Loss_G: 0.0404 Convergence: 0.0944 k= 0.021421 lr = 0.0000150\n",
      "[11/25][5510/9765] Loss_D: 0.0974 Loss_G: 0.0381 Convergence: 0.0994 k= 0.021425 lr = 0.0000150\n",
      "[11/25][5520/9765] Loss_D: 0.0978 Loss_G: 0.0380 Convergence: 0.1000 k= 0.021429 lr = 0.0000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][5530/9765] Loss_D: 0.0966 Loss_G: 0.0382 Convergence: 0.0982 k= 0.021434 lr = 0.0000150\n",
      "[11/25][5540/9765] Loss_D: 0.0958 Loss_G: 0.0385 Convergence: 0.0968 k= 0.021433 lr = 0.0000150\n",
      "[11/25][5550/9765] Loss_D: 0.0995 Loss_G: 0.0381 Convergence: 0.1022 k= 0.021433 lr = 0.0000150\n",
      "[11/25][5560/9765] Loss_D: 0.0985 Loss_G: 0.0387 Convergence: 0.1003 k= 0.021444 lr = 0.0000150\n",
      "[11/25][5570/9765] Loss_D: 0.0955 Loss_G: 0.0405 Convergence: 0.0984 k= 0.021438 lr = 0.0000150\n",
      "[11/25][5580/9765] Loss_D: 0.1028 Loss_G: 0.0387 Convergence: 0.1063 k= 0.021427 lr = 0.0000150\n",
      "[11/25][5590/9765] Loss_D: 0.1035 Loss_G: 0.0410 Convergence: 0.1051 k= 0.021435 lr = 0.0000150\n",
      "[11/25][5600/9765] Loss_D: 0.1052 Loss_G: 0.0376 Convergence: 0.1108 k= 0.021460 lr = 0.0000150\n",
      "[11/25][5610/9765] Loss_D: 0.0961 Loss_G: 0.0382 Convergence: 0.0976 k= 0.021478 lr = 0.0000150\n",
      "[11/25][5620/9765] Loss_D: 0.0997 Loss_G: 0.0424 Convergence: 0.1028 k= 0.021464 lr = 0.0000150\n",
      "[11/25][5630/9765] Loss_D: 0.0879 Loss_G: 0.0392 Convergence: 0.0925 k= 0.021433 lr = 0.0000150\n",
      "[11/25][5640/9765] Loss_D: 0.1015 Loss_G: 0.0404 Convergence: 0.1029 k= 0.021427 lr = 0.0000150\n",
      "[11/25][5650/9765] Loss_D: 0.0922 Loss_G: 0.0409 Convergence: 0.0968 k= 0.021411 lr = 0.0000150\n",
      "[11/25][5660/9765] Loss_D: 0.0990 Loss_G: 0.0353 Convergence: 0.1044 k= 0.021406 lr = 0.0000150\n",
      "[11/25][5670/9765] Loss_D: 0.0964 Loss_G: 0.0399 Convergence: 0.0982 k= 0.021426 lr = 0.0000150\n",
      "[11/25][5680/9765] Loss_D: 0.0980 Loss_G: 0.0390 Convergence: 0.0993 k= 0.021425 lr = 0.0000150\n",
      "[11/25][5690/9765] Loss_D: 0.0879 Loss_G: 0.0374 Convergence: 0.0906 k= 0.021422 lr = 0.0000150\n",
      "[11/25][5700/9765] Loss_D: 0.0979 Loss_G: 0.0411 Convergence: 0.1003 k= 0.021425 lr = 0.0000150\n",
      "[11/25][5710/9765] Loss_D: 0.1015 Loss_G: 0.0420 Convergence: 0.1034 k= 0.021422 lr = 0.0000150\n",
      "[11/25][5720/9765] Loss_D: 0.0854 Loss_G: 0.0400 Convergence: 0.0917 k= 0.021406 lr = 0.0000150\n",
      "[11/25][5730/9765] Loss_D: 0.0954 Loss_G: 0.0367 Convergence: 0.0980 k= 0.021412 lr = 0.0000150\n",
      "[11/25][5740/9765] Loss_D: 0.1015 Loss_G: 0.0394 Convergence: 0.1039 k= 0.021431 lr = 0.0000150\n",
      "[11/25][5750/9765] Loss_D: 0.0972 Loss_G: 0.0396 Convergence: 0.0984 k= 0.021441 lr = 0.0000150\n",
      "[11/25][5760/9765] Loss_D: 0.1003 Loss_G: 0.0401 Convergence: 0.1015 k= 0.021438 lr = 0.0000150\n",
      "[11/25][5770/9765] Loss_D: 0.0935 Loss_G: 0.0401 Convergence: 0.0967 k= 0.021424 lr = 0.0000150\n",
      "[11/25][5780/9765] Loss_D: 0.1045 Loss_G: 0.0395 Convergence: 0.1080 k= 0.021428 lr = 0.0000150\n",
      "[11/25][5790/9765] Loss_D: 0.1024 Loss_G: 0.0396 Convergence: 0.1050 k= 0.021438 lr = 0.0000150\n",
      "[11/25][5800/9765] Loss_D: 0.1048 Loss_G: 0.0421 Convergence: 0.1060 k= 0.021437 lr = 0.0000150\n",
      "[11/25][5810/9765] Loss_D: 0.0948 Loss_G: 0.0396 Convergence: 0.0970 k= 0.021416 lr = 0.0000150\n",
      "[11/25][5820/9765] Loss_D: 0.0996 Loss_G: 0.0392 Convergence: 0.1014 k= 0.021435 lr = 0.0000150\n",
      "[11/25][5830/9765] Loss_D: 0.0930 Loss_G: 0.0399 Convergence: 0.0963 k= 0.021432 lr = 0.0000150\n",
      "[11/25][5840/9765] Loss_D: 0.0891 Loss_G: 0.0390 Convergence: 0.0929 k= 0.021424 lr = 0.0000150\n",
      "[11/25][5850/9765] Loss_D: 0.1017 Loss_G: 0.0390 Convergence: 0.1045 k= 0.021441 lr = 0.0000150\n",
      "[11/25][5860/9765] Loss_D: 0.0930 Loss_G: 0.0396 Convergence: 0.0959 k= 0.021437 lr = 0.0000150\n",
      "[11/25][5870/9765] Loss_D: 0.0861 Loss_G: 0.0380 Convergence: 0.0901 k= 0.021441 lr = 0.0000150\n",
      "[11/25][5880/9765] Loss_D: 0.0986 Loss_G: 0.0447 Convergence: 0.1044 k= 0.021427 lr = 0.0000150\n",
      "[11/25][5890/9765] Loss_D: 0.0968 Loss_G: 0.0418 Convergence: 0.1004 k= 0.021401 lr = 0.0000150\n",
      "[11/25][5900/9765] Loss_D: 0.0944 Loss_G: 0.0417 Convergence: 0.0989 k= 0.021389 lr = 0.0000150\n",
      "[11/25][5910/9765] Loss_D: 0.0996 Loss_G: 0.0379 Convergence: 0.1027 k= 0.021398 lr = 0.0000150\n",
      "[11/25][5920/9765] Loss_D: 0.0970 Loss_G: 0.0409 Convergence: 0.0997 k= 0.021405 lr = 0.0000150\n",
      "[11/25][5930/9765] Loss_D: 0.0933 Loss_G: 0.0403 Convergence: 0.0968 k= 0.021387 lr = 0.0000150\n",
      "[11/25][5940/9765] Loss_D: 0.1011 Loss_G: 0.0407 Convergence: 0.1020 k= 0.021375 lr = 0.0000150\n",
      "[11/25][5950/9765] Loss_D: 0.0936 Loss_G: 0.0387 Convergence: 0.0954 k= 0.021368 lr = 0.0000150\n",
      "[11/25][5960/9765] Loss_D: 0.0997 Loss_G: 0.0385 Convergence: 0.1023 k= 0.021388 lr = 0.0000150\n",
      "[11/25][5970/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0966 k= 0.021383 lr = 0.0000150\n",
      "[11/25][5980/9765] Loss_D: 0.0965 Loss_G: 0.0394 Convergence: 0.0978 k= 0.021393 lr = 0.0000150\n",
      "[11/25][5990/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.021406 lr = 0.0000150\n",
      "[11/25][6000/9765] Loss_D: 0.1009 Loss_G: 0.0393 Convergence: 0.1031 k= 0.021405 lr = 0.0000150\n",
      "[11/25][6010/9765] Loss_D: 0.0934 Loss_G: 0.0385 Convergence: 0.0950 k= 0.021424 lr = 0.0000150\n",
      "[11/25][6020/9765] Loss_D: 0.0938 Loss_G: 0.0405 Convergence: 0.0973 k= 0.021416 lr = 0.0000150\n",
      "[11/25][6030/9765] Loss_D: 0.1026 Loss_G: 0.0384 Convergence: 0.1064 k= 0.021432 lr = 0.0000150\n",
      "[11/25][6040/9765] Loss_D: 0.0982 Loss_G: 0.0372 Convergence: 0.1014 k= 0.021423 lr = 0.0000150\n",
      "[11/25][6050/9765] Loss_D: 0.0972 Loss_G: 0.0393 Convergence: 0.0981 k= 0.021427 lr = 0.0000150\n",
      "[11/25][6060/9765] Loss_D: 0.0958 Loss_G: 0.0358 Convergence: 0.0995 k= 0.021438 lr = 0.0000150\n",
      "[11/25][6070/9765] Loss_D: 0.1002 Loss_G: 0.0391 Convergence: 0.1024 k= 0.021440 lr = 0.0000150\n",
      "[11/25][6080/9765] Loss_D: 0.0892 Loss_G: 0.0442 Convergence: 0.0983 k= 0.021407 lr = 0.0000150\n",
      "[11/25][6090/9765] Loss_D: 0.0946 Loss_G: 0.0440 Convergence: 0.1013 k= 0.021353 lr = 0.0000150\n",
      "[11/25][6100/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0959 k= 0.021322 lr = 0.0000150\n",
      "[11/25][6110/9765] Loss_D: 0.0914 Loss_G: 0.0350 Convergence: 0.0941 k= 0.021348 lr = 0.0000150\n",
      "[11/25][6120/9765] Loss_D: 0.0999 Loss_G: 0.0373 Convergence: 0.1037 k= 0.021384 lr = 0.0000150\n",
      "[11/25][6130/9765] Loss_D: 0.0962 Loss_G: 0.0383 Convergence: 0.0975 k= 0.021395 lr = 0.0000150\n",
      "[11/25][6140/9765] Loss_D: 0.0929 Loss_G: 0.0385 Convergence: 0.0948 k= 0.021391 lr = 0.0000150\n",
      "[11/25][6150/9765] Loss_D: 0.0962 Loss_G: 0.0401 Convergence: 0.0984 k= 0.021396 lr = 0.0000150\n",
      "[11/25][6160/9765] Loss_D: 0.0867 Loss_G: 0.0375 Convergence: 0.0900 k= 0.021377 lr = 0.0000150\n",
      "[11/25][6170/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1026 k= 0.021391 lr = 0.0000150\n",
      "[11/25][6180/9765] Loss_D: 0.0978 Loss_G: 0.0421 Convergence: 0.1013 k= 0.021381 lr = 0.0000150\n",
      "[11/25][6190/9765] Loss_D: 0.1102 Loss_G: 0.0404 Convergence: 0.1151 k= 0.021362 lr = 0.0000150\n",
      "[11/25][6200/9765] Loss_D: 0.1084 Loss_G: 0.0406 Convergence: 0.1124 k= 0.021362 lr = 0.0000150\n",
      "[11/25][6210/9765] Loss_D: 0.1045 Loss_G: 0.0399 Convergence: 0.1075 k= 0.021355 lr = 0.0000150\n",
      "[11/25][6220/9765] Loss_D: 0.0874 Loss_G: 0.0408 Convergence: 0.0937 k= 0.021357 lr = 0.0000150\n",
      "[11/25][6230/9765] Loss_D: 0.0937 Loss_G: 0.0389 Convergence: 0.0956 k= 0.021370 lr = 0.0000150\n",
      "[11/25][6240/9765] Loss_D: 0.0962 Loss_G: 0.0384 Convergence: 0.0974 k= 0.021378 lr = 0.0000150\n",
      "[11/25][6250/9765] Loss_D: 0.0999 Loss_G: 0.0379 Convergence: 0.1031 k= 0.021380 lr = 0.0000150\n",
      "[11/25][6260/9765] Loss_D: 0.0984 Loss_G: 0.0414 Convergence: 0.1010 k= 0.021373 lr = 0.0000150\n",
      "[11/25][6270/9765] Loss_D: 0.0955 Loss_G: 0.0407 Convergence: 0.0985 k= 0.021361 lr = 0.0000150\n",
      "[11/25][6280/9765] Loss_D: 0.1025 Loss_G: 0.0441 Convergence: 0.1062 k= 0.021341 lr = 0.0000150\n",
      "[11/25][6290/9765] Loss_D: 0.0976 Loss_G: 0.0414 Convergence: 0.1005 k= 0.021328 lr = 0.0000150\n",
      "[11/25][6300/9765] Loss_D: 0.1008 Loss_G: 0.0363 Convergence: 0.1060 k= 0.021335 lr = 0.0000150\n",
      "[11/25][6310/9765] Loss_D: 0.0883 Loss_G: 0.0395 Convergence: 0.0930 k= 0.021347 lr = 0.0000150\n",
      "[11/25][6320/9765] Loss_D: 0.0905 Loss_G: 0.0393 Convergence: 0.0940 k= 0.021363 lr = 0.0000150\n",
      "[11/25][6330/9765] Loss_D: 0.0835 Loss_G: 0.0410 Convergence: 0.0916 k= 0.021348 lr = 0.0000150\n",
      "[11/25][6340/9765] Loss_D: 0.0884 Loss_G: 0.0401 Convergence: 0.0936 k= 0.021332 lr = 0.0000150\n",
      "[11/25][6350/9765] Loss_D: 0.0867 Loss_G: 0.0418 Convergence: 0.0944 k= 0.021313 lr = 0.0000150\n",
      "[11/25][6360/9765] Loss_D: 0.0955 Loss_G: 0.0352 Convergence: 0.0997 k= 0.021306 lr = 0.0000150\n",
      "[11/25][6370/9765] Loss_D: 0.0918 Loss_G: 0.0343 Convergence: 0.0953 k= 0.021339 lr = 0.0000150\n",
      "[11/25][6380/9765] Loss_D: 0.0941 Loss_G: 0.0379 Convergence: 0.0950 k= 0.021380 lr = 0.0000150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][6390/9765] Loss_D: 0.1023 Loss_G: 0.0409 Convergence: 0.1034 k= 0.021381 lr = 0.0000150\n",
      "[11/25][6400/9765] Loss_D: 0.0993 Loss_G: 0.0391 Convergence: 0.1010 k= 0.021365 lr = 0.0000150\n",
      "[11/25][6410/9765] Loss_D: 0.0948 Loss_G: 0.0405 Convergence: 0.0980 k= 0.021360 lr = 0.0000150\n",
      "[11/25][6420/9765] Loss_D: 0.0938 Loss_G: 0.0373 Convergence: 0.0952 k= 0.021356 lr = 0.0000150\n",
      "[11/25][6430/9765] Loss_D: 0.0920 Loss_G: 0.0381 Convergence: 0.0938 k= 0.021372 lr = 0.0000150\n",
      "[11/25][6440/9765] Loss_D: 0.0996 Loss_G: 0.0404 Convergence: 0.1006 k= 0.021387 lr = 0.0000150\n",
      "[11/25][6450/9765] Loss_D: 0.0980 Loss_G: 0.0418 Convergence: 0.1011 k= 0.021382 lr = 0.0000150\n",
      "[11/25][6460/9765] Loss_D: 0.0953 Loss_G: 0.0418 Convergence: 0.0995 k= 0.021358 lr = 0.0000150\n",
      "[11/25][6470/9765] Loss_D: 0.1042 Loss_G: 0.0379 Convergence: 0.1091 k= 0.021364 lr = 0.0000150\n",
      "[11/25][6480/9765] Loss_D: 0.0977 Loss_G: 0.0372 Convergence: 0.1007 k= 0.021377 lr = 0.0000150\n",
      "[11/25][6490/9765] Loss_D: 0.0946 Loss_G: 0.0400 Convergence: 0.0972 k= 0.021382 lr = 0.0000150\n",
      "[11/25][6500/9765] Loss_D: 0.0962 Loss_G: 0.0393 Convergence: 0.0976 k= 0.021388 lr = 0.0000150\n",
      "[11/25][6510/9765] Loss_D: 0.0920 Loss_G: 0.0372 Convergence: 0.0928 k= 0.021389 lr = 0.0000150\n",
      "[11/25][6520/9765] Loss_D: 0.0859 Loss_G: 0.0359 Convergence: 0.0879 k= 0.021412 lr = 0.0000150\n",
      "[11/25][6530/9765] Loss_D: 0.0961 Loss_G: 0.0374 Convergence: 0.0982 k= 0.021437 lr = 0.0000150\n",
      "[11/25][6540/9765] Loss_D: 0.1006 Loss_G: 0.0430 Convergence: 0.1039 k= 0.021431 lr = 0.0000150\n",
      "[11/25][6550/9765] Loss_D: 0.0870 Loss_G: 0.0392 Convergence: 0.0918 k= 0.021421 lr = 0.0000150\n",
      "[11/25][6560/9765] Loss_D: 0.0957 Loss_G: 0.0373 Convergence: 0.0977 k= 0.021439 lr = 0.0000150\n",
      "[11/25][6570/9765] Loss_D: 0.1013 Loss_G: 0.0363 Convergence: 0.1066 k= 0.021457 lr = 0.0000150\n",
      "[11/25][6580/9765] Loss_D: 0.1089 Loss_G: 0.0402 Convergence: 0.1134 k= 0.021485 lr = 0.0000150\n",
      "[11/25][6590/9765] Loss_D: 0.1009 Loss_G: 0.0401 Convergence: 0.1024 k= 0.021483 lr = 0.0000142\n",
      "[11/25][6600/9765] Loss_D: 0.1028 Loss_G: 0.0363 Convergence: 0.1086 k= 0.021493 lr = 0.0000142\n",
      "[11/25][6610/9765] Loss_D: 0.0913 Loss_G: 0.0369 Convergence: 0.0922 k= 0.021505 lr = 0.0000142\n",
      "[11/25][6620/9765] Loss_D: 0.0986 Loss_G: 0.0401 Convergence: 0.0998 k= 0.021508 lr = 0.0000142\n",
      "[11/25][6630/9765] Loss_D: 0.0883 Loss_G: 0.0413 Convergence: 0.0949 k= 0.021489 lr = 0.0000142\n",
      "[11/25][6640/9765] Loss_D: 0.0962 Loss_G: 0.0400 Convergence: 0.0983 k= 0.021472 lr = 0.0000142\n",
      "[11/25][6650/9765] Loss_D: 0.1038 Loss_G: 0.0392 Convergence: 0.1073 k= 0.021478 lr = 0.0000142\n",
      "[11/25][6660/9765] Loss_D: 0.0991 Loss_G: 0.0364 Convergence: 0.1034 k= 0.021484 lr = 0.0000142\n",
      "[11/25][6670/9765] Loss_D: 0.1020 Loss_G: 0.0391 Convergence: 0.1048 k= 0.021501 lr = 0.0000142\n",
      "[11/25][6680/9765] Loss_D: 0.0904 Loss_G: 0.0391 Convergence: 0.0938 k= 0.021495 lr = 0.0000142\n",
      "[11/25][6690/9765] Loss_D: 0.1018 Loss_G: 0.0397 Convergence: 0.1041 k= 0.021520 lr = 0.0000142\n",
      "[11/25][6700/9765] Loss_D: 0.0973 Loss_G: 0.0421 Convergence: 0.1010 k= 0.021502 lr = 0.0000142\n",
      "[11/25][6710/9765] Loss_D: 0.0910 Loss_G: 0.0404 Convergence: 0.0956 k= 0.021488 lr = 0.0000142\n",
      "[11/25][6720/9765] Loss_D: 0.0960 Loss_G: 0.0390 Convergence: 0.0971 k= 0.021492 lr = 0.0000142\n",
      "[11/25][6730/9765] Loss_D: 0.0951 Loss_G: 0.0368 Convergence: 0.0975 k= 0.021509 lr = 0.0000142\n",
      "[11/25][6740/9765] Loss_D: 0.0977 Loss_G: 0.0401 Convergence: 0.0992 k= 0.021519 lr = 0.0000142\n",
      "[11/25][6750/9765] Loss_D: 0.0895 Loss_G: 0.0389 Convergence: 0.0931 k= 0.021517 lr = 0.0000142\n",
      "[11/25][6760/9765] Loss_D: 0.0996 Loss_G: 0.0443 Convergence: 0.1046 k= 0.021472 lr = 0.0000142\n",
      "[11/25][6770/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0978 k= 0.021461 lr = 0.0000142\n",
      "[11/25][6780/9765] Loss_D: 0.0941 Loss_G: 0.0384 Convergence: 0.0954 k= 0.021464 lr = 0.0000142\n",
      "[11/25][6790/9765] Loss_D: 0.1111 Loss_G: 0.0392 Convergence: 0.1174 k= 0.021474 lr = 0.0000142\n",
      "[11/25][6800/9765] Loss_D: 0.1056 Loss_G: 0.0367 Convergence: 0.1122 k= 0.021494 lr = 0.0000142\n",
      "[11/25][6810/9765] Loss_D: 0.0927 Loss_G: 0.0374 Convergence: 0.0935 k= 0.021538 lr = 0.0000142\n",
      "[11/25][6820/9765] Loss_D: 0.1081 Loss_G: 0.0386 Convergence: 0.1139 k= 0.021573 lr = 0.0000142\n",
      "[11/25][6830/9765] Loss_D: 0.0974 Loss_G: 0.0403 Convergence: 0.0992 k= 0.021568 lr = 0.0000142\n",
      "[11/25][6840/9765] Loss_D: 0.1023 Loss_G: 0.0392 Convergence: 0.1052 k= 0.021568 lr = 0.0000142\n",
      "[11/25][6850/9765] Loss_D: 0.0902 Loss_G: 0.0398 Convergence: 0.0945 k= 0.021559 lr = 0.0000142\n",
      "[11/25][6860/9765] Loss_D: 0.1042 Loss_G: 0.0406 Convergence: 0.1065 k= 0.021551 lr = 0.0000142\n",
      "[11/25][6870/9765] Loss_D: 0.0951 Loss_G: 0.0412 Convergence: 0.0988 k= 0.021545 lr = 0.0000142\n",
      "[11/25][6880/9765] Loss_D: 0.0913 Loss_G: 0.0424 Convergence: 0.0977 k= 0.021523 lr = 0.0000142\n",
      "[11/25][6890/9765] Loss_D: 0.0981 Loss_G: 0.0405 Convergence: 0.0998 k= 0.021510 lr = 0.0000142\n",
      "[11/25][6900/9765] Loss_D: 0.1005 Loss_G: 0.0388 Convergence: 0.1031 k= 0.021491 lr = 0.0000142\n",
      "[11/25][6910/9765] Loss_D: 0.0958 Loss_G: 0.0392 Convergence: 0.0971 k= 0.021498 lr = 0.0000142\n",
      "[11/25][6920/9765] Loss_D: 0.0992 Loss_G: 0.0413 Convergence: 0.1013 k= 0.021480 lr = 0.0000142\n",
      "[11/25][6930/9765] Loss_D: 0.1066 Loss_G: 0.0385 Convergence: 0.1119 k= 0.021491 lr = 0.0000142\n",
      "[11/25][6940/9765] Loss_D: 0.1122 Loss_G: 0.0374 Convergence: 0.1208 k= 0.021500 lr = 0.0000142\n",
      "[11/25][6950/9765] Loss_D: 0.0926 Loss_G: 0.0405 Convergence: 0.0965 k= 0.021506 lr = 0.0000142\n",
      "[11/25][6960/9765] Loss_D: 0.0885 Loss_G: 0.0363 Convergence: 0.0899 k= 0.021503 lr = 0.0000142\n",
      "[11/25][6970/9765] Loss_D: 0.0870 Loss_G: 0.0364 Convergence: 0.0891 k= 0.021513 lr = 0.0000142\n",
      "[11/25][6980/9765] Loss_D: 0.0869 Loss_G: 0.0397 Convergence: 0.0923 k= 0.021531 lr = 0.0000142\n",
      "[11/25][6990/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0967 k= 0.021546 lr = 0.0000142\n",
      "[11/25][7000/9765] Loss_D: 0.0952 Loss_G: 0.0416 Convergence: 0.0992 k= 0.021538 lr = 0.0000142\n",
      "[11/25][7010/9765] Loss_D: 0.1061 Loss_G: 0.0381 Convergence: 0.1116 k= 0.021536 lr = 0.0000142\n",
      "[11/25][7020/9765] Loss_D: 0.0880 Loss_G: 0.0379 Convergence: 0.0912 k= 0.021564 lr = 0.0000142\n",
      "[11/25][7030/9765] Loss_D: 0.0910 Loss_G: 0.0381 Convergence: 0.0932 k= 0.021575 lr = 0.0000142\n",
      "[11/25][7040/9765] Loss_D: 0.1052 Loss_G: 0.0386 Convergence: 0.1098 k= 0.021575 lr = 0.0000142\n",
      "[11/25][7050/9765] Loss_D: 0.1010 Loss_G: 0.0377 Convergence: 0.1048 k= 0.021582 lr = 0.0000142\n",
      "[11/25][7060/9765] Loss_D: 0.0989 Loss_G: 0.0379 Convergence: 0.1017 k= 0.021596 lr = 0.0000142\n",
      "[11/25][7070/9765] Loss_D: 0.0973 Loss_G: 0.0386 Convergence: 0.0988 k= 0.021616 lr = 0.0000142\n",
      "[11/25][7080/9765] Loss_D: 0.1048 Loss_G: 0.0389 Convergence: 0.1090 k= 0.021615 lr = 0.0000142\n",
      "[11/25][7090/9765] Loss_D: 0.0897 Loss_G: 0.0366 Convergence: 0.0909 k= 0.021634 lr = 0.0000142\n",
      "[11/25][7100/9765] Loss_D: 0.0917 Loss_G: 0.0391 Convergence: 0.0947 k= 0.021645 lr = 0.0000142\n",
      "[11/25][7110/9765] Loss_D: 0.0971 Loss_G: 0.0396 Convergence: 0.0984 k= 0.021660 lr = 0.0000142\n",
      "[11/25][7120/9765] Loss_D: 0.1059 Loss_G: 0.0429 Convergence: 0.1070 k= 0.021658 lr = 0.0000142\n",
      "[11/25][7130/9765] Loss_D: 0.0966 Loss_G: 0.0399 Convergence: 0.0983 k= 0.021646 lr = 0.0000142\n",
      "[11/25][7140/9765] Loss_D: 0.1002 Loss_G: 0.0408 Convergence: 0.1014 k= 0.021626 lr = 0.0000142\n",
      "[11/25][7150/9765] Loss_D: 0.0900 Loss_G: 0.0411 Convergence: 0.0957 k= 0.021612 lr = 0.0000142\n",
      "[11/25][7160/9765] Loss_D: 0.1019 Loss_G: 0.0385 Convergence: 0.1053 k= 0.021622 lr = 0.0000142\n",
      "[11/25][7170/9765] Loss_D: 0.0904 Loss_G: 0.0371 Convergence: 0.0918 k= 0.021647 lr = 0.0000142\n",
      "[11/25][7180/9765] Loss_D: 0.0956 Loss_G: 0.0345 Convergence: 0.1005 k= 0.021680 lr = 0.0000142\n",
      "[11/25][7190/9765] Loss_D: 0.0978 Loss_G: 0.0361 Convergence: 0.1020 k= 0.021710 lr = 0.0000142\n",
      "[11/25][7200/9765] Loss_D: 0.0944 Loss_G: 0.0401 Convergence: 0.0973 k= 0.021714 lr = 0.0000142\n",
      "[11/25][7210/9765] Loss_D: 0.1064 Loss_G: 0.0405 Convergence: 0.1098 k= 0.021695 lr = 0.0000142\n",
      "[11/25][7220/9765] Loss_D: 0.0887 Loss_G: 0.0403 Convergence: 0.0941 k= 0.021670 lr = 0.0000142\n",
      "[11/25][7230/9765] Loss_D: 0.0921 Loss_G: 0.0397 Convergence: 0.0954 k= 0.021655 lr = 0.0000142\n",
      "[11/25][7240/9765] Loss_D: 0.0954 Loss_G: 0.0425 Convergence: 0.1003 k= 0.021660 lr = 0.0000142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][7250/9765] Loss_D: 0.1116 Loss_G: 0.0426 Convergence: 0.1149 k= 0.021659 lr = 0.0000142\n",
      "[11/25][7260/9765] Loss_D: 0.1008 Loss_G: 0.0398 Convergence: 0.1025 k= 0.021648 lr = 0.0000142\n",
      "[11/25][7270/9765] Loss_D: 0.0984 Loss_G: 0.0437 Convergence: 0.1032 k= 0.021633 lr = 0.0000142\n",
      "[11/25][7280/9765] Loss_D: 0.0851 Loss_G: 0.0401 Convergence: 0.0917 k= 0.021613 lr = 0.0000142\n",
      "[11/25][7290/9765] Loss_D: 0.1027 Loss_G: 0.0404 Convergence: 0.1046 k= 0.021616 lr = 0.0000142\n",
      "[11/25][7300/9765] Loss_D: 0.0928 Loss_G: 0.0420 Convergence: 0.0983 k= 0.021587 lr = 0.0000142\n",
      "[11/25][7310/9765] Loss_D: 0.0915 Loss_G: 0.0405 Convergence: 0.0960 k= 0.021565 lr = 0.0000142\n",
      "[11/25][7320/9765] Loss_D: 0.0948 Loss_G: 0.0419 Convergence: 0.0993 k= 0.021547 lr = 0.0000142\n",
      "[11/25][7330/9765] Loss_D: 0.0974 Loss_G: 0.0360 Convergence: 0.1015 k= 0.021566 lr = 0.0000142\n",
      "[11/25][7340/9765] Loss_D: 0.0951 Loss_G: 0.0398 Convergence: 0.0973 k= 0.021595 lr = 0.0000142\n",
      "[11/25][7350/9765] Loss_D: 0.0895 Loss_G: 0.0393 Convergence: 0.0935 k= 0.021574 lr = 0.0000142\n",
      "[11/25][7360/9765] Loss_D: 0.0906 Loss_G: 0.0393 Convergence: 0.0942 k= 0.021591 lr = 0.0000142\n",
      "[11/25][7370/9765] Loss_D: 0.0937 Loss_G: 0.0411 Convergence: 0.0978 k= 0.021598 lr = 0.0000142\n",
      "[11/25][7380/9765] Loss_D: 0.0874 Loss_G: 0.0373 Convergence: 0.0903 k= 0.021602 lr = 0.0000142\n",
      "[11/25][7390/9765] Loss_D: 0.1021 Loss_G: 0.0382 Convergence: 0.1059 k= 0.021634 lr = 0.0000142\n",
      "[11/25][7400/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1006 k= 0.021650 lr = 0.0000142\n",
      "[11/25][7410/9765] Loss_D: 0.1044 Loss_G: 0.0426 Convergence: 0.1058 k= 0.021631 lr = 0.0000142\n",
      "[11/25][7420/9765] Loss_D: 0.1060 Loss_G: 0.0416 Convergence: 0.1080 k= 0.021617 lr = 0.0000142\n",
      "[11/25][7430/9765] Loss_D: 0.1004 Loss_G: 0.0417 Convergence: 0.1024 k= 0.021594 lr = 0.0000142\n",
      "[11/25][7440/9765] Loss_D: 0.1027 Loss_G: 0.0404 Convergence: 0.1045 k= 0.021592 lr = 0.0000142\n",
      "[11/25][7450/9765] Loss_D: 0.1000 Loss_G: 0.0413 Convergence: 0.1019 k= 0.021573 lr = 0.0000142\n",
      "[11/25][7460/9765] Loss_D: 0.1008 Loss_G: 0.0399 Convergence: 0.1024 k= 0.021585 lr = 0.0000142\n",
      "[11/25][7470/9765] Loss_D: 0.0958 Loss_G: 0.0396 Convergence: 0.0975 k= 0.021565 lr = 0.0000142\n",
      "[11/25][7480/9765] Loss_D: 0.0932 Loss_G: 0.0378 Convergence: 0.0943 k= 0.021573 lr = 0.0000142\n",
      "[11/25][7490/9765] Loss_D: 0.1030 Loss_G: 0.0357 Convergence: 0.1095 k= 0.021587 lr = 0.0000142\n",
      "[11/25][7500/9765] Loss_D: 0.0979 Loss_G: 0.0380 Convergence: 0.1001 k= 0.021606 lr = 0.0000142\n",
      "[11/25][7510/9765] Loss_D: 0.0950 Loss_G: 0.0400 Convergence: 0.0975 k= 0.021589 lr = 0.0000142\n",
      "[11/25][7520/9765] Loss_D: 0.0942 Loss_G: 0.0403 Convergence: 0.0973 k= 0.021575 lr = 0.0000142\n",
      "[11/25][7530/9765] Loss_D: 0.0938 Loss_G: 0.0428 Convergence: 0.0996 k= 0.021554 lr = 0.0000142\n",
      "[11/25][7540/9765] Loss_D: 0.0924 Loss_G: 0.0414 Convergence: 0.0974 k= 0.021546 lr = 0.0000142\n",
      "[11/25][7550/9765] Loss_D: 0.1035 Loss_G: 0.0400 Convergence: 0.1061 k= 0.021538 lr = 0.0000142\n",
      "[11/25][7560/9765] Loss_D: 0.1030 Loss_G: 0.0412 Convergence: 0.1042 k= 0.021537 lr = 0.0000142\n",
      "[11/25][7570/9765] Loss_D: 0.0931 Loss_G: 0.0390 Convergence: 0.0954 k= 0.021534 lr = 0.0000142\n",
      "[11/25][7580/9765] Loss_D: 0.0988 Loss_G: 0.0366 Convergence: 0.1028 k= 0.021538 lr = 0.0000142\n",
      "[11/25][7590/9765] Loss_D: 0.0897 Loss_G: 0.0386 Convergence: 0.0930 k= 0.021550 lr = 0.0000142\n",
      "[11/25][7600/9765] Loss_D: 0.0995 Loss_G: 0.0416 Convergence: 0.1018 k= 0.021560 lr = 0.0000142\n",
      "[11/25][7610/9765] Loss_D: 0.0931 Loss_G: 0.0407 Convergence: 0.0972 k= 0.021539 lr = 0.0000142\n",
      "[11/25][7620/9765] Loss_D: 0.0902 Loss_G: 0.0400 Convergence: 0.0947 k= 0.021523 lr = 0.0000142\n",
      "[11/25][7630/9765] Loss_D: 0.0882 Loss_G: 0.0365 Convergence: 0.0899 k= 0.021523 lr = 0.0000142\n",
      "[11/25][7640/9765] Loss_D: 0.1033 Loss_G: 0.0408 Convergence: 0.1050 k= 0.021528 lr = 0.0000142\n",
      "[11/25][7650/9765] Loss_D: 0.0852 Loss_G: 0.0380 Convergence: 0.0896 k= 0.021515 lr = 0.0000142\n",
      "[11/25][7660/9765] Loss_D: 0.0959 Loss_G: 0.0408 Convergence: 0.0988 k= 0.021511 lr = 0.0000142\n",
      "[11/25][7670/9765] Loss_D: 0.0943 Loss_G: 0.0399 Convergence: 0.0969 k= 0.021510 lr = 0.0000142\n",
      "[11/25][7680/9765] Loss_D: 0.0953 Loss_G: 0.0394 Convergence: 0.0970 k= 0.021508 lr = 0.0000142\n",
      "[11/25][7690/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.021515 lr = 0.0000142\n",
      "[11/25][7700/9765] Loss_D: 0.0927 Loss_G: 0.0368 Convergence: 0.0941 k= 0.021525 lr = 0.0000142\n",
      "[11/25][7710/9765] Loss_D: 0.0987 Loss_G: 0.0375 Convergence: 0.1017 k= 0.021538 lr = 0.0000142\n",
      "[11/25][7720/9765] Loss_D: 0.1019 Loss_G: 0.0360 Convergence: 0.1078 k= 0.021555 lr = 0.0000142\n",
      "[11/25][7730/9765] Loss_D: 0.0977 Loss_G: 0.0418 Convergence: 0.1010 k= 0.021537 lr = 0.0000142\n",
      "[11/25][7740/9765] Loss_D: 0.0968 Loss_G: 0.0475 Convergence: 0.1062 k= 0.021463 lr = 0.0000142\n",
      "[11/25][7750/9765] Loss_D: 0.0904 Loss_G: 0.0423 Convergence: 0.0971 k= 0.021412 lr = 0.0000142\n",
      "[11/25][7760/9765] Loss_D: 0.0887 Loss_G: 0.0358 Convergence: 0.0894 k= 0.021417 lr = 0.0000142\n",
      "[11/25][7770/9765] Loss_D: 0.1021 Loss_G: 0.0343 Convergence: 0.1096 k= 0.021467 lr = 0.0000142\n",
      "[11/25][7780/9765] Loss_D: 0.1044 Loss_G: 0.0344 Convergence: 0.1128 k= 0.021521 lr = 0.0000142\n",
      "[11/25][7790/9765] Loss_D: 0.0933 Loss_G: 0.0427 Convergence: 0.0992 k= 0.021511 lr = 0.0000142\n",
      "[11/25][7800/9765] Loss_D: 0.0949 Loss_G: 0.0424 Convergence: 0.0999 k= 0.021478 lr = 0.0000142\n",
      "[11/25][7810/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1009 k= 0.021470 lr = 0.0000142\n",
      "[11/25][7820/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0924 k= 0.021481 lr = 0.0000142\n",
      "[11/25][7830/9765] Loss_D: 0.0951 Loss_G: 0.0406 Convergence: 0.0982 k= 0.021468 lr = 0.0000142\n",
      "[11/25][7840/9765] Loss_D: 0.0997 Loss_G: 0.0392 Convergence: 0.1015 k= 0.021465 lr = 0.0000142\n",
      "[11/25][7850/9765] Loss_D: 0.0979 Loss_G: 0.0395 Convergence: 0.0988 k= 0.021459 lr = 0.0000142\n",
      "[11/25][7860/9765] Loss_D: 0.0963 Loss_G: 0.0365 Convergence: 0.0995 k= 0.021456 lr = 0.0000142\n",
      "[11/25][7870/9765] Loss_D: 0.0998 Loss_G: 0.0394 Convergence: 0.1014 k= 0.021451 lr = 0.0000142\n",
      "[11/25][7880/9765] Loss_D: 0.0873 Loss_G: 0.0409 Convergence: 0.0938 k= 0.021431 lr = 0.0000142\n",
      "[11/25][7890/9765] Loss_D: 0.1046 Loss_G: 0.0376 Convergence: 0.1099 k= 0.021443 lr = 0.0000142\n",
      "[11/25][7900/9765] Loss_D: 0.1016 Loss_G: 0.0419 Convergence: 0.1034 k= 0.021443 lr = 0.0000142\n",
      "[11/25][7910/9765] Loss_D: 0.0902 Loss_G: 0.0388 Convergence: 0.0934 k= 0.021425 lr = 0.0000142\n",
      "[11/25][7920/9765] Loss_D: 0.0990 Loss_G: 0.0378 Convergence: 0.1019 k= 0.021442 lr = 0.0000142\n",
      "[11/25][7930/9765] Loss_D: 0.1108 Loss_G: 0.0370 Convergence: 0.1192 k= 0.021465 lr = 0.0000142\n",
      "[11/25][7940/9765] Loss_D: 0.0902 Loss_G: 0.0431 Convergence: 0.0977 k= 0.021453 lr = 0.0000142\n",
      "[11/25][7950/9765] Loss_D: 0.1012 Loss_G: 0.0404 Convergence: 0.1026 k= 0.021441 lr = 0.0000142\n",
      "[11/25][7960/9765] Loss_D: 0.1004 Loss_G: 0.0410 Convergence: 0.1018 k= 0.021434 lr = 0.0000142\n",
      "[11/25][7970/9765] Loss_D: 0.0963 Loss_G: 0.0402 Convergence: 0.0985 k= 0.021414 lr = 0.0000142\n",
      "[11/25][7980/9765] Loss_D: 0.0921 Loss_G: 0.0374 Convergence: 0.0932 k= 0.021424 lr = 0.0000142\n",
      "[11/25][7990/9765] Loss_D: 0.0883 Loss_G: 0.0359 Convergence: 0.0894 k= 0.021448 lr = 0.0000142\n",
      "[11/25][8000/9765] Loss_D: 0.1071 Loss_G: 0.0399 Convergence: 0.1112 k= 0.021495 lr = 0.0000142\n",
      "[11/25][8010/9765] Loss_D: 0.0924 Loss_G: 0.0402 Convergence: 0.0962 k= 0.021498 lr = 0.0000142\n",
      "[11/25][8020/9765] Loss_D: 0.1039 Loss_G: 0.0427 Convergence: 0.1056 k= 0.021480 lr = 0.0000142\n",
      "[11/25][8030/9765] Loss_D: 0.1128 Loss_G: 0.0419 Convergence: 0.1173 k= 0.021463 lr = 0.0000142\n",
      "[11/25][8040/9765] Loss_D: 0.0944 Loss_G: 0.0355 Convergence: 0.0977 k= 0.021462 lr = 0.0000142\n",
      "[11/25][8050/9765] Loss_D: 0.0964 Loss_G: 0.0395 Convergence: 0.0979 k= 0.021487 lr = 0.0000142\n",
      "[11/25][8060/9765] Loss_D: 0.0924 Loss_G: 0.0366 Convergence: 0.0939 k= 0.021497 lr = 0.0000142\n",
      "[11/25][8070/9765] Loss_D: 0.0980 Loss_G: 0.0384 Convergence: 0.1000 k= 0.021510 lr = 0.0000142\n",
      "[11/25][8080/9765] Loss_D: 0.1001 Loss_G: 0.0386 Convergence: 0.1027 k= 0.021529 lr = 0.0000142\n",
      "[11/25][8090/9765] Loss_D: 0.0992 Loss_G: 0.0399 Convergence: 0.1002 k= 0.021519 lr = 0.0000142\n",
      "[11/25][8100/9765] Loss_D: 0.0953 Loss_G: 0.0388 Convergence: 0.0965 k= 0.021512 lr = 0.0000142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][8110/9765] Loss_D: 0.1008 Loss_G: 0.0391 Convergence: 0.1032 k= 0.021510 lr = 0.0000142\n",
      "[11/25][8120/9765] Loss_D: 0.0963 Loss_G: 0.0412 Convergence: 0.0996 k= 0.021488 lr = 0.0000142\n",
      "[11/25][8130/9765] Loss_D: 0.0895 Loss_G: 0.0376 Convergence: 0.0918 k= 0.021490 lr = 0.0000142\n",
      "[11/25][8140/9765] Loss_D: 0.0902 Loss_G: 0.0383 Convergence: 0.0929 k= 0.021483 lr = 0.0000142\n",
      "[11/25][8150/9765] Loss_D: 0.0989 Loss_G: 0.0393 Convergence: 0.1003 k= 0.021476 lr = 0.0000142\n",
      "[11/25][8160/9765] Loss_D: 0.1017 Loss_G: 0.0387 Convergence: 0.1049 k= 0.021473 lr = 0.0000142\n",
      "[11/25][8170/9765] Loss_D: 0.1007 Loss_G: 0.0367 Convergence: 0.1055 k= 0.021466 lr = 0.0000142\n",
      "[11/25][8180/9765] Loss_D: 0.1120 Loss_G: 0.0379 Convergence: 0.1200 k= 0.021496 lr = 0.0000142\n",
      "[11/25][8190/9765] Loss_D: 0.0966 Loss_G: 0.0398 Convergence: 0.0983 k= 0.021501 lr = 0.0000142\n",
      "[11/25][8200/9765] Loss_D: 0.1065 Loss_G: 0.0414 Convergence: 0.1090 k= 0.021510 lr = 0.0000142\n",
      "[11/25][8210/9765] Loss_D: 0.0882 Loss_G: 0.0372 Convergence: 0.0906 k= 0.021497 lr = 0.0000142\n",
      "[11/25][8220/9765] Loss_D: 0.0986 Loss_G: 0.0373 Convergence: 0.1018 k= 0.021513 lr = 0.0000142\n",
      "[11/25][8230/9765] Loss_D: 0.0978 Loss_G: 0.0359 Convergence: 0.1021 k= 0.021522 lr = 0.0000142\n",
      "[11/25][8240/9765] Loss_D: 0.0947 Loss_G: 0.0372 Convergence: 0.0965 k= 0.021550 lr = 0.0000142\n",
      "[11/25][8250/9765] Loss_D: 0.0942 Loss_G: 0.0411 Convergence: 0.0981 k= 0.021546 lr = 0.0000142\n",
      "[11/25][8260/9765] Loss_D: 0.0978 Loss_G: 0.0389 Convergence: 0.0991 k= 0.021531 lr = 0.0000142\n",
      "[11/25][8270/9765] Loss_D: 0.0967 Loss_G: 0.0377 Convergence: 0.0989 k= 0.021527 lr = 0.0000142\n",
      "[11/25][8280/9765] Loss_D: 0.0943 Loss_G: 0.0416 Convergence: 0.0987 k= 0.021529 lr = 0.0000142\n",
      "[11/25][8290/9765] Loss_D: 0.0927 Loss_G: 0.0400 Convergence: 0.0961 k= 0.021513 lr = 0.0000142\n",
      "[11/25][8300/9765] Loss_D: 0.0935 Loss_G: 0.0408 Convergence: 0.0974 k= 0.021494 lr = 0.0000142\n",
      "[11/25][8310/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0999 k= 0.021476 lr = 0.0000142\n",
      "[11/25][8320/9765] Loss_D: 0.0962 Loss_G: 0.0363 Convergence: 0.0995 k= 0.021464 lr = 0.0000142\n",
      "[11/25][8330/9765] Loss_D: 0.0970 Loss_G: 0.0393 Convergence: 0.0980 k= 0.021472 lr = 0.0000142\n",
      "[11/25][8340/9765] Loss_D: 0.0904 Loss_G: 0.0406 Convergence: 0.0953 k= 0.021470 lr = 0.0000142\n",
      "[11/25][8350/9765] Loss_D: 0.1043 Loss_G: 0.0440 Convergence: 0.1071 k= 0.021454 lr = 0.0000142\n",
      "[11/25][8360/9765] Loss_D: 0.0909 Loss_G: 0.0385 Convergence: 0.0935 k= 0.021436 lr = 0.0000142\n",
      "[11/25][8370/9765] Loss_D: 0.1104 Loss_G: 0.0401 Convergence: 0.1156 k= 0.021457 lr = 0.0000142\n",
      "[11/25][8380/9765] Loss_D: 0.1044 Loss_G: 0.0409 Convergence: 0.1065 k= 0.021458 lr = 0.0000142\n",
      "[11/25][8390/9765] Loss_D: 0.1040 Loss_G: 0.0400 Convergence: 0.1068 k= 0.021450 lr = 0.0000142\n",
      "[11/25][8400/9765] Loss_D: 0.0921 Loss_G: 0.0379 Convergence: 0.0937 k= 0.021439 lr = 0.0000142\n",
      "[11/25][8410/9765] Loss_D: 0.0994 Loss_G: 0.0368 Convergence: 0.1034 k= 0.021453 lr = 0.0000142\n",
      "[11/25][8420/9765] Loss_D: 0.1029 Loss_G: 0.0390 Convergence: 0.1063 k= 0.021461 lr = 0.0000142\n",
      "[11/25][8430/9765] Loss_D: 0.0942 Loss_G: 0.0410 Convergence: 0.0980 k= 0.021462 lr = 0.0000142\n",
      "[11/25][8440/9765] Loss_D: 0.0978 Loss_G: 0.0406 Convergence: 0.0998 k= 0.021458 lr = 0.0000142\n",
      "[11/25][8450/9765] Loss_D: 0.0969 Loss_G: 0.0387 Convergence: 0.0982 k= 0.021451 lr = 0.0000142\n",
      "[11/25][8460/9765] Loss_D: 0.1006 Loss_G: 0.0400 Convergence: 0.1021 k= 0.021439 lr = 0.0000142\n",
      "[11/25][8470/9765] Loss_D: 0.0907 Loss_G: 0.0388 Convergence: 0.0938 k= 0.021422 lr = 0.0000142\n",
      "[11/25][8480/9765] Loss_D: 0.1000 Loss_G: 0.0424 Convergence: 0.1029 k= 0.021426 lr = 0.0000142\n",
      "[11/25][8490/9765] Loss_D: 0.0938 Loss_G: 0.0376 Convergence: 0.0949 k= 0.021431 lr = 0.0000142\n",
      "[11/25][8500/9765] Loss_D: 0.0836 Loss_G: 0.0353 Convergence: 0.0858 k= 0.021458 lr = 0.0000142\n",
      "[11/25][8510/9765] Loss_D: 0.0976 Loss_G: 0.0359 Convergence: 0.1018 k= 0.021492 lr = 0.0000142\n",
      "[11/25][8520/9765] Loss_D: 0.1007 Loss_G: 0.0397 Convergence: 0.1024 k= 0.021504 lr = 0.0000142\n",
      "[11/25][8530/9765] Loss_D: 0.1009 Loss_G: 0.0407 Convergence: 0.1018 k= 0.021501 lr = 0.0000142\n",
      "[11/25][8540/9765] Loss_D: 0.1029 Loss_G: 0.0391 Convergence: 0.1062 k= 0.021509 lr = 0.0000142\n",
      "[11/25][8550/9765] Loss_D: 0.0994 Loss_G: 0.0367 Convergence: 0.1035 k= 0.021521 lr = 0.0000142\n",
      "[11/25][8560/9765] Loss_D: 0.0970 Loss_G: 0.0379 Convergence: 0.0989 k= 0.021543 lr = 0.0000142\n",
      "[11/25][8570/9765] Loss_D: 0.0989 Loss_G: 0.0385 Convergence: 0.1012 k= 0.021550 lr = 0.0000142\n",
      "[11/25][8580/9765] Loss_D: 0.1000 Loss_G: 0.0403 Convergence: 0.1009 k= 0.021556 lr = 0.0000142\n",
      "[11/25][8590/9765] Loss_D: 0.1046 Loss_G: 0.0419 Convergence: 0.1059 k= 0.021538 lr = 0.0000142\n",
      "[11/25][8600/9765] Loss_D: 0.0972 Loss_G: 0.0491 Convergence: 0.1081 k= 0.021482 lr = 0.0000142\n",
      "[11/25][8610/9765] Loss_D: 0.0948 Loss_G: 0.0416 Convergence: 0.0990 k= 0.021442 lr = 0.0000142\n",
      "[11/25][8620/9765] Loss_D: 0.1079 Loss_G: 0.0431 Convergence: 0.1091 k= 0.021431 lr = 0.0000142\n",
      "[11/25][8630/9765] Loss_D: 0.0972 Loss_G: 0.0374 Convergence: 0.0997 k= 0.021444 lr = 0.0000142\n",
      "[11/25][8640/9765] Loss_D: 0.1020 Loss_G: 0.0367 Convergence: 0.1072 k= 0.021464 lr = 0.0000142\n",
      "[11/25][8650/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0981 k= 0.021474 lr = 0.0000142\n",
      "[11/25][8660/9765] Loss_D: 0.0955 Loss_G: 0.0401 Convergence: 0.0979 k= 0.021449 lr = 0.0000142\n",
      "[11/25][8670/9765] Loss_D: 0.0890 Loss_G: 0.0386 Convergence: 0.0925 k= 0.021428 lr = 0.0000142\n",
      "[11/25][8680/9765] Loss_D: 0.0968 Loss_G: 0.0369 Convergence: 0.0998 k= 0.021434 lr = 0.0000142\n",
      "[11/25][8690/9765] Loss_D: 0.0912 Loss_G: 0.0385 Convergence: 0.0937 k= 0.021430 lr = 0.0000142\n",
      "[11/25][8700/9765] Loss_D: 0.0890 Loss_G: 0.0365 Convergence: 0.0904 k= 0.021429 lr = 0.0000142\n",
      "[11/25][8710/9765] Loss_D: 0.1026 Loss_G: 0.0386 Convergence: 0.1061 k= 0.021444 lr = 0.0000142\n",
      "[11/25][8720/9765] Loss_D: 0.0991 Loss_G: 0.0419 Convergence: 0.1019 k= 0.021443 lr = 0.0000142\n",
      "[11/25][8730/9765] Loss_D: 0.0971 Loss_G: 0.0389 Convergence: 0.0982 k= 0.021445 lr = 0.0000142\n",
      "[11/25][8740/9765] Loss_D: 0.1022 Loss_G: 0.0431 Convergence: 0.1050 k= 0.021430 lr = 0.0000142\n",
      "[11/25][8750/9765] Loss_D: 0.1024 Loss_G: 0.0389 Convergence: 0.1056 k= 0.021411 lr = 0.0000142\n",
      "[11/25][8760/9765] Loss_D: 0.0971 Loss_G: 0.0368 Convergence: 0.1003 k= 0.021410 lr = 0.0000142\n",
      "[11/25][8770/9765] Loss_D: 0.0961 Loss_G: 0.0366 Convergence: 0.0989 k= 0.021435 lr = 0.0000142\n",
      "[11/25][8780/9765] Loss_D: 0.0926 Loss_G: 0.0384 Convergence: 0.0944 k= 0.021471 lr = 0.0000142\n",
      "[11/25][8790/9765] Loss_D: 0.0953 Loss_G: 0.0457 Convergence: 0.1034 k= 0.021439 lr = 0.0000142\n",
      "[11/25][8800/9765] Loss_D: 0.0936 Loss_G: 0.0408 Convergence: 0.0975 k= 0.021411 lr = 0.0000142\n",
      "[11/25][8810/9765] Loss_D: 0.1026 Loss_G: 0.0394 Convergence: 0.1055 k= 0.021411 lr = 0.0000142\n",
      "[11/25][8820/9765] Loss_D: 0.1029 Loss_G: 0.0381 Convergence: 0.1072 k= 0.021430 lr = 0.0000142\n",
      "[11/25][8830/9765] Loss_D: 0.1026 Loss_G: 0.0436 Convergence: 0.1057 k= 0.021425 lr = 0.0000142\n",
      "[11/25][8840/9765] Loss_D: 0.0943 Loss_G: 0.0388 Convergence: 0.0959 k= 0.021418 lr = 0.0000142\n",
      "[11/25][8850/9765] Loss_D: 0.0974 Loss_G: 0.0437 Convergence: 0.1027 k= 0.021394 lr = 0.0000142\n",
      "[11/25][8860/9765] Loss_D: 0.1001 Loss_G: 0.0409 Convergence: 0.1015 k= 0.021354 lr = 0.0000142\n",
      "[11/25][8870/9765] Loss_D: 0.0980 Loss_G: 0.0376 Convergence: 0.1008 k= 0.021362 lr = 0.0000142\n",
      "[11/25][8880/9765] Loss_D: 0.0930 Loss_G: 0.0402 Convergence: 0.0966 k= 0.021369 lr = 0.0000142\n",
      "[11/25][8890/9765] Loss_D: 0.0924 Loss_G: 0.0371 Convergence: 0.0934 k= 0.021367 lr = 0.0000142\n",
      "[11/25][8900/9765] Loss_D: 0.0959 Loss_G: 0.0426 Convergence: 0.1007 k= 0.021373 lr = 0.0000142\n",
      "[11/25][8910/9765] Loss_D: 0.0922 Loss_G: 0.0406 Convergence: 0.0965 k= 0.021355 lr = 0.0000142\n",
      "[11/25][8920/9765] Loss_D: 0.0999 Loss_G: 0.0384 Convergence: 0.1026 k= 0.021360 lr = 0.0000142\n",
      "[11/25][8930/9765] Loss_D: 0.0897 Loss_G: 0.0372 Convergence: 0.0915 k= 0.021360 lr = 0.0000142\n",
      "[11/25][8940/9765] Loss_D: 0.1002 Loss_G: 0.0377 Convergence: 0.1038 k= 0.021372 lr = 0.0000142\n",
      "[11/25][8950/9765] Loss_D: 0.0904 Loss_G: 0.0404 Convergence: 0.0951 k= 0.021375 lr = 0.0000142\n",
      "[11/25][8960/9765] Loss_D: 0.0963 Loss_G: 0.0365 Convergence: 0.0994 k= 0.021361 lr = 0.0000142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/25][8970/9765] Loss_D: 0.0921 Loss_G: 0.0399 Convergence: 0.0957 k= 0.021378 lr = 0.0000142\n",
      "[11/25][8980/9765] Loss_D: 0.1026 Loss_G: 0.0368 Convergence: 0.1079 k= 0.021388 lr = 0.0000142\n",
      "[11/25][8990/9765] Loss_D: 0.0863 Loss_G: 0.0383 Convergence: 0.0906 k= 0.021393 lr = 0.0000142\n",
      "[11/25][9000/9765] Loss_D: 0.0965 Loss_G: 0.0405 Convergence: 0.0989 k= 0.021384 lr = 0.0000142\n",
      "[11/25][9010/9765] Loss_D: 0.0889 Loss_G: 0.0390 Convergence: 0.0929 k= 0.021362 lr = 0.0000142\n",
      "[11/25][9020/9765] Loss_D: 0.0876 Loss_G: 0.0411 Convergence: 0.0942 k= 0.021377 lr = 0.0000142\n",
      "[11/25][9030/9765] Loss_D: 0.1000 Loss_G: 0.0398 Convergence: 0.1014 k= 0.021373 lr = 0.0000142\n",
      "[11/25][9040/9765] Loss_D: 0.0911 Loss_G: 0.0383 Convergence: 0.0935 k= 0.021386 lr = 0.0000142\n",
      "[11/25][9050/9765] Loss_D: 0.1028 Loss_G: 0.0384 Convergence: 0.1066 k= 0.021399 lr = 0.0000142\n",
      "[11/25][9060/9765] Loss_D: 0.0974 Loss_G: 0.0363 Convergence: 0.1011 k= 0.021409 lr = 0.0000142\n",
      "[11/25][9070/9765] Loss_D: 0.0994 Loss_G: 0.0369 Convergence: 0.1034 k= 0.021437 lr = 0.0000142\n",
      "[11/25][9080/9765] Loss_D: 0.1022 Loss_G: 0.0368 Convergence: 0.1073 k= 0.021455 lr = 0.0000142\n",
      "[11/25][9090/9765] Loss_D: 0.0976 Loss_G: 0.0394 Convergence: 0.0985 k= 0.021467 lr = 0.0000142\n",
      "[11/25][9100/9765] Loss_D: 0.1010 Loss_G: 0.0424 Convergence: 0.1036 k= 0.021450 lr = 0.0000142\n",
      "[11/25][9110/9765] Loss_D: 0.0934 Loss_G: 0.0420 Convergence: 0.0985 k= 0.021443 lr = 0.0000142\n",
      "[11/25][9120/9765] Loss_D: 0.1035 Loss_G: 0.0409 Convergence: 0.1052 k= 0.021436 lr = 0.0000142\n",
      "[11/25][9130/9765] Loss_D: 0.0918 Loss_G: 0.0382 Convergence: 0.0937 k= 0.021429 lr = 0.0000142\n",
      "[11/25][9140/9765] Loss_D: 0.1018 Loss_G: 0.0369 Convergence: 0.1068 k= 0.021429 lr = 0.0000142\n",
      "[11/25][9150/9765] Loss_D: 0.0911 Loss_G: 0.0409 Convergence: 0.0961 k= 0.021425 lr = 0.0000142\n",
      "[11/25][9160/9765] Loss_D: 0.0921 Loss_G: 0.0426 Convergence: 0.0984 k= 0.021421 lr = 0.0000142\n",
      "[11/25][9170/9765] Loss_D: 0.1015 Loss_G: 0.0429 Convergence: 0.1044 k= 0.021404 lr = 0.0000142\n",
      "[11/25][9180/9765] Loss_D: 0.0925 Loss_G: 0.0387 Convergence: 0.0946 k= 0.021384 lr = 0.0000142\n",
      "[11/25][9190/9765] Loss_D: 0.0990 Loss_G: 0.0400 Convergence: 0.0999 k= 0.021381 lr = 0.0000142\n",
      "[11/25][9200/9765] Loss_D: 0.0872 Loss_G: 0.0391 Convergence: 0.0920 k= 0.021384 lr = 0.0000142\n",
      "[11/25][9210/9765] Loss_D: 0.0923 Loss_G: 0.0383 Convergence: 0.0942 k= 0.021379 lr = 0.0000142\n",
      "[11/25][9220/9765] Loss_D: 0.1034 Loss_G: 0.0374 Convergence: 0.1085 k= 0.021396 lr = 0.0000142\n",
      "[11/25][9230/9765] Loss_D: 0.0943 Loss_G: 0.0380 Convergence: 0.0952 k= 0.021390 lr = 0.0000142\n",
      "[11/25][9240/9765] Loss_D: 0.0981 Loss_G: 0.0440 Convergence: 0.1034 k= 0.021379 lr = 0.0000142\n",
      "[11/25][9250/9765] Loss_D: 0.0975 Loss_G: 0.0428 Convergence: 0.1019 k= 0.021357 lr = 0.0000142\n",
      "[11/25][9260/9765] Loss_D: 0.1028 Loss_G: 0.0408 Convergence: 0.1043 k= 0.021368 lr = 0.0000142\n",
      "[11/25][9270/9765] Loss_D: 0.0907 Loss_G: 0.0393 Convergence: 0.0943 k= 0.021387 lr = 0.0000142\n",
      "[11/25][9280/9765] Loss_D: 0.0987 Loss_G: 0.0409 Convergence: 0.1007 k= 0.021378 lr = 0.0000142\n",
      "[11/25][9290/9765] Loss_D: 0.0906 Loss_G: 0.0407 Convergence: 0.0956 k= 0.021373 lr = 0.0000142\n",
      "[11/25][9300/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1002 k= 0.021369 lr = 0.0000142\n",
      "[11/25][9310/9765] Loss_D: 0.0974 Loss_G: 0.0414 Convergence: 0.1003 k= 0.021359 lr = 0.0000142\n",
      "[11/25][9320/9765] Loss_D: 0.1052 Loss_G: 0.0386 Convergence: 0.1098 k= 0.021376 lr = 0.0000142\n",
      "[11/25][9330/9765] Loss_D: 0.0936 Loss_G: 0.0393 Convergence: 0.0959 k= 0.021387 lr = 0.0000142\n",
      "[11/25][9340/9765] Loss_D: 0.1030 Loss_G: 0.0414 Convergence: 0.1040 k= 0.021395 lr = 0.0000142\n",
      "[11/25][9350/9765] Loss_D: 0.0991 Loss_G: 0.0415 Convergence: 0.1015 k= 0.021382 lr = 0.0000142\n",
      "[11/25][9360/9765] Loss_D: 0.0917 Loss_G: 0.0395 Convergence: 0.0951 k= 0.021356 lr = 0.0000142\n",
      "[11/25][9370/9765] Loss_D: 0.0908 Loss_G: 0.0425 Convergence: 0.0975 k= 0.021349 lr = 0.0000142\n",
      "[11/25][9380/9765] Loss_D: 0.0991 Loss_G: 0.0402 Convergence: 0.1002 k= 0.021340 lr = 0.0000142\n",
      "[11/25][9390/9765] Loss_D: 0.0996 Loss_G: 0.0382 Convergence: 0.1025 k= 0.021347 lr = 0.0000142\n",
      "[11/25][9400/9765] Loss_D: 0.1010 Loss_G: 0.0449 Convergence: 0.1060 k= 0.021343 lr = 0.0000142\n",
      "[11/25][9410/9765] Loss_D: 0.0896 Loss_G: 0.0377 Convergence: 0.0920 k= 0.021335 lr = 0.0000142\n",
      "[11/25][9420/9765] Loss_D: 0.1076 Loss_G: 0.0424 Convergence: 0.1093 k= 0.021337 lr = 0.0000142\n",
      "[11/25][9430/9765] Loss_D: 0.0917 Loss_G: 0.0385 Convergence: 0.0940 k= 0.021333 lr = 0.0000142\n",
      "[11/25][9440/9765] Loss_D: 0.0950 Loss_G: 0.0372 Convergence: 0.0968 k= 0.021343 lr = 0.0000142\n",
      "[11/25][9450/9765] Loss_D: 0.1060 Loss_G: 0.0414 Convergence: 0.1082 k= 0.021340 lr = 0.0000142\n",
      "[11/25][9460/9765] Loss_D: 0.0949 Loss_G: 0.0390 Convergence: 0.0964 k= 0.021331 lr = 0.0000142\n",
      "[11/25][9470/9765] Loss_D: 0.1014 Loss_G: 0.0367 Convergence: 0.1065 k= 0.021337 lr = 0.0000142\n",
      "[11/25][9480/9765] Loss_D: 0.1042 Loss_G: 0.0367 Convergence: 0.1102 k= 0.021370 lr = 0.0000142\n",
      "[11/25][9490/9765] Loss_D: 0.1034 Loss_G: 0.0384 Convergence: 0.1075 k= 0.021381 lr = 0.0000142\n",
      "[11/25][9500/9765] Loss_D: 0.0857 Loss_G: 0.0357 Convergence: 0.0876 k= 0.021380 lr = 0.0000142\n",
      "[11/25][9510/9765] Loss_D: 0.1032 Loss_G: 0.0393 Convergence: 0.1063 k= 0.021413 lr = 0.0000142\n",
      "[11/25][9520/9765] Loss_D: 0.1000 Loss_G: 0.0403 Convergence: 0.1009 k= 0.021417 lr = 0.0000142\n",
      "[11/25][9530/9765] Loss_D: 0.0965 Loss_G: 0.0376 Convergence: 0.0985 k= 0.021411 lr = 0.0000142\n",
      "[11/25][9540/9765] Loss_D: 0.0997 Loss_G: 0.0374 Convergence: 0.1033 k= 0.021437 lr = 0.0000142\n",
      "[11/25][9550/9765] Loss_D: 0.0969 Loss_G: 0.0389 Convergence: 0.0979 k= 0.021429 lr = 0.0000142\n",
      "[11/25][9560/9765] Loss_D: 0.1049 Loss_G: 0.0449 Convergence: 0.1084 k= 0.021407 lr = 0.0000142\n",
      "[11/25][9570/9765] Loss_D: 0.0990 Loss_G: 0.0410 Convergence: 0.1009 k= 0.021381 lr = 0.0000142\n",
      "[11/25][9580/9765] Loss_D: 0.0959 Loss_G: 0.0398 Convergence: 0.0978 k= 0.021383 lr = 0.0000142\n",
      "[11/25][9590/9765] Loss_D: 0.1060 Loss_G: 0.0380 Convergence: 0.1116 k= 0.021393 lr = 0.0000135\n",
      "[11/25][9600/9765] Loss_D: 0.0858 Loss_G: 0.0369 Convergence: 0.0889 k= 0.021397 lr = 0.0000135\n",
      "[11/25][9610/9765] Loss_D: 0.0926 Loss_G: 0.0370 Convergence: 0.0939 k= 0.021424 lr = 0.0000135\n",
      "[11/25][9620/9765] Loss_D: 0.1121 Loss_G: 0.0393 Convergence: 0.1188 k= 0.021434 lr = 0.0000135\n",
      "[11/25][9630/9765] Loss_D: 0.0907 Loss_G: 0.0414 Convergence: 0.0964 k= 0.021420 lr = 0.0000135\n",
      "[11/25][9640/9765] Loss_D: 0.0868 Loss_G: 0.0413 Convergence: 0.0939 k= 0.021382 lr = 0.0000135\n",
      "[11/25][9650/9765] Loss_D: 0.0949 Loss_G: 0.0417 Convergence: 0.0992 k= 0.021370 lr = 0.0000135\n",
      "[11/25][9660/9765] Loss_D: 0.1034 Loss_G: 0.0359 Convergence: 0.1100 k= 0.021356 lr = 0.0000135\n",
      "[11/25][9670/9765] Loss_D: 0.1001 Loss_G: 0.0382 Convergence: 0.1030 k= 0.021386 lr = 0.0000135\n",
      "[11/25][9680/9765] Loss_D: 0.1021 Loss_G: 0.0379 Convergence: 0.1063 k= 0.021396 lr = 0.0000135\n",
      "[11/25][9690/9765] Loss_D: 0.1023 Loss_G: 0.0360 Convergence: 0.1082 k= 0.021420 lr = 0.0000135\n",
      "[11/25][9700/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1013 k= 0.021430 lr = 0.0000135\n",
      "[11/25][9710/9765] Loss_D: 0.0912 Loss_G: 0.0401 Convergence: 0.0953 k= 0.021428 lr = 0.0000135\n",
      "[11/25][9720/9765] Loss_D: 0.1034 Loss_G: 0.0391 Convergence: 0.1068 k= 0.021414 lr = 0.0000135\n",
      "[11/25][9730/9765] Loss_D: 0.1086 Loss_G: 0.0402 Convergence: 0.1129 k= 0.021410 lr = 0.0000135\n",
      "[11/25][9740/9765] Loss_D: 0.1020 Loss_G: 0.0377 Convergence: 0.1063 k= 0.021416 lr = 0.0000135\n",
      "[11/25][9750/9765] Loss_D: 0.0923 Loss_G: 0.0401 Convergence: 0.0959 k= 0.021423 lr = 0.0000135\n",
      "[11/25][9760/9765] Loss_D: 0.1041 Loss_G: 0.0391 Convergence: 0.1078 k= 0.021423 lr = 0.0000135\n",
      "[12/25][0/9765] Loss_D: 0.0995 Loss_G: 0.0384 Convergence: 0.1020 k= 0.021419 lr = 0.0000135\n",
      "[12/25][10/9765] Loss_D: 0.1028 Loss_G: 0.0372 Convergence: 0.1079 k= 0.021429 lr = 0.0000135\n",
      "[12/25][20/9765] Loss_D: 0.0919 Loss_G: 0.0395 Convergence: 0.0951 k= 0.021429 lr = 0.0000135\n",
      "[12/25][30/9765] Loss_D: 0.0929 Loss_G: 0.0359 Convergence: 0.0952 k= 0.021434 lr = 0.0000135\n",
      "[12/25][40/9765] Loss_D: 0.0859 Loss_G: 0.0373 Convergence: 0.0893 k= 0.021434 lr = 0.0000135\n",
      "[12/25][50/9765] Loss_D: 0.0983 Loss_G: 0.0385 Convergence: 0.1002 k= 0.021438 lr = 0.0000135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][60/9765] Loss_D: 0.0967 Loss_G: 0.0383 Convergence: 0.0982 k= 0.021441 lr = 0.0000135\n",
      "[12/25][70/9765] Loss_D: 0.1050 Loss_G: 0.0393 Convergence: 0.1089 k= 0.021428 lr = 0.0000135\n",
      "[12/25][80/9765] Loss_D: 0.1045 Loss_G: 0.0386 Convergence: 0.1087 k= 0.021442 lr = 0.0000135\n",
      "[12/25][90/9765] Loss_D: 0.0929 Loss_G: 0.0400 Convergence: 0.0963 k= 0.021427 lr = 0.0000135\n",
      "[12/25][100/9765] Loss_D: 0.0942 Loss_G: 0.0405 Convergence: 0.0975 k= 0.021416 lr = 0.0000135\n",
      "[12/25][110/9765] Loss_D: 0.0976 Loss_G: 0.0377 Convergence: 0.1000 k= 0.021423 lr = 0.0000135\n",
      "[12/25][120/9765] Loss_D: 0.0989 Loss_G: 0.0388 Convergence: 0.1008 k= 0.021431 lr = 0.0000135\n",
      "[12/25][130/9765] Loss_D: 0.0924 Loss_G: 0.0416 Convergence: 0.0976 k= 0.021424 lr = 0.0000135\n",
      "[12/25][140/9765] Loss_D: 0.1007 Loss_G: 0.0376 Convergence: 0.1046 k= 0.021429 lr = 0.0000135\n",
      "[12/25][150/9765] Loss_D: 0.0947 Loss_G: 0.0391 Convergence: 0.0964 k= 0.021438 lr = 0.0000135\n",
      "[12/25][160/9765] Loss_D: 0.1048 Loss_G: 0.0389 Convergence: 0.1090 k= 0.021424 lr = 0.0000135\n",
      "[12/25][170/9765] Loss_D: 0.0941 Loss_G: 0.0355 Convergence: 0.0973 k= 0.021426 lr = 0.0000135\n",
      "[12/25][180/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0978 k= 0.021435 lr = 0.0000135\n",
      "[12/25][190/9765] Loss_D: 0.0963 Loss_G: 0.0384 Convergence: 0.0976 k= 0.021452 lr = 0.0000135\n",
      "[12/25][200/9765] Loss_D: 0.1059 Loss_G: 0.0413 Convergence: 0.1082 k= 0.021445 lr = 0.0000135\n",
      "[12/25][210/9765] Loss_D: 0.0964 Loss_G: 0.0410 Convergence: 0.0994 k= 0.021430 lr = 0.0000135\n",
      "[12/25][220/9765] Loss_D: 0.0949 Loss_G: 0.0421 Convergence: 0.0996 k= 0.021404 lr = 0.0000135\n",
      "[12/25][230/9765] Loss_D: 0.1059 Loss_G: 0.0387 Convergence: 0.1107 k= 0.021400 lr = 0.0000135\n",
      "[12/25][240/9765] Loss_D: 0.1000 Loss_G: 0.0371 Convergence: 0.1040 k= 0.021410 lr = 0.0000135\n",
      "[12/25][250/9765] Loss_D: 0.0969 Loss_G: 0.0373 Convergence: 0.0995 k= 0.021414 lr = 0.0000135\n",
      "[12/25][260/9765] Loss_D: 0.0878 Loss_G: 0.0388 Convergence: 0.0920 k= 0.021409 lr = 0.0000135\n",
      "[12/25][270/9765] Loss_D: 0.0928 Loss_G: 0.0355 Convergence: 0.0954 k= 0.021424 lr = 0.0000135\n",
      "[12/25][280/9765] Loss_D: 0.0914 Loss_G: 0.0358 Convergence: 0.0932 k= 0.021444 lr = 0.0000135\n",
      "[12/25][290/9765] Loss_D: 0.0976 Loss_G: 0.0380 Convergence: 0.0999 k= 0.021465 lr = 0.0000135\n",
      "[12/25][300/9765] Loss_D: 0.0870 Loss_G: 0.0391 Convergence: 0.0918 k= 0.021452 lr = 0.0000135\n",
      "[12/25][310/9765] Loss_D: 0.0984 Loss_G: 0.0417 Convergence: 0.1013 k= 0.021444 lr = 0.0000135\n",
      "[12/25][320/9765] Loss_D: 0.1025 Loss_G: 0.0416 Convergence: 0.1036 k= 0.021416 lr = 0.0000135\n",
      "[12/25][330/9765] Loss_D: 0.0968 Loss_G: 0.0359 Convergence: 0.1007 k= 0.021413 lr = 0.0000135\n",
      "[12/25][340/9765] Loss_D: 0.0950 Loss_G: 0.0338 Convergence: 0.1002 k= 0.021455 lr = 0.0000135\n",
      "[12/25][350/9765] Loss_D: 0.1046 Loss_G: 0.0372 Convergence: 0.1104 k= 0.021485 lr = 0.0000135\n",
      "[12/25][360/9765] Loss_D: 0.1083 Loss_G: 0.0392 Convergence: 0.1134 k= 0.021509 lr = 0.0000135\n",
      "[12/25][370/9765] Loss_D: 0.0979 Loss_G: 0.0440 Convergence: 0.1033 k= 0.021479 lr = 0.0000135\n",
      "[12/25][380/9765] Loss_D: 0.0979 Loss_G: 0.0482 Convergence: 0.1075 k= 0.021405 lr = 0.0000135\n",
      "[12/25][390/9765] Loss_D: 0.1085 Loss_G: 0.0428 Convergence: 0.1103 k= 0.021356 lr = 0.0000135\n",
      "[12/25][400/9765] Loss_D: 0.0998 Loss_G: 0.0393 Convergence: 0.1016 k= 0.021359 lr = 0.0000135\n",
      "[12/25][410/9765] Loss_D: 0.0972 Loss_G: 0.0379 Convergence: 0.0992 k= 0.021379 lr = 0.0000135\n",
      "[12/25][420/9765] Loss_D: 0.1001 Loss_G: 0.0367 Convergence: 0.1046 k= 0.021398 lr = 0.0000135\n",
      "[12/25][430/9765] Loss_D: 0.1005 Loss_G: 0.0376 Convergence: 0.1042 k= 0.021418 lr = 0.0000135\n",
      "[12/25][440/9765] Loss_D: 0.0956 Loss_G: 0.0402 Convergence: 0.0981 k= 0.021418 lr = 0.0000135\n",
      "[12/25][450/9765] Loss_D: 0.0931 Loss_G: 0.0424 Convergence: 0.0988 k= 0.021390 lr = 0.0000135\n",
      "[12/25][460/9765] Loss_D: 0.0918 Loss_G: 0.0402 Convergence: 0.0958 k= 0.021388 lr = 0.0000135\n",
      "[12/25][470/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0973 k= 0.021372 lr = 0.0000135\n",
      "[12/25][480/9765] Loss_D: 0.0979 Loss_G: 0.0361 Convergence: 0.1021 k= 0.021385 lr = 0.0000135\n",
      "[12/25][490/9765] Loss_D: 0.0883 Loss_G: 0.0380 Convergence: 0.0914 k= 0.021399 lr = 0.0000135\n",
      "[12/25][500/9765] Loss_D: 0.0901 Loss_G: 0.0380 Convergence: 0.0925 k= 0.021392 lr = 0.0000135\n",
      "[12/25][510/9765] Loss_D: 0.1023 Loss_G: 0.0411 Convergence: 0.1033 k= 0.021405 lr = 0.0000135\n",
      "[12/25][520/9765] Loss_D: 0.0924 Loss_G: 0.0391 Convergence: 0.0950 k= 0.021396 lr = 0.0000135\n",
      "[12/25][530/9765] Loss_D: 0.0986 Loss_G: 0.0407 Convergence: 0.1004 k= 0.021387 lr = 0.0000135\n",
      "[12/25][540/9765] Loss_D: 0.0970 Loss_G: 0.0375 Convergence: 0.0994 k= 0.021356 lr = 0.0000135\n",
      "[12/25][550/9765] Loss_D: 0.1000 Loss_G: 0.0374 Convergence: 0.1038 k= 0.021358 lr = 0.0000135\n",
      "[12/25][560/9765] Loss_D: 0.0969 Loss_G: 0.0415 Convergence: 0.1002 k= 0.021362 lr = 0.0000135\n",
      "[12/25][570/9765] Loss_D: 0.1042 Loss_G: 0.0401 Convergence: 0.1069 k= 0.021345 lr = 0.0000135\n",
      "[12/25][580/9765] Loss_D: 0.0927 Loss_G: 0.0403 Convergence: 0.0964 k= 0.021339 lr = 0.0000135\n",
      "[12/25][590/9765] Loss_D: 0.0917 Loss_G: 0.0391 Convergence: 0.0946 k= 0.021331 lr = 0.0000135\n",
      "[12/25][600/9765] Loss_D: 0.0868 Loss_G: 0.0397 Convergence: 0.0923 k= 0.021345 lr = 0.0000135\n",
      "[12/25][610/9765] Loss_D: 0.0852 Loss_G: 0.0385 Convergence: 0.0902 k= 0.021357 lr = 0.0000135\n",
      "[12/25][620/9765] Loss_D: 0.0891 Loss_G: 0.0353 Convergence: 0.0905 k= 0.021367 lr = 0.0000135\n",
      "[12/25][630/9765] Loss_D: 0.0991 Loss_G: 0.0397 Convergence: 0.1002 k= 0.021396 lr = 0.0000135\n",
      "[12/25][640/9765] Loss_D: 0.1014 Loss_G: 0.0420 Convergence: 0.1034 k= 0.021382 lr = 0.0000135\n",
      "[12/25][650/9765] Loss_D: 0.0947 Loss_G: 0.0405 Convergence: 0.0978 k= 0.021364 lr = 0.0000135\n",
      "[12/25][660/9765] Loss_D: 0.0855 Loss_G: 0.0380 Convergence: 0.0898 k= 0.021364 lr = 0.0000135\n",
      "[12/25][670/9765] Loss_D: 0.1001 Loss_G: 0.0408 Convergence: 0.1014 k= 0.021377 lr = 0.0000135\n",
      "[12/25][680/9765] Loss_D: 0.0958 Loss_G: 0.0378 Convergence: 0.0974 k= 0.021371 lr = 0.0000135\n",
      "[12/25][690/9765] Loss_D: 0.0934 Loss_G: 0.0402 Convergence: 0.0968 k= 0.021373 lr = 0.0000135\n",
      "[12/25][700/9765] Loss_D: 0.0933 Loss_G: 0.0399 Convergence: 0.0964 k= 0.021344 lr = 0.0000135\n",
      "[12/25][710/9765] Loss_D: 0.0885 Loss_G: 0.0379 Convergence: 0.0915 k= 0.021334 lr = 0.0000135\n",
      "[12/25][720/9765] Loss_D: 0.1012 Loss_G: 0.0378 Convergence: 0.1051 k= 0.021344 lr = 0.0000135\n",
      "[12/25][730/9765] Loss_D: 0.0853 Loss_G: 0.0392 Convergence: 0.0909 k= 0.021336 lr = 0.0000135\n",
      "[12/25][740/9765] Loss_D: 0.0959 Loss_G: 0.0388 Convergence: 0.0968 k= 0.021330 lr = 0.0000135\n",
      "[12/25][750/9765] Loss_D: 0.0982 Loss_G: 0.0391 Convergence: 0.0995 k= 0.021333 lr = 0.0000135\n",
      "[12/25][760/9765] Loss_D: 0.1104 Loss_G: 0.0379 Convergence: 0.1178 k= 0.021334 lr = 0.0000135\n",
      "[12/25][770/9765] Loss_D: 0.0952 Loss_G: 0.0380 Convergence: 0.0963 k= 0.021346 lr = 0.0000135\n",
      "[12/25][780/9765] Loss_D: 0.0933 Loss_G: 0.0387 Convergence: 0.0951 k= 0.021334 lr = 0.0000135\n",
      "[12/25][790/9765] Loss_D: 0.0956 Loss_G: 0.0378 Convergence: 0.0973 k= 0.021342 lr = 0.0000135\n",
      "[12/25][800/9765] Loss_D: 0.0919 Loss_G: 0.0415 Convergence: 0.0972 k= 0.021320 lr = 0.0000135\n",
      "[12/25][810/9765] Loss_D: 0.1063 Loss_G: 0.0425 Convergence: 0.1076 k= 0.021293 lr = 0.0000135\n",
      "[12/25][820/9765] Loss_D: 0.0895 Loss_G: 0.0394 Convergence: 0.0937 k= 0.021279 lr = 0.0000135\n",
      "[12/25][830/9765] Loss_D: 0.0950 Loss_G: 0.0405 Convergence: 0.0981 k= 0.021267 lr = 0.0000135\n",
      "[12/25][840/9765] Loss_D: 0.0962 Loss_G: 0.0418 Convergence: 0.1001 k= 0.021253 lr = 0.0000135\n",
      "[12/25][850/9765] Loss_D: 0.0879 Loss_G: 0.0397 Convergence: 0.0930 k= 0.021255 lr = 0.0000135\n",
      "[12/25][860/9765] Loss_D: 0.0942 Loss_G: 0.0397 Convergence: 0.0967 k= 0.021250 lr = 0.0000135\n",
      "[12/25][870/9765] Loss_D: 0.0884 Loss_G: 0.0393 Convergence: 0.0929 k= 0.021229 lr = 0.0000135\n",
      "[12/25][880/9765] Loss_D: 0.1084 Loss_G: 0.0376 Convergence: 0.1152 k= 0.021250 lr = 0.0000135\n",
      "[12/25][890/9765] Loss_D: 0.0943 Loss_G: 0.0410 Convergence: 0.0981 k= 0.021255 lr = 0.0000135\n",
      "[12/25][900/9765] Loss_D: 0.0920 Loss_G: 0.0412 Convergence: 0.0969 k= 0.021242 lr = 0.0000135\n",
      "[12/25][910/9765] Loss_D: 0.0960 Loss_G: 0.0396 Convergence: 0.0977 k= 0.021229 lr = 0.0000135\n",
      "[12/25][920/9765] Loss_D: 0.1060 Loss_G: 0.0418 Convergence: 0.1078 k= 0.021226 lr = 0.0000135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][930/9765] Loss_D: 0.0893 Loss_G: 0.0363 Convergence: 0.0904 k= 0.021216 lr = 0.0000135\n",
      "[12/25][940/9765] Loss_D: 0.0941 Loss_G: 0.0398 Convergence: 0.0968 k= 0.021236 lr = 0.0000135\n",
      "[12/25][950/9765] Loss_D: 0.0855 Loss_G: 0.0367 Convergence: 0.0885 k= 0.021231 lr = 0.0000135\n",
      "[12/25][960/9765] Loss_D: 0.0929 Loss_G: 0.0406 Convergence: 0.0968 k= 0.021233 lr = 0.0000135\n",
      "[12/25][970/9765] Loss_D: 0.0927 Loss_G: 0.0384 Convergence: 0.0946 k= 0.021203 lr = 0.0000135\n",
      "[12/25][980/9765] Loss_D: 0.1013 Loss_G: 0.0415 Convergence: 0.1028 k= 0.021203 lr = 0.0000135\n",
      "[12/25][990/9765] Loss_D: 0.0937 Loss_G: 0.0387 Convergence: 0.0954 k= 0.021210 lr = 0.0000135\n",
      "[12/25][1000/9765] Loss_D: 0.0956 Loss_G: 0.0389 Convergence: 0.0968 k= 0.021208 lr = 0.0000135\n",
      "[12/25][1010/9765] Loss_D: 0.0967 Loss_G: 0.0409 Convergence: 0.0995 k= 0.021214 lr = 0.0000135\n",
      "[12/25][1020/9765] Loss_D: 0.1042 Loss_G: 0.0398 Convergence: 0.1073 k= 0.021209 lr = 0.0000135\n",
      "[12/25][1030/9765] Loss_D: 0.0967 Loss_G: 0.0389 Convergence: 0.0976 k= 0.021213 lr = 0.0000135\n",
      "[12/25][1040/9765] Loss_D: 0.1035 Loss_G: 0.0406 Convergence: 0.1055 k= 0.021212 lr = 0.0000135\n",
      "[12/25][1050/9765] Loss_D: 0.0988 Loss_G: 0.0389 Convergence: 0.1005 k= 0.021198 lr = 0.0000135\n",
      "[12/25][1060/9765] Loss_D: 0.0926 Loss_G: 0.0394 Convergence: 0.0954 k= 0.021181 lr = 0.0000135\n",
      "[12/25][1070/9765] Loss_D: 0.0948 Loss_G: 0.0404 Convergence: 0.0978 k= 0.021178 lr = 0.0000135\n",
      "[12/25][1080/9765] Loss_D: 0.0986 Loss_G: 0.0416 Convergence: 0.1012 k= 0.021165 lr = 0.0000135\n",
      "[12/25][1090/9765] Loss_D: 0.0928 Loss_G: 0.0427 Convergence: 0.0989 k= 0.021147 lr = 0.0000135\n",
      "[12/25][1100/9765] Loss_D: 0.1015 Loss_G: 0.0397 Convergence: 0.1036 k= 0.021151 lr = 0.0000135\n",
      "[12/25][1110/9765] Loss_D: 0.0989 Loss_G: 0.0375 Convergence: 0.1020 k= 0.021163 lr = 0.0000135\n",
      "[12/25][1120/9765] Loss_D: 0.1007 Loss_G: 0.0405 Convergence: 0.1016 k= 0.021175 lr = 0.0000135\n",
      "[12/25][1130/9765] Loss_D: 0.0965 Loss_G: 0.0397 Convergence: 0.0980 k= 0.021170 lr = 0.0000135\n",
      "[12/25][1140/9765] Loss_D: 0.0916 Loss_G: 0.0377 Convergence: 0.0932 k= 0.021171 lr = 0.0000135\n",
      "[12/25][1150/9765] Loss_D: 0.1034 Loss_G: 0.0409 Convergence: 0.1051 k= 0.021163 lr = 0.0000135\n",
      "[12/25][1160/9765] Loss_D: 0.1024 Loss_G: 0.0400 Convergence: 0.1045 k= 0.021154 lr = 0.0000135\n",
      "[12/25][1170/9765] Loss_D: 0.1031 Loss_G: 0.0375 Convergence: 0.1081 k= 0.021151 lr = 0.0000135\n",
      "[12/25][1180/9765] Loss_D: 0.0977 Loss_G: 0.0371 Convergence: 0.1006 k= 0.021175 lr = 0.0000135\n",
      "[12/25][1190/9765] Loss_D: 0.0936 Loss_G: 0.0383 Convergence: 0.0949 k= 0.021188 lr = 0.0000135\n",
      "[12/25][1200/9765] Loss_D: 0.0901 Loss_G: 0.0383 Convergence: 0.0928 k= 0.021207 lr = 0.0000135\n",
      "[12/25][1210/9765] Loss_D: 0.0981 Loss_G: 0.0399 Convergence: 0.0993 k= 0.021202 lr = 0.0000135\n",
      "[12/25][1220/9765] Loss_D: 0.0982 Loss_G: 0.0398 Convergence: 0.0993 k= 0.021197 lr = 0.0000135\n",
      "[12/25][1230/9765] Loss_D: 0.0993 Loss_G: 0.0383 Convergence: 0.1019 k= 0.021193 lr = 0.0000135\n",
      "[12/25][1240/9765] Loss_D: 0.0965 Loss_G: 0.0414 Convergence: 0.0999 k= 0.021201 lr = 0.0000135\n",
      "[12/25][1250/9765] Loss_D: 0.0903 Loss_G: 0.0380 Convergence: 0.0927 k= 0.021185 lr = 0.0000135\n",
      "[12/25][1260/9765] Loss_D: 0.0950 Loss_G: 0.0374 Convergence: 0.0967 k= 0.021208 lr = 0.0000135\n",
      "[12/25][1270/9765] Loss_D: 0.0882 Loss_G: 0.0416 Convergence: 0.0950 k= 0.021188 lr = 0.0000135\n",
      "[12/25][1280/9765] Loss_D: 0.1005 Loss_G: 0.0403 Convergence: 0.1016 k= 0.021185 lr = 0.0000135\n",
      "[12/25][1290/9765] Loss_D: 0.0892 Loss_G: 0.0389 Convergence: 0.0929 k= 0.021158 lr = 0.0000135\n",
      "[12/25][1300/9765] Loss_D: 0.0956 Loss_G: 0.0397 Convergence: 0.0975 k= 0.021166 lr = 0.0000135\n",
      "[12/25][1310/9765] Loss_D: 0.0992 Loss_G: 0.0408 Convergence: 0.1008 k= 0.021175 lr = 0.0000135\n",
      "[12/25][1320/9765] Loss_D: 0.0977 Loss_G: 0.0432 Convergence: 0.1023 k= 0.021161 lr = 0.0000135\n",
      "[12/25][1330/9765] Loss_D: 0.0970 Loss_G: 0.0361 Convergence: 0.1008 k= 0.021161 lr = 0.0000135\n",
      "[12/25][1340/9765] Loss_D: 0.0948 Loss_G: 0.0399 Convergence: 0.0973 k= 0.021142 lr = 0.0000135\n",
      "[12/25][1350/9765] Loss_D: 0.0955 Loss_G: 0.0409 Convergence: 0.0987 k= 0.021128 lr = 0.0000135\n",
      "[12/25][1360/9765] Loss_D: 0.0914 Loss_G: 0.0419 Convergence: 0.0974 k= 0.021089 lr = 0.0000135\n",
      "[12/25][1370/9765] Loss_D: 0.0931 Loss_G: 0.0383 Convergence: 0.0947 k= 0.021075 lr = 0.0000135\n",
      "[12/25][1380/9765] Loss_D: 0.1060 Loss_G: 0.0377 Convergence: 0.1119 k= 0.021097 lr = 0.0000135\n",
      "[12/25][1390/9765] Loss_D: 0.1011 Loss_G: 0.0392 Convergence: 0.1034 k= 0.021106 lr = 0.0000135\n",
      "[12/25][1400/9765] Loss_D: 0.1158 Loss_G: 0.0420 Convergence: 0.1213 k= 0.021112 lr = 0.0000135\n",
      "[12/25][1410/9765] Loss_D: 0.1163 Loss_G: 0.0425 Convergence: 0.1216 k= 0.021114 lr = 0.0000135\n",
      "[12/25][1420/9765] Loss_D: 0.1063 Loss_G: 0.0433 Convergence: 0.1076 k= 0.021107 lr = 0.0000135\n",
      "[12/25][1430/9765] Loss_D: 0.0954 Loss_G: 0.0391 Convergence: 0.0969 k= 0.021086 lr = 0.0000135\n",
      "[12/25][1440/9765] Loss_D: 0.1134 Loss_G: 0.0416 Convergence: 0.1184 k= 0.021078 lr = 0.0000135\n",
      "[12/25][1450/9765] Loss_D: 0.0915 Loss_G: 0.0366 Convergence: 0.0926 k= 0.021085 lr = 0.0000135\n",
      "[12/25][1460/9765] Loss_D: 0.0996 Loss_G: 0.0352 Convergence: 0.1052 k= 0.021123 lr = 0.0000135\n",
      "[12/25][1470/9765] Loss_D: 0.0970 Loss_G: 0.0406 Convergence: 0.0993 k= 0.021137 lr = 0.0000135\n",
      "[12/25][1480/9765] Loss_D: 0.0968 Loss_G: 0.0392 Convergence: 0.0978 k= 0.021121 lr = 0.0000135\n",
      "[12/25][1490/9765] Loss_D: 0.0973 Loss_G: 0.0390 Convergence: 0.0984 k= 0.021119 lr = 0.0000135\n",
      "[12/25][1500/9765] Loss_D: 0.0984 Loss_G: 0.0397 Convergence: 0.0992 k= 0.021135 lr = 0.0000135\n",
      "[12/25][1510/9765] Loss_D: 0.0944 Loss_G: 0.0400 Convergence: 0.0972 k= 0.021127 lr = 0.0000135\n",
      "[12/25][1520/9765] Loss_D: 0.0953 Loss_G: 0.0391 Convergence: 0.0968 k= 0.021135 lr = 0.0000135\n",
      "[12/25][1530/9765] Loss_D: 0.0898 Loss_G: 0.0370 Convergence: 0.0914 k= 0.021136 lr = 0.0000135\n",
      "[12/25][1540/9765] Loss_D: 0.0997 Loss_G: 0.0376 Convergence: 0.1032 k= 0.021157 lr = 0.0000135\n",
      "[12/25][1550/9765] Loss_D: 0.0968 Loss_G: 0.0407 Convergence: 0.0992 k= 0.021161 lr = 0.0000135\n",
      "[12/25][1560/9765] Loss_D: 0.0925 Loss_G: 0.0399 Convergence: 0.0958 k= 0.021159 lr = 0.0000135\n",
      "[12/25][1570/9765] Loss_D: 0.1011 Loss_G: 0.0418 Convergence: 0.1029 k= 0.021169 lr = 0.0000135\n",
      "[12/25][1580/9765] Loss_D: 0.0955 Loss_G: 0.0419 Convergence: 0.0998 k= 0.021156 lr = 0.0000135\n",
      "[12/25][1590/9765] Loss_D: 0.0996 Loss_G: 0.0399 Convergence: 0.1006 k= 0.021143 lr = 0.0000135\n",
      "[12/25][1600/9765] Loss_D: 0.1027 Loss_G: 0.0396 Convergence: 0.1053 k= 0.021120 lr = 0.0000135\n",
      "[12/25][1610/9765] Loss_D: 0.1011 Loss_G: 0.0426 Convergence: 0.1038 k= 0.021106 lr = 0.0000135\n",
      "[12/25][1620/9765] Loss_D: 0.0975 Loss_G: 0.0382 Convergence: 0.0994 k= 0.021106 lr = 0.0000135\n",
      "[12/25][1630/9765] Loss_D: 0.0962 Loss_G: 0.0377 Convergence: 0.0982 k= 0.021112 lr = 0.0000135\n",
      "[12/25][1640/9765] Loss_D: 0.1061 Loss_G: 0.0375 Convergence: 0.1122 k= 0.021113 lr = 0.0000135\n",
      "[12/25][1650/9765] Loss_D: 0.0978 Loss_G: 0.0376 Convergence: 0.1005 k= 0.021120 lr = 0.0000135\n",
      "[12/25][1660/9765] Loss_D: 0.1068 Loss_G: 0.0408 Convergence: 0.1099 k= 0.021121 lr = 0.0000135\n",
      "[12/25][1670/9765] Loss_D: 0.1030 Loss_G: 0.0406 Convergence: 0.1047 k= 0.021122 lr = 0.0000135\n",
      "[12/25][1680/9765] Loss_D: 0.0980 Loss_G: 0.0381 Convergence: 0.1002 k= 0.021130 lr = 0.0000135\n",
      "[12/25][1690/9765] Loss_D: 0.0889 Loss_G: 0.0376 Convergence: 0.0914 k= 0.021147 lr = 0.0000135\n",
      "[12/25][1700/9765] Loss_D: 0.0986 Loss_G: 0.0381 Convergence: 0.1011 k= 0.021170 lr = 0.0000135\n",
      "[12/25][1710/9765] Loss_D: 0.0978 Loss_G: 0.0402 Convergence: 0.0994 k= 0.021167 lr = 0.0000135\n",
      "[12/25][1720/9765] Loss_D: 0.0971 Loss_G: 0.0406 Convergence: 0.0994 k= 0.021152 lr = 0.0000135\n",
      "[12/25][1730/9765] Loss_D: 0.1013 Loss_G: 0.0357 Convergence: 0.1072 k= 0.021164 lr = 0.0000135\n",
      "[12/25][1740/9765] Loss_D: 0.1025 Loss_G: 0.0397 Convergence: 0.1049 k= 0.021178 lr = 0.0000135\n",
      "[12/25][1750/9765] Loss_D: 0.0915 Loss_G: 0.0377 Convergence: 0.0930 k= 0.021184 lr = 0.0000135\n",
      "[12/25][1760/9765] Loss_D: 0.1014 Loss_G: 0.0409 Convergence: 0.1023 k= 0.021186 lr = 0.0000135\n",
      "[12/25][1770/9765] Loss_D: 0.0943 Loss_G: 0.0413 Convergence: 0.0985 k= 0.021180 lr = 0.0000135\n",
      "[12/25][1780/9765] Loss_D: 0.1058 Loss_G: 0.0430 Convergence: 0.1071 k= 0.021151 lr = 0.0000135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][1790/9765] Loss_D: 0.0984 Loss_G: 0.0400 Convergence: 0.0995 k= 0.021120 lr = 0.0000135\n",
      "[12/25][1800/9765] Loss_D: 0.1022 Loss_G: 0.0390 Convergence: 0.1051 k= 0.021131 lr = 0.0000135\n",
      "[12/25][1810/9765] Loss_D: 0.0966 Loss_G: 0.0357 Convergence: 0.1006 k= 0.021151 lr = 0.0000135\n",
      "[12/25][1820/9765] Loss_D: 0.0971 Loss_G: 0.0384 Convergence: 0.0987 k= 0.021191 lr = 0.0000135\n",
      "[12/25][1830/9765] Loss_D: 0.1002 Loss_G: 0.0397 Convergence: 0.1017 k= 0.021204 lr = 0.0000135\n",
      "[12/25][1840/9765] Loss_D: 0.0984 Loss_G: 0.0420 Convergence: 0.1016 k= 0.021193 lr = 0.0000135\n",
      "[12/25][1850/9765] Loss_D: 0.1117 Loss_G: 0.0400 Convergence: 0.1175 k= 0.021203 lr = 0.0000135\n",
      "[12/25][1860/9765] Loss_D: 0.0940 Loss_G: 0.0379 Convergence: 0.0948 k= 0.021205 lr = 0.0000135\n",
      "[12/25][1870/9765] Loss_D: 0.1015 Loss_G: 0.0370 Convergence: 0.1061 k= 0.021205 lr = 0.0000135\n",
      "[12/25][1880/9765] Loss_D: 0.0908 Loss_G: 0.0375 Convergence: 0.0925 k= 0.021212 lr = 0.0000135\n",
      "[12/25][1890/9765] Loss_D: 0.0878 Loss_G: 0.0376 Convergence: 0.0908 k= 0.021208 lr = 0.0000135\n",
      "[12/25][1900/9765] Loss_D: 0.1032 Loss_G: 0.0394 Convergence: 0.1062 k= 0.021219 lr = 0.0000135\n",
      "[12/25][1910/9765] Loss_D: 0.0983 Loss_G: 0.0402 Convergence: 0.0996 k= 0.021213 lr = 0.0000135\n",
      "[12/25][1920/9765] Loss_D: 0.0968 Loss_G: 0.0413 Convergence: 0.0999 k= 0.021210 lr = 0.0000135\n",
      "[12/25][1930/9765] Loss_D: 0.0975 Loss_G: 0.0396 Convergence: 0.0986 k= 0.021201 lr = 0.0000135\n",
      "[12/25][1940/9765] Loss_D: 0.0925 Loss_G: 0.0377 Convergence: 0.0937 k= 0.021206 lr = 0.0000135\n",
      "[12/25][1950/9765] Loss_D: 0.0948 Loss_G: 0.0380 Convergence: 0.0958 k= 0.021215 lr = 0.0000135\n",
      "[12/25][1960/9765] Loss_D: 0.1018 Loss_G: 0.0374 Convergence: 0.1062 k= 0.021231 lr = 0.0000135\n",
      "[12/25][1970/9765] Loss_D: 0.0958 Loss_G: 0.0395 Convergence: 0.0975 k= 0.021246 lr = 0.0000135\n",
      "[12/25][1980/9765] Loss_D: 0.0961 Loss_G: 0.0399 Convergence: 0.0981 k= 0.021238 lr = 0.0000135\n",
      "[12/25][1990/9765] Loss_D: 0.1013 Loss_G: 0.0403 Convergence: 0.1027 k= 0.021226 lr = 0.0000135\n",
      "[12/25][2000/9765] Loss_D: 0.1018 Loss_G: 0.0413 Convergence: 0.1029 k= 0.021214 lr = 0.0000135\n",
      "[12/25][2010/9765] Loss_D: 0.0936 Loss_G: 0.0382 Convergence: 0.0948 k= 0.021202 lr = 0.0000135\n",
      "[12/25][2020/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.021213 lr = 0.0000135\n",
      "[12/25][2030/9765] Loss_D: 0.0875 Loss_G: 0.0409 Convergence: 0.0939 k= 0.021199 lr = 0.0000135\n",
      "[12/25][2040/9765] Loss_D: 0.1012 Loss_G: 0.0403 Convergence: 0.1027 k= 0.021192 lr = 0.0000135\n",
      "[12/25][2050/9765] Loss_D: 0.0917 Loss_G: 0.0367 Convergence: 0.0928 k= 0.021181 lr = 0.0000135\n",
      "[12/25][2060/9765] Loss_D: 0.0953 Loss_G: 0.0364 Convergence: 0.0981 k= 0.021192 lr = 0.0000135\n",
      "[12/25][2070/9765] Loss_D: 0.0956 Loss_G: 0.0411 Convergence: 0.0989 k= 0.021210 lr = 0.0000135\n",
      "[12/25][2080/9765] Loss_D: 0.0896 Loss_G: 0.0421 Convergence: 0.0964 k= 0.021178 lr = 0.0000135\n",
      "[12/25][2090/9765] Loss_D: 0.0959 Loss_G: 0.0474 Convergence: 0.1056 k= 0.021099 lr = 0.0000135\n",
      "[12/25][2100/9765] Loss_D: 0.1062 Loss_G: 0.0410 Convergence: 0.1089 k= 0.021042 lr = 0.0000135\n",
      "[12/25][2110/9765] Loss_D: 0.0941 Loss_G: 0.0360 Convergence: 0.0968 k= 0.021055 lr = 0.0000135\n",
      "[12/25][2120/9765] Loss_D: 0.0899 Loss_G: 0.0338 Convergence: 0.0931 k= 0.021080 lr = 0.0000135\n",
      "[12/25][2130/9765] Loss_D: 0.1150 Loss_G: 0.0374 Convergence: 0.1246 k= 0.021113 lr = 0.0000135\n",
      "[12/25][2140/9765] Loss_D: 0.1036 Loss_G: 0.0396 Convergence: 0.1066 k= 0.021119 lr = 0.0000135\n",
      "[12/25][2150/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0955 k= 0.021102 lr = 0.0000135\n",
      "[12/25][2160/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0974 k= 0.021121 lr = 0.0000135\n",
      "[12/25][2170/9765] Loss_D: 0.1033 Loss_G: 0.0422 Convergence: 0.1047 k= 0.021126 lr = 0.0000135\n",
      "[12/25][2180/9765] Loss_D: 0.0995 Loss_G: 0.0388 Convergence: 0.1015 k= 0.021133 lr = 0.0000135\n",
      "[12/25][2190/9765] Loss_D: 0.0975 Loss_G: 0.0394 Convergence: 0.0984 k= 0.021147 lr = 0.0000135\n",
      "[12/25][2200/9765] Loss_D: 0.0896 Loss_G: 0.0394 Convergence: 0.0937 k= 0.021149 lr = 0.0000135\n",
      "[12/25][2210/9765] Loss_D: 0.1014 Loss_G: 0.0394 Convergence: 0.1037 k= 0.021150 lr = 0.0000135\n",
      "[12/25][2220/9765] Loss_D: 0.0992 Loss_G: 0.0405 Convergence: 0.1005 k= 0.021151 lr = 0.0000135\n",
      "[12/25][2230/9765] Loss_D: 0.1049 Loss_G: 0.0417 Convergence: 0.1064 k= 0.021142 lr = 0.0000135\n",
      "[12/25][2240/9765] Loss_D: 0.1050 Loss_G: 0.0410 Convergence: 0.1073 k= 0.021129 lr = 0.0000135\n",
      "[12/25][2250/9765] Loss_D: 0.0998 Loss_G: 0.0379 Convergence: 0.1029 k= 0.021135 lr = 0.0000135\n",
      "[12/25][2260/9765] Loss_D: 0.0913 Loss_G: 0.0364 Convergence: 0.0925 k= 0.021146 lr = 0.0000135\n",
      "[12/25][2270/9765] Loss_D: 0.0970 Loss_G: 0.0378 Convergence: 0.0992 k= 0.021161 lr = 0.0000135\n",
      "[12/25][2280/9765] Loss_D: 0.0915 Loss_G: 0.0379 Convergence: 0.0932 k= 0.021166 lr = 0.0000135\n",
      "[12/25][2290/9765] Loss_D: 0.1001 Loss_G: 0.0408 Convergence: 0.1014 k= 0.021160 lr = 0.0000135\n",
      "[12/25][2300/9765] Loss_D: 0.0967 Loss_G: 0.0418 Convergence: 0.1003 k= 0.021128 lr = 0.0000135\n",
      "[12/25][2310/9765] Loss_D: 0.0951 Loss_G: 0.0408 Convergence: 0.0984 k= 0.021115 lr = 0.0000135\n",
      "[12/25][2320/9765] Loss_D: 0.0962 Loss_G: 0.0411 Convergence: 0.0994 k= 0.021094 lr = 0.0000135\n",
      "[12/25][2330/9765] Loss_D: 0.0909 Loss_G: 0.0408 Convergence: 0.0959 k= 0.021078 lr = 0.0000135\n",
      "[12/25][2340/9765] Loss_D: 0.1031 Loss_G: 0.0396 Convergence: 0.1059 k= 0.021069 lr = 0.0000135\n",
      "[12/25][2350/9765] Loss_D: 0.0891 Loss_G: 0.0381 Convergence: 0.0920 k= 0.021074 lr = 0.0000135\n",
      "[12/25][2360/9765] Loss_D: 0.0877 Loss_G: 0.0346 Convergence: 0.0893 k= 0.021085 lr = 0.0000135\n",
      "[12/25][2370/9765] Loss_D: 0.1012 Loss_G: 0.0388 Convergence: 0.1041 k= 0.021107 lr = 0.0000135\n",
      "[12/25][2380/9765] Loss_D: 0.1094 Loss_G: 0.0437 Convergence: 0.1107 k= 0.021086 lr = 0.0000135\n",
      "[12/25][2390/9765] Loss_D: 0.1067 Loss_G: 0.0441 Convergence: 0.1086 k= 0.021057 lr = 0.0000135\n",
      "[12/25][2400/9765] Loss_D: 0.0979 Loss_G: 0.0447 Convergence: 0.1041 k= 0.021021 lr = 0.0000135\n",
      "[12/25][2410/9765] Loss_D: 0.1068 Loss_G: 0.0431 Convergence: 0.1078 k= 0.020990 lr = 0.0000135\n",
      "[12/25][2420/9765] Loss_D: 0.0971 Loss_G: 0.0375 Convergence: 0.0996 k= 0.020983 lr = 0.0000135\n",
      "[12/25][2430/9765] Loss_D: 0.1085 Loss_G: 0.0390 Convergence: 0.1141 k= 0.020997 lr = 0.0000135\n",
      "[12/25][2440/9765] Loss_D: 0.0875 Loss_G: 0.0387 Convergence: 0.0917 k= 0.020995 lr = 0.0000135\n",
      "[12/25][2450/9765] Loss_D: 0.0857 Loss_G: 0.0383 Convergence: 0.0902 k= 0.020996 lr = 0.0000135\n",
      "[12/25][2460/9765] Loss_D: 0.0894 Loss_G: 0.0396 Convergence: 0.0937 k= 0.020987 lr = 0.0000135\n",
      "[12/25][2470/9765] Loss_D: 0.0987 Loss_G: 0.0393 Convergence: 0.1000 k= 0.020982 lr = 0.0000135\n",
      "[12/25][2480/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0966 k= 0.020981 lr = 0.0000135\n",
      "[12/25][2490/9765] Loss_D: 0.1039 Loss_G: 0.0409 Convergence: 0.1058 k= 0.020990 lr = 0.0000135\n",
      "[12/25][2500/9765] Loss_D: 0.1044 Loss_G: 0.0384 Convergence: 0.1089 k= 0.020992 lr = 0.0000135\n",
      "[12/25][2510/9765] Loss_D: 0.0987 Loss_G: 0.0408 Convergence: 0.1005 k= 0.020962 lr = 0.0000135\n",
      "[12/25][2520/9765] Loss_D: 0.1038 Loss_G: 0.0383 Convergence: 0.1081 k= 0.020960 lr = 0.0000135\n",
      "[12/25][2530/9765] Loss_D: 0.0979 Loss_G: 0.0406 Convergence: 0.0999 k= 0.020964 lr = 0.0000135\n",
      "[12/25][2540/9765] Loss_D: 0.0889 Loss_G: 0.0382 Convergence: 0.0920 k= 0.020980 lr = 0.0000135\n",
      "[12/25][2550/9765] Loss_D: 0.0950 Loss_G: 0.0410 Convergence: 0.0985 k= 0.020969 lr = 0.0000135\n",
      "[12/25][2560/9765] Loss_D: 0.1016 Loss_G: 0.0377 Convergence: 0.1056 k= 0.020968 lr = 0.0000135\n",
      "[12/25][2570/9765] Loss_D: 0.0932 Loss_G: 0.0394 Convergence: 0.0958 k= 0.020954 lr = 0.0000135\n",
      "[12/25][2580/9765] Loss_D: 0.0979 Loss_G: 0.0397 Convergence: 0.0989 k= 0.020936 lr = 0.0000135\n",
      "[12/25][2590/9765] Loss_D: 0.0967 Loss_G: 0.0375 Convergence: 0.0989 k= 0.020949 lr = 0.0000135\n",
      "[12/25][2600/9765] Loss_D: 0.0913 Loss_G: 0.0368 Convergence: 0.0921 k= 0.020958 lr = 0.0000135\n",
      "[12/25][2610/9765] Loss_D: 0.1012 Loss_G: 0.0382 Convergence: 0.1046 k= 0.020973 lr = 0.0000135\n",
      "[12/25][2620/9765] Loss_D: 0.0987 Loss_G: 0.0388 Convergence: 0.1004 k= 0.020979 lr = 0.0000135\n",
      "[12/25][2630/9765] Loss_D: 0.0910 Loss_G: 0.0382 Convergence: 0.0933 k= 0.020968 lr = 0.0000135\n",
      "[12/25][2640/9765] Loss_D: 0.0994 Loss_G: 0.0406 Convergence: 0.1007 k= 0.020972 lr = 0.0000135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][2650/9765] Loss_D: 0.1005 Loss_G: 0.0385 Convergence: 0.1034 k= 0.020977 lr = 0.0000135\n",
      "[12/25][2660/9765] Loss_D: 0.0951 Loss_G: 0.0378 Convergence: 0.0965 k= 0.020989 lr = 0.0000135\n",
      "[12/25][2670/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0924 k= 0.020996 lr = 0.0000135\n",
      "[12/25][2680/9765] Loss_D: 0.0926 Loss_G: 0.0370 Convergence: 0.0938 k= 0.021005 lr = 0.0000135\n",
      "[12/25][2690/9765] Loss_D: 0.1089 Loss_G: 0.0392 Convergence: 0.1145 k= 0.021020 lr = 0.0000135\n",
      "[12/25][2700/9765] Loss_D: 0.0951 Loss_G: 0.0378 Convergence: 0.0965 k= 0.021028 lr = 0.0000135\n",
      "[12/25][2710/9765] Loss_D: 0.1044 Loss_G: 0.0389 Convergence: 0.1084 k= 0.021045 lr = 0.0000135\n",
      "[12/25][2720/9765] Loss_D: 0.0964 Loss_G: 0.0369 Convergence: 0.0991 k= 0.021045 lr = 0.0000135\n",
      "[12/25][2730/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0978 k= 0.021031 lr = 0.0000135\n",
      "[12/25][2740/9765] Loss_D: 0.0937 Loss_G: 0.0385 Convergence: 0.0952 k= 0.021028 lr = 0.0000135\n",
      "[12/25][2750/9765] Loss_D: 0.0919 Loss_G: 0.0391 Convergence: 0.0947 k= 0.021036 lr = 0.0000135\n",
      "[12/25][2760/9765] Loss_D: 0.1087 Loss_G: 0.0399 Convergence: 0.1135 k= 0.021042 lr = 0.0000135\n",
      "[12/25][2770/9765] Loss_D: 0.0882 Loss_G: 0.0363 Convergence: 0.0897 k= 0.021046 lr = 0.0000135\n",
      "[12/25][2780/9765] Loss_D: 0.0931 Loss_G: 0.0369 Convergence: 0.0945 k= 0.021061 lr = 0.0000135\n",
      "[12/25][2790/9765] Loss_D: 0.0990 Loss_G: 0.0399 Convergence: 0.0999 k= 0.021049 lr = 0.0000135\n",
      "[12/25][2800/9765] Loss_D: 0.0918 Loss_G: 0.0368 Convergence: 0.0928 k= 0.021037 lr = 0.0000135\n",
      "[12/25][2810/9765] Loss_D: 0.1011 Loss_G: 0.0399 Convergence: 0.1029 k= 0.021039 lr = 0.0000135\n",
      "[12/25][2820/9765] Loss_D: 0.0986 Loss_G: 0.0415 Convergence: 0.1012 k= 0.021031 lr = 0.0000129\n",
      "[12/25][2830/9765] Loss_D: 0.0942 Loss_G: 0.0411 Convergence: 0.0982 k= 0.020997 lr = 0.0000129\n",
      "[12/25][2840/9765] Loss_D: 0.0905 Loss_G: 0.0401 Convergence: 0.0949 k= 0.020981 lr = 0.0000129\n",
      "[12/25][2850/9765] Loss_D: 0.1039 Loss_G: 0.0400 Convergence: 0.1066 k= 0.020975 lr = 0.0000129\n",
      "[12/25][2860/9765] Loss_D: 0.0975 Loss_G: 0.0392 Convergence: 0.0984 k= 0.020976 lr = 0.0000129\n",
      "[12/25][2870/9765] Loss_D: 0.0977 Loss_G: 0.0383 Convergence: 0.0997 k= 0.020983 lr = 0.0000129\n",
      "[12/25][2880/9765] Loss_D: 0.0928 Loss_G: 0.0392 Convergence: 0.0954 k= 0.020976 lr = 0.0000129\n",
      "[12/25][2890/9765] Loss_D: 0.1018 Loss_G: 0.0414 Convergence: 0.1030 k= 0.020961 lr = 0.0000129\n",
      "[12/25][2900/9765] Loss_D: 0.0988 Loss_G: 0.0434 Convergence: 0.1032 k= 0.020948 lr = 0.0000129\n",
      "[12/25][2910/9765] Loss_D: 0.0880 Loss_G: 0.0365 Convergence: 0.0897 k= 0.020945 lr = 0.0000129\n",
      "[12/25][2920/9765] Loss_D: 0.0983 Loss_G: 0.0361 Convergence: 0.1025 k= 0.020974 lr = 0.0000129\n",
      "[12/25][2930/9765] Loss_D: 0.0970 Loss_G: 0.0357 Convergence: 0.1011 k= 0.021010 lr = 0.0000129\n",
      "[12/25][2940/9765] Loss_D: 0.0934 Loss_G: 0.0375 Convergence: 0.0944 k= 0.021035 lr = 0.0000129\n",
      "[12/25][2950/9765] Loss_D: 0.1060 Loss_G: 0.0423 Convergence: 0.1072 k= 0.021031 lr = 0.0000129\n",
      "[12/25][2960/9765] Loss_D: 0.0959 Loss_G: 0.0428 Convergence: 0.1009 k= 0.020989 lr = 0.0000129\n",
      "[12/25][2970/9765] Loss_D: 0.1004 Loss_G: 0.0406 Convergence: 0.1013 k= 0.020981 lr = 0.0000129\n",
      "[12/25][2980/9765] Loss_D: 0.0929 Loss_G: 0.0372 Convergence: 0.0938 k= 0.020969 lr = 0.0000129\n",
      "[12/25][2990/9765] Loss_D: 0.0912 Loss_G: 0.0401 Convergence: 0.0954 k= 0.020991 lr = 0.0000129\n",
      "[12/25][3000/9765] Loss_D: 0.0912 Loss_G: 0.0404 Convergence: 0.0955 k= 0.020989 lr = 0.0000129\n",
      "[12/25][3010/9765] Loss_D: 0.0941 Loss_G: 0.0405 Convergence: 0.0975 k= 0.020974 lr = 0.0000129\n",
      "[12/25][3020/9765] Loss_D: 0.1012 Loss_G: 0.0411 Convergence: 0.1024 k= 0.020972 lr = 0.0000129\n",
      "[12/25][3030/9765] Loss_D: 0.0945 Loss_G: 0.0415 Convergence: 0.0987 k= 0.020941 lr = 0.0000129\n",
      "[12/25][3040/9765] Loss_D: 0.0947 Loss_G: 0.0404 Convergence: 0.0977 k= 0.020926 lr = 0.0000129\n",
      "[12/25][3050/9765] Loss_D: 0.0874 Loss_G: 0.0359 Convergence: 0.0888 k= 0.020924 lr = 0.0000129\n",
      "[12/25][3060/9765] Loss_D: 0.0957 Loss_G: 0.0411 Convergence: 0.0991 k= 0.020929 lr = 0.0000129\n",
      "[12/25][3070/9765] Loss_D: 0.0980 Loss_G: 0.0404 Convergence: 0.0997 k= 0.020942 lr = 0.0000129\n",
      "[12/25][3080/9765] Loss_D: 0.0948 Loss_G: 0.0379 Convergence: 0.0959 k= 0.020941 lr = 0.0000129\n",
      "[12/25][3090/9765] Loss_D: 0.0984 Loss_G: 0.0412 Convergence: 0.1007 k= 0.020954 lr = 0.0000129\n",
      "[12/25][3100/9765] Loss_D: 0.0995 Loss_G: 0.0382 Convergence: 0.1022 k= 0.020967 lr = 0.0000129\n",
      "[12/25][3110/9765] Loss_D: 0.0907 Loss_G: 0.0394 Convergence: 0.0943 k= 0.020977 lr = 0.0000129\n",
      "[12/25][3120/9765] Loss_D: 0.0879 Loss_G: 0.0391 Convergence: 0.0924 k= 0.020965 lr = 0.0000129\n",
      "[12/25][3130/9765] Loss_D: 0.0948 Loss_G: 0.0414 Convergence: 0.0988 k= 0.020960 lr = 0.0000129\n",
      "[12/25][3140/9765] Loss_D: 0.0896 Loss_G: 0.0425 Convergence: 0.0968 k= 0.020947 lr = 0.0000129\n",
      "[12/25][3150/9765] Loss_D: 0.1053 Loss_G: 0.0381 Convergence: 0.1105 k= 0.020936 lr = 0.0000129\n",
      "[12/25][3160/9765] Loss_D: 0.0984 Loss_G: 0.0380 Convergence: 0.1009 k= 0.020966 lr = 0.0000129\n",
      "[12/25][3170/9765] Loss_D: 0.0973 Loss_G: 0.0353 Convergence: 0.1018 k= 0.020987 lr = 0.0000129\n",
      "[12/25][3180/9765] Loss_D: 0.1037 Loss_G: 0.0412 Convergence: 0.1053 k= 0.021005 lr = 0.0000129\n",
      "[12/25][3190/9765] Loss_D: 0.0895 Loss_G: 0.0403 Convergence: 0.0945 k= 0.021012 lr = 0.0000129\n",
      "[12/25][3200/9765] Loss_D: 0.1033 Loss_G: 0.0414 Convergence: 0.1044 k= 0.021005 lr = 0.0000129\n",
      "[12/25][3210/9765] Loss_D: 0.1017 Loss_G: 0.0401 Convergence: 0.1034 k= 0.020995 lr = 0.0000129\n",
      "[12/25][3220/9765] Loss_D: 0.1054 Loss_G: 0.0401 Convergence: 0.1087 k= 0.021018 lr = 0.0000129\n",
      "[12/25][3230/9765] Loss_D: 0.0967 Loss_G: 0.0383 Convergence: 0.0983 k= 0.021025 lr = 0.0000129\n",
      "[12/25][3240/9765] Loss_D: 0.1019 Loss_G: 0.0383 Convergence: 0.1056 k= 0.021028 lr = 0.0000129\n",
      "[12/25][3250/9765] Loss_D: 0.0945 Loss_G: 0.0394 Convergence: 0.0965 k= 0.021021 lr = 0.0000129\n",
      "[12/25][3260/9765] Loss_D: 0.0919 Loss_G: 0.0395 Convergence: 0.0951 k= 0.021027 lr = 0.0000129\n",
      "[12/25][3270/9765] Loss_D: 0.0978 Loss_G: 0.0387 Convergence: 0.0993 k= 0.021022 lr = 0.0000129\n",
      "[12/25][3280/9765] Loss_D: 0.1066 Loss_G: 0.0411 Convergence: 0.1093 k= 0.021020 lr = 0.0000129\n",
      "[12/25][3290/9765] Loss_D: 0.0962 Loss_G: 0.0397 Convergence: 0.0980 k= 0.021008 lr = 0.0000129\n",
      "[12/25][3300/9765] Loss_D: 0.1026 Loss_G: 0.0391 Convergence: 0.1057 k= 0.021014 lr = 0.0000129\n",
      "[12/25][3310/9765] Loss_D: 0.0905 Loss_G: 0.0374 Convergence: 0.0922 k= 0.021023 lr = 0.0000129\n",
      "[12/25][3320/9765] Loss_D: 0.1030 Loss_G: 0.0368 Convergence: 0.1085 k= 0.021052 lr = 0.0000129\n",
      "[12/25][3330/9765] Loss_D: 0.0974 Loss_G: 0.0388 Convergence: 0.0987 k= 0.021070 lr = 0.0000129\n",
      "[12/25][3340/9765] Loss_D: 0.0994 Loss_G: 0.0455 Convergence: 0.1057 k= 0.021068 lr = 0.0000129\n",
      "[12/25][3350/9765] Loss_D: 0.0982 Loss_G: 0.0431 Convergence: 0.1026 k= 0.021046 lr = 0.0000129\n",
      "[12/25][3360/9765] Loss_D: 0.0895 Loss_G: 0.0410 Convergence: 0.0952 k= 0.021025 lr = 0.0000129\n",
      "[12/25][3370/9765] Loss_D: 0.0957 Loss_G: 0.0417 Convergence: 0.0996 k= 0.021015 lr = 0.0000129\n",
      "[12/25][3380/9765] Loss_D: 0.0971 Loss_G: 0.0366 Convergence: 0.1005 k= 0.021043 lr = 0.0000129\n",
      "[12/25][3390/9765] Loss_D: 0.1033 Loss_G: 0.0334 Convergence: 0.1123 k= 0.021080 lr = 0.0000129\n",
      "[12/25][3400/9765] Loss_D: 0.1005 Loss_G: 0.0355 Convergence: 0.1062 k= 0.021110 lr = 0.0000129\n",
      "[12/25][3410/9765] Loss_D: 0.0968 Loss_G: 0.0382 Convergence: 0.0985 k= 0.021114 lr = 0.0000129\n",
      "[12/25][3420/9765] Loss_D: 0.0882 Loss_G: 0.0388 Convergence: 0.0922 k= 0.021110 lr = 0.0000129\n",
      "[12/25][3430/9765] Loss_D: 0.1006 Loss_G: 0.0419 Convergence: 0.1028 k= 0.021092 lr = 0.0000129\n",
      "[12/25][3440/9765] Loss_D: 0.0899 Loss_G: 0.0407 Convergence: 0.0952 k= 0.021076 lr = 0.0000129\n",
      "[12/25][3450/9765] Loss_D: 0.0944 Loss_G: 0.0415 Convergence: 0.0986 k= 0.021049 lr = 0.0000129\n",
      "[12/25][3460/9765] Loss_D: 0.0928 Loss_G: 0.0390 Convergence: 0.0952 k= 0.021045 lr = 0.0000129\n",
      "[12/25][3470/9765] Loss_D: 0.0900 Loss_G: 0.0365 Convergence: 0.0909 k= 0.021076 lr = 0.0000129\n",
      "[12/25][3480/9765] Loss_D: 0.0982 Loss_G: 0.0376 Convergence: 0.1009 k= 0.021100 lr = 0.0000129\n",
      "[12/25][3490/9765] Loss_D: 0.0985 Loss_G: 0.0386 Convergence: 0.1005 k= 0.021095 lr = 0.0000129\n",
      "[12/25][3500/9765] Loss_D: 0.1072 Loss_G: 0.0425 Convergence: 0.1088 k= 0.021086 lr = 0.0000129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][3510/9765] Loss_D: 0.0957 Loss_G: 0.0416 Convergence: 0.0995 k= 0.021072 lr = 0.0000129\n",
      "[12/25][3520/9765] Loss_D: 0.0945 Loss_G: 0.0381 Convergence: 0.0953 k= 0.021056 lr = 0.0000129\n",
      "[12/25][3530/9765] Loss_D: 0.1020 Loss_G: 0.0383 Convergence: 0.1056 k= 0.021060 lr = 0.0000129\n",
      "[12/25][3540/9765] Loss_D: 0.0933 Loss_G: 0.0378 Convergence: 0.0942 k= 0.021061 lr = 0.0000129\n",
      "[12/25][3550/9765] Loss_D: 0.1006 Loss_G: 0.0403 Convergence: 0.1016 k= 0.021064 lr = 0.0000129\n",
      "[12/25][3560/9765] Loss_D: 0.1024 Loss_G: 0.0391 Convergence: 0.1054 k= 0.021072 lr = 0.0000129\n",
      "[12/25][3570/9765] Loss_D: 0.0899 Loss_G: 0.0394 Convergence: 0.0938 k= 0.021072 lr = 0.0000129\n",
      "[12/25][3580/9765] Loss_D: 0.1012 Loss_G: 0.0397 Convergence: 0.1031 k= 0.021083 lr = 0.0000129\n",
      "[12/25][3590/9765] Loss_D: 0.0868 Loss_G: 0.0415 Convergence: 0.0941 k= 0.021089 lr = 0.0000129\n",
      "[12/25][3600/9765] Loss_D: 0.0958 Loss_G: 0.0398 Convergence: 0.0979 k= 0.021080 lr = 0.0000129\n",
      "[12/25][3610/9765] Loss_D: 0.0978 Loss_G: 0.0432 Convergence: 0.1024 k= 0.021064 lr = 0.0000129\n",
      "[12/25][3620/9765] Loss_D: 0.1104 Loss_G: 0.0395 Convergence: 0.1162 k= 0.021053 lr = 0.0000129\n",
      "[12/25][3630/9765] Loss_D: 0.0990 Loss_G: 0.0380 Convergence: 0.1017 k= 0.021063 lr = 0.0000129\n",
      "[12/25][3640/9765] Loss_D: 0.0978 Loss_G: 0.0386 Convergence: 0.0995 k= 0.021061 lr = 0.0000129\n",
      "[12/25][3650/9765] Loss_D: 0.0932 Loss_G: 0.0370 Convergence: 0.0946 k= 0.021062 lr = 0.0000129\n",
      "[12/25][3660/9765] Loss_D: 0.0993 Loss_G: 0.0401 Convergence: 0.1002 k= 0.021081 lr = 0.0000129\n",
      "[12/25][3670/9765] Loss_D: 0.0905 Loss_G: 0.0359 Convergence: 0.0919 k= 0.021091 lr = 0.0000129\n",
      "[12/25][3680/9765] Loss_D: 0.0936 Loss_G: 0.0399 Convergence: 0.0966 k= 0.021095 lr = 0.0000129\n",
      "[12/25][3690/9765] Loss_D: 0.0902 Loss_G: 0.0390 Convergence: 0.0936 k= 0.021084 lr = 0.0000129\n",
      "[12/25][3700/9765] Loss_D: 0.1041 Loss_G: 0.0417 Convergence: 0.1052 k= 0.021080 lr = 0.0000129\n",
      "[12/25][3710/9765] Loss_D: 0.0935 Loss_G: 0.0384 Convergence: 0.0950 k= 0.021072 lr = 0.0000129\n",
      "[12/25][3720/9765] Loss_D: 0.0973 Loss_G: 0.0383 Convergence: 0.0991 k= 0.021079 lr = 0.0000129\n",
      "[12/25][3730/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0973 k= 0.021076 lr = 0.0000129\n",
      "[12/25][3740/9765] Loss_D: 0.0952 Loss_G: 0.0374 Convergence: 0.0969 k= 0.021100 lr = 0.0000129\n",
      "[12/25][3750/9765] Loss_D: 0.0987 Loss_G: 0.0386 Convergence: 0.1008 k= 0.021111 lr = 0.0000129\n",
      "[12/25][3760/9765] Loss_D: 0.1038 Loss_G: 0.0415 Convergence: 0.1051 k= 0.021111 lr = 0.0000129\n",
      "[12/25][3770/9765] Loss_D: 0.0981 Loss_G: 0.0393 Convergence: 0.0992 k= 0.021097 lr = 0.0000129\n",
      "[12/25][3780/9765] Loss_D: 0.1013 Loss_G: 0.0397 Convergence: 0.1033 k= 0.021096 lr = 0.0000129\n",
      "[12/25][3790/9765] Loss_D: 0.1059 Loss_G: 0.0377 Convergence: 0.1116 k= 0.021106 lr = 0.0000129\n",
      "[12/25][3800/9765] Loss_D: 0.0965 Loss_G: 0.0401 Convergence: 0.0985 k= 0.021110 lr = 0.0000129\n",
      "[12/25][3810/9765] Loss_D: 0.0958 Loss_G: 0.0388 Convergence: 0.0968 k= 0.021104 lr = 0.0000129\n",
      "[12/25][3820/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.021098 lr = 0.0000129\n",
      "[12/25][3830/9765] Loss_D: 0.1027 Loss_G: 0.0397 Convergence: 0.1053 k= 0.021092 lr = 0.0000129\n",
      "[12/25][3840/9765] Loss_D: 0.0990 Loss_G: 0.0389 Convergence: 0.1009 k= 0.021094 lr = 0.0000129\n",
      "[12/25][3850/9765] Loss_D: 0.0928 Loss_G: 0.0369 Convergence: 0.0942 k= 0.021100 lr = 0.0000129\n",
      "[12/25][3860/9765] Loss_D: 0.1057 Loss_G: 0.0405 Convergence: 0.1087 k= 0.021098 lr = 0.0000129\n",
      "[12/25][3870/9765] Loss_D: 0.0994 Loss_G: 0.0407 Convergence: 0.1009 k= 0.021089 lr = 0.0000129\n",
      "[12/25][3880/9765] Loss_D: 0.0948 Loss_G: 0.0376 Convergence: 0.0963 k= 0.021089 lr = 0.0000129\n",
      "[12/25][3890/9765] Loss_D: 0.1088 Loss_G: 0.0381 Convergence: 0.1154 k= 0.021096 lr = 0.0000129\n",
      "[12/25][3900/9765] Loss_D: 0.0912 Loss_G: 0.0375 Convergence: 0.0927 k= 0.021102 lr = 0.0000129\n",
      "[12/25][3910/9765] Loss_D: 0.0995 Loss_G: 0.0405 Convergence: 0.1007 k= 0.021102 lr = 0.0000129\n",
      "[12/25][3920/9765] Loss_D: 0.0881 Loss_G: 0.0392 Convergence: 0.0926 k= 0.021088 lr = 0.0000129\n",
      "[12/25][3930/9765] Loss_D: 0.0984 Loss_G: 0.0385 Convergence: 0.1004 k= 0.021088 lr = 0.0000129\n",
      "[12/25][3940/9765] Loss_D: 0.1043 Loss_G: 0.0420 Convergence: 0.1052 k= 0.021075 lr = 0.0000129\n",
      "[12/25][3950/9765] Loss_D: 0.0957 Loss_G: 0.0403 Convergence: 0.0982 k= 0.021058 lr = 0.0000129\n",
      "[12/25][3960/9765] Loss_D: 0.0984 Loss_G: 0.0398 Convergence: 0.0993 k= 0.021074 lr = 0.0000129\n",
      "[12/25][3970/9765] Loss_D: 0.0944 Loss_G: 0.0393 Convergence: 0.0965 k= 0.021066 lr = 0.0000129\n",
      "[12/25][3980/9765] Loss_D: 0.0926 Loss_G: 0.0395 Convergence: 0.0956 k= 0.021055 lr = 0.0000129\n",
      "[12/25][3990/9765] Loss_D: 0.0941 Loss_G: 0.0362 Convergence: 0.0967 k= 0.021038 lr = 0.0000129\n",
      "[12/25][4000/9765] Loss_D: 0.0939 Loss_G: 0.0378 Convergence: 0.0947 k= 0.021046 lr = 0.0000129\n",
      "[12/25][4010/9765] Loss_D: 0.0891 Loss_G: 0.0382 Convergence: 0.0921 k= 0.021045 lr = 0.0000129\n",
      "[12/25][4020/9765] Loss_D: 0.0996 Loss_G: 0.0403 Convergence: 0.1006 k= 0.021063 lr = 0.0000129\n",
      "[12/25][4030/9765] Loss_D: 0.1019 Loss_G: 0.0373 Convergence: 0.1064 k= 0.021068 lr = 0.0000129\n",
      "[12/25][4040/9765] Loss_D: 0.1057 Loss_G: 0.0400 Convergence: 0.1091 k= 0.021087 lr = 0.0000129\n",
      "[12/25][4050/9765] Loss_D: 0.0930 Loss_G: 0.0431 Convergence: 0.0994 k= 0.021081 lr = 0.0000129\n",
      "[12/25][4060/9765] Loss_D: 0.0881 Loss_G: 0.0426 Convergence: 0.0960 k= 0.021062 lr = 0.0000129\n",
      "[12/25][4070/9765] Loss_D: 0.0944 Loss_G: 0.0392 Convergence: 0.0963 k= 0.021052 lr = 0.0000129\n",
      "[12/25][4080/9765] Loss_D: 0.0942 Loss_G: 0.0379 Convergence: 0.0951 k= 0.021062 lr = 0.0000129\n",
      "[12/25][4090/9765] Loss_D: 0.1049 Loss_G: 0.0388 Convergence: 0.1092 k= 0.021071 lr = 0.0000129\n",
      "[12/25][4100/9765] Loss_D: 0.0943 Loss_G: 0.0385 Convergence: 0.0955 k= 0.021084 lr = 0.0000129\n",
      "[12/25][4110/9765] Loss_D: 0.1119 Loss_G: 0.0402 Convergence: 0.1177 k= 0.021095 lr = 0.0000129\n",
      "[12/25][4120/9765] Loss_D: 0.1130 Loss_G: 0.0401 Convergence: 0.1194 k= 0.021109 lr = 0.0000129\n",
      "[12/25][4130/9765] Loss_D: 0.0877 Loss_G: 0.0391 Convergence: 0.0923 k= 0.021111 lr = 0.0000129\n",
      "[12/25][4140/9765] Loss_D: 0.0930 Loss_G: 0.0375 Convergence: 0.0938 k= 0.021119 lr = 0.0000129\n",
      "[12/25][4150/9765] Loss_D: 0.0908 Loss_G: 0.0383 Convergence: 0.0933 k= 0.021133 lr = 0.0000129\n",
      "[12/25][4160/9765] Loss_D: 0.1014 Loss_G: 0.0429 Convergence: 0.1042 k= 0.021126 lr = 0.0000129\n",
      "[12/25][4170/9765] Loss_D: 0.0889 Loss_G: 0.0390 Convergence: 0.0928 k= 0.021118 lr = 0.0000129\n",
      "[12/25][4180/9765] Loss_D: 0.1101 Loss_G: 0.0414 Convergence: 0.1139 k= 0.021121 lr = 0.0000129\n",
      "[12/25][4190/9765] Loss_D: 0.0979 Loss_G: 0.0416 Convergence: 0.1009 k= 0.021116 lr = 0.0000129\n",
      "[12/25][4200/9765] Loss_D: 0.0999 Loss_G: 0.0397 Convergence: 0.1014 k= 0.021101 lr = 0.0000129\n",
      "[12/25][4210/9765] Loss_D: 0.0846 Loss_G: 0.0367 Convergence: 0.0879 k= 0.021101 lr = 0.0000129\n",
      "[12/25][4220/9765] Loss_D: 0.0902 Loss_G: 0.0372 Convergence: 0.0918 k= 0.021126 lr = 0.0000129\n",
      "[12/25][4230/9765] Loss_D: 0.0951 Loss_G: 0.0404 Convergence: 0.0980 k= 0.021126 lr = 0.0000129\n",
      "[12/25][4240/9765] Loss_D: 0.1001 Loss_G: 0.0389 Convergence: 0.1024 k= 0.021121 lr = 0.0000129\n",
      "[12/25][4250/9765] Loss_D: 0.0948 Loss_G: 0.0367 Convergence: 0.0971 k= 0.021124 lr = 0.0000129\n",
      "[12/25][4260/9765] Loss_D: 0.0883 Loss_G: 0.0367 Convergence: 0.0901 k= 0.021137 lr = 0.0000129\n",
      "[12/25][4270/9765] Loss_D: 0.0978 Loss_G: 0.0387 Convergence: 0.0995 k= 0.021148 lr = 0.0000129\n",
      "[12/25][4280/9765] Loss_D: 0.0994 Loss_G: 0.0389 Convergence: 0.1014 k= 0.021171 lr = 0.0000129\n",
      "[12/25][4290/9765] Loss_D: 0.0946 Loss_G: 0.0366 Convergence: 0.0969 k= 0.021166 lr = 0.0000129\n",
      "[12/25][4300/9765] Loss_D: 0.0923 Loss_G: 0.0380 Convergence: 0.0938 k= 0.021181 lr = 0.0000129\n",
      "[12/25][4310/9765] Loss_D: 0.1001 Loss_G: 0.0407 Convergence: 0.1013 k= 0.021172 lr = 0.0000129\n",
      "[12/25][4320/9765] Loss_D: 0.1000 Loss_G: 0.0403 Convergence: 0.1010 k= 0.021180 lr = 0.0000129\n",
      "[12/25][4330/9765] Loss_D: 0.0981 Loss_G: 0.0384 Convergence: 0.1002 k= 0.021174 lr = 0.0000129\n",
      "[12/25][4340/9765] Loss_D: 0.1018 Loss_G: 0.0398 Convergence: 0.1038 k= 0.021186 lr = 0.0000129\n",
      "[12/25][4350/9765] Loss_D: 0.0982 Loss_G: 0.0344 Convergence: 0.1041 k= 0.021183 lr = 0.0000129\n",
      "[12/25][4360/9765] Loss_D: 0.0886 Loss_G: 0.0343 Convergence: 0.0908 k= 0.021221 lr = 0.0000129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][4370/9765] Loss_D: 0.0997 Loss_G: 0.0409 Convergence: 0.1012 k= 0.021245 lr = 0.0000129\n",
      "[12/25][4380/9765] Loss_D: 0.0980 Loss_G: 0.0460 Convergence: 0.1054 k= 0.021209 lr = 0.0000129\n",
      "[12/25][4390/9765] Loss_D: 0.1017 Loss_G: 0.0452 Convergence: 0.1068 k= 0.021155 lr = 0.0000129\n",
      "[12/25][4400/9765] Loss_D: 0.0945 Loss_G: 0.0416 Convergence: 0.0988 k= 0.021113 lr = 0.0000129\n",
      "[12/25][4410/9765] Loss_D: 0.1009 Loss_G: 0.0366 Convergence: 0.1058 k= 0.021124 lr = 0.0000129\n",
      "[12/25][4420/9765] Loss_D: 0.1009 Loss_G: 0.0375 Convergence: 0.1048 k= 0.021154 lr = 0.0000129\n",
      "[12/25][4430/9765] Loss_D: 0.0892 Loss_G: 0.0393 Convergence: 0.0933 k= 0.021175 lr = 0.0000129\n",
      "[12/25][4440/9765] Loss_D: 0.0932 Loss_G: 0.0374 Convergence: 0.0942 k= 0.021198 lr = 0.0000129\n",
      "[12/25][4450/9765] Loss_D: 0.1009 Loss_G: 0.0430 Convergence: 0.1041 k= 0.021180 lr = 0.0000129\n",
      "[12/25][4460/9765] Loss_D: 0.1039 Loss_G: 0.0407 Convergence: 0.1060 k= 0.021149 lr = 0.0000129\n",
      "[12/25][4470/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0962 k= 0.021146 lr = 0.0000129\n",
      "[12/25][4480/9765] Loss_D: 0.1031 Loss_G: 0.0392 Convergence: 0.1063 k= 0.021146 lr = 0.0000129\n",
      "[12/25][4490/9765] Loss_D: 0.1004 Loss_G: 0.0428 Convergence: 0.1035 k= 0.021141 lr = 0.0000129\n",
      "[12/25][4500/9765] Loss_D: 0.0938 Loss_G: 0.0385 Convergence: 0.0952 k= 0.021136 lr = 0.0000129\n",
      "[12/25][4510/9765] Loss_D: 0.0949 Loss_G: 0.0396 Convergence: 0.0970 k= 0.021131 lr = 0.0000129\n",
      "[12/25][4520/9765] Loss_D: 0.1042 Loss_G: 0.0398 Convergence: 0.1073 k= 0.021115 lr = 0.0000129\n",
      "[12/25][4530/9765] Loss_D: 0.1013 Loss_G: 0.0397 Convergence: 0.1032 k= 0.021100 lr = 0.0000129\n",
      "[12/25][4540/9765] Loss_D: 0.1013 Loss_G: 0.0376 Convergence: 0.1054 k= 0.021105 lr = 0.0000129\n",
      "[12/25][4550/9765] Loss_D: 0.1105 Loss_G: 0.0407 Convergence: 0.1152 k= 0.021116 lr = 0.0000129\n",
      "[12/25][4560/9765] Loss_D: 0.1006 Loss_G: 0.0390 Convergence: 0.1030 k= 0.021115 lr = 0.0000129\n",
      "[12/25][4570/9765] Loss_D: 0.0967 Loss_G: 0.0385 Convergence: 0.0980 k= 0.021115 lr = 0.0000129\n",
      "[12/25][4580/9765] Loss_D: 0.1029 Loss_G: 0.0380 Convergence: 0.1071 k= 0.021123 lr = 0.0000129\n",
      "[12/25][4590/9765] Loss_D: 0.0849 Loss_G: 0.0360 Convergence: 0.0875 k= 0.021141 lr = 0.0000129\n",
      "[12/25][4600/9765] Loss_D: 0.0876 Loss_G: 0.0359 Convergence: 0.0890 k= 0.021166 lr = 0.0000129\n",
      "[12/25][4610/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0990 k= 0.021188 lr = 0.0000129\n",
      "[12/25][4620/9765] Loss_D: 0.0868 Loss_G: 0.0395 Convergence: 0.0921 k= 0.021186 lr = 0.0000129\n",
      "[12/25][4630/9765] Loss_D: 0.0944 Loss_G: 0.0408 Convergence: 0.0980 k= 0.021176 lr = 0.0000129\n",
      "[12/25][4640/9765] Loss_D: 0.0965 Loss_G: 0.0395 Convergence: 0.0979 k= 0.021169 lr = 0.0000129\n",
      "[12/25][4650/9765] Loss_D: 0.0943 Loss_G: 0.0402 Convergence: 0.0972 k= 0.021161 lr = 0.0000129\n",
      "[12/25][4660/9765] Loss_D: 0.0853 Loss_G: 0.0391 Convergence: 0.0909 k= 0.021161 lr = 0.0000129\n",
      "[12/25][4670/9765] Loss_D: 0.1001 Loss_G: 0.0401 Convergence: 0.1012 k= 0.021156 lr = 0.0000129\n",
      "[12/25][4680/9765] Loss_D: 0.1012 Loss_G: 0.0392 Convergence: 0.1036 k= 0.021151 lr = 0.0000129\n",
      "[12/25][4690/9765] Loss_D: 0.1027 Loss_G: 0.0380 Convergence: 0.1068 k= 0.021179 lr = 0.0000129\n",
      "[12/25][4700/9765] Loss_D: 0.0960 Loss_G: 0.0415 Convergence: 0.0997 k= 0.021190 lr = 0.0000129\n",
      "[12/25][4710/9765] Loss_D: 0.0985 Loss_G: 0.0412 Convergence: 0.1008 k= 0.021190 lr = 0.0000129\n",
      "[12/25][4720/9765] Loss_D: 0.1109 Loss_G: 0.0387 Convergence: 0.1176 k= 0.021197 lr = 0.0000129\n",
      "[12/25][4730/9765] Loss_D: 0.0926 Loss_G: 0.0389 Convergence: 0.0949 k= 0.021201 lr = 0.0000129\n",
      "[12/25][4740/9765] Loss_D: 0.1005 Loss_G: 0.0417 Convergence: 0.1025 k= 0.021185 lr = 0.0000129\n",
      "[12/25][4750/9765] Loss_D: 0.1010 Loss_G: 0.0377 Convergence: 0.1048 k= 0.021184 lr = 0.0000129\n",
      "[12/25][4760/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0982 k= 0.021189 lr = 0.0000129\n",
      "[12/25][4770/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0978 k= 0.021189 lr = 0.0000129\n",
      "[12/25][4780/9765] Loss_D: 0.0996 Loss_G: 0.0387 Convergence: 0.1019 k= 0.021205 lr = 0.0000129\n",
      "[12/25][4790/9765] Loss_D: 0.0972 Loss_G: 0.0379 Convergence: 0.0993 k= 0.021203 lr = 0.0000129\n",
      "[12/25][4800/9765] Loss_D: 0.0922 Loss_G: 0.0396 Convergence: 0.0954 k= 0.021202 lr = 0.0000129\n",
      "[12/25][4810/9765] Loss_D: 0.1027 Loss_G: 0.0376 Convergence: 0.1073 k= 0.021204 lr = 0.0000129\n",
      "[12/25][4820/9765] Loss_D: 0.0949 Loss_G: 0.0383 Convergence: 0.0958 k= 0.021205 lr = 0.0000129\n",
      "[12/25][4830/9765] Loss_D: 0.0932 Loss_G: 0.0396 Convergence: 0.0960 k= 0.021201 lr = 0.0000129\n",
      "[12/25][4840/9765] Loss_D: 0.1032 Loss_G: 0.0409 Convergence: 0.1048 k= 0.021207 lr = 0.0000129\n",
      "[12/25][4850/9765] Loss_D: 0.0882 Loss_G: 0.0386 Convergence: 0.0920 k= 0.021209 lr = 0.0000129\n",
      "[12/25][4860/9765] Loss_D: 0.1058 Loss_G: 0.0393 Convergence: 0.1100 k= 0.021207 lr = 0.0000129\n",
      "[12/25][4870/9765] Loss_D: 0.0947 Loss_G: 0.0380 Convergence: 0.0957 k= 0.021216 lr = 0.0000129\n",
      "[12/25][4880/9765] Loss_D: 0.1034 Loss_G: 0.0376 Convergence: 0.1084 k= 0.021237 lr = 0.0000129\n",
      "[12/25][4890/9765] Loss_D: 0.0978 Loss_G: 0.0390 Convergence: 0.0992 k= 0.021232 lr = 0.0000129\n",
      "[12/25][4900/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0946 k= 0.021235 lr = 0.0000129\n",
      "[12/25][4910/9765] Loss_D: 0.1024 Loss_G: 0.0409 Convergence: 0.1036 k= 0.021250 lr = 0.0000129\n",
      "[12/25][4920/9765] Loss_D: 0.0954 Loss_G: 0.0378 Convergence: 0.0969 k= 0.021249 lr = 0.0000129\n",
      "[12/25][4930/9765] Loss_D: 0.0944 Loss_G: 0.0361 Convergence: 0.0972 k= 0.021258 lr = 0.0000129\n",
      "[12/25][4940/9765] Loss_D: 0.1001 Loss_G: 0.0409 Convergence: 0.1014 k= 0.021260 lr = 0.0000129\n",
      "[12/25][4950/9765] Loss_D: 0.0914 Loss_G: 0.0434 Convergence: 0.0987 k= 0.021222 lr = 0.0000129\n",
      "[12/25][4960/9765] Loss_D: 0.0968 Loss_G: 0.0415 Convergence: 0.1001 k= 0.021204 lr = 0.0000129\n",
      "[12/25][4970/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0967 k= 0.021200 lr = 0.0000129\n",
      "[12/25][4980/9765] Loss_D: 0.0906 Loss_G: 0.0382 Convergence: 0.0931 k= 0.021206 lr = 0.0000129\n",
      "[12/25][4990/9765] Loss_D: 0.1064 Loss_G: 0.0374 Convergence: 0.1127 k= 0.021219 lr = 0.0000129\n",
      "[12/25][5000/9765] Loss_D: 0.1007 Loss_G: 0.0405 Convergence: 0.1017 k= 0.021237 lr = 0.0000129\n",
      "[12/25][5010/9765] Loss_D: 0.1042 Loss_G: 0.0414 Convergence: 0.1057 k= 0.021216 lr = 0.0000129\n",
      "[12/25][5020/9765] Loss_D: 0.1018 Loss_G: 0.0403 Convergence: 0.1033 k= 0.021199 lr = 0.0000129\n",
      "[12/25][5030/9765] Loss_D: 0.0926 Loss_G: 0.0445 Convergence: 0.1005 k= 0.021167 lr = 0.0000129\n",
      "[12/25][5040/9765] Loss_D: 0.0947 Loss_G: 0.0408 Convergence: 0.0981 k= 0.021142 lr = 0.0000129\n",
      "[12/25][5050/9765] Loss_D: 0.0960 Loss_G: 0.0409 Convergence: 0.0991 k= 0.021153 lr = 0.0000129\n",
      "[12/25][5060/9765] Loss_D: 0.1057 Loss_G: 0.0373 Convergence: 0.1118 k= 0.021182 lr = 0.0000129\n",
      "[12/25][5070/9765] Loss_D: 0.0919 Loss_G: 0.0364 Convergence: 0.0934 k= 0.021205 lr = 0.0000129\n",
      "[12/25][5080/9765] Loss_D: 0.1020 Loss_G: 0.0455 Convergence: 0.1073 k= 0.021176 lr = 0.0000129\n",
      "[12/25][5090/9765] Loss_D: 0.0952 Loss_G: 0.0419 Convergence: 0.0996 k= 0.021119 lr = 0.0000129\n",
      "[12/25][5100/9765] Loss_D: 0.1101 Loss_G: 0.0410 Convergence: 0.1142 k= 0.021104 lr = 0.0000129\n",
      "[12/25][5110/9765] Loss_D: 0.0908 Loss_G: 0.0428 Convergence: 0.0978 k= 0.021068 lr = 0.0000129\n",
      "[12/25][5120/9765] Loss_D: 0.0908 Loss_G: 0.0397 Convergence: 0.0947 k= 0.021032 lr = 0.0000129\n",
      "[12/25][5130/9765] Loss_D: 0.0905 Loss_G: 0.0362 Convergence: 0.0916 k= 0.021042 lr = 0.0000129\n",
      "[12/25][5140/9765] Loss_D: 0.1007 Loss_G: 0.0344 Convergence: 0.1076 k= 0.021061 lr = 0.0000129\n",
      "[12/25][5150/9765] Loss_D: 0.1036 Loss_G: 0.0387 Convergence: 0.1075 k= 0.021090 lr = 0.0000129\n",
      "[12/25][5160/9765] Loss_D: 0.1019 Loss_G: 0.0383 Convergence: 0.1055 k= 0.021092 lr = 0.0000129\n",
      "[12/25][5170/9765] Loss_D: 0.1011 Loss_G: 0.0413 Convergence: 0.1025 k= 0.021091 lr = 0.0000129\n",
      "[12/25][5180/9765] Loss_D: 0.1030 Loss_G: 0.0419 Convergence: 0.1043 k= 0.021090 lr = 0.0000129\n",
      "[12/25][5190/9765] Loss_D: 0.1004 Loss_G: 0.0393 Convergence: 0.1024 k= 0.021090 lr = 0.0000129\n",
      "[12/25][5200/9765] Loss_D: 0.1021 Loss_G: 0.0395 Convergence: 0.1046 k= 0.021102 lr = 0.0000129\n",
      "[12/25][5210/9765] Loss_D: 0.0919 Loss_G: 0.0384 Convergence: 0.0940 k= 0.021103 lr = 0.0000129\n",
      "[12/25][5220/9765] Loss_D: 0.0971 Loss_G: 0.0392 Convergence: 0.0980 k= 0.021110 lr = 0.0000129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][5230/9765] Loss_D: 0.0923 Loss_G: 0.0394 Convergence: 0.0953 k= 0.021088 lr = 0.0000129\n",
      "[12/25][5240/9765] Loss_D: 0.0990 Loss_G: 0.0393 Convergence: 0.1005 k= 0.021105 lr = 0.0000129\n",
      "[12/25][5250/9765] Loss_D: 0.0878 Loss_G: 0.0389 Convergence: 0.0921 k= 0.021101 lr = 0.0000129\n",
      "[12/25][5260/9765] Loss_D: 0.0917 Loss_G: 0.0392 Convergence: 0.0947 k= 0.021103 lr = 0.0000129\n",
      "[12/25][5270/9765] Loss_D: 0.1034 Loss_G: 0.0389 Convergence: 0.1070 k= 0.021103 lr = 0.0000129\n",
      "[12/25][5280/9765] Loss_D: 0.0929 Loss_G: 0.0388 Convergence: 0.0950 k= 0.021118 lr = 0.0000129\n",
      "[12/25][5290/9765] Loss_D: 0.1166 Loss_G: 0.0398 Convergence: 0.1246 k= 0.021114 lr = 0.0000129\n",
      "[12/25][5300/9765] Loss_D: 0.0974 Loss_G: 0.0417 Convergence: 0.1006 k= 0.021117 lr = 0.0000129\n",
      "[12/25][5310/9765] Loss_D: 0.0929 Loss_G: 0.0373 Convergence: 0.0938 k= 0.021125 lr = 0.0000129\n",
      "[12/25][5320/9765] Loss_D: 0.1115 Loss_G: 0.0361 Convergence: 0.1210 k= 0.021127 lr = 0.0000129\n",
      "[12/25][5330/9765] Loss_D: 0.0995 Loss_G: 0.0376 Convergence: 0.1029 k= 0.021162 lr = 0.0000129\n",
      "[12/25][5340/9765] Loss_D: 0.0927 Loss_G: 0.0367 Convergence: 0.0941 k= 0.021172 lr = 0.0000129\n",
      "[12/25][5350/9765] Loss_D: 0.0835 Loss_G: 0.0375 Convergence: 0.0881 k= 0.021190 lr = 0.0000129\n",
      "[12/25][5360/9765] Loss_D: 0.0927 Loss_G: 0.0406 Convergence: 0.0967 k= 0.021196 lr = 0.0000129\n",
      "[12/25][5370/9765] Loss_D: 0.0929 Loss_G: 0.0413 Convergence: 0.0976 k= 0.021194 lr = 0.0000129\n",
      "[12/25][5380/9765] Loss_D: 0.1035 Loss_G: 0.0402 Convergence: 0.1059 k= 0.021192 lr = 0.0000129\n",
      "[12/25][5390/9765] Loss_D: 0.0928 Loss_G: 0.0401 Convergence: 0.0964 k= 0.021191 lr = 0.0000129\n",
      "[12/25][5400/9765] Loss_D: 0.0870 Loss_G: 0.0390 Convergence: 0.0917 k= 0.021174 lr = 0.0000129\n",
      "[12/25][5410/9765] Loss_D: 0.0969 Loss_G: 0.0388 Convergence: 0.0979 k= 0.021174 lr = 0.0000129\n",
      "[12/25][5420/9765] Loss_D: 0.1021 Loss_G: 0.0373 Convergence: 0.1067 k= 0.021199 lr = 0.0000129\n",
      "[12/25][5430/9765] Loss_D: 0.0978 Loss_G: 0.0374 Convergence: 0.1007 k= 0.021215 lr = 0.0000129\n",
      "[12/25][5440/9765] Loss_D: 0.0948 Loss_G: 0.0385 Convergence: 0.0958 k= 0.021231 lr = 0.0000129\n",
      "[12/25][5450/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0961 k= 0.021231 lr = 0.0000129\n",
      "[12/25][5460/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1001 k= 0.021228 lr = 0.0000129\n",
      "[12/25][5470/9765] Loss_D: 0.0996 Loss_G: 0.0401 Convergence: 0.1005 k= 0.021218 lr = 0.0000129\n",
      "[12/25][5480/9765] Loss_D: 0.0883 Loss_G: 0.0384 Convergence: 0.0919 k= 0.021218 lr = 0.0000129\n",
      "[12/25][5490/9765] Loss_D: 0.1015 Loss_G: 0.0394 Convergence: 0.1039 k= 0.021227 lr = 0.0000129\n",
      "[12/25][5500/9765] Loss_D: 0.1006 Loss_G: 0.0386 Convergence: 0.1034 k= 0.021249 lr = 0.0000129\n",
      "[12/25][5510/9765] Loss_D: 0.1102 Loss_G: 0.0434 Convergence: 0.1121 k= 0.021253 lr = 0.0000129\n",
      "[12/25][5520/9765] Loss_D: 0.0922 Loss_G: 0.0395 Convergence: 0.0953 k= 0.021237 lr = 0.0000129\n",
      "[12/25][5530/9765] Loss_D: 0.0924 Loss_G: 0.0391 Convergence: 0.0950 k= 0.021231 lr = 0.0000129\n",
      "[12/25][5540/9765] Loss_D: 0.0981 Loss_G: 0.0416 Convergence: 0.1010 k= 0.021231 lr = 0.0000129\n",
      "[12/25][5550/9765] Loss_D: 0.0967 Loss_G: 0.0404 Convergence: 0.0989 k= 0.021212 lr = 0.0000129\n",
      "[12/25][5560/9765] Loss_D: 0.1012 Loss_G: 0.0412 Convergence: 0.1025 k= 0.021212 lr = 0.0000129\n",
      "[12/25][5570/9765] Loss_D: 0.0996 Loss_G: 0.0372 Convergence: 0.1034 k= 0.021210 lr = 0.0000129\n",
      "[12/25][5580/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.021236 lr = 0.0000129\n",
      "[12/25][5590/9765] Loss_D: 0.0886 Loss_G: 0.0397 Convergence: 0.0933 k= 0.021227 lr = 0.0000129\n",
      "[12/25][5600/9765] Loss_D: 0.0921 Loss_G: 0.0367 Convergence: 0.0934 k= 0.021236 lr = 0.0000129\n",
      "[12/25][5610/9765] Loss_D: 0.0972 Loss_G: 0.0393 Convergence: 0.0981 k= 0.021248 lr = 0.0000129\n",
      "[12/25][5620/9765] Loss_D: 0.0961 Loss_G: 0.0410 Convergence: 0.0992 k= 0.021227 lr = 0.0000129\n",
      "[12/25][5630/9765] Loss_D: 0.0948 Loss_G: 0.0380 Convergence: 0.0958 k= 0.021211 lr = 0.0000129\n",
      "[12/25][5640/9765] Loss_D: 0.0981 Loss_G: 0.0405 Convergence: 0.0999 k= 0.021216 lr = 0.0000129\n",
      "[12/25][5650/9765] Loss_D: 0.0872 Loss_G: 0.0364 Convergence: 0.0892 k= 0.021226 lr = 0.0000129\n",
      "[12/25][5660/9765] Loss_D: 0.1011 Loss_G: 0.0376 Convergence: 0.1050 k= 0.021234 lr = 0.0000129\n",
      "[12/25][5670/9765] Loss_D: 0.0978 Loss_G: 0.0394 Convergence: 0.0986 k= 0.021235 lr = 0.0000129\n",
      "[12/25][5680/9765] Loss_D: 0.1039 Loss_G: 0.0387 Convergence: 0.1079 k= 0.021215 lr = 0.0000129\n",
      "[12/25][5690/9765] Loss_D: 0.0928 Loss_G: 0.0407 Convergence: 0.0969 k= 0.021195 lr = 0.0000129\n",
      "[12/25][5700/9765] Loss_D: 0.0894 Loss_G: 0.0396 Convergence: 0.0938 k= 0.021191 lr = 0.0000129\n",
      "[12/25][5710/9765] Loss_D: 0.1055 Loss_G: 0.0397 Convergence: 0.1092 k= 0.021184 lr = 0.0000129\n",
      "[12/25][5720/9765] Loss_D: 0.0921 Loss_G: 0.0394 Convergence: 0.0952 k= 0.021178 lr = 0.0000129\n",
      "[12/25][5730/9765] Loss_D: 0.0959 Loss_G: 0.0411 Convergence: 0.0991 k= 0.021161 lr = 0.0000129\n",
      "[12/25][5740/9765] Loss_D: 0.0991 Loss_G: 0.0373 Convergence: 0.1026 k= 0.021162 lr = 0.0000129\n",
      "[12/25][5750/9765] Loss_D: 0.0881 Loss_G: 0.0385 Convergence: 0.0918 k= 0.021163 lr = 0.0000129\n",
      "[12/25][5760/9765] Loss_D: 0.1072 Loss_G: 0.0386 Convergence: 0.1125 k= 0.021174 lr = 0.0000129\n",
      "[12/25][5770/9765] Loss_D: 0.1039 Loss_G: 0.0399 Convergence: 0.1068 k= 0.021171 lr = 0.0000129\n",
      "[12/25][5780/9765] Loss_D: 0.0935 Loss_G: 0.0385 Convergence: 0.0951 k= 0.021171 lr = 0.0000129\n",
      "[12/25][5790/9765] Loss_D: 0.0963 Loss_G: 0.0395 Convergence: 0.0978 k= 0.021168 lr = 0.0000129\n",
      "[12/25][5800/9765] Loss_D: 0.0916 Loss_G: 0.0396 Convergence: 0.0950 k= 0.021160 lr = 0.0000129\n",
      "[12/25][5810/9765] Loss_D: 0.1013 Loss_G: 0.0378 Convergence: 0.1051 k= 0.021177 lr = 0.0000129\n",
      "[12/25][5820/9765] Loss_D: 0.1035 Loss_G: 0.0372 Convergence: 0.1089 k= 0.021185 lr = 0.0000122\n",
      "[12/25][5830/9765] Loss_D: 0.0882 Loss_G: 0.0401 Convergence: 0.0935 k= 0.021167 lr = 0.0000122\n",
      "[12/25][5840/9765] Loss_D: 0.0968 Loss_G: 0.0389 Convergence: 0.0978 k= 0.021159 lr = 0.0000122\n",
      "[12/25][5850/9765] Loss_D: 0.0925 Loss_G: 0.0363 Convergence: 0.0943 k= 0.021173 lr = 0.0000122\n",
      "[12/25][5860/9765] Loss_D: 0.0988 Loss_G: 0.0395 Convergence: 0.1000 k= 0.021189 lr = 0.0000122\n",
      "[12/25][5870/9765] Loss_D: 0.1079 Loss_G: 0.0428 Convergence: 0.1096 k= 0.021205 lr = 0.0000122\n",
      "[12/25][5880/9765] Loss_D: 0.0974 Loss_G: 0.0419 Convergence: 0.1008 k= 0.021193 lr = 0.0000122\n",
      "[12/25][5890/9765] Loss_D: 0.0989 Loss_G: 0.0400 Convergence: 0.0999 k= 0.021173 lr = 0.0000122\n",
      "[12/25][5900/9765] Loss_D: 0.1045 Loss_G: 0.0416 Convergence: 0.1060 k= 0.021169 lr = 0.0000122\n",
      "[12/25][5910/9765] Loss_D: 0.0928 Loss_G: 0.0365 Convergence: 0.0946 k= 0.021163 lr = 0.0000122\n",
      "[12/25][5920/9765] Loss_D: 0.0898 Loss_G: 0.0350 Convergence: 0.0918 k= 0.021176 lr = 0.0000122\n",
      "[12/25][5930/9765] Loss_D: 0.0965 Loss_G: 0.0393 Convergence: 0.0977 k= 0.021185 lr = 0.0000122\n",
      "[12/25][5940/9765] Loss_D: 0.0948 Loss_G: 0.0410 Convergence: 0.0984 k= 0.021173 lr = 0.0000122\n",
      "[12/25][5950/9765] Loss_D: 0.0938 Loss_G: 0.0384 Convergence: 0.0952 k= 0.021163 lr = 0.0000122\n",
      "[12/25][5960/9765] Loss_D: 0.0937 Loss_G: 0.0428 Convergence: 0.0996 k= 0.021159 lr = 0.0000122\n",
      "[12/25][5970/9765] Loss_D: 0.0972 Loss_G: 0.0404 Convergence: 0.0993 k= 0.021138 lr = 0.0000122\n",
      "[12/25][5980/9765] Loss_D: 0.1008 Loss_G: 0.0419 Convergence: 0.1029 k= 0.021135 lr = 0.0000122\n",
      "[12/25][5990/9765] Loss_D: 0.0940 Loss_G: 0.0394 Convergence: 0.0963 k= 0.021127 lr = 0.0000122\n",
      "[12/25][6000/9765] Loss_D: 0.0984 Loss_G: 0.0397 Convergence: 0.0993 k= 0.021126 lr = 0.0000122\n",
      "[12/25][6010/9765] Loss_D: 0.1042 Loss_G: 0.0410 Convergence: 0.1060 k= 0.021135 lr = 0.0000122\n",
      "[12/25][6020/9765] Loss_D: 0.1031 Loss_G: 0.0421 Convergence: 0.1045 k= 0.021128 lr = 0.0000122\n",
      "[12/25][6030/9765] Loss_D: 0.0936 Loss_G: 0.0382 Convergence: 0.0948 k= 0.021124 lr = 0.0000122\n",
      "[12/25][6040/9765] Loss_D: 0.0902 Loss_G: 0.0370 Convergence: 0.0916 k= 0.021121 lr = 0.0000122\n",
      "[12/25][6050/9765] Loss_D: 0.0957 Loss_G: 0.0383 Convergence: 0.0967 k= 0.021137 lr = 0.0000122\n",
      "[12/25][6060/9765] Loss_D: 0.1028 Loss_G: 0.0384 Convergence: 0.1066 k= 0.021156 lr = 0.0000122\n",
      "[12/25][6070/9765] Loss_D: 0.1079 Loss_G: 0.0373 Convergence: 0.1149 k= 0.021188 lr = 0.0000122\n",
      "[12/25][6080/9765] Loss_D: 0.1042 Loss_G: 0.0389 Convergence: 0.1080 k= 0.021191 lr = 0.0000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][6090/9765] Loss_D: 0.0966 Loss_G: 0.0372 Convergence: 0.0991 k= 0.021184 lr = 0.0000122\n",
      "[12/25][6100/9765] Loss_D: 0.0918 Loss_G: 0.0358 Convergence: 0.0938 k= 0.021194 lr = 0.0000122\n",
      "[12/25][6110/9765] Loss_D: 0.0986 Loss_G: 0.0374 Convergence: 0.1017 k= 0.021214 lr = 0.0000122\n",
      "[12/25][6120/9765] Loss_D: 0.0931 Loss_G: 0.0370 Convergence: 0.0944 k= 0.021223 lr = 0.0000122\n",
      "[12/25][6130/9765] Loss_D: 0.1015 Loss_G: 0.0387 Convergence: 0.1045 k= 0.021233 lr = 0.0000122\n",
      "[12/25][6140/9765] Loss_D: 0.0996 Loss_G: 0.0397 Convergence: 0.1009 k= 0.021236 lr = 0.0000122\n",
      "[12/25][6150/9765] Loss_D: 0.0976 Loss_G: 0.0397 Convergence: 0.0987 k= 0.021225 lr = 0.0000122\n",
      "[12/25][6160/9765] Loss_D: 0.1033 Loss_G: 0.0394 Convergence: 0.1063 k= 0.021243 lr = 0.0000122\n",
      "[12/25][6170/9765] Loss_D: 0.0941 Loss_G: 0.0411 Convergence: 0.0981 k= 0.021234 lr = 0.0000122\n",
      "[12/25][6180/9765] Loss_D: 0.0921 Loss_G: 0.0409 Convergence: 0.0967 k= 0.021231 lr = 0.0000122\n",
      "[12/25][6190/9765] Loss_D: 0.1081 Loss_G: 0.0407 Convergence: 0.1118 k= 0.021227 lr = 0.0000122\n",
      "[12/25][6200/9765] Loss_D: 0.0943 Loss_G: 0.0382 Convergence: 0.0953 k= 0.021228 lr = 0.0000122\n",
      "[12/25][6210/9765] Loss_D: 0.1009 Loss_G: 0.0421 Convergence: 0.1032 k= 0.021222 lr = 0.0000122\n",
      "[12/25][6220/9765] Loss_D: 0.0926 Loss_G: 0.0411 Convergence: 0.0971 k= 0.021228 lr = 0.0000122\n",
      "[12/25][6230/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0985 k= 0.021221 lr = 0.0000122\n",
      "[12/25][6240/9765] Loss_D: 0.1004 Loss_G: 0.0406 Convergence: 0.1013 k= 0.021212 lr = 0.0000122\n",
      "[12/25][6250/9765] Loss_D: 0.0957 Loss_G: 0.0434 Convergence: 0.1014 k= 0.021180 lr = 0.0000122\n",
      "[12/25][6260/9765] Loss_D: 0.1094 Loss_G: 0.0386 Convergence: 0.1158 k= 0.021177 lr = 0.0000122\n",
      "[12/25][6270/9765] Loss_D: 0.1007 Loss_G: 0.0372 Convergence: 0.1049 k= 0.021176 lr = 0.0000122\n",
      "[12/25][6280/9765] Loss_D: 0.0989 Loss_G: 0.0385 Convergence: 0.1011 k= 0.021187 lr = 0.0000122\n",
      "[12/25][6290/9765] Loss_D: 0.0955 Loss_G: 0.0373 Convergence: 0.0975 k= 0.021213 lr = 0.0000122\n",
      "[12/25][6300/9765] Loss_D: 0.0921 Loss_G: 0.0374 Convergence: 0.0932 k= 0.021230 lr = 0.0000122\n",
      "[12/25][6310/9765] Loss_D: 0.0948 Loss_G: 0.0383 Convergence: 0.0957 k= 0.021231 lr = 0.0000122\n",
      "[12/25][6320/9765] Loss_D: 0.0938 Loss_G: 0.0370 Convergence: 0.0954 k= 0.021237 lr = 0.0000122\n",
      "[12/25][6330/9765] Loss_D: 0.0964 Loss_G: 0.0382 Convergence: 0.0980 k= 0.021243 lr = 0.0000122\n",
      "[12/25][6340/9765] Loss_D: 0.1045 Loss_G: 0.0427 Convergence: 0.1059 k= 0.021233 lr = 0.0000122\n",
      "[12/25][6350/9765] Loss_D: 0.1005 Loss_G: 0.0425 Convergence: 0.1033 k= 0.021213 lr = 0.0000122\n",
      "[12/25][6360/9765] Loss_D: 0.0950 Loss_G: 0.0417 Convergence: 0.0993 k= 0.021197 lr = 0.0000122\n",
      "[12/25][6370/9765] Loss_D: 0.1006 Loss_G: 0.0380 Convergence: 0.1040 k= 0.021193 lr = 0.0000122\n",
      "[12/25][6380/9765] Loss_D: 0.1042 Loss_G: 0.0401 Convergence: 0.1069 k= 0.021198 lr = 0.0000122\n",
      "[12/25][6390/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0945 k= 0.021180 lr = 0.0000122\n",
      "[12/25][6400/9765] Loss_D: 0.1036 Loss_G: 0.0407 Convergence: 0.1055 k= 0.021181 lr = 0.0000122\n",
      "[12/25][6410/9765] Loss_D: 0.0996 Loss_G: 0.0392 Convergence: 0.1014 k= 0.021173 lr = 0.0000122\n",
      "[12/25][6420/9765] Loss_D: 0.0953 Loss_G: 0.0394 Convergence: 0.0971 k= 0.021162 lr = 0.0000122\n",
      "[12/25][6430/9765] Loss_D: 0.0977 Loss_G: 0.0371 Convergence: 0.1008 k= 0.021176 lr = 0.0000122\n",
      "[12/25][6440/9765] Loss_D: 0.1064 Loss_G: 0.0360 Convergence: 0.1140 k= 0.021208 lr = 0.0000122\n",
      "[12/25][6450/9765] Loss_D: 0.1079 Loss_G: 0.0356 Convergence: 0.1165 k= 0.021232 lr = 0.0000122\n",
      "[12/25][6460/9765] Loss_D: 0.0957 Loss_G: 0.0368 Convergence: 0.0982 k= 0.021265 lr = 0.0000122\n",
      "[12/25][6470/9765] Loss_D: 0.1022 Loss_G: 0.0406 Convergence: 0.1036 k= 0.021269 lr = 0.0000122\n",
      "[12/25][6480/9765] Loss_D: 0.1030 Loss_G: 0.0383 Convergence: 0.1071 k= 0.021263 lr = 0.0000122\n",
      "[12/25][6490/9765] Loss_D: 0.0953 Loss_G: 0.0398 Convergence: 0.0975 k= 0.021265 lr = 0.0000122\n",
      "[12/25][6500/9765] Loss_D: 0.0964 Loss_G: 0.0392 Convergence: 0.0975 k= 0.021265 lr = 0.0000122\n",
      "[12/25][6510/9765] Loss_D: 0.1032 Loss_G: 0.0435 Convergence: 0.1059 k= 0.021254 lr = 0.0000122\n",
      "[12/25][6520/9765] Loss_D: 0.1000 Loss_G: 0.0377 Convergence: 0.1035 k= 0.021242 lr = 0.0000122\n",
      "[12/25][6530/9765] Loss_D: 0.0952 Loss_G: 0.0398 Convergence: 0.0974 k= 0.021234 lr = 0.0000122\n",
      "[12/25][6540/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0947 k= 0.021231 lr = 0.0000122\n",
      "[12/25][6550/9765] Loss_D: 0.1010 Loss_G: 0.0382 Convergence: 0.1044 k= 0.021233 lr = 0.0000122\n",
      "[12/25][6560/9765] Loss_D: 0.0891 Loss_G: 0.0386 Convergence: 0.0926 k= 0.021240 lr = 0.0000122\n",
      "[12/25][6570/9765] Loss_D: 0.1136 Loss_G: 0.0400 Convergence: 0.1202 k= 0.021259 lr = 0.0000122\n",
      "[12/25][6580/9765] Loss_D: 0.0925 Loss_G: 0.0398 Convergence: 0.0958 k= 0.021260 lr = 0.0000122\n",
      "[12/25][6590/9765] Loss_D: 0.0909 Loss_G: 0.0392 Convergence: 0.0942 k= 0.021256 lr = 0.0000122\n",
      "[12/25][6600/9765] Loss_D: 0.1012 Loss_G: 0.0405 Convergence: 0.1024 k= 0.021244 lr = 0.0000122\n",
      "[12/25][6610/9765] Loss_D: 0.0968 Loss_G: 0.0403 Convergence: 0.0989 k= 0.021231 lr = 0.0000122\n",
      "[12/25][6620/9765] Loss_D: 0.1030 Loss_G: 0.0382 Convergence: 0.1070 k= 0.021240 lr = 0.0000122\n",
      "[12/25][6630/9765] Loss_D: 0.0968 Loss_G: 0.0399 Convergence: 0.0985 k= 0.021246 lr = 0.0000122\n",
      "[12/25][6640/9765] Loss_D: 0.0932 Loss_G: 0.0397 Convergence: 0.0961 k= 0.021247 lr = 0.0000122\n",
      "[12/25][6650/9765] Loss_D: 0.0983 Loss_G: 0.0381 Convergence: 0.1007 k= 0.021257 lr = 0.0000122\n",
      "[12/25][6660/9765] Loss_D: 0.1039 Loss_G: 0.0384 Convergence: 0.1081 k= 0.021258 lr = 0.0000122\n",
      "[12/25][6670/9765] Loss_D: 0.0977 Loss_G: 0.0378 Convergence: 0.1002 k= 0.021263 lr = 0.0000122\n",
      "[12/25][6680/9765] Loss_D: 0.1011 Loss_G: 0.0391 Convergence: 0.1036 k= 0.021273 lr = 0.0000122\n",
      "[12/25][6690/9765] Loss_D: 0.0974 Loss_G: 0.0385 Convergence: 0.0990 k= 0.021253 lr = 0.0000122\n",
      "[12/25][6700/9765] Loss_D: 0.0927 Loss_G: 0.0369 Convergence: 0.0940 k= 0.021252 lr = 0.0000122\n",
      "[12/25][6710/9765] Loss_D: 0.0986 Loss_G: 0.0379 Convergence: 0.1011 k= 0.021268 lr = 0.0000122\n",
      "[12/25][6720/9765] Loss_D: 0.0936 Loss_G: 0.0364 Convergence: 0.0958 k= 0.021271 lr = 0.0000122\n",
      "[12/25][6730/9765] Loss_D: 0.0908 Loss_G: 0.0388 Convergence: 0.0938 k= 0.021290 lr = 0.0000122\n",
      "[12/25][6740/9765] Loss_D: 0.0919 Loss_G: 0.0397 Convergence: 0.0953 k= 0.021266 lr = 0.0000122\n",
      "[12/25][6750/9765] Loss_D: 0.0926 Loss_G: 0.0408 Convergence: 0.0969 k= 0.021251 lr = 0.0000122\n",
      "[12/25][6760/9765] Loss_D: 0.0904 Loss_G: 0.0410 Convergence: 0.0958 k= 0.021225 lr = 0.0000122\n",
      "[12/25][6770/9765] Loss_D: 0.0968 Loss_G: 0.0374 Convergence: 0.0993 k= 0.021222 lr = 0.0000122\n",
      "[12/25][6780/9765] Loss_D: 0.0930 Loss_G: 0.0397 Convergence: 0.0960 k= 0.021230 lr = 0.0000122\n",
      "[12/25][6790/9765] Loss_D: 0.1020 Loss_G: 0.0423 Convergence: 0.1040 k= 0.021223 lr = 0.0000122\n",
      "[12/25][6800/9765] Loss_D: 0.1081 Loss_G: 0.0421 Convergence: 0.1104 k= 0.021203 lr = 0.0000122\n",
      "[12/25][6810/9765] Loss_D: 0.0877 Loss_G: 0.0386 Convergence: 0.0918 k= 0.021191 lr = 0.0000122\n",
      "[12/25][6820/9765] Loss_D: 0.0919 Loss_G: 0.0393 Convergence: 0.0949 k= 0.021195 lr = 0.0000122\n",
      "[12/25][6830/9765] Loss_D: 0.0964 Loss_G: 0.0398 Convergence: 0.0981 k= 0.021204 lr = 0.0000122\n",
      "[12/25][6840/9765] Loss_D: 0.0966 Loss_G: 0.0401 Convergence: 0.0986 k= 0.021206 lr = 0.0000122\n",
      "[12/25][6850/9765] Loss_D: 0.0898 Loss_G: 0.0408 Convergence: 0.0952 k= 0.021192 lr = 0.0000122\n",
      "[12/25][6860/9765] Loss_D: 0.0898 Loss_G: 0.0361 Convergence: 0.0907 k= 0.021166 lr = 0.0000122\n",
      "[12/25][6870/9765] Loss_D: 0.0962 Loss_G: 0.0389 Convergence: 0.0971 k= 0.021163 lr = 0.0000122\n",
      "[12/25][6880/9765] Loss_D: 0.0991 Loss_G: 0.0388 Convergence: 0.1011 k= 0.021168 lr = 0.0000122\n",
      "[12/25][6890/9765] Loss_D: 0.0888 Loss_G: 0.0378 Convergence: 0.0915 k= 0.021160 lr = 0.0000122\n",
      "[12/25][6900/9765] Loss_D: 0.1013 Loss_G: 0.0404 Convergence: 0.1026 k= 0.021159 lr = 0.0000122\n",
      "[12/25][6910/9765] Loss_D: 0.0962 Loss_G: 0.0380 Convergence: 0.0978 k= 0.021159 lr = 0.0000122\n",
      "[12/25][6920/9765] Loss_D: 0.0872 Loss_G: 0.0380 Convergence: 0.0908 k= 0.021148 lr = 0.0000122\n",
      "[12/25][6930/9765] Loss_D: 0.0926 Loss_G: 0.0396 Convergence: 0.0957 k= 0.021147 lr = 0.0000122\n",
      "[12/25][6940/9765] Loss_D: 0.1004 Loss_G: 0.0421 Convergence: 0.1029 k= 0.021136 lr = 0.0000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][6950/9765] Loss_D: 0.0961 Loss_G: 0.0368 Convergence: 0.0989 k= 0.021130 lr = 0.0000122\n",
      "[12/25][6960/9765] Loss_D: 0.0992 Loss_G: 0.0391 Convergence: 0.1009 k= 0.021146 lr = 0.0000122\n",
      "[12/25][6970/9765] Loss_D: 0.0969 Loss_G: 0.0390 Convergence: 0.0978 k= 0.021139 lr = 0.0000122\n",
      "[12/25][6980/9765] Loss_D: 0.0986 Loss_G: 0.0392 Convergence: 0.1000 k= 0.021145 lr = 0.0000122\n",
      "[12/25][6990/9765] Loss_D: 0.0946 Loss_G: 0.0402 Convergence: 0.0975 k= 0.021130 lr = 0.0000122\n",
      "[12/25][7000/9765] Loss_D: 0.0968 Loss_G: 0.0422 Convergence: 0.1008 k= 0.021108 lr = 0.0000122\n",
      "[12/25][7010/9765] Loss_D: 0.0932 Loss_G: 0.0402 Convergence: 0.0966 k= 0.021080 lr = 0.0000122\n",
      "[12/25][7020/9765] Loss_D: 0.0959 Loss_G: 0.0356 Convergence: 0.0998 k= 0.021091 lr = 0.0000122\n",
      "[12/25][7030/9765] Loss_D: 0.0917 Loss_G: 0.0349 Convergence: 0.0945 k= 0.021119 lr = 0.0000122\n",
      "[12/25][7040/9765] Loss_D: 0.0890 Loss_G: 0.0345 Convergence: 0.0912 k= 0.021147 lr = 0.0000122\n",
      "[12/25][7050/9765] Loss_D: 0.0977 Loss_G: 0.0397 Convergence: 0.0988 k= 0.021167 lr = 0.0000122\n",
      "[12/25][7060/9765] Loss_D: 0.0951 Loss_G: 0.0396 Convergence: 0.0971 k= 0.021165 lr = 0.0000122\n",
      "[12/25][7070/9765] Loss_D: 0.0941 Loss_G: 0.0409 Convergence: 0.0979 k= 0.021137 lr = 0.0000122\n",
      "[12/25][7080/9765] Loss_D: 0.0973 Loss_G: 0.0411 Convergence: 0.1000 k= 0.021116 lr = 0.0000122\n",
      "[12/25][7090/9765] Loss_D: 0.0890 Loss_G: 0.0377 Convergence: 0.0916 k= 0.021116 lr = 0.0000122\n",
      "[12/25][7100/9765] Loss_D: 0.1035 Loss_G: 0.0385 Convergence: 0.1075 k= 0.021128 lr = 0.0000122\n",
      "[12/25][7110/9765] Loss_D: 0.1053 Loss_G: 0.0373 Convergence: 0.1112 k= 0.021147 lr = 0.0000122\n",
      "[12/25][7120/9765] Loss_D: 0.0991 Loss_G: 0.0405 Convergence: 0.1004 k= 0.021139 lr = 0.0000122\n",
      "[12/25][7130/9765] Loss_D: 0.1059 Loss_G: 0.0451 Convergence: 0.1091 k= 0.021108 lr = 0.0000122\n",
      "[12/25][7140/9765] Loss_D: 0.1023 Loss_G: 0.0452 Convergence: 0.1070 k= 0.021077 lr = 0.0000122\n",
      "[12/25][7150/9765] Loss_D: 0.0970 Loss_G: 0.0402 Convergence: 0.0990 k= 0.021055 lr = 0.0000122\n",
      "[12/25][7160/9765] Loss_D: 0.1013 Loss_G: 0.0400 Convergence: 0.1029 k= 0.021056 lr = 0.0000122\n",
      "[12/25][7170/9765] Loss_D: 0.0914 Loss_G: 0.0372 Convergence: 0.0925 k= 0.021058 lr = 0.0000122\n",
      "[12/25][7180/9765] Loss_D: 0.0906 Loss_G: 0.0373 Convergence: 0.0922 k= 0.021085 lr = 0.0000122\n",
      "[12/25][7190/9765] Loss_D: 0.0898 Loss_G: 0.0410 Convergence: 0.0954 k= 0.021092 lr = 0.0000122\n",
      "[12/25][7200/9765] Loss_D: 0.0927 Loss_G: 0.0395 Convergence: 0.0956 k= 0.021068 lr = 0.0000122\n",
      "[12/25][7210/9765] Loss_D: 0.1006 Loss_G: 0.0391 Convergence: 0.1029 k= 0.021064 lr = 0.0000122\n",
      "[12/25][7220/9765] Loss_D: 0.0958 Loss_G: 0.0394 Convergence: 0.0973 k= 0.021066 lr = 0.0000122\n",
      "[12/25][7230/9765] Loss_D: 0.0981 Loss_G: 0.0402 Convergence: 0.0996 k= 0.021068 lr = 0.0000122\n",
      "[12/25][7240/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0948 k= 0.021084 lr = 0.0000122\n",
      "[12/25][7250/9765] Loss_D: 0.1004 Loss_G: 0.0399 Convergence: 0.1019 k= 0.021089 lr = 0.0000122\n",
      "[12/25][7260/9765] Loss_D: 0.0972 Loss_G: 0.0389 Convergence: 0.0983 k= 0.021099 lr = 0.0000122\n",
      "[12/25][7270/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1003 k= 0.021100 lr = 0.0000122\n",
      "[12/25][7280/9765] Loss_D: 0.1009 Loss_G: 0.0371 Convergence: 0.1053 k= 0.021111 lr = 0.0000122\n",
      "[12/25][7290/9765] Loss_D: 0.0947 Loss_G: 0.0371 Convergence: 0.0966 k= 0.021117 lr = 0.0000122\n",
      "[12/25][7300/9765] Loss_D: 0.0998 Loss_G: 0.0403 Convergence: 0.1007 k= 0.021122 lr = 0.0000122\n",
      "[12/25][7310/9765] Loss_D: 0.0996 Loss_G: 0.0398 Convergence: 0.1008 k= 0.021126 lr = 0.0000122\n",
      "[12/25][7320/9765] Loss_D: 0.0982 Loss_G: 0.0387 Convergence: 0.0999 k= 0.021136 lr = 0.0000122\n",
      "[12/25][7330/9765] Loss_D: 0.0960 Loss_G: 0.0419 Convergence: 0.1001 k= 0.021130 lr = 0.0000122\n",
      "[12/25][7340/9765] Loss_D: 0.1000 Loss_G: 0.0401 Convergence: 0.1010 k= 0.021121 lr = 0.0000122\n",
      "[12/25][7350/9765] Loss_D: 0.0920 Loss_G: 0.0379 Convergence: 0.0936 k= 0.021119 lr = 0.0000122\n",
      "[12/25][7360/9765] Loss_D: 0.0913 Loss_G: 0.0355 Convergence: 0.0933 k= 0.021140 lr = 0.0000122\n",
      "[12/25][7370/9765] Loss_D: 0.0911 Loss_G: 0.0355 Convergence: 0.0931 k= 0.021166 lr = 0.0000122\n",
      "[12/25][7380/9765] Loss_D: 0.1181 Loss_G: 0.0455 Convergence: 0.1211 k= 0.021152 lr = 0.0000122\n",
      "[12/25][7390/9765] Loss_D: 0.1007 Loss_G: 0.0474 Convergence: 0.1084 k= 0.021081 lr = 0.0000122\n",
      "[12/25][7400/9765] Loss_D: 0.0944 Loss_G: 0.0428 Convergence: 0.1000 k= 0.021034 lr = 0.0000122\n",
      "[12/25][7410/9765] Loss_D: 0.0880 Loss_G: 0.0363 Convergence: 0.0896 k= 0.021035 lr = 0.0000122\n",
      "[12/25][7420/9765] Loss_D: 0.0939 Loss_G: 0.0365 Convergence: 0.0960 k= 0.021063 lr = 0.0000122\n",
      "[12/25][7430/9765] Loss_D: 0.1046 Loss_G: 0.0426 Convergence: 0.1059 k= 0.021059 lr = 0.0000122\n",
      "[12/25][7440/9765] Loss_D: 0.0894 Loss_G: 0.0407 Convergence: 0.0949 k= 0.021049 lr = 0.0000122\n",
      "[12/25][7450/9765] Loss_D: 0.0961 Loss_G: 0.0398 Convergence: 0.0979 k= 0.021028 lr = 0.0000122\n",
      "[12/25][7460/9765] Loss_D: 0.0913 Loss_G: 0.0400 Convergence: 0.0953 k= 0.021015 lr = 0.0000122\n",
      "[12/25][7470/9765] Loss_D: 0.1039 Loss_G: 0.0380 Convergence: 0.1086 k= 0.021021 lr = 0.0000122\n",
      "[12/25][7480/9765] Loss_D: 0.0944 Loss_G: 0.0377 Convergence: 0.0956 k= 0.021025 lr = 0.0000122\n",
      "[12/25][7490/9765] Loss_D: 0.0971 Loss_G: 0.0382 Convergence: 0.0989 k= 0.021048 lr = 0.0000122\n",
      "[12/25][7500/9765] Loss_D: 0.0925 Loss_G: 0.0389 Convergence: 0.0949 k= 0.021058 lr = 0.0000122\n",
      "[12/25][7510/9765] Loss_D: 0.0917 Loss_G: 0.0405 Convergence: 0.0960 k= 0.021049 lr = 0.0000122\n",
      "[12/25][7520/9765] Loss_D: 0.0950 Loss_G: 0.0390 Convergence: 0.0965 k= 0.021036 lr = 0.0000122\n",
      "[12/25][7530/9765] Loss_D: 0.0984 Loss_G: 0.0378 Convergence: 0.1011 k= 0.021030 lr = 0.0000122\n",
      "[12/25][7540/9765] Loss_D: 0.1024 Loss_G: 0.0400 Convergence: 0.1045 k= 0.021035 lr = 0.0000122\n",
      "[12/25][7550/9765] Loss_D: 0.0879 Loss_G: 0.0357 Convergence: 0.0889 k= 0.021043 lr = 0.0000122\n",
      "[12/25][7560/9765] Loss_D: 0.0967 Loss_G: 0.0369 Convergence: 0.0996 k= 0.021075 lr = 0.0000122\n",
      "[12/25][7570/9765] Loss_D: 0.0906 Loss_G: 0.0387 Convergence: 0.0935 k= 0.021095 lr = 0.0000122\n",
      "[12/25][7580/9765] Loss_D: 0.0935 Loss_G: 0.0433 Convergence: 0.0999 k= 0.021078 lr = 0.0000122\n",
      "[12/25][7590/9765] Loss_D: 0.0906 Loss_G: 0.0406 Convergence: 0.0955 k= 0.021043 lr = 0.0000122\n",
      "[12/25][7600/9765] Loss_D: 0.1033 Loss_G: 0.0386 Convergence: 0.1072 k= 0.021064 lr = 0.0000122\n",
      "[12/25][7610/9765] Loss_D: 0.0905 Loss_G: 0.0381 Convergence: 0.0929 k= 0.021064 lr = 0.0000122\n",
      "[12/25][7620/9765] Loss_D: 0.0980 Loss_G: 0.0422 Convergence: 0.1015 k= 0.021064 lr = 0.0000122\n",
      "[12/25][7630/9765] Loss_D: 0.1050 Loss_G: 0.0412 Convergence: 0.1070 k= 0.021044 lr = 0.0000122\n",
      "[12/25][7640/9765] Loss_D: 0.0903 Loss_G: 0.0356 Convergence: 0.0918 k= 0.021043 lr = 0.0000122\n",
      "[12/25][7650/9765] Loss_D: 0.0969 Loss_G: 0.0382 Convergence: 0.0987 k= 0.021060 lr = 0.0000122\n",
      "[12/25][7660/9765] Loss_D: 0.0939 Loss_G: 0.0406 Convergence: 0.0974 k= 0.021072 lr = 0.0000122\n",
      "[12/25][7670/9765] Loss_D: 0.1093 Loss_G: 0.0393 Convergence: 0.1148 k= 0.021071 lr = 0.0000122\n",
      "[12/25][7680/9765] Loss_D: 0.0973 Loss_G: 0.0389 Convergence: 0.0984 k= 0.021070 lr = 0.0000122\n",
      "[12/25][7690/9765] Loss_D: 0.0942 Loss_G: 0.0373 Convergence: 0.0958 k= 0.021071 lr = 0.0000122\n",
      "[12/25][7700/9765] Loss_D: 0.0970 Loss_G: 0.0408 Convergence: 0.0995 k= 0.021082 lr = 0.0000122\n",
      "[12/25][7710/9765] Loss_D: 0.1007 Loss_G: 0.0390 Convergence: 0.1032 k= 0.021101 lr = 0.0000122\n",
      "[12/25][7720/9765] Loss_D: 0.0939 Loss_G: 0.0384 Convergence: 0.0952 k= 0.021105 lr = 0.0000122\n",
      "[12/25][7730/9765] Loss_D: 0.0982 Loss_G: 0.0365 Convergence: 0.1020 k= 0.021103 lr = 0.0000122\n",
      "[12/25][7740/9765] Loss_D: 0.0965 Loss_G: 0.0425 Convergence: 0.1010 k= 0.021101 lr = 0.0000122\n",
      "[12/25][7750/9765] Loss_D: 0.0935 Loss_G: 0.0388 Convergence: 0.0954 k= 0.021089 lr = 0.0000122\n",
      "[12/25][7760/9765] Loss_D: 0.0880 Loss_G: 0.0357 Convergence: 0.0890 k= 0.021098 lr = 0.0000122\n",
      "[12/25][7770/9765] Loss_D: 0.1046 Loss_G: 0.0384 Convergence: 0.1092 k= 0.021134 lr = 0.0000122\n",
      "[12/25][7780/9765] Loss_D: 0.0928 Loss_G: 0.0407 Convergence: 0.0969 k= 0.021132 lr = 0.0000122\n",
      "[12/25][7790/9765] Loss_D: 0.0988 Loss_G: 0.0404 Convergence: 0.1002 k= 0.021112 lr = 0.0000122\n",
      "[12/25][7800/9765] Loss_D: 0.1036 Loss_G: 0.0393 Convergence: 0.1069 k= 0.021104 lr = 0.0000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][7810/9765] Loss_D: 0.0997 Loss_G: 0.0396 Convergence: 0.1012 k= 0.021103 lr = 0.0000122\n",
      "[12/25][7820/9765] Loss_D: 0.0999 Loss_G: 0.0412 Convergence: 0.1016 k= 0.021096 lr = 0.0000122\n",
      "[12/25][7830/9765] Loss_D: 0.0995 Loss_G: 0.0371 Convergence: 0.1033 k= 0.021085 lr = 0.0000122\n",
      "[12/25][7840/9765] Loss_D: 0.0950 Loss_G: 0.0362 Convergence: 0.0979 k= 0.021108 lr = 0.0000122\n",
      "[12/25][7850/9765] Loss_D: 0.1015 Loss_G: 0.0396 Convergence: 0.1037 k= 0.021128 lr = 0.0000122\n",
      "[12/25][7860/9765] Loss_D: 0.0930 Loss_G: 0.0438 Convergence: 0.1001 k= 0.021105 lr = 0.0000122\n",
      "[12/25][7870/9765] Loss_D: 0.0926 Loss_G: 0.0373 Convergence: 0.0935 k= 0.021113 lr = 0.0000122\n",
      "[12/25][7880/9765] Loss_D: 0.1080 Loss_G: 0.0375 Convergence: 0.1147 k= 0.021115 lr = 0.0000122\n",
      "[12/25][7890/9765] Loss_D: 0.0916 Loss_G: 0.0383 Convergence: 0.0937 k= 0.021125 lr = 0.0000122\n",
      "[12/25][7900/9765] Loss_D: 0.1018 Loss_G: 0.0388 Convergence: 0.1049 k= 0.021138 lr = 0.0000122\n",
      "[12/25][7910/9765] Loss_D: 0.0978 Loss_G: 0.0393 Convergence: 0.0988 k= 0.021132 lr = 0.0000122\n",
      "[12/25][7920/9765] Loss_D: 0.0954 Loss_G: 0.0391 Convergence: 0.0968 k= 0.021137 lr = 0.0000122\n",
      "[12/25][7930/9765] Loss_D: 0.0966 Loss_G: 0.0367 Convergence: 0.0997 k= 0.021147 lr = 0.0000122\n",
      "[12/25][7940/9765] Loss_D: 0.1055 Loss_G: 0.0372 Convergence: 0.1116 k= 0.021164 lr = 0.0000122\n",
      "[12/25][7950/9765] Loss_D: 0.1012 Loss_G: 0.0395 Convergence: 0.1034 k= 0.021171 lr = 0.0000122\n",
      "[12/25][7960/9765] Loss_D: 0.1019 Loss_G: 0.0421 Convergence: 0.1038 k= 0.021153 lr = 0.0000122\n",
      "[12/25][7970/9765] Loss_D: 0.0909 Loss_G: 0.0389 Convergence: 0.0939 k= 0.021143 lr = 0.0000122\n",
      "[12/25][7980/9765] Loss_D: 0.1005 Loss_G: 0.0396 Convergence: 0.1023 k= 0.021137 lr = 0.0000122\n",
      "[12/25][7990/9765] Loss_D: 0.0973 Loss_G: 0.0369 Convergence: 0.1004 k= 0.021137 lr = 0.0000122\n",
      "[12/25][8000/9765] Loss_D: 0.0940 Loss_G: 0.0406 Convergence: 0.0975 k= 0.021147 lr = 0.0000122\n",
      "[12/25][8010/9765] Loss_D: 0.0979 Loss_G: 0.0368 Convergence: 0.1014 k= 0.021156 lr = 0.0000122\n",
      "[12/25][8020/9765] Loss_D: 0.0927 Loss_G: 0.0402 Convergence: 0.0963 k= 0.021159 lr = 0.0000122\n",
      "[12/25][8030/9765] Loss_D: 0.0971 Loss_G: 0.0402 Convergence: 0.0990 k= 0.021150 lr = 0.0000122\n",
      "[12/25][8040/9765] Loss_D: 0.0905 Loss_G: 0.0392 Convergence: 0.0939 k= 0.021151 lr = 0.0000122\n",
      "[12/25][8050/9765] Loss_D: 0.1022 Loss_G: 0.0393 Convergence: 0.1049 k= 0.021153 lr = 0.0000122\n",
      "[12/25][8060/9765] Loss_D: 0.0982 Loss_G: 0.0384 Convergence: 0.1003 k= 0.021169 lr = 0.0000122\n",
      "[12/25][8070/9765] Loss_D: 0.0931 Loss_G: 0.0385 Convergence: 0.0949 k= 0.021157 lr = 0.0000122\n",
      "[12/25][8080/9765] Loss_D: 0.0928 Loss_G: 0.0366 Convergence: 0.0944 k= 0.021184 lr = 0.0000122\n",
      "[12/25][8090/9765] Loss_D: 0.0983 Loss_G: 0.0394 Convergence: 0.0994 k= 0.021186 lr = 0.0000122\n",
      "[12/25][8100/9765] Loss_D: 0.0980 Loss_G: 0.0396 Convergence: 0.0989 k= 0.021162 lr = 0.0000122\n",
      "[12/25][8110/9765] Loss_D: 0.0979 Loss_G: 0.0419 Convergence: 0.1012 k= 0.021143 lr = 0.0000122\n",
      "[12/25][8120/9765] Loss_D: 0.0927 Loss_G: 0.0389 Convergence: 0.0950 k= 0.021133 lr = 0.0000122\n",
      "[12/25][8130/9765] Loss_D: 0.0950 Loss_G: 0.0394 Convergence: 0.0969 k= 0.021134 lr = 0.0000122\n",
      "[12/25][8140/9765] Loss_D: 0.0874 Loss_G: 0.0389 Convergence: 0.0919 k= 0.021149 lr = 0.0000122\n",
      "[12/25][8150/9765] Loss_D: 0.0956 Loss_G: 0.0429 Convergence: 0.1008 k= 0.021138 lr = 0.0000122\n",
      "[12/25][8160/9765] Loss_D: 0.0938 Loss_G: 0.0395 Convergence: 0.0963 k= 0.021130 lr = 0.0000122\n",
      "[12/25][8170/9765] Loss_D: 0.0995 Loss_G: 0.0434 Convergence: 0.1036 k= 0.021102 lr = 0.0000122\n",
      "[12/25][8180/9765] Loss_D: 0.0959 Loss_G: 0.0412 Convergence: 0.0992 k= 0.021088 lr = 0.0000122\n",
      "[12/25][8190/9765] Loss_D: 0.0947 Loss_G: 0.0399 Convergence: 0.0972 k= 0.021079 lr = 0.0000122\n",
      "[12/25][8200/9765] Loss_D: 0.1032 Loss_G: 0.0383 Convergence: 0.1073 k= 0.021091 lr = 0.0000122\n",
      "[12/25][8210/9765] Loss_D: 0.0993 Loss_G: 0.0386 Convergence: 0.1015 k= 0.021109 lr = 0.0000122\n",
      "[12/25][8220/9765] Loss_D: 0.1007 Loss_G: 0.0362 Convergence: 0.1058 k= 0.021125 lr = 0.0000122\n",
      "[12/25][8230/9765] Loss_D: 0.0959 Loss_G: 0.0381 Convergence: 0.0974 k= 0.021133 lr = 0.0000122\n",
      "[12/25][8240/9765] Loss_D: 0.0948 Loss_G: 0.0377 Convergence: 0.0961 k= 0.021137 lr = 0.0000122\n",
      "[12/25][8250/9765] Loss_D: 0.0948 Loss_G: 0.0369 Convergence: 0.0969 k= 0.021131 lr = 0.0000122\n",
      "[12/25][8260/9765] Loss_D: 0.0965 Loss_G: 0.0402 Convergence: 0.0986 k= 0.021138 lr = 0.0000122\n",
      "[12/25][8270/9765] Loss_D: 0.0980 Loss_G: 0.0403 Convergence: 0.0996 k= 0.021149 lr = 0.0000122\n",
      "[12/25][8280/9765] Loss_D: 0.0934 Loss_G: 0.0370 Convergence: 0.0950 k= 0.021155 lr = 0.0000122\n",
      "[12/25][8290/9765] Loss_D: 0.0910 Loss_G: 0.0374 Convergence: 0.0925 k= 0.021169 lr = 0.0000122\n",
      "[12/25][8300/9765] Loss_D: 0.0940 Loss_G: 0.0405 Convergence: 0.0974 k= 0.021173 lr = 0.0000122\n",
      "[12/25][8310/9765] Loss_D: 0.0990 Loss_G: 0.0409 Convergence: 0.1008 k= 0.021173 lr = 0.0000122\n",
      "[12/25][8320/9765] Loss_D: 0.1010 Loss_G: 0.0371 Convergence: 0.1053 k= 0.021177 lr = 0.0000122\n",
      "[12/25][8330/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0979 k= 0.021202 lr = 0.0000122\n",
      "[12/25][8340/9765] Loss_D: 0.0979 Loss_G: 0.0414 Convergence: 0.1006 k= 0.021196 lr = 0.0000122\n",
      "[12/25][8350/9765] Loss_D: 0.0983 Loss_G: 0.0398 Convergence: 0.0993 k= 0.021193 lr = 0.0000122\n",
      "[12/25][8360/9765] Loss_D: 0.0986 Loss_G: 0.0394 Convergence: 0.0997 k= 0.021191 lr = 0.0000122\n",
      "[12/25][8370/9765] Loss_D: 0.0994 Loss_G: 0.0387 Convergence: 0.1016 k= 0.021213 lr = 0.0000122\n",
      "[12/25][8380/9765] Loss_D: 0.1093 Loss_G: 0.0419 Convergence: 0.1123 k= 0.021225 lr = 0.0000122\n",
      "[12/25][8390/9765] Loss_D: 0.1047 Loss_G: 0.0403 Convergence: 0.1075 k= 0.021229 lr = 0.0000122\n",
      "[12/25][8400/9765] Loss_D: 0.0914 Loss_G: 0.0423 Convergence: 0.0977 k= 0.021204 lr = 0.0000122\n",
      "[12/25][8410/9765] Loss_D: 0.0994 Loss_G: 0.0409 Convergence: 0.1010 k= 0.021200 lr = 0.0000122\n",
      "[12/25][8420/9765] Loss_D: 0.1053 Loss_G: 0.0404 Convergence: 0.1083 k= 0.021191 lr = 0.0000122\n",
      "[12/25][8430/9765] Loss_D: 0.1008 Loss_G: 0.0371 Convergence: 0.1051 k= 0.021208 lr = 0.0000122\n",
      "[12/25][8440/9765] Loss_D: 0.0980 Loss_G: 0.0420 Convergence: 0.1013 k= 0.021215 lr = 0.0000122\n",
      "[12/25][8450/9765] Loss_D: 0.0950 Loss_G: 0.0404 Convergence: 0.0979 k= 0.021200 lr = 0.0000122\n",
      "[12/25][8460/9765] Loss_D: 0.0964 Loss_G: 0.0413 Convergence: 0.0996 k= 0.021189 lr = 0.0000122\n",
      "[12/25][8470/9765] Loss_D: 0.0967 Loss_G: 0.0401 Convergence: 0.0987 k= 0.021182 lr = 0.0000122\n",
      "[12/25][8480/9765] Loss_D: 0.1033 Loss_G: 0.0408 Convergence: 0.1050 k= 0.021179 lr = 0.0000122\n",
      "[12/25][8490/9765] Loss_D: 0.1000 Loss_G: 0.0393 Convergence: 0.1019 k= 0.021180 lr = 0.0000122\n",
      "[12/25][8500/9765] Loss_D: 0.0968 Loss_G: 0.0385 Convergence: 0.0982 k= 0.021182 lr = 0.0000122\n",
      "[12/25][8510/9765] Loss_D: 0.0894 Loss_G: 0.0391 Convergence: 0.0932 k= 0.021184 lr = 0.0000122\n",
      "[12/25][8520/9765] Loss_D: 0.0898 Loss_G: 0.0363 Convergence: 0.0907 k= 0.021214 lr = 0.0000122\n",
      "[12/25][8530/9765] Loss_D: 0.0953 Loss_G: 0.0393 Convergence: 0.0969 k= 0.021232 lr = 0.0000122\n",
      "[12/25][8540/9765] Loss_D: 0.0854 Loss_G: 0.0431 Convergence: 0.0948 k= 0.021196 lr = 0.0000122\n",
      "[12/25][8550/9765] Loss_D: 0.0919 Loss_G: 0.0445 Convergence: 0.1001 k= 0.021148 lr = 0.0000122\n",
      "[12/25][8560/9765] Loss_D: 0.0956 Loss_G: 0.0434 Convergence: 0.1013 k= 0.021115 lr = 0.0000122\n",
      "[12/25][8570/9765] Loss_D: 0.0977 Loss_G: 0.0403 Convergence: 0.0995 k= 0.021093 lr = 0.0000122\n",
      "[12/25][8580/9765] Loss_D: 0.0891 Loss_G: 0.0352 Convergence: 0.0906 k= 0.021097 lr = 0.0000122\n",
      "[12/25][8590/9765] Loss_D: 0.1009 Loss_G: 0.0366 Convergence: 0.1058 k= 0.021143 lr = 0.0000122\n",
      "[12/25][8600/9765] Loss_D: 0.0988 Loss_G: 0.0373 Convergence: 0.1021 k= 0.021171 lr = 0.0000122\n",
      "[12/25][8610/9765] Loss_D: 0.1041 Loss_G: 0.0400 Convergence: 0.1069 k= 0.021181 lr = 0.0000122\n",
      "[12/25][8620/9765] Loss_D: 0.1003 Loss_G: 0.0409 Convergence: 0.1016 k= 0.021179 lr = 0.0000122\n",
      "[12/25][8630/9765] Loss_D: 0.0953 Loss_G: 0.0412 Convergence: 0.0989 k= 0.021177 lr = 0.0000122\n",
      "[12/25][8640/9765] Loss_D: 0.0900 Loss_G: 0.0366 Convergence: 0.0911 k= 0.021166 lr = 0.0000122\n",
      "[12/25][8650/9765] Loss_D: 0.0912 Loss_G: 0.0394 Convergence: 0.0946 k= 0.021162 lr = 0.0000122\n",
      "[12/25][8660/9765] Loss_D: 0.1029 Loss_G: 0.0364 Convergence: 0.1088 k= 0.021176 lr = 0.0000122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][8670/9765] Loss_D: 0.0989 Loss_G: 0.0383 Convergence: 0.1013 k= 0.021166 lr = 0.0000122\n",
      "[12/25][8680/9765] Loss_D: 0.1064 Loss_G: 0.0432 Convergence: 0.1075 k= 0.021151 lr = 0.0000122\n",
      "[12/25][8690/9765] Loss_D: 0.0976 Loss_G: 0.0382 Convergence: 0.0996 k= 0.021145 lr = 0.0000122\n",
      "[12/25][8700/9765] Loss_D: 0.0906 Loss_G: 0.0385 Convergence: 0.0934 k= 0.021164 lr = 0.0000122\n",
      "[12/25][8710/9765] Loss_D: 0.0918 Loss_G: 0.0385 Convergence: 0.0941 k= 0.021169 lr = 0.0000122\n",
      "[12/25][8720/9765] Loss_D: 0.0950 Loss_G: 0.0430 Convergence: 0.1005 k= 0.021166 lr = 0.0000122\n",
      "[12/25][8730/9765] Loss_D: 0.1038 Loss_G: 0.0403 Convergence: 0.1062 k= 0.021169 lr = 0.0000122\n",
      "[12/25][8740/9765] Loss_D: 0.0947 Loss_G: 0.0381 Convergence: 0.0956 k= 0.021163 lr = 0.0000122\n",
      "[12/25][8750/9765] Loss_D: 0.0907 Loss_G: 0.0387 Convergence: 0.0936 k= 0.021160 lr = 0.0000122\n",
      "[12/25][8760/9765] Loss_D: 0.0988 Loss_G: 0.0381 Convergence: 0.1013 k= 0.021152 lr = 0.0000122\n",
      "[12/25][8770/9765] Loss_D: 0.0943 Loss_G: 0.0392 Convergence: 0.0962 k= 0.021155 lr = 0.0000122\n",
      "[12/25][8780/9765] Loss_D: 0.0932 Loss_G: 0.0411 Convergence: 0.0975 k= 0.021158 lr = 0.0000122\n",
      "[12/25][8790/9765] Loss_D: 0.1020 Loss_G: 0.0392 Convergence: 0.1048 k= 0.021150 lr = 0.0000122\n",
      "[12/25][8800/9765] Loss_D: 0.1026 Loss_G: 0.0385 Convergence: 0.1063 k= 0.021160 lr = 0.0000122\n",
      "[12/25][8810/9765] Loss_D: 0.0969 Loss_G: 0.0371 Convergence: 0.0997 k= 0.021175 lr = 0.0000122\n",
      "[12/25][8820/9765] Loss_D: 0.1091 Loss_G: 0.0418 Convergence: 0.1121 k= 0.021170 lr = 0.0000116\n",
      "[12/25][8830/9765] Loss_D: 0.0962 Loss_G: 0.0394 Convergence: 0.0976 k= 0.021161 lr = 0.0000116\n",
      "[12/25][8840/9765] Loss_D: 0.0925 Loss_G: 0.0372 Convergence: 0.0934 k= 0.021162 lr = 0.0000116\n",
      "[12/25][8850/9765] Loss_D: 0.0957 Loss_G: 0.0387 Convergence: 0.0966 k= 0.021161 lr = 0.0000116\n",
      "[12/25][8860/9765] Loss_D: 0.0982 Loss_G: 0.0394 Convergence: 0.0992 k= 0.021151 lr = 0.0000116\n",
      "[12/25][8870/9765] Loss_D: 0.1064 Loss_G: 0.0380 Convergence: 0.1121 k= 0.021166 lr = 0.0000116\n",
      "[12/25][8880/9765] Loss_D: 0.0964 Loss_G: 0.0385 Convergence: 0.0976 k= 0.021172 lr = 0.0000116\n",
      "[12/25][8890/9765] Loss_D: 0.1020 Loss_G: 0.0411 Convergence: 0.1030 k= 0.021162 lr = 0.0000116\n",
      "[12/25][8900/9765] Loss_D: 0.0892 Loss_G: 0.0374 Convergence: 0.0913 k= 0.021150 lr = 0.0000116\n",
      "[12/25][8910/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0999 k= 0.021152 lr = 0.0000116\n",
      "[12/25][8920/9765] Loss_D: 0.0979 Loss_G: 0.0402 Convergence: 0.0995 k= 0.021144 lr = 0.0000116\n",
      "[12/25][8930/9765] Loss_D: 0.0979 Loss_G: 0.0396 Convergence: 0.0988 k= 0.021147 lr = 0.0000116\n",
      "[12/25][8940/9765] Loss_D: 0.0953 Loss_G: 0.0395 Convergence: 0.0972 k= 0.021145 lr = 0.0000116\n",
      "[12/25][8950/9765] Loss_D: 0.0922 Loss_G: 0.0378 Convergence: 0.0936 k= 0.021146 lr = 0.0000116\n",
      "[12/25][8960/9765] Loss_D: 0.0993 Loss_G: 0.0401 Convergence: 0.1002 k= 0.021141 lr = 0.0000116\n",
      "[12/25][8970/9765] Loss_D: 0.0956 Loss_G: 0.0402 Convergence: 0.0981 k= 0.021111 lr = 0.0000116\n",
      "[12/25][8980/9765] Loss_D: 0.0945 Loss_G: 0.0369 Convergence: 0.0965 k= 0.021102 lr = 0.0000116\n",
      "[12/25][8990/9765] Loss_D: 0.0860 Loss_G: 0.0370 Convergence: 0.0891 k= 0.021118 lr = 0.0000116\n",
      "[12/25][9000/9765] Loss_D: 0.0993 Loss_G: 0.0384 Convergence: 0.1018 k= 0.021130 lr = 0.0000116\n",
      "[12/25][9010/9765] Loss_D: 0.0971 Loss_G: 0.0397 Convergence: 0.0984 k= 0.021134 lr = 0.0000116\n",
      "[12/25][9020/9765] Loss_D: 0.0993 Loss_G: 0.0414 Convergence: 0.1015 k= 0.021140 lr = 0.0000116\n",
      "[12/25][9030/9765] Loss_D: 0.1082 Loss_G: 0.0410 Convergence: 0.1116 k= 0.021150 lr = 0.0000116\n",
      "[12/25][9040/9765] Loss_D: 0.0973 Loss_G: 0.0387 Convergence: 0.0987 k= 0.021140 lr = 0.0000116\n",
      "[12/25][9050/9765] Loss_D: 0.0950 Loss_G: 0.0398 Convergence: 0.0973 k= 0.021135 lr = 0.0000116\n",
      "[12/25][9060/9765] Loss_D: 0.0949 Loss_G: 0.0402 Convergence: 0.0976 k= 0.021121 lr = 0.0000116\n",
      "[12/25][9070/9765] Loss_D: 0.0897 Loss_G: 0.0386 Convergence: 0.0929 k= 0.021121 lr = 0.0000116\n",
      "[12/25][9080/9765] Loss_D: 0.0980 Loss_G: 0.0379 Convergence: 0.1004 k= 0.021138 lr = 0.0000116\n",
      "[12/25][9090/9765] Loss_D: 0.1021 Loss_G: 0.0382 Convergence: 0.1059 k= 0.021137 lr = 0.0000116\n",
      "[12/25][9100/9765] Loss_D: 0.0954 Loss_G: 0.0390 Convergence: 0.0967 k= 0.021130 lr = 0.0000116\n",
      "[12/25][9110/9765] Loss_D: 0.0956 Loss_G: 0.0394 Convergence: 0.0972 k= 0.021126 lr = 0.0000116\n",
      "[12/25][9120/9765] Loss_D: 0.1001 Loss_G: 0.0417 Convergence: 0.1022 k= 0.021147 lr = 0.0000116\n",
      "[12/25][9130/9765] Loss_D: 0.0902 Loss_G: 0.0393 Convergence: 0.0939 k= 0.021133 lr = 0.0000116\n",
      "[12/25][9140/9765] Loss_D: 0.1042 Loss_G: 0.0397 Convergence: 0.1074 k= 0.021152 lr = 0.0000116\n",
      "[12/25][9150/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1003 k= 0.021171 lr = 0.0000116\n",
      "[12/25][9160/9765] Loss_D: 0.1011 Loss_G: 0.0390 Convergence: 0.1037 k= 0.021169 lr = 0.0000116\n",
      "[12/25][9170/9765] Loss_D: 0.0998 Loss_G: 0.0401 Convergence: 0.1008 k= 0.021157 lr = 0.0000116\n",
      "[12/25][9180/9765] Loss_D: 0.0937 Loss_G: 0.0407 Convergence: 0.0975 k= 0.021154 lr = 0.0000116\n",
      "[12/25][9190/9765] Loss_D: 0.1019 Loss_G: 0.0416 Convergence: 0.1033 k= 0.021137 lr = 0.0000116\n",
      "[12/25][9200/9765] Loss_D: 0.0918 Loss_G: 0.0390 Convergence: 0.0946 k= 0.021129 lr = 0.0000116\n",
      "[12/25][9210/9765] Loss_D: 0.1068 Loss_G: 0.0378 Convergence: 0.1129 k= 0.021147 lr = 0.0000116\n",
      "[12/25][9220/9765] Loss_D: 0.0916 Loss_G: 0.0399 Convergence: 0.0954 k= 0.021151 lr = 0.0000116\n",
      "[12/25][9230/9765] Loss_D: 0.0973 Loss_G: 0.0395 Convergence: 0.0983 k= 0.021150 lr = 0.0000116\n",
      "[12/25][9240/9765] Loss_D: 0.0954 Loss_G: 0.0457 Convergence: 0.1035 k= 0.021130 lr = 0.0000116\n",
      "[12/25][9250/9765] Loss_D: 0.0926 Loss_G: 0.0443 Convergence: 0.1004 k= 0.021079 lr = 0.0000116\n",
      "[12/25][9260/9765] Loss_D: 0.1015 Loss_G: 0.0408 Convergence: 0.1025 k= 0.021040 lr = 0.0000116\n",
      "[12/25][9270/9765] Loss_D: 0.0955 Loss_G: 0.0352 Convergence: 0.0995 k= 0.021053 lr = 0.0000116\n",
      "[12/25][9280/9765] Loss_D: 0.0960 Loss_G: 0.0348 Convergence: 0.1006 k= 0.021099 lr = 0.0000116\n",
      "[12/25][9290/9765] Loss_D: 0.1010 Loss_G: 0.0361 Convergence: 0.1064 k= 0.021137 lr = 0.0000116\n",
      "[12/25][9300/9765] Loss_D: 0.1050 Loss_G: 0.0386 Convergence: 0.1095 k= 0.021155 lr = 0.0000116\n",
      "[12/25][9310/9765] Loss_D: 0.0909 Loss_G: 0.0381 Convergence: 0.0930 k= 0.021158 lr = 0.0000116\n",
      "[12/25][9320/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0974 k= 0.021160 lr = 0.0000116\n",
      "[12/25][9330/9765] Loss_D: 0.0979 Loss_G: 0.0413 Convergence: 0.1006 k= 0.021159 lr = 0.0000116\n",
      "[12/25][9340/9765] Loss_D: 0.0980 Loss_G: 0.0415 Convergence: 0.1009 k= 0.021151 lr = 0.0000116\n",
      "[12/25][9350/9765] Loss_D: 0.0917 Loss_G: 0.0397 Convergence: 0.0952 k= 0.021142 lr = 0.0000116\n",
      "[12/25][9360/9765] Loss_D: 0.0953 Loss_G: 0.0377 Convergence: 0.0968 k= 0.021137 lr = 0.0000116\n",
      "[12/25][9370/9765] Loss_D: 0.1033 Loss_G: 0.0378 Convergence: 0.1080 k= 0.021144 lr = 0.0000116\n",
      "[12/25][9380/9765] Loss_D: 0.0997 Loss_G: 0.0384 Convergence: 0.1023 k= 0.021158 lr = 0.0000116\n",
      "[12/25][9390/9765] Loss_D: 0.0979 Loss_G: 0.0402 Convergence: 0.0994 k= 0.021148 lr = 0.0000116\n",
      "[12/25][9400/9765] Loss_D: 0.0936 Loss_G: 0.0397 Convergence: 0.0963 k= 0.021149 lr = 0.0000116\n",
      "[12/25][9410/9765] Loss_D: 0.1018 Loss_G: 0.0437 Convergence: 0.1053 k= 0.021142 lr = 0.0000116\n",
      "[12/25][9420/9765] Loss_D: 0.1001 Loss_G: 0.0398 Convergence: 0.1014 k= 0.021147 lr = 0.0000116\n",
      "[12/25][9430/9765] Loss_D: 0.0951 Loss_G: 0.0379 Convergence: 0.0963 k= 0.021142 lr = 0.0000116\n",
      "[12/25][9440/9765] Loss_D: 0.1080 Loss_G: 0.0391 Convergence: 0.1133 k= 0.021152 lr = 0.0000116\n",
      "[12/25][9450/9765] Loss_D: 0.1030 Loss_G: 0.0369 Convergence: 0.1083 k= 0.021151 lr = 0.0000116\n",
      "[12/25][9460/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0971 k= 0.021170 lr = 0.0000116\n",
      "[12/25][9470/9765] Loss_D: 0.0979 Loss_G: 0.0355 Convergence: 0.1025 k= 0.021188 lr = 0.0000116\n",
      "[12/25][9480/9765] Loss_D: 0.0958 Loss_G: 0.0418 Convergence: 0.0998 k= 0.021181 lr = 0.0000116\n",
      "[12/25][9490/9765] Loss_D: 0.0985 Loss_G: 0.0415 Convergence: 0.1012 k= 0.021168 lr = 0.0000116\n",
      "[12/25][9500/9765] Loss_D: 0.1037 Loss_G: 0.0388 Convergence: 0.1075 k= 0.021153 lr = 0.0000116\n",
      "[12/25][9510/9765] Loss_D: 0.0926 Loss_G: 0.0406 Convergence: 0.0967 k= 0.021141 lr = 0.0000116\n",
      "[12/25][9520/9765] Loss_D: 0.0938 Loss_G: 0.0376 Convergence: 0.0947 k= 0.021156 lr = 0.0000116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/25][9530/9765] Loss_D: 0.1021 Loss_G: 0.0400 Convergence: 0.1041 k= 0.021164 lr = 0.0000116\n",
      "[12/25][9540/9765] Loss_D: 0.1034 Loss_G: 0.0383 Convergence: 0.1076 k= 0.021166 lr = 0.0000116\n",
      "[12/25][9550/9765] Loss_D: 0.1069 Loss_G: 0.0412 Convergence: 0.1097 k= 0.021166 lr = 0.0000116\n",
      "[12/25][9560/9765] Loss_D: 0.0971 Loss_G: 0.0431 Convergence: 0.1019 k= 0.021135 lr = 0.0000116\n",
      "[12/25][9570/9765] Loss_D: 0.0898 Loss_G: 0.0397 Convergence: 0.0941 k= 0.021127 lr = 0.0000116\n",
      "[12/25][9580/9765] Loss_D: 0.0949 Loss_G: 0.0388 Convergence: 0.0962 k= 0.021144 lr = 0.0000116\n",
      "[12/25][9590/9765] Loss_D: 0.0971 Loss_G: 0.0421 Convergence: 0.1008 k= 0.021144 lr = 0.0000116\n",
      "[12/25][9600/9765] Loss_D: 0.0930 Loss_G: 0.0411 Convergence: 0.0974 k= 0.021129 lr = 0.0000116\n",
      "[12/25][9610/9765] Loss_D: 0.0951 Loss_G: 0.0381 Convergence: 0.0961 k= 0.021145 lr = 0.0000116\n",
      "[12/25][9620/9765] Loss_D: 0.1013 Loss_G: 0.0397 Convergence: 0.1033 k= 0.021156 lr = 0.0000116\n",
      "[12/25][9630/9765] Loss_D: 0.0895 Loss_G: 0.0377 Convergence: 0.0919 k= 0.021150 lr = 0.0000116\n",
      "[12/25][9640/9765] Loss_D: 0.0911 Loss_G: 0.0397 Convergence: 0.0948 k= 0.021142 lr = 0.0000116\n",
      "[12/25][9650/9765] Loss_D: 0.1003 Loss_G: 0.0365 Convergence: 0.1051 k= 0.021135 lr = 0.0000116\n",
      "[12/25][9660/9765] Loss_D: 0.1021 Loss_G: 0.0401 Convergence: 0.1040 k= 0.021133 lr = 0.0000116\n",
      "[12/25][9670/9765] Loss_D: 0.0932 Loss_G: 0.0408 Convergence: 0.0973 k= 0.021128 lr = 0.0000116\n",
      "[12/25][9680/9765] Loss_D: 0.0963 Loss_G: 0.0409 Convergence: 0.0992 k= 0.021115 lr = 0.0000116\n",
      "[12/25][9690/9765] Loss_D: 0.0874 Loss_G: 0.0366 Convergence: 0.0894 k= 0.021110 lr = 0.0000116\n",
      "[12/25][9700/9765] Loss_D: 0.1010 Loss_G: 0.0421 Convergence: 0.1033 k= 0.021118 lr = 0.0000116\n",
      "[12/25][9710/9765] Loss_D: 0.0981 Loss_G: 0.0432 Convergence: 0.1026 k= 0.021101 lr = 0.0000116\n",
      "[12/25][9720/9765] Loss_D: 0.0996 Loss_G: 0.0430 Convergence: 0.1032 k= 0.021080 lr = 0.0000116\n",
      "[12/25][9730/9765] Loss_D: 0.0988 Loss_G: 0.0417 Convergence: 0.1015 k= 0.021074 lr = 0.0000116\n",
      "[12/25][9740/9765] Loss_D: 0.0985 Loss_G: 0.0402 Convergence: 0.0998 k= 0.021054 lr = 0.0000116\n",
      "[12/25][9750/9765] Loss_D: 0.0978 Loss_G: 0.0389 Convergence: 0.0992 k= 0.021059 lr = 0.0000116\n",
      "[12/25][9760/9765] Loss_D: 0.1039 Loss_G: 0.0407 Convergence: 0.1059 k= 0.021060 lr = 0.0000116\n",
      "[13/25][0/9765] Loss_D: 0.0918 Loss_G: 0.0385 Convergence: 0.0940 k= 0.021071 lr = 0.0000116\n",
      "[13/25][10/9765] Loss_D: 0.0968 Loss_G: 0.0401 Convergence: 0.0987 k= 0.021075 lr = 0.0000116\n",
      "[13/25][20/9765] Loss_D: 0.0939 Loss_G: 0.0404 Convergence: 0.0972 k= 0.021069 lr = 0.0000116\n",
      "[13/25][30/9765] Loss_D: 0.0906 Loss_G: 0.0405 Convergence: 0.0954 k= 0.021054 lr = 0.0000116\n",
      "[13/25][40/9765] Loss_D: 0.0951 Loss_G: 0.0436 Convergence: 0.1012 k= 0.021016 lr = 0.0000116\n",
      "[13/25][50/9765] Loss_D: 0.0922 Loss_G: 0.0394 Convergence: 0.0951 k= 0.021015 lr = 0.0000116\n",
      "[13/25][60/9765] Loss_D: 0.1046 Loss_G: 0.0405 Convergence: 0.1072 k= 0.021016 lr = 0.0000116\n",
      "[13/25][70/9765] Loss_D: 0.0986 Loss_G: 0.0404 Convergence: 0.1000 k= 0.021008 lr = 0.0000116\n",
      "[13/25][80/9765] Loss_D: 0.1033 Loss_G: 0.0379 Convergence: 0.1078 k= 0.021024 lr = 0.0000116\n",
      "[13/25][90/9765] Loss_D: 0.0927 Loss_G: 0.0369 Convergence: 0.0940 k= 0.021033 lr = 0.0000116\n",
      "[13/25][100/9765] Loss_D: 0.1025 Loss_G: 0.0393 Convergence: 0.1052 k= 0.021050 lr = 0.0000116\n",
      "[13/25][110/9765] Loss_D: 0.0953 Loss_G: 0.0417 Convergence: 0.0994 k= 0.021053 lr = 0.0000116\n",
      "[13/25][120/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0965 k= 0.021046 lr = 0.0000116\n",
      "[13/25][130/9765] Loss_D: 0.0954 Loss_G: 0.0381 Convergence: 0.0967 k= 0.021052 lr = 0.0000116\n",
      "[13/25][140/9765] Loss_D: 0.1022 Loss_G: 0.0405 Convergence: 0.1038 k= 0.021057 lr = 0.0000116\n",
      "[13/25][150/9765] Loss_D: 0.0950 Loss_G: 0.0419 Convergence: 0.0993 k= 0.021060 lr = 0.0000116\n",
      "[13/25][160/9765] Loss_D: 0.0992 Loss_G: 0.0383 Convergence: 0.1017 k= 0.021077 lr = 0.0000116\n",
      "[13/25][170/9765] Loss_D: 0.1018 Loss_G: 0.0388 Convergence: 0.1048 k= 0.021088 lr = 0.0000116\n",
      "[13/25][180/9765] Loss_D: 0.0957 Loss_G: 0.0405 Convergence: 0.0984 k= 0.021083 lr = 0.0000116\n",
      "[13/25][190/9765] Loss_D: 0.1052 Loss_G: 0.0395 Convergence: 0.1090 k= 0.021071 lr = 0.0000116\n",
      "[13/25][200/9765] Loss_D: 0.1011 Loss_G: 0.0385 Convergence: 0.1040 k= 0.021070 lr = 0.0000116\n",
      "[13/25][210/9765] Loss_D: 0.0915 Loss_G: 0.0362 Convergence: 0.0930 k= 0.021078 lr = 0.0000116\n",
      "[13/25][220/9765] Loss_D: 0.0998 Loss_G: 0.0356 Convergence: 0.1052 k= 0.021118 lr = 0.0000116\n",
      "[13/25][230/9765] Loss_D: 0.0896 Loss_G: 0.0362 Convergence: 0.0905 k= 0.021146 lr = 0.0000116\n",
      "[13/25][240/9765] Loss_D: 0.1042 Loss_G: 0.0377 Convergence: 0.1093 k= 0.021165 lr = 0.0000116\n",
      "[13/25][250/9765] Loss_D: 0.0981 Loss_G: 0.0407 Convergence: 0.1001 k= 0.021161 lr = 0.0000116\n",
      "[13/25][260/9765] Loss_D: 0.0956 Loss_G: 0.0397 Convergence: 0.0976 k= 0.021151 lr = 0.0000116\n",
      "[13/25][270/9765] Loss_D: 0.1030 Loss_G: 0.0400 Convergence: 0.1055 k= 0.021164 lr = 0.0000116\n",
      "[13/25][280/9765] Loss_D: 0.0999 Loss_G: 0.0401 Convergence: 0.1010 k= 0.021156 lr = 0.0000116\n",
      "[13/25][290/9765] Loss_D: 0.0918 Loss_G: 0.0429 Convergence: 0.0985 k= 0.021122 lr = 0.0000116\n",
      "[13/25][300/9765] Loss_D: 0.1075 Loss_G: 0.0415 Convergence: 0.1102 k= 0.021100 lr = 0.0000116\n",
      "[13/25][310/9765] Loss_D: 0.1010 Loss_G: 0.0426 Convergence: 0.1037 k= 0.021084 lr = 0.0000116\n",
      "[13/25][320/9765] Loss_D: 0.0962 Loss_G: 0.0398 Convergence: 0.0980 k= 0.021074 lr = 0.0000116\n",
      "[13/25][330/9765] Loss_D: 0.0954 Loss_G: 0.0365 Convergence: 0.0982 k= 0.021064 lr = 0.0000116\n",
      "[13/25][340/9765] Loss_D: 0.0988 Loss_G: 0.0393 Convergence: 0.1002 k= 0.021063 lr = 0.0000116\n",
      "[13/25][350/9765] Loss_D: 0.0949 Loss_G: 0.0394 Convergence: 0.0968 k= 0.021061 lr = 0.0000116\n",
      "[13/25][360/9765] Loss_D: 0.0946 Loss_G: 0.0415 Convergence: 0.0988 k= 0.021033 lr = 0.0000116\n",
      "[13/25][370/9765] Loss_D: 0.0964 Loss_G: 0.0380 Convergence: 0.0980 k= 0.021026 lr = 0.0000116\n",
      "[13/25][380/9765] Loss_D: 0.0948 Loss_G: 0.0384 Convergence: 0.0958 k= 0.021029 lr = 0.0000116\n",
      "[13/25][390/9765] Loss_D: 0.0939 Loss_G: 0.0398 Convergence: 0.0966 k= 0.021029 lr = 0.0000116\n",
      "[13/25][400/9765] Loss_D: 0.1079 Loss_G: 0.0386 Convergence: 0.1135 k= 0.021046 lr = 0.0000116\n",
      "[13/25][410/9765] Loss_D: 0.0936 Loss_G: 0.0392 Convergence: 0.0959 k= 0.021034 lr = 0.0000116\n",
      "[13/25][420/9765] Loss_D: 0.1039 Loss_G: 0.0429 Convergence: 0.1058 k= 0.021025 lr = 0.0000116\n",
      "[13/25][430/9765] Loss_D: 0.1016 Loss_G: 0.0409 Convergence: 0.1026 k= 0.021005 lr = 0.0000116\n",
      "[13/25][440/9765] Loss_D: 0.0993 Loss_G: 0.0411 Convergence: 0.1012 k= 0.020983 lr = 0.0000116\n",
      "[13/25][450/9765] Loss_D: 0.0931 Loss_G: 0.0401 Convergence: 0.0965 k= 0.020969 lr = 0.0000116\n",
      "[13/25][460/9765] Loss_D: 0.0927 Loss_G: 0.0421 Convergence: 0.0983 k= 0.020949 lr = 0.0000116\n",
      "[13/25][470/9765] Loss_D: 0.0991 Loss_G: 0.0419 Convergence: 0.1018 k= 0.020939 lr = 0.0000116\n",
      "[13/25][480/9765] Loss_D: 0.1049 Loss_G: 0.0416 Convergence: 0.1064 k= 0.020928 lr = 0.0000116\n",
      "[13/25][490/9765] Loss_D: 0.0987 Loss_G: 0.0366 Convergence: 0.1026 k= 0.020942 lr = 0.0000116\n",
      "[13/25][500/9765] Loss_D: 0.0996 Loss_G: 0.0370 Convergence: 0.1036 k= 0.020969 lr = 0.0000116\n",
      "[13/25][510/9765] Loss_D: 0.1012 Loss_G: 0.0389 Convergence: 0.1039 k= 0.020987 lr = 0.0000116\n",
      "[13/25][520/9765] Loss_D: 0.0963 Loss_G: 0.0422 Convergence: 0.1006 k= 0.020968 lr = 0.0000116\n",
      "[13/25][530/9765] Loss_D: 0.0947 Loss_G: 0.0412 Convergence: 0.0985 k= 0.020931 lr = 0.0000116\n",
      "[13/25][540/9765] Loss_D: 0.0976 Loss_G: 0.0407 Convergence: 0.0998 k= 0.020924 lr = 0.0000116\n",
      "[13/25][550/9765] Loss_D: 0.0924 Loss_G: 0.0416 Convergence: 0.0975 k= 0.020896 lr = 0.0000116\n",
      "[13/25][560/9765] Loss_D: 0.0896 Loss_G: 0.0383 Convergence: 0.0926 k= 0.020900 lr = 0.0000116\n",
      "[13/25][570/9765] Loss_D: 0.1050 Loss_G: 0.0380 Convergence: 0.1101 k= 0.020906 lr = 0.0000116\n",
      "[13/25][580/9765] Loss_D: 0.0979 Loss_G: 0.0371 Convergence: 0.1010 k= 0.020913 lr = 0.0000116\n",
      "[13/25][590/9765] Loss_D: 0.1006 Loss_G: 0.0439 Convergence: 0.1047 k= 0.020894 lr = 0.0000116\n",
      "[13/25][600/9765] Loss_D: 0.0950 Loss_G: 0.0421 Convergence: 0.0996 k= 0.020845 lr = 0.0000116\n",
      "[13/25][610/9765] Loss_D: 0.0978 Loss_G: 0.0411 Convergence: 0.1003 k= 0.020824 lr = 0.0000116\n",
      "[13/25][620/9765] Loss_D: 0.1020 Loss_G: 0.0391 Convergence: 0.1048 k= 0.020823 lr = 0.0000116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][630/9765] Loss_D: 0.0974 Loss_G: 0.0352 Convergence: 0.1022 k= 0.020841 lr = 0.0000116\n",
      "[13/25][640/9765] Loss_D: 0.0943 Loss_G: 0.0348 Convergence: 0.0982 k= 0.020866 lr = 0.0000116\n",
      "[13/25][650/9765] Loss_D: 0.0901 Loss_G: 0.0366 Convergence: 0.0911 k= 0.020900 lr = 0.0000116\n",
      "[13/25][660/9765] Loss_D: 0.0917 Loss_G: 0.0379 Convergence: 0.0934 k= 0.020920 lr = 0.0000116\n",
      "[13/25][670/9765] Loss_D: 0.1038 Loss_G: 0.0423 Convergence: 0.1052 k= 0.020926 lr = 0.0000116\n",
      "[13/25][680/9765] Loss_D: 0.0912 Loss_G: 0.0408 Convergence: 0.0960 k= 0.020907 lr = 0.0000116\n",
      "[13/25][690/9765] Loss_D: 0.0953 Loss_G: 0.0383 Convergence: 0.0963 k= 0.020914 lr = 0.0000116\n",
      "[13/25][700/9765] Loss_D: 0.1011 Loss_G: 0.0386 Convergence: 0.1040 k= 0.020929 lr = 0.0000116\n",
      "[13/25][710/9765] Loss_D: 0.0957 Loss_G: 0.0387 Convergence: 0.0966 k= 0.020937 lr = 0.0000116\n",
      "[13/25][720/9765] Loss_D: 0.1002 Loss_G: 0.0439 Convergence: 0.1045 k= 0.020932 lr = 0.0000116\n",
      "[13/25][730/9765] Loss_D: 0.1071 Loss_G: 0.0417 Convergence: 0.1094 k= 0.020921 lr = 0.0000116\n",
      "[13/25][740/9765] Loss_D: 0.0938 Loss_G: 0.0417 Convergence: 0.0985 k= 0.020918 lr = 0.0000116\n",
      "[13/25][750/9765] Loss_D: 0.0928 Loss_G: 0.0396 Convergence: 0.0957 k= 0.020941 lr = 0.0000116\n",
      "[13/25][760/9765] Loss_D: 0.1009 Loss_G: 0.0409 Convergence: 0.1020 k= 0.020938 lr = 0.0000116\n",
      "[13/25][770/9765] Loss_D: 0.1134 Loss_G: 0.0392 Convergence: 0.1207 k= 0.020934 lr = 0.0000116\n",
      "[13/25][780/9765] Loss_D: 0.0925 Loss_G: 0.0415 Convergence: 0.0976 k= 0.020933 lr = 0.0000116\n",
      "[13/25][790/9765] Loss_D: 0.0978 Loss_G: 0.0392 Convergence: 0.0988 k= 0.020931 lr = 0.0000116\n",
      "[13/25][800/9765] Loss_D: 0.0983 Loss_G: 0.0394 Convergence: 0.0994 k= 0.020920 lr = 0.0000116\n",
      "[13/25][810/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0975 k= 0.020922 lr = 0.0000116\n",
      "[13/25][820/9765] Loss_D: 0.0927 Loss_G: 0.0364 Convergence: 0.0945 k= 0.020929 lr = 0.0000116\n",
      "[13/25][830/9765] Loss_D: 0.1125 Loss_G: 0.0380 Convergence: 0.1205 k= 0.020957 lr = 0.0000116\n",
      "[13/25][840/9765] Loss_D: 0.0869 Loss_G: 0.0403 Convergence: 0.0929 k= 0.020970 lr = 0.0000116\n",
      "[13/25][850/9765] Loss_D: 0.0971 Loss_G: 0.0395 Convergence: 0.0983 k= 0.020970 lr = 0.0000116\n",
      "[13/25][860/9765] Loss_D: 0.0938 Loss_G: 0.0391 Convergence: 0.0959 k= 0.020971 lr = 0.0000116\n",
      "[13/25][870/9765] Loss_D: 0.1025 Loss_G: 0.0378 Convergence: 0.1068 k= 0.020986 lr = 0.0000116\n",
      "[13/25][880/9765] Loss_D: 0.0895 Loss_G: 0.0420 Convergence: 0.0963 k= 0.020976 lr = 0.0000116\n",
      "[13/25][890/9765] Loss_D: 0.1011 Loss_G: 0.0379 Convergence: 0.1048 k= 0.020974 lr = 0.0000116\n",
      "[13/25][900/9765] Loss_D: 0.0948 Loss_G: 0.0425 Convergence: 0.0999 k= 0.020970 lr = 0.0000116\n",
      "[13/25][910/9765] Loss_D: 0.0967 Loss_G: 0.0411 Convergence: 0.0997 k= 0.020951 lr = 0.0000116\n",
      "[13/25][920/9765] Loss_D: 0.0956 Loss_G: 0.0369 Convergence: 0.0981 k= 0.020947 lr = 0.0000116\n",
      "[13/25][930/9765] Loss_D: 0.1015 Loss_G: 0.0385 Convergence: 0.1048 k= 0.020957 lr = 0.0000116\n",
      "[13/25][940/9765] Loss_D: 0.0992 Loss_G: 0.0387 Convergence: 0.1013 k= 0.020950 lr = 0.0000116\n",
      "[13/25][950/9765] Loss_D: 0.1024 Loss_G: 0.0424 Convergence: 0.1043 k= 0.020934 lr = 0.0000116\n",
      "[13/25][960/9765] Loss_D: 0.0961 Loss_G: 0.0386 Convergence: 0.0971 k= 0.020934 lr = 0.0000116\n",
      "[13/25][970/9765] Loss_D: 0.0894 Loss_G: 0.0413 Convergence: 0.0955 k= 0.020921 lr = 0.0000116\n",
      "[13/25][980/9765] Loss_D: 0.1029 Loss_G: 0.0381 Convergence: 0.1071 k= 0.020917 lr = 0.0000116\n",
      "[13/25][990/9765] Loss_D: 0.0938 Loss_G: 0.0384 Convergence: 0.0951 k= 0.020930 lr = 0.0000116\n",
      "[13/25][1000/9765] Loss_D: 0.0939 Loss_G: 0.0388 Convergence: 0.0956 k= 0.020936 lr = 0.0000116\n",
      "[13/25][1010/9765] Loss_D: 0.1029 Loss_G: 0.0403 Convergence: 0.1049 k= 0.020942 lr = 0.0000116\n",
      "[13/25][1020/9765] Loss_D: 0.0942 Loss_G: 0.0383 Convergence: 0.0952 k= 0.020932 lr = 0.0000116\n",
      "[13/25][1030/9765] Loss_D: 0.0917 Loss_G: 0.0388 Convergence: 0.0943 k= 0.020920 lr = 0.0000116\n",
      "[13/25][1040/9765] Loss_D: 0.0920 Loss_G: 0.0376 Convergence: 0.0934 k= 0.020936 lr = 0.0000116\n",
      "[13/25][1050/9765] Loss_D: 0.0920 Loss_G: 0.0387 Convergence: 0.0944 k= 0.020956 lr = 0.0000116\n",
      "[13/25][1060/9765] Loss_D: 0.1052 Loss_G: 0.0402 Convergence: 0.1082 k= 0.020968 lr = 0.0000116\n",
      "[13/25][1070/9765] Loss_D: 0.0975 Loss_G: 0.0406 Convergence: 0.0996 k= 0.020949 lr = 0.0000116\n",
      "[13/25][1080/9765] Loss_D: 0.1023 Loss_G: 0.0390 Convergence: 0.1054 k= 0.020950 lr = 0.0000116\n",
      "[13/25][1090/9765] Loss_D: 0.0954 Loss_G: 0.0384 Convergence: 0.0963 k= 0.020965 lr = 0.0000116\n",
      "[13/25][1100/9765] Loss_D: 0.1062 Loss_G: 0.0372 Convergence: 0.1126 k= 0.020979 lr = 0.0000116\n",
      "[13/25][1110/9765] Loss_D: 0.0945 Loss_G: 0.0391 Convergence: 0.0963 k= 0.020985 lr = 0.0000116\n",
      "[13/25][1120/9765] Loss_D: 0.0966 Loss_G: 0.0387 Convergence: 0.0977 k= 0.020997 lr = 0.0000116\n",
      "[13/25][1130/9765] Loss_D: 0.0999 Loss_G: 0.0394 Convergence: 0.1015 k= 0.021001 lr = 0.0000116\n",
      "[13/25][1140/9765] Loss_D: 0.1011 Loss_G: 0.0421 Convergence: 0.1033 k= 0.020999 lr = 0.0000116\n",
      "[13/25][1150/9765] Loss_D: 0.0915 Loss_G: 0.0405 Convergence: 0.0959 k= 0.020980 lr = 0.0000116\n",
      "[13/25][1160/9765] Loss_D: 0.1040 Loss_G: 0.0399 Convergence: 0.1068 k= 0.020955 lr = 0.0000116\n",
      "[13/25][1170/9765] Loss_D: 0.0874 Loss_G: 0.0373 Convergence: 0.0902 k= 0.020950 lr = 0.0000116\n",
      "[13/25][1180/9765] Loss_D: 0.0970 Loss_G: 0.0387 Convergence: 0.0983 k= 0.020967 lr = 0.0000116\n",
      "[13/25][1190/9765] Loss_D: 0.0864 Loss_G: 0.0373 Convergence: 0.0895 k= 0.020989 lr = 0.0000116\n",
      "[13/25][1200/9765] Loss_D: 0.0884 Loss_G: 0.0358 Convergence: 0.0893 k= 0.021009 lr = 0.0000116\n",
      "[13/25][1210/9765] Loss_D: 0.0920 Loss_G: 0.0408 Convergence: 0.0965 k= 0.021011 lr = 0.0000116\n",
      "[13/25][1220/9765] Loss_D: 0.0972 Loss_G: 0.0403 Convergence: 0.0991 k= 0.020993 lr = 0.0000116\n",
      "[13/25][1230/9765] Loss_D: 0.1055 Loss_G: 0.0370 Convergence: 0.1118 k= 0.020987 lr = 0.0000116\n",
      "[13/25][1240/9765] Loss_D: 0.0956 Loss_G: 0.0407 Convergence: 0.0985 k= 0.021000 lr = 0.0000116\n",
      "[13/25][1250/9765] Loss_D: 0.1050 Loss_G: 0.0369 Convergence: 0.1111 k= 0.021014 lr = 0.0000116\n",
      "[13/25][1260/9765] Loss_D: 0.0928 Loss_G: 0.0374 Convergence: 0.0937 k= 0.021011 lr = 0.0000116\n",
      "[13/25][1270/9765] Loss_D: 0.0929 Loss_G: 0.0380 Convergence: 0.0942 k= 0.021006 lr = 0.0000116\n",
      "[13/25][1280/9765] Loss_D: 0.0884 Loss_G: 0.0377 Convergence: 0.0912 k= 0.021005 lr = 0.0000116\n",
      "[13/25][1290/9765] Loss_D: 0.0956 Loss_G: 0.0391 Convergence: 0.0970 k= 0.021009 lr = 0.0000116\n",
      "[13/25][1300/9765] Loss_D: 0.1015 Loss_G: 0.0414 Convergence: 0.1029 k= 0.021004 lr = 0.0000116\n",
      "[13/25][1310/9765] Loss_D: 0.0943 Loss_G: 0.0405 Convergence: 0.0977 k= 0.020983 lr = 0.0000116\n",
      "[13/25][1320/9765] Loss_D: 0.1013 Loss_G: 0.0397 Convergence: 0.1033 k= 0.020972 lr = 0.0000116\n",
      "[13/25][1330/9765] Loss_D: 0.0937 Loss_G: 0.0398 Convergence: 0.0965 k= 0.020977 lr = 0.0000116\n",
      "[13/25][1340/9765] Loss_D: 0.0886 Loss_G: 0.0365 Convergence: 0.0901 k= 0.020993 lr = 0.0000116\n",
      "[13/25][1350/9765] Loss_D: 0.0989 Loss_G: 0.0401 Convergence: 0.0999 k= 0.020995 lr = 0.0000116\n",
      "[13/25][1360/9765] Loss_D: 0.0946 Loss_G: 0.0443 Convergence: 0.1017 k= 0.020970 lr = 0.0000116\n",
      "[13/25][1370/9765] Loss_D: 0.0891 Loss_G: 0.0390 Convergence: 0.0929 k= 0.020966 lr = 0.0000116\n",
      "[13/25][1380/9765] Loss_D: 0.0948 Loss_G: 0.0397 Convergence: 0.0970 k= 0.020961 lr = 0.0000116\n",
      "[13/25][1390/9765] Loss_D: 0.0932 Loss_G: 0.0409 Convergence: 0.0974 k= 0.020947 lr = 0.0000116\n",
      "[13/25][1400/9765] Loss_D: 0.0946 Loss_G: 0.0390 Convergence: 0.0962 k= 0.020943 lr = 0.0000116\n",
      "[13/25][1410/9765] Loss_D: 0.1020 Loss_G: 0.0378 Convergence: 0.1062 k= 0.020941 lr = 0.0000116\n",
      "[13/25][1420/9765] Loss_D: 0.0984 Loss_G: 0.0386 Convergence: 0.1003 k= 0.020947 lr = 0.0000116\n",
      "[13/25][1430/9765] Loss_D: 0.0964 Loss_G: 0.0375 Convergence: 0.0986 k= 0.020950 lr = 0.0000116\n",
      "[13/25][1440/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.020963 lr = 0.0000116\n",
      "[13/25][1450/9765] Loss_D: 0.1021 Loss_G: 0.0402 Convergence: 0.1038 k= 0.020971 lr = 0.0000116\n",
      "[13/25][1460/9765] Loss_D: 0.0969 Loss_G: 0.0401 Convergence: 0.0988 k= 0.020954 lr = 0.0000116\n",
      "[13/25][1470/9765] Loss_D: 0.1097 Loss_G: 0.0407 Convergence: 0.1140 k= 0.020945 lr = 0.0000116\n",
      "[13/25][1480/9765] Loss_D: 0.1041 Loss_G: 0.0382 Convergence: 0.1087 k= 0.020948 lr = 0.0000116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][1490/9765] Loss_D: 0.0960 Loss_G: 0.0373 Convergence: 0.0983 k= 0.020956 lr = 0.0000116\n",
      "[13/25][1500/9765] Loss_D: 0.1024 Loss_G: 0.0397 Convergence: 0.1048 k= 0.020968 lr = 0.0000116\n",
      "[13/25][1510/9765] Loss_D: 0.0997 Loss_G: 0.0392 Convergence: 0.1016 k= 0.020971 lr = 0.0000116\n",
      "[13/25][1520/9765] Loss_D: 0.0813 Loss_G: 0.0411 Convergence: 0.0905 k= 0.020962 lr = 0.0000116\n",
      "[13/25][1530/9765] Loss_D: 0.0915 Loss_G: 0.0413 Convergence: 0.0967 k= 0.020945 lr = 0.0000116\n",
      "[13/25][1540/9765] Loss_D: 0.0958 Loss_G: 0.0413 Convergence: 0.0993 k= 0.020934 lr = 0.0000116\n",
      "[13/25][1550/9765] Loss_D: 0.0977 Loss_G: 0.0424 Convergence: 0.1015 k= 0.020924 lr = 0.0000116\n",
      "[13/25][1560/9765] Loss_D: 0.0922 Loss_G: 0.0402 Convergence: 0.0960 k= 0.020921 lr = 0.0000116\n",
      "[13/25][1570/9765] Loss_D: 0.0935 Loss_G: 0.0415 Convergence: 0.0981 k= 0.020913 lr = 0.0000116\n",
      "[13/25][1580/9765] Loss_D: 0.0974 Loss_G: 0.0416 Convergence: 0.1006 k= 0.020887 lr = 0.0000116\n",
      "[13/25][1590/9765] Loss_D: 0.1032 Loss_G: 0.0395 Convergence: 0.1061 k= 0.020871 lr = 0.0000116\n",
      "[13/25][1600/9765] Loss_D: 0.0987 Loss_G: 0.0394 Convergence: 0.0999 k= 0.020867 lr = 0.0000116\n",
      "[13/25][1610/9765] Loss_D: 0.0901 Loss_G: 0.0422 Convergence: 0.0968 k= 0.020851 lr = 0.0000116\n",
      "[13/25][1620/9765] Loss_D: 0.0961 Loss_G: 0.0389 Convergence: 0.0971 k= 0.020832 lr = 0.0000116\n",
      "[13/25][1630/9765] Loss_D: 0.0957 Loss_G: 0.0390 Convergence: 0.0969 k= 0.020842 lr = 0.0000116\n",
      "[13/25][1640/9765] Loss_D: 0.0925 Loss_G: 0.0410 Convergence: 0.0969 k= 0.020824 lr = 0.0000116\n",
      "[13/25][1650/9765] Loss_D: 0.0964 Loss_G: 0.0385 Convergence: 0.0976 k= 0.020816 lr = 0.0000116\n",
      "[13/25][1660/9765] Loss_D: 0.0983 Loss_G: 0.0390 Convergence: 0.0997 k= 0.020835 lr = 0.0000116\n",
      "[13/25][1670/9765] Loss_D: 0.0981 Loss_G: 0.0416 Convergence: 0.1010 k= 0.020839 lr = 0.0000116\n",
      "[13/25][1680/9765] Loss_D: 0.1038 Loss_G: 0.0398 Convergence: 0.1067 k= 0.020837 lr = 0.0000116\n",
      "[13/25][1690/9765] Loss_D: 0.0959 Loss_G: 0.0421 Convergence: 0.1002 k= 0.020825 lr = 0.0000116\n",
      "[13/25][1700/9765] Loss_D: 0.0969 Loss_G: 0.0423 Convergence: 0.1009 k= 0.020807 lr = 0.0000116\n",
      "[13/25][1710/9765] Loss_D: 0.1011 Loss_G: 0.0400 Convergence: 0.1027 k= 0.020796 lr = 0.0000116\n",
      "[13/25][1720/9765] Loss_D: 0.1035 Loss_G: 0.0385 Convergence: 0.1075 k= 0.020807 lr = 0.0000116\n",
      "[13/25][1730/9765] Loss_D: 0.0898 Loss_G: 0.0366 Convergence: 0.0910 k= 0.020817 lr = 0.0000116\n",
      "[13/25][1740/9765] Loss_D: 0.0978 Loss_G: 0.0374 Convergence: 0.1006 k= 0.020831 lr = 0.0000116\n",
      "[13/25][1750/9765] Loss_D: 0.0936 Loss_G: 0.0419 Convergence: 0.0986 k= 0.020814 lr = 0.0000116\n",
      "[13/25][1760/9765] Loss_D: 0.1031 Loss_G: 0.0416 Convergence: 0.1040 k= 0.020801 lr = 0.0000116\n",
      "[13/25][1770/9765] Loss_D: 0.0946 Loss_G: 0.0404 Convergence: 0.0977 k= 0.020764 lr = 0.0000116\n",
      "[13/25][1780/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0954 k= 0.020770 lr = 0.0000116\n",
      "[13/25][1790/9765] Loss_D: 0.0958 Loss_G: 0.0392 Convergence: 0.0971 k= 0.020769 lr = 0.0000116\n",
      "[13/25][1800/9765] Loss_D: 0.1072 Loss_G: 0.0401 Convergence: 0.1111 k= 0.020790 lr = 0.0000116\n",
      "[13/25][1810/9765] Loss_D: 0.0988 Loss_G: 0.0392 Convergence: 0.1003 k= 0.020772 lr = 0.0000116\n",
      "[13/25][1820/9765] Loss_D: 0.0873 Loss_G: 0.0388 Convergence: 0.0917 k= 0.020753 lr = 0.0000116\n",
      "[13/25][1830/9765] Loss_D: 0.0958 Loss_G: 0.0399 Convergence: 0.0978 k= 0.020755 lr = 0.0000116\n",
      "[13/25][1840/9765] Loss_D: 0.0923 Loss_G: 0.0395 Convergence: 0.0953 k= 0.020757 lr = 0.0000116\n",
      "[13/25][1850/9765] Loss_D: 0.1029 Loss_G: 0.0361 Convergence: 0.1091 k= 0.020764 lr = 0.0000116\n",
      "[13/25][1860/9765] Loss_D: 0.0987 Loss_G: 0.0346 Convergence: 0.1045 k= 0.020802 lr = 0.0000116\n",
      "[13/25][1870/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0971 k= 0.020822 lr = 0.0000116\n",
      "[13/25][1880/9765] Loss_D: 0.0949 Loss_G: 0.0395 Convergence: 0.0969 k= 0.020812 lr = 0.0000116\n",
      "[13/25][1890/9765] Loss_D: 0.0935 Loss_G: 0.0432 Convergence: 0.0998 k= 0.020793 lr = 0.0000116\n",
      "[13/25][1900/9765] Loss_D: 0.0949 Loss_G: 0.0433 Convergence: 0.1008 k= 0.020742 lr = 0.0000116\n",
      "[13/25][1910/9765] Loss_D: 0.1002 Loss_G: 0.0396 Convergence: 0.1017 k= 0.020711 lr = 0.0000116\n",
      "[13/25][1920/9765] Loss_D: 0.0920 Loss_G: 0.0366 Convergence: 0.0933 k= 0.020701 lr = 0.0000116\n",
      "[13/25][1930/9765] Loss_D: 0.0956 Loss_G: 0.0364 Convergence: 0.0985 k= 0.020738 lr = 0.0000116\n",
      "[13/25][1940/9765] Loss_D: 0.0976 Loss_G: 0.0380 Convergence: 0.0998 k= 0.020760 lr = 0.0000116\n",
      "[13/25][1950/9765] Loss_D: 0.1011 Loss_G: 0.0419 Convergence: 0.1031 k= 0.020749 lr = 0.0000116\n",
      "[13/25][1960/9765] Loss_D: 0.0922 Loss_G: 0.0413 Convergence: 0.0971 k= 0.020735 lr = 0.0000116\n",
      "[13/25][1970/9765] Loss_D: 0.0974 Loss_G: 0.0361 Convergence: 0.1013 k= 0.020734 lr = 0.0000116\n",
      "[13/25][1980/9765] Loss_D: 0.0919 Loss_G: 0.0392 Convergence: 0.0948 k= 0.020750 lr = 0.0000116\n",
      "[13/25][1990/9765] Loss_D: 0.0948 Loss_G: 0.0416 Convergence: 0.0990 k= 0.020758 lr = 0.0000116\n",
      "[13/25][2000/9765] Loss_D: 0.0956 Loss_G: 0.0405 Convergence: 0.0983 k= 0.020750 lr = 0.0000116\n",
      "[13/25][2010/9765] Loss_D: 0.0945 Loss_G: 0.0359 Convergence: 0.0975 k= 0.020758 lr = 0.0000116\n",
      "[13/25][2020/9765] Loss_D: 0.1003 Loss_G: 0.0402 Convergence: 0.1015 k= 0.020766 lr = 0.0000116\n",
      "[13/25][2030/9765] Loss_D: 0.0845 Loss_G: 0.0391 Convergence: 0.0902 k= 0.020749 lr = 0.0000116\n",
      "[13/25][2040/9765] Loss_D: 0.0973 Loss_G: 0.0392 Convergence: 0.0982 k= 0.020744 lr = 0.0000116\n",
      "[13/25][2050/9765] Loss_D: 0.0947 Loss_G: 0.0418 Convergence: 0.0991 k= 0.020729 lr = 0.0000116\n",
      "[13/25][2060/9765] Loss_D: 0.1024 Loss_G: 0.0394 Convergence: 0.1051 k= 0.020742 lr = 0.0000110\n",
      "[13/25][2070/9765] Loss_D: 0.0952 Loss_G: 0.0387 Convergence: 0.0963 k= 0.020737 lr = 0.0000110\n",
      "[13/25][2080/9765] Loss_D: 0.0986 Loss_G: 0.0395 Convergence: 0.0997 k= 0.020743 lr = 0.0000110\n",
      "[13/25][2090/9765] Loss_D: 0.1096 Loss_G: 0.0403 Convergence: 0.1142 k= 0.020750 lr = 0.0000110\n",
      "[13/25][2100/9765] Loss_D: 0.0960 Loss_G: 0.0389 Convergence: 0.0970 k= 0.020731 lr = 0.0000110\n",
      "[13/25][2110/9765] Loss_D: 0.0888 Loss_G: 0.0415 Convergence: 0.0953 k= 0.020718 lr = 0.0000110\n",
      "[13/25][2120/9765] Loss_D: 0.1046 Loss_G: 0.0396 Convergence: 0.1080 k= 0.020713 lr = 0.0000110\n",
      "[13/25][2130/9765] Loss_D: 0.0975 Loss_G: 0.0380 Convergence: 0.0996 k= 0.020711 lr = 0.0000110\n",
      "[13/25][2140/9765] Loss_D: 0.0953 Loss_G: 0.0398 Convergence: 0.0975 k= 0.020725 lr = 0.0000110\n",
      "[13/25][2150/9765] Loss_D: 0.0947 Loss_G: 0.0398 Convergence: 0.0971 k= 0.020722 lr = 0.0000110\n",
      "[13/25][2160/9765] Loss_D: 0.0959 Loss_G: 0.0388 Convergence: 0.0968 k= 0.020732 lr = 0.0000110\n",
      "[13/25][2170/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0973 k= 0.020737 lr = 0.0000110\n",
      "[13/25][2180/9765] Loss_D: 0.0994 Loss_G: 0.0397 Convergence: 0.1006 k= 0.020738 lr = 0.0000110\n",
      "[13/25][2190/9765] Loss_D: 0.0846 Loss_G: 0.0427 Convergence: 0.0940 k= 0.020714 lr = 0.0000110\n",
      "[13/25][2200/9765] Loss_D: 0.1071 Loss_G: 0.0410 Convergence: 0.1100 k= 0.020702 lr = 0.0000110\n",
      "[13/25][2210/9765] Loss_D: 0.0979 Loss_G: 0.0415 Convergence: 0.1007 k= 0.020690 lr = 0.0000110\n",
      "[13/25][2220/9765] Loss_D: 0.0994 Loss_G: 0.0409 Convergence: 0.1010 k= 0.020689 lr = 0.0000110\n",
      "[13/25][2230/9765] Loss_D: 0.0976 Loss_G: 0.0398 Convergence: 0.0989 k= 0.020692 lr = 0.0000110\n",
      "[13/25][2240/9765] Loss_D: 0.1021 Loss_G: 0.0373 Convergence: 0.1068 k= 0.020709 lr = 0.0000110\n",
      "[13/25][2250/9765] Loss_D: 0.0933 Loss_G: 0.0359 Convergence: 0.0959 k= 0.020722 lr = 0.0000110\n",
      "[13/25][2260/9765] Loss_D: 0.0973 Loss_G: 0.0406 Convergence: 0.0995 k= 0.020723 lr = 0.0000110\n",
      "[13/25][2270/9765] Loss_D: 0.1042 Loss_G: 0.0414 Convergence: 0.1057 k= 0.020711 lr = 0.0000110\n",
      "[13/25][2280/9765] Loss_D: 0.0983 Loss_G: 0.0446 Convergence: 0.1041 k= 0.020672 lr = 0.0000110\n",
      "[13/25][2290/9765] Loss_D: 0.0912 Loss_G: 0.0399 Convergence: 0.0951 k= 0.020667 lr = 0.0000110\n",
      "[13/25][2300/9765] Loss_D: 0.0872 Loss_G: 0.0390 Convergence: 0.0918 k= 0.020676 lr = 0.0000110\n",
      "[13/25][2310/9765] Loss_D: 0.1072 Loss_G: 0.0381 Convergence: 0.1131 k= 0.020682 lr = 0.0000110\n",
      "[13/25][2320/9765] Loss_D: 0.0962 Loss_G: 0.0400 Convergence: 0.0982 k= 0.020681 lr = 0.0000110\n",
      "[13/25][2330/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1011 k= 0.020678 lr = 0.0000110\n",
      "[13/25][2340/9765] Loss_D: 0.0966 Loss_G: 0.0368 Convergence: 0.0994 k= 0.020690 lr = 0.0000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][2350/9765] Loss_D: 0.0901 Loss_G: 0.0374 Convergence: 0.0919 k= 0.020707 lr = 0.0000110\n",
      "[13/25][2360/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.0998 k= 0.020733 lr = 0.0000110\n",
      "[13/25][2370/9765] Loss_D: 0.1006 Loss_G: 0.0419 Convergence: 0.1028 k= 0.020739 lr = 0.0000110\n",
      "[13/25][2380/9765] Loss_D: 0.1101 Loss_G: 0.0407 Convergence: 0.1145 k= 0.020726 lr = 0.0000110\n",
      "[13/25][2390/9765] Loss_D: 0.0979 Loss_G: 0.0425 Convergence: 0.1017 k= 0.020710 lr = 0.0000110\n",
      "[13/25][2400/9765] Loss_D: 0.0942 Loss_G: 0.0381 Convergence: 0.0951 k= 0.020706 lr = 0.0000110\n",
      "[13/25][2410/9765] Loss_D: 0.0887 Loss_G: 0.0363 Convergence: 0.0900 k= 0.020706 lr = 0.0000110\n",
      "[13/25][2420/9765] Loss_D: 0.1043 Loss_G: 0.0385 Convergence: 0.1086 k= 0.020735 lr = 0.0000110\n",
      "[13/25][2430/9765] Loss_D: 0.0946 Loss_G: 0.0401 Convergence: 0.0973 k= 0.020731 lr = 0.0000110\n",
      "[13/25][2440/9765] Loss_D: 0.1075 Loss_G: 0.0391 Convergence: 0.1124 k= 0.020730 lr = 0.0000110\n",
      "[13/25][2450/9765] Loss_D: 0.1010 Loss_G: 0.0404 Convergence: 0.1021 k= 0.020726 lr = 0.0000110\n",
      "[13/25][2460/9765] Loss_D: 0.0900 Loss_G: 0.0382 Convergence: 0.0927 k= 0.020714 lr = 0.0000110\n",
      "[13/25][2470/9765] Loss_D: 0.0868 Loss_G: 0.0371 Convergence: 0.0896 k= 0.020720 lr = 0.0000110\n",
      "[13/25][2480/9765] Loss_D: 0.0989 Loss_G: 0.0379 Convergence: 0.1017 k= 0.020741 lr = 0.0000110\n",
      "[13/25][2490/9765] Loss_D: 0.0990 Loss_G: 0.0371 Convergence: 0.1025 k= 0.020774 lr = 0.0000110\n",
      "[13/25][2500/9765] Loss_D: 0.0938 Loss_G: 0.0363 Convergence: 0.0961 k= 0.020783 lr = 0.0000110\n",
      "[13/25][2510/9765] Loss_D: 0.0993 Loss_G: 0.0420 Convergence: 0.1021 k= 0.020779 lr = 0.0000110\n",
      "[13/25][2520/9765] Loss_D: 0.1000 Loss_G: 0.0404 Convergence: 0.1009 k= 0.020759 lr = 0.0000110\n",
      "[13/25][2530/9765] Loss_D: 0.1014 Loss_G: 0.0380 Convergence: 0.1051 k= 0.020752 lr = 0.0000110\n",
      "[13/25][2540/9765] Loss_D: 0.1050 Loss_G: 0.0384 Convergence: 0.1096 k= 0.020766 lr = 0.0000110\n",
      "[13/25][2550/9765] Loss_D: 0.0955 Loss_G: 0.0413 Convergence: 0.0991 k= 0.020756 lr = 0.0000110\n",
      "[13/25][2560/9765] Loss_D: 0.0996 Loss_G: 0.0406 Convergence: 0.1009 k= 0.020752 lr = 0.0000110\n",
      "[13/25][2570/9765] Loss_D: 0.0920 Loss_G: 0.0392 Convergence: 0.0948 k= 0.020739 lr = 0.0000110\n",
      "[13/25][2580/9765] Loss_D: 0.0972 Loss_G: 0.0390 Convergence: 0.0982 k= 0.020737 lr = 0.0000110\n",
      "[13/25][2590/9765] Loss_D: 0.0842 Loss_G: 0.0387 Convergence: 0.0897 k= 0.020742 lr = 0.0000110\n",
      "[13/25][2600/9765] Loss_D: 0.0923 Loss_G: 0.0430 Convergence: 0.0989 k= 0.020732 lr = 0.0000110\n",
      "[13/25][2610/9765] Loss_D: 0.0913 Loss_G: 0.0483 Convergence: 0.1037 k= 0.020660 lr = 0.0000110\n",
      "[13/25][2620/9765] Loss_D: 0.0938 Loss_G: 0.0417 Convergence: 0.0986 k= 0.020575 lr = 0.0000110\n",
      "[13/25][2630/9765] Loss_D: 0.0998 Loss_G: 0.0371 Convergence: 0.1036 k= 0.020574 lr = 0.0000110\n",
      "[13/25][2640/9765] Loss_D: 0.0988 Loss_G: 0.0353 Convergence: 0.1040 k= 0.020599 lr = 0.0000110\n",
      "[13/25][2650/9765] Loss_D: 0.0987 Loss_G: 0.0352 Convergence: 0.1040 k= 0.020641 lr = 0.0000110\n",
      "[13/25][2660/9765] Loss_D: 0.0843 Loss_G: 0.0355 Convergence: 0.0865 k= 0.020684 lr = 0.0000110\n",
      "[13/25][2670/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0961 k= 0.020699 lr = 0.0000110\n",
      "[13/25][2680/9765] Loss_D: 0.0961 Loss_G: 0.0394 Convergence: 0.0976 k= 0.020693 lr = 0.0000110\n",
      "[13/25][2690/9765] Loss_D: 0.0947 Loss_G: 0.0423 Convergence: 0.0997 k= 0.020672 lr = 0.0000110\n",
      "[13/25][2700/9765] Loss_D: 0.1001 Loss_G: 0.0388 Convergence: 0.1024 k= 0.020672 lr = 0.0000110\n",
      "[13/25][2710/9765] Loss_D: 0.1146 Loss_G: 0.0385 Convergence: 0.1230 k= 0.020685 lr = 0.0000110\n",
      "[13/25][2720/9765] Loss_D: 0.0900 Loss_G: 0.0370 Convergence: 0.0915 k= 0.020695 lr = 0.0000110\n",
      "[13/25][2730/9765] Loss_D: 0.0990 Loss_G: 0.0377 Convergence: 0.1020 k= 0.020707 lr = 0.0000110\n",
      "[13/25][2740/9765] Loss_D: 0.0921 Loss_G: 0.0390 Convergence: 0.0947 k= 0.020719 lr = 0.0000110\n",
      "[13/25][2750/9765] Loss_D: 0.1058 Loss_G: 0.0387 Convergence: 0.1105 k= 0.020729 lr = 0.0000110\n",
      "[13/25][2760/9765] Loss_D: 0.0971 Loss_G: 0.0411 Convergence: 0.0999 k= 0.020729 lr = 0.0000110\n",
      "[13/25][2770/9765] Loss_D: 0.1025 Loss_G: 0.0394 Convergence: 0.1052 k= 0.020741 lr = 0.0000110\n",
      "[13/25][2780/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0961 k= 0.020743 lr = 0.0000110\n",
      "[13/25][2790/9765] Loss_D: 0.1015 Loss_G: 0.0410 Convergence: 0.1024 k= 0.020742 lr = 0.0000110\n",
      "[13/25][2800/9765] Loss_D: 0.1029 Loss_G: 0.0398 Convergence: 0.1054 k= 0.020753 lr = 0.0000110\n",
      "[13/25][2810/9765] Loss_D: 0.1047 Loss_G: 0.0421 Convergence: 0.1057 k= 0.020752 lr = 0.0000110\n",
      "[13/25][2820/9765] Loss_D: 0.0943 Loss_G: 0.0374 Convergence: 0.0958 k= 0.020750 lr = 0.0000110\n",
      "[13/25][2830/9765] Loss_D: 0.1021 Loss_G: 0.0369 Convergence: 0.1072 k= 0.020767 lr = 0.0000110\n",
      "[13/25][2840/9765] Loss_D: 0.1048 Loss_G: 0.0395 Convergence: 0.1082 k= 0.020787 lr = 0.0000110\n",
      "[13/25][2850/9765] Loss_D: 0.0967 Loss_G: 0.0365 Convergence: 0.1000 k= 0.020798 lr = 0.0000110\n",
      "[13/25][2860/9765] Loss_D: 0.0998 Loss_G: 0.0383 Convergence: 0.1026 k= 0.020829 lr = 0.0000110\n",
      "[13/25][2870/9765] Loss_D: 0.0957 Loss_G: 0.0399 Convergence: 0.0978 k= 0.020824 lr = 0.0000110\n",
      "[13/25][2880/9765] Loss_D: 0.0941 Loss_G: 0.0399 Convergence: 0.0969 k= 0.020816 lr = 0.0000110\n",
      "[13/25][2890/9765] Loss_D: 0.0998 Loss_G: 0.0416 Convergence: 0.1020 k= 0.020815 lr = 0.0000110\n",
      "[13/25][2900/9765] Loss_D: 0.0930 Loss_G: 0.0386 Convergence: 0.0949 k= 0.020806 lr = 0.0000110\n",
      "[13/25][2910/9765] Loss_D: 0.0960 Loss_G: 0.0398 Convergence: 0.0979 k= 0.020809 lr = 0.0000110\n",
      "[13/25][2920/9765] Loss_D: 0.1027 Loss_G: 0.0379 Convergence: 0.1069 k= 0.020814 lr = 0.0000110\n",
      "[13/25][2930/9765] Loss_D: 0.0856 Loss_G: 0.0398 Convergence: 0.0917 k= 0.020810 lr = 0.0000110\n",
      "[13/25][2940/9765] Loss_D: 0.1038 Loss_G: 0.0367 Convergence: 0.1096 k= 0.020809 lr = 0.0000110\n",
      "[13/25][2950/9765] Loss_D: 0.0954 Loss_G: 0.0386 Convergence: 0.0963 k= 0.020818 lr = 0.0000110\n",
      "[13/25][2960/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0969 k= 0.020828 lr = 0.0000110\n",
      "[13/25][2970/9765] Loss_D: 0.0859 Loss_G: 0.0391 Convergence: 0.0911 k= 0.020818 lr = 0.0000110\n",
      "[13/25][2980/9765] Loss_D: 0.1016 Loss_G: 0.0384 Convergence: 0.1049 k= 0.020820 lr = 0.0000110\n",
      "[13/25][2990/9765] Loss_D: 0.0907 Loss_G: 0.0396 Convergence: 0.0946 k= 0.020817 lr = 0.0000110\n",
      "[13/25][3000/9765] Loss_D: 0.0892 Loss_G: 0.0376 Convergence: 0.0916 k= 0.020828 lr = 0.0000110\n",
      "[13/25][3010/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0947 k= 0.020838 lr = 0.0000110\n",
      "[13/25][3020/9765] Loss_D: 0.0993 Loss_G: 0.0368 Convergence: 0.1033 k= 0.020846 lr = 0.0000110\n",
      "[13/25][3030/9765] Loss_D: 0.0904 Loss_G: 0.0388 Convergence: 0.0936 k= 0.020833 lr = 0.0000110\n",
      "[13/25][3040/9765] Loss_D: 0.0928 Loss_G: 0.0411 Convergence: 0.0973 k= 0.020813 lr = 0.0000110\n",
      "[13/25][3050/9765] Loss_D: 0.0993 Loss_G: 0.0397 Convergence: 0.1003 k= 0.020821 lr = 0.0000110\n",
      "[13/25][3060/9765] Loss_D: 0.0949 Loss_G: 0.0357 Convergence: 0.0982 k= 0.020840 lr = 0.0000110\n",
      "[13/25][3070/9765] Loss_D: 0.0995 Loss_G: 0.0360 Convergence: 0.1043 k= 0.020868 lr = 0.0000110\n",
      "[13/25][3080/9765] Loss_D: 0.1003 Loss_G: 0.0383 Convergence: 0.1032 k= 0.020893 lr = 0.0000110\n",
      "[13/25][3090/9765] Loss_D: 0.0886 Loss_G: 0.0397 Convergence: 0.0934 k= 0.020888 lr = 0.0000110\n",
      "[13/25][3100/9765] Loss_D: 0.0958 Loss_G: 0.0434 Convergence: 0.1015 k= 0.020885 lr = 0.0000110\n",
      "[13/25][3110/9765] Loss_D: 0.0929 Loss_G: 0.0398 Convergence: 0.0960 k= 0.020871 lr = 0.0000110\n",
      "[13/25][3120/9765] Loss_D: 0.0982 Loss_G: 0.0396 Convergence: 0.0990 k= 0.020872 lr = 0.0000110\n",
      "[13/25][3130/9765] Loss_D: 0.1002 Loss_G: 0.0363 Convergence: 0.1050 k= 0.020877 lr = 0.0000110\n",
      "[13/25][3140/9765] Loss_D: 0.1061 Loss_G: 0.0409 Convergence: 0.1089 k= 0.020885 lr = 0.0000110\n",
      "[13/25][3150/9765] Loss_D: 0.0932 Loss_G: 0.0384 Convergence: 0.0948 k= 0.020867 lr = 0.0000110\n",
      "[13/25][3160/9765] Loss_D: 0.0912 Loss_G: 0.0374 Convergence: 0.0926 k= 0.020883 lr = 0.0000110\n",
      "[13/25][3170/9765] Loss_D: 0.0911 Loss_G: 0.0370 Convergence: 0.0921 k= 0.020895 lr = 0.0000110\n",
      "[13/25][3180/9765] Loss_D: 0.0987 Loss_G: 0.0360 Convergence: 0.1033 k= 0.020904 lr = 0.0000110\n",
      "[13/25][3190/9765] Loss_D: 0.0967 Loss_G: 0.0375 Convergence: 0.0990 k= 0.020926 lr = 0.0000110\n",
      "[13/25][3200/9765] Loss_D: 0.1046 Loss_G: 0.0371 Convergence: 0.1104 k= 0.020946 lr = 0.0000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][3210/9765] Loss_D: 0.0917 Loss_G: 0.0375 Convergence: 0.0930 k= 0.020956 lr = 0.0000110\n",
      "[13/25][3220/9765] Loss_D: 0.0948 Loss_G: 0.0390 Convergence: 0.0963 k= 0.020949 lr = 0.0000110\n",
      "[13/25][3230/9765] Loss_D: 0.0941 Loss_G: 0.0378 Convergence: 0.0951 k= 0.020949 lr = 0.0000110\n",
      "[13/25][3240/9765] Loss_D: 0.0878 Loss_G: 0.0388 Convergence: 0.0919 k= 0.020943 lr = 0.0000110\n",
      "[13/25][3250/9765] Loss_D: 0.0968 Loss_G: 0.0395 Convergence: 0.0981 k= 0.020946 lr = 0.0000110\n",
      "[13/25][3260/9765] Loss_D: 0.1053 Loss_G: 0.0376 Convergence: 0.1109 k= 0.020951 lr = 0.0000110\n",
      "[13/25][3270/9765] Loss_D: 0.1017 Loss_G: 0.0382 Convergence: 0.1052 k= 0.020954 lr = 0.0000110\n",
      "[13/25][3280/9765] Loss_D: 0.0989 Loss_G: 0.0420 Convergence: 0.1018 k= 0.020953 lr = 0.0000110\n",
      "[13/25][3290/9765] Loss_D: 0.0993 Loss_G: 0.0403 Convergence: 0.1004 k= 0.020946 lr = 0.0000110\n",
      "[13/25][3300/9765] Loss_D: 0.0984 Loss_G: 0.0418 Convergence: 0.1014 k= 0.020918 lr = 0.0000110\n",
      "[13/25][3310/9765] Loss_D: 0.0869 Loss_G: 0.0392 Convergence: 0.0919 k= 0.020908 lr = 0.0000110\n",
      "[13/25][3320/9765] Loss_D: 0.0957 Loss_G: 0.0382 Convergence: 0.0969 k= 0.020917 lr = 0.0000110\n",
      "[13/25][3330/9765] Loss_D: 0.0954 Loss_G: 0.0357 Convergence: 0.0990 k= 0.020938 lr = 0.0000110\n",
      "[13/25][3340/9765] Loss_D: 0.0957 Loss_G: 0.0369 Convergence: 0.0982 k= 0.020963 lr = 0.0000110\n",
      "[13/25][3350/9765] Loss_D: 0.0928 Loss_G: 0.0425 Convergence: 0.0988 k= 0.020938 lr = 0.0000110\n",
      "[13/25][3360/9765] Loss_D: 0.0939 Loss_G: 0.0431 Convergence: 0.0999 k= 0.020888 lr = 0.0000110\n",
      "[13/25][3370/9765] Loss_D: 0.0952 Loss_G: 0.0417 Convergence: 0.0993 k= 0.020848 lr = 0.0000110\n",
      "[13/25][3380/9765] Loss_D: 0.1001 Loss_G: 0.0423 Convergence: 0.1029 k= 0.020833 lr = 0.0000110\n",
      "[13/25][3390/9765] Loss_D: 0.0986 Loss_G: 0.0369 Convergence: 0.1023 k= 0.020834 lr = 0.0000110\n",
      "[13/25][3400/9765] Loss_D: 0.1069 Loss_G: 0.0369 Convergence: 0.1139 k= 0.020846 lr = 0.0000110\n",
      "[13/25][3410/9765] Loss_D: 0.0995 Loss_G: 0.0398 Convergence: 0.1006 k= 0.020855 lr = 0.0000110\n",
      "[13/25][3420/9765] Loss_D: 0.0992 Loss_G: 0.0415 Convergence: 0.1016 k= 0.020846 lr = 0.0000110\n",
      "[13/25][3430/9765] Loss_D: 0.1053 Loss_G: 0.0426 Convergence: 0.1063 k= 0.020837 lr = 0.0000110\n",
      "[13/25][3440/9765] Loss_D: 0.0924 Loss_G: 0.0392 Convergence: 0.0952 k= 0.020817 lr = 0.0000110\n",
      "[13/25][3450/9765] Loss_D: 0.0956 Loss_G: 0.0398 Convergence: 0.0977 k= 0.020807 lr = 0.0000110\n",
      "[13/25][3460/9765] Loss_D: 0.1032 Loss_G: 0.0402 Convergence: 0.1054 k= 0.020799 lr = 0.0000110\n",
      "[13/25][3470/9765] Loss_D: 0.0915 Loss_G: 0.0375 Convergence: 0.0929 k= 0.020810 lr = 0.0000110\n",
      "[13/25][3480/9765] Loss_D: 0.0895 Loss_G: 0.0388 Convergence: 0.0930 k= 0.020810 lr = 0.0000110\n",
      "[13/25][3490/9765] Loss_D: 0.0991 Loss_G: 0.0377 Convergence: 0.1022 k= 0.020810 lr = 0.0000110\n",
      "[13/25][3500/9765] Loss_D: 0.0873 Loss_G: 0.0389 Convergence: 0.0918 k= 0.020806 lr = 0.0000110\n",
      "[13/25][3510/9765] Loss_D: 0.0966 Loss_G: 0.0424 Convergence: 0.1009 k= 0.020799 lr = 0.0000110\n",
      "[13/25][3520/9765] Loss_D: 0.0967 Loss_G: 0.0399 Convergence: 0.0984 k= 0.020786 lr = 0.0000110\n",
      "[13/25][3530/9765] Loss_D: 0.0902 Loss_G: 0.0390 Convergence: 0.0936 k= 0.020765 lr = 0.0000110\n",
      "[13/25][3540/9765] Loss_D: 0.1010 Loss_G: 0.0392 Convergence: 0.1034 k= 0.020761 lr = 0.0000110\n",
      "[13/25][3550/9765] Loss_D: 0.0906 Loss_G: 0.0386 Convergence: 0.0935 k= 0.020746 lr = 0.0000110\n",
      "[13/25][3560/9765] Loss_D: 0.0903 Loss_G: 0.0393 Convergence: 0.0940 k= 0.020751 lr = 0.0000110\n",
      "[13/25][3570/9765] Loss_D: 0.0999 Loss_G: 0.0368 Convergence: 0.1041 k= 0.020763 lr = 0.0000110\n",
      "[13/25][3580/9765] Loss_D: 0.0926 Loss_G: 0.0365 Convergence: 0.0942 k= 0.020790 lr = 0.0000110\n",
      "[13/25][3590/9765] Loss_D: 0.0934 Loss_G: 0.0400 Convergence: 0.0966 k= 0.020804 lr = 0.0000110\n",
      "[13/25][3600/9765] Loss_D: 0.0890 Loss_G: 0.0393 Convergence: 0.0932 k= 0.020787 lr = 0.0000110\n",
      "[13/25][3610/9765] Loss_D: 0.1078 Loss_G: 0.0396 Convergence: 0.1124 k= 0.020785 lr = 0.0000110\n",
      "[13/25][3620/9765] Loss_D: 0.0921 Loss_G: 0.0393 Convergence: 0.0950 k= 0.020781 lr = 0.0000110\n",
      "[13/25][3630/9765] Loss_D: 0.0964 Loss_G: 0.0399 Convergence: 0.0983 k= 0.020778 lr = 0.0000110\n",
      "[13/25][3640/9765] Loss_D: 0.0945 Loss_G: 0.0386 Convergence: 0.0958 k= 0.020782 lr = 0.0000110\n",
      "[13/25][3650/9765] Loss_D: 0.0950 Loss_G: 0.0405 Convergence: 0.0980 k= 0.020777 lr = 0.0000110\n",
      "[13/25][3660/9765] Loss_D: 0.0998 Loss_G: 0.0380 Convergence: 0.1028 k= 0.020795 lr = 0.0000110\n",
      "[13/25][3670/9765] Loss_D: 0.0917 Loss_G: 0.0379 Convergence: 0.0934 k= 0.020791 lr = 0.0000110\n",
      "[13/25][3680/9765] Loss_D: 0.0862 Loss_G: 0.0391 Convergence: 0.0913 k= 0.020794 lr = 0.0000110\n",
      "[13/25][3690/9765] Loss_D: 0.1075 Loss_G: 0.0411 Convergence: 0.1105 k= 0.020785 lr = 0.0000110\n",
      "[13/25][3700/9765] Loss_D: 0.0874 Loss_G: 0.0377 Convergence: 0.0906 k= 0.020788 lr = 0.0000110\n",
      "[13/25][3710/9765] Loss_D: 0.0998 Loss_G: 0.0375 Convergence: 0.1033 k= 0.020804 lr = 0.0000110\n",
      "[13/25][3720/9765] Loss_D: 0.1011 Loss_G: 0.0369 Convergence: 0.1058 k= 0.020797 lr = 0.0000110\n",
      "[13/25][3730/9765] Loss_D: 0.1010 Loss_G: 0.0392 Convergence: 0.1034 k= 0.020816 lr = 0.0000110\n",
      "[13/25][3740/9765] Loss_D: 0.0983 Loss_G: 0.0388 Convergence: 0.1000 k= 0.020810 lr = 0.0000110\n",
      "[13/25][3750/9765] Loss_D: 0.1038 Loss_G: 0.0373 Convergence: 0.1091 k= 0.020824 lr = 0.0000110\n",
      "[13/25][3760/9765] Loss_D: 0.0927 Loss_G: 0.0364 Convergence: 0.0945 k= 0.020848 lr = 0.0000110\n",
      "[13/25][3770/9765] Loss_D: 0.0888 Loss_G: 0.0355 Convergence: 0.0899 k= 0.020863 lr = 0.0000110\n",
      "[13/25][3780/9765] Loss_D: 0.0952 Loss_G: 0.0354 Convergence: 0.0990 k= 0.020887 lr = 0.0000110\n",
      "[13/25][3790/9765] Loss_D: 0.1000 Loss_G: 0.0380 Convergence: 0.1031 k= 0.020891 lr = 0.0000110\n",
      "[13/25][3800/9765] Loss_D: 0.0985 Loss_G: 0.0402 Convergence: 0.0999 k= 0.020873 lr = 0.0000110\n",
      "[13/25][3810/9765] Loss_D: 0.0886 Loss_G: 0.0367 Convergence: 0.0903 k= 0.020872 lr = 0.0000110\n",
      "[13/25][3820/9765] Loss_D: 0.1005 Loss_G: 0.0390 Convergence: 0.1028 k= 0.020888 lr = 0.0000110\n",
      "[13/25][3830/9765] Loss_D: 0.0964 Loss_G: 0.0403 Convergence: 0.0986 k= 0.020884 lr = 0.0000110\n",
      "[13/25][3840/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1008 k= 0.020888 lr = 0.0000110\n",
      "[13/25][3850/9765] Loss_D: 0.1036 Loss_G: 0.0398 Convergence: 0.1064 k= 0.020898 lr = 0.0000110\n",
      "[13/25][3860/9765] Loss_D: 0.0989 Loss_G: 0.0392 Convergence: 0.1005 k= 0.020899 lr = 0.0000110\n",
      "[13/25][3870/9765] Loss_D: 0.1017 Loss_G: 0.0410 Convergence: 0.1026 k= 0.020882 lr = 0.0000110\n",
      "[13/25][3880/9765] Loss_D: 0.0954 Loss_G: 0.0407 Convergence: 0.0985 k= 0.020867 lr = 0.0000110\n",
      "[13/25][3890/9765] Loss_D: 0.0988 Loss_G: 0.0374 Convergence: 0.1020 k= 0.020861 lr = 0.0000110\n",
      "[13/25][3900/9765] Loss_D: 0.0966 Loss_G: 0.0391 Convergence: 0.0975 k= 0.020858 lr = 0.0000110\n",
      "[13/25][3910/9765] Loss_D: 0.0910 Loss_G: 0.0372 Convergence: 0.0923 k= 0.020858 lr = 0.0000110\n",
      "[13/25][3920/9765] Loss_D: 0.0961 Loss_G: 0.0384 Convergence: 0.0973 k= 0.020868 lr = 0.0000110\n",
      "[13/25][3930/9765] Loss_D: 0.1063 Loss_G: 0.0388 Convergence: 0.1112 k= 0.020879 lr = 0.0000110\n",
      "[13/25][3940/9765] Loss_D: 0.0958 Loss_G: 0.0398 Convergence: 0.0977 k= 0.020874 lr = 0.0000110\n",
      "[13/25][3950/9765] Loss_D: 0.0930 Loss_G: 0.0391 Convergence: 0.0954 k= 0.020862 lr = 0.0000110\n",
      "[13/25][3960/9765] Loss_D: 0.0994 Loss_G: 0.0389 Convergence: 0.1014 k= 0.020875 lr = 0.0000110\n",
      "[13/25][3970/9765] Loss_D: 0.1075 Loss_G: 0.0393 Convergence: 0.1124 k= 0.020879 lr = 0.0000110\n",
      "[13/25][3980/9765] Loss_D: 0.0898 Loss_G: 0.0373 Convergence: 0.0917 k= 0.020905 lr = 0.0000110\n",
      "[13/25][3990/9765] Loss_D: 0.1053 Loss_G: 0.0411 Convergence: 0.1075 k= 0.020907 lr = 0.0000110\n",
      "[13/25][4000/9765] Loss_D: 0.1104 Loss_G: 0.0427 Convergence: 0.1131 k= 0.020888 lr = 0.0000110\n",
      "[13/25][4010/9765] Loss_D: 0.0910 Loss_G: 0.0420 Convergence: 0.0971 k= 0.020843 lr = 0.0000110\n",
      "[13/25][4020/9765] Loss_D: 0.1013 Loss_G: 0.0403 Convergence: 0.1028 k= 0.020819 lr = 0.0000110\n",
      "[13/25][4030/9765] Loss_D: 0.0960 Loss_G: 0.0403 Convergence: 0.0985 k= 0.020794 lr = 0.0000110\n",
      "[13/25][4040/9765] Loss_D: 0.1037 Loss_G: 0.0400 Convergence: 0.1063 k= 0.020768 lr = 0.0000110\n",
      "[13/25][4050/9765] Loss_D: 0.1116 Loss_G: 0.0408 Convergence: 0.1166 k= 0.020745 lr = 0.0000110\n",
      "[13/25][4060/9765] Loss_D: 0.0897 Loss_G: 0.0403 Convergence: 0.0946 k= 0.020735 lr = 0.0000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][4070/9765] Loss_D: 0.1032 Loss_G: 0.0397 Convergence: 0.1058 k= 0.020735 lr = 0.0000110\n",
      "[13/25][4080/9765] Loss_D: 0.0958 Loss_G: 0.0426 Convergence: 0.1006 k= 0.020708 lr = 0.0000110\n",
      "[13/25][4090/9765] Loss_D: 0.0947 Loss_G: 0.0378 Convergence: 0.0959 k= 0.020713 lr = 0.0000110\n",
      "[13/25][4100/9765] Loss_D: 0.0912 Loss_G: 0.0367 Convergence: 0.0920 k= 0.020720 lr = 0.0000110\n",
      "[13/25][4110/9765] Loss_D: 0.1048 Loss_G: 0.0387 Convergence: 0.1091 k= 0.020735 lr = 0.0000110\n",
      "[13/25][4120/9765] Loss_D: 0.1048 Loss_G: 0.0393 Convergence: 0.1086 k= 0.020737 lr = 0.0000110\n",
      "[13/25][4130/9765] Loss_D: 0.0871 Loss_G: 0.0402 Convergence: 0.0929 k= 0.020734 lr = 0.0000110\n",
      "[13/25][4140/9765] Loss_D: 0.1002 Loss_G: 0.0396 Convergence: 0.1017 k= 0.020729 lr = 0.0000110\n",
      "[13/25][4150/9765] Loss_D: 0.1001 Loss_G: 0.0391 Convergence: 0.1022 k= 0.020728 lr = 0.0000110\n",
      "[13/25][4160/9765] Loss_D: 0.0886 Loss_G: 0.0398 Convergence: 0.0935 k= 0.020725 lr = 0.0000110\n",
      "[13/25][4170/9765] Loss_D: 0.0931 Loss_G: 0.0407 Convergence: 0.0970 k= 0.020697 lr = 0.0000110\n",
      "[13/25][4180/9765] Loss_D: 0.0922 Loss_G: 0.0423 Convergence: 0.0982 k= 0.020682 lr = 0.0000110\n",
      "[13/25][4190/9765] Loss_D: 0.0850 Loss_G: 0.0404 Convergence: 0.0919 k= 0.020656 lr = 0.0000110\n",
      "[13/25][4200/9765] Loss_D: 0.1060 Loss_G: 0.0395 Convergence: 0.1100 k= 0.020641 lr = 0.0000110\n",
      "[13/25][4210/9765] Loss_D: 0.0985 Loss_G: 0.0387 Convergence: 0.1004 k= 0.020655 lr = 0.0000110\n",
      "[13/25][4220/9765] Loss_D: 0.1056 Loss_G: 0.0378 Convergence: 0.1111 k= 0.020687 lr = 0.0000110\n",
      "[13/25][4230/9765] Loss_D: 0.0968 Loss_G: 0.0398 Convergence: 0.0984 k= 0.020698 lr = 0.0000110\n",
      "[13/25][4240/9765] Loss_D: 0.1063 Loss_G: 0.0415 Convergence: 0.1084 k= 0.020689 lr = 0.0000110\n",
      "[13/25][4250/9765] Loss_D: 0.0963 Loss_G: 0.0469 Convergence: 0.1052 k= 0.020646 lr = 0.0000110\n",
      "[13/25][4260/9765] Loss_D: 0.1099 Loss_G: 0.0404 Convergence: 0.1147 k= 0.020620 lr = 0.0000110\n",
      "[13/25][4270/9765] Loss_D: 0.1105 Loss_G: 0.0415 Convergence: 0.1143 k= 0.020620 lr = 0.0000110\n",
      "[13/25][4280/9765] Loss_D: 0.0988 Loss_G: 0.0396 Convergence: 0.0999 k= 0.020614 lr = 0.0000110\n",
      "[13/25][4290/9765] Loss_D: 0.1000 Loss_G: 0.0373 Convergence: 0.1037 k= 0.020627 lr = 0.0000110\n",
      "[13/25][4300/9765] Loss_D: 0.0989 Loss_G: 0.0364 Convergence: 0.1031 k= 0.020651 lr = 0.0000110\n",
      "[13/25][4310/9765] Loss_D: 0.1117 Loss_G: 0.0413 Convergence: 0.1163 k= 0.020659 lr = 0.0000110\n",
      "[13/25][4320/9765] Loss_D: 0.0959 Loss_G: 0.0382 Convergence: 0.0971 k= 0.020654 lr = 0.0000110\n",
      "[13/25][4330/9765] Loss_D: 0.0917 Loss_G: 0.0408 Convergence: 0.0963 k= 0.020647 lr = 0.0000110\n",
      "[13/25][4340/9765] Loss_D: 0.1004 Loss_G: 0.0388 Convergence: 0.1029 k= 0.020637 lr = 0.0000110\n",
      "[13/25][4350/9765] Loss_D: 0.1053 Loss_G: 0.0402 Convergence: 0.1084 k= 0.020646 lr = 0.0000110\n",
      "[13/25][4360/9765] Loss_D: 0.1020 Loss_G: 0.0379 Convergence: 0.1060 k= 0.020658 lr = 0.0000110\n",
      "[13/25][4370/9765] Loss_D: 0.1025 Loss_G: 0.0392 Convergence: 0.1053 k= 0.020652 lr = 0.0000110\n",
      "[13/25][4380/9765] Loss_D: 0.1006 Loss_G: 0.0412 Convergence: 0.1020 k= 0.020643 lr = 0.0000110\n",
      "[13/25][4390/9765] Loss_D: 0.0968 Loss_G: 0.0387 Convergence: 0.0980 k= 0.020640 lr = 0.0000110\n",
      "[13/25][4400/9765] Loss_D: 0.0988 Loss_G: 0.0380 Convergence: 0.1014 k= 0.020641 lr = 0.0000110\n",
      "[13/25][4410/9765] Loss_D: 0.1017 Loss_G: 0.0392 Convergence: 0.1044 k= 0.020644 lr = 0.0000110\n",
      "[13/25][4420/9765] Loss_D: 0.0946 Loss_G: 0.0377 Convergence: 0.0958 k= 0.020634 lr = 0.0000110\n",
      "[13/25][4430/9765] Loss_D: 0.1008 Loss_G: 0.0388 Convergence: 0.1035 k= 0.020645 lr = 0.0000110\n",
      "[13/25][4440/9765] Loss_D: 0.1017 Loss_G: 0.0414 Convergence: 0.1029 k= 0.020638 lr = 0.0000110\n",
      "[13/25][4450/9765] Loss_D: 0.1071 Loss_G: 0.0397 Convergence: 0.1114 k= 0.020627 lr = 0.0000110\n",
      "[13/25][4460/9765] Loss_D: 0.0972 Loss_G: 0.0378 Convergence: 0.0994 k= 0.020627 lr = 0.0000110\n",
      "[13/25][4470/9765] Loss_D: 0.0933 Loss_G: 0.0415 Convergence: 0.0980 k= 0.020615 lr = 0.0000110\n",
      "[13/25][4480/9765] Loss_D: 0.0982 Loss_G: 0.0397 Convergence: 0.0991 k= 0.020601 lr = 0.0000110\n",
      "[13/25][4490/9765] Loss_D: 0.0916 Loss_G: 0.0396 Convergence: 0.0950 k= 0.020593 lr = 0.0000110\n",
      "[13/25][4500/9765] Loss_D: 0.1008 Loss_G: 0.0379 Convergence: 0.1043 k= 0.020584 lr = 0.0000110\n",
      "[13/25][4510/9765] Loss_D: 0.0899 Loss_G: 0.0380 Convergence: 0.0924 k= 0.020590 lr = 0.0000110\n",
      "[13/25][4520/9765] Loss_D: 0.0972 Loss_G: 0.0408 Convergence: 0.0996 k= 0.020582 lr = 0.0000110\n",
      "[13/25][4530/9765] Loss_D: 0.0903 Loss_G: 0.0395 Convergence: 0.0942 k= 0.020584 lr = 0.0000110\n",
      "[13/25][4540/9765] Loss_D: 0.1012 Loss_G: 0.0380 Convergence: 0.1049 k= 0.020580 lr = 0.0000110\n",
      "[13/25][4550/9765] Loss_D: 0.0933 Loss_G: 0.0393 Convergence: 0.0958 k= 0.020597 lr = 0.0000110\n",
      "[13/25][4560/9765] Loss_D: 0.0999 Loss_G: 0.0374 Convergence: 0.1035 k= 0.020596 lr = 0.0000110\n",
      "[13/25][4570/9765] Loss_D: 0.0965 Loss_G: 0.0374 Convergence: 0.0987 k= 0.020613 lr = 0.0000110\n",
      "[13/25][4580/9765] Loss_D: 0.1083 Loss_G: 0.0365 Convergence: 0.1162 k= 0.020637 lr = 0.0000110\n",
      "[13/25][4590/9765] Loss_D: 0.0923 Loss_G: 0.0394 Convergence: 0.0953 k= 0.020646 lr = 0.0000110\n",
      "[13/25][4600/9765] Loss_D: 0.0979 Loss_G: 0.0415 Convergence: 0.1008 k= 0.020648 lr = 0.0000110\n",
      "[13/25][4610/9765] Loss_D: 0.0970 Loss_G: 0.0384 Convergence: 0.0986 k= 0.020632 lr = 0.0000110\n",
      "[13/25][4620/9765] Loss_D: 0.0958 Loss_G: 0.0405 Convergence: 0.0984 k= 0.020634 lr = 0.0000110\n",
      "[13/25][4630/9765] Loss_D: 0.0919 Loss_G: 0.0382 Convergence: 0.0938 k= 0.020624 lr = 0.0000110\n",
      "[13/25][4640/9765] Loss_D: 0.0988 Loss_G: 0.0394 Convergence: 0.1000 k= 0.020625 lr = 0.0000110\n",
      "[13/25][4650/9765] Loss_D: 0.0953 Loss_G: 0.0381 Convergence: 0.0965 k= 0.020617 lr = 0.0000110\n",
      "[13/25][4660/9765] Loss_D: 0.0890 Loss_G: 0.0378 Convergence: 0.0916 k= 0.020610 lr = 0.0000110\n",
      "[13/25][4670/9765] Loss_D: 0.0905 Loss_G: 0.0381 Convergence: 0.0929 k= 0.020608 lr = 0.0000110\n",
      "[13/25][4680/9765] Loss_D: 0.0976 Loss_G: 0.0412 Convergence: 0.1003 k= 0.020606 lr = 0.0000110\n",
      "[13/25][4690/9765] Loss_D: 0.0943 Loss_G: 0.0429 Convergence: 0.0999 k= 0.020591 lr = 0.0000110\n",
      "[13/25][4700/9765] Loss_D: 0.0964 Loss_G: 0.0408 Convergence: 0.0991 k= 0.020579 lr = 0.0000110\n",
      "[13/25][4710/9765] Loss_D: 0.0962 Loss_G: 0.0422 Convergence: 0.1004 k= 0.020556 lr = 0.0000110\n",
      "[13/25][4720/9765] Loss_D: 0.0916 Loss_G: 0.0381 Convergence: 0.0935 k= 0.020537 lr = 0.0000110\n",
      "[13/25][4730/9765] Loss_D: 0.1041 Loss_G: 0.0383 Convergence: 0.1087 k= 0.020527 lr = 0.0000110\n",
      "[13/25][4740/9765] Loss_D: 0.0950 Loss_G: 0.0357 Convergence: 0.0984 k= 0.020562 lr = 0.0000110\n",
      "[13/25][4750/9765] Loss_D: 0.1081 Loss_G: 0.0373 Convergence: 0.1150 k= 0.020601 lr = 0.0000110\n",
      "[13/25][4760/9765] Loss_D: 0.0918 Loss_G: 0.0374 Convergence: 0.0930 k= 0.020610 lr = 0.0000110\n",
      "[13/25][4770/9765] Loss_D: 0.0950 Loss_G: 0.0401 Convergence: 0.0975 k= 0.020612 lr = 0.0000110\n",
      "[13/25][4780/9765] Loss_D: 0.0980 Loss_G: 0.0413 Convergence: 0.1006 k= 0.020596 lr = 0.0000110\n",
      "[13/25][4790/9765] Loss_D: 0.0927 Loss_G: 0.0419 Convergence: 0.0981 k= 0.020565 lr = 0.0000110\n",
      "[13/25][4800/9765] Loss_D: 0.0897 Loss_G: 0.0405 Convergence: 0.0948 k= 0.020560 lr = 0.0000110\n",
      "[13/25][4810/9765] Loss_D: 0.0978 Loss_G: 0.0371 Convergence: 0.1009 k= 0.020563 lr = 0.0000110\n",
      "[13/25][4820/9765] Loss_D: 0.0995 Loss_G: 0.0380 Convergence: 0.1023 k= 0.020575 lr = 0.0000110\n",
      "[13/25][4830/9765] Loss_D: 0.0865 Loss_G: 0.0375 Convergence: 0.0899 k= 0.020578 lr = 0.0000110\n",
      "[13/25][4840/9765] Loss_D: 0.0971 Loss_G: 0.0380 Convergence: 0.0990 k= 0.020592 lr = 0.0000110\n",
      "[13/25][4850/9765] Loss_D: 0.1059 Loss_G: 0.0447 Convergence: 0.1088 k= 0.020576 lr = 0.0000110\n",
      "[13/25][4860/9765] Loss_D: 0.0971 Loss_G: 0.0392 Convergence: 0.0980 k= 0.020550 lr = 0.0000110\n",
      "[13/25][4870/9765] Loss_D: 0.0969 Loss_G: 0.0456 Convergence: 0.1043 k= 0.020497 lr = 0.0000110\n",
      "[13/25][4880/9765] Loss_D: 0.0949 Loss_G: 0.0396 Convergence: 0.0970 k= 0.020467 lr = 0.0000110\n",
      "[13/25][4890/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0955 k= 0.020458 lr = 0.0000110\n",
      "[13/25][4900/9765] Loss_D: 0.1019 Loss_G: 0.0406 Convergence: 0.1033 k= 0.020462 lr = 0.0000110\n",
      "[13/25][4910/9765] Loss_D: 0.0942 Loss_G: 0.0376 Convergence: 0.0953 k= 0.020459 lr = 0.0000110\n",
      "[13/25][4920/9765] Loss_D: 0.0892 Loss_G: 0.0381 Convergence: 0.0921 k= 0.020491 lr = 0.0000110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][4930/9765] Loss_D: 0.1013 Loss_G: 0.0388 Convergence: 0.1041 k= 0.020495 lr = 0.0000110\n",
      "[13/25][4940/9765] Loss_D: 0.0931 Loss_G: 0.0365 Convergence: 0.0949 k= 0.020477 lr = 0.0000110\n",
      "[13/25][4950/9765] Loss_D: 0.1076 Loss_G: 0.0407 Convergence: 0.1111 k= 0.020493 lr = 0.0000110\n",
      "[13/25][4960/9765] Loss_D: 0.0974 Loss_G: 0.0393 Convergence: 0.0981 k= 0.020501 lr = 0.0000110\n",
      "[13/25][4970/9765] Loss_D: 0.0990 Loss_G: 0.0363 Convergence: 0.1034 k= 0.020503 lr = 0.0000110\n",
      "[13/25][4980/9765] Loss_D: 0.1010 Loss_G: 0.0365 Convergence: 0.1060 k= 0.020523 lr = 0.0000110\n",
      "[13/25][4990/9765] Loss_D: 0.0904 Loss_G: 0.0388 Convergence: 0.0936 k= 0.020542 lr = 0.0000110\n",
      "[13/25][5000/9765] Loss_D: 0.1117 Loss_G: 0.0405 Convergence: 0.1171 k= 0.020542 lr = 0.0000110\n",
      "[13/25][5010/9765] Loss_D: 0.1043 Loss_G: 0.0384 Convergence: 0.1086 k= 0.020533 lr = 0.0000110\n",
      "[13/25][5020/9765] Loss_D: 0.0867 Loss_G: 0.0427 Convergence: 0.0953 k= 0.020522 lr = 0.0000110\n",
      "[13/25][5030/9765] Loss_D: 0.0945 Loss_G: 0.0419 Convergence: 0.0991 k= 0.020497 lr = 0.0000110\n",
      "[13/25][5040/9765] Loss_D: 0.0901 Loss_G: 0.0403 Convergence: 0.0948 k= 0.020481 lr = 0.0000110\n",
      "[13/25][5050/9765] Loss_D: 0.1076 Loss_G: 0.0377 Convergence: 0.1140 k= 0.020497 lr = 0.0000110\n",
      "[13/25][5060/9765] Loss_D: 0.0895 Loss_G: 0.0366 Convergence: 0.0908 k= 0.020505 lr = 0.0000105\n",
      "[13/25][5070/9765] Loss_D: 0.0968 Loss_G: 0.0412 Convergence: 0.0998 k= 0.020501 lr = 0.0000105\n",
      "[13/25][5080/9765] Loss_D: 0.0961 Loss_G: 0.0421 Convergence: 0.1003 k= 0.020504 lr = 0.0000105\n",
      "[13/25][5090/9765] Loss_D: 0.0892 Loss_G: 0.0380 Convergence: 0.0920 k= 0.020503 lr = 0.0000105\n",
      "[13/25][5100/9765] Loss_D: 0.0885 Loss_G: 0.0374 Convergence: 0.0910 k= 0.020507 lr = 0.0000105\n",
      "[13/25][5110/9765] Loss_D: 0.0898 Loss_G: 0.0377 Convergence: 0.0920 k= 0.020514 lr = 0.0000105\n",
      "[13/25][5120/9765] Loss_D: 0.0989 Loss_G: 0.0373 Convergence: 0.1022 k= 0.020530 lr = 0.0000105\n",
      "[13/25][5130/9765] Loss_D: 0.1105 Loss_G: 0.0392 Convergence: 0.1166 k= 0.020551 lr = 0.0000105\n",
      "[13/25][5140/9765] Loss_D: 0.0942 Loss_G: 0.0395 Convergence: 0.0965 k= 0.020538 lr = 0.0000105\n",
      "[13/25][5150/9765] Loss_D: 0.0954 Loss_G: 0.0403 Convergence: 0.0981 k= 0.020514 lr = 0.0000105\n",
      "[13/25][5160/9765] Loss_D: 0.0952 Loss_G: 0.0386 Convergence: 0.0962 k= 0.020504 lr = 0.0000105\n",
      "[13/25][5170/9765] Loss_D: 0.0948 Loss_G: 0.0378 Convergence: 0.0961 k= 0.020499 lr = 0.0000105\n",
      "[13/25][5180/9765] Loss_D: 0.0933 Loss_G: 0.0391 Convergence: 0.0955 k= 0.020511 lr = 0.0000105\n",
      "[13/25][5190/9765] Loss_D: 0.0912 Loss_G: 0.0392 Convergence: 0.0944 k= 0.020520 lr = 0.0000105\n",
      "[13/25][5200/9765] Loss_D: 0.0832 Loss_G: 0.0387 Convergence: 0.0891 k= 0.020501 lr = 0.0000105\n",
      "[13/25][5210/9765] Loss_D: 0.0906 Loss_G: 0.0396 Convergence: 0.0944 k= 0.020498 lr = 0.0000105\n",
      "[13/25][5220/9765] Loss_D: 0.1020 Loss_G: 0.0410 Convergence: 0.1030 k= 0.020497 lr = 0.0000105\n",
      "[13/25][5230/9765] Loss_D: 0.0980 Loss_G: 0.0406 Convergence: 0.0998 k= 0.020499 lr = 0.0000105\n",
      "[13/25][5240/9765] Loss_D: 0.1073 Loss_G: 0.0370 Convergence: 0.1142 k= 0.020497 lr = 0.0000105\n",
      "[13/25][5250/9765] Loss_D: 0.0924 Loss_G: 0.0369 Convergence: 0.0936 k= 0.020504 lr = 0.0000105\n",
      "[13/25][5260/9765] Loss_D: 0.0883 Loss_G: 0.0363 Convergence: 0.0898 k= 0.020527 lr = 0.0000105\n",
      "[13/25][5270/9765] Loss_D: 0.0971 Loss_G: 0.0396 Convergence: 0.0983 k= 0.020541 lr = 0.0000105\n",
      "[13/25][5280/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1026 k= 0.020553 lr = 0.0000105\n",
      "[13/25][5290/9765] Loss_D: 0.0874 Loss_G: 0.0366 Convergence: 0.0895 k= 0.020565 lr = 0.0000105\n",
      "[13/25][5300/9765] Loss_D: 0.0979 Loss_G: 0.0383 Convergence: 0.0999 k= 0.020563 lr = 0.0000105\n",
      "[13/25][5310/9765] Loss_D: 0.0909 Loss_G: 0.0396 Convergence: 0.0946 k= 0.020561 lr = 0.0000105\n",
      "[13/25][5320/9765] Loss_D: 0.0903 Loss_G: 0.0372 Convergence: 0.0918 k= 0.020558 lr = 0.0000105\n",
      "[13/25][5330/9765] Loss_D: 0.0919 Loss_G: 0.0380 Convergence: 0.0936 k= 0.020561 lr = 0.0000105\n",
      "[13/25][5340/9765] Loss_D: 0.1068 Loss_G: 0.0386 Convergence: 0.1120 k= 0.020578 lr = 0.0000105\n",
      "[13/25][5350/9765] Loss_D: 0.0982 Loss_G: 0.0399 Convergence: 0.0993 k= 0.020591 lr = 0.0000105\n",
      "[13/25][5360/9765] Loss_D: 0.1032 Loss_G: 0.0399 Convergence: 0.1057 k= 0.020587 lr = 0.0000105\n",
      "[13/25][5370/9765] Loss_D: 0.1062 Loss_G: 0.0408 Convergence: 0.1091 k= 0.020584 lr = 0.0000105\n",
      "[13/25][5380/9765] Loss_D: 0.1001 Loss_G: 0.0387 Convergence: 0.1026 k= 0.020576 lr = 0.0000105\n",
      "[13/25][5390/9765] Loss_D: 0.0835 Loss_G: 0.0412 Convergence: 0.0918 k= 0.020551 lr = 0.0000105\n",
      "[13/25][5400/9765] Loss_D: 0.1049 Loss_G: 0.0402 Convergence: 0.1078 k= 0.020555 lr = 0.0000105\n",
      "[13/25][5410/9765] Loss_D: 0.0916 Loss_G: 0.0382 Convergence: 0.0936 k= 0.020554 lr = 0.0000105\n",
      "[13/25][5420/9765] Loss_D: 0.1014 Loss_G: 0.0379 Convergence: 0.1052 k= 0.020563 lr = 0.0000105\n",
      "[13/25][5430/9765] Loss_D: 0.0935 Loss_G: 0.0400 Convergence: 0.0966 k= 0.020564 lr = 0.0000105\n",
      "[13/25][5440/9765] Loss_D: 0.1019 Loss_G: 0.0399 Convergence: 0.1038 k= 0.020567 lr = 0.0000105\n",
      "[13/25][5450/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0971 k= 0.020575 lr = 0.0000105\n",
      "[13/25][5460/9765] Loss_D: 0.0907 Loss_G: 0.0377 Convergence: 0.0926 k= 0.020569 lr = 0.0000105\n",
      "[13/25][5470/9765] Loss_D: 0.1059 Loss_G: 0.0408 Convergence: 0.1085 k= 0.020569 lr = 0.0000105\n",
      "[13/25][5480/9765] Loss_D: 0.1001 Loss_G: 0.0378 Convergence: 0.1034 k= 0.020561 lr = 0.0000105\n",
      "[13/25][5490/9765] Loss_D: 0.0912 Loss_G: 0.0381 Convergence: 0.0933 k= 0.020560 lr = 0.0000105\n",
      "[13/25][5500/9765] Loss_D: 0.0927 Loss_G: 0.0358 Convergence: 0.0950 k= 0.020576 lr = 0.0000105\n",
      "[13/25][5510/9765] Loss_D: 0.0948 Loss_G: 0.0361 Convergence: 0.0977 k= 0.020611 lr = 0.0000105\n",
      "[13/25][5520/9765] Loss_D: 0.1001 Loss_G: 0.0381 Convergence: 0.1030 k= 0.020649 lr = 0.0000105\n",
      "[13/25][5530/9765] Loss_D: 0.0939 Loss_G: 0.0409 Convergence: 0.0978 k= 0.020650 lr = 0.0000105\n",
      "[13/25][5540/9765] Loss_D: 0.1030 Loss_G: 0.0447 Convergence: 0.1071 k= 0.020624 lr = 0.0000105\n",
      "[13/25][5550/9765] Loss_D: 0.1081 Loss_G: 0.0440 Convergence: 0.1094 k= 0.020565 lr = 0.0000105\n",
      "[13/25][5560/9765] Loss_D: 0.1015 Loss_G: 0.0399 Convergence: 0.1033 k= 0.020530 lr = 0.0000105\n",
      "[13/25][5570/9765] Loss_D: 0.1048 Loss_G: 0.0396 Convergence: 0.1082 k= 0.020540 lr = 0.0000105\n",
      "[13/25][5580/9765] Loss_D: 0.0957 Loss_G: 0.0386 Convergence: 0.0965 k= 0.020546 lr = 0.0000105\n",
      "[13/25][5590/9765] Loss_D: 0.0941 Loss_G: 0.0359 Convergence: 0.0969 k= 0.020572 lr = 0.0000105\n",
      "[13/25][5600/9765] Loss_D: 0.0947 Loss_G: 0.0366 Convergence: 0.0970 k= 0.020578 lr = 0.0000105\n",
      "[13/25][5610/9765] Loss_D: 0.0893 Loss_G: 0.0375 Convergence: 0.0915 k= 0.020576 lr = 0.0000105\n",
      "[13/25][5620/9765] Loss_D: 0.0888 Loss_G: 0.0392 Convergence: 0.0930 k= 0.020579 lr = 0.0000105\n",
      "[13/25][5630/9765] Loss_D: 0.0878 Loss_G: 0.0415 Convergence: 0.0947 k= 0.020559 lr = 0.0000105\n",
      "[13/25][5640/9765] Loss_D: 0.0978 Loss_G: 0.0409 Convergence: 0.1001 k= 0.020543 lr = 0.0000105\n",
      "[13/25][5650/9765] Loss_D: 0.0978 Loss_G: 0.0385 Convergence: 0.0995 k= 0.020549 lr = 0.0000105\n",
      "[13/25][5660/9765] Loss_D: 0.0929 Loss_G: 0.0378 Convergence: 0.0940 k= 0.020564 lr = 0.0000105\n",
      "[13/25][5670/9765] Loss_D: 0.0966 Loss_G: 0.0408 Convergence: 0.0992 k= 0.020562 lr = 0.0000105\n",
      "[13/25][5680/9765] Loss_D: 0.0886 Loss_G: 0.0401 Convergence: 0.0937 k= 0.020562 lr = 0.0000105\n",
      "[13/25][5690/9765] Loss_D: 0.0872 Loss_G: 0.0401 Convergence: 0.0929 k= 0.020559 lr = 0.0000105\n",
      "[13/25][5700/9765] Loss_D: 0.1013 Loss_G: 0.0406 Convergence: 0.1023 k= 0.020551 lr = 0.0000105\n",
      "[13/25][5710/9765] Loss_D: 0.0969 Loss_G: 0.0382 Convergence: 0.0985 k= 0.020536 lr = 0.0000105\n",
      "[13/25][5720/9765] Loss_D: 0.1040 Loss_G: 0.0389 Convergence: 0.1079 k= 0.020539 lr = 0.0000105\n",
      "[13/25][5730/9765] Loss_D: 0.1048 Loss_G: 0.0394 Convergence: 0.1084 k= 0.020548 lr = 0.0000105\n",
      "[13/25][5740/9765] Loss_D: 0.0967 Loss_G: 0.0377 Convergence: 0.0988 k= 0.020560 lr = 0.0000105\n",
      "[13/25][5750/9765] Loss_D: 0.1091 Loss_G: 0.0383 Convergence: 0.1155 k= 0.020582 lr = 0.0000105\n",
      "[13/25][5760/9765] Loss_D: 0.0957 Loss_G: 0.0385 Convergence: 0.0966 k= 0.020590 lr = 0.0000105\n",
      "[13/25][5770/9765] Loss_D: 0.0962 Loss_G: 0.0344 Convergence: 0.1013 k= 0.020604 lr = 0.0000105\n",
      "[13/25][5780/9765] Loss_D: 0.1024 Loss_G: 0.0396 Convergence: 0.1049 k= 0.020622 lr = 0.0000105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][5790/9765] Loss_D: 0.0939 Loss_G: 0.0416 Convergence: 0.0984 k= 0.020610 lr = 0.0000105\n",
      "[13/25][5800/9765] Loss_D: 0.1075 Loss_G: 0.0409 Convergence: 0.1108 k= 0.020606 lr = 0.0000105\n",
      "[13/25][5810/9765] Loss_D: 0.1014 Loss_G: 0.0408 Convergence: 0.1023 k= 0.020590 lr = 0.0000105\n",
      "[13/25][5820/9765] Loss_D: 0.0907 Loss_G: 0.0395 Convergence: 0.0944 k= 0.020572 lr = 0.0000105\n",
      "[13/25][5830/9765] Loss_D: 0.0899 Loss_G: 0.0377 Convergence: 0.0921 k= 0.020593 lr = 0.0000105\n",
      "[13/25][5840/9765] Loss_D: 0.1017 Loss_G: 0.0390 Convergence: 0.1045 k= 0.020590 lr = 0.0000105\n",
      "[13/25][5850/9765] Loss_D: 0.0925 Loss_G: 0.0394 Convergence: 0.0954 k= 0.020585 lr = 0.0000105\n",
      "[13/25][5860/9765] Loss_D: 0.0899 Loss_G: 0.0401 Convergence: 0.0946 k= 0.020580 lr = 0.0000105\n",
      "[13/25][5870/9765] Loss_D: 0.1013 Loss_G: 0.0409 Convergence: 0.1021 k= 0.020574 lr = 0.0000105\n",
      "[13/25][5880/9765] Loss_D: 0.1028 Loss_G: 0.0388 Convergence: 0.1062 k= 0.020580 lr = 0.0000105\n",
      "[13/25][5890/9765] Loss_D: 0.0906 Loss_G: 0.0389 Convergence: 0.0937 k= 0.020574 lr = 0.0000105\n",
      "[13/25][5900/9765] Loss_D: 0.1034 Loss_G: 0.0392 Convergence: 0.1067 k= 0.020573 lr = 0.0000105\n",
      "[13/25][5910/9765] Loss_D: 0.1034 Loss_G: 0.0405 Convergence: 0.1054 k= 0.020579 lr = 0.0000105\n",
      "[13/25][5920/9765] Loss_D: 0.1021 Loss_G: 0.0377 Convergence: 0.1063 k= 0.020582 lr = 0.0000105\n",
      "[13/25][5930/9765] Loss_D: 0.0973 Loss_G: 0.0390 Convergence: 0.0983 k= 0.020585 lr = 0.0000105\n",
      "[13/25][5940/9765] Loss_D: 0.0986 Loss_G: 0.0395 Convergence: 0.0997 k= 0.020588 lr = 0.0000105\n",
      "[13/25][5950/9765] Loss_D: 0.0994 Loss_G: 0.0365 Convergence: 0.1037 k= 0.020587 lr = 0.0000105\n",
      "[13/25][5960/9765] Loss_D: 0.1001 Loss_G: 0.0376 Convergence: 0.1036 k= 0.020601 lr = 0.0000105\n",
      "[13/25][5970/9765] Loss_D: 0.0973 Loss_G: 0.0389 Convergence: 0.0985 k= 0.020605 lr = 0.0000105\n",
      "[13/25][5980/9765] Loss_D: 0.1024 Loss_G: 0.0387 Convergence: 0.1058 k= 0.020614 lr = 0.0000105\n",
      "[13/25][5990/9765] Loss_D: 0.0912 Loss_G: 0.0392 Convergence: 0.0944 k= 0.020602 lr = 0.0000105\n",
      "[13/25][6000/9765] Loss_D: 0.0975 Loss_G: 0.0427 Convergence: 0.1017 k= 0.020590 lr = 0.0000105\n",
      "[13/25][6010/9765] Loss_D: 0.1085 Loss_G: 0.0400 Convergence: 0.1130 k= 0.020581 lr = 0.0000105\n",
      "[13/25][6020/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0990 k= 0.020580 lr = 0.0000105\n",
      "[13/25][6030/9765] Loss_D: 0.0901 Loss_G: 0.0354 Convergence: 0.0918 k= 0.020579 lr = 0.0000105\n",
      "[13/25][6040/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0988 k= 0.020601 lr = 0.0000105\n",
      "[13/25][6050/9765] Loss_D: 0.0904 Loss_G: 0.0391 Convergence: 0.0938 k= 0.020598 lr = 0.0000105\n",
      "[13/25][6060/9765] Loss_D: 0.0988 Loss_G: 0.0405 Convergence: 0.1002 k= 0.020598 lr = 0.0000105\n",
      "[13/25][6070/9765] Loss_D: 0.0956 Loss_G: 0.0392 Convergence: 0.0971 k= 0.020591 lr = 0.0000105\n",
      "[13/25][6080/9765] Loss_D: 0.0982 Loss_G: 0.0404 Convergence: 0.0998 k= 0.020589 lr = 0.0000105\n",
      "[13/25][6090/9765] Loss_D: 0.1007 Loss_G: 0.0385 Convergence: 0.1036 k= 0.020587 lr = 0.0000105\n",
      "[13/25][6100/9765] Loss_D: 0.0914 Loss_G: 0.0389 Convergence: 0.0943 k= 0.020585 lr = 0.0000105\n",
      "[13/25][6110/9765] Loss_D: 0.1126 Loss_G: 0.0398 Convergence: 0.1190 k= 0.020601 lr = 0.0000105\n",
      "[13/25][6120/9765] Loss_D: 0.0963 Loss_G: 0.0403 Convergence: 0.0986 k= 0.020598 lr = 0.0000105\n",
      "[13/25][6130/9765] Loss_D: 0.0906 Loss_G: 0.0412 Convergence: 0.0961 k= 0.020576 lr = 0.0000105\n",
      "[13/25][6140/9765] Loss_D: 0.0952 Loss_G: 0.0427 Convergence: 0.1003 k= 0.020570 lr = 0.0000105\n",
      "[13/25][6150/9765] Loss_D: 0.0999 Loss_G: 0.0407 Convergence: 0.1012 k= 0.020536 lr = 0.0000105\n",
      "[13/25][6160/9765] Loss_D: 0.0904 Loss_G: 0.0375 Convergence: 0.0922 k= 0.020523 lr = 0.0000105\n",
      "[13/25][6170/9765] Loss_D: 0.0945 Loss_G: 0.0365 Convergence: 0.0968 k= 0.020530 lr = 0.0000105\n",
      "[13/25][6180/9765] Loss_D: 0.0921 Loss_G: 0.0383 Convergence: 0.0940 k= 0.020547 lr = 0.0000105\n",
      "[13/25][6190/9765] Loss_D: 0.1051 Loss_G: 0.0401 Convergence: 0.1082 k= 0.020558 lr = 0.0000105\n",
      "[13/25][6200/9765] Loss_D: 0.0967 Loss_G: 0.0400 Convergence: 0.0985 k= 0.020545 lr = 0.0000105\n",
      "[13/25][6210/9765] Loss_D: 0.0993 Loss_G: 0.0427 Convergence: 0.1027 k= 0.020521 lr = 0.0000105\n",
      "[13/25][6220/9765] Loss_D: 0.0999 Loss_G: 0.0389 Convergence: 0.1020 k= 0.020514 lr = 0.0000105\n",
      "[13/25][6230/9765] Loss_D: 0.1021 Loss_G: 0.0406 Convergence: 0.1034 k= 0.020502 lr = 0.0000105\n",
      "[13/25][6240/9765] Loss_D: 0.1000 Loss_G: 0.0404 Convergence: 0.1009 k= 0.020498 lr = 0.0000105\n",
      "[13/25][6250/9765] Loss_D: 0.0959 Loss_G: 0.0375 Convergence: 0.0978 k= 0.020510 lr = 0.0000105\n",
      "[13/25][6260/9765] Loss_D: 0.1015 Loss_G: 0.0373 Convergence: 0.1059 k= 0.020530 lr = 0.0000105\n",
      "[13/25][6270/9765] Loss_D: 0.0938 Loss_G: 0.0377 Convergence: 0.0947 k= 0.020530 lr = 0.0000105\n",
      "[13/25][6280/9765] Loss_D: 0.0910 Loss_G: 0.0406 Convergence: 0.0957 k= 0.020527 lr = 0.0000105\n",
      "[13/25][6290/9765] Loss_D: 0.0951 Loss_G: 0.0403 Convergence: 0.0978 k= 0.020520 lr = 0.0000105\n",
      "[13/25][6300/9765] Loss_D: 0.1015 Loss_G: 0.0424 Convergence: 0.1038 k= 0.020507 lr = 0.0000105\n",
      "[13/25][6310/9765] Loss_D: 0.0957 Loss_G: 0.0391 Convergence: 0.0970 k= 0.020487 lr = 0.0000105\n",
      "[13/25][6320/9765] Loss_D: 0.1003 Loss_G: 0.0387 Convergence: 0.1028 k= 0.020488 lr = 0.0000105\n",
      "[13/25][6330/9765] Loss_D: 0.0996 Loss_G: 0.0368 Convergence: 0.1037 k= 0.020503 lr = 0.0000105\n",
      "[13/25][6340/9765] Loss_D: 0.1014 Loss_G: 0.0372 Convergence: 0.1059 k= 0.020504 lr = 0.0000105\n",
      "[13/25][6350/9765] Loss_D: 0.0987 Loss_G: 0.0387 Convergence: 0.1006 k= 0.020509 lr = 0.0000105\n",
      "[13/25][6360/9765] Loss_D: 0.0933 Loss_G: 0.0355 Convergence: 0.0962 k= 0.020530 lr = 0.0000105\n",
      "[13/25][6370/9765] Loss_D: 0.0964 Loss_G: 0.0396 Convergence: 0.0979 k= 0.020539 lr = 0.0000105\n",
      "[13/25][6380/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0966 k= 0.020524 lr = 0.0000105\n",
      "[13/25][6390/9765] Loss_D: 0.0944 Loss_G: 0.0408 Convergence: 0.0980 k= 0.020525 lr = 0.0000105\n",
      "[13/25][6400/9765] Loss_D: 0.0893 Loss_G: 0.0395 Convergence: 0.0936 k= 0.020506 lr = 0.0000105\n",
      "[13/25][6410/9765] Loss_D: 0.0975 Loss_G: 0.0385 Convergence: 0.0991 k= 0.020530 lr = 0.0000105\n",
      "[13/25][6420/9765] Loss_D: 0.0916 Loss_G: 0.0375 Convergence: 0.0929 k= 0.020543 lr = 0.0000105\n",
      "[13/25][6430/9765] Loss_D: 0.0982 Loss_G: 0.0389 Convergence: 0.0998 k= 0.020538 lr = 0.0000105\n",
      "[13/25][6440/9765] Loss_D: 0.1040 Loss_G: 0.0350 Convergence: 0.1116 k= 0.020550 lr = 0.0000105\n",
      "[13/25][6450/9765] Loss_D: 0.1008 Loss_G: 0.0371 Convergence: 0.1050 k= 0.020571 lr = 0.0000105\n",
      "[13/25][6460/9765] Loss_D: 0.0931 Loss_G: 0.0366 Convergence: 0.0947 k= 0.020582 lr = 0.0000105\n",
      "[13/25][6470/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1000 k= 0.020586 lr = 0.0000105\n",
      "[13/25][6480/9765] Loss_D: 0.0967 Loss_G: 0.0394 Convergence: 0.0979 k= 0.020583 lr = 0.0000105\n",
      "[13/25][6490/9765] Loss_D: 0.0965 Loss_G: 0.0384 Convergence: 0.0978 k= 0.020586 lr = 0.0000105\n",
      "[13/25][6500/9765] Loss_D: 0.0864 Loss_G: 0.0377 Convergence: 0.0900 k= 0.020575 lr = 0.0000105\n",
      "[13/25][6510/9765] Loss_D: 0.0883 Loss_G: 0.0373 Convergence: 0.0907 k= 0.020581 lr = 0.0000105\n",
      "[13/25][6520/9765] Loss_D: 0.1068 Loss_G: 0.0412 Convergence: 0.1094 k= 0.020604 lr = 0.0000105\n",
      "[13/25][6530/9765] Loss_D: 0.0982 Loss_G: 0.0388 Convergence: 0.0998 k= 0.020607 lr = 0.0000105\n",
      "[13/25][6540/9765] Loss_D: 0.1016 Loss_G: 0.0419 Convergence: 0.1034 k= 0.020592 lr = 0.0000105\n",
      "[13/25][6550/9765] Loss_D: 0.1078 Loss_G: 0.0427 Convergence: 0.1095 k= 0.020569 lr = 0.0000105\n",
      "[13/25][6560/9765] Loss_D: 0.0896 Loss_G: 0.0393 Convergence: 0.0935 k= 0.020552 lr = 0.0000105\n",
      "[13/25][6570/9765] Loss_D: 0.1022 Loss_G: 0.0370 Convergence: 0.1071 k= 0.020568 lr = 0.0000105\n",
      "[13/25][6580/9765] Loss_D: 0.1037 Loss_G: 0.0383 Convergence: 0.1080 k= 0.020580 lr = 0.0000105\n",
      "[13/25][6590/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0951 k= 0.020594 lr = 0.0000105\n",
      "[13/25][6600/9765] Loss_D: 0.1020 Loss_G: 0.0404 Convergence: 0.1035 k= 0.020589 lr = 0.0000105\n",
      "[13/25][6610/9765] Loss_D: 0.0916 Loss_G: 0.0410 Convergence: 0.0965 k= 0.020583 lr = 0.0000105\n",
      "[13/25][6620/9765] Loss_D: 0.0884 Loss_G: 0.0373 Convergence: 0.0908 k= 0.020582 lr = 0.0000105\n",
      "[13/25][6630/9765] Loss_D: 0.0991 Loss_G: 0.0375 Convergence: 0.1023 k= 0.020596 lr = 0.0000105\n",
      "[13/25][6640/9765] Loss_D: 0.0963 Loss_G: 0.0396 Convergence: 0.0978 k= 0.020608 lr = 0.0000105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][6650/9765] Loss_D: 0.0986 Loss_G: 0.0416 Convergence: 0.1012 k= 0.020603 lr = 0.0000105\n",
      "[13/25][6660/9765] Loss_D: 0.1075 Loss_G: 0.0389 Convergence: 0.1128 k= 0.020603 lr = 0.0000105\n",
      "[13/25][6670/9765] Loss_D: 0.0991 Loss_G: 0.0374 Convergence: 0.1024 k= 0.020613 lr = 0.0000105\n",
      "[13/25][6680/9765] Loss_D: 0.0930 Loss_G: 0.0387 Convergence: 0.0950 k= 0.020618 lr = 0.0000105\n",
      "[13/25][6690/9765] Loss_D: 0.0956 Loss_G: 0.0390 Convergence: 0.0968 k= 0.020622 lr = 0.0000105\n",
      "[13/25][6700/9765] Loss_D: 0.1030 Loss_G: 0.0409 Convergence: 0.1044 k= 0.020630 lr = 0.0000105\n",
      "[13/25][6710/9765] Loss_D: 0.0959 Loss_G: 0.0411 Convergence: 0.0992 k= 0.020619 lr = 0.0000105\n",
      "[13/25][6720/9765] Loss_D: 0.0975 Loss_G: 0.0370 Convergence: 0.1006 k= 0.020606 lr = 0.0000105\n",
      "[13/25][6730/9765] Loss_D: 0.0940 Loss_G: 0.0352 Convergence: 0.0975 k= 0.020620 lr = 0.0000105\n",
      "[13/25][6740/9765] Loss_D: 0.0936 Loss_G: 0.0342 Convergence: 0.0979 k= 0.020650 lr = 0.0000105\n",
      "[13/25][6750/9765] Loss_D: 0.0895 Loss_G: 0.0370 Convergence: 0.0912 k= 0.020668 lr = 0.0000105\n",
      "[13/25][6760/9765] Loss_D: 0.0912 Loss_G: 0.0371 Convergence: 0.0924 k= 0.020680 lr = 0.0000105\n",
      "[13/25][6770/9765] Loss_D: 0.0984 Loss_G: 0.0434 Convergence: 0.1030 k= 0.020679 lr = 0.0000105\n",
      "[13/25][6780/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1031 k= 0.020659 lr = 0.0000105\n",
      "[13/25][6790/9765] Loss_D: 0.0927 Loss_G: 0.0389 Convergence: 0.0949 k= 0.020651 lr = 0.0000105\n",
      "[13/25][6800/9765] Loss_D: 0.1014 Loss_G: 0.0382 Convergence: 0.1049 k= 0.020643 lr = 0.0000105\n",
      "[13/25][6810/9765] Loss_D: 0.0939 Loss_G: 0.0373 Convergence: 0.0952 k= 0.020660 lr = 0.0000105\n",
      "[13/25][6820/9765] Loss_D: 0.0984 Loss_G: 0.0381 Convergence: 0.1007 k= 0.020654 lr = 0.0000105\n",
      "[13/25][6830/9765] Loss_D: 0.0921 Loss_G: 0.0386 Convergence: 0.0943 k= 0.020645 lr = 0.0000105\n",
      "[13/25][6840/9765] Loss_D: 0.0949 Loss_G: 0.0400 Convergence: 0.0975 k= 0.020643 lr = 0.0000105\n",
      "[13/25][6850/9765] Loss_D: 0.0942 Loss_G: 0.0404 Convergence: 0.0974 k= 0.020645 lr = 0.0000105\n",
      "[13/25][6860/9765] Loss_D: 0.0988 Loss_G: 0.0388 Convergence: 0.1006 k= 0.020644 lr = 0.0000105\n",
      "[13/25][6870/9765] Loss_D: 0.0934 Loss_G: 0.0410 Convergence: 0.0975 k= 0.020632 lr = 0.0000105\n",
      "[13/25][6880/9765] Loss_D: 0.0916 Loss_G: 0.0406 Convergence: 0.0961 k= 0.020621 lr = 0.0000105\n",
      "[13/25][6890/9765] Loss_D: 0.1039 Loss_G: 0.0393 Convergence: 0.1073 k= 0.020610 lr = 0.0000105\n",
      "[13/25][6900/9765] Loss_D: 0.0919 Loss_G: 0.0351 Convergence: 0.0946 k= 0.020631 lr = 0.0000105\n",
      "[13/25][6910/9765] Loss_D: 0.0914 Loss_G: 0.0375 Convergence: 0.0928 k= 0.020648 lr = 0.0000105\n",
      "[13/25][6920/9765] Loss_D: 0.1003 Loss_G: 0.0393 Convergence: 0.1022 k= 0.020655 lr = 0.0000105\n",
      "[13/25][6930/9765] Loss_D: 0.0989 Loss_G: 0.0387 Convergence: 0.1009 k= 0.020656 lr = 0.0000105\n",
      "[13/25][6940/9765] Loss_D: 0.0957 Loss_G: 0.0398 Convergence: 0.0977 k= 0.020644 lr = 0.0000105\n",
      "[13/25][6950/9765] Loss_D: 0.0993 Loss_G: 0.0410 Convergence: 0.1011 k= 0.020639 lr = 0.0000105\n",
      "[13/25][6960/9765] Loss_D: 0.1037 Loss_G: 0.0397 Convergence: 0.1065 k= 0.020629 lr = 0.0000105\n",
      "[13/25][6970/9765] Loss_D: 0.1016 Loss_G: 0.0383 Convergence: 0.1051 k= 0.020638 lr = 0.0000105\n",
      "[13/25][6980/9765] Loss_D: 0.0922 Loss_G: 0.0381 Convergence: 0.0939 k= 0.020650 lr = 0.0000105\n",
      "[13/25][6990/9765] Loss_D: 0.1066 Loss_G: 0.0417 Convergence: 0.1087 k= 0.020658 lr = 0.0000105\n",
      "[13/25][7000/9765] Loss_D: 0.0899 Loss_G: 0.0394 Convergence: 0.0938 k= 0.020648 lr = 0.0000105\n",
      "[13/25][7010/9765] Loss_D: 0.1032 Loss_G: 0.0392 Convergence: 0.1063 k= 0.020653 lr = 0.0000105\n",
      "[13/25][7020/9765] Loss_D: 0.0950 Loss_G: 0.0389 Convergence: 0.0964 k= 0.020664 lr = 0.0000105\n",
      "[13/25][7030/9765] Loss_D: 0.0988 Loss_G: 0.0394 Convergence: 0.1000 k= 0.020679 lr = 0.0000105\n",
      "[13/25][7040/9765] Loss_D: 0.0962 Loss_G: 0.0411 Convergence: 0.0993 k= 0.020684 lr = 0.0000105\n",
      "[13/25][7050/9765] Loss_D: 0.0993 Loss_G: 0.0380 Convergence: 0.1021 k= 0.020685 lr = 0.0000105\n",
      "[13/25][7060/9765] Loss_D: 0.0907 Loss_G: 0.0375 Convergence: 0.0924 k= 0.020681 lr = 0.0000105\n",
      "[13/25][7070/9765] Loss_D: 0.1054 Loss_G: 0.0369 Convergence: 0.1117 k= 0.020699 lr = 0.0000105\n",
      "[13/25][7080/9765] Loss_D: 0.0918 Loss_G: 0.0363 Convergence: 0.0933 k= 0.020706 lr = 0.0000105\n",
      "[13/25][7090/9765] Loss_D: 0.1094 Loss_G: 0.0373 Convergence: 0.1169 k= 0.020726 lr = 0.0000105\n",
      "[13/25][7100/9765] Loss_D: 0.0933 Loss_G: 0.0405 Convergence: 0.0970 k= 0.020730 lr = 0.0000105\n",
      "[13/25][7110/9765] Loss_D: 0.0970 Loss_G: 0.0393 Convergence: 0.0980 k= 0.020727 lr = 0.0000105\n",
      "[13/25][7120/9765] Loss_D: 0.0909 Loss_G: 0.0418 Convergence: 0.0969 k= 0.020722 lr = 0.0000105\n",
      "[13/25][7130/9765] Loss_D: 0.0882 Loss_G: 0.0378 Convergence: 0.0912 k= 0.020716 lr = 0.0000105\n",
      "[13/25][7140/9765] Loss_D: 0.0890 Loss_G: 0.0387 Convergence: 0.0926 k= 0.020728 lr = 0.0000105\n",
      "[13/25][7150/9765] Loss_D: 0.1073 Loss_G: 0.0382 Convergence: 0.1131 k= 0.020735 lr = 0.0000105\n",
      "[13/25][7160/9765] Loss_D: 0.0972 Loss_G: 0.0397 Convergence: 0.0985 k= 0.020740 lr = 0.0000105\n",
      "[13/25][7170/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0947 k= 0.020743 lr = 0.0000105\n",
      "[13/25][7180/9765] Loss_D: 0.0964 Loss_G: 0.0401 Convergence: 0.0984 k= 0.020737 lr = 0.0000105\n",
      "[13/25][7190/9765] Loss_D: 0.0988 Loss_G: 0.0397 Convergence: 0.0998 k= 0.020724 lr = 0.0000105\n",
      "[13/25][7200/9765] Loss_D: 0.0931 Loss_G: 0.0410 Convergence: 0.0974 k= 0.020711 lr = 0.0000105\n",
      "[13/25][7210/9765] Loss_D: 0.0912 Loss_G: 0.0364 Convergence: 0.0923 k= 0.020717 lr = 0.0000105\n",
      "[13/25][7220/9765] Loss_D: 0.0946 Loss_G: 0.0362 Convergence: 0.0972 k= 0.020745 lr = 0.0000105\n",
      "[13/25][7230/9765] Loss_D: 0.1002 Loss_G: 0.0381 Convergence: 0.1032 k= 0.020753 lr = 0.0000105\n",
      "[13/25][7240/9765] Loss_D: 0.0906 Loss_G: 0.0366 Convergence: 0.0914 k= 0.020767 lr = 0.0000105\n",
      "[13/25][7250/9765] Loss_D: 0.0933 Loss_G: 0.0384 Convergence: 0.0949 k= 0.020781 lr = 0.0000105\n",
      "[13/25][7260/9765] Loss_D: 0.1022 Loss_G: 0.0398 Convergence: 0.1044 k= 0.020776 lr = 0.0000105\n",
      "[13/25][7270/9765] Loss_D: 0.1025 Loss_G: 0.0421 Convergence: 0.1042 k= 0.020750 lr = 0.0000105\n",
      "[13/25][7280/9765] Loss_D: 0.0865 Loss_G: 0.0406 Convergence: 0.0930 k= 0.020705 lr = 0.0000105\n",
      "[13/25][7290/9765] Loss_D: 0.0946 Loss_G: 0.0372 Convergence: 0.0963 k= 0.020714 lr = 0.0000105\n",
      "[13/25][7300/9765] Loss_D: 0.0907 Loss_G: 0.0361 Convergence: 0.0919 k= 0.020731 lr = 0.0000105\n",
      "[13/25][7310/9765] Loss_D: 0.0992 Loss_G: 0.0382 Convergence: 0.1018 k= 0.020742 lr = 0.0000105\n",
      "[13/25][7320/9765] Loss_D: 0.0930 Loss_G: 0.0385 Convergence: 0.0948 k= 0.020745 lr = 0.0000105\n",
      "[13/25][7330/9765] Loss_D: 0.0907 Loss_G: 0.0391 Convergence: 0.0940 k= 0.020750 lr = 0.0000105\n",
      "[13/25][7340/9765] Loss_D: 0.0939 Loss_G: 0.0406 Convergence: 0.0975 k= 0.020745 lr = 0.0000105\n",
      "[13/25][7350/9765] Loss_D: 0.1013 Loss_G: 0.0450 Convergence: 0.1063 k= 0.020712 lr = 0.0000105\n",
      "[13/25][7360/9765] Loss_D: 0.0957 Loss_G: 0.0419 Convergence: 0.0998 k= 0.020664 lr = 0.0000105\n",
      "[13/25][7370/9765] Loss_D: 0.1028 Loss_G: 0.0397 Convergence: 0.1053 k= 0.020649 lr = 0.0000105\n",
      "[13/25][7380/9765] Loss_D: 0.0932 Loss_G: 0.0372 Convergence: 0.0944 k= 0.020636 lr = 0.0000105\n",
      "[13/25][7390/9765] Loss_D: 0.0994 Loss_G: 0.0367 Convergence: 0.1036 k= 0.020659 lr = 0.0000105\n",
      "[13/25][7400/9765] Loss_D: 0.0991 Loss_G: 0.0369 Convergence: 0.1028 k= 0.020675 lr = 0.0000105\n",
      "[13/25][7410/9765] Loss_D: 0.0948 Loss_G: 0.0403 Convergence: 0.0977 k= 0.020679 lr = 0.0000105\n",
      "[13/25][7420/9765] Loss_D: 0.0973 Loss_G: 0.0416 Convergence: 0.1005 k= 0.020652 lr = 0.0000105\n",
      "[13/25][7430/9765] Loss_D: 0.1114 Loss_G: 0.0415 Convergence: 0.1156 k= 0.020634 lr = 0.0000105\n",
      "[13/25][7440/9765] Loss_D: 0.0898 Loss_G: 0.0386 Convergence: 0.0930 k= 0.020617 lr = 0.0000105\n",
      "[13/25][7450/9765] Loss_D: 0.0904 Loss_G: 0.0396 Convergence: 0.0944 k= 0.020616 lr = 0.0000105\n",
      "[13/25][7460/9765] Loss_D: 0.0972 Loss_G: 0.0372 Convergence: 0.1000 k= 0.020632 lr = 0.0000105\n",
      "[13/25][7470/9765] Loss_D: 0.0912 Loss_G: 0.0409 Convergence: 0.0961 k= 0.020638 lr = 0.0000105\n",
      "[13/25][7480/9765] Loss_D: 0.1108 Loss_G: 0.0405 Convergence: 0.1158 k= 0.020646 lr = 0.0000105\n",
      "[13/25][7490/9765] Loss_D: 0.0934 Loss_G: 0.0392 Convergence: 0.0957 k= 0.020627 lr = 0.0000105\n",
      "[13/25][7500/9765] Loss_D: 0.0938 Loss_G: 0.0381 Convergence: 0.0948 k= 0.020633 lr = 0.0000105\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][7510/9765] Loss_D: 0.0988 Loss_G: 0.0366 Convergence: 0.1027 k= 0.020655 lr = 0.0000105\n",
      "[13/25][7520/9765] Loss_D: 0.1052 Loss_G: 0.0358 Convergence: 0.1124 k= 0.020668 lr = 0.0000105\n",
      "[13/25][7530/9765] Loss_D: 0.1019 Loss_G: 0.0390 Convergence: 0.1048 k= 0.020684 lr = 0.0000105\n",
      "[13/25][7540/9765] Loss_D: 0.0997 Loss_G: 0.0391 Convergence: 0.1016 k= 0.020695 lr = 0.0000105\n",
      "[13/25][7550/9765] Loss_D: 0.0918 Loss_G: 0.0377 Convergence: 0.0933 k= 0.020701 lr = 0.0000105\n",
      "[13/25][7560/9765] Loss_D: 0.0916 Loss_G: 0.0411 Convergence: 0.0965 k= 0.020709 lr = 0.0000105\n",
      "[13/25][7570/9765] Loss_D: 0.0948 Loss_G: 0.0369 Convergence: 0.0970 k= 0.020724 lr = 0.0000105\n",
      "[13/25][7580/9765] Loss_D: 0.1089 Loss_G: 0.0414 Convergence: 0.1123 k= 0.020730 lr = 0.0000105\n",
      "[13/25][7590/9765] Loss_D: 0.0978 Loss_G: 0.0395 Convergence: 0.0987 k= 0.020698 lr = 0.0000105\n",
      "[13/25][7600/9765] Loss_D: 0.0929 Loss_G: 0.0419 Convergence: 0.0981 k= 0.020691 lr = 0.0000105\n",
      "[13/25][7610/9765] Loss_D: 0.1006 Loss_G: 0.0377 Convergence: 0.1041 k= 0.020702 lr = 0.0000105\n",
      "[13/25][7620/9765] Loss_D: 0.0966 Loss_G: 0.0402 Convergence: 0.0987 k= 0.020707 lr = 0.0000105\n",
      "[13/25][7630/9765] Loss_D: 0.0884 Loss_G: 0.0402 Convergence: 0.0938 k= 0.020690 lr = 0.0000105\n",
      "[13/25][7640/9765] Loss_D: 0.1011 Loss_G: 0.0375 Convergence: 0.1051 k= 0.020690 lr = 0.0000105\n",
      "[13/25][7650/9765] Loss_D: 0.0894 Loss_G: 0.0390 Convergence: 0.0931 k= 0.020687 lr = 0.0000105\n",
      "[13/25][7660/9765] Loss_D: 0.1064 Loss_G: 0.0379 Convergence: 0.1120 k= 0.020701 lr = 0.0000105\n",
      "[13/25][7670/9765] Loss_D: 0.1014 Loss_G: 0.0381 Convergence: 0.1051 k= 0.020722 lr = 0.0000105\n",
      "[13/25][7680/9765] Loss_D: 0.1095 Loss_G: 0.0408 Convergence: 0.1136 k= 0.020717 lr = 0.0000105\n",
      "[13/25][7690/9765] Loss_D: 0.0996 Loss_G: 0.0408 Convergence: 0.1011 k= 0.020721 lr = 0.0000105\n",
      "[13/25][7700/9765] Loss_D: 0.0985 Loss_G: 0.0404 Convergence: 0.1000 k= 0.020700 lr = 0.0000105\n",
      "[13/25][7710/9765] Loss_D: 0.0951 Loss_G: 0.0436 Convergence: 0.1012 k= 0.020668 lr = 0.0000105\n",
      "[13/25][7720/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0972 k= 0.020658 lr = 0.0000105\n",
      "[13/25][7730/9765] Loss_D: 0.1023 Loss_G: 0.0364 Convergence: 0.1079 k= 0.020693 lr = 0.0000105\n",
      "[13/25][7740/9765] Loss_D: 0.0903 Loss_G: 0.0358 Convergence: 0.0917 k= 0.020715 lr = 0.0000105\n",
      "[13/25][7750/9765] Loss_D: 0.0906 Loss_G: 0.0378 Convergence: 0.0927 k= 0.020721 lr = 0.0000105\n",
      "[13/25][7760/9765] Loss_D: 0.0915 Loss_G: 0.0384 Convergence: 0.0938 k= 0.020724 lr = 0.0000105\n",
      "[13/25][7770/9765] Loss_D: 0.0933 Loss_G: 0.0379 Convergence: 0.0943 k= 0.020726 lr = 0.0000105\n",
      "[13/25][7780/9765] Loss_D: 0.0906 Loss_G: 0.0407 Convergence: 0.0956 k= 0.020709 lr = 0.0000105\n",
      "[13/25][7790/9765] Loss_D: 0.0886 Loss_G: 0.0396 Convergence: 0.0932 k= 0.020702 lr = 0.0000105\n",
      "[13/25][7800/9765] Loss_D: 0.0904 Loss_G: 0.0403 Convergence: 0.0951 k= 0.020697 lr = 0.0000105\n",
      "[13/25][7810/9765] Loss_D: 0.0995 Loss_G: 0.0359 Convergence: 0.1044 k= 0.020706 lr = 0.0000105\n",
      "[13/25][7820/9765] Loss_D: 0.0918 Loss_G: 0.0377 Convergence: 0.0933 k= 0.020709 lr = 0.0000105\n",
      "[13/25][7830/9765] Loss_D: 0.0889 Loss_G: 0.0408 Convergence: 0.0946 k= 0.020700 lr = 0.0000105\n",
      "[13/25][7840/9765] Loss_D: 0.1008 Loss_G: 0.0403 Convergence: 0.1020 k= 0.020705 lr = 0.0000105\n",
      "[13/25][7850/9765] Loss_D: 0.0941 Loss_G: 0.0393 Convergence: 0.0962 k= 0.020698 lr = 0.0000105\n",
      "[13/25][7860/9765] Loss_D: 0.0887 Loss_G: 0.0368 Convergence: 0.0905 k= 0.020708 lr = 0.0000105\n",
      "[13/25][7870/9765] Loss_D: 0.1053 Loss_G: 0.0404 Convergence: 0.1082 k= 0.020721 lr = 0.0000105\n",
      "[13/25][7880/9765] Loss_D: 0.0971 Loss_G: 0.0386 Convergence: 0.0985 k= 0.020726 lr = 0.0000105\n",
      "[13/25][7890/9765] Loss_D: 0.0927 Loss_G: 0.0403 Convergence: 0.0964 k= 0.020716 lr = 0.0000105\n",
      "[13/25][7900/9765] Loss_D: 0.1011 Loss_G: 0.0397 Convergence: 0.1030 k= 0.020716 lr = 0.0000105\n",
      "[13/25][7910/9765] Loss_D: 0.0966 Loss_G: 0.0426 Convergence: 0.1011 k= 0.020700 lr = 0.0000105\n",
      "[13/25][7920/9765] Loss_D: 0.1024 Loss_G: 0.0382 Convergence: 0.1062 k= 0.020686 lr = 0.0000105\n",
      "[13/25][7930/9765] Loss_D: 0.0975 Loss_G: 0.0391 Convergence: 0.0985 k= 0.020698 lr = 0.0000105\n",
      "[13/25][7940/9765] Loss_D: 0.0984 Loss_G: 0.0388 Convergence: 0.1002 k= 0.020699 lr = 0.0000105\n",
      "[13/25][7950/9765] Loss_D: 0.1002 Loss_G: 0.0382 Convergence: 0.1032 k= 0.020720 lr = 0.0000105\n",
      "[13/25][7960/9765] Loss_D: 0.0907 Loss_G: 0.0375 Convergence: 0.0924 k= 0.020723 lr = 0.0000105\n",
      "[13/25][7970/9765] Loss_D: 0.0932 Loss_G: 0.0386 Convergence: 0.0950 k= 0.020743 lr = 0.0000105\n",
      "[13/25][7980/9765] Loss_D: 0.0961 Loss_G: 0.0414 Convergence: 0.0995 k= 0.020733 lr = 0.0000105\n",
      "[13/25][7990/9765] Loss_D: 0.0966 Loss_G: 0.0417 Convergence: 0.1001 k= 0.020735 lr = 0.0000105\n",
      "[13/25][8000/9765] Loss_D: 0.0960 Loss_G: 0.0466 Convergence: 0.1048 k= 0.020690 lr = 0.0000105\n",
      "[13/25][8010/9765] Loss_D: 0.0995 Loss_G: 0.0434 Convergence: 0.1036 k= 0.020641 lr = 0.0000105\n",
      "[13/25][8020/9765] Loss_D: 0.0996 Loss_G: 0.0374 Convergence: 0.1031 k= 0.020629 lr = 0.0000105\n",
      "[13/25][8030/9765] Loss_D: 0.1007 Loss_G: 0.0369 Convergence: 0.1051 k= 0.020652 lr = 0.0000105\n",
      "[13/25][8040/9765] Loss_D: 0.0982 Loss_G: 0.0378 Convergence: 0.1008 k= 0.020677 lr = 0.0000105\n",
      "[13/25][8050/9765] Loss_D: 0.0968 Loss_G: 0.0356 Convergence: 0.1010 k= 0.020708 lr = 0.0000105\n",
      "[13/25][8060/9765] Loss_D: 0.0980 Loss_G: 0.0392 Convergence: 0.0991 k= 0.020722 lr = 0.0000099\n",
      "[13/25][8070/9765] Loss_D: 0.0954 Loss_G: 0.0403 Convergence: 0.0980 k= 0.020714 lr = 0.0000099\n",
      "[13/25][8080/9765] Loss_D: 0.0902 Loss_G: 0.0392 Convergence: 0.0937 k= 0.020711 lr = 0.0000099\n",
      "[13/25][8090/9765] Loss_D: 0.0903 Loss_G: 0.0427 Convergence: 0.0975 k= 0.020697 lr = 0.0000099\n",
      "[13/25][8100/9765] Loss_D: 0.0955 Loss_G: 0.0409 Convergence: 0.0987 k= 0.020679 lr = 0.0000099\n",
      "[13/25][8110/9765] Loss_D: 0.0849 Loss_G: 0.0382 Convergence: 0.0896 k= 0.020661 lr = 0.0000099\n",
      "[13/25][8120/9765] Loss_D: 0.1026 Loss_G: 0.0409 Convergence: 0.1039 k= 0.020657 lr = 0.0000099\n",
      "[13/25][8130/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0981 k= 0.020653 lr = 0.0000099\n",
      "[13/25][8140/9765] Loss_D: 0.1026 Loss_G: 0.0385 Convergence: 0.1062 k= 0.020670 lr = 0.0000099\n",
      "[13/25][8150/9765] Loss_D: 0.0927 Loss_G: 0.0372 Convergence: 0.0936 k= 0.020687 lr = 0.0000099\n",
      "[13/25][8160/9765] Loss_D: 0.1009 Loss_G: 0.0386 Convergence: 0.1038 k= 0.020677 lr = 0.0000099\n",
      "[13/25][8170/9765] Loss_D: 0.0958 Loss_G: 0.0413 Convergence: 0.0993 k= 0.020674 lr = 0.0000099\n",
      "[13/25][8180/9765] Loss_D: 0.0929 Loss_G: 0.0382 Convergence: 0.0944 k= 0.020669 lr = 0.0000099\n",
      "[13/25][8190/9765] Loss_D: 0.0905 Loss_G: 0.0392 Convergence: 0.0940 k= 0.020667 lr = 0.0000099\n",
      "[13/25][8200/9765] Loss_D: 0.0992 Loss_G: 0.0417 Convergence: 0.1017 k= 0.020654 lr = 0.0000099\n",
      "[13/25][8210/9765] Loss_D: 0.0996 Loss_G: 0.0389 Convergence: 0.1017 k= 0.020653 lr = 0.0000099\n",
      "[13/25][8220/9765] Loss_D: 0.1028 Loss_G: 0.0385 Convergence: 0.1065 k= 0.020654 lr = 0.0000099\n",
      "[13/25][8230/9765] Loss_D: 0.0980 Loss_G: 0.0383 Convergence: 0.1000 k= 0.020657 lr = 0.0000099\n",
      "[13/25][8240/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0991 k= 0.020661 lr = 0.0000099\n",
      "[13/25][8250/9765] Loss_D: 0.0941 Loss_G: 0.0375 Convergence: 0.0954 k= 0.020668 lr = 0.0000099\n",
      "[13/25][8260/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1006 k= 0.020677 lr = 0.0000099\n",
      "[13/25][8270/9765] Loss_D: 0.0970 Loss_G: 0.0394 Convergence: 0.0981 k= 0.020677 lr = 0.0000099\n",
      "[13/25][8280/9765] Loss_D: 0.0998 Loss_G: 0.0402 Convergence: 0.1006 k= 0.020672 lr = 0.0000099\n",
      "[13/25][8290/9765] Loss_D: 0.0946 Loss_G: 0.0405 Convergence: 0.0977 k= 0.020662 lr = 0.0000099\n",
      "[13/25][8300/9765] Loss_D: 0.0985 Loss_G: 0.0393 Convergence: 0.0998 k= 0.020668 lr = 0.0000099\n",
      "[13/25][8310/9765] Loss_D: 0.0954 Loss_G: 0.0391 Convergence: 0.0968 k= 0.020667 lr = 0.0000099\n",
      "[13/25][8320/9765] Loss_D: 0.0972 Loss_G: 0.0404 Convergence: 0.0992 k= 0.020662 lr = 0.0000099\n",
      "[13/25][8330/9765] Loss_D: 0.0883 Loss_G: 0.0398 Convergence: 0.0933 k= 0.020648 lr = 0.0000099\n",
      "[13/25][8340/9765] Loss_D: 0.1000 Loss_G: 0.0398 Convergence: 0.1013 k= 0.020652 lr = 0.0000099\n",
      "[13/25][8350/9765] Loss_D: 0.0900 Loss_G: 0.0386 Convergence: 0.0930 k= 0.020659 lr = 0.0000099\n",
      "[13/25][8360/9765] Loss_D: 0.1001 Loss_G: 0.0405 Convergence: 0.1011 k= 0.020649 lr = 0.0000099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][8370/9765] Loss_D: 0.0940 Loss_G: 0.0387 Convergence: 0.0956 k= 0.020622 lr = 0.0000099\n",
      "[13/25][8380/9765] Loss_D: 0.0991 Loss_G: 0.0373 Convergence: 0.1025 k= 0.020626 lr = 0.0000099\n",
      "[13/25][8390/9765] Loss_D: 0.1034 Loss_G: 0.0386 Convergence: 0.1073 k= 0.020647 lr = 0.0000099\n",
      "[13/25][8400/9765] Loss_D: 0.1142 Loss_G: 0.0400 Convergence: 0.1210 k= 0.020654 lr = 0.0000099\n",
      "[13/25][8410/9765] Loss_D: 0.0993 Loss_G: 0.0406 Convergence: 0.1007 k= 0.020636 lr = 0.0000099\n",
      "[13/25][8420/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1033 k= 0.020632 lr = 0.0000099\n",
      "[13/25][8430/9765] Loss_D: 0.1011 Loss_G: 0.0380 Convergence: 0.1046 k= 0.020640 lr = 0.0000099\n",
      "[13/25][8440/9765] Loss_D: 0.0996 Loss_G: 0.0414 Convergence: 0.1017 k= 0.020646 lr = 0.0000099\n",
      "[13/25][8450/9765] Loss_D: 0.0915 Loss_G: 0.0404 Convergence: 0.0958 k= 0.020629 lr = 0.0000099\n",
      "[13/25][8460/9765] Loss_D: 0.0991 Loss_G: 0.0406 Convergence: 0.1006 k= 0.020619 lr = 0.0000099\n",
      "[13/25][8470/9765] Loss_D: 0.0913 Loss_G: 0.0403 Convergence: 0.0956 k= 0.020607 lr = 0.0000099\n",
      "[13/25][8480/9765] Loss_D: 0.1031 Loss_G: 0.0382 Convergence: 0.1071 k= 0.020604 lr = 0.0000099\n",
      "[13/25][8490/9765] Loss_D: 0.0924 Loss_G: 0.0365 Convergence: 0.0940 k= 0.020593 lr = 0.0000099\n",
      "[13/25][8500/9765] Loss_D: 0.0924 Loss_G: 0.0384 Convergence: 0.0943 k= 0.020608 lr = 0.0000099\n",
      "[13/25][8510/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1003 k= 0.020609 lr = 0.0000099\n",
      "[13/25][8520/9765] Loss_D: 0.0984 Loss_G: 0.0425 Convergence: 0.1021 k= 0.020596 lr = 0.0000099\n",
      "[13/25][8530/9765] Loss_D: 0.0927 Loss_G: 0.0391 Convergence: 0.0951 k= 0.020586 lr = 0.0000099\n",
      "[13/25][8540/9765] Loss_D: 0.1057 Loss_G: 0.0391 Convergence: 0.1100 k= 0.020581 lr = 0.0000099\n",
      "[13/25][8550/9765] Loss_D: 0.0949 Loss_G: 0.0377 Convergence: 0.0962 k= 0.020587 lr = 0.0000099\n",
      "[13/25][8560/9765] Loss_D: 0.0951 Loss_G: 0.0392 Convergence: 0.0968 k= 0.020606 lr = 0.0000099\n",
      "[13/25][8570/9765] Loss_D: 0.1025 Loss_G: 0.0413 Convergence: 0.1034 k= 0.020588 lr = 0.0000099\n",
      "[13/25][8580/9765] Loss_D: 0.1001 Loss_G: 0.0364 Convergence: 0.1047 k= 0.020586 lr = 0.0000099\n",
      "[13/25][8590/9765] Loss_D: 0.0978 Loss_G: 0.0370 Convergence: 0.1009 k= 0.020598 lr = 0.0000099\n",
      "[13/25][8600/9765] Loss_D: 0.0959 Loss_G: 0.0385 Convergence: 0.0969 k= 0.020604 lr = 0.0000099\n",
      "[13/25][8610/9765] Loss_D: 0.0951 Loss_G: 0.0398 Convergence: 0.0973 k= 0.020609 lr = 0.0000099\n",
      "[13/25][8620/9765] Loss_D: 0.0948 Loss_G: 0.0378 Convergence: 0.0960 k= 0.020622 lr = 0.0000099\n",
      "[13/25][8630/9765] Loss_D: 0.0949 Loss_G: 0.0403 Convergence: 0.0977 k= 0.020611 lr = 0.0000099\n",
      "[13/25][8640/9765] Loss_D: 0.1015 Loss_G: 0.0387 Convergence: 0.1045 k= 0.020602 lr = 0.0000099\n",
      "[13/25][8650/9765] Loss_D: 0.1091 Loss_G: 0.0397 Convergence: 0.1141 k= 0.020609 lr = 0.0000099\n",
      "[13/25][8660/9765] Loss_D: 0.1004 Loss_G: 0.0397 Convergence: 0.1020 k= 0.020611 lr = 0.0000099\n",
      "[13/25][8670/9765] Loss_D: 0.0939 Loss_G: 0.0408 Convergence: 0.0976 k= 0.020610 lr = 0.0000099\n",
      "[13/25][8680/9765] Loss_D: 0.1041 Loss_G: 0.0383 Convergence: 0.1085 k= 0.020623 lr = 0.0000099\n",
      "[13/25][8690/9765] Loss_D: 0.1002 Loss_G: 0.0398 Convergence: 0.1016 k= 0.020631 lr = 0.0000099\n",
      "[13/25][8700/9765] Loss_D: 0.1040 Loss_G: 0.0350 Convergence: 0.1115 k= 0.020671 lr = 0.0000099\n",
      "[13/25][8710/9765] Loss_D: 0.1000 Loss_G: 0.0404 Convergence: 0.1010 k= 0.020687 lr = 0.0000099\n",
      "[13/25][8720/9765] Loss_D: 0.0930 Loss_G: 0.0462 Convergence: 0.1026 k= 0.020625 lr = 0.0000099\n",
      "[13/25][8730/9765] Loss_D: 0.0924 Loss_G: 0.0458 Convergence: 0.1018 k= 0.020560 lr = 0.0000099\n",
      "[13/25][8740/9765] Loss_D: 0.0918 Loss_G: 0.0424 Convergence: 0.0981 k= 0.020499 lr = 0.0000099\n",
      "[13/25][8750/9765] Loss_D: 0.1051 Loss_G: 0.0371 Convergence: 0.1111 k= 0.020512 lr = 0.0000099\n",
      "[13/25][8760/9765] Loss_D: 0.1006 Loss_G: 0.0355 Convergence: 0.1063 k= 0.020529 lr = 0.0000099\n",
      "[13/25][8770/9765] Loss_D: 0.0962 Loss_G: 0.0357 Convergence: 0.1001 k= 0.020574 lr = 0.0000099\n",
      "[13/25][8780/9765] Loss_D: 0.0996 Loss_G: 0.0380 Convergence: 0.1025 k= 0.020592 lr = 0.0000099\n",
      "[13/25][8790/9765] Loss_D: 0.0944 Loss_G: 0.0388 Convergence: 0.0959 k= 0.020602 lr = 0.0000099\n",
      "[13/25][8800/9765] Loss_D: 0.1006 Loss_G: 0.0410 Convergence: 0.1018 k= 0.020596 lr = 0.0000099\n",
      "[13/25][8810/9765] Loss_D: 0.0981 Loss_G: 0.0409 Convergence: 0.1003 k= 0.020570 lr = 0.0000099\n",
      "[13/25][8820/9765] Loss_D: 0.0946 Loss_G: 0.0407 Convergence: 0.0979 k= 0.020559 lr = 0.0000099\n",
      "[13/25][8830/9765] Loss_D: 0.0849 Loss_G: 0.0383 Convergence: 0.0898 k= 0.020541 lr = 0.0000099\n",
      "[13/25][8840/9765] Loss_D: 0.0931 Loss_G: 0.0351 Convergence: 0.0962 k= 0.020553 lr = 0.0000099\n",
      "[13/25][8850/9765] Loss_D: 0.1028 Loss_G: 0.0374 Convergence: 0.1076 k= 0.020586 lr = 0.0000099\n",
      "[13/25][8860/9765] Loss_D: 0.0923 Loss_G: 0.0355 Convergence: 0.0949 k= 0.020602 lr = 0.0000099\n",
      "[13/25][8870/9765] Loss_D: 0.0974 Loss_G: 0.0379 Convergence: 0.0996 k= 0.020623 lr = 0.0000099\n",
      "[13/25][8880/9765] Loss_D: 0.0971 Loss_G: 0.0400 Convergence: 0.0988 k= 0.020617 lr = 0.0000099\n",
      "[13/25][8890/9765] Loss_D: 0.1005 Loss_G: 0.0390 Convergence: 0.1029 k= 0.020606 lr = 0.0000099\n",
      "[13/25][8900/9765] Loss_D: 0.1006 Loss_G: 0.0413 Convergence: 0.1021 k= 0.020615 lr = 0.0000099\n",
      "[13/25][8910/9765] Loss_D: 0.0962 Loss_G: 0.0397 Convergence: 0.0979 k= 0.020602 lr = 0.0000099\n",
      "[13/25][8920/9765] Loss_D: 0.1052 Loss_G: 0.0400 Convergence: 0.1083 k= 0.020611 lr = 0.0000099\n",
      "[13/25][8930/9765] Loss_D: 0.0960 Loss_G: 0.0387 Convergence: 0.0968 k= 0.020610 lr = 0.0000099\n",
      "[13/25][8940/9765] Loss_D: 0.0956 Loss_G: 0.0386 Convergence: 0.0965 k= 0.020600 lr = 0.0000099\n",
      "[13/25][8950/9765] Loss_D: 0.0981 Loss_G: 0.0358 Convergence: 0.1026 k= 0.020617 lr = 0.0000099\n",
      "[13/25][8960/9765] Loss_D: 0.0993 Loss_G: 0.0402 Convergence: 0.1003 k= 0.020629 lr = 0.0000099\n",
      "[13/25][8970/9765] Loss_D: 0.1034 Loss_G: 0.0413 Convergence: 0.1046 k= 0.020616 lr = 0.0000099\n",
      "[13/25][8980/9765] Loss_D: 0.0920 Loss_G: 0.0402 Convergence: 0.0958 k= 0.020601 lr = 0.0000099\n",
      "[13/25][8990/9765] Loss_D: 0.0961 Loss_G: 0.0394 Convergence: 0.0976 k= 0.020605 lr = 0.0000099\n",
      "[13/25][9000/9765] Loss_D: 0.0973 Loss_G: 0.0417 Convergence: 0.1006 k= 0.020605 lr = 0.0000099\n",
      "[13/25][9010/9765] Loss_D: 0.0994 Loss_G: 0.0385 Convergence: 0.1018 k= 0.020621 lr = 0.0000099\n",
      "[13/25][9020/9765] Loss_D: 0.0913 Loss_G: 0.0377 Convergence: 0.0930 k= 0.020644 lr = 0.0000099\n",
      "[13/25][9030/9765] Loss_D: 0.0935 Loss_G: 0.0407 Convergence: 0.0973 k= 0.020651 lr = 0.0000099\n",
      "[13/25][9040/9765] Loss_D: 0.0924 Loss_G: 0.0432 Convergence: 0.0992 k= 0.020638 lr = 0.0000099\n",
      "[13/25][9050/9765] Loss_D: 0.0970 Loss_G: 0.0424 Convergence: 0.1012 k= 0.020580 lr = 0.0000099\n",
      "[13/25][9060/9765] Loss_D: 0.0952 Loss_G: 0.0405 Convergence: 0.0981 k= 0.020531 lr = 0.0000099\n",
      "[13/25][9070/9765] Loss_D: 0.0956 Loss_G: 0.0366 Convergence: 0.0983 k= 0.020535 lr = 0.0000099\n",
      "[13/25][9080/9765] Loss_D: 0.0862 Loss_G: 0.0366 Convergence: 0.0888 k= 0.020570 lr = 0.0000099\n",
      "[13/25][9090/9765] Loss_D: 0.0963 Loss_G: 0.0370 Convergence: 0.0988 k= 0.020594 lr = 0.0000099\n",
      "[13/25][9100/9765] Loss_D: 0.0986 Loss_G: 0.0399 Convergence: 0.0995 k= 0.020626 lr = 0.0000099\n",
      "[13/25][9110/9765] Loss_D: 0.0962 Loss_G: 0.0402 Convergence: 0.0984 k= 0.020617 lr = 0.0000099\n",
      "[13/25][9120/9765] Loss_D: 0.1052 Loss_G: 0.0383 Convergence: 0.1100 k= 0.020607 lr = 0.0000099\n",
      "[13/25][9130/9765] Loss_D: 0.0917 Loss_G: 0.0384 Convergence: 0.0939 k= 0.020599 lr = 0.0000099\n",
      "[13/25][9140/9765] Loss_D: 0.1019 Loss_G: 0.0368 Convergence: 0.1069 k= 0.020612 lr = 0.0000099\n",
      "[13/25][9150/9765] Loss_D: 0.0928 Loss_G: 0.0384 Convergence: 0.0946 k= 0.020635 lr = 0.0000099\n",
      "[13/25][9160/9765] Loss_D: 0.0996 Loss_G: 0.0380 Convergence: 0.1025 k= 0.020643 lr = 0.0000099\n",
      "[13/25][9170/9765] Loss_D: 0.0915 Loss_G: 0.0385 Convergence: 0.0939 k= 0.020635 lr = 0.0000099\n",
      "[13/25][9180/9765] Loss_D: 0.0895 Loss_G: 0.0381 Convergence: 0.0923 k= 0.020630 lr = 0.0000099\n",
      "[13/25][9190/9765] Loss_D: 0.0917 Loss_G: 0.0405 Convergence: 0.0960 k= 0.020625 lr = 0.0000099\n",
      "[13/25][9200/9765] Loss_D: 0.1010 Loss_G: 0.0406 Convergence: 0.1020 k= 0.020615 lr = 0.0000099\n",
      "[13/25][9210/9765] Loss_D: 0.0959 Loss_G: 0.0373 Convergence: 0.0981 k= 0.020616 lr = 0.0000099\n",
      "[13/25][9220/9765] Loss_D: 0.0934 Loss_G: 0.0364 Convergence: 0.0955 k= 0.020629 lr = 0.0000099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/25][9230/9765] Loss_D: 0.0977 Loss_G: 0.0365 Convergence: 0.1012 k= 0.020654 lr = 0.0000099\n",
      "[13/25][9240/9765] Loss_D: 0.0992 Loss_G: 0.0399 Convergence: 0.1001 k= 0.020662 lr = 0.0000099\n",
      "[13/25][9250/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0948 k= 0.020642 lr = 0.0000099\n",
      "[13/25][9260/9765] Loss_D: 0.0985 Loss_G: 0.0397 Convergence: 0.0994 k= 0.020624 lr = 0.0000099\n",
      "[13/25][9270/9765] Loss_D: 0.0971 Loss_G: 0.0378 Convergence: 0.0993 k= 0.020646 lr = 0.0000099\n",
      "[13/25][9280/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0994 k= 0.020648 lr = 0.0000099\n",
      "[13/25][9290/9765] Loss_D: 0.0958 Loss_G: 0.0369 Convergence: 0.0982 k= 0.020667 lr = 0.0000099\n",
      "[13/25][9300/9765] Loss_D: 0.0891 Loss_G: 0.0367 Convergence: 0.0906 k= 0.020676 lr = 0.0000099\n",
      "[13/25][9310/9765] Loss_D: 0.0960 Loss_G: 0.0372 Convergence: 0.0982 k= 0.020695 lr = 0.0000099\n",
      "[13/25][9320/9765] Loss_D: 0.0977 Loss_G: 0.0381 Convergence: 0.0998 k= 0.020682 lr = 0.0000099\n",
      "[13/25][9330/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0995 k= 0.020688 lr = 0.0000099\n",
      "[13/25][9340/9765] Loss_D: 0.0911 Loss_G: 0.0378 Convergence: 0.0930 k= 0.020691 lr = 0.0000099\n",
      "[13/25][9350/9765] Loss_D: 0.1012 Loss_G: 0.0384 Convergence: 0.1044 k= 0.020713 lr = 0.0000099\n",
      "[13/25][9360/9765] Loss_D: 0.0979 Loss_G: 0.0383 Convergence: 0.0999 k= 0.020723 lr = 0.0000099\n",
      "[13/25][9370/9765] Loss_D: 0.0938 Loss_G: 0.0376 Convergence: 0.0949 k= 0.020736 lr = 0.0000099\n",
      "[13/25][9380/9765] Loss_D: 0.0890 Loss_G: 0.0389 Convergence: 0.0927 k= 0.020729 lr = 0.0000099\n",
      "[13/25][9390/9765] Loss_D: 0.0979 Loss_G: 0.0395 Convergence: 0.0987 k= 0.020724 lr = 0.0000099\n",
      "[13/25][9400/9765] Loss_D: 0.1057 Loss_G: 0.0402 Convergence: 0.1088 k= 0.020714 lr = 0.0000099\n",
      "[13/25][9410/9765] Loss_D: 0.0918 Loss_G: 0.0367 Convergence: 0.0929 k= 0.020704 lr = 0.0000099\n",
      "[13/25][9420/9765] Loss_D: 0.0880 Loss_G: 0.0388 Convergence: 0.0921 k= 0.020704 lr = 0.0000099\n",
      "[13/25][9430/9765] Loss_D: 0.0908 Loss_G: 0.0380 Convergence: 0.0930 k= 0.020714 lr = 0.0000099\n",
      "[13/25][9440/9765] Loss_D: 0.0902 Loss_G: 0.0386 Convergence: 0.0933 k= 0.020708 lr = 0.0000099\n",
      "[13/25][9450/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0987 k= 0.020707 lr = 0.0000099\n",
      "[13/25][9460/9765] Loss_D: 0.0922 Loss_G: 0.0403 Convergence: 0.0961 k= 0.020704 lr = 0.0000099\n",
      "[13/25][9470/9765] Loss_D: 0.1074 Loss_G: 0.0424 Convergence: 0.1091 k= 0.020711 lr = 0.0000099\n",
      "[13/25][9480/9765] Loss_D: 0.0878 Loss_G: 0.0390 Convergence: 0.0922 k= 0.020683 lr = 0.0000099\n",
      "[13/25][9490/9765] Loss_D: 0.1051 Loss_G: 0.0391 Convergence: 0.1093 k= 0.020675 lr = 0.0000099\n",
      "[13/25][9500/9765] Loss_D: 0.0999 Loss_G: 0.0382 Convergence: 0.1027 k= 0.020670 lr = 0.0000099\n",
      "[13/25][9510/9765] Loss_D: 0.0931 Loss_G: 0.0364 Convergence: 0.0950 k= 0.020675 lr = 0.0000099\n",
      "[13/25][9520/9765] Loss_D: 0.0951 Loss_G: 0.0392 Convergence: 0.0968 k= 0.020685 lr = 0.0000099\n",
      "[13/25][9530/9765] Loss_D: 0.1018 Loss_G: 0.0380 Convergence: 0.1057 k= 0.020689 lr = 0.0000099\n",
      "[13/25][9540/9765] Loss_D: 0.0965 Loss_G: 0.0372 Convergence: 0.0990 k= 0.020682 lr = 0.0000099\n",
      "[13/25][9550/9765] Loss_D: 0.0986 Loss_G: 0.0410 Convergence: 0.1006 k= 0.020686 lr = 0.0000099\n",
      "[13/25][9560/9765] Loss_D: 0.0963 Loss_G: 0.0404 Convergence: 0.0987 k= 0.020680 lr = 0.0000099\n",
      "[13/25][9570/9765] Loss_D: 0.0991 Loss_G: 0.0357 Convergence: 0.1041 k= 0.020685 lr = 0.0000099\n",
      "[13/25][9580/9765] Loss_D: 0.0913 Loss_G: 0.0384 Convergence: 0.0936 k= 0.020689 lr = 0.0000099\n",
      "[13/25][9590/9765] Loss_D: 0.0869 Loss_G: 0.0373 Convergence: 0.0899 k= 0.020702 lr = 0.0000099\n",
      "[13/25][9600/9765] Loss_D: 0.0856 Loss_G: 0.0391 Convergence: 0.0910 k= 0.020706 lr = 0.0000099\n",
      "[13/25][9610/9765] Loss_D: 0.0978 Loss_G: 0.0398 Convergence: 0.0989 k= 0.020718 lr = 0.0000099\n",
      "[13/25][9620/9765] Loss_D: 0.1014 Loss_G: 0.0400 Convergence: 0.1031 k= 0.020732 lr = 0.0000099\n",
      "[13/25][9630/9765] Loss_D: 0.0974 Loss_G: 0.0391 Convergence: 0.0984 k= 0.020731 lr = 0.0000099\n",
      "[13/25][9640/9765] Loss_D: 0.0927 Loss_G: 0.0375 Convergence: 0.0936 k= 0.020723 lr = 0.0000099\n",
      "[13/25][9650/9765] Loss_D: 0.0899 Loss_G: 0.0409 Convergence: 0.0953 k= 0.020727 lr = 0.0000099\n",
      "[13/25][9660/9765] Loss_D: 0.0919 Loss_G: 0.0400 Convergence: 0.0957 k= 0.020731 lr = 0.0000099\n",
      "[13/25][9670/9765] Loss_D: 0.1044 Loss_G: 0.0378 Convergence: 0.1095 k= 0.020739 lr = 0.0000099\n",
      "[13/25][9680/9765] Loss_D: 0.0967 Loss_G: 0.0381 Convergence: 0.0984 k= 0.020745 lr = 0.0000099\n",
      "[13/25][9690/9765] Loss_D: 0.0968 Loss_G: 0.0398 Convergence: 0.0984 k= 0.020741 lr = 0.0000099\n",
      "[13/25][9700/9765] Loss_D: 0.0941 Loss_G: 0.0417 Convergence: 0.0987 k= 0.020736 lr = 0.0000099\n",
      "[13/25][9710/9765] Loss_D: 0.0944 Loss_G: 0.0382 Convergence: 0.0953 k= 0.020724 lr = 0.0000099\n",
      "[13/25][9720/9765] Loss_D: 0.0921 Loss_G: 0.0402 Convergence: 0.0960 k= 0.020725 lr = 0.0000099\n",
      "[13/25][9730/9765] Loss_D: 0.0876 Loss_G: 0.0394 Convergence: 0.0924 k= 0.020732 lr = 0.0000099\n",
      "[13/25][9740/9765] Loss_D: 0.1027 Loss_G: 0.0404 Convergence: 0.1046 k= 0.020750 lr = 0.0000099\n",
      "[13/25][9750/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0972 k= 0.020761 lr = 0.0000099\n",
      "[13/25][9760/9765] Loss_D: 0.1025 Loss_G: 0.0398 Convergence: 0.1049 k= 0.020751 lr = 0.0000099\n",
      "[14/25][0/9765] Loss_D: 0.1094 Loss_G: 0.0436 Convergence: 0.1107 k= 0.020748 lr = 0.0000099\n",
      "[14/25][10/9765] Loss_D: 0.0910 Loss_G: 0.0424 Convergence: 0.0975 k= 0.020716 lr = 0.0000099\n",
      "[14/25][20/9765] Loss_D: 0.1015 Loss_G: 0.0402 Convergence: 0.1031 k= 0.020688 lr = 0.0000099\n",
      "[14/25][30/9765] Loss_D: 0.1039 Loss_G: 0.0365 Convergence: 0.1100 k= 0.020690 lr = 0.0000099\n",
      "[14/25][40/9765] Loss_D: 0.1043 Loss_G: 0.0407 Convergence: 0.1064 k= 0.020689 lr = 0.0000099\n",
      "[14/25][50/9765] Loss_D: 0.1014 Loss_G: 0.0389 Convergence: 0.1041 k= 0.020689 lr = 0.0000099\n",
      "[14/25][60/9765] Loss_D: 0.0977 Loss_G: 0.0384 Convergence: 0.0994 k= 0.020685 lr = 0.0000099\n",
      "[14/25][70/9765] Loss_D: 0.0927 Loss_G: 0.0389 Convergence: 0.0950 k= 0.020699 lr = 0.0000099\n",
      "[14/25][80/9765] Loss_D: 0.0902 Loss_G: 0.0394 Convergence: 0.0940 k= 0.020698 lr = 0.0000099\n",
      "[14/25][90/9765] Loss_D: 0.0981 Loss_G: 0.0378 Convergence: 0.1005 k= 0.020700 lr = 0.0000099\n",
      "[14/25][100/9765] Loss_D: 0.0968 Loss_G: 0.0419 Convergence: 0.1005 k= 0.020695 lr = 0.0000099\n",
      "[14/25][110/9765] Loss_D: 0.0925 Loss_G: 0.0379 Convergence: 0.0939 k= 0.020686 lr = 0.0000099\n",
      "[14/25][120/9765] Loss_D: 0.1055 Loss_G: 0.0410 Convergence: 0.1079 k= 0.020682 lr = 0.0000099\n",
      "[14/25][130/9765] Loss_D: 0.0949 Loss_G: 0.0402 Convergence: 0.0976 k= 0.020674 lr = 0.0000099\n",
      "[14/25][140/9765] Loss_D: 0.0963 Loss_G: 0.0383 Convergence: 0.0975 k= 0.020678 lr = 0.0000099\n",
      "[14/25][150/9765] Loss_D: 0.0953 Loss_G: 0.0372 Convergence: 0.0972 k= 0.020691 lr = 0.0000099\n",
      "[14/25][160/9765] Loss_D: 0.0981 Loss_G: 0.0391 Convergence: 0.0993 k= 0.020712 lr = 0.0000099\n",
      "[14/25][170/9765] Loss_D: 0.0887 Loss_G: 0.0369 Convergence: 0.0906 k= 0.020709 lr = 0.0000099\n",
      "[14/25][180/9765] Loss_D: 0.0972 Loss_G: 0.0377 Convergence: 0.0996 k= 0.020714 lr = 0.0000099\n",
      "[14/25][190/9765] Loss_D: 0.0979 Loss_G: 0.0399 Convergence: 0.0991 k= 0.020708 lr = 0.0000099\n",
      "[14/25][200/9765] Loss_D: 0.0882 Loss_G: 0.0375 Convergence: 0.0910 k= 0.020715 lr = 0.0000099\n",
      "[14/25][210/9765] Loss_D: 0.0983 Loss_G: 0.0387 Convergence: 0.1001 k= 0.020721 lr = 0.0000099\n",
      "[14/25][220/9765] Loss_D: 0.1076 Loss_G: 0.0388 Convergence: 0.1129 k= 0.020730 lr = 0.0000099\n",
      "[14/25][230/9765] Loss_D: 0.0970 Loss_G: 0.0356 Convergence: 0.1013 k= 0.020746 lr = 0.0000099\n",
      "[14/25][240/9765] Loss_D: 0.0942 Loss_G: 0.0370 Convergence: 0.0960 k= 0.020767 lr = 0.0000099\n",
      "[14/25][250/9765] Loss_D: 0.0940 Loss_G: 0.0378 Convergence: 0.0949 k= 0.020759 lr = 0.0000099\n",
      "[14/25][260/9765] Loss_D: 0.0901 Loss_G: 0.0389 Convergence: 0.0934 k= 0.020752 lr = 0.0000099\n",
      "[14/25][270/9765] Loss_D: 0.0871 Loss_G: 0.0382 Convergence: 0.0909 k= 0.020746 lr = 0.0000099\n",
      "[14/25][280/9765] Loss_D: 0.0938 Loss_G: 0.0369 Convergence: 0.0954 k= 0.020755 lr = 0.0000099\n",
      "[14/25][290/9765] Loss_D: 0.1039 Loss_G: 0.0392 Convergence: 0.1074 k= 0.020746 lr = 0.0000099\n",
      "[14/25][300/9765] Loss_D: 0.1087 Loss_G: 0.0407 Convergence: 0.1127 k= 0.020748 lr = 0.0000099\n",
      "[14/25][310/9765] Loss_D: 0.0975 Loss_G: 0.0378 Convergence: 0.0998 k= 0.020753 lr = 0.0000099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][320/9765] Loss_D: 0.1009 Loss_G: 0.0407 Convergence: 0.1017 k= 0.020762 lr = 0.0000099\n",
      "[14/25][330/9765] Loss_D: 0.0930 Loss_G: 0.0363 Convergence: 0.0950 k= 0.020774 lr = 0.0000099\n",
      "[14/25][340/9765] Loss_D: 0.0993 Loss_G: 0.0400 Convergence: 0.1002 k= 0.020777 lr = 0.0000099\n",
      "[14/25][350/9765] Loss_D: 0.0892 Loss_G: 0.0368 Convergence: 0.0908 k= 0.020771 lr = 0.0000099\n",
      "[14/25][360/9765] Loss_D: 0.0946 Loss_G: 0.0384 Convergence: 0.0956 k= 0.020787 lr = 0.0000099\n",
      "[14/25][370/9765] Loss_D: 0.1001 Loss_G: 0.0392 Convergence: 0.1020 k= 0.020784 lr = 0.0000099\n",
      "[14/25][380/9765] Loss_D: 0.0927 Loss_G: 0.0375 Convergence: 0.0936 k= 0.020784 lr = 0.0000099\n",
      "[14/25][390/9765] Loss_D: 0.0934 Loss_G: 0.0404 Convergence: 0.0969 k= 0.020790 lr = 0.0000099\n",
      "[14/25][400/9765] Loss_D: 0.0897 Loss_G: 0.0378 Convergence: 0.0921 k= 0.020782 lr = 0.0000099\n",
      "[14/25][410/9765] Loss_D: 0.0968 Loss_G: 0.0379 Convergence: 0.0986 k= 0.020783 lr = 0.0000099\n",
      "[14/25][420/9765] Loss_D: 0.1003 Loss_G: 0.0393 Convergence: 0.1023 k= 0.020777 lr = 0.0000099\n",
      "[14/25][430/9765] Loss_D: 0.0928 Loss_G: 0.0375 Convergence: 0.0937 k= 0.020774 lr = 0.0000099\n",
      "[14/25][440/9765] Loss_D: 0.0971 Loss_G: 0.0426 Convergence: 0.1014 k= 0.020765 lr = 0.0000099\n",
      "[14/25][450/9765] Loss_D: 0.0977 Loss_G: 0.0418 Convergence: 0.1009 k= 0.020751 lr = 0.0000099\n",
      "[14/25][460/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0993 k= 0.020740 lr = 0.0000099\n",
      "[14/25][470/9765] Loss_D: 0.0984 Loss_G: 0.0377 Convergence: 0.1012 k= 0.020736 lr = 0.0000099\n",
      "[14/25][480/9765] Loss_D: 0.1022 Loss_G: 0.0413 Convergence: 0.1031 k= 0.020750 lr = 0.0000099\n",
      "[14/25][490/9765] Loss_D: 0.0878 Loss_G: 0.0382 Convergence: 0.0914 k= 0.020752 lr = 0.0000099\n",
      "[14/25][500/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0956 k= 0.020752 lr = 0.0000099\n",
      "[14/25][510/9765] Loss_D: 0.0868 Loss_G: 0.0389 Convergence: 0.0915 k= 0.020749 lr = 0.0000099\n",
      "[14/25][520/9765] Loss_D: 0.1010 Loss_G: 0.0375 Convergence: 0.1050 k= 0.020751 lr = 0.0000099\n",
      "[14/25][530/9765] Loss_D: 0.0917 Loss_G: 0.0384 Convergence: 0.0939 k= 0.020764 lr = 0.0000099\n",
      "[14/25][540/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0979 k= 0.020757 lr = 0.0000099\n",
      "[14/25][550/9765] Loss_D: 0.0913 Loss_G: 0.0388 Convergence: 0.0940 k= 0.020758 lr = 0.0000099\n",
      "[14/25][560/9765] Loss_D: 0.0921 Loss_G: 0.0394 Convergence: 0.0952 k= 0.020760 lr = 0.0000099\n",
      "[14/25][570/9765] Loss_D: 0.0979 Loss_G: 0.0384 Convergence: 0.0998 k= 0.020741 lr = 0.0000099\n",
      "[14/25][580/9765] Loss_D: 0.0947 Loss_G: 0.0396 Convergence: 0.0969 k= 0.020731 lr = 0.0000099\n",
      "[14/25][590/9765] Loss_D: 0.0903 Loss_G: 0.0382 Convergence: 0.0929 k= 0.020725 lr = 0.0000099\n",
      "[14/25][600/9765] Loss_D: 0.1009 Loss_G: 0.0416 Convergence: 0.1026 k= 0.020712 lr = 0.0000099\n",
      "[14/25][610/9765] Loss_D: 0.0983 Loss_G: 0.0389 Convergence: 0.0998 k= 0.020698 lr = 0.0000099\n",
      "[14/25][620/9765] Loss_D: 0.1016 Loss_G: 0.0389 Convergence: 0.1045 k= 0.020699 lr = 0.0000099\n",
      "[14/25][630/9765] Loss_D: 0.1018 Loss_G: 0.0391 Convergence: 0.1045 k= 0.020698 lr = 0.0000099\n",
      "[14/25][640/9765] Loss_D: 0.0864 Loss_G: 0.0380 Convergence: 0.0903 k= 0.020705 lr = 0.0000099\n",
      "[14/25][650/9765] Loss_D: 0.0972 Loss_G: 0.0407 Convergence: 0.0995 k= 0.020720 lr = 0.0000099\n",
      "[14/25][660/9765] Loss_D: 0.0987 Loss_G: 0.0424 Convergence: 0.1022 k= 0.020699 lr = 0.0000099\n",
      "[14/25][670/9765] Loss_D: 0.0953 Loss_G: 0.0439 Convergence: 0.1016 k= 0.020652 lr = 0.0000099\n",
      "[14/25][680/9765] Loss_D: 0.1033 Loss_G: 0.0428 Convergence: 0.1053 k= 0.020624 lr = 0.0000099\n",
      "[14/25][690/9765] Loss_D: 0.1017 Loss_G: 0.0419 Convergence: 0.1035 k= 0.020597 lr = 0.0000099\n",
      "[14/25][700/9765] Loss_D: 0.1005 Loss_G: 0.0415 Convergence: 0.1023 k= 0.020588 lr = 0.0000099\n",
      "[14/25][710/9765] Loss_D: 0.0893 Loss_G: 0.0367 Convergence: 0.0908 k= 0.020581 lr = 0.0000099\n",
      "[14/25][720/9765] Loss_D: 0.0909 Loss_G: 0.0374 Convergence: 0.0925 k= 0.020594 lr = 0.0000099\n",
      "[14/25][730/9765] Loss_D: 0.1013 Loss_G: 0.0363 Convergence: 0.1065 k= 0.020615 lr = 0.0000099\n",
      "[14/25][740/9765] Loss_D: 0.0915 Loss_G: 0.0397 Convergence: 0.0952 k= 0.020617 lr = 0.0000099\n",
      "[14/25][750/9765] Loss_D: 0.1002 Loss_G: 0.0420 Convergence: 0.1026 k= 0.020607 lr = 0.0000099\n",
      "[14/25][760/9765] Loss_D: 0.1026 Loss_G: 0.0448 Convergence: 0.1069 k= 0.020586 lr = 0.0000099\n",
      "[14/25][770/9765] Loss_D: 0.0899 Loss_G: 0.0390 Convergence: 0.0934 k= 0.020571 lr = 0.0000099\n",
      "[14/25][780/9765] Loss_D: 0.0945 Loss_G: 0.0412 Convergence: 0.0983 k= 0.020571 lr = 0.0000099\n",
      "[14/25][790/9765] Loss_D: 0.0954 Loss_G: 0.0385 Convergence: 0.0962 k= 0.020563 lr = 0.0000099\n",
      "[14/25][800/9765] Loss_D: 0.0935 Loss_G: 0.0384 Convergence: 0.0950 k= 0.020566 lr = 0.0000099\n",
      "[14/25][810/9765] Loss_D: 0.0998 Loss_G: 0.0405 Convergence: 0.1009 k= 0.020574 lr = 0.0000099\n",
      "[14/25][820/9765] Loss_D: 0.0926 Loss_G: 0.0399 Convergence: 0.0960 k= 0.020570 lr = 0.0000099\n",
      "[14/25][830/9765] Loss_D: 0.0941 Loss_G: 0.0389 Convergence: 0.0959 k= 0.020564 lr = 0.0000099\n",
      "[14/25][840/9765] Loss_D: 0.0851 Loss_G: 0.0375 Convergence: 0.0890 k= 0.020559 lr = 0.0000099\n",
      "[14/25][850/9765] Loss_D: 0.0961 Loss_G: 0.0381 Convergence: 0.0975 k= 0.020564 lr = 0.0000099\n",
      "[14/25][860/9765] Loss_D: 0.0959 Loss_G: 0.0382 Convergence: 0.0972 k= 0.020575 lr = 0.0000099\n",
      "[14/25][870/9765] Loss_D: 0.0959 Loss_G: 0.0392 Convergence: 0.0973 k= 0.020584 lr = 0.0000099\n",
      "[14/25][880/9765] Loss_D: 0.0957 Loss_G: 0.0381 Convergence: 0.0970 k= 0.020584 lr = 0.0000099\n",
      "[14/25][890/9765] Loss_D: 0.1048 Loss_G: 0.0390 Convergence: 0.1089 k= 0.020593 lr = 0.0000099\n",
      "[14/25][900/9765] Loss_D: 0.0930 Loss_G: 0.0365 Convergence: 0.0948 k= 0.020607 lr = 0.0000099\n",
      "[14/25][910/9765] Loss_D: 0.0897 Loss_G: 0.0382 Convergence: 0.0926 k= 0.020609 lr = 0.0000099\n",
      "[14/25][920/9765] Loss_D: 0.0825 Loss_G: 0.0396 Convergence: 0.0896 k= 0.020594 lr = 0.0000099\n",
      "[14/25][930/9765] Loss_D: 0.0905 Loss_G: 0.0395 Convergence: 0.0942 k= 0.020589 lr = 0.0000099\n",
      "[14/25][940/9765] Loss_D: 0.0947 Loss_G: 0.0384 Convergence: 0.0957 k= 0.020599 lr = 0.0000099\n",
      "[14/25][950/9765] Loss_D: 0.0961 Loss_G: 0.0370 Convergence: 0.0986 k= 0.020600 lr = 0.0000099\n",
      "[14/25][960/9765] Loss_D: 0.1059 Loss_G: 0.0384 Convergence: 0.1110 k= 0.020610 lr = 0.0000099\n",
      "[14/25][970/9765] Loss_D: 0.0980 Loss_G: 0.0395 Convergence: 0.0988 k= 0.020608 lr = 0.0000099\n",
      "[14/25][980/9765] Loss_D: 0.0953 Loss_G: 0.0410 Convergence: 0.0987 k= 0.020598 lr = 0.0000099\n",
      "[14/25][990/9765] Loss_D: 0.0994 Loss_G: 0.0419 Convergence: 0.1021 k= 0.020582 lr = 0.0000099\n",
      "[14/25][1000/9765] Loss_D: 0.1085 Loss_G: 0.0429 Convergence: 0.1102 k= 0.020545 lr = 0.0000099\n",
      "[14/25][1010/9765] Loss_D: 0.0976 Loss_G: 0.0418 Convergence: 0.1008 k= 0.020525 lr = 0.0000099\n",
      "[14/25][1020/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0964 k= 0.020528 lr = 0.0000099\n",
      "[14/25][1030/9765] Loss_D: 0.0933 Loss_G: 0.0370 Convergence: 0.0948 k= 0.020538 lr = 0.0000099\n",
      "[14/25][1040/9765] Loss_D: 0.1013 Loss_G: 0.0369 Convergence: 0.1060 k= 0.020560 lr = 0.0000099\n",
      "[14/25][1050/9765] Loss_D: 0.0987 Loss_G: 0.0395 Convergence: 0.0999 k= 0.020575 lr = 0.0000099\n",
      "[14/25][1060/9765] Loss_D: 0.1022 Loss_G: 0.0416 Convergence: 0.1035 k= 0.020574 lr = 0.0000099\n",
      "[14/25][1070/9765] Loss_D: 0.1027 Loss_G: 0.0427 Convergence: 0.1049 k= 0.020551 lr = 0.0000099\n",
      "[14/25][1080/9765] Loss_D: 0.1045 Loss_G: 0.0390 Convergence: 0.1085 k= 0.020537 lr = 0.0000099\n",
      "[14/25][1090/9765] Loss_D: 0.0956 Loss_G: 0.0411 Convergence: 0.0990 k= 0.020527 lr = 0.0000099\n",
      "[14/25][1100/9765] Loss_D: 0.1021 Loss_G: 0.0417 Convergence: 0.1035 k= 0.020524 lr = 0.0000099\n",
      "[14/25][1110/9765] Loss_D: 0.0994 Loss_G: 0.0403 Convergence: 0.1004 k= 0.020517 lr = 0.0000099\n",
      "[14/25][1120/9765] Loss_D: 0.0979 Loss_G: 0.0406 Convergence: 0.0999 k= 0.020523 lr = 0.0000099\n",
      "[14/25][1130/9765] Loss_D: 0.0913 Loss_G: 0.0406 Convergence: 0.0958 k= 0.020503 lr = 0.0000099\n",
      "[14/25][1140/9765] Loss_D: 0.0954 Loss_G: 0.0388 Convergence: 0.0965 k= 0.020503 lr = 0.0000099\n",
      "[14/25][1150/9765] Loss_D: 0.0928 Loss_G: 0.0390 Convergence: 0.0952 k= 0.020505 lr = 0.0000099\n",
      "[14/25][1160/9765] Loss_D: 0.0987 Loss_G: 0.0377 Convergence: 0.1014 k= 0.020509 lr = 0.0000099\n",
      "[14/25][1170/9765] Loss_D: 0.0875 Loss_G: 0.0396 Convergence: 0.0926 k= 0.020503 lr = 0.0000099\n",
      "[14/25][1180/9765] Loss_D: 0.1058 Loss_G: 0.0431 Convergence: 0.1071 k= 0.020504 lr = 0.0000099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][1190/9765] Loss_D: 0.0939 Loss_G: 0.0381 Convergence: 0.0949 k= 0.020494 lr = 0.0000099\n",
      "[14/25][1200/9765] Loss_D: 0.1021 Loss_G: 0.0384 Convergence: 0.1057 k= 0.020507 lr = 0.0000099\n",
      "[14/25][1210/9765] Loss_D: 0.0937 Loss_G: 0.0375 Convergence: 0.0948 k= 0.020518 lr = 0.0000099\n",
      "[14/25][1220/9765] Loss_D: 0.1039 Loss_G: 0.0386 Convergence: 0.1080 k= 0.020534 lr = 0.0000099\n",
      "[14/25][1230/9765] Loss_D: 0.1088 Loss_G: 0.0379 Convergence: 0.1154 k= 0.020542 lr = 0.0000099\n",
      "[14/25][1240/9765] Loss_D: 0.0844 Loss_G: 0.0365 Convergence: 0.0877 k= 0.020550 lr = 0.0000099\n",
      "[14/25][1250/9765] Loss_D: 0.1112 Loss_G: 0.0374 Convergence: 0.1194 k= 0.020564 lr = 0.0000099\n",
      "[14/25][1260/9765] Loss_D: 0.0961 Loss_G: 0.0401 Convergence: 0.0983 k= 0.020564 lr = 0.0000099\n",
      "[14/25][1270/9765] Loss_D: 0.1015 Loss_G: 0.0377 Convergence: 0.1054 k= 0.020569 lr = 0.0000099\n",
      "[14/25][1280/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1023 k= 0.020557 lr = 0.0000099\n",
      "[14/25][1290/9765] Loss_D: 0.0920 Loss_G: 0.0403 Convergence: 0.0960 k= 0.020555 lr = 0.0000094\n",
      "[14/25][1300/9765] Loss_D: 0.0975 Loss_G: 0.0401 Convergence: 0.0990 k= 0.020556 lr = 0.0000094\n",
      "[14/25][1310/9765] Loss_D: 0.0918 Loss_G: 0.0378 Convergence: 0.0933 k= 0.020539 lr = 0.0000094\n",
      "[14/25][1320/9765] Loss_D: 0.0929 Loss_G: 0.0408 Convergence: 0.0970 k= 0.020541 lr = 0.0000094\n",
      "[14/25][1330/9765] Loss_D: 0.0989 Loss_G: 0.0403 Convergence: 0.1002 k= 0.020528 lr = 0.0000094\n",
      "[14/25][1340/9765] Loss_D: 0.0896 Loss_G: 0.0402 Convergence: 0.0944 k= 0.020507 lr = 0.0000094\n",
      "[14/25][1350/9765] Loss_D: 0.1021 Loss_G: 0.0416 Convergence: 0.1033 k= 0.020505 lr = 0.0000094\n",
      "[14/25][1360/9765] Loss_D: 0.0965 Loss_G: 0.0382 Convergence: 0.0980 k= 0.020501 lr = 0.0000094\n",
      "[14/25][1370/9765] Loss_D: 0.0999 Loss_G: 0.0378 Convergence: 0.1030 k= 0.020515 lr = 0.0000094\n",
      "[14/25][1380/9765] Loss_D: 0.0934 Loss_G: 0.0372 Convergence: 0.0947 k= 0.020529 lr = 0.0000094\n",
      "[14/25][1390/9765] Loss_D: 0.0908 Loss_G: 0.0400 Convergence: 0.0949 k= 0.020543 lr = 0.0000094\n",
      "[14/25][1400/9765] Loss_D: 0.0974 Loss_G: 0.0369 Convergence: 0.1005 k= 0.020534 lr = 0.0000094\n",
      "[14/25][1410/9765] Loss_D: 0.1040 Loss_G: 0.0416 Convergence: 0.1051 k= 0.020518 lr = 0.0000094\n",
      "[14/25][1420/9765] Loss_D: 0.1017 Loss_G: 0.0398 Convergence: 0.1037 k= 0.020494 lr = 0.0000094\n",
      "[14/25][1430/9765] Loss_D: 0.0939 Loss_G: 0.0424 Convergence: 0.0993 k= 0.020456 lr = 0.0000094\n",
      "[14/25][1440/9765] Loss_D: 0.1038 Loss_G: 0.0427 Convergence: 0.1055 k= 0.020437 lr = 0.0000094\n",
      "[14/25][1450/9765] Loss_D: 0.0989 Loss_G: 0.0415 Convergence: 0.1013 k= 0.020440 lr = 0.0000094\n",
      "[14/25][1460/9765] Loss_D: 0.0915 Loss_G: 0.0374 Convergence: 0.0927 k= 0.020448 lr = 0.0000094\n",
      "[14/25][1470/9765] Loss_D: 0.1037 Loss_G: 0.0388 Convergence: 0.1075 k= 0.020461 lr = 0.0000094\n",
      "[14/25][1480/9765] Loss_D: 0.0937 Loss_G: 0.0397 Convergence: 0.0964 k= 0.020473 lr = 0.0000094\n",
      "[14/25][1490/9765] Loss_D: 0.1009 Loss_G: 0.0405 Convergence: 0.1019 k= 0.020463 lr = 0.0000094\n",
      "[14/25][1500/9765] Loss_D: 0.0883 Loss_G: 0.0407 Convergence: 0.0942 k= 0.020443 lr = 0.0000094\n",
      "[14/25][1510/9765] Loss_D: 0.1020 Loss_G: 0.0408 Convergence: 0.1032 k= 0.020434 lr = 0.0000094\n",
      "[14/25][1520/9765] Loss_D: 0.0990 Loss_G: 0.0384 Convergence: 0.1013 k= 0.020424 lr = 0.0000094\n",
      "[14/25][1530/9765] Loss_D: 0.1023 Loss_G: 0.0361 Convergence: 0.1082 k= 0.020437 lr = 0.0000094\n",
      "[14/25][1540/9765] Loss_D: 0.0982 Loss_G: 0.0354 Convergence: 0.1031 k= 0.020450 lr = 0.0000094\n",
      "[14/25][1550/9765] Loss_D: 0.1054 Loss_G: 0.0394 Convergence: 0.1092 k= 0.020469 lr = 0.0000094\n",
      "[14/25][1560/9765] Loss_D: 0.0947 Loss_G: 0.0400 Convergence: 0.0973 k= 0.020459 lr = 0.0000094\n",
      "[14/25][1570/9765] Loss_D: 0.1005 Loss_G: 0.0415 Convergence: 0.1023 k= 0.020450 lr = 0.0000094\n",
      "[14/25][1580/9765] Loss_D: 0.1095 Loss_G: 0.0397 Convergence: 0.1148 k= 0.020437 lr = 0.0000094\n",
      "[14/25][1590/9765] Loss_D: 0.1023 Loss_G: 0.0379 Convergence: 0.1064 k= 0.020427 lr = 0.0000094\n",
      "[14/25][1600/9765] Loss_D: 0.0919 Loss_G: 0.0394 Convergence: 0.0950 k= 0.020433 lr = 0.0000094\n",
      "[14/25][1610/9765] Loss_D: 0.0865 Loss_G: 0.0398 Convergence: 0.0923 k= 0.020414 lr = 0.0000094\n",
      "[14/25][1620/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.0997 k= 0.020416 lr = 0.0000094\n",
      "[14/25][1630/9765] Loss_D: 0.1010 Loss_G: 0.0408 Convergence: 0.1019 k= 0.020408 lr = 0.0000094\n",
      "[14/25][1640/9765] Loss_D: 0.0977 Loss_G: 0.0403 Convergence: 0.0995 k= 0.020385 lr = 0.0000094\n",
      "[14/25][1650/9765] Loss_D: 0.1019 Loss_G: 0.0401 Convergence: 0.1038 k= 0.020391 lr = 0.0000094\n",
      "[14/25][1660/9765] Loss_D: 0.1042 Loss_G: 0.0371 Convergence: 0.1098 k= 0.020399 lr = 0.0000094\n",
      "[14/25][1670/9765] Loss_D: 0.0986 Loss_G: 0.0382 Convergence: 0.1008 k= 0.020418 lr = 0.0000094\n",
      "[14/25][1680/9765] Loss_D: 0.0960 Loss_G: 0.0381 Convergence: 0.0974 k= 0.020413 lr = 0.0000094\n",
      "[14/25][1690/9765] Loss_D: 0.0903 Loss_G: 0.0377 Convergence: 0.0924 k= 0.020406 lr = 0.0000094\n",
      "[14/25][1700/9765] Loss_D: 0.0889 Loss_G: 0.0391 Convergence: 0.0929 k= 0.020402 lr = 0.0000094\n",
      "[14/25][1710/9765] Loss_D: 0.0884 Loss_G: 0.0395 Convergence: 0.0931 k= 0.020389 lr = 0.0000094\n",
      "[14/25][1720/9765] Loss_D: 0.0928 Loss_G: 0.0383 Convergence: 0.0945 k= 0.020399 lr = 0.0000094\n",
      "[14/25][1730/9765] Loss_D: 0.0930 Loss_G: 0.0385 Convergence: 0.0948 k= 0.020402 lr = 0.0000094\n",
      "[14/25][1740/9765] Loss_D: 0.0942 Loss_G: 0.0351 Convergence: 0.0978 k= 0.020421 lr = 0.0000094\n",
      "[14/25][1750/9765] Loss_D: 0.0943 Loss_G: 0.0378 Convergence: 0.0953 k= 0.020434 lr = 0.0000094\n",
      "[14/25][1760/9765] Loss_D: 0.0994 Loss_G: 0.0401 Convergence: 0.1003 k= 0.020439 lr = 0.0000094\n",
      "[14/25][1770/9765] Loss_D: 0.0811 Loss_G: 0.0373 Convergence: 0.0864 k= 0.020420 lr = 0.0000094\n",
      "[14/25][1780/9765] Loss_D: 0.1012 Loss_G: 0.0391 Convergence: 0.1037 k= 0.020424 lr = 0.0000094\n",
      "[14/25][1790/9765] Loss_D: 0.0944 Loss_G: 0.0398 Convergence: 0.0969 k= 0.020427 lr = 0.0000094\n",
      "[14/25][1800/9765] Loss_D: 0.0989 Loss_G: 0.0397 Convergence: 0.0999 k= 0.020422 lr = 0.0000094\n",
      "[14/25][1810/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0988 k= 0.020421 lr = 0.0000094\n",
      "[14/25][1820/9765] Loss_D: 0.1000 Loss_G: 0.0411 Convergence: 0.1015 k= 0.020421 lr = 0.0000094\n",
      "[14/25][1830/9765] Loss_D: 0.0904 Loss_G: 0.0391 Convergence: 0.0939 k= 0.020407 lr = 0.0000094\n",
      "[14/25][1840/9765] Loss_D: 0.0986 Loss_G: 0.0380 Convergence: 0.1011 k= 0.020406 lr = 0.0000094\n",
      "[14/25][1850/9765] Loss_D: 0.0901 Loss_G: 0.0367 Convergence: 0.0912 k= 0.020405 lr = 0.0000094\n",
      "[14/25][1860/9765] Loss_D: 0.1019 Loss_G: 0.0381 Convergence: 0.1057 k= 0.020419 lr = 0.0000094\n",
      "[14/25][1870/9765] Loss_D: 0.0983 Loss_G: 0.0384 Convergence: 0.1003 k= 0.020430 lr = 0.0000094\n",
      "[14/25][1880/9765] Loss_D: 0.1068 Loss_G: 0.0393 Convergence: 0.1113 k= 0.020445 lr = 0.0000094\n",
      "[14/25][1890/9765] Loss_D: 0.1103 Loss_G: 0.0425 Convergence: 0.1130 k= 0.020451 lr = 0.0000094\n",
      "[14/25][1900/9765] Loss_D: 0.0974 Loss_G: 0.0412 Convergence: 0.1002 k= 0.020424 lr = 0.0000094\n",
      "[14/25][1910/9765] Loss_D: 0.0935 Loss_G: 0.0409 Convergence: 0.0975 k= 0.020412 lr = 0.0000094\n",
      "[14/25][1920/9765] Loss_D: 0.1015 Loss_G: 0.0395 Convergence: 0.1037 k= 0.020421 lr = 0.0000094\n",
      "[14/25][1930/9765] Loss_D: 0.0991 Loss_G: 0.0400 Convergence: 0.0999 k= 0.020423 lr = 0.0000094\n",
      "[14/25][1940/9765] Loss_D: 0.1056 Loss_G: 0.0374 Convergence: 0.1116 k= 0.020428 lr = 0.0000094\n",
      "[14/25][1950/9765] Loss_D: 0.0980 Loss_G: 0.0404 Convergence: 0.0997 k= 0.020428 lr = 0.0000094\n",
      "[14/25][1960/9765] Loss_D: 0.1029 Loss_G: 0.0415 Convergence: 0.1037 k= 0.020431 lr = 0.0000094\n",
      "[14/25][1970/9765] Loss_D: 0.0889 Loss_G: 0.0423 Convergence: 0.0961 k= 0.020405 lr = 0.0000094\n",
      "[14/25][1980/9765] Loss_D: 0.1036 Loss_G: 0.0395 Convergence: 0.1067 k= 0.020400 lr = 0.0000094\n",
      "[14/25][1990/9765] Loss_D: 0.0982 Loss_G: 0.0396 Convergence: 0.0991 k= 0.020402 lr = 0.0000094\n",
      "[14/25][2000/9765] Loss_D: 0.0929 Loss_G: 0.0394 Convergence: 0.0956 k= 0.020413 lr = 0.0000094\n",
      "[14/25][2010/9765] Loss_D: 0.1037 Loss_G: 0.0399 Convergence: 0.1064 k= 0.020421 lr = 0.0000094\n",
      "[14/25][2020/9765] Loss_D: 0.1020 Loss_G: 0.0364 Convergence: 0.1074 k= 0.020439 lr = 0.0000094\n",
      "[14/25][2030/9765] Loss_D: 0.0997 Loss_G: 0.0392 Convergence: 0.1016 k= 0.020453 lr = 0.0000094\n",
      "[14/25][2040/9765] Loss_D: 0.1000 Loss_G: 0.0378 Convergence: 0.1033 k= 0.020466 lr = 0.0000094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][2050/9765] Loss_D: 0.0987 Loss_G: 0.0393 Convergence: 0.1000 k= 0.020480 lr = 0.0000094\n",
      "[14/25][2060/9765] Loss_D: 0.1004 Loss_G: 0.0406 Convergence: 0.1014 k= 0.020467 lr = 0.0000094\n",
      "[14/25][2070/9765] Loss_D: 0.0880 Loss_G: 0.0435 Convergence: 0.0968 k= 0.020446 lr = 0.0000094\n",
      "[14/25][2080/9765] Loss_D: 0.0910 Loss_G: 0.0433 Convergence: 0.0984 k= 0.020416 lr = 0.0000094\n",
      "[14/25][2090/9765] Loss_D: 0.0995 Loss_G: 0.0386 Convergence: 0.1019 k= 0.020399 lr = 0.0000094\n",
      "[14/25][2100/9765] Loss_D: 0.0931 Loss_G: 0.0392 Convergence: 0.0955 k= 0.020398 lr = 0.0000094\n",
      "[14/25][2110/9765] Loss_D: 0.0976 Loss_G: 0.0370 Convergence: 0.1007 k= 0.020409 lr = 0.0000094\n",
      "[14/25][2120/9765] Loss_D: 0.0995 Loss_G: 0.0359 Convergence: 0.1043 k= 0.020425 lr = 0.0000094\n",
      "[14/25][2130/9765] Loss_D: 0.1087 Loss_G: 0.0383 Convergence: 0.1150 k= 0.020444 lr = 0.0000094\n",
      "[14/25][2140/9765] Loss_D: 0.0969 Loss_G: 0.0391 Convergence: 0.0977 k= 0.020448 lr = 0.0000094\n",
      "[14/25][2150/9765] Loss_D: 0.0936 Loss_G: 0.0395 Convergence: 0.0962 k= 0.020446 lr = 0.0000094\n",
      "[14/25][2160/9765] Loss_D: 0.0951 Loss_G: 0.0381 Convergence: 0.0961 k= 0.020423 lr = 0.0000094\n",
      "[14/25][2170/9765] Loss_D: 0.1023 Loss_G: 0.0390 Convergence: 0.1052 k= 0.020452 lr = 0.0000094\n",
      "[14/25][2180/9765] Loss_D: 0.0863 Loss_G: 0.0370 Convergence: 0.0892 k= 0.020459 lr = 0.0000094\n",
      "[14/25][2190/9765] Loss_D: 0.1005 Loss_G: 0.0368 Convergence: 0.1049 k= 0.020484 lr = 0.0000094\n",
      "[14/25][2200/9765] Loss_D: 0.0924 Loss_G: 0.0388 Convergence: 0.0947 k= 0.020502 lr = 0.0000094\n",
      "[14/25][2210/9765] Loss_D: 0.0862 Loss_G: 0.0394 Convergence: 0.0916 k= 0.020501 lr = 0.0000094\n",
      "[14/25][2220/9765] Loss_D: 0.0954 Loss_G: 0.0487 Convergence: 0.1065 k= 0.020474 lr = 0.0000094\n",
      "[14/25][2230/9765] Loss_D: 0.0992 Loss_G: 0.0472 Convergence: 0.1073 k= 0.020414 lr = 0.0000094\n",
      "[14/25][2240/9765] Loss_D: 0.1009 Loss_G: 0.0434 Convergence: 0.1045 k= 0.020375 lr = 0.0000094\n",
      "[14/25][2250/9765] Loss_D: 0.0965 Loss_G: 0.0387 Convergence: 0.0976 k= 0.020357 lr = 0.0000094\n",
      "[14/25][2260/9765] Loss_D: 0.0912 Loss_G: 0.0370 Convergence: 0.0922 k= 0.020370 lr = 0.0000094\n",
      "[14/25][2270/9765] Loss_D: 0.0917 Loss_G: 0.0399 Convergence: 0.0954 k= 0.020384 lr = 0.0000094\n",
      "[14/25][2280/9765] Loss_D: 0.0996 Loss_G: 0.0394 Convergence: 0.1012 k= 0.020379 lr = 0.0000094\n",
      "[14/25][2290/9765] Loss_D: 0.0966 Loss_G: 0.0413 Convergence: 0.0998 k= 0.020372 lr = 0.0000094\n",
      "[14/25][2300/9765] Loss_D: 0.0938 Loss_G: 0.0379 Convergence: 0.0946 k= 0.020373 lr = 0.0000094\n",
      "[14/25][2310/9765] Loss_D: 0.0968 Loss_G: 0.0406 Convergence: 0.0992 k= 0.020379 lr = 0.0000094\n",
      "[14/25][2320/9765] Loss_D: 0.0864 Loss_G: 0.0413 Convergence: 0.0936 k= 0.020361 lr = 0.0000094\n",
      "[14/25][2330/9765] Loss_D: 0.1029 Loss_G: 0.0400 Convergence: 0.1053 k= 0.020355 lr = 0.0000094\n",
      "[14/25][2340/9765] Loss_D: 0.0988 Loss_G: 0.0409 Convergence: 0.1007 k= 0.020353 lr = 0.0000094\n",
      "[14/25][2350/9765] Loss_D: 0.0978 Loss_G: 0.0409 Convergence: 0.1001 k= 0.020342 lr = 0.0000094\n",
      "[14/25][2360/9765] Loss_D: 0.0959 Loss_G: 0.0423 Convergence: 0.1003 k= 0.020324 lr = 0.0000094\n",
      "[14/25][2370/9765] Loss_D: 0.1090 Loss_G: 0.0386 Convergence: 0.1151 k= 0.020316 lr = 0.0000094\n",
      "[14/25][2380/9765] Loss_D: 0.1030 Loss_G: 0.0388 Convergence: 0.1065 k= 0.020312 lr = 0.0000094\n",
      "[14/25][2390/9765] Loss_D: 0.1063 Loss_G: 0.0379 Convergence: 0.1120 k= 0.020316 lr = 0.0000094\n",
      "[14/25][2400/9765] Loss_D: 0.0974 Loss_G: 0.0421 Convergence: 0.1010 k= 0.020316 lr = 0.0000094\n",
      "[14/25][2410/9765] Loss_D: 0.1047 Loss_G: 0.0402 Convergence: 0.1075 k= 0.020318 lr = 0.0000094\n",
      "[14/25][2420/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0985 k= 0.020306 lr = 0.0000094\n",
      "[14/25][2430/9765] Loss_D: 0.0927 Loss_G: 0.0408 Convergence: 0.0969 k= 0.020282 lr = 0.0000094\n",
      "[14/25][2440/9765] Loss_D: 0.0959 Loss_G: 0.0389 Convergence: 0.0969 k= 0.020281 lr = 0.0000094\n",
      "[14/25][2450/9765] Loss_D: 0.1015 Loss_G: 0.0414 Convergence: 0.1028 k= 0.020274 lr = 0.0000094\n",
      "[14/25][2460/9765] Loss_D: 0.1035 Loss_G: 0.0347 Convergence: 0.1112 k= 0.020298 lr = 0.0000094\n",
      "[14/25][2470/9765] Loss_D: 0.0992 Loss_G: 0.0373 Convergence: 0.1025 k= 0.020316 lr = 0.0000094\n",
      "[14/25][2480/9765] Loss_D: 0.1020 Loss_G: 0.0389 Convergence: 0.1050 k= 0.020327 lr = 0.0000094\n",
      "[14/25][2490/9765] Loss_D: 0.0935 Loss_G: 0.0394 Convergence: 0.0959 k= 0.020325 lr = 0.0000094\n",
      "[14/25][2500/9765] Loss_D: 0.1062 Loss_G: 0.0405 Convergence: 0.1093 k= 0.020315 lr = 0.0000094\n",
      "[14/25][2510/9765] Loss_D: 0.1063 Loss_G: 0.0404 Convergence: 0.1095 k= 0.020301 lr = 0.0000094\n",
      "[14/25][2520/9765] Loss_D: 0.1074 Loss_G: 0.0379 Convergence: 0.1135 k= 0.020309 lr = 0.0000094\n",
      "[14/25][2530/9765] Loss_D: 0.0977 Loss_G: 0.0388 Convergence: 0.0991 k= 0.020310 lr = 0.0000094\n",
      "[14/25][2540/9765] Loss_D: 0.0994 Loss_G: 0.0407 Convergence: 0.1008 k= 0.020316 lr = 0.0000094\n",
      "[14/25][2550/9765] Loss_D: 0.0953 Loss_G: 0.0403 Convergence: 0.0980 k= 0.020303 lr = 0.0000094\n",
      "[14/25][2560/9765] Loss_D: 0.1065 Loss_G: 0.0417 Convergence: 0.1087 k= 0.020285 lr = 0.0000094\n",
      "[14/25][2570/9765] Loss_D: 0.0945 Loss_G: 0.0368 Convergence: 0.0965 k= 0.020302 lr = 0.0000094\n",
      "[14/25][2580/9765] Loss_D: 0.0935 Loss_G: 0.0385 Convergence: 0.0951 k= 0.020318 lr = 0.0000094\n",
      "[14/25][2590/9765] Loss_D: 0.0896 Loss_G: 0.0383 Convergence: 0.0925 k= 0.020311 lr = 0.0000094\n",
      "[14/25][2600/9765] Loss_D: 0.1040 Loss_G: 0.0394 Convergence: 0.1073 k= 0.020313 lr = 0.0000094\n",
      "[14/25][2610/9765] Loss_D: 0.0995 Loss_G: 0.0393 Convergence: 0.1011 k= 0.020317 lr = 0.0000094\n",
      "[14/25][2620/9765] Loss_D: 0.1024 Loss_G: 0.0401 Convergence: 0.1043 k= 0.020310 lr = 0.0000094\n",
      "[14/25][2630/9765] Loss_D: 0.0946 Loss_G: 0.0380 Convergence: 0.0956 k= 0.020323 lr = 0.0000094\n",
      "[14/25][2640/9765] Loss_D: 0.1027 Loss_G: 0.0380 Convergence: 0.1069 k= 0.020335 lr = 0.0000094\n",
      "[14/25][2650/9765] Loss_D: 0.1008 Loss_G: 0.0389 Convergence: 0.1033 k= 0.020334 lr = 0.0000094\n",
      "[14/25][2660/9765] Loss_D: 0.0953 Loss_G: 0.0385 Convergence: 0.0961 k= 0.020333 lr = 0.0000094\n",
      "[14/25][2670/9765] Loss_D: 0.0931 Loss_G: 0.0404 Convergence: 0.0967 k= 0.020313 lr = 0.0000094\n",
      "[14/25][2680/9765] Loss_D: 0.0961 Loss_G: 0.0369 Convergence: 0.0986 k= 0.020309 lr = 0.0000094\n",
      "[14/25][2690/9765] Loss_D: 0.0919 Loss_G: 0.0390 Convergence: 0.0946 k= 0.020307 lr = 0.0000094\n",
      "[14/25][2700/9765] Loss_D: 0.1008 Loss_G: 0.0385 Convergence: 0.1037 k= 0.020317 lr = 0.0000094\n",
      "[14/25][2710/9765] Loss_D: 0.1006 Loss_G: 0.0401 Convergence: 0.1019 k= 0.020310 lr = 0.0000094\n",
      "[14/25][2720/9765] Loss_D: 0.0943 Loss_G: 0.0392 Convergence: 0.0963 k= 0.020310 lr = 0.0000094\n",
      "[14/25][2730/9765] Loss_D: 0.0892 Loss_G: 0.0396 Convergence: 0.0937 k= 0.020294 lr = 0.0000094\n",
      "[14/25][2740/9765] Loss_D: 0.1010 Loss_G: 0.0376 Convergence: 0.1048 k= 0.020285 lr = 0.0000094\n",
      "[14/25][2750/9765] Loss_D: 0.0992 Loss_G: 0.0415 Convergence: 0.1015 k= 0.020283 lr = 0.0000094\n",
      "[14/25][2760/9765] Loss_D: 0.0958 Loss_G: 0.0400 Convergence: 0.0979 k= 0.020264 lr = 0.0000094\n",
      "[14/25][2770/9765] Loss_D: 0.0950 Loss_G: 0.0373 Convergence: 0.0968 k= 0.020273 lr = 0.0000094\n",
      "[14/25][2780/9765] Loss_D: 0.0984 Loss_G: 0.0375 Convergence: 0.1013 k= 0.020279 lr = 0.0000094\n",
      "[14/25][2790/9765] Loss_D: 0.0940 Loss_G: 0.0399 Convergence: 0.0968 k= 0.020282 lr = 0.0000094\n",
      "[14/25][2800/9765] Loss_D: 0.0961 Loss_G: 0.0402 Convergence: 0.0983 k= 0.020282 lr = 0.0000094\n",
      "[14/25][2810/9765] Loss_D: 0.1062 Loss_G: 0.0401 Convergence: 0.1097 k= 0.020289 lr = 0.0000094\n",
      "[14/25][2820/9765] Loss_D: 0.1025 Loss_G: 0.0414 Convergence: 0.1034 k= 0.020256 lr = 0.0000094\n",
      "[14/25][2830/9765] Loss_D: 0.0916 Loss_G: 0.0390 Convergence: 0.0944 k= 0.020248 lr = 0.0000094\n",
      "[14/25][2840/9765] Loss_D: 0.0889 Loss_G: 0.0388 Convergence: 0.0926 k= 0.020252 lr = 0.0000094\n",
      "[14/25][2850/9765] Loss_D: 0.1056 Loss_G: 0.0406 Convergence: 0.1084 k= 0.020266 lr = 0.0000094\n",
      "[14/25][2860/9765] Loss_D: 0.0951 Loss_G: 0.0402 Convergence: 0.0978 k= 0.020251 lr = 0.0000094\n",
      "[14/25][2870/9765] Loss_D: 0.0894 Loss_G: 0.0382 Convergence: 0.0924 k= 0.020257 lr = 0.0000094\n",
      "[14/25][2880/9765] Loss_D: 0.0966 Loss_G: 0.0380 Convergence: 0.0983 k= 0.020273 lr = 0.0000094\n",
      "[14/25][2890/9765] Loss_D: 0.0951 Loss_G: 0.0394 Convergence: 0.0970 k= 0.020269 lr = 0.0000094\n",
      "[14/25][2900/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0985 k= 0.020275 lr = 0.0000094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][2910/9765] Loss_D: 0.0926 Loss_G: 0.0392 Convergence: 0.0952 k= 0.020277 lr = 0.0000094\n",
      "[14/25][2920/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0968 k= 0.020270 lr = 0.0000094\n",
      "[14/25][2930/9765] Loss_D: 0.1000 Loss_G: 0.0379 Convergence: 0.1033 k= 0.020266 lr = 0.0000094\n",
      "[14/25][2940/9765] Loss_D: 0.0908 Loss_G: 0.0339 Convergence: 0.0942 k= 0.020279 lr = 0.0000094\n",
      "[14/25][2950/9765] Loss_D: 0.0991 Loss_G: 0.0403 Convergence: 0.1003 k= 0.020285 lr = 0.0000094\n",
      "[14/25][2960/9765] Loss_D: 0.1048 Loss_G: 0.0405 Convergence: 0.1075 k= 0.020275 lr = 0.0000094\n",
      "[14/25][2970/9765] Loss_D: 0.1033 Loss_G: 0.0393 Convergence: 0.1064 k= 0.020257 lr = 0.0000094\n",
      "[14/25][2980/9765] Loss_D: 0.0913 Loss_G: 0.0401 Convergence: 0.0954 k= 0.020237 lr = 0.0000094\n",
      "[14/25][2990/9765] Loss_D: 0.0962 Loss_G: 0.0398 Convergence: 0.0980 k= 0.020226 lr = 0.0000094\n",
      "[14/25][3000/9765] Loss_D: 0.0958 Loss_G: 0.0391 Convergence: 0.0970 k= 0.020209 lr = 0.0000094\n",
      "[14/25][3010/9765] Loss_D: 0.1036 Loss_G: 0.0395 Convergence: 0.1066 k= 0.020206 lr = 0.0000094\n",
      "[14/25][3020/9765] Loss_D: 0.1042 Loss_G: 0.0374 Convergence: 0.1095 k= 0.020207 lr = 0.0000094\n",
      "[14/25][3030/9765] Loss_D: 0.0999 Loss_G: 0.0386 Convergence: 0.1022 k= 0.020224 lr = 0.0000094\n",
      "[14/25][3040/9765] Loss_D: 0.0881 Loss_G: 0.0398 Convergence: 0.0932 k= 0.020232 lr = 0.0000094\n",
      "[14/25][3050/9765] Loss_D: 0.0889 Loss_G: 0.0439 Convergence: 0.0978 k= 0.020204 lr = 0.0000094\n",
      "[14/25][3060/9765] Loss_D: 0.1024 Loss_G: 0.0450 Convergence: 0.1070 k= 0.020167 lr = 0.0000094\n",
      "[14/25][3070/9765] Loss_D: 0.0951 Loss_G: 0.0448 Convergence: 0.1024 k= 0.020128 lr = 0.0000094\n",
      "[14/25][3080/9765] Loss_D: 0.0978 Loss_G: 0.0425 Convergence: 0.1017 k= 0.020096 lr = 0.0000094\n",
      "[14/25][3090/9765] Loss_D: 0.0963 Loss_G: 0.0394 Convergence: 0.0976 k= 0.020093 lr = 0.0000094\n",
      "[14/25][3100/9765] Loss_D: 0.1082 Loss_G: 0.0355 Convergence: 0.1170 k= 0.020123 lr = 0.0000094\n",
      "[14/25][3110/9765] Loss_D: 0.0857 Loss_G: 0.0372 Convergence: 0.0891 k= 0.020150 lr = 0.0000094\n",
      "[14/25][3120/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0975 k= 0.020159 lr = 0.0000094\n",
      "[14/25][3130/9765] Loss_D: 0.0953 Loss_G: 0.0392 Convergence: 0.0968 k= 0.020163 lr = 0.0000094\n",
      "[14/25][3140/9765] Loss_D: 0.1025 Loss_G: 0.0472 Convergence: 0.1093 k= 0.020126 lr = 0.0000094\n",
      "[14/25][3150/9765] Loss_D: 0.1005 Loss_G: 0.0442 Convergence: 0.1050 k= 0.020067 lr = 0.0000094\n",
      "[14/25][3160/9765] Loss_D: 0.0897 Loss_G: 0.0420 Convergence: 0.0964 k= 0.020003 lr = 0.0000094\n",
      "[14/25][3170/9765] Loss_D: 0.0939 Loss_G: 0.0408 Convergence: 0.0976 k= 0.019993 lr = 0.0000094\n",
      "[14/25][3180/9765] Loss_D: 0.0952 Loss_G: 0.0353 Convergence: 0.0990 k= 0.019998 lr = 0.0000094\n",
      "[14/25][3190/9765] Loss_D: 0.0994 Loss_G: 0.0345 Convergence: 0.1055 k= 0.020035 lr = 0.0000094\n",
      "[14/25][3200/9765] Loss_D: 0.0985 Loss_G: 0.0365 Convergence: 0.1024 k= 0.020067 lr = 0.0000094\n",
      "[14/25][3210/9765] Loss_D: 0.0964 Loss_G: 0.0361 Convergence: 0.0998 k= 0.020094 lr = 0.0000094\n",
      "[14/25][3220/9765] Loss_D: 0.0954 Loss_G: 0.0379 Convergence: 0.0967 k= 0.020100 lr = 0.0000094\n",
      "[14/25][3230/9765] Loss_D: 0.0922 Loss_G: 0.0394 Convergence: 0.0952 k= 0.020092 lr = 0.0000094\n",
      "[14/25][3240/9765] Loss_D: 0.0996 Loss_G: 0.0384 Convergence: 0.1021 k= 0.020094 lr = 0.0000094\n",
      "[14/25][3250/9765] Loss_D: 0.0964 Loss_G: 0.0410 Convergence: 0.0993 k= 0.020110 lr = 0.0000094\n",
      "[14/25][3260/9765] Loss_D: 0.0929 Loss_G: 0.0403 Convergence: 0.0965 k= 0.020110 lr = 0.0000094\n",
      "[14/25][3270/9765] Loss_D: 0.0934 Loss_G: 0.0390 Convergence: 0.0955 k= 0.020090 lr = 0.0000094\n",
      "[14/25][3280/9765] Loss_D: 0.0944 Loss_G: 0.0433 Convergence: 0.1004 k= 0.020067 lr = 0.0000094\n",
      "[14/25][3290/9765] Loss_D: 0.1009 Loss_G: 0.0387 Convergence: 0.1037 k= 0.020079 lr = 0.0000094\n",
      "[14/25][3300/9765] Loss_D: 0.1011 Loss_G: 0.0385 Convergence: 0.1041 k= 0.020075 lr = 0.0000094\n",
      "[14/25][3310/9765] Loss_D: 0.0860 Loss_G: 0.0405 Convergence: 0.0926 k= 0.020084 lr = 0.0000094\n",
      "[14/25][3320/9765] Loss_D: 0.0906 Loss_G: 0.0425 Convergence: 0.0974 k= 0.020082 lr = 0.0000094\n",
      "[14/25][3330/9765] Loss_D: 0.1052 Loss_G: 0.0388 Convergence: 0.1095 k= 0.020066 lr = 0.0000094\n",
      "[14/25][3340/9765] Loss_D: 0.0979 Loss_G: 0.0359 Convergence: 0.1021 k= 0.020077 lr = 0.0000094\n",
      "[14/25][3350/9765] Loss_D: 0.1115 Loss_G: 0.0390 Convergence: 0.1181 k= 0.020105 lr = 0.0000094\n",
      "[14/25][3360/9765] Loss_D: 0.0963 Loss_G: 0.0382 Convergence: 0.0978 k= 0.020110 lr = 0.0000094\n",
      "[14/25][3370/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0941 k= 0.020117 lr = 0.0000094\n",
      "[14/25][3380/9765] Loss_D: 0.1014 Loss_G: 0.0412 Convergence: 0.1026 k= 0.020116 lr = 0.0000094\n",
      "[14/25][3390/9765] Loss_D: 0.0943 Loss_G: 0.0376 Convergence: 0.0954 k= 0.020105 lr = 0.0000094\n",
      "[14/25][3400/9765] Loss_D: 0.0962 Loss_G: 0.0374 Convergence: 0.0983 k= 0.020136 lr = 0.0000094\n",
      "[14/25][3410/9765] Loss_D: 0.1014 Loss_G: 0.0376 Convergence: 0.1055 k= 0.020145 lr = 0.0000094\n",
      "[14/25][3420/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0957 k= 0.020148 lr = 0.0000094\n",
      "[14/25][3430/9765] Loss_D: 0.0934 Loss_G: 0.0395 Convergence: 0.0961 k= 0.020138 lr = 0.0000094\n",
      "[14/25][3440/9765] Loss_D: 0.0948 Loss_G: 0.0387 Convergence: 0.0961 k= 0.020127 lr = 0.0000094\n",
      "[14/25][3450/9765] Loss_D: 0.0980 Loss_G: 0.0418 Convergence: 0.1011 k= 0.020126 lr = 0.0000094\n",
      "[14/25][3460/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0990 k= 0.020125 lr = 0.0000094\n",
      "[14/25][3470/9765] Loss_D: 0.1007 Loss_G: 0.0391 Convergence: 0.1029 k= 0.020125 lr = 0.0000094\n",
      "[14/25][3480/9765] Loss_D: 0.1011 Loss_G: 0.0393 Convergence: 0.1033 k= 0.020139 lr = 0.0000094\n",
      "[14/25][3490/9765] Loss_D: 0.1042 Loss_G: 0.0398 Convergence: 0.1073 k= 0.020134 lr = 0.0000094\n",
      "[14/25][3500/9765] Loss_D: 0.0926 Loss_G: 0.0377 Convergence: 0.0938 k= 0.020139 lr = 0.0000094\n",
      "[14/25][3510/9765] Loss_D: 0.1021 Loss_G: 0.0373 Convergence: 0.1067 k= 0.020169 lr = 0.0000094\n",
      "[14/25][3520/9765] Loss_D: 0.0982 Loss_G: 0.0377 Convergence: 0.1008 k= 0.020169 lr = 0.0000094\n",
      "[14/25][3530/9765] Loss_D: 0.0895 Loss_G: 0.0363 Convergence: 0.0904 k= 0.020181 lr = 0.0000094\n",
      "[14/25][3540/9765] Loss_D: 0.1028 Loss_G: 0.0386 Convergence: 0.1064 k= 0.020198 lr = 0.0000094\n",
      "[14/25][3550/9765] Loss_D: 0.0964 Loss_G: 0.0370 Convergence: 0.0990 k= 0.020198 lr = 0.0000094\n",
      "[14/25][3560/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.0989 k= 0.020198 lr = 0.0000094\n",
      "[14/25][3570/9765] Loss_D: 0.0916 Loss_G: 0.0356 Convergence: 0.0936 k= 0.020218 lr = 0.0000094\n",
      "[14/25][3580/9765] Loss_D: 0.0914 Loss_G: 0.0386 Convergence: 0.0939 k= 0.020236 lr = 0.0000094\n",
      "[14/25][3590/9765] Loss_D: 0.0957 Loss_G: 0.0381 Convergence: 0.0970 k= 0.020234 lr = 0.0000094\n",
      "[14/25][3600/9765] Loss_D: 0.0961 Loss_G: 0.0387 Convergence: 0.0970 k= 0.020221 lr = 0.0000094\n",
      "[14/25][3610/9765] Loss_D: 0.0869 Loss_G: 0.0399 Convergence: 0.0925 k= 0.020211 lr = 0.0000094\n",
      "[14/25][3620/9765] Loss_D: 0.0913 Loss_G: 0.0375 Convergence: 0.0928 k= 0.020210 lr = 0.0000094\n",
      "[14/25][3630/9765] Loss_D: 0.0947 Loss_G: 0.0393 Convergence: 0.0966 k= 0.020219 lr = 0.0000094\n",
      "[14/25][3640/9765] Loss_D: 0.0916 Loss_G: 0.0379 Convergence: 0.0934 k= 0.020216 lr = 0.0000094\n",
      "[14/25][3650/9765] Loss_D: 0.1000 Loss_G: 0.0386 Convergence: 0.1025 k= 0.020218 lr = 0.0000094\n",
      "[14/25][3660/9765] Loss_D: 0.0950 Loss_G: 0.0411 Convergence: 0.0986 k= 0.020218 lr = 0.0000094\n",
      "[14/25][3670/9765] Loss_D: 0.0940 Loss_G: 0.0412 Convergence: 0.0981 k= 0.020201 lr = 0.0000094\n",
      "[14/25][3680/9765] Loss_D: 0.1055 Loss_G: 0.0436 Convergence: 0.1074 k= 0.020188 lr = 0.0000094\n",
      "[14/25][3690/9765] Loss_D: 0.1029 Loss_G: 0.0409 Convergence: 0.1044 k= 0.020178 lr = 0.0000094\n",
      "[14/25][3700/9765] Loss_D: 0.1010 Loss_G: 0.0386 Convergence: 0.1038 k= 0.020168 lr = 0.0000094\n",
      "[14/25][3710/9765] Loss_D: 0.0934 Loss_G: 0.0376 Convergence: 0.0942 k= 0.020178 lr = 0.0000094\n",
      "[14/25][3720/9765] Loss_D: 0.0987 Loss_G: 0.0398 Convergence: 0.0995 k= 0.020181 lr = 0.0000094\n",
      "[14/25][3730/9765] Loss_D: 0.0968 Loss_G: 0.0388 Convergence: 0.0979 k= 0.020172 lr = 0.0000094\n",
      "[14/25][3740/9765] Loss_D: 0.1000 Loss_G: 0.0388 Convergence: 0.1022 k= 0.020172 lr = 0.0000094\n",
      "[14/25][3750/9765] Loss_D: 0.0914 Loss_G: 0.0369 Convergence: 0.0922 k= 0.020161 lr = 0.0000094\n",
      "[14/25][3760/9765] Loss_D: 0.0948 Loss_G: 0.0382 Convergence: 0.0956 k= 0.020181 lr = 0.0000094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][3770/9765] Loss_D: 0.0974 Loss_G: 0.0394 Convergence: 0.0983 k= 0.020179 lr = 0.0000094\n",
      "[14/25][3780/9765] Loss_D: 0.0936 Loss_G: 0.0371 Convergence: 0.0950 k= 0.020183 lr = 0.0000094\n",
      "[14/25][3790/9765] Loss_D: 0.0997 Loss_G: 0.0378 Convergence: 0.1029 k= 0.020200 lr = 0.0000094\n",
      "[14/25][3800/9765] Loss_D: 0.1073 Loss_G: 0.0399 Convergence: 0.1115 k= 0.020208 lr = 0.0000094\n",
      "[14/25][3810/9765] Loss_D: 0.0934 Loss_G: 0.0394 Convergence: 0.0959 k= 0.020206 lr = 0.0000094\n",
      "[14/25][3820/9765] Loss_D: 0.1023 Loss_G: 0.0405 Convergence: 0.1038 k= 0.020205 lr = 0.0000094\n",
      "[14/25][3830/9765] Loss_D: 0.0918 Loss_G: 0.0388 Convergence: 0.0944 k= 0.020199 lr = 0.0000094\n",
      "[14/25][3840/9765] Loss_D: 0.0932 Loss_G: 0.0415 Convergence: 0.0980 k= 0.020187 lr = 0.0000094\n",
      "[14/25][3850/9765] Loss_D: 0.1012 Loss_G: 0.0407 Convergence: 0.1021 k= 0.020185 lr = 0.0000094\n",
      "[14/25][3860/9765] Loss_D: 0.0900 Loss_G: 0.0398 Convergence: 0.0943 k= 0.020172 lr = 0.0000094\n",
      "[14/25][3870/9765] Loss_D: 0.0974 Loss_G: 0.0413 Convergence: 0.1002 k= 0.020173 lr = 0.0000094\n",
      "[14/25][3880/9765] Loss_D: 0.1016 Loss_G: 0.0385 Convergence: 0.1048 k= 0.020178 lr = 0.0000094\n",
      "[14/25][3890/9765] Loss_D: 0.0978 Loss_G: 0.0408 Convergence: 0.1000 k= 0.020173 lr = 0.0000094\n",
      "[14/25][3900/9765] Loss_D: 0.0991 Loss_G: 0.0395 Convergence: 0.1003 k= 0.020156 lr = 0.0000094\n",
      "[14/25][3910/9765] Loss_D: 0.0855 Loss_G: 0.0408 Convergence: 0.0925 k= 0.020134 lr = 0.0000094\n",
      "[14/25][3920/9765] Loss_D: 0.0927 Loss_G: 0.0379 Convergence: 0.0940 k= 0.020136 lr = 0.0000094\n",
      "[14/25][3930/9765] Loss_D: 0.0969 Loss_G: 0.0403 Convergence: 0.0990 k= 0.020142 lr = 0.0000094\n",
      "[14/25][3940/9765] Loss_D: 0.0976 Loss_G: 0.0387 Convergence: 0.0990 k= 0.020136 lr = 0.0000094\n",
      "[14/25][3950/9765] Loss_D: 0.0949 Loss_G: 0.0370 Convergence: 0.0969 k= 0.020141 lr = 0.0000094\n",
      "[14/25][3960/9765] Loss_D: 0.0937 Loss_G: 0.0424 Convergence: 0.0991 k= 0.020126 lr = 0.0000094\n",
      "[14/25][3970/9765] Loss_D: 0.0999 Loss_G: 0.0404 Convergence: 0.1008 k= 0.020100 lr = 0.0000094\n",
      "[14/25][3980/9765] Loss_D: 0.0962 Loss_G: 0.0397 Convergence: 0.0979 k= 0.020087 lr = 0.0000094\n",
      "[14/25][3990/9765] Loss_D: 0.1001 Loss_G: 0.0381 Convergence: 0.1031 k= 0.020078 lr = 0.0000094\n",
      "[14/25][4000/9765] Loss_D: 0.0906 Loss_G: 0.0402 Convergence: 0.0950 k= 0.020072 lr = 0.0000094\n",
      "[14/25][4010/9765] Loss_D: 0.0975 Loss_G: 0.0394 Convergence: 0.0984 k= 0.020078 lr = 0.0000094\n",
      "[14/25][4020/9765] Loss_D: 0.0904 Loss_G: 0.0373 Convergence: 0.0921 k= 0.020081 lr = 0.0000094\n",
      "[14/25][4030/9765] Loss_D: 0.0967 Loss_G: 0.0374 Convergence: 0.0991 k= 0.020090 lr = 0.0000094\n",
      "[14/25][4040/9765] Loss_D: 0.0989 Loss_G: 0.0384 Convergence: 0.1011 k= 0.020099 lr = 0.0000094\n",
      "[14/25][4050/9765] Loss_D: 0.0844 Loss_G: 0.0345 Convergence: 0.0856 k= 0.020113 lr = 0.0000094\n",
      "[14/25][4060/9765] Loss_D: 0.0981 Loss_G: 0.0415 Convergence: 0.1009 k= 0.020117 lr = 0.0000094\n",
      "[14/25][4070/9765] Loss_D: 0.0914 Loss_G: 0.0418 Convergence: 0.0971 k= 0.020100 lr = 0.0000094\n",
      "[14/25][4080/9765] Loss_D: 0.0923 Loss_G: 0.0430 Convergence: 0.0989 k= 0.020058 lr = 0.0000094\n",
      "[14/25][4090/9765] Loss_D: 0.1037 Loss_G: 0.0390 Convergence: 0.1072 k= 0.020033 lr = 0.0000094\n",
      "[14/25][4100/9765] Loss_D: 0.0971 Loss_G: 0.0373 Convergence: 0.0996 k= 0.020053 lr = 0.0000094\n",
      "[14/25][4110/9765] Loss_D: 0.1029 Loss_G: 0.0344 Convergence: 0.1107 k= 0.020077 lr = 0.0000094\n",
      "[14/25][4120/9765] Loss_D: 0.0961 Loss_G: 0.0335 Convergence: 0.1019 k= 0.020119 lr = 0.0000094\n",
      "[14/25][4130/9765] Loss_D: 0.0950 Loss_G: 0.0363 Convergence: 0.0977 k= 0.020152 lr = 0.0000094\n",
      "[14/25][4140/9765] Loss_D: 0.0935 Loss_G: 0.0395 Convergence: 0.0961 k= 0.020153 lr = 0.0000094\n",
      "[14/25][4150/9765] Loss_D: 0.0943 Loss_G: 0.0467 Convergence: 0.1038 k= 0.020113 lr = 0.0000094\n",
      "[14/25][4160/9765] Loss_D: 0.0895 Loss_G: 0.0423 Convergence: 0.0965 k= 0.020060 lr = 0.0000094\n",
      "[14/25][4170/9765] Loss_D: 0.0906 Loss_G: 0.0386 Convergence: 0.0935 k= 0.020044 lr = 0.0000094\n",
      "[14/25][4180/9765] Loss_D: 0.1058 Loss_G: 0.0408 Convergence: 0.1084 k= 0.020034 lr = 0.0000094\n",
      "[14/25][4190/9765] Loss_D: 0.0916 Loss_G: 0.0385 Convergence: 0.0940 k= 0.020039 lr = 0.0000094\n",
      "[14/25][4200/9765] Loss_D: 0.0930 Loss_G: 0.0379 Convergence: 0.0941 k= 0.020048 lr = 0.0000094\n",
      "[14/25][4210/9765] Loss_D: 0.1005 Loss_G: 0.0370 Convergence: 0.1047 k= 0.020043 lr = 0.0000094\n",
      "[14/25][4220/9765] Loss_D: 0.1007 Loss_G: 0.0384 Convergence: 0.1037 k= 0.020052 lr = 0.0000094\n",
      "[14/25][4230/9765] Loss_D: 0.1003 Loss_G: 0.0408 Convergence: 0.1014 k= 0.020048 lr = 0.0000094\n",
      "[14/25][4240/9765] Loss_D: 0.1033 Loss_G: 0.0413 Convergence: 0.1044 k= 0.020042 lr = 0.0000094\n",
      "[14/25][4250/9765] Loss_D: 0.1024 Loss_G: 0.0375 Convergence: 0.1069 k= 0.020052 lr = 0.0000094\n",
      "[14/25][4260/9765] Loss_D: 0.0902 Loss_G: 0.0399 Convergence: 0.0945 k= 0.020053 lr = 0.0000094\n",
      "[14/25][4270/9765] Loss_D: 0.0959 Loss_G: 0.0418 Convergence: 0.0998 k= 0.020043 lr = 0.0000094\n",
      "[14/25][4280/9765] Loss_D: 0.1052 Loss_G: 0.0388 Convergence: 0.1096 k= 0.020051 lr = 0.0000094\n",
      "[14/25][4290/9765] Loss_D: 0.0956 Loss_G: 0.0380 Convergence: 0.0970 k= 0.020049 lr = 0.0000090\n",
      "[14/25][4300/9765] Loss_D: 0.0867 Loss_G: 0.0378 Convergence: 0.0903 k= 0.020052 lr = 0.0000090\n",
      "[14/25][4310/9765] Loss_D: 0.1002 Loss_G: 0.0390 Convergence: 0.1024 k= 0.020071 lr = 0.0000090\n",
      "[14/25][4320/9765] Loss_D: 0.0924 Loss_G: 0.0410 Convergence: 0.0970 k= 0.020067 lr = 0.0000090\n",
      "[14/25][4330/9765] Loss_D: 0.0941 Loss_G: 0.0396 Convergence: 0.0966 k= 0.020070 lr = 0.0000090\n",
      "[14/25][4340/9765] Loss_D: 0.0973 Loss_G: 0.0374 Convergence: 0.0999 k= 0.020075 lr = 0.0000090\n",
      "[14/25][4350/9765] Loss_D: 0.0950 Loss_G: 0.0381 Convergence: 0.0960 k= 0.020086 lr = 0.0000090\n",
      "[14/25][4360/9765] Loss_D: 0.1004 Loss_G: 0.0395 Convergence: 0.1021 k= 0.020093 lr = 0.0000090\n",
      "[14/25][4370/9765] Loss_D: 0.0922 Loss_G: 0.0386 Convergence: 0.0944 k= 0.020082 lr = 0.0000090\n",
      "[14/25][4380/9765] Loss_D: 0.0948 Loss_G: 0.0412 Convergence: 0.0986 k= 0.020062 lr = 0.0000090\n",
      "[14/25][4390/9765] Loss_D: 0.0888 Loss_G: 0.0398 Convergence: 0.0935 k= 0.020061 lr = 0.0000090\n",
      "[14/25][4400/9765] Loss_D: 0.0910 Loss_G: 0.0385 Convergence: 0.0935 k= 0.020067 lr = 0.0000090\n",
      "[14/25][4410/9765] Loss_D: 0.0889 Loss_G: 0.0376 Convergence: 0.0914 k= 0.020058 lr = 0.0000090\n",
      "[14/25][4420/9765] Loss_D: 0.1017 Loss_G: 0.0399 Convergence: 0.1036 k= 0.020057 lr = 0.0000090\n",
      "[14/25][4430/9765] Loss_D: 0.1020 Loss_G: 0.0390 Convergence: 0.1049 k= 0.020048 lr = 0.0000090\n",
      "[14/25][4440/9765] Loss_D: 0.0931 Loss_G: 0.0375 Convergence: 0.0939 k= 0.020055 lr = 0.0000090\n",
      "[14/25][4450/9765] Loss_D: 0.0955 Loss_G: 0.0384 Convergence: 0.0963 k= 0.020062 lr = 0.0000090\n",
      "[14/25][4460/9765] Loss_D: 0.0944 Loss_G: 0.0390 Convergence: 0.0961 k= 0.020055 lr = 0.0000090\n",
      "[14/25][4470/9765] Loss_D: 0.0874 Loss_G: 0.0391 Convergence: 0.0920 k= 0.020036 lr = 0.0000090\n",
      "[14/25][4480/9765] Loss_D: 0.0940 Loss_G: 0.0368 Convergence: 0.0958 k= 0.020043 lr = 0.0000090\n",
      "[14/25][4490/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0973 k= 0.020050 lr = 0.0000090\n",
      "[14/25][4500/9765] Loss_D: 0.0928 Loss_G: 0.0382 Convergence: 0.0944 k= 0.020046 lr = 0.0000090\n",
      "[14/25][4510/9765] Loss_D: 0.0995 Loss_G: 0.0395 Convergence: 0.1009 k= 0.020040 lr = 0.0000090\n",
      "[14/25][4520/9765] Loss_D: 0.0992 Loss_G: 0.0383 Convergence: 0.1016 k= 0.020061 lr = 0.0000090\n",
      "[14/25][4530/9765] Loss_D: 0.0952 Loss_G: 0.0389 Convergence: 0.0965 k= 0.020054 lr = 0.0000090\n",
      "[14/25][4540/9765] Loss_D: 0.0970 Loss_G: 0.0380 Convergence: 0.0989 k= 0.020043 lr = 0.0000090\n",
      "[14/25][4550/9765] Loss_D: 0.0907 Loss_G: 0.0381 Convergence: 0.0930 k= 0.020051 lr = 0.0000090\n",
      "[14/25][4560/9765] Loss_D: 0.0996 Loss_G: 0.0389 Convergence: 0.1016 k= 0.020074 lr = 0.0000090\n",
      "[14/25][4570/9765] Loss_D: 0.0966 Loss_G: 0.0394 Convergence: 0.0978 k= 0.020075 lr = 0.0000090\n",
      "[14/25][4580/9765] Loss_D: 0.0926 Loss_G: 0.0400 Convergence: 0.0960 k= 0.020070 lr = 0.0000090\n",
      "[14/25][4590/9765] Loss_D: 0.1023 Loss_G: 0.0397 Convergence: 0.1046 k= 0.020066 lr = 0.0000090\n",
      "[14/25][4600/9765] Loss_D: 0.1021 Loss_G: 0.0417 Convergence: 0.1035 k= 0.020052 lr = 0.0000090\n",
      "[14/25][4610/9765] Loss_D: 0.0884 Loss_G: 0.0401 Convergence: 0.0937 k= 0.020035 lr = 0.0000090\n",
      "[14/25][4620/9765] Loss_D: 0.1035 Loss_G: 0.0382 Convergence: 0.1078 k= 0.020049 lr = 0.0000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][4630/9765] Loss_D: 0.0978 Loss_G: 0.0367 Convergence: 0.1013 k= 0.020066 lr = 0.0000090\n",
      "[14/25][4640/9765] Loss_D: 0.0940 Loss_G: 0.0353 Convergence: 0.0973 k= 0.020094 lr = 0.0000090\n",
      "[14/25][4650/9765] Loss_D: 0.0895 Loss_G: 0.0382 Convergence: 0.0923 k= 0.020117 lr = 0.0000090\n",
      "[14/25][4660/9765] Loss_D: 0.0967 Loss_G: 0.0425 Convergence: 0.1010 k= 0.020109 lr = 0.0000090\n",
      "[14/25][4670/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1005 k= 0.020101 lr = 0.0000090\n",
      "[14/25][4680/9765] Loss_D: 0.0931 Loss_G: 0.0389 Convergence: 0.0952 k= 0.020111 lr = 0.0000090\n",
      "[14/25][4690/9765] Loss_D: 0.1037 Loss_G: 0.0407 Convergence: 0.1057 k= 0.020104 lr = 0.0000090\n",
      "[14/25][4700/9765] Loss_D: 0.0950 Loss_G: 0.0412 Convergence: 0.0987 k= 0.020082 lr = 0.0000090\n",
      "[14/25][4710/9765] Loss_D: 0.1014 Loss_G: 0.0407 Convergence: 0.1023 k= 0.020066 lr = 0.0000090\n",
      "[14/25][4720/9765] Loss_D: 0.0946 Loss_G: 0.0405 Convergence: 0.0977 k= 0.020062 lr = 0.0000090\n",
      "[14/25][4730/9765] Loss_D: 0.0993 Loss_G: 0.0370 Convergence: 0.1030 k= 0.020061 lr = 0.0000090\n",
      "[14/25][4740/9765] Loss_D: 0.0965 Loss_G: 0.0380 Convergence: 0.0981 k= 0.020080 lr = 0.0000090\n",
      "[14/25][4750/9765] Loss_D: 0.0892 Loss_G: 0.0375 Convergence: 0.0914 k= 0.020085 lr = 0.0000090\n",
      "[14/25][4760/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1036 k= 0.020113 lr = 0.0000090\n",
      "[14/25][4770/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0960 k= 0.020111 lr = 0.0000090\n",
      "[14/25][4780/9765] Loss_D: 0.0987 Loss_G: 0.0479 Convergence: 0.1077 k= 0.020092 lr = 0.0000090\n",
      "[14/25][4790/9765] Loss_D: 0.0984 Loss_G: 0.0445 Convergence: 0.1041 k= 0.020036 lr = 0.0000090\n",
      "[14/25][4800/9765] Loss_D: 0.0955 Loss_G: 0.0414 Convergence: 0.0992 k= 0.019980 lr = 0.0000090\n",
      "[14/25][4810/9765] Loss_D: 0.1008 Loss_G: 0.0389 Convergence: 0.1033 k= 0.019967 lr = 0.0000090\n",
      "[14/25][4820/9765] Loss_D: 0.1013 Loss_G: 0.0359 Convergence: 0.1069 k= 0.019984 lr = 0.0000090\n",
      "[14/25][4830/9765] Loss_D: 0.1011 Loss_G: 0.0364 Convergence: 0.1062 k= 0.020026 lr = 0.0000090\n",
      "[14/25][4840/9765] Loss_D: 0.0937 Loss_G: 0.0355 Convergence: 0.0966 k= 0.020063 lr = 0.0000090\n",
      "[14/25][4850/9765] Loss_D: 0.0952 Loss_G: 0.0407 Convergence: 0.0983 k= 0.020076 lr = 0.0000090\n",
      "[14/25][4860/9765] Loss_D: 0.0912 Loss_G: 0.0385 Convergence: 0.0937 k= 0.020058 lr = 0.0000090\n",
      "[14/25][4870/9765] Loss_D: 0.1041 Loss_G: 0.0391 Convergence: 0.1078 k= 0.020038 lr = 0.0000090\n",
      "[14/25][4880/9765] Loss_D: 0.1046 Loss_G: 0.0430 Convergence: 0.1063 k= 0.020014 lr = 0.0000090\n",
      "[14/25][4890/9765] Loss_D: 0.0821 Loss_G: 0.0392 Convergence: 0.0889 k= 0.019971 lr = 0.0000090\n",
      "[14/25][4900/9765] Loss_D: 0.0976 Loss_G: 0.0398 Convergence: 0.0989 k= 0.019971 lr = 0.0000090\n",
      "[14/25][4910/9765] Loss_D: 0.0852 Loss_G: 0.0376 Convergence: 0.0892 k= 0.019975 lr = 0.0000090\n",
      "[14/25][4920/9765] Loss_D: 0.0962 Loss_G: 0.0382 Convergence: 0.0976 k= 0.019982 lr = 0.0000090\n",
      "[14/25][4930/9765] Loss_D: 0.0993 Loss_G: 0.0401 Convergence: 0.1001 k= 0.019990 lr = 0.0000090\n",
      "[14/25][4940/9765] Loss_D: 0.0911 Loss_G: 0.0393 Convergence: 0.0944 k= 0.019990 lr = 0.0000090\n",
      "[14/25][4950/9765] Loss_D: 0.0961 Loss_G: 0.0384 Convergence: 0.0972 k= 0.019980 lr = 0.0000090\n",
      "[14/25][4960/9765] Loss_D: 0.0942 Loss_G: 0.0396 Convergence: 0.0966 k= 0.019971 lr = 0.0000090\n",
      "[14/25][4970/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0973 k= 0.019965 lr = 0.0000090\n",
      "[14/25][4980/9765] Loss_D: 0.1049 Loss_G: 0.0381 Convergence: 0.1097 k= 0.019986 lr = 0.0000090\n",
      "[14/25][4990/9765] Loss_D: 0.0977 Loss_G: 0.0388 Convergence: 0.0990 k= 0.019985 lr = 0.0000090\n",
      "[14/25][5000/9765] Loss_D: 0.0916 Loss_G: 0.0400 Convergence: 0.0954 k= 0.019991 lr = 0.0000090\n",
      "[14/25][5010/9765] Loss_D: 0.0964 Loss_G: 0.0378 Convergence: 0.0982 k= 0.019998 lr = 0.0000090\n",
      "[14/25][5020/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1002 k= 0.019985 lr = 0.0000090\n",
      "[14/25][5030/9765] Loss_D: 0.1037 Loss_G: 0.0388 Convergence: 0.1074 k= 0.019982 lr = 0.0000090\n",
      "[14/25][5040/9765] Loss_D: 0.1010 Loss_G: 0.0380 Convergence: 0.1044 k= 0.019978 lr = 0.0000090\n",
      "[14/25][5050/9765] Loss_D: 0.0930 Loss_G: 0.0383 Convergence: 0.0946 k= 0.019983 lr = 0.0000090\n",
      "[14/25][5060/9765] Loss_D: 0.0972 Loss_G: 0.0391 Convergence: 0.0980 k= 0.019980 lr = 0.0000090\n",
      "[14/25][5070/9765] Loss_D: 0.0803 Loss_G: 0.0362 Convergence: 0.0848 k= 0.019987 lr = 0.0000090\n",
      "[14/25][5080/9765] Loss_D: 0.0968 Loss_G: 0.0364 Convergence: 0.1001 k= 0.020006 lr = 0.0000090\n",
      "[14/25][5090/9765] Loss_D: 0.0996 Loss_G: 0.0381 Convergence: 0.1024 k= 0.020009 lr = 0.0000090\n",
      "[14/25][5100/9765] Loss_D: 0.1104 Loss_G: 0.0407 Convergence: 0.1149 k= 0.020005 lr = 0.0000090\n",
      "[14/25][5110/9765] Loss_D: 0.0946 Loss_G: 0.0399 Convergence: 0.0971 k= 0.019987 lr = 0.0000090\n",
      "[14/25][5120/9765] Loss_D: 0.0875 Loss_G: 0.0382 Convergence: 0.0911 k= 0.019999 lr = 0.0000090\n",
      "[14/25][5130/9765] Loss_D: 0.0929 Loss_G: 0.0398 Convergence: 0.0960 k= 0.019996 lr = 0.0000090\n",
      "[14/25][5140/9765] Loss_D: 0.1046 Loss_G: 0.0374 Convergence: 0.1102 k= 0.020012 lr = 0.0000090\n",
      "[14/25][5150/9765] Loss_D: 0.0908 Loss_G: 0.0372 Convergence: 0.0921 k= 0.020028 lr = 0.0000090\n",
      "[14/25][5160/9765] Loss_D: 0.0938 Loss_G: 0.0370 Convergence: 0.0953 k= 0.020050 lr = 0.0000090\n",
      "[14/25][5170/9765] Loss_D: 0.1037 Loss_G: 0.0359 Convergence: 0.1102 k= 0.020070 lr = 0.0000090\n",
      "[14/25][5180/9765] Loss_D: 0.0957 Loss_G: 0.0371 Convergence: 0.0979 k= 0.020106 lr = 0.0000090\n",
      "[14/25][5190/9765] Loss_D: 0.1102 Loss_G: 0.0404 Convergence: 0.1151 k= 0.020110 lr = 0.0000090\n",
      "[14/25][5200/9765] Loss_D: 0.0982 Loss_G: 0.0429 Convergence: 0.1023 k= 0.020089 lr = 0.0000090\n",
      "[14/25][5210/9765] Loss_D: 0.0906 Loss_G: 0.0396 Convergence: 0.0945 k= 0.020076 lr = 0.0000090\n",
      "[14/25][5220/9765] Loss_D: 0.0961 Loss_G: 0.0412 Convergence: 0.0994 k= 0.020075 lr = 0.0000090\n",
      "[14/25][5230/9765] Loss_D: 0.1011 Loss_G: 0.0398 Convergence: 0.1028 k= 0.020055 lr = 0.0000090\n",
      "[14/25][5240/9765] Loss_D: 0.0881 Loss_G: 0.0364 Convergence: 0.0897 k= 0.020059 lr = 0.0000090\n",
      "[14/25][5250/9765] Loss_D: 0.0992 Loss_G: 0.0370 Convergence: 0.1030 k= 0.020078 lr = 0.0000090\n",
      "[14/25][5260/9765] Loss_D: 0.1017 Loss_G: 0.0369 Convergence: 0.1065 k= 0.020085 lr = 0.0000090\n",
      "[14/25][5270/9765] Loss_D: 0.1002 Loss_G: 0.0409 Convergence: 0.1014 k= 0.020093 lr = 0.0000090\n",
      "[14/25][5280/9765] Loss_D: 0.0940 Loss_G: 0.0407 Convergence: 0.0975 k= 0.020086 lr = 0.0000090\n",
      "[14/25][5290/9765] Loss_D: 0.0979 Loss_G: 0.0401 Convergence: 0.0994 k= 0.020079 lr = 0.0000090\n",
      "[14/25][5300/9765] Loss_D: 0.0934 Loss_G: 0.0407 Convergence: 0.0972 k= 0.020085 lr = 0.0000090\n",
      "[14/25][5310/9765] Loss_D: 0.0930 Loss_G: 0.0374 Convergence: 0.0939 k= 0.020082 lr = 0.0000090\n",
      "[14/25][5320/9765] Loss_D: 0.0952 Loss_G: 0.0376 Convergence: 0.0967 k= 0.020101 lr = 0.0000090\n",
      "[14/25][5330/9765] Loss_D: 0.1076 Loss_G: 0.0375 Convergence: 0.1141 k= 0.020124 lr = 0.0000090\n",
      "[14/25][5340/9765] Loss_D: 0.0965 Loss_G: 0.0384 Convergence: 0.0977 k= 0.020128 lr = 0.0000090\n",
      "[14/25][5350/9765] Loss_D: 0.0953 Loss_G: 0.0404 Convergence: 0.0981 k= 0.020117 lr = 0.0000090\n",
      "[14/25][5360/9765] Loss_D: 0.0966 Loss_G: 0.0406 Convergence: 0.0990 k= 0.020118 lr = 0.0000090\n",
      "[14/25][5370/9765] Loss_D: 0.1008 Loss_G: 0.0439 Convergence: 0.1049 k= 0.020099 lr = 0.0000090\n",
      "[14/25][5380/9765] Loss_D: 0.0960 Loss_G: 0.0389 Convergence: 0.0970 k= 0.020072 lr = 0.0000090\n",
      "[14/25][5390/9765] Loss_D: 0.0957 Loss_G: 0.0411 Convergence: 0.0990 k= 0.020057 lr = 0.0000090\n",
      "[14/25][5400/9765] Loss_D: 0.0944 Loss_G: 0.0416 Convergence: 0.0987 k= 0.020037 lr = 0.0000090\n",
      "[14/25][5410/9765] Loss_D: 0.1074 Loss_G: 0.0362 Convergence: 0.1151 k= 0.020033 lr = 0.0000090\n",
      "[14/25][5420/9765] Loss_D: 0.0959 Loss_G: 0.0389 Convergence: 0.0969 k= 0.020056 lr = 0.0000090\n",
      "[14/25][5430/9765] Loss_D: 0.0942 Loss_G: 0.0342 Convergence: 0.0986 k= 0.020086 lr = 0.0000090\n",
      "[14/25][5440/9765] Loss_D: 0.0953 Loss_G: 0.0366 Convergence: 0.0979 k= 0.020123 lr = 0.0000090\n",
      "[14/25][5450/9765] Loss_D: 0.0980 Loss_G: 0.0392 Convergence: 0.0992 k= 0.020127 lr = 0.0000090\n",
      "[14/25][5460/9765] Loss_D: 0.0887 Loss_G: 0.0398 Convergence: 0.0935 k= 0.020138 lr = 0.0000090\n",
      "[14/25][5470/9765] Loss_D: 0.0938 Loss_G: 0.0382 Convergence: 0.0949 k= 0.020126 lr = 0.0000090\n",
      "[14/25][5480/9765] Loss_D: 0.0977 Loss_G: 0.0393 Convergence: 0.0985 k= 0.020132 lr = 0.0000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][5490/9765] Loss_D: 0.1007 Loss_G: 0.0386 Convergence: 0.1035 k= 0.020138 lr = 0.0000090\n",
      "[14/25][5500/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0984 k= 0.020137 lr = 0.0000090\n",
      "[14/25][5510/9765] Loss_D: 0.0931 Loss_G: 0.0388 Convergence: 0.0951 k= 0.020148 lr = 0.0000090\n",
      "[14/25][5520/9765] Loss_D: 0.1009 Loss_G: 0.0373 Convergence: 0.1050 k= 0.020170 lr = 0.0000090\n",
      "[14/25][5530/9765] Loss_D: 0.0944 Loss_G: 0.0392 Convergence: 0.0963 k= 0.020177 lr = 0.0000090\n",
      "[14/25][5540/9765] Loss_D: 0.0885 Loss_G: 0.0385 Convergence: 0.0920 k= 0.020174 lr = 0.0000090\n",
      "[14/25][5550/9765] Loss_D: 0.1126 Loss_G: 0.0398 Convergence: 0.1189 k= 0.020187 lr = 0.0000090\n",
      "[14/25][5560/9765] Loss_D: 0.1023 Loss_G: 0.0404 Convergence: 0.1039 k= 0.020182 lr = 0.0000090\n",
      "[14/25][5570/9765] Loss_D: 0.0894 Loss_G: 0.0386 Convergence: 0.0928 k= 0.020185 lr = 0.0000090\n",
      "[14/25][5580/9765] Loss_D: 0.1033 Loss_G: 0.0395 Convergence: 0.1062 k= 0.020201 lr = 0.0000090\n",
      "[14/25][5590/9765] Loss_D: 0.0881 Loss_G: 0.0392 Convergence: 0.0925 k= 0.020207 lr = 0.0000090\n",
      "[14/25][5600/9765] Loss_D: 0.1019 Loss_G: 0.0420 Convergence: 0.1036 k= 0.020191 lr = 0.0000090\n",
      "[14/25][5610/9765] Loss_D: 0.1018 Loss_G: 0.0375 Convergence: 0.1060 k= 0.020200 lr = 0.0000090\n",
      "[14/25][5620/9765] Loss_D: 0.0903 Loss_G: 0.0387 Convergence: 0.0934 k= 0.020204 lr = 0.0000090\n",
      "[14/25][5630/9765] Loss_D: 0.0973 Loss_G: 0.0394 Convergence: 0.0982 k= 0.020207 lr = 0.0000090\n",
      "[14/25][5640/9765] Loss_D: 0.0952 Loss_G: 0.0398 Convergence: 0.0973 k= 0.020213 lr = 0.0000090\n",
      "[14/25][5650/9765] Loss_D: 0.0962 Loss_G: 0.0382 Convergence: 0.0975 k= 0.020216 lr = 0.0000090\n",
      "[14/25][5660/9765] Loss_D: 0.0988 Loss_G: 0.0391 Convergence: 0.1004 k= 0.020215 lr = 0.0000090\n",
      "[14/25][5670/9765] Loss_D: 0.0882 Loss_G: 0.0383 Convergence: 0.0917 k= 0.020213 lr = 0.0000090\n",
      "[14/25][5680/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.0997 k= 0.020219 lr = 0.0000090\n",
      "[14/25][5690/9765] Loss_D: 0.0950 Loss_G: 0.0424 Convergence: 0.0999 k= 0.020199 lr = 0.0000090\n",
      "[14/25][5700/9765] Loss_D: 0.1034 Loss_G: 0.0404 Convergence: 0.1054 k= 0.020188 lr = 0.0000090\n",
      "[14/25][5710/9765] Loss_D: 0.0937 Loss_G: 0.0377 Convergence: 0.0945 k= 0.020190 lr = 0.0000090\n",
      "[14/25][5720/9765] Loss_D: 0.1040 Loss_G: 0.0361 Convergence: 0.1106 k= 0.020212 lr = 0.0000090\n",
      "[14/25][5730/9765] Loss_D: 0.0920 Loss_G: 0.0387 Convergence: 0.0944 k= 0.020226 lr = 0.0000090\n",
      "[14/25][5740/9765] Loss_D: 0.0933 Loss_G: 0.0392 Convergence: 0.0957 k= 0.020231 lr = 0.0000090\n",
      "[14/25][5750/9765] Loss_D: 0.1021 Loss_G: 0.0371 Convergence: 0.1068 k= 0.020234 lr = 0.0000090\n",
      "[14/25][5760/9765] Loss_D: 0.1050 Loss_G: 0.0360 Convergence: 0.1121 k= 0.020253 lr = 0.0000090\n",
      "[14/25][5770/9765] Loss_D: 0.1015 Loss_G: 0.0375 Convergence: 0.1057 k= 0.020280 lr = 0.0000090\n",
      "[14/25][5780/9765] Loss_D: 0.0915 Loss_G: 0.0383 Convergence: 0.0936 k= 0.020292 lr = 0.0000090\n",
      "[14/25][5790/9765] Loss_D: 0.0880 Loss_G: 0.0393 Convergence: 0.0925 k= 0.020297 lr = 0.0000090\n",
      "[14/25][5800/9765] Loss_D: 0.0939 Loss_G: 0.0389 Convergence: 0.0957 k= 0.020293 lr = 0.0000090\n",
      "[14/25][5810/9765] Loss_D: 0.0899 Loss_G: 0.0377 Convergence: 0.0920 k= 0.020306 lr = 0.0000090\n",
      "[14/25][5820/9765] Loss_D: 0.0967 Loss_G: 0.0377 Convergence: 0.0987 k= 0.020308 lr = 0.0000090\n",
      "[14/25][5830/9765] Loss_D: 0.0971 Loss_G: 0.0401 Convergence: 0.0989 k= 0.020301 lr = 0.0000090\n",
      "[14/25][5840/9765] Loss_D: 0.1038 Loss_G: 0.0413 Convergence: 0.1051 k= 0.020292 lr = 0.0000090\n",
      "[14/25][5850/9765] Loss_D: 0.0936 Loss_G: 0.0375 Convergence: 0.0947 k= 0.020297 lr = 0.0000090\n",
      "[14/25][5860/9765] Loss_D: 0.0875 Loss_G: 0.0371 Convergence: 0.0901 k= 0.020290 lr = 0.0000090\n",
      "[14/25][5870/9765] Loss_D: 0.0929 Loss_G: 0.0384 Convergence: 0.0946 k= 0.020294 lr = 0.0000090\n",
      "[14/25][5880/9765] Loss_D: 0.1082 Loss_G: 0.0402 Convergence: 0.1124 k= 0.020302 lr = 0.0000090\n",
      "[14/25][5890/9765] Loss_D: 0.0992 Loss_G: 0.0403 Convergence: 0.1003 k= 0.020298 lr = 0.0000090\n",
      "[14/25][5900/9765] Loss_D: 0.0872 Loss_G: 0.0385 Convergence: 0.0913 k= 0.020300 lr = 0.0000090\n",
      "[14/25][5910/9765] Loss_D: 0.0903 Loss_G: 0.0391 Convergence: 0.0938 k= 0.020292 lr = 0.0000090\n",
      "[14/25][5920/9765] Loss_D: 0.0945 Loss_G: 0.0417 Convergence: 0.0989 k= 0.020287 lr = 0.0000090\n",
      "[14/25][5930/9765] Loss_D: 0.0821 Loss_G: 0.0400 Convergence: 0.0898 k= 0.020264 lr = 0.0000090\n",
      "[14/25][5940/9765] Loss_D: 0.0931 Loss_G: 0.0423 Convergence: 0.0987 k= 0.020244 lr = 0.0000090\n",
      "[14/25][5950/9765] Loss_D: 0.0971 Loss_G: 0.0411 Convergence: 0.0999 k= 0.020226 lr = 0.0000090\n",
      "[14/25][5960/9765] Loss_D: 0.1013 Loss_G: 0.0379 Convergence: 0.1050 k= 0.020219 lr = 0.0000090\n",
      "[14/25][5970/9765] Loss_D: 0.0943 Loss_G: 0.0360 Convergence: 0.0969 k= 0.020251 lr = 0.0000090\n",
      "[14/25][5980/9765] Loss_D: 0.0996 Loss_G: 0.0367 Convergence: 0.1038 k= 0.020274 lr = 0.0000090\n",
      "[14/25][5990/9765] Loss_D: 0.0933 Loss_G: 0.0384 Convergence: 0.0948 k= 0.020269 lr = 0.0000090\n",
      "[14/25][6000/9765] Loss_D: 0.0892 Loss_G: 0.0376 Convergence: 0.0915 k= 0.020288 lr = 0.0000090\n",
      "[14/25][6010/9765] Loss_D: 0.0923 Loss_G: 0.0377 Convergence: 0.0936 k= 0.020290 lr = 0.0000090\n",
      "[14/25][6020/9765] Loss_D: 0.0940 Loss_G: 0.0384 Convergence: 0.0952 k= 0.020301 lr = 0.0000090\n",
      "[14/25][6030/9765] Loss_D: 0.0895 Loss_G: 0.0369 Convergence: 0.0911 k= 0.020307 lr = 0.0000090\n",
      "[14/25][6040/9765] Loss_D: 0.0912 Loss_G: 0.0395 Convergence: 0.0947 k= 0.020297 lr = 0.0000090\n",
      "[14/25][6050/9765] Loss_D: 0.1011 Loss_G: 0.0410 Convergence: 0.1022 k= 0.020294 lr = 0.0000090\n",
      "[14/25][6060/9765] Loss_D: 0.0941 Loss_G: 0.0403 Convergence: 0.0972 k= 0.020270 lr = 0.0000090\n",
      "[14/25][6070/9765] Loss_D: 0.0984 Loss_G: 0.0395 Convergence: 0.0994 k= 0.020270 lr = 0.0000090\n",
      "[14/25][6080/9765] Loss_D: 0.0893 Loss_G: 0.0399 Convergence: 0.0939 k= 0.020256 lr = 0.0000090\n",
      "[14/25][6090/9765] Loss_D: 0.0959 Loss_G: 0.0391 Convergence: 0.0971 k= 0.020243 lr = 0.0000090\n",
      "[14/25][6100/9765] Loss_D: 0.0936 Loss_G: 0.0377 Convergence: 0.0945 k= 0.020236 lr = 0.0000090\n",
      "[14/25][6110/9765] Loss_D: 0.0937 Loss_G: 0.0362 Convergence: 0.0960 k= 0.020241 lr = 0.0000090\n",
      "[14/25][6120/9765] Loss_D: 0.0889 Loss_G: 0.0373 Convergence: 0.0911 k= 0.020244 lr = 0.0000090\n",
      "[14/25][6130/9765] Loss_D: 0.1010 Loss_G: 0.0380 Convergence: 0.1044 k= 0.020258 lr = 0.0000090\n",
      "[14/25][6140/9765] Loss_D: 0.1032 Loss_G: 0.0405 Convergence: 0.1051 k= 0.020261 lr = 0.0000090\n",
      "[14/25][6150/9765] Loss_D: 0.1026 Loss_G: 0.0406 Convergence: 0.1041 k= 0.020258 lr = 0.0000090\n",
      "[14/25][6160/9765] Loss_D: 0.0960 Loss_G: 0.0401 Convergence: 0.0982 k= 0.020256 lr = 0.0000090\n",
      "[14/25][6170/9765] Loss_D: 0.0968 Loss_G: 0.0387 Convergence: 0.0980 k= 0.020254 lr = 0.0000090\n",
      "[14/25][6180/9765] Loss_D: 0.1040 Loss_G: 0.0375 Convergence: 0.1092 k= 0.020273 lr = 0.0000090\n",
      "[14/25][6190/9765] Loss_D: 0.0938 Loss_G: 0.0385 Convergence: 0.0953 k= 0.020285 lr = 0.0000090\n",
      "[14/25][6200/9765] Loss_D: 0.1035 Loss_G: 0.0394 Convergence: 0.1066 k= 0.020286 lr = 0.0000090\n",
      "[14/25][6210/9765] Loss_D: 0.0959 Loss_G: 0.0390 Convergence: 0.0970 k= 0.020305 lr = 0.0000090\n",
      "[14/25][6220/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.0998 k= 0.020313 lr = 0.0000090\n",
      "[14/25][6230/9765] Loss_D: 0.1008 Loss_G: 0.0402 Convergence: 0.1020 k= 0.020312 lr = 0.0000090\n",
      "[14/25][6240/9765] Loss_D: 0.1018 Loss_G: 0.0375 Convergence: 0.1060 k= 0.020323 lr = 0.0000090\n",
      "[14/25][6250/9765] Loss_D: 0.0869 Loss_G: 0.0381 Convergence: 0.0907 k= 0.020326 lr = 0.0000090\n",
      "[14/25][6260/9765] Loss_D: 0.0998 Loss_G: 0.0399 Convergence: 0.1010 k= 0.020339 lr = 0.0000090\n",
      "[14/25][6270/9765] Loss_D: 0.1013 Loss_G: 0.0417 Convergence: 0.1030 k= 0.020323 lr = 0.0000090\n",
      "[14/25][6280/9765] Loss_D: 0.1004 Loss_G: 0.0402 Convergence: 0.1015 k= 0.020316 lr = 0.0000090\n",
      "[14/25][6290/9765] Loss_D: 0.1011 Loss_G: 0.0411 Convergence: 0.1022 k= 0.020304 lr = 0.0000090\n",
      "[14/25][6300/9765] Loss_D: 0.0965 Loss_G: 0.0381 Convergence: 0.0981 k= 0.020302 lr = 0.0000090\n",
      "[14/25][6310/9765] Loss_D: 0.0944 Loss_G: 0.0375 Convergence: 0.0957 k= 0.020311 lr = 0.0000090\n",
      "[14/25][6320/9765] Loss_D: 0.1006 Loss_G: 0.0381 Convergence: 0.1038 k= 0.020317 lr = 0.0000090\n",
      "[14/25][6330/9765] Loss_D: 0.0983 Loss_G: 0.0403 Convergence: 0.0997 k= 0.020315 lr = 0.0000090\n",
      "[14/25][6340/9765] Loss_D: 0.0966 Loss_G: 0.0416 Convergence: 0.1000 k= 0.020299 lr = 0.0000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][6350/9765] Loss_D: 0.0949 Loss_G: 0.0429 Convergence: 0.1003 k= 0.020272 lr = 0.0000090\n",
      "[14/25][6360/9765] Loss_D: 0.1040 Loss_G: 0.0380 Convergence: 0.1087 k= 0.020262 lr = 0.0000090\n",
      "[14/25][6370/9765] Loss_D: 0.1031 Loss_G: 0.0393 Convergence: 0.1061 k= 0.020267 lr = 0.0000090\n",
      "[14/25][6380/9765] Loss_D: 0.0941 Loss_G: 0.0366 Convergence: 0.0962 k= 0.020272 lr = 0.0000090\n",
      "[14/25][6390/9765] Loss_D: 0.0928 Loss_G: 0.0372 Convergence: 0.0937 k= 0.020290 lr = 0.0000090\n",
      "[14/25][6400/9765] Loss_D: 0.0975 Loss_G: 0.0382 Convergence: 0.0994 k= 0.020291 lr = 0.0000090\n",
      "[14/25][6410/9765] Loss_D: 0.1009 Loss_G: 0.0390 Convergence: 0.1035 k= 0.020293 lr = 0.0000090\n",
      "[14/25][6420/9765] Loss_D: 0.0993 Loss_G: 0.0402 Convergence: 0.1002 k= 0.020280 lr = 0.0000090\n",
      "[14/25][6430/9765] Loss_D: 0.1021 Loss_G: 0.0428 Convergence: 0.1046 k= 0.020247 lr = 0.0000090\n",
      "[14/25][6440/9765] Loss_D: 0.1000 Loss_G: 0.0396 Convergence: 0.1016 k= 0.020232 lr = 0.0000090\n",
      "[14/25][6450/9765] Loss_D: 0.0999 Loss_G: 0.0359 Convergence: 0.1050 k= 0.020231 lr = 0.0000090\n",
      "[14/25][6460/9765] Loss_D: 0.0986 Loss_G: 0.0365 Convergence: 0.1026 k= 0.020242 lr = 0.0000090\n",
      "[14/25][6470/9765] Loss_D: 0.1028 Loss_G: 0.0401 Convergence: 0.1049 k= 0.020261 lr = 0.0000090\n",
      "[14/25][6480/9765] Loss_D: 0.0952 Loss_G: 0.0393 Convergence: 0.0970 k= 0.020257 lr = 0.0000090\n",
      "[14/25][6490/9765] Loss_D: 0.1047 Loss_G: 0.0392 Convergence: 0.1084 k= 0.020255 lr = 0.0000090\n",
      "[14/25][6500/9765] Loss_D: 0.0919 Loss_G: 0.0402 Convergence: 0.0958 k= 0.020255 lr = 0.0000090\n",
      "[14/25][6510/9765] Loss_D: 0.1023 Loss_G: 0.0423 Convergence: 0.1042 k= 0.020252 lr = 0.0000090\n",
      "[14/25][6520/9765] Loss_D: 0.1040 Loss_G: 0.0390 Convergence: 0.1077 k= 0.020249 lr = 0.0000090\n",
      "[14/25][6530/9765] Loss_D: 0.0937 Loss_G: 0.0382 Convergence: 0.0948 k= 0.020250 lr = 0.0000090\n",
      "[14/25][6540/9765] Loss_D: 0.1069 Loss_G: 0.0402 Convergence: 0.1106 k= 0.020251 lr = 0.0000090\n",
      "[14/25][6550/9765] Loss_D: 0.0878 Loss_G: 0.0388 Convergence: 0.0920 k= 0.020248 lr = 0.0000090\n",
      "[14/25][6560/9765] Loss_D: 0.0971 Loss_G: 0.0419 Convergence: 0.1006 k= 0.020240 lr = 0.0000090\n",
      "[14/25][6570/9765] Loss_D: 0.0982 Loss_G: 0.0416 Convergence: 0.1009 k= 0.020233 lr = 0.0000090\n",
      "[14/25][6580/9765] Loss_D: 0.1004 Loss_G: 0.0420 Convergence: 0.1028 k= 0.020217 lr = 0.0000090\n",
      "[14/25][6590/9765] Loss_D: 0.0933 Loss_G: 0.0385 Convergence: 0.0950 k= 0.020224 lr = 0.0000090\n",
      "[14/25][6600/9765] Loss_D: 0.0887 Loss_G: 0.0389 Convergence: 0.0926 k= 0.020222 lr = 0.0000090\n",
      "[14/25][6610/9765] Loss_D: 0.1016 Loss_G: 0.0406 Convergence: 0.1028 k= 0.020225 lr = 0.0000090\n",
      "[14/25][6620/9765] Loss_D: 0.0954 Loss_G: 0.0410 Convergence: 0.0987 k= 0.020203 lr = 0.0000090\n",
      "[14/25][6630/9765] Loss_D: 0.1063 Loss_G: 0.0430 Convergence: 0.1073 k= 0.020176 lr = 0.0000090\n",
      "[14/25][6640/9765] Loss_D: 0.1088 Loss_G: 0.0411 Convergence: 0.1124 k= 0.020144 lr = 0.0000090\n",
      "[14/25][6650/9765] Loss_D: 0.1067 Loss_G: 0.0397 Convergence: 0.1109 k= 0.020137 lr = 0.0000090\n",
      "[14/25][6660/9765] Loss_D: 0.1079 Loss_G: 0.0377 Convergence: 0.1144 k= 0.020153 lr = 0.0000090\n",
      "[14/25][6670/9765] Loss_D: 0.0881 Loss_G: 0.0336 Convergence: 0.0906 k= 0.020177 lr = 0.0000090\n",
      "[14/25][6680/9765] Loss_D: 0.0959 Loss_G: 0.0331 Convergence: 0.1021 k= 0.020231 lr = 0.0000090\n",
      "[14/25][6690/9765] Loss_D: 0.0891 Loss_G: 0.0348 Convergence: 0.0910 k= 0.020271 lr = 0.0000090\n",
      "[14/25][6700/9765] Loss_D: 0.1018 Loss_G: 0.0407 Convergence: 0.1029 k= 0.020279 lr = 0.0000090\n",
      "[14/25][6710/9765] Loss_D: 0.0981 Loss_G: 0.0445 Convergence: 0.1038 k= 0.020238 lr = 0.0000090\n",
      "[14/25][6720/9765] Loss_D: 0.0940 Loss_G: 0.0400 Convergence: 0.0969 k= 0.020206 lr = 0.0000090\n",
      "[14/25][6730/9765] Loss_D: 0.0971 Loss_G: 0.0397 Convergence: 0.0984 k= 0.020192 lr = 0.0000090\n",
      "[14/25][6740/9765] Loss_D: 0.0951 Loss_G: 0.0407 Convergence: 0.0983 k= 0.020182 lr = 0.0000090\n",
      "[14/25][6750/9765] Loss_D: 0.1101 Loss_G: 0.0395 Convergence: 0.1158 k= 0.020178 lr = 0.0000090\n",
      "[14/25][6760/9765] Loss_D: 0.0986 Loss_G: 0.0398 Convergence: 0.0994 k= 0.020187 lr = 0.0000090\n",
      "[14/25][6770/9765] Loss_D: 0.1038 Loss_G: 0.0401 Convergence: 0.1063 k= 0.020197 lr = 0.0000090\n",
      "[14/25][6780/9765] Loss_D: 0.1054 Loss_G: 0.0402 Convergence: 0.1085 k= 0.020208 lr = 0.0000090\n",
      "[14/25][6790/9765] Loss_D: 0.0915 Loss_G: 0.0398 Convergence: 0.0951 k= 0.020195 lr = 0.0000090\n",
      "[14/25][6800/9765] Loss_D: 0.1005 Loss_G: 0.0414 Convergence: 0.1022 k= 0.020185 lr = 0.0000090\n",
      "[14/25][6810/9765] Loss_D: 0.1001 Loss_G: 0.0409 Convergence: 0.1015 k= 0.020172 lr = 0.0000090\n",
      "[14/25][6820/9765] Loss_D: 0.1015 Loss_G: 0.0392 Convergence: 0.1040 k= 0.020177 lr = 0.0000090\n",
      "[14/25][6830/9765] Loss_D: 0.0976 Loss_G: 0.0395 Convergence: 0.0985 k= 0.020172 lr = 0.0000090\n",
      "[14/25][6840/9765] Loss_D: 0.0903 Loss_G: 0.0371 Convergence: 0.0918 k= 0.020171 lr = 0.0000090\n",
      "[14/25][6850/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0967 k= 0.020186 lr = 0.0000090\n",
      "[14/25][6860/9765] Loss_D: 0.1031 Loss_G: 0.0387 Convergence: 0.1068 k= 0.020205 lr = 0.0000090\n",
      "[14/25][6870/9765] Loss_D: 0.1098 Loss_G: 0.0423 Convergence: 0.1126 k= 0.020199 lr = 0.0000090\n",
      "[14/25][6880/9765] Loss_D: 0.1013 Loss_G: 0.0404 Convergence: 0.1026 k= 0.020200 lr = 0.0000090\n",
      "[14/25][6890/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0991 k= 0.020199 lr = 0.0000090\n",
      "[14/25][6900/9765] Loss_D: 0.0975 Loss_G: 0.0403 Convergence: 0.0992 k= 0.020185 lr = 0.0000090\n",
      "[14/25][6910/9765] Loss_D: 0.0917 Loss_G: 0.0365 Convergence: 0.0929 k= 0.020181 lr = 0.0000090\n",
      "[14/25][6920/9765] Loss_D: 0.0993 Loss_G: 0.0385 Convergence: 0.1016 k= 0.020210 lr = 0.0000090\n",
      "[14/25][6930/9765] Loss_D: 0.0970 Loss_G: 0.0378 Convergence: 0.0990 k= 0.020215 lr = 0.0000090\n",
      "[14/25][6940/9765] Loss_D: 0.0994 Loss_G: 0.0376 Convergence: 0.1027 k= 0.020220 lr = 0.0000090\n",
      "[14/25][6950/9765] Loss_D: 0.1008 Loss_G: 0.0393 Convergence: 0.1030 k= 0.020223 lr = 0.0000090\n",
      "[14/25][6960/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0960 k= 0.020216 lr = 0.0000090\n",
      "[14/25][6970/9765] Loss_D: 0.1055 Loss_G: 0.0382 Convergence: 0.1106 k= 0.020207 lr = 0.0000090\n",
      "[14/25][6980/9765] Loss_D: 0.0900 Loss_G: 0.0393 Convergence: 0.0938 k= 0.020210 lr = 0.0000090\n",
      "[14/25][6990/9765] Loss_D: 0.0928 Loss_G: 0.0401 Convergence: 0.0963 k= 0.020217 lr = 0.0000090\n",
      "[14/25][7000/9765] Loss_D: 0.1110 Loss_G: 0.0399 Convergence: 0.1167 k= 0.020219 lr = 0.0000090\n",
      "[14/25][7010/9765] Loss_D: 0.0951 Loss_G: 0.0365 Convergence: 0.0977 k= 0.020229 lr = 0.0000090\n",
      "[14/25][7020/9765] Loss_D: 0.0993 Loss_G: 0.0367 Convergence: 0.1034 k= 0.020255 lr = 0.0000090\n",
      "[14/25][7030/9765] Loss_D: 0.0995 Loss_G: 0.0405 Convergence: 0.1007 k= 0.020273 lr = 0.0000090\n",
      "[14/25][7040/9765] Loss_D: 0.1025 Loss_G: 0.0420 Convergence: 0.1040 k= 0.020253 lr = 0.0000090\n",
      "[14/25][7050/9765] Loss_D: 0.1009 Loss_G: 0.0416 Convergence: 0.1027 k= 0.020226 lr = 0.0000090\n",
      "[14/25][7060/9765] Loss_D: 0.0947 Loss_G: 0.0405 Convergence: 0.0978 k= 0.020211 lr = 0.0000090\n",
      "[14/25][7070/9765] Loss_D: 0.0948 Loss_G: 0.0402 Convergence: 0.0976 k= 0.020205 lr = 0.0000090\n",
      "[14/25][7080/9765] Loss_D: 0.0957 Loss_G: 0.0400 Convergence: 0.0979 k= 0.020201 lr = 0.0000090\n",
      "[14/25][7090/9765] Loss_D: 0.1083 Loss_G: 0.0370 Convergence: 0.1156 k= 0.020225 lr = 0.0000090\n",
      "[14/25][7100/9765] Loss_D: 0.0911 Loss_G: 0.0375 Convergence: 0.0927 k= 0.020237 lr = 0.0000090\n",
      "[14/25][7110/9765] Loss_D: 0.0924 Loss_G: 0.0387 Convergence: 0.0947 k= 0.020233 lr = 0.0000090\n",
      "[14/25][7120/9765] Loss_D: 0.0960 Loss_G: 0.0387 Convergence: 0.0968 k= 0.020245 lr = 0.0000090\n",
      "[14/25][7130/9765] Loss_D: 0.0941 Loss_G: 0.0388 Convergence: 0.0958 k= 0.020239 lr = 0.0000090\n",
      "[14/25][7140/9765] Loss_D: 0.0965 Loss_G: 0.0381 Convergence: 0.0981 k= 0.020239 lr = 0.0000090\n",
      "[14/25][7150/9765] Loss_D: 0.0945 Loss_G: 0.0369 Convergence: 0.0964 k= 0.020263 lr = 0.0000090\n",
      "[14/25][7160/9765] Loss_D: 0.0980 Loss_G: 0.0380 Convergence: 0.1003 k= 0.020269 lr = 0.0000090\n",
      "[14/25][7170/9765] Loss_D: 0.0937 Loss_G: 0.0386 Convergence: 0.0953 k= 0.020283 lr = 0.0000090\n",
      "[14/25][7180/9765] Loss_D: 0.0998 Loss_G: 0.0395 Convergence: 0.1014 k= 0.020289 lr = 0.0000090\n",
      "[14/25][7190/9765] Loss_D: 0.1011 Loss_G: 0.0404 Convergence: 0.1023 k= 0.020282 lr = 0.0000090\n",
      "[14/25][7200/9765] Loss_D: 0.1058 Loss_G: 0.0404 Convergence: 0.1088 k= 0.020281 lr = 0.0000090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][7210/9765] Loss_D: 0.0927 Loss_G: 0.0402 Convergence: 0.0963 k= 0.020272 lr = 0.0000090\n",
      "[14/25][7220/9765] Loss_D: 0.0947 Loss_G: 0.0388 Convergence: 0.0961 k= 0.020265 lr = 0.0000090\n",
      "[14/25][7230/9765] Loss_D: 0.1019 Loss_G: 0.0387 Convergence: 0.1051 k= 0.020264 lr = 0.0000090\n",
      "[14/25][7240/9765] Loss_D: 0.1028 Loss_G: 0.0381 Convergence: 0.1069 k= 0.020273 lr = 0.0000090\n",
      "[14/25][7250/9765] Loss_D: 0.0952 Loss_G: 0.0419 Convergence: 0.0995 k= 0.020267 lr = 0.0000090\n",
      "[14/25][7260/9765] Loss_D: 0.0953 Loss_G: 0.0396 Convergence: 0.0972 k= 0.020270 lr = 0.0000090\n",
      "[14/25][7270/9765] Loss_D: 0.0870 Loss_G: 0.0409 Convergence: 0.0936 k= 0.020247 lr = 0.0000090\n",
      "[14/25][7280/9765] Loss_D: 0.0902 Loss_G: 0.0392 Convergence: 0.0938 k= 0.020230 lr = 0.0000090\n",
      "[14/25][7290/9765] Loss_D: 0.0939 Loss_G: 0.0380 Convergence: 0.0948 k= 0.020224 lr = 0.0000085\n",
      "[14/25][7300/9765] Loss_D: 0.1012 Loss_G: 0.0393 Convergence: 0.1035 k= 0.020241 lr = 0.0000085\n",
      "[14/25][7310/9765] Loss_D: 0.0939 Loss_G: 0.0384 Convergence: 0.0952 k= 0.020253 lr = 0.0000085\n",
      "[14/25][7320/9765] Loss_D: 0.0975 Loss_G: 0.0392 Convergence: 0.0984 k= 0.020260 lr = 0.0000085\n",
      "[14/25][7330/9765] Loss_D: 0.0913 Loss_G: 0.0400 Convergence: 0.0953 k= 0.020248 lr = 0.0000085\n",
      "[14/25][7340/9765] Loss_D: 0.0873 Loss_G: 0.0387 Convergence: 0.0916 k= 0.020244 lr = 0.0000085\n",
      "[14/25][7350/9765] Loss_D: 0.1013 Loss_G: 0.0386 Convergence: 0.1044 k= 0.020242 lr = 0.0000085\n",
      "[14/25][7360/9765] Loss_D: 0.0929 Loss_G: 0.0403 Convergence: 0.0966 k= 0.020246 lr = 0.0000085\n",
      "[14/25][7370/9765] Loss_D: 0.0886 Loss_G: 0.0386 Convergence: 0.0922 k= 0.020235 lr = 0.0000085\n",
      "[14/25][7380/9765] Loss_D: 0.0923 Loss_G: 0.0373 Convergence: 0.0931 k= 0.020232 lr = 0.0000085\n",
      "[14/25][7390/9765] Loss_D: 0.0939 Loss_G: 0.0370 Convergence: 0.0954 k= 0.020240 lr = 0.0000085\n",
      "[14/25][7400/9765] Loss_D: 0.0967 Loss_G: 0.0403 Convergence: 0.0988 k= 0.020250 lr = 0.0000085\n",
      "[14/25][7410/9765] Loss_D: 0.1054 Loss_G: 0.0379 Convergence: 0.1106 k= 0.020258 lr = 0.0000085\n",
      "[14/25][7420/9765] Loss_D: 0.0942 Loss_G: 0.0404 Convergence: 0.0975 k= 0.020260 lr = 0.0000085\n",
      "[14/25][7430/9765] Loss_D: 0.0961 Loss_G: 0.0429 Convergence: 0.1011 k= 0.020233 lr = 0.0000085\n",
      "[14/25][7440/9765] Loss_D: 0.1028 Loss_G: 0.0398 Convergence: 0.1052 k= 0.020226 lr = 0.0000085\n",
      "[14/25][7450/9765] Loss_D: 0.0958 Loss_G: 0.0391 Convergence: 0.0970 k= 0.020212 lr = 0.0000085\n",
      "[14/25][7460/9765] Loss_D: 0.1012 Loss_G: 0.0381 Convergence: 0.1047 k= 0.020207 lr = 0.0000085\n",
      "[14/25][7470/9765] Loss_D: 0.0941 Loss_G: 0.0359 Convergence: 0.0969 k= 0.020213 lr = 0.0000085\n",
      "[14/25][7480/9765] Loss_D: 0.1036 Loss_G: 0.0364 Convergence: 0.1096 k= 0.020246 lr = 0.0000085\n",
      "[14/25][7490/9765] Loss_D: 0.0992 Loss_G: 0.0363 Convergence: 0.1035 k= 0.020290 lr = 0.0000085\n",
      "[14/25][7500/9765] Loss_D: 0.0978 Loss_G: 0.0402 Convergence: 0.0994 k= 0.020309 lr = 0.0000085\n",
      "[14/25][7510/9765] Loss_D: 0.0954 Loss_G: 0.0433 Convergence: 0.1011 k= 0.020300 lr = 0.0000085\n",
      "[14/25][7520/9765] Loss_D: 0.1043 Loss_G: 0.0432 Convergence: 0.1063 k= 0.020271 lr = 0.0000085\n",
      "[14/25][7530/9765] Loss_D: 0.1044 Loss_G: 0.0386 Convergence: 0.1087 k= 0.020264 lr = 0.0000085\n",
      "[14/25][7540/9765] Loss_D: 0.1040 Loss_G: 0.0411 Convergence: 0.1057 k= 0.020251 lr = 0.0000085\n",
      "[14/25][7550/9765] Loss_D: 0.0996 Loss_G: 0.0404 Convergence: 0.1007 k= 0.020242 lr = 0.0000085\n",
      "[14/25][7560/9765] Loss_D: 0.0921 Loss_G: 0.0376 Convergence: 0.0933 k= 0.020238 lr = 0.0000085\n",
      "[14/25][7570/9765] Loss_D: 0.0973 Loss_G: 0.0368 Convergence: 0.1004 k= 0.020270 lr = 0.0000085\n",
      "[14/25][7580/9765] Loss_D: 0.0914 Loss_G: 0.0397 Convergence: 0.0950 k= 0.020279 lr = 0.0000085\n",
      "[14/25][7590/9765] Loss_D: 0.0939 Loss_G: 0.0380 Convergence: 0.0948 k= 0.020281 lr = 0.0000085\n",
      "[14/25][7600/9765] Loss_D: 0.0930 Loss_G: 0.0383 Convergence: 0.0945 k= 0.020284 lr = 0.0000085\n",
      "[14/25][7610/9765] Loss_D: 0.1070 Loss_G: 0.0391 Convergence: 0.1118 k= 0.020290 lr = 0.0000085\n",
      "[14/25][7620/9765] Loss_D: 0.0974 Loss_G: 0.0423 Convergence: 0.1013 k= 0.020278 lr = 0.0000085\n",
      "[14/25][7630/9765] Loss_D: 0.0857 Loss_G: 0.0400 Convergence: 0.0919 k= 0.020276 lr = 0.0000085\n",
      "[14/25][7640/9765] Loss_D: 0.0947 Loss_G: 0.0427 Convergence: 0.1001 k= 0.020267 lr = 0.0000085\n",
      "[14/25][7650/9765] Loss_D: 0.0903 Loss_G: 0.0400 Convergence: 0.0947 k= 0.020266 lr = 0.0000085\n",
      "[14/25][7660/9765] Loss_D: 0.0982 Loss_G: 0.0369 Convergence: 0.1015 k= 0.020261 lr = 0.0000085\n",
      "[14/25][7670/9765] Loss_D: 0.0917 Loss_G: 0.0346 Convergence: 0.0947 k= 0.020282 lr = 0.0000085\n",
      "[14/25][7680/9765] Loss_D: 0.0937 Loss_G: 0.0374 Convergence: 0.0948 k= 0.020303 lr = 0.0000085\n",
      "[14/25][7690/9765] Loss_D: 0.0970 Loss_G: 0.0403 Convergence: 0.0990 k= 0.020308 lr = 0.0000085\n",
      "[14/25][7700/9765] Loss_D: 0.0966 Loss_G: 0.0398 Convergence: 0.0982 k= 0.020311 lr = 0.0000085\n",
      "[14/25][7710/9765] Loss_D: 0.0944 Loss_G: 0.0373 Convergence: 0.0959 k= 0.020312 lr = 0.0000085\n",
      "[14/25][7720/9765] Loss_D: 0.0888 Loss_G: 0.0393 Convergence: 0.0931 k= 0.020306 lr = 0.0000085\n",
      "[14/25][7730/9765] Loss_D: 0.1055 Loss_G: 0.0390 Convergence: 0.1097 k= 0.020308 lr = 0.0000085\n",
      "[14/25][7740/9765] Loss_D: 0.0946 Loss_G: 0.0363 Convergence: 0.0971 k= 0.020326 lr = 0.0000085\n",
      "[14/25][7750/9765] Loss_D: 0.0922 Loss_G: 0.0404 Convergence: 0.0962 k= 0.020324 lr = 0.0000085\n",
      "[14/25][7760/9765] Loss_D: 0.1050 Loss_G: 0.0398 Convergence: 0.1082 k= 0.020326 lr = 0.0000085\n",
      "[14/25][7770/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0966 k= 0.020314 lr = 0.0000085\n",
      "[14/25][7780/9765] Loss_D: 0.1075 Loss_G: 0.0396 Convergence: 0.1121 k= 0.020335 lr = 0.0000085\n",
      "[14/25][7790/9765] Loss_D: 0.1055 Loss_G: 0.0395 Convergence: 0.1094 k= 0.020338 lr = 0.0000085\n",
      "[14/25][7800/9765] Loss_D: 0.0991 Loss_G: 0.0406 Convergence: 0.1006 k= 0.020334 lr = 0.0000085\n",
      "[14/25][7810/9765] Loss_D: 0.0924 Loss_G: 0.0407 Convergence: 0.0967 k= 0.020310 lr = 0.0000085\n",
      "[14/25][7820/9765] Loss_D: 0.1023 Loss_G: 0.0418 Convergence: 0.1036 k= 0.020307 lr = 0.0000085\n",
      "[14/25][7830/9765] Loss_D: 0.1005 Loss_G: 0.0383 Convergence: 0.1034 k= 0.020314 lr = 0.0000085\n",
      "[14/25][7840/9765] Loss_D: 0.0966 Loss_G: 0.0384 Convergence: 0.0979 k= 0.020327 lr = 0.0000085\n",
      "[14/25][7850/9765] Loss_D: 0.0966 Loss_G: 0.0369 Convergence: 0.0994 k= 0.020321 lr = 0.0000085\n",
      "[14/25][7860/9765] Loss_D: 0.0992 Loss_G: 0.0371 Convergence: 0.1028 k= 0.020324 lr = 0.0000085\n",
      "[14/25][7870/9765] Loss_D: 0.0932 Loss_G: 0.0373 Convergence: 0.0942 k= 0.020326 lr = 0.0000085\n",
      "[14/25][7880/9765] Loss_D: 0.1032 Loss_G: 0.0395 Convergence: 0.1061 k= 0.020338 lr = 0.0000085\n",
      "[14/25][7890/9765] Loss_D: 0.1030 Loss_G: 0.0377 Convergence: 0.1076 k= 0.020341 lr = 0.0000085\n",
      "[14/25][7900/9765] Loss_D: 0.1006 Loss_G: 0.0382 Convergence: 0.1037 k= 0.020369 lr = 0.0000085\n",
      "[14/25][7910/9765] Loss_D: 0.0936 Loss_G: 0.0396 Convergence: 0.0962 k= 0.020388 lr = 0.0000085\n",
      "[14/25][7920/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1013 k= 0.020383 lr = 0.0000085\n",
      "[14/25][7930/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0967 k= 0.020374 lr = 0.0000085\n",
      "[14/25][7940/9765] Loss_D: 0.0879 Loss_G: 0.0393 Convergence: 0.0925 k= 0.020362 lr = 0.0000085\n",
      "[14/25][7950/9765] Loss_D: 0.1062 Loss_G: 0.0383 Convergence: 0.1115 k= 0.020350 lr = 0.0000085\n",
      "[14/25][7960/9765] Loss_D: 0.1121 Loss_G: 0.0393 Convergence: 0.1188 k= 0.020358 lr = 0.0000085\n",
      "[14/25][7970/9765] Loss_D: 0.0958 Loss_G: 0.0398 Convergence: 0.0978 k= 0.020348 lr = 0.0000085\n",
      "[14/25][7980/9765] Loss_D: 0.0974 Loss_G: 0.0397 Convergence: 0.0987 k= 0.020344 lr = 0.0000085\n",
      "[14/25][7990/9765] Loss_D: 0.0985 Loss_G: 0.0397 Convergence: 0.0993 k= 0.020351 lr = 0.0000085\n",
      "[14/25][8000/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0955 k= 0.020362 lr = 0.0000085\n",
      "[14/25][8010/9765] Loss_D: 0.1056 Loss_G: 0.0400 Convergence: 0.1091 k= 0.020369 lr = 0.0000085\n",
      "[14/25][8020/9765] Loss_D: 0.0977 Loss_G: 0.0382 Convergence: 0.0997 k= 0.020360 lr = 0.0000085\n",
      "[14/25][8030/9765] Loss_D: 0.1063 Loss_G: 0.0384 Convergence: 0.1115 k= 0.020367 lr = 0.0000085\n",
      "[14/25][8040/9765] Loss_D: 0.0983 Loss_G: 0.0372 Convergence: 0.1014 k= 0.020382 lr = 0.0000085\n",
      "[14/25][8050/9765] Loss_D: 0.0889 Loss_G: 0.0386 Convergence: 0.0924 k= 0.020390 lr = 0.0000085\n",
      "[14/25][8060/9765] Loss_D: 0.1066 Loss_G: 0.0390 Convergence: 0.1114 k= 0.020397 lr = 0.0000085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][8070/9765] Loss_D: 0.0969 Loss_G: 0.0386 Convergence: 0.0982 k= 0.020403 lr = 0.0000085\n",
      "[14/25][8080/9765] Loss_D: 0.0978 Loss_G: 0.0378 Convergence: 0.1003 k= 0.020407 lr = 0.0000085\n",
      "[14/25][8090/9765] Loss_D: 0.0905 Loss_G: 0.0397 Convergence: 0.0946 k= 0.020412 lr = 0.0000085\n",
      "[14/25][8100/9765] Loss_D: 0.0954 Loss_G: 0.0413 Convergence: 0.0990 k= 0.020404 lr = 0.0000085\n",
      "[14/25][8110/9765] Loss_D: 0.1086 Loss_G: 0.0394 Convergence: 0.1139 k= 0.020401 lr = 0.0000085\n",
      "[14/25][8120/9765] Loss_D: 0.1000 Loss_G: 0.0366 Convergence: 0.1044 k= 0.020417 lr = 0.0000085\n",
      "[14/25][8130/9765] Loss_D: 0.0974 Loss_G: 0.0368 Convergence: 0.1007 k= 0.020435 lr = 0.0000085\n",
      "[14/25][8140/9765] Loss_D: 0.0931 Loss_G: 0.0377 Convergence: 0.0940 k= 0.020445 lr = 0.0000085\n",
      "[14/25][8150/9765] Loss_D: 0.0910 Loss_G: 0.0384 Convergence: 0.0935 k= 0.020449 lr = 0.0000085\n",
      "[14/25][8160/9765] Loss_D: 0.0979 Loss_G: 0.0382 Convergence: 0.1000 k= 0.020460 lr = 0.0000085\n",
      "[14/25][8170/9765] Loss_D: 0.0964 Loss_G: 0.0405 Convergence: 0.0988 k= 0.020457 lr = 0.0000085\n",
      "[14/25][8180/9765] Loss_D: 0.1040 Loss_G: 0.0389 Convergence: 0.1078 k= 0.020461 lr = 0.0000085\n",
      "[14/25][8190/9765] Loss_D: 0.0886 Loss_G: 0.0372 Convergence: 0.0909 k= 0.020461 lr = 0.0000085\n",
      "[14/25][8200/9765] Loss_D: 0.1004 Loss_G: 0.0391 Convergence: 0.1025 k= 0.020472 lr = 0.0000085\n",
      "[14/25][8210/9765] Loss_D: 0.0933 Loss_G: 0.0415 Convergence: 0.0980 k= 0.020464 lr = 0.0000085\n",
      "[14/25][8220/9765] Loss_D: 0.1096 Loss_G: 0.0429 Convergence: 0.1118 k= 0.020457 lr = 0.0000085\n",
      "[14/25][8230/9765] Loss_D: 0.1035 Loss_G: 0.0384 Convergence: 0.1076 k= 0.020434 lr = 0.0000085\n",
      "[14/25][8240/9765] Loss_D: 0.0944 Loss_G: 0.0401 Convergence: 0.0972 k= 0.020432 lr = 0.0000085\n",
      "[14/25][8250/9765] Loss_D: 0.0880 Loss_G: 0.0376 Convergence: 0.0909 k= 0.020432 lr = 0.0000085\n",
      "[14/25][8260/9765] Loss_D: 0.0911 Loss_G: 0.0388 Convergence: 0.0939 k= 0.020440 lr = 0.0000085\n",
      "[14/25][8270/9765] Loss_D: 0.0907 Loss_G: 0.0359 Convergence: 0.0921 k= 0.020467 lr = 0.0000085\n",
      "[14/25][8280/9765] Loss_D: 0.1006 Loss_G: 0.0402 Convergence: 0.1017 k= 0.020472 lr = 0.0000085\n",
      "[14/25][8290/9765] Loss_D: 0.0956 Loss_G: 0.0396 Convergence: 0.0974 k= 0.020479 lr = 0.0000085\n",
      "[14/25][8300/9765] Loss_D: 0.0954 Loss_G: 0.0400 Convergence: 0.0978 k= 0.020476 lr = 0.0000085\n",
      "[14/25][8310/9765] Loss_D: 0.0966 Loss_G: 0.0421 Convergence: 0.1005 k= 0.020466 lr = 0.0000085\n",
      "[14/25][8320/9765] Loss_D: 0.1008 Loss_G: 0.0407 Convergence: 0.1017 k= 0.020451 lr = 0.0000085\n",
      "[14/25][8330/9765] Loss_D: 0.0920 Loss_G: 0.0401 Convergence: 0.0958 k= 0.020438 lr = 0.0000085\n",
      "[14/25][8340/9765] Loss_D: 0.1049 Loss_G: 0.0397 Convergence: 0.1082 k= 0.020448 lr = 0.0000085\n",
      "[14/25][8350/9765] Loss_D: 0.0976 Loss_G: 0.0366 Convergence: 0.1011 k= 0.020460 lr = 0.0000085\n",
      "[14/25][8360/9765] Loss_D: 0.0904 Loss_G: 0.0375 Convergence: 0.0922 k= 0.020462 lr = 0.0000085\n",
      "[14/25][8370/9765] Loss_D: 0.0926 Loss_G: 0.0387 Convergence: 0.0947 k= 0.020455 lr = 0.0000085\n",
      "[14/25][8380/9765] Loss_D: 0.1002 Loss_G: 0.0403 Convergence: 0.1012 k= 0.020455 lr = 0.0000085\n",
      "[14/25][8390/9765] Loss_D: 0.0894 Loss_G: 0.0411 Convergence: 0.0952 k= 0.020439 lr = 0.0000085\n",
      "[14/25][8400/9765] Loss_D: 0.1074 Loss_G: 0.0415 Convergence: 0.1100 k= 0.020419 lr = 0.0000085\n",
      "[14/25][8410/9765] Loss_D: 0.0937 Loss_G: 0.0392 Convergence: 0.0959 k= 0.020403 lr = 0.0000085\n",
      "[14/25][8420/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0980 k= 0.020393 lr = 0.0000085\n",
      "[14/25][8430/9765] Loss_D: 0.0863 Loss_G: 0.0372 Convergence: 0.0894 k= 0.020390 lr = 0.0000085\n",
      "[14/25][8440/9765] Loss_D: 0.0984 Loss_G: 0.0379 Convergence: 0.1010 k= 0.020394 lr = 0.0000085\n",
      "[14/25][8450/9765] Loss_D: 0.0953 Loss_G: 0.0404 Convergence: 0.0980 k= 0.020386 lr = 0.0000085\n",
      "[14/25][8460/9765] Loss_D: 0.0896 Loss_G: 0.0387 Convergence: 0.0930 k= 0.020377 lr = 0.0000085\n",
      "[14/25][8470/9765] Loss_D: 0.0888 Loss_G: 0.0411 Convergence: 0.0948 k= 0.020350 lr = 0.0000085\n",
      "[14/25][8480/9765] Loss_D: 0.0980 Loss_G: 0.0403 Convergence: 0.0997 k= 0.020337 lr = 0.0000085\n",
      "[14/25][8490/9765] Loss_D: 0.0896 Loss_G: 0.0378 Convergence: 0.0921 k= 0.020321 lr = 0.0000085\n",
      "[14/25][8500/9765] Loss_D: 0.0942 Loss_G: 0.0376 Convergence: 0.0954 k= 0.020326 lr = 0.0000085\n",
      "[14/25][8510/9765] Loss_D: 0.0970 Loss_G: 0.0394 Convergence: 0.0980 k= 0.020344 lr = 0.0000085\n",
      "[14/25][8520/9765] Loss_D: 0.0913 Loss_G: 0.0374 Convergence: 0.0926 k= 0.020368 lr = 0.0000085\n",
      "[14/25][8530/9765] Loss_D: 0.1075 Loss_G: 0.0369 Convergence: 0.1147 k= 0.020378 lr = 0.0000085\n",
      "[14/25][8540/9765] Loss_D: 0.1047 Loss_G: 0.0409 Convergence: 0.1069 k= 0.020373 lr = 0.0000085\n",
      "[14/25][8550/9765] Loss_D: 0.1001 Loss_G: 0.0399 Convergence: 0.1014 k= 0.020365 lr = 0.0000085\n",
      "[14/25][8560/9765] Loss_D: 0.1017 Loss_G: 0.0413 Convergence: 0.1028 k= 0.020353 lr = 0.0000085\n",
      "[14/25][8570/9765] Loss_D: 0.0988 Loss_G: 0.0417 Convergence: 0.1015 k= 0.020329 lr = 0.0000085\n",
      "[14/25][8580/9765] Loss_D: 0.0922 Loss_G: 0.0399 Convergence: 0.0956 k= 0.020307 lr = 0.0000085\n",
      "[14/25][8590/9765] Loss_D: 0.1039 Loss_G: 0.0398 Convergence: 0.1068 k= 0.020297 lr = 0.0000085\n",
      "[14/25][8600/9765] Loss_D: 0.0974 Loss_G: 0.0406 Convergence: 0.0996 k= 0.020295 lr = 0.0000085\n",
      "[14/25][8610/9765] Loss_D: 0.0977 Loss_G: 0.0397 Convergence: 0.0988 k= 0.020301 lr = 0.0000085\n",
      "[14/25][8620/9765] Loss_D: 0.0939 Loss_G: 0.0379 Convergence: 0.0947 k= 0.020300 lr = 0.0000085\n",
      "[14/25][8630/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0983 k= 0.020298 lr = 0.0000085\n",
      "[14/25][8640/9765] Loss_D: 0.0882 Loss_G: 0.0386 Convergence: 0.0920 k= 0.020291 lr = 0.0000085\n",
      "[14/25][8650/9765] Loss_D: 0.0948 Loss_G: 0.0409 Convergence: 0.0983 k= 0.020291 lr = 0.0000085\n",
      "[14/25][8660/9765] Loss_D: 0.0974 Loss_G: 0.0391 Convergence: 0.0983 k= 0.020275 lr = 0.0000085\n",
      "[14/25][8670/9765] Loss_D: 0.0954 Loss_G: 0.0383 Convergence: 0.0963 k= 0.020274 lr = 0.0000085\n",
      "[14/25][8680/9765] Loss_D: 0.0964 Loss_G: 0.0361 Convergence: 0.1000 k= 0.020298 lr = 0.0000085\n",
      "[14/25][8690/9765] Loss_D: 0.0927 Loss_G: 0.0354 Convergence: 0.0955 k= 0.020329 lr = 0.0000085\n",
      "[14/25][8700/9765] Loss_D: 0.0951 Loss_G: 0.0366 Convergence: 0.0976 k= 0.020351 lr = 0.0000085\n",
      "[14/25][8710/9765] Loss_D: 0.0885 Loss_G: 0.0385 Convergence: 0.0921 k= 0.020369 lr = 0.0000085\n",
      "[14/25][8720/9765] Loss_D: 0.0848 Loss_G: 0.0382 Convergence: 0.0896 k= 0.020356 lr = 0.0000085\n",
      "[14/25][8730/9765] Loss_D: 0.0850 Loss_G: 0.0404 Convergence: 0.0919 k= 0.020363 lr = 0.0000085\n",
      "[14/25][8740/9765] Loss_D: 0.1045 Loss_G: 0.0392 Convergence: 0.1081 k= 0.020351 lr = 0.0000085\n",
      "[14/25][8750/9765] Loss_D: 0.0896 Loss_G: 0.0377 Convergence: 0.0919 k= 0.020347 lr = 0.0000085\n",
      "[14/25][8760/9765] Loss_D: 0.0904 Loss_G: 0.0368 Convergence: 0.0915 k= 0.020356 lr = 0.0000085\n",
      "[14/25][8770/9765] Loss_D: 0.0988 Loss_G: 0.0386 Convergence: 0.1007 k= 0.020360 lr = 0.0000085\n",
      "[14/25][8780/9765] Loss_D: 0.0915 Loss_G: 0.0384 Convergence: 0.0938 k= 0.020358 lr = 0.0000085\n",
      "[14/25][8790/9765] Loss_D: 0.0968 Loss_G: 0.0372 Convergence: 0.0994 k= 0.020377 lr = 0.0000085\n",
      "[14/25][8800/9765] Loss_D: 0.0962 Loss_G: 0.0407 Convergence: 0.0989 k= 0.020385 lr = 0.0000085\n",
      "[14/25][8810/9765] Loss_D: 0.0957 Loss_G: 0.0403 Convergence: 0.0982 k= 0.020379 lr = 0.0000085\n",
      "[14/25][8820/9765] Loss_D: 0.1029 Loss_G: 0.0429 Convergence: 0.1052 k= 0.020364 lr = 0.0000085\n",
      "[14/25][8830/9765] Loss_D: 0.0934 Loss_G: 0.0428 Convergence: 0.0994 k= 0.020335 lr = 0.0000085\n",
      "[14/25][8840/9765] Loss_D: 0.0949 Loss_G: 0.0424 Convergence: 0.0999 k= 0.020314 lr = 0.0000085\n",
      "[14/25][8850/9765] Loss_D: 0.1009 Loss_G: 0.0424 Convergence: 0.1035 k= 0.020260 lr = 0.0000085\n",
      "[14/25][8860/9765] Loss_D: 0.0916 Loss_G: 0.0383 Convergence: 0.0937 k= 0.020242 lr = 0.0000085\n",
      "[14/25][8870/9765] Loss_D: 0.0937 Loss_G: 0.0375 Convergence: 0.0948 k= 0.020249 lr = 0.0000085\n",
      "[14/25][8880/9765] Loss_D: 0.0975 Loss_G: 0.0381 Convergence: 0.0995 k= 0.020270 lr = 0.0000085\n",
      "[14/25][8890/9765] Loss_D: 0.0903 Loss_G: 0.0349 Convergence: 0.0924 k= 0.020288 lr = 0.0000085\n",
      "[14/25][8900/9765] Loss_D: 0.0830 Loss_G: 0.0369 Convergence: 0.0872 k= 0.020318 lr = 0.0000085\n",
      "[14/25][8910/9765] Loss_D: 0.0974 Loss_G: 0.0367 Convergence: 0.1007 k= 0.020326 lr = 0.0000085\n",
      "[14/25][8920/9765] Loss_D: 0.0896 Loss_G: 0.0395 Convergence: 0.0938 k= 0.020345 lr = 0.0000085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/25][8930/9765] Loss_D: 0.0883 Loss_G: 0.0391 Convergence: 0.0926 k= 0.020334 lr = 0.0000085\n",
      "[14/25][8940/9765] Loss_D: 0.0961 Loss_G: 0.0393 Convergence: 0.0974 k= 0.020328 lr = 0.0000085\n",
      "[14/25][8950/9765] Loss_D: 0.0941 Loss_G: 0.0368 Convergence: 0.0960 k= 0.020347 lr = 0.0000085\n",
      "[14/25][8960/9765] Loss_D: 0.0928 Loss_G: 0.0389 Convergence: 0.0950 k= 0.020349 lr = 0.0000085\n",
      "[14/25][8970/9765] Loss_D: 0.0947 Loss_G: 0.0403 Convergence: 0.0976 k= 0.020349 lr = 0.0000085\n",
      "[14/25][8980/9765] Loss_D: 0.0981 Loss_G: 0.0394 Convergence: 0.0991 k= 0.020336 lr = 0.0000085\n",
      "[14/25][8990/9765] Loss_D: 0.0966 Loss_G: 0.0381 Convergence: 0.0982 k= 0.020333 lr = 0.0000085\n",
      "[14/25][9000/9765] Loss_D: 0.1010 Loss_G: 0.0363 Convergence: 0.1061 k= 0.020349 lr = 0.0000085\n",
      "[14/25][9010/9765] Loss_D: 0.1025 Loss_G: 0.0374 Convergence: 0.1072 k= 0.020363 lr = 0.0000085\n",
      "[14/25][9020/9765] Loss_D: 0.1007 Loss_G: 0.0380 Convergence: 0.1040 k= 0.020385 lr = 0.0000085\n",
      "[14/25][9030/9765] Loss_D: 0.0896 Loss_G: 0.0397 Convergence: 0.0940 k= 0.020382 lr = 0.0000085\n",
      "[14/25][9040/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0991 k= 0.020376 lr = 0.0000085\n",
      "[14/25][9050/9765] Loss_D: 0.0936 Loss_G: 0.0397 Convergence: 0.0963 k= 0.020375 lr = 0.0000085\n",
      "[14/25][9060/9765] Loss_D: 0.1071 Loss_G: 0.0428 Convergence: 0.1083 k= 0.020361 lr = 0.0000085\n",
      "[14/25][9070/9765] Loss_D: 0.1025 Loss_G: 0.0427 Convergence: 0.1047 k= 0.020349 lr = 0.0000085\n",
      "[14/25][9080/9765] Loss_D: 0.1023 Loss_G: 0.0385 Convergence: 0.1059 k= 0.020349 lr = 0.0000085\n",
      "[14/25][9090/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0976 k= 0.020353 lr = 0.0000085\n",
      "[14/25][9100/9765] Loss_D: 0.0970 Loss_G: 0.0375 Convergence: 0.0995 k= 0.020365 lr = 0.0000085\n",
      "[14/25][9110/9765] Loss_D: 0.0915 Loss_G: 0.0384 Convergence: 0.0938 k= 0.020370 lr = 0.0000085\n",
      "[14/25][9120/9765] Loss_D: 0.1079 Loss_G: 0.0378 Convergence: 0.1142 k= 0.020388 lr = 0.0000085\n",
      "[14/25][9130/9765] Loss_D: 0.0994 Loss_G: 0.0376 Convergence: 0.1027 k= 0.020397 lr = 0.0000085\n",
      "[14/25][9140/9765] Loss_D: 0.1059 Loss_G: 0.0375 Convergence: 0.1118 k= 0.020404 lr = 0.0000085\n",
      "[14/25][9150/9765] Loss_D: 0.0883 Loss_G: 0.0394 Convergence: 0.0928 k= 0.020409 lr = 0.0000085\n",
      "[14/25][9160/9765] Loss_D: 0.0896 Loss_G: 0.0398 Convergence: 0.0940 k= 0.020399 lr = 0.0000085\n",
      "[14/25][9170/9765] Loss_D: 0.0916 Loss_G: 0.0399 Convergence: 0.0954 k= 0.020397 lr = 0.0000085\n",
      "[14/25][9180/9765] Loss_D: 0.1034 Loss_G: 0.0373 Convergence: 0.1086 k= 0.020409 lr = 0.0000085\n",
      "[14/25][9190/9765] Loss_D: 0.0916 Loss_G: 0.0396 Convergence: 0.0950 k= 0.020406 lr = 0.0000085\n",
      "[14/25][9200/9765] Loss_D: 0.1035 Loss_G: 0.0384 Convergence: 0.1076 k= 0.020408 lr = 0.0000085\n",
      "[14/25][9210/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0958 k= 0.020401 lr = 0.0000085\n",
      "[14/25][9220/9765] Loss_D: 0.1085 Loss_G: 0.0370 Convergence: 0.1159 k= 0.020413 lr = 0.0000085\n",
      "[14/25][9230/9765] Loss_D: 0.0908 Loss_G: 0.0398 Convergence: 0.0948 k= 0.020422 lr = 0.0000085\n",
      "[14/25][9240/9765] Loss_D: 0.0972 Loss_G: 0.0398 Convergence: 0.0986 k= 0.020424 lr = 0.0000085\n",
      "[14/25][9250/9765] Loss_D: 0.0943 Loss_G: 0.0376 Convergence: 0.0954 k= 0.020418 lr = 0.0000085\n",
      "[14/25][9260/9765] Loss_D: 0.0930 Loss_G: 0.0379 Convergence: 0.0941 k= 0.020421 lr = 0.0000085\n",
      "[14/25][9270/9765] Loss_D: 0.0994 Loss_G: 0.0377 Convergence: 0.1026 k= 0.020421 lr = 0.0000085\n",
      "[14/25][9280/9765] Loss_D: 0.0924 Loss_G: 0.0381 Convergence: 0.0940 k= 0.020435 lr = 0.0000085\n",
      "[14/25][9290/9765] Loss_D: 0.0990 Loss_G: 0.0403 Convergence: 0.1002 k= 0.020430 lr = 0.0000085\n",
      "[14/25][9300/9765] Loss_D: 0.0920 Loss_G: 0.0387 Convergence: 0.0944 k= 0.020426 lr = 0.0000085\n",
      "[14/25][9310/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0987 k= 0.020418 lr = 0.0000085\n",
      "[14/25][9320/9765] Loss_D: 0.0947 Loss_G: 0.0415 Convergence: 0.0988 k= 0.020416 lr = 0.0000085\n",
      "[14/25][9330/9765] Loss_D: 0.0953 Loss_G: 0.0382 Convergence: 0.0964 k= 0.020410 lr = 0.0000085\n",
      "[14/25][9340/9765] Loss_D: 0.0980 Loss_G: 0.0394 Convergence: 0.0988 k= 0.020400 lr = 0.0000085\n",
      "[14/25][9350/9765] Loss_D: 0.1045 Loss_G: 0.0392 Convergence: 0.1082 k= 0.020410 lr = 0.0000085\n",
      "[14/25][9360/9765] Loss_D: 0.0939 Loss_G: 0.0381 Convergence: 0.0949 k= 0.020408 lr = 0.0000085\n",
      "[14/25][9370/9765] Loss_D: 0.0994 Loss_G: 0.0389 Convergence: 0.1013 k= 0.020414 lr = 0.0000085\n",
      "[14/25][9380/9765] Loss_D: 0.0872 Loss_G: 0.0368 Convergence: 0.0897 k= 0.020440 lr = 0.0000085\n",
      "[14/25][9390/9765] Loss_D: 0.0974 Loss_G: 0.0384 Convergence: 0.0990 k= 0.020448 lr = 0.0000085\n",
      "[14/25][9400/9765] Loss_D: 0.0997 Loss_G: 0.0394 Convergence: 0.1014 k= 0.020450 lr = 0.0000085\n",
      "[14/25][9410/9765] Loss_D: 0.0836 Loss_G: 0.0375 Convergence: 0.0882 k= 0.020443 lr = 0.0000085\n",
      "[14/25][9420/9765] Loss_D: 0.0977 Loss_G: 0.0390 Convergence: 0.0989 k= 0.020446 lr = 0.0000085\n",
      "[14/25][9430/9765] Loss_D: 0.0970 Loss_G: 0.0388 Convergence: 0.0982 k= 0.020447 lr = 0.0000085\n",
      "[14/25][9440/9765] Loss_D: 0.1043 Loss_G: 0.0367 Convergence: 0.1105 k= 0.020462 lr = 0.0000085\n",
      "[14/25][9450/9765] Loss_D: 0.0907 Loss_G: 0.0389 Convergence: 0.0938 k= 0.020458 lr = 0.0000085\n",
      "[14/25][9460/9765] Loss_D: 0.0922 Loss_G: 0.0409 Convergence: 0.0967 k= 0.020449 lr = 0.0000085\n",
      "[14/25][9470/9765] Loss_D: 0.0928 Loss_G: 0.0388 Convergence: 0.0950 k= 0.020435 lr = 0.0000085\n",
      "[14/25][9480/9765] Loss_D: 0.0964 Loss_G: 0.0416 Convergence: 0.0999 k= 0.020432 lr = 0.0000085\n",
      "[14/25][9490/9765] Loss_D: 0.0979 Loss_G: 0.0394 Convergence: 0.0987 k= 0.020435 lr = 0.0000085\n",
      "[14/25][9500/9765] Loss_D: 0.1009 Loss_G: 0.0384 Convergence: 0.1039 k= 0.020449 lr = 0.0000085\n",
      "[14/25][9510/9765] Loss_D: 0.0839 Loss_G: 0.0355 Convergence: 0.0863 k= 0.020474 lr = 0.0000085\n",
      "[14/25][9520/9765] Loss_D: 0.0924 Loss_G: 0.0369 Convergence: 0.0935 k= 0.020487 lr = 0.0000085\n",
      "[14/25][9530/9765] Loss_D: 0.0914 Loss_G: 0.0378 Convergence: 0.0931 k= 0.020491 lr = 0.0000085\n",
      "[14/25][9540/9765] Loss_D: 0.1027 Loss_G: 0.0418 Convergence: 0.1039 k= 0.020465 lr = 0.0000085\n",
      "[14/25][9550/9765] Loss_D: 0.0947 Loss_G: 0.0431 Convergence: 0.1004 k= 0.020406 lr = 0.0000085\n",
      "[14/25][9560/9765] Loss_D: 0.0906 Loss_G: 0.0415 Convergence: 0.0964 k= 0.020389 lr = 0.0000085\n",
      "[14/25][9570/9765] Loss_D: 0.0906 Loss_G: 0.0411 Convergence: 0.0959 k= 0.020363 lr = 0.0000085\n",
      "[14/25][9580/9765] Loss_D: 0.0901 Loss_G: 0.0384 Convergence: 0.0929 k= 0.020359 lr = 0.0000085\n",
      "[14/25][9590/9765] Loss_D: 0.0859 Loss_G: 0.0362 Convergence: 0.0882 k= 0.020359 lr = 0.0000085\n",
      "[14/25][9600/9765] Loss_D: 0.0983 Loss_G: 0.0360 Convergence: 0.1026 k= 0.020365 lr = 0.0000085\n",
      "[14/25][9610/9765] Loss_D: 0.0960 Loss_G: 0.0359 Convergence: 0.0995 k= 0.020396 lr = 0.0000085\n",
      "[14/25][9620/9765] Loss_D: 0.1015 Loss_G: 0.0371 Convergence: 0.1060 k= 0.020435 lr = 0.0000085\n",
      "[14/25][9630/9765] Loss_D: 0.0823 Loss_G: 0.0361 Convergence: 0.0860 k= 0.020440 lr = 0.0000085\n",
      "[14/25][9640/9765] Loss_D: 0.0962 Loss_G: 0.0394 Convergence: 0.0975 k= 0.020443 lr = 0.0000085\n",
      "[14/25][9650/9765] Loss_D: 0.0909 Loss_G: 0.0408 Convergence: 0.0958 k= 0.020417 lr = 0.0000085\n",
      "[14/25][9660/9765] Loss_D: 0.0873 Loss_G: 0.0435 Convergence: 0.0964 k= 0.020382 lr = 0.0000085\n",
      "[14/25][9670/9765] Loss_D: 0.0953 Loss_G: 0.0399 Convergence: 0.0976 k= 0.020359 lr = 0.0000085\n",
      "[14/25][9680/9765] Loss_D: 0.0975 Loss_G: 0.0363 Convergence: 0.1013 k= 0.020359 lr = 0.0000085\n",
      "[14/25][9690/9765] Loss_D: 0.0905 Loss_G: 0.0372 Convergence: 0.0919 k= 0.020368 lr = 0.0000085\n",
      "[14/25][9700/9765] Loss_D: 0.0894 Loss_G: 0.0416 Convergence: 0.0957 k= 0.020380 lr = 0.0000085\n",
      "[14/25][9710/9765] Loss_D: 0.0929 Loss_G: 0.0387 Convergence: 0.0950 k= 0.020379 lr = 0.0000085\n",
      "[14/25][9720/9765] Loss_D: 0.0942 Loss_G: 0.0414 Convergence: 0.0984 k= 0.020368 lr = 0.0000085\n",
      "[14/25][9730/9765] Loss_D: 0.0888 Loss_G: 0.0423 Convergence: 0.0961 k= 0.020338 lr = 0.0000085\n",
      "[14/25][9740/9765] Loss_D: 0.1034 Loss_G: 0.0417 Convergence: 0.1042 k= 0.020323 lr = 0.0000085\n",
      "[14/25][9750/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1002 k= 0.020311 lr = 0.0000085\n",
      "[14/25][9760/9765] Loss_D: 0.1057 Loss_G: 0.0364 Convergence: 0.1127 k= 0.020323 lr = 0.0000085\n",
      "[15/25][0/9765] Loss_D: 0.0912 Loss_G: 0.0385 Convergence: 0.0936 k= 0.020337 lr = 0.0000085\n",
      "[15/25][10/9765] Loss_D: 0.0948 Loss_G: 0.0379 Convergence: 0.0959 k= 0.020338 lr = 0.0000085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][20/9765] Loss_D: 0.0846 Loss_G: 0.0383 Convergence: 0.0895 k= 0.020340 lr = 0.0000085\n",
      "[15/25][30/9765] Loss_D: 0.0976 Loss_G: 0.0386 Convergence: 0.0991 k= 0.020326 lr = 0.0000085\n",
      "[15/25][40/9765] Loss_D: 0.0944 Loss_G: 0.0408 Convergence: 0.0980 k= 0.020320 lr = 0.0000085\n",
      "[15/25][50/9765] Loss_D: 0.1024 Loss_G: 0.0391 Convergence: 0.1053 k= 0.020340 lr = 0.0000085\n",
      "[15/25][60/9765] Loss_D: 0.0905 Loss_G: 0.0407 Convergence: 0.0955 k= 0.020340 lr = 0.0000085\n",
      "[15/25][70/9765] Loss_D: 0.0944 Loss_G: 0.0404 Convergence: 0.0976 k= 0.020331 lr = 0.0000085\n",
      "[15/25][80/9765] Loss_D: 0.0893 Loss_G: 0.0384 Convergence: 0.0924 k= 0.020346 lr = 0.0000085\n",
      "[15/25][90/9765] Loss_D: 0.1059 Loss_G: 0.0405 Convergence: 0.1090 k= 0.020356 lr = 0.0000085\n",
      "[15/25][100/9765] Loss_D: 0.0965 Loss_G: 0.0423 Convergence: 0.1007 k= 0.020349 lr = 0.0000085\n",
      "[15/25][110/9765] Loss_D: 0.0923 Loss_G: 0.0395 Convergence: 0.0953 k= 0.020329 lr = 0.0000085\n",
      "[15/25][120/9765] Loss_D: 0.1028 Loss_G: 0.0395 Convergence: 0.1055 k= 0.020337 lr = 0.0000085\n",
      "[15/25][130/9765] Loss_D: 0.0943 Loss_G: 0.0376 Convergence: 0.0955 k= 0.020343 lr = 0.0000085\n",
      "[15/25][140/9765] Loss_D: 0.0968 Loss_G: 0.0381 Convergence: 0.0985 k= 0.020346 lr = 0.0000085\n",
      "[15/25][150/9765] Loss_D: 0.0909 Loss_G: 0.0406 Convergence: 0.0957 k= 0.020345 lr = 0.0000085\n",
      "[15/25][160/9765] Loss_D: 0.1045 Loss_G: 0.0390 Convergence: 0.1084 k= 0.020351 lr = 0.0000085\n",
      "[15/25][170/9765] Loss_D: 0.0935 Loss_G: 0.0386 Convergence: 0.0952 k= 0.020354 lr = 0.0000085\n",
      "[15/25][180/9765] Loss_D: 0.0893 Loss_G: 0.0396 Convergence: 0.0936 k= 0.020355 lr = 0.0000085\n",
      "[15/25][190/9765] Loss_D: 0.0976 Loss_G: 0.0401 Convergence: 0.0992 k= 0.020348 lr = 0.0000085\n",
      "[15/25][200/9765] Loss_D: 0.0939 Loss_G: 0.0389 Convergence: 0.0956 k= 0.020355 lr = 0.0000085\n",
      "[15/25][210/9765] Loss_D: 0.0890 Loss_G: 0.0365 Convergence: 0.0904 k= 0.020357 lr = 0.0000085\n",
      "[15/25][220/9765] Loss_D: 0.0884 Loss_G: 0.0385 Convergence: 0.0919 k= 0.020377 lr = 0.0000085\n",
      "[15/25][230/9765] Loss_D: 0.0979 Loss_G: 0.0397 Convergence: 0.0989 k= 0.020390 lr = 0.0000085\n",
      "[15/25][240/9765] Loss_D: 0.1071 Loss_G: 0.0381 Convergence: 0.1129 k= 0.020401 lr = 0.0000085\n",
      "[15/25][250/9765] Loss_D: 0.0933 Loss_G: 0.0408 Convergence: 0.0973 k= 0.020402 lr = 0.0000085\n",
      "[15/25][260/9765] Loss_D: 0.1050 Loss_G: 0.0396 Convergence: 0.1085 k= 0.020398 lr = 0.0000085\n",
      "[15/25][270/9765] Loss_D: 0.0992 Loss_G: 0.0366 Convergence: 0.1034 k= 0.020384 lr = 0.0000085\n",
      "[15/25][280/9765] Loss_D: 0.0950 Loss_G: 0.0422 Convergence: 0.0997 k= 0.020393 lr = 0.0000085\n",
      "[15/25][290/9765] Loss_D: 0.0982 Loss_G: 0.0399 Convergence: 0.0993 k= 0.020385 lr = 0.0000085\n",
      "[15/25][300/9765] Loss_D: 0.1038 Loss_G: 0.0357 Convergence: 0.1107 k= 0.020385 lr = 0.0000085\n",
      "[15/25][310/9765] Loss_D: 0.0973 Loss_G: 0.0355 Convergence: 0.1017 k= 0.020411 lr = 0.0000085\n",
      "[15/25][320/9765] Loss_D: 0.0914 Loss_G: 0.0376 Convergence: 0.0929 k= 0.020437 lr = 0.0000085\n",
      "[15/25][330/9765] Loss_D: 0.0963 Loss_G: 0.0370 Convergence: 0.0989 k= 0.020451 lr = 0.0000085\n",
      "[15/25][340/9765] Loss_D: 0.0955 Loss_G: 0.0392 Convergence: 0.0970 k= 0.020455 lr = 0.0000085\n",
      "[15/25][350/9765] Loss_D: 0.0945 Loss_G: 0.0392 Convergence: 0.0963 k= 0.020450 lr = 0.0000085\n",
      "[15/25][360/9765] Loss_D: 0.0955 Loss_G: 0.0372 Convergence: 0.0976 k= 0.020434 lr = 0.0000085\n",
      "[15/25][370/9765] Loss_D: 0.0994 Loss_G: 0.0401 Convergence: 0.1002 k= 0.020438 lr = 0.0000085\n",
      "[15/25][380/9765] Loss_D: 0.0914 Loss_G: 0.0371 Convergence: 0.0925 k= 0.020428 lr = 0.0000085\n",
      "[15/25][390/9765] Loss_D: 0.0931 Loss_G: 0.0372 Convergence: 0.0942 k= 0.020435 lr = 0.0000085\n",
      "[15/25][400/9765] Loss_D: 0.0960 Loss_G: 0.0372 Convergence: 0.0983 k= 0.020445 lr = 0.0000085\n",
      "[15/25][410/9765] Loss_D: 0.0884 Loss_G: 0.0394 Convergence: 0.0930 k= 0.020437 lr = 0.0000085\n",
      "[15/25][420/9765] Loss_D: 0.0959 Loss_G: 0.0418 Convergence: 0.0999 k= 0.020426 lr = 0.0000085\n",
      "[15/25][430/9765] Loss_D: 0.1144 Loss_G: 0.0405 Convergence: 0.1207 k= 0.020418 lr = 0.0000085\n",
      "[15/25][440/9765] Loss_D: 0.1041 Loss_G: 0.0408 Convergence: 0.1061 k= 0.020418 lr = 0.0000085\n",
      "[15/25][450/9765] Loss_D: 0.0958 Loss_G: 0.0410 Convergence: 0.0989 k= 0.020402 lr = 0.0000085\n",
      "[15/25][460/9765] Loss_D: 0.0862 Loss_G: 0.0375 Convergence: 0.0897 k= 0.020400 lr = 0.0000085\n",
      "[15/25][470/9765] Loss_D: 0.0997 Loss_G: 0.0377 Convergence: 0.1029 k= 0.020407 lr = 0.0000085\n",
      "[15/25][480/9765] Loss_D: 0.0997 Loss_G: 0.0383 Convergence: 0.1024 k= 0.020411 lr = 0.0000085\n",
      "[15/25][490/9765] Loss_D: 0.1039 Loss_G: 0.0392 Convergence: 0.1073 k= 0.020410 lr = 0.0000085\n",
      "[15/25][500/9765] Loss_D: 0.0953 Loss_G: 0.0404 Convergence: 0.0980 k= 0.020408 lr = 0.0000085\n",
      "[15/25][510/9765] Loss_D: 0.0922 Loss_G: 0.0428 Convergence: 0.0987 k= 0.020392 lr = 0.0000085\n",
      "[15/25][520/9765] Loss_D: 0.0982 Loss_G: 0.0390 Convergence: 0.0996 k= 0.020367 lr = 0.0000085\n",
      "[15/25][530/9765] Loss_D: 0.0977 Loss_G: 0.0390 Convergence: 0.0989 k= 0.020362 lr = 0.0000081\n",
      "[15/25][540/9765] Loss_D: 0.0995 Loss_G: 0.0399 Convergence: 0.1006 k= 0.020354 lr = 0.0000081\n",
      "[15/25][550/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0934 k= 0.020343 lr = 0.0000081\n",
      "[15/25][560/9765] Loss_D: 0.1014 Loss_G: 0.0389 Convergence: 0.1042 k= 0.020366 lr = 0.0000081\n",
      "[15/25][570/9765] Loss_D: 0.0920 Loss_G: 0.0379 Convergence: 0.0936 k= 0.020370 lr = 0.0000081\n",
      "[15/25][580/9765] Loss_D: 0.0872 Loss_G: 0.0399 Convergence: 0.0927 k= 0.020375 lr = 0.0000081\n",
      "[15/25][590/9765] Loss_D: 0.0973 Loss_G: 0.0413 Convergence: 0.1002 k= 0.020365 lr = 0.0000081\n",
      "[15/25][600/9765] Loss_D: 0.0905 Loss_G: 0.0397 Convergence: 0.0946 k= 0.020341 lr = 0.0000081\n",
      "[15/25][610/9765] Loss_D: 0.0948 Loss_G: 0.0383 Convergence: 0.0956 k= 0.020337 lr = 0.0000081\n",
      "[15/25][620/9765] Loss_D: 0.0961 Loss_G: 0.0424 Convergence: 0.1006 k= 0.020330 lr = 0.0000081\n",
      "[15/25][630/9765] Loss_D: 0.1036 Loss_G: 0.0412 Convergence: 0.1050 k= 0.020307 lr = 0.0000081\n",
      "[15/25][640/9765] Loss_D: 0.1006 Loss_G: 0.0425 Convergence: 0.1034 k= 0.020285 lr = 0.0000081\n",
      "[15/25][650/9765] Loss_D: 0.0991 Loss_G: 0.0426 Convergence: 0.1026 k= 0.020242 lr = 0.0000081\n",
      "[15/25][660/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1013 k= 0.020236 lr = 0.0000081\n",
      "[15/25][670/9765] Loss_D: 0.1011 Loss_G: 0.0395 Convergence: 0.1031 k= 0.020250 lr = 0.0000081\n",
      "[15/25][680/9765] Loss_D: 0.0967 Loss_G: 0.0375 Convergence: 0.0990 k= 0.020271 lr = 0.0000081\n",
      "[15/25][690/9765] Loss_D: 0.0865 Loss_G: 0.0379 Convergence: 0.0903 k= 0.020282 lr = 0.0000081\n",
      "[15/25][700/9765] Loss_D: 0.0980 Loss_G: 0.0376 Convergence: 0.1006 k= 0.020295 lr = 0.0000081\n",
      "[15/25][710/9765] Loss_D: 0.0975 Loss_G: 0.0396 Convergence: 0.0986 k= 0.020299 lr = 0.0000081\n",
      "[15/25][720/9765] Loss_D: 0.0987 Loss_G: 0.0374 Convergence: 0.1018 k= 0.020298 lr = 0.0000081\n",
      "[15/25][730/9765] Loss_D: 0.0916 Loss_G: 0.0388 Convergence: 0.0942 k= 0.020285 lr = 0.0000081\n",
      "[15/25][740/9765] Loss_D: 0.0982 Loss_G: 0.0404 Convergence: 0.0998 k= 0.020289 lr = 0.0000081\n",
      "[15/25][750/9765] Loss_D: 0.0865 Loss_G: 0.0386 Convergence: 0.0910 k= 0.020279 lr = 0.0000081\n",
      "[15/25][760/9765] Loss_D: 0.1071 Loss_G: 0.0399 Convergence: 0.1112 k= 0.020279 lr = 0.0000081\n",
      "[15/25][770/9765] Loss_D: 0.0963 Loss_G: 0.0378 Convergence: 0.0981 k= 0.020272 lr = 0.0000081\n",
      "[15/25][780/9765] Loss_D: 0.0958 Loss_G: 0.0391 Convergence: 0.0970 k= 0.020272 lr = 0.0000081\n",
      "[15/25][790/9765] Loss_D: 0.0899 Loss_G: 0.0385 Convergence: 0.0929 k= 0.020256 lr = 0.0000081\n",
      "[15/25][800/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0956 k= 0.020261 lr = 0.0000081\n",
      "[15/25][810/9765] Loss_D: 0.0964 Loss_G: 0.0387 Convergence: 0.0973 k= 0.020261 lr = 0.0000081\n",
      "[15/25][820/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0968 k= 0.020252 lr = 0.0000081\n",
      "[15/25][830/9765] Loss_D: 0.0958 Loss_G: 0.0379 Convergence: 0.0973 k= 0.020261 lr = 0.0000081\n",
      "[15/25][840/9765] Loss_D: 0.0951 Loss_G: 0.0367 Convergence: 0.0974 k= 0.020273 lr = 0.0000081\n",
      "[15/25][850/9765] Loss_D: 0.0971 Loss_G: 0.0377 Convergence: 0.0992 k= 0.020295 lr = 0.0000081\n",
      "[15/25][860/9765] Loss_D: 0.0930 Loss_G: 0.0378 Convergence: 0.0941 k= 0.020299 lr = 0.0000081\n",
      "[15/25][870/9765] Loss_D: 0.1031 Loss_G: 0.0389 Convergence: 0.1066 k= 0.020305 lr = 0.0000081\n",
      "[15/25][880/9765] Loss_D: 0.1003 Loss_G: 0.0388 Convergence: 0.1027 k= 0.020313 lr = 0.0000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][890/9765] Loss_D: 0.0961 Loss_G: 0.0373 Convergence: 0.0983 k= 0.020316 lr = 0.0000081\n",
      "[15/25][900/9765] Loss_D: 0.0983 Loss_G: 0.0396 Convergence: 0.0992 k= 0.020323 lr = 0.0000081\n",
      "[15/25][910/9765] Loss_D: 0.1076 Loss_G: 0.0417 Convergence: 0.1101 k= 0.020311 lr = 0.0000081\n",
      "[15/25][920/9765] Loss_D: 0.0958 Loss_G: 0.0406 Convergence: 0.0986 k= 0.020305 lr = 0.0000081\n",
      "[15/25][930/9765] Loss_D: 0.1067 Loss_G: 0.0388 Convergence: 0.1117 k= 0.020304 lr = 0.0000081\n",
      "[15/25][940/9765] Loss_D: 0.0987 Loss_G: 0.0370 Convergence: 0.1022 k= 0.020307 lr = 0.0000081\n",
      "[15/25][950/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.020321 lr = 0.0000081\n",
      "[15/25][960/9765] Loss_D: 0.1023 Loss_G: 0.0400 Convergence: 0.1043 k= 0.020311 lr = 0.0000081\n",
      "[15/25][970/9765] Loss_D: 0.0886 Loss_G: 0.0387 Convergence: 0.0924 k= 0.020302 lr = 0.0000081\n",
      "[15/25][980/9765] Loss_D: 0.0892 Loss_G: 0.0363 Convergence: 0.0903 k= 0.020301 lr = 0.0000081\n",
      "[15/25][990/9765] Loss_D: 0.0939 Loss_G: 0.0383 Convergence: 0.0951 k= 0.020310 lr = 0.0000081\n",
      "[15/25][1000/9765] Loss_D: 0.0985 Loss_G: 0.0403 Convergence: 0.0999 k= 0.020304 lr = 0.0000081\n",
      "[15/25][1010/9765] Loss_D: 0.0961 Loss_G: 0.0419 Convergence: 0.1001 k= 0.020299 lr = 0.0000081\n",
      "[15/25][1020/9765] Loss_D: 0.0962 Loss_G: 0.0393 Convergence: 0.0975 k= 0.020283 lr = 0.0000081\n",
      "[15/25][1030/9765] Loss_D: 0.1055 Loss_G: 0.0428 Convergence: 0.1066 k= 0.020268 lr = 0.0000081\n",
      "[15/25][1040/9765] Loss_D: 0.0908 Loss_G: 0.0406 Convergence: 0.0955 k= 0.020246 lr = 0.0000081\n",
      "[15/25][1050/9765] Loss_D: 0.0947 Loss_G: 0.0383 Convergence: 0.0956 k= 0.020240 lr = 0.0000081\n",
      "[15/25][1060/9765] Loss_D: 0.0979 Loss_G: 0.0398 Convergence: 0.0990 k= 0.020231 lr = 0.0000081\n",
      "[15/25][1070/9765] Loss_D: 0.1038 Loss_G: 0.0373 Convergence: 0.1090 k= 0.020243 lr = 0.0000081\n",
      "[15/25][1080/9765] Loss_D: 0.1067 Loss_G: 0.0366 Convergence: 0.1138 k= 0.020261 lr = 0.0000081\n",
      "[15/25][1090/9765] Loss_D: 0.1000 Loss_G: 0.0379 Convergence: 0.1031 k= 0.020290 lr = 0.0000081\n",
      "[15/25][1100/9765] Loss_D: 0.0975 Loss_G: 0.0402 Convergence: 0.0993 k= 0.020296 lr = 0.0000081\n",
      "[15/25][1110/9765] Loss_D: 0.0998 Loss_G: 0.0370 Convergence: 0.1038 k= 0.020295 lr = 0.0000081\n",
      "[15/25][1120/9765] Loss_D: 0.1039 Loss_G: 0.0391 Convergence: 0.1075 k= 0.020295 lr = 0.0000081\n",
      "[15/25][1130/9765] Loss_D: 0.0941 Loss_G: 0.0398 Convergence: 0.0967 k= 0.020273 lr = 0.0000081\n",
      "[15/25][1140/9765] Loss_D: 0.1000 Loss_G: 0.0405 Convergence: 0.1009 k= 0.020262 lr = 0.0000081\n",
      "[15/25][1150/9765] Loss_D: 0.0851 Loss_G: 0.0386 Convergence: 0.0901 k= 0.020248 lr = 0.0000081\n",
      "[15/25][1160/9765] Loss_D: 0.0908 Loss_G: 0.0407 Convergence: 0.0956 k= 0.020242 lr = 0.0000081\n",
      "[15/25][1170/9765] Loss_D: 0.0956 Loss_G: 0.0405 Convergence: 0.0983 k= 0.020227 lr = 0.0000081\n",
      "[15/25][1180/9765] Loss_D: 0.0975 Loss_G: 0.0410 Convergence: 0.1000 k= 0.020229 lr = 0.0000081\n",
      "[15/25][1190/9765] Loss_D: 0.0925 Loss_G: 0.0376 Convergence: 0.0935 k= 0.020217 lr = 0.0000081\n",
      "[15/25][1200/9765] Loss_D: 0.1082 Loss_G: 0.0395 Convergence: 0.1132 k= 0.020222 lr = 0.0000081\n",
      "[15/25][1210/9765] Loss_D: 0.1045 Loss_G: 0.0405 Convergence: 0.1069 k= 0.020207 lr = 0.0000081\n",
      "[15/25][1220/9765] Loss_D: 0.1072 Loss_G: 0.0417 Convergence: 0.1096 k= 0.020207 lr = 0.0000081\n",
      "[15/25][1230/9765] Loss_D: 0.1004 Loss_G: 0.0378 Convergence: 0.1038 k= 0.020202 lr = 0.0000081\n",
      "[15/25][1240/9765] Loss_D: 0.0899 Loss_G: 0.0379 Convergence: 0.0923 k= 0.020205 lr = 0.0000081\n",
      "[15/25][1250/9765] Loss_D: 0.1146 Loss_G: 0.0387 Convergence: 0.1227 k= 0.020221 lr = 0.0000081\n",
      "[15/25][1260/9765] Loss_D: 0.0961 Loss_G: 0.0388 Convergence: 0.0969 k= 0.020213 lr = 0.0000081\n",
      "[15/25][1270/9765] Loss_D: 0.0908 Loss_G: 0.0379 Convergence: 0.0928 k= 0.020207 lr = 0.0000081\n",
      "[15/25][1280/9765] Loss_D: 0.0976 Loss_G: 0.0376 Convergence: 0.1001 k= 0.020210 lr = 0.0000081\n",
      "[15/25][1290/9765] Loss_D: 0.0910 Loss_G: 0.0368 Convergence: 0.0919 k= 0.020211 lr = 0.0000081\n",
      "[15/25][1300/9765] Loss_D: 0.0939 Loss_G: 0.0388 Convergence: 0.0956 k= 0.020212 lr = 0.0000081\n",
      "[15/25][1310/9765] Loss_D: 0.0976 Loss_G: 0.0393 Convergence: 0.0985 k= 0.020218 lr = 0.0000081\n",
      "[15/25][1320/9765] Loss_D: 0.0914 Loss_G: 0.0376 Convergence: 0.0929 k= 0.020209 lr = 0.0000081\n",
      "[15/25][1330/9765] Loss_D: 0.0915 Loss_G: 0.0361 Convergence: 0.0931 k= 0.020230 lr = 0.0000081\n",
      "[15/25][1340/9765] Loss_D: 0.0933 Loss_G: 0.0404 Convergence: 0.0968 k= 0.020226 lr = 0.0000081\n",
      "[15/25][1350/9765] Loss_D: 0.1039 Loss_G: 0.0404 Convergence: 0.1061 k= 0.020209 lr = 0.0000081\n",
      "[15/25][1360/9765] Loss_D: 0.0924 Loss_G: 0.0375 Convergence: 0.0934 k= 0.020199 lr = 0.0000081\n",
      "[15/25][1370/9765] Loss_D: 0.0969 Loss_G: 0.0380 Convergence: 0.0987 k= 0.020216 lr = 0.0000081\n",
      "[15/25][1380/9765] Loss_D: 0.0937 Loss_G: 0.0392 Convergence: 0.0959 k= 0.020218 lr = 0.0000081\n",
      "[15/25][1390/9765] Loss_D: 0.0913 Loss_G: 0.0378 Convergence: 0.0931 k= 0.020231 lr = 0.0000081\n",
      "[15/25][1400/9765] Loss_D: 0.0947 Loss_G: 0.0369 Convergence: 0.0967 k= 0.020243 lr = 0.0000081\n",
      "[15/25][1410/9765] Loss_D: 0.0972 Loss_G: 0.0392 Convergence: 0.0980 k= 0.020249 lr = 0.0000081\n",
      "[15/25][1420/9765] Loss_D: 0.0901 Loss_G: 0.0389 Convergence: 0.0935 k= 0.020249 lr = 0.0000081\n",
      "[15/25][1430/9765] Loss_D: 0.1016 Loss_G: 0.0380 Convergence: 0.1054 k= 0.020276 lr = 0.0000081\n",
      "[15/25][1440/9765] Loss_D: 0.0907 Loss_G: 0.0389 Convergence: 0.0937 k= 0.020273 lr = 0.0000081\n",
      "[15/25][1450/9765] Loss_D: 0.0967 Loss_G: 0.0390 Convergence: 0.0976 k= 0.020277 lr = 0.0000081\n",
      "[15/25][1460/9765] Loss_D: 0.0885 Loss_G: 0.0404 Convergence: 0.0939 k= 0.020264 lr = 0.0000081\n",
      "[15/25][1470/9765] Loss_D: 0.0913 Loss_G: 0.0421 Convergence: 0.0974 k= 0.020236 lr = 0.0000081\n",
      "[15/25][1480/9765] Loss_D: 0.0912 Loss_G: 0.0419 Convergence: 0.0971 k= 0.020211 lr = 0.0000081\n",
      "[15/25][1490/9765] Loss_D: 0.0847 Loss_G: 0.0383 Convergence: 0.0895 k= 0.020189 lr = 0.0000081\n",
      "[15/25][1500/9765] Loss_D: 0.0953 Loss_G: 0.0391 Convergence: 0.0968 k= 0.020202 lr = 0.0000081\n",
      "[15/25][1510/9765] Loss_D: 0.0904 Loss_G: 0.0382 Convergence: 0.0929 k= 0.020214 lr = 0.0000081\n",
      "[15/25][1520/9765] Loss_D: 0.1007 Loss_G: 0.0388 Convergence: 0.1033 k= 0.020211 lr = 0.0000081\n",
      "[15/25][1530/9765] Loss_D: 0.1122 Loss_G: 0.0407 Convergence: 0.1174 k= 0.020217 lr = 0.0000081\n",
      "[15/25][1540/9765] Loss_D: 0.1005 Loss_G: 0.0393 Convergence: 0.1025 k= 0.020211 lr = 0.0000081\n",
      "[15/25][1550/9765] Loss_D: 0.0868 Loss_G: 0.0410 Convergence: 0.0935 k= 0.020201 lr = 0.0000081\n",
      "[15/25][1560/9765] Loss_D: 0.0940 Loss_G: 0.0412 Convergence: 0.0981 k= 0.020171 lr = 0.0000081\n",
      "[15/25][1570/9765] Loss_D: 0.0895 Loss_G: 0.0402 Convergence: 0.0944 k= 0.020165 lr = 0.0000081\n",
      "[15/25][1580/9765] Loss_D: 0.0927 Loss_G: 0.0411 Convergence: 0.0972 k= 0.020139 lr = 0.0000081\n",
      "[15/25][1590/9765] Loss_D: 0.0951 Loss_G: 0.0408 Convergence: 0.0984 k= 0.020124 lr = 0.0000081\n",
      "[15/25][1600/9765] Loss_D: 0.1012 Loss_G: 0.0373 Convergence: 0.1054 k= 0.020132 lr = 0.0000081\n",
      "[15/25][1610/9765] Loss_D: 0.1003 Loss_G: 0.0383 Convergence: 0.1033 k= 0.020146 lr = 0.0000081\n",
      "[15/25][1620/9765] Loss_D: 0.0871 Loss_G: 0.0383 Convergence: 0.0910 k= 0.020153 lr = 0.0000081\n",
      "[15/25][1630/9765] Loss_D: 0.0915 Loss_G: 0.0379 Convergence: 0.0933 k= 0.020154 lr = 0.0000081\n",
      "[15/25][1640/9765] Loss_D: 0.0898 Loss_G: 0.0385 Convergence: 0.0928 k= 0.020152 lr = 0.0000081\n",
      "[15/25][1650/9765] Loss_D: 0.0982 Loss_G: 0.0404 Convergence: 0.0999 k= 0.020134 lr = 0.0000081\n",
      "[15/25][1660/9765] Loss_D: 0.0983 Loss_G: 0.0399 Convergence: 0.0993 k= 0.020128 lr = 0.0000081\n",
      "[15/25][1670/9765] Loss_D: 0.1041 Loss_G: 0.0418 Convergence: 0.1052 k= 0.020117 lr = 0.0000081\n",
      "[15/25][1680/9765] Loss_D: 0.0935 Loss_G: 0.0374 Convergence: 0.0945 k= 0.020117 lr = 0.0000081\n",
      "[15/25][1690/9765] Loss_D: 0.0969 Loss_G: 0.0389 Convergence: 0.0978 k= 0.020123 lr = 0.0000081\n",
      "[15/25][1700/9765] Loss_D: 0.0933 Loss_G: 0.0387 Convergence: 0.0951 k= 0.020113 lr = 0.0000081\n",
      "[15/25][1710/9765] Loss_D: 0.0932 Loss_G: 0.0389 Convergence: 0.0953 k= 0.020120 lr = 0.0000081\n",
      "[15/25][1720/9765] Loss_D: 0.0958 Loss_G: 0.0402 Convergence: 0.0981 k= 0.020123 lr = 0.0000081\n",
      "[15/25][1730/9765] Loss_D: 0.0935 Loss_G: 0.0412 Convergence: 0.0978 k= 0.020102 lr = 0.0000081\n",
      "[15/25][1740/9765] Loss_D: 0.1076 Loss_G: 0.0400 Convergence: 0.1117 k= 0.020087 lr = 0.0000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][1750/9765] Loss_D: 0.0968 Loss_G: 0.0393 Convergence: 0.0978 k= 0.020079 lr = 0.0000081\n",
      "[15/25][1760/9765] Loss_D: 0.0989 Loss_G: 0.0380 Convergence: 0.1015 k= 0.020079 lr = 0.0000081\n",
      "[15/25][1770/9765] Loss_D: 0.0999 Loss_G: 0.0394 Convergence: 0.1015 k= 0.020073 lr = 0.0000081\n",
      "[15/25][1780/9765] Loss_D: 0.0994 Loss_G: 0.0378 Convergence: 0.1023 k= 0.020073 lr = 0.0000081\n",
      "[15/25][1790/9765] Loss_D: 0.1020 Loss_G: 0.0396 Convergence: 0.1043 k= 0.020078 lr = 0.0000081\n",
      "[15/25][1800/9765] Loss_D: 0.1020 Loss_G: 0.0410 Convergence: 0.1029 k= 0.020073 lr = 0.0000081\n",
      "[15/25][1810/9765] Loss_D: 0.0935 Loss_G: 0.0415 Convergence: 0.0981 k= 0.020066 lr = 0.0000081\n",
      "[15/25][1820/9765] Loss_D: 0.0959 Loss_G: 0.0418 Convergence: 0.0998 k= 0.020039 lr = 0.0000081\n",
      "[15/25][1830/9765] Loss_D: 0.0944 Loss_G: 0.0421 Convergence: 0.0993 k= 0.020019 lr = 0.0000081\n",
      "[15/25][1840/9765] Loss_D: 0.0965 Loss_G: 0.0398 Convergence: 0.0982 k= 0.019988 lr = 0.0000081\n",
      "[15/25][1850/9765] Loss_D: 0.0878 Loss_G: 0.0388 Convergence: 0.0920 k= 0.019982 lr = 0.0000081\n",
      "[15/25][1860/9765] Loss_D: 0.1005 Loss_G: 0.0386 Convergence: 0.1032 k= 0.019985 lr = 0.0000081\n",
      "[15/25][1870/9765] Loss_D: 0.1025 Loss_G: 0.0388 Convergence: 0.1059 k= 0.019982 lr = 0.0000081\n",
      "[15/25][1880/9765] Loss_D: 0.1000 Loss_G: 0.0366 Convergence: 0.1045 k= 0.020008 lr = 0.0000081\n",
      "[15/25][1890/9765] Loss_D: 0.0963 Loss_G: 0.0397 Convergence: 0.0979 k= 0.020008 lr = 0.0000081\n",
      "[15/25][1900/9765] Loss_D: 0.0955 Loss_G: 0.0372 Convergence: 0.0975 k= 0.020032 lr = 0.0000081\n",
      "[15/25][1910/9765] Loss_D: 0.1067 Loss_G: 0.0387 Convergence: 0.1117 k= 0.020050 lr = 0.0000081\n",
      "[15/25][1920/9765] Loss_D: 0.1008 Loss_G: 0.0421 Convergence: 0.1030 k= 0.020044 lr = 0.0000081\n",
      "[15/25][1930/9765] Loss_D: 0.0992 Loss_G: 0.0381 Convergence: 0.1018 k= 0.020043 lr = 0.0000081\n",
      "[15/25][1940/9765] Loss_D: 0.0972 Loss_G: 0.0393 Convergence: 0.0981 k= 0.020043 lr = 0.0000081\n",
      "[15/25][1950/9765] Loss_D: 0.0866 Loss_G: 0.0400 Convergence: 0.0924 k= 0.020041 lr = 0.0000081\n",
      "[15/25][1960/9765] Loss_D: 0.0989 Loss_G: 0.0387 Convergence: 0.1009 k= 0.020041 lr = 0.0000081\n",
      "[15/25][1970/9765] Loss_D: 0.0988 Loss_G: 0.0378 Convergence: 0.1016 k= 0.020048 lr = 0.0000081\n",
      "[15/25][1980/9765] Loss_D: 0.0981 Loss_G: 0.0367 Convergence: 0.1017 k= 0.020063 lr = 0.0000081\n",
      "[15/25][1990/9765] Loss_D: 0.0919 Loss_G: 0.0371 Convergence: 0.0926 k= 0.020076 lr = 0.0000081\n",
      "[15/25][2000/9765] Loss_D: 0.0965 Loss_G: 0.0394 Convergence: 0.0978 k= 0.020084 lr = 0.0000081\n",
      "[15/25][2010/9765] Loss_D: 0.1034 Loss_G: 0.0389 Convergence: 0.1070 k= 0.020090 lr = 0.0000081\n",
      "[15/25][2020/9765] Loss_D: 0.0984 Loss_G: 0.0383 Convergence: 0.1005 k= 0.020098 lr = 0.0000081\n",
      "[15/25][2030/9765] Loss_D: 0.1083 Loss_G: 0.0406 Convergence: 0.1122 k= 0.020095 lr = 0.0000081\n",
      "[15/25][2040/9765] Loss_D: 0.0913 Loss_G: 0.0378 Convergence: 0.0931 k= 0.020085 lr = 0.0000081\n",
      "[15/25][2050/9765] Loss_D: 0.0913 Loss_G: 0.0357 Convergence: 0.0931 k= 0.020086 lr = 0.0000081\n",
      "[15/25][2060/9765] Loss_D: 0.0891 Loss_G: 0.0371 Convergence: 0.0910 k= 0.020106 lr = 0.0000081\n",
      "[15/25][2070/9765] Loss_D: 0.0914 Loss_G: 0.0414 Convergence: 0.0967 k= 0.020104 lr = 0.0000081\n",
      "[15/25][2080/9765] Loss_D: 0.0955 Loss_G: 0.0389 Convergence: 0.0966 k= 0.020117 lr = 0.0000081\n",
      "[15/25][2090/9765] Loss_D: 0.0959 Loss_G: 0.0387 Convergence: 0.0967 k= 0.020123 lr = 0.0000081\n",
      "[15/25][2100/9765] Loss_D: 0.0907 Loss_G: 0.0396 Convergence: 0.0945 k= 0.020116 lr = 0.0000081\n",
      "[15/25][2110/9765] Loss_D: 0.0848 Loss_G: 0.0393 Convergence: 0.0907 k= 0.020110 lr = 0.0000081\n",
      "[15/25][2120/9765] Loss_D: 0.1080 Loss_G: 0.0382 Convergence: 0.1141 k= 0.020106 lr = 0.0000081\n",
      "[15/25][2130/9765] Loss_D: 0.0971 Loss_G: 0.0364 Convergence: 0.1007 k= 0.020106 lr = 0.0000081\n",
      "[15/25][2140/9765] Loss_D: 0.0905 Loss_G: 0.0393 Convergence: 0.0941 k= 0.020112 lr = 0.0000081\n",
      "[15/25][2150/9765] Loss_D: 0.0951 Loss_G: 0.0396 Convergence: 0.0971 k= 0.020103 lr = 0.0000081\n",
      "[15/25][2160/9765] Loss_D: 0.0981 Loss_G: 0.0397 Convergence: 0.0991 k= 0.020089 lr = 0.0000081\n",
      "[15/25][2170/9765] Loss_D: 0.0931 Loss_G: 0.0397 Convergence: 0.0961 k= 0.020080 lr = 0.0000081\n",
      "[15/25][2180/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0952 k= 0.020082 lr = 0.0000081\n",
      "[15/25][2190/9765] Loss_D: 0.1072 Loss_G: 0.0378 Convergence: 0.1133 k= 0.020091 lr = 0.0000081\n",
      "[15/25][2200/9765] Loss_D: 0.1023 Loss_G: 0.0400 Convergence: 0.1044 k= 0.020101 lr = 0.0000081\n",
      "[15/25][2210/9765] Loss_D: 0.0962 Loss_G: 0.0397 Convergence: 0.0979 k= 0.020095 lr = 0.0000081\n",
      "[15/25][2220/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0966 k= 0.020092 lr = 0.0000081\n",
      "[15/25][2230/9765] Loss_D: 0.0954 Loss_G: 0.0373 Convergence: 0.0974 k= 0.020098 lr = 0.0000081\n",
      "[15/25][2240/9765] Loss_D: 0.0947 Loss_G: 0.0391 Convergence: 0.0963 k= 0.020117 lr = 0.0000081\n",
      "[15/25][2250/9765] Loss_D: 0.0907 Loss_G: 0.0411 Convergence: 0.0960 k= 0.020114 lr = 0.0000081\n",
      "[15/25][2260/9765] Loss_D: 0.0978 Loss_G: 0.0422 Convergence: 0.1013 k= 0.020095 lr = 0.0000081\n",
      "[15/25][2270/9765] Loss_D: 0.1014 Loss_G: 0.0397 Convergence: 0.1034 k= 0.020092 lr = 0.0000081\n",
      "[15/25][2280/9765] Loss_D: 0.1028 Loss_G: 0.0401 Convergence: 0.1049 k= 0.020084 lr = 0.0000081\n",
      "[15/25][2290/9765] Loss_D: 0.0865 Loss_G: 0.0392 Convergence: 0.0916 k= 0.020072 lr = 0.0000081\n",
      "[15/25][2300/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0964 k= 0.020085 lr = 0.0000081\n",
      "[15/25][2310/9765] Loss_D: 0.1029 Loss_G: 0.0387 Convergence: 0.1063 k= 0.020094 lr = 0.0000081\n",
      "[15/25][2320/9765] Loss_D: 0.0915 Loss_G: 0.0415 Convergence: 0.0968 k= 0.020091 lr = 0.0000081\n",
      "[15/25][2330/9765] Loss_D: 0.1028 Loss_G: 0.0408 Convergence: 0.1042 k= 0.020071 lr = 0.0000081\n",
      "[15/25][2340/9765] Loss_D: 0.0927 Loss_G: 0.0404 Convergence: 0.0965 k= 0.020053 lr = 0.0000081\n",
      "[15/25][2350/9765] Loss_D: 0.0915 Loss_G: 0.0416 Convergence: 0.0969 k= 0.020045 lr = 0.0000081\n",
      "[15/25][2360/9765] Loss_D: 0.0855 Loss_G: 0.0389 Convergence: 0.0907 k= 0.020024 lr = 0.0000081\n",
      "[15/25][2370/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0993 k= 0.020025 lr = 0.0000081\n",
      "[15/25][2380/9765] Loss_D: 0.0951 Loss_G: 0.0407 Convergence: 0.0982 k= 0.020004 lr = 0.0000081\n",
      "[15/25][2390/9765] Loss_D: 0.1004 Loss_G: 0.0391 Convergence: 0.1025 k= 0.019999 lr = 0.0000081\n",
      "[15/25][2400/9765] Loss_D: 0.0963 Loss_G: 0.0388 Convergence: 0.0971 k= 0.020016 lr = 0.0000081\n",
      "[15/25][2410/9765] Loss_D: 0.0927 Loss_G: 0.0415 Convergence: 0.0976 k= 0.020001 lr = 0.0000081\n",
      "[15/25][2420/9765] Loss_D: 0.1035 Loss_G: 0.0416 Convergence: 0.1044 k= 0.019991 lr = 0.0000081\n",
      "[15/25][2430/9765] Loss_D: 0.0981 Loss_G: 0.0422 Convergence: 0.1016 k= 0.019978 lr = 0.0000081\n",
      "[15/25][2440/9765] Loss_D: 0.0955 Loss_G: 0.0421 Convergence: 0.0999 k= 0.019953 lr = 0.0000081\n",
      "[15/25][2450/9765] Loss_D: 0.0974 Loss_G: 0.0376 Convergence: 0.0997 k= 0.019948 lr = 0.0000081\n",
      "[15/25][2460/9765] Loss_D: 0.0953 Loss_G: 0.0385 Convergence: 0.0962 k= 0.019960 lr = 0.0000081\n",
      "[15/25][2470/9765] Loss_D: 0.0990 Loss_G: 0.0380 Convergence: 0.1017 k= 0.019975 lr = 0.0000081\n",
      "[15/25][2480/9765] Loss_D: 0.0895 Loss_G: 0.0362 Convergence: 0.0904 k= 0.019982 lr = 0.0000081\n",
      "[15/25][2490/9765] Loss_D: 0.0901 Loss_G: 0.0369 Convergence: 0.0914 k= 0.019991 lr = 0.0000081\n",
      "[15/25][2500/9765] Loss_D: 0.0985 Loss_G: 0.0355 Convergence: 0.1034 k= 0.020019 lr = 0.0000081\n",
      "[15/25][2510/9765] Loss_D: 0.0965 Loss_G: 0.0375 Convergence: 0.0988 k= 0.020028 lr = 0.0000081\n",
      "[15/25][2520/9765] Loss_D: 0.1022 Loss_G: 0.0433 Convergence: 0.1051 k= 0.020021 lr = 0.0000081\n",
      "[15/25][2530/9765] Loss_D: 0.1122 Loss_G: 0.0432 Convergence: 0.1152 k= 0.019999 lr = 0.0000081\n",
      "[15/25][2540/9765] Loss_D: 0.1054 Loss_G: 0.0435 Convergence: 0.1072 k= 0.019961 lr = 0.0000081\n",
      "[15/25][2550/9765] Loss_D: 0.0983 Loss_G: 0.0417 Convergence: 0.1012 k= 0.019936 lr = 0.0000081\n",
      "[15/25][2560/9765] Loss_D: 0.0992 Loss_G: 0.0387 Convergence: 0.1013 k= 0.019925 lr = 0.0000081\n",
      "[15/25][2570/9765] Loss_D: 0.0903 Loss_G: 0.0392 Convergence: 0.0939 k= 0.019921 lr = 0.0000081\n",
      "[15/25][2580/9765] Loss_D: 0.0926 Loss_G: 0.0393 Convergence: 0.0954 k= 0.019926 lr = 0.0000081\n",
      "[15/25][2590/9765] Loss_D: 0.0871 Loss_G: 0.0388 Convergence: 0.0915 k= 0.019923 lr = 0.0000081\n",
      "[15/25][2600/9765] Loss_D: 0.0930 Loss_G: 0.0383 Convergence: 0.0946 k= 0.019941 lr = 0.0000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][2610/9765] Loss_D: 0.0977 Loss_G: 0.0408 Convergence: 0.0999 k= 0.019936 lr = 0.0000081\n",
      "[15/25][2620/9765] Loss_D: 0.0976 Loss_G: 0.0394 Convergence: 0.0984 k= 0.019933 lr = 0.0000081\n",
      "[15/25][2630/9765] Loss_D: 0.0967 Loss_G: 0.0393 Convergence: 0.0977 k= 0.019950 lr = 0.0000081\n",
      "[15/25][2640/9765] Loss_D: 0.0896 Loss_G: 0.0388 Convergence: 0.0930 k= 0.019952 lr = 0.0000081\n",
      "[15/25][2650/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0974 k= 0.019939 lr = 0.0000081\n",
      "[15/25][2660/9765] Loss_D: 0.0982 Loss_G: 0.0385 Convergence: 0.1000 k= 0.019945 lr = 0.0000081\n",
      "[15/25][2670/9765] Loss_D: 0.0880 Loss_G: 0.0378 Convergence: 0.0911 k= 0.019943 lr = 0.0000081\n",
      "[15/25][2680/9765] Loss_D: 0.0986 Loss_G: 0.0376 Convergence: 0.1015 k= 0.019940 lr = 0.0000081\n",
      "[15/25][2690/9765] Loss_D: 0.0955 Loss_G: 0.0381 Convergence: 0.0966 k= 0.019927 lr = 0.0000081\n",
      "[15/25][2700/9765] Loss_D: 0.0932 Loss_G: 0.0411 Convergence: 0.0976 k= 0.019933 lr = 0.0000081\n",
      "[15/25][2710/9765] Loss_D: 0.1002 Loss_G: 0.0419 Convergence: 0.1025 k= 0.019919 lr = 0.0000081\n",
      "[15/25][2720/9765] Loss_D: 0.0952 Loss_G: 0.0416 Convergence: 0.0992 k= 0.019895 lr = 0.0000081\n",
      "[15/25][2730/9765] Loss_D: 0.0984 Loss_G: 0.0398 Convergence: 0.0993 k= 0.019891 lr = 0.0000081\n",
      "[15/25][2740/9765] Loss_D: 0.0908 Loss_G: 0.0372 Convergence: 0.0921 k= 0.019911 lr = 0.0000081\n",
      "[15/25][2750/9765] Loss_D: 0.1000 Loss_G: 0.0362 Convergence: 0.1048 k= 0.019915 lr = 0.0000081\n",
      "[15/25][2760/9765] Loss_D: 0.1050 Loss_G: 0.0388 Convergence: 0.1093 k= 0.019921 lr = 0.0000081\n",
      "[15/25][2770/9765] Loss_D: 0.0965 Loss_G: 0.0376 Convergence: 0.0985 k= 0.019921 lr = 0.0000081\n",
      "[15/25][2780/9765] Loss_D: 0.0900 Loss_G: 0.0396 Convergence: 0.0941 k= 0.019929 lr = 0.0000081\n",
      "[15/25][2790/9765] Loss_D: 0.0928 Loss_G: 0.0437 Convergence: 0.0999 k= 0.019919 lr = 0.0000081\n",
      "[15/25][2800/9765] Loss_D: 0.0918 Loss_G: 0.0424 Convergence: 0.0980 k= 0.019894 lr = 0.0000081\n",
      "[15/25][2810/9765] Loss_D: 0.0990 Loss_G: 0.0424 Convergence: 0.1023 k= 0.019858 lr = 0.0000081\n",
      "[15/25][2820/9765] Loss_D: 0.1028 Loss_G: 0.0380 Convergence: 0.1069 k= 0.019844 lr = 0.0000081\n",
      "[15/25][2830/9765] Loss_D: 0.1037 Loss_G: 0.0364 Convergence: 0.1098 k= 0.019850 lr = 0.0000081\n",
      "[15/25][2840/9765] Loss_D: 0.0977 Loss_G: 0.0374 Convergence: 0.1004 k= 0.019862 lr = 0.0000081\n",
      "[15/25][2850/9765] Loss_D: 0.1023 Loss_G: 0.0381 Convergence: 0.1062 k= 0.019880 lr = 0.0000081\n",
      "[15/25][2860/9765] Loss_D: 0.0929 Loss_G: 0.0398 Convergence: 0.0960 k= 0.019880 lr = 0.0000081\n",
      "[15/25][2870/9765] Loss_D: 0.0972 Loss_G: 0.0397 Convergence: 0.0984 k= 0.019863 lr = 0.0000081\n",
      "[15/25][2880/9765] Loss_D: 0.0884 Loss_G: 0.0390 Convergence: 0.0926 k= 0.019840 lr = 0.0000081\n",
      "[15/25][2890/9765] Loss_D: 0.0929 Loss_G: 0.0382 Convergence: 0.0944 k= 0.019835 lr = 0.0000081\n",
      "[15/25][2900/9765] Loss_D: 0.0961 Loss_G: 0.0402 Convergence: 0.0983 k= 0.019843 lr = 0.0000081\n",
      "[15/25][2910/9765] Loss_D: 0.0988 Loss_G: 0.0381 Convergence: 0.1013 k= 0.019857 lr = 0.0000081\n",
      "[15/25][2920/9765] Loss_D: 0.1008 Loss_G: 0.0386 Convergence: 0.1036 k= 0.019867 lr = 0.0000081\n",
      "[15/25][2930/9765] Loss_D: 0.0970 Loss_G: 0.0397 Convergence: 0.0983 k= 0.019874 lr = 0.0000081\n",
      "[15/25][2940/9765] Loss_D: 0.0935 Loss_G: 0.0382 Convergence: 0.0948 k= 0.019868 lr = 0.0000081\n",
      "[15/25][2950/9765] Loss_D: 0.0939 Loss_G: 0.0387 Convergence: 0.0955 k= 0.019859 lr = 0.0000081\n",
      "[15/25][2960/9765] Loss_D: 0.0979 Loss_G: 0.0439 Convergence: 0.1032 k= 0.019843 lr = 0.0000081\n",
      "[15/25][2970/9765] Loss_D: 0.0996 Loss_G: 0.0400 Convergence: 0.1005 k= 0.019836 lr = 0.0000081\n",
      "[15/25][2980/9765] Loss_D: 0.0950 Loss_G: 0.0401 Convergence: 0.0975 k= 0.019827 lr = 0.0000081\n",
      "[15/25][2990/9765] Loss_D: 0.0958 Loss_G: 0.0377 Convergence: 0.0974 k= 0.019834 lr = 0.0000081\n",
      "[15/25][3000/9765] Loss_D: 0.0943 Loss_G: 0.0386 Convergence: 0.0956 k= 0.019847 lr = 0.0000081\n",
      "[15/25][3010/9765] Loss_D: 0.0937 Loss_G: 0.0397 Convergence: 0.0965 k= 0.019846 lr = 0.0000081\n",
      "[15/25][3020/9765] Loss_D: 0.0991 Loss_G: 0.0384 Convergence: 0.1014 k= 0.019854 lr = 0.0000081\n",
      "[15/25][3030/9765] Loss_D: 0.0971 Loss_G: 0.0407 Convergence: 0.0994 k= 0.019855 lr = 0.0000081\n",
      "[15/25][3040/9765] Loss_D: 0.1000 Loss_G: 0.0408 Convergence: 0.1013 k= 0.019836 lr = 0.0000081\n",
      "[15/25][3050/9765] Loss_D: 0.1109 Loss_G: 0.0395 Convergence: 0.1168 k= 0.019844 lr = 0.0000081\n",
      "[15/25][3060/9765] Loss_D: 0.0933 Loss_G: 0.0381 Convergence: 0.0946 k= 0.019838 lr = 0.0000081\n",
      "[15/25][3070/9765] Loss_D: 0.1109 Loss_G: 0.0387 Convergence: 0.1177 k= 0.019844 lr = 0.0000081\n",
      "[15/25][3080/9765] Loss_D: 0.0905 Loss_G: 0.0373 Convergence: 0.0920 k= 0.019863 lr = 0.0000081\n",
      "[15/25][3090/9765] Loss_D: 0.1007 Loss_G: 0.0390 Convergence: 0.1031 k= 0.019866 lr = 0.0000081\n",
      "[15/25][3100/9765] Loss_D: 0.0927 Loss_G: 0.0379 Convergence: 0.0940 k= 0.019880 lr = 0.0000081\n",
      "[15/25][3110/9765] Loss_D: 0.0943 Loss_G: 0.0380 Convergence: 0.0952 k= 0.019872 lr = 0.0000081\n",
      "[15/25][3120/9765] Loss_D: 0.0900 Loss_G: 0.0381 Convergence: 0.0926 k= 0.019858 lr = 0.0000081\n",
      "[15/25][3130/9765] Loss_D: 0.1037 Loss_G: 0.0415 Convergence: 0.1048 k= 0.019840 lr = 0.0000081\n",
      "[15/25][3140/9765] Loss_D: 0.0978 Loss_G: 0.0387 Convergence: 0.0994 k= 0.019821 lr = 0.0000081\n",
      "[15/25][3150/9765] Loss_D: 0.1038 Loss_G: 0.0385 Convergence: 0.1078 k= 0.019816 lr = 0.0000081\n",
      "[15/25][3160/9765] Loss_D: 0.0961 Loss_G: 0.0410 Convergence: 0.0991 k= 0.019801 lr = 0.0000081\n",
      "[15/25][3170/9765] Loss_D: 0.0893 Loss_G: 0.0398 Convergence: 0.0938 k= 0.019789 lr = 0.0000081\n",
      "[15/25][3180/9765] Loss_D: 0.0872 Loss_G: 0.0366 Convergence: 0.0894 k= 0.019805 lr = 0.0000081\n",
      "[15/25][3190/9765] Loss_D: 0.0961 Loss_G: 0.0353 Convergence: 0.1002 k= 0.019824 lr = 0.0000081\n",
      "[15/25][3200/9765] Loss_D: 0.1024 Loss_G: 0.0371 Convergence: 0.1073 k= 0.019859 lr = 0.0000081\n",
      "[15/25][3210/9765] Loss_D: 0.0940 Loss_G: 0.0356 Convergence: 0.0970 k= 0.019881 lr = 0.0000081\n",
      "[15/25][3220/9765] Loss_D: 0.0993 Loss_G: 0.0378 Convergence: 0.1023 k= 0.019895 lr = 0.0000081\n",
      "[15/25][3230/9765] Loss_D: 0.1032 Loss_G: 0.0388 Convergence: 0.1068 k= 0.019898 lr = 0.0000081\n",
      "[15/25][3240/9765] Loss_D: 0.0975 Loss_G: 0.0412 Convergence: 0.1002 k= 0.019870 lr = 0.0000081\n",
      "[15/25][3250/9765] Loss_D: 0.0948 Loss_G: 0.0404 Convergence: 0.0978 k= 0.019848 lr = 0.0000081\n",
      "[15/25][3260/9765] Loss_D: 0.1081 Loss_G: 0.0411 Convergence: 0.1114 k= 0.019849 lr = 0.0000081\n",
      "[15/25][3270/9765] Loss_D: 0.0918 Loss_G: 0.0392 Convergence: 0.0948 k= 0.019838 lr = 0.0000081\n",
      "[15/25][3280/9765] Loss_D: 0.1033 Loss_G: 0.0377 Convergence: 0.1079 k= 0.019857 lr = 0.0000081\n",
      "[15/25][3290/9765] Loss_D: 0.1084 Loss_G: 0.0399 Convergence: 0.1129 k= 0.019866 lr = 0.0000081\n",
      "[15/25][3300/9765] Loss_D: 0.0959 Loss_G: 0.0385 Convergence: 0.0968 k= 0.019874 lr = 0.0000081\n",
      "[15/25][3310/9765] Loss_D: 0.1044 Loss_G: 0.0377 Convergence: 0.1095 k= 0.019882 lr = 0.0000081\n",
      "[15/25][3320/9765] Loss_D: 0.0988 Loss_G: 0.0376 Convergence: 0.1017 k= 0.019895 lr = 0.0000081\n",
      "[15/25][3330/9765] Loss_D: 0.1002 Loss_G: 0.0396 Convergence: 0.1017 k= 0.019910 lr = 0.0000081\n",
      "[15/25][3340/9765] Loss_D: 0.1045 Loss_G: 0.0406 Convergence: 0.1069 k= 0.019902 lr = 0.0000081\n",
      "[15/25][3350/9765] Loss_D: 0.0964 Loss_G: 0.0387 Convergence: 0.0972 k= 0.019885 lr = 0.0000081\n",
      "[15/25][3360/9765] Loss_D: 0.0948 Loss_G: 0.0403 Convergence: 0.0977 k= 0.019872 lr = 0.0000081\n",
      "[15/25][3370/9765] Loss_D: 0.1034 Loss_G: 0.0382 Convergence: 0.1076 k= 0.019872 lr = 0.0000081\n",
      "[15/25][3380/9765] Loss_D: 0.1082 Loss_G: 0.0369 Convergence: 0.1155 k= 0.019899 lr = 0.0000081\n",
      "[15/25][3390/9765] Loss_D: 0.1063 Loss_G: 0.0401 Convergence: 0.1098 k= 0.019917 lr = 0.0000081\n",
      "[15/25][3400/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0976 k= 0.019917 lr = 0.0000081\n",
      "[15/25][3410/9765] Loss_D: 0.0888 Loss_G: 0.0377 Convergence: 0.0914 k= 0.019899 lr = 0.0000081\n",
      "[15/25][3420/9765] Loss_D: 0.0988 Loss_G: 0.0381 Convergence: 0.1012 k= 0.019898 lr = 0.0000081\n",
      "[15/25][3430/9765] Loss_D: 0.0940 Loss_G: 0.0398 Convergence: 0.0967 k= 0.019892 lr = 0.0000081\n",
      "[15/25][3440/9765] Loss_D: 0.0941 Loss_G: 0.0408 Convergence: 0.0978 k= 0.019883 lr = 0.0000081\n",
      "[15/25][3450/9765] Loss_D: 0.1025 Loss_G: 0.0399 Convergence: 0.1047 k= 0.019872 lr = 0.0000081\n",
      "[15/25][3460/9765] Loss_D: 0.0899 Loss_G: 0.0375 Convergence: 0.0919 k= 0.019882 lr = 0.0000081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][3470/9765] Loss_D: 0.0922 Loss_G: 0.0392 Convergence: 0.0950 k= 0.019880 lr = 0.0000081\n",
      "[15/25][3480/9765] Loss_D: 0.0930 Loss_G: 0.0371 Convergence: 0.0942 k= 0.019885 lr = 0.0000081\n",
      "[15/25][3490/9765] Loss_D: 0.0956 Loss_G: 0.0387 Convergence: 0.0966 k= 0.019911 lr = 0.0000081\n",
      "[15/25][3500/9765] Loss_D: 0.0886 Loss_G: 0.0370 Convergence: 0.0906 k= 0.019928 lr = 0.0000081\n",
      "[15/25][3510/9765] Loss_D: 0.0924 Loss_G: 0.0374 Convergence: 0.0932 k= 0.019925 lr = 0.0000081\n",
      "[15/25][3520/9765] Loss_D: 0.0999 Loss_G: 0.0414 Convergence: 0.1019 k= 0.019931 lr = 0.0000081\n",
      "[15/25][3530/9765] Loss_D: 0.1053 Loss_G: 0.0404 Convergence: 0.1081 k= 0.019920 lr = 0.0000077\n",
      "[15/25][3540/9765] Loss_D: 0.1041 Loss_G: 0.0425 Convergence: 0.1055 k= 0.019899 lr = 0.0000077\n",
      "[15/25][3550/9765] Loss_D: 0.0985 Loss_G: 0.0439 Convergence: 0.1036 k= 0.019844 lr = 0.0000077\n",
      "[15/25][3560/9765] Loss_D: 0.0900 Loss_G: 0.0425 Convergence: 0.0970 k= 0.019787 lr = 0.0000077\n",
      "[15/25][3570/9765] Loss_D: 0.1011 Loss_G: 0.0407 Convergence: 0.1020 k= 0.019758 lr = 0.0000077\n",
      "[15/25][3580/9765] Loss_D: 0.1076 Loss_G: 0.0400 Convergence: 0.1118 k= 0.019737 lr = 0.0000077\n",
      "[15/25][3590/9765] Loss_D: 0.0927 Loss_G: 0.0386 Convergence: 0.0947 k= 0.019744 lr = 0.0000077\n",
      "[15/25][3600/9765] Loss_D: 0.0966 Loss_G: 0.0372 Convergence: 0.0990 k= 0.019756 lr = 0.0000077\n",
      "[15/25][3610/9765] Loss_D: 0.1011 Loss_G: 0.0390 Convergence: 0.1036 k= 0.019780 lr = 0.0000077\n",
      "[15/25][3620/9765] Loss_D: 0.0967 Loss_G: 0.0368 Convergence: 0.0995 k= 0.019797 lr = 0.0000077\n",
      "[15/25][3630/9765] Loss_D: 0.0985 Loss_G: 0.0390 Convergence: 0.1000 k= 0.019818 lr = 0.0000077\n",
      "[15/25][3640/9765] Loss_D: 0.1037 Loss_G: 0.0402 Convergence: 0.1060 k= 0.019823 lr = 0.0000077\n",
      "[15/25][3650/9765] Loss_D: 0.1079 Loss_G: 0.0386 Convergence: 0.1135 k= 0.019828 lr = 0.0000077\n",
      "[15/25][3660/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0976 k= 0.019830 lr = 0.0000077\n",
      "[15/25][3670/9765] Loss_D: 0.1024 Loss_G: 0.0406 Convergence: 0.1039 k= 0.019836 lr = 0.0000077\n",
      "[15/25][3680/9765] Loss_D: 0.0980 Loss_G: 0.0394 Convergence: 0.0989 k= 0.019834 lr = 0.0000077\n",
      "[15/25][3690/9765] Loss_D: 0.1057 Loss_G: 0.0403 Convergence: 0.1087 k= 0.019831 lr = 0.0000077\n",
      "[15/25][3700/9765] Loss_D: 0.0983 Loss_G: 0.0350 Convergence: 0.1036 k= 0.019833 lr = 0.0000077\n",
      "[15/25][3710/9765] Loss_D: 0.0923 Loss_G: 0.0372 Convergence: 0.0931 k= 0.019852 lr = 0.0000077\n",
      "[15/25][3720/9765] Loss_D: 0.0957 Loss_G: 0.0363 Convergence: 0.0987 k= 0.019850 lr = 0.0000077\n",
      "[15/25][3730/9765] Loss_D: 0.0937 Loss_G: 0.0372 Convergence: 0.0949 k= 0.019872 lr = 0.0000077\n",
      "[15/25][3740/9765] Loss_D: 0.0948 Loss_G: 0.0368 Convergence: 0.0969 k= 0.019894 lr = 0.0000077\n",
      "[15/25][3750/9765] Loss_D: 0.0991 Loss_G: 0.0354 Convergence: 0.1044 k= 0.019910 lr = 0.0000077\n",
      "[15/25][3760/9765] Loss_D: 0.0956 Loss_G: 0.0383 Convergence: 0.0966 k= 0.019924 lr = 0.0000077\n",
      "[15/25][3770/9765] Loss_D: 0.0896 Loss_G: 0.0385 Convergence: 0.0927 k= 0.019924 lr = 0.0000077\n",
      "[15/25][3780/9765] Loss_D: 0.0940 Loss_G: 0.0397 Convergence: 0.0966 k= 0.019925 lr = 0.0000077\n",
      "[15/25][3790/9765] Loss_D: 0.0848 Loss_G: 0.0404 Convergence: 0.0918 k= 0.019907 lr = 0.0000077\n",
      "[15/25][3800/9765] Loss_D: 0.1006 Loss_G: 0.0395 Convergence: 0.1025 k= 0.019900 lr = 0.0000077\n",
      "[15/25][3810/9765] Loss_D: 0.0921 Loss_G: 0.0402 Convergence: 0.0960 k= 0.019899 lr = 0.0000077\n",
      "[15/25][3820/9765] Loss_D: 0.0987 Loss_G: 0.0387 Convergence: 0.1005 k= 0.019904 lr = 0.0000077\n",
      "[15/25][3830/9765] Loss_D: 0.1056 Loss_G: 0.0395 Convergence: 0.1095 k= 0.019902 lr = 0.0000077\n",
      "[15/25][3840/9765] Loss_D: 0.0902 Loss_G: 0.0366 Convergence: 0.0911 k= 0.019927 lr = 0.0000077\n",
      "[15/25][3850/9765] Loss_D: 0.0960 Loss_G: 0.0386 Convergence: 0.0969 k= 0.019948 lr = 0.0000077\n",
      "[15/25][3860/9765] Loss_D: 0.0953 Loss_G: 0.0372 Convergence: 0.0972 k= 0.019952 lr = 0.0000077\n",
      "[15/25][3870/9765] Loss_D: 0.0971 Loss_G: 0.0373 Convergence: 0.0997 k= 0.019959 lr = 0.0000077\n",
      "[15/25][3880/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0983 k= 0.019951 lr = 0.0000077\n",
      "[15/25][3890/9765] Loss_D: 0.0976 Loss_G: 0.0414 Convergence: 0.1005 k= 0.019935 lr = 0.0000077\n",
      "[15/25][3900/9765] Loss_D: 0.0900 Loss_G: 0.0383 Convergence: 0.0927 k= 0.019920 lr = 0.0000077\n",
      "[15/25][3910/9765] Loss_D: 0.0958 Loss_G: 0.0417 Convergence: 0.0997 k= 0.019912 lr = 0.0000077\n",
      "[15/25][3920/9765] Loss_D: 0.0952 Loss_G: 0.0374 Convergence: 0.0970 k= 0.019908 lr = 0.0000077\n",
      "[15/25][3930/9765] Loss_D: 0.0995 Loss_G: 0.0404 Convergence: 0.1006 k= 0.019912 lr = 0.0000077\n",
      "[15/25][3940/9765] Loss_D: 0.1024 Loss_G: 0.0407 Convergence: 0.1038 k= 0.019914 lr = 0.0000077\n",
      "[15/25][3950/9765] Loss_D: 0.1040 Loss_G: 0.0391 Convergence: 0.1076 k= 0.019912 lr = 0.0000077\n",
      "[15/25][3960/9765] Loss_D: 0.1108 Loss_G: 0.0416 Convergence: 0.1148 k= 0.019889 lr = 0.0000077\n",
      "[15/25][3970/9765] Loss_D: 0.0891 Loss_G: 0.0386 Convergence: 0.0925 k= 0.019881 lr = 0.0000077\n",
      "[15/25][3980/9765] Loss_D: 0.0945 Loss_G: 0.0397 Convergence: 0.0968 k= 0.019877 lr = 0.0000077\n",
      "[15/25][3990/9765] Loss_D: 0.0925 Loss_G: 0.0375 Convergence: 0.0934 k= 0.019882 lr = 0.0000077\n",
      "[15/25][4000/9765] Loss_D: 0.0929 Loss_G: 0.0371 Convergence: 0.0940 k= 0.019896 lr = 0.0000077\n",
      "[15/25][4010/9765] Loss_D: 0.0980 Loss_G: 0.0390 Convergence: 0.0994 k= 0.019898 lr = 0.0000077\n",
      "[15/25][4020/9765] Loss_D: 0.1041 Loss_G: 0.0391 Convergence: 0.1077 k= 0.019902 lr = 0.0000077\n",
      "[15/25][4030/9765] Loss_D: 0.0959 Loss_G: 0.0411 Convergence: 0.0991 k= 0.019890 lr = 0.0000077\n",
      "[15/25][4040/9765] Loss_D: 0.0960 Loss_G: 0.0397 Convergence: 0.0978 k= 0.019878 lr = 0.0000077\n",
      "[15/25][4050/9765] Loss_D: 0.0994 Loss_G: 0.0406 Convergence: 0.1007 k= 0.019870 lr = 0.0000077\n",
      "[15/25][4060/9765] Loss_D: 0.1026 Loss_G: 0.0394 Convergence: 0.1054 k= 0.019866 lr = 0.0000077\n",
      "[15/25][4070/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0955 k= 0.019866 lr = 0.0000077\n",
      "[15/25][4080/9765] Loss_D: 0.0992 Loss_G: 0.0393 Convergence: 0.1007 k= 0.019867 lr = 0.0000077\n",
      "[15/25][4090/9765] Loss_D: 0.0939 Loss_G: 0.0395 Convergence: 0.0963 k= 0.019865 lr = 0.0000077\n",
      "[15/25][4100/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0979 k= 0.019869 lr = 0.0000077\n",
      "[15/25][4110/9765] Loss_D: 0.1017 Loss_G: 0.0397 Convergence: 0.1037 k= 0.019866 lr = 0.0000077\n",
      "[15/25][4120/9765] Loss_D: 0.1019 Loss_G: 0.0392 Convergence: 0.1045 k= 0.019886 lr = 0.0000077\n",
      "[15/25][4130/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.019883 lr = 0.0000077\n",
      "[15/25][4140/9765] Loss_D: 0.0966 Loss_G: 0.0393 Convergence: 0.0977 k= 0.019872 lr = 0.0000077\n",
      "[15/25][4150/9765] Loss_D: 0.1015 Loss_G: 0.0389 Convergence: 0.1042 k= 0.019874 lr = 0.0000077\n",
      "[15/25][4160/9765] Loss_D: 0.0957 Loss_G: 0.0392 Convergence: 0.0971 k= 0.019886 lr = 0.0000077\n",
      "[15/25][4170/9765] Loss_D: 0.1017 Loss_G: 0.0378 Convergence: 0.1056 k= 0.019890 lr = 0.0000077\n",
      "[15/25][4180/9765] Loss_D: 0.0991 Loss_G: 0.0390 Convergence: 0.1008 k= 0.019893 lr = 0.0000077\n",
      "[15/25][4190/9765] Loss_D: 0.1040 Loss_G: 0.0404 Convergence: 0.1064 k= 0.019887 lr = 0.0000077\n",
      "[15/25][4200/9765] Loss_D: 0.0919 Loss_G: 0.0390 Convergence: 0.0947 k= 0.019881 lr = 0.0000077\n",
      "[15/25][4210/9765] Loss_D: 0.0972 Loss_G: 0.0376 Convergence: 0.0995 k= 0.019898 lr = 0.0000077\n",
      "[15/25][4220/9765] Loss_D: 0.0914 Loss_G: 0.0392 Convergence: 0.0945 k= 0.019892 lr = 0.0000077\n",
      "[15/25][4230/9765] Loss_D: 0.0955 Loss_G: 0.0401 Convergence: 0.0979 k= 0.019884 lr = 0.0000077\n",
      "[15/25][4240/9765] Loss_D: 0.1020 Loss_G: 0.0385 Convergence: 0.1054 k= 0.019886 lr = 0.0000077\n",
      "[15/25][4250/9765] Loss_D: 0.0943 Loss_G: 0.0420 Convergence: 0.0991 k= 0.019878 lr = 0.0000077\n",
      "[15/25][4260/9765] Loss_D: 0.1004 Loss_G: 0.0393 Convergence: 0.1024 k= 0.019867 lr = 0.0000077\n",
      "[15/25][4270/9765] Loss_D: 0.1009 Loss_G: 0.0396 Convergence: 0.1027 k= 0.019855 lr = 0.0000077\n",
      "[15/25][4280/9765] Loss_D: 0.0969 Loss_G: 0.0380 Convergence: 0.0987 k= 0.019856 lr = 0.0000077\n",
      "[15/25][4290/9765] Loss_D: 0.0888 Loss_G: 0.0393 Convergence: 0.0930 k= 0.019860 lr = 0.0000077\n",
      "[15/25][4300/9765] Loss_D: 0.0941 Loss_G: 0.0387 Convergence: 0.0956 k= 0.019868 lr = 0.0000077\n",
      "[15/25][4310/9765] Loss_D: 0.1042 Loss_G: 0.0375 Convergence: 0.1094 k= 0.019867 lr = 0.0000077\n",
      "[15/25][4320/9765] Loss_D: 0.0950 Loss_G: 0.0374 Convergence: 0.0967 k= 0.019872 lr = 0.0000077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][4330/9765] Loss_D: 0.0965 Loss_G: 0.0428 Convergence: 0.1012 k= 0.019871 lr = 0.0000077\n",
      "[15/25][4340/9765] Loss_D: 0.0986 Loss_G: 0.0384 Convergence: 0.1007 k= 0.019871 lr = 0.0000077\n",
      "[15/25][4350/9765] Loss_D: 0.0938 Loss_G: 0.0409 Convergence: 0.0977 k= 0.019881 lr = 0.0000077\n",
      "[15/25][4360/9765] Loss_D: 0.0907 Loss_G: 0.0382 Convergence: 0.0930 k= 0.019868 lr = 0.0000077\n",
      "[15/25][4370/9765] Loss_D: 0.0880 Loss_G: 0.0383 Convergence: 0.0916 k= 0.019872 lr = 0.0000077\n",
      "[15/25][4380/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0960 k= 0.019878 lr = 0.0000077\n",
      "[15/25][4390/9765] Loss_D: 0.0898 Loss_G: 0.0388 Convergence: 0.0932 k= 0.019876 lr = 0.0000077\n",
      "[15/25][4400/9765] Loss_D: 0.1023 Loss_G: 0.0403 Convergence: 0.1040 k= 0.019876 lr = 0.0000077\n",
      "[15/25][4410/9765] Loss_D: 0.1010 Loss_G: 0.0420 Convergence: 0.1031 k= 0.019871 lr = 0.0000077\n",
      "[15/25][4420/9765] Loss_D: 0.1084 Loss_G: 0.0405 Convergence: 0.1124 k= 0.019864 lr = 0.0000077\n",
      "[15/25][4430/9765] Loss_D: 0.1014 Loss_G: 0.0394 Convergence: 0.1037 k= 0.019858 lr = 0.0000077\n",
      "[15/25][4440/9765] Loss_D: 0.0955 Loss_G: 0.0391 Convergence: 0.0969 k= 0.019848 lr = 0.0000077\n",
      "[15/25][4450/9765] Loss_D: 0.0939 Loss_G: 0.0403 Convergence: 0.0972 k= 0.019866 lr = 0.0000077\n",
      "[15/25][4460/9765] Loss_D: 0.0971 Loss_G: 0.0394 Convergence: 0.0982 k= 0.019866 lr = 0.0000077\n",
      "[15/25][4470/9765] Loss_D: 0.1015 Loss_G: 0.0409 Convergence: 0.1023 k= 0.019861 lr = 0.0000077\n",
      "[15/25][4480/9765] Loss_D: 0.0995 Loss_G: 0.0397 Convergence: 0.1008 k= 0.019842 lr = 0.0000077\n",
      "[15/25][4490/9765] Loss_D: 0.0958 Loss_G: 0.0402 Convergence: 0.0982 k= 0.019845 lr = 0.0000077\n",
      "[15/25][4500/9765] Loss_D: 0.0882 Loss_G: 0.0377 Convergence: 0.0911 k= 0.019830 lr = 0.0000077\n",
      "[15/25][4510/9765] Loss_D: 0.0987 Loss_G: 0.0371 Convergence: 0.1022 k= 0.019832 lr = 0.0000077\n",
      "[15/25][4520/9765] Loss_D: 0.0904 Loss_G: 0.0390 Convergence: 0.0937 k= 0.019837 lr = 0.0000077\n",
      "[15/25][4530/9765] Loss_D: 0.0984 Loss_G: 0.0402 Convergence: 0.0998 k= 0.019819 lr = 0.0000077\n",
      "[15/25][4540/9765] Loss_D: 0.1031 Loss_G: 0.0404 Convergence: 0.1050 k= 0.019812 lr = 0.0000077\n",
      "[15/25][4550/9765] Loss_D: 0.0970 Loss_G: 0.0419 Convergence: 0.1006 k= 0.019805 lr = 0.0000077\n",
      "[15/25][4560/9765] Loss_D: 0.0944 Loss_G: 0.0391 Convergence: 0.0962 k= 0.019799 lr = 0.0000077\n",
      "[15/25][4570/9765] Loss_D: 0.1023 Loss_G: 0.0403 Convergence: 0.1039 k= 0.019805 lr = 0.0000077\n",
      "[15/25][4580/9765] Loss_D: 0.0898 Loss_G: 0.0376 Convergence: 0.0920 k= 0.019804 lr = 0.0000077\n",
      "[15/25][4590/9765] Loss_D: 0.0974 Loss_G: 0.0405 Convergence: 0.0993 k= 0.019804 lr = 0.0000077\n",
      "[15/25][4600/9765] Loss_D: 0.0934 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019807 lr = 0.0000077\n",
      "[15/25][4610/9765] Loss_D: 0.0943 Loss_G: 0.0400 Convergence: 0.0970 k= 0.019811 lr = 0.0000077\n",
      "[15/25][4620/9765] Loss_D: 0.0966 Loss_G: 0.0388 Convergence: 0.0976 k= 0.019800 lr = 0.0000077\n",
      "[15/25][4630/9765] Loss_D: 0.1069 Loss_G: 0.0391 Convergence: 0.1115 k= 0.019793 lr = 0.0000077\n",
      "[15/25][4640/9765] Loss_D: 0.0972 Loss_G: 0.0385 Convergence: 0.0986 k= 0.019797 lr = 0.0000077\n",
      "[15/25][4650/9765] Loss_D: 0.0990 Loss_G: 0.0392 Convergence: 0.1005 k= 0.019785 lr = 0.0000077\n",
      "[15/25][4660/9765] Loss_D: 0.0963 Loss_G: 0.0381 Convergence: 0.0978 k= 0.019778 lr = 0.0000077\n",
      "[15/25][4670/9765] Loss_D: 0.1148 Loss_G: 0.0378 Convergence: 0.1239 k= 0.019792 lr = 0.0000077\n",
      "[15/25][4680/9765] Loss_D: 0.0928 Loss_G: 0.0383 Convergence: 0.0945 k= 0.019796 lr = 0.0000077\n",
      "[15/25][4690/9765] Loss_D: 0.0947 Loss_G: 0.0389 Convergence: 0.0962 k= 0.019785 lr = 0.0000077\n",
      "[15/25][4700/9765] Loss_D: 0.0974 Loss_G: 0.0393 Convergence: 0.0982 k= 0.019788 lr = 0.0000077\n",
      "[15/25][4710/9765] Loss_D: 0.1081 Loss_G: 0.0375 Convergence: 0.1148 k= 0.019787 lr = 0.0000077\n",
      "[15/25][4720/9765] Loss_D: 0.0905 Loss_G: 0.0401 Convergence: 0.0949 k= 0.019783 lr = 0.0000077\n",
      "[15/25][4730/9765] Loss_D: 0.0976 Loss_G: 0.0376 Convergence: 0.1001 k= 0.019783 lr = 0.0000077\n",
      "[15/25][4740/9765] Loss_D: 0.0968 Loss_G: 0.0414 Convergence: 0.1000 k= 0.019770 lr = 0.0000077\n",
      "[15/25][4750/9765] Loss_D: 0.1058 Loss_G: 0.0395 Convergence: 0.1097 k= 0.019762 lr = 0.0000077\n",
      "[15/25][4760/9765] Loss_D: 0.1002 Loss_G: 0.0416 Convergence: 0.1022 k= 0.019740 lr = 0.0000077\n",
      "[15/25][4770/9765] Loss_D: 0.0977 Loss_G: 0.0378 Convergence: 0.1000 k= 0.019721 lr = 0.0000077\n",
      "[15/25][4780/9765] Loss_D: 0.1004 Loss_G: 0.0374 Convergence: 0.1042 k= 0.019714 lr = 0.0000077\n",
      "[15/25][4790/9765] Loss_D: 0.0955 Loss_G: 0.0406 Convergence: 0.0984 k= 0.019712 lr = 0.0000077\n",
      "[15/25][4800/9765] Loss_D: 0.0970 Loss_G: 0.0400 Convergence: 0.0987 k= 0.019703 lr = 0.0000077\n",
      "[15/25][4810/9765] Loss_D: 0.1062 Loss_G: 0.0389 Convergence: 0.1109 k= 0.019705 lr = 0.0000077\n",
      "[15/25][4820/9765] Loss_D: 0.0880 Loss_G: 0.0377 Convergence: 0.0909 k= 0.019715 lr = 0.0000077\n",
      "[15/25][4830/9765] Loss_D: 0.0923 Loss_G: 0.0378 Convergence: 0.0936 k= 0.019736 lr = 0.0000077\n",
      "[15/25][4840/9765] Loss_D: 0.1037 Loss_G: 0.0383 Convergence: 0.1079 k= 0.019762 lr = 0.0000077\n",
      "[15/25][4850/9765] Loss_D: 0.1064 Loss_G: 0.0415 Convergence: 0.1085 k= 0.019752 lr = 0.0000077\n",
      "[15/25][4860/9765] Loss_D: 0.0990 Loss_G: 0.0412 Convergence: 0.1011 k= 0.019728 lr = 0.0000077\n",
      "[15/25][4870/9765] Loss_D: 0.0938 Loss_G: 0.0407 Convergence: 0.0975 k= 0.019713 lr = 0.0000077\n",
      "[15/25][4880/9765] Loss_D: 0.0972 Loss_G: 0.0416 Convergence: 0.1004 k= 0.019689 lr = 0.0000077\n",
      "[15/25][4890/9765] Loss_D: 0.0996 Loss_G: 0.0401 Convergence: 0.1005 k= 0.019689 lr = 0.0000077\n",
      "[15/25][4900/9765] Loss_D: 0.1085 Loss_G: 0.0412 Convergence: 0.1118 k= 0.019682 lr = 0.0000077\n",
      "[15/25][4910/9765] Loss_D: 0.0973 Loss_G: 0.0367 Convergence: 0.1004 k= 0.019701 lr = 0.0000077\n",
      "[15/25][4920/9765] Loss_D: 0.0934 Loss_G: 0.0385 Convergence: 0.0950 k= 0.019719 lr = 0.0000077\n",
      "[15/25][4930/9765] Loss_D: 0.0988 Loss_G: 0.0400 Convergence: 0.0997 k= 0.019722 lr = 0.0000077\n",
      "[15/25][4940/9765] Loss_D: 0.0952 Loss_G: 0.0434 Convergence: 0.1011 k= 0.019698 lr = 0.0000077\n",
      "[15/25][4950/9765] Loss_D: 0.1009 Loss_G: 0.0486 Convergence: 0.1097 k= 0.019615 lr = 0.0000077\n",
      "[15/25][4960/9765] Loss_D: 0.0940 Loss_G: 0.0490 Convergence: 0.1060 k= 0.019513 lr = 0.0000077\n",
      "[15/25][4970/9765] Loss_D: 0.0991 Loss_G: 0.0445 Convergence: 0.1045 k= 0.019425 lr = 0.0000077\n",
      "[15/25][4980/9765] Loss_D: 0.0996 Loss_G: 0.0400 Convergence: 0.1005 k= 0.019405 lr = 0.0000077\n",
      "[15/25][4990/9765] Loss_D: 0.1063 Loss_G: 0.0389 Convergence: 0.1110 k= 0.019414 lr = 0.0000077\n",
      "[15/25][5000/9765] Loss_D: 0.1057 Loss_G: 0.0369 Convergence: 0.1122 k= 0.019435 lr = 0.0000077\n",
      "[15/25][5010/9765] Loss_D: 0.0901 Loss_G: 0.0369 Convergence: 0.0914 k= 0.019436 lr = 0.0000077\n",
      "[15/25][5020/9765] Loss_D: 0.0907 Loss_G: 0.0370 Convergence: 0.0919 k= 0.019453 lr = 0.0000077\n",
      "[15/25][5030/9765] Loss_D: 0.1018 Loss_G: 0.0383 Convergence: 0.1052 k= 0.019471 lr = 0.0000077\n",
      "[15/25][5040/9765] Loss_D: 0.1002 Loss_G: 0.0368 Convergence: 0.1045 k= 0.019472 lr = 0.0000077\n",
      "[15/25][5050/9765] Loss_D: 0.0907 Loss_G: 0.0393 Convergence: 0.0941 k= 0.019465 lr = 0.0000077\n",
      "[15/25][5060/9765] Loss_D: 0.0889 Loss_G: 0.0401 Convergence: 0.0939 k= 0.019447 lr = 0.0000077\n",
      "[15/25][5070/9765] Loss_D: 0.0954 Loss_G: 0.0391 Convergence: 0.0968 k= 0.019444 lr = 0.0000077\n",
      "[15/25][5080/9765] Loss_D: 0.0983 Loss_G: 0.0429 Convergence: 0.1023 k= 0.019434 lr = 0.0000077\n",
      "[15/25][5090/9765] Loss_D: 0.0995 Loss_G: 0.0382 Convergence: 0.1022 k= 0.019428 lr = 0.0000077\n",
      "[15/25][5100/9765] Loss_D: 0.0992 Loss_G: 0.0393 Convergence: 0.1007 k= 0.019431 lr = 0.0000077\n",
      "[15/25][5110/9765] Loss_D: 0.0969 Loss_G: 0.0388 Convergence: 0.0979 k= 0.019439 lr = 0.0000077\n",
      "[15/25][5120/9765] Loss_D: 0.0988 Loss_G: 0.0399 Convergence: 0.0996 k= 0.019443 lr = 0.0000077\n",
      "[15/25][5130/9765] Loss_D: 0.0925 Loss_G: 0.0387 Convergence: 0.0946 k= 0.019454 lr = 0.0000077\n",
      "[15/25][5140/9765] Loss_D: 0.0920 Loss_G: 0.0393 Convergence: 0.0949 k= 0.019464 lr = 0.0000077\n",
      "[15/25][5150/9765] Loss_D: 0.0956 Loss_G: 0.0373 Convergence: 0.0977 k= 0.019484 lr = 0.0000077\n",
      "[15/25][5160/9765] Loss_D: 0.1031 Loss_G: 0.0390 Convergence: 0.1064 k= 0.019496 lr = 0.0000077\n",
      "[15/25][5170/9765] Loss_D: 0.0906 Loss_G: 0.0399 Convergence: 0.0947 k= 0.019500 lr = 0.0000077\n",
      "[15/25][5180/9765] Loss_D: 0.0990 Loss_G: 0.0409 Convergence: 0.1008 k= 0.019485 lr = 0.0000077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][5190/9765] Loss_D: 0.0988 Loss_G: 0.0394 Convergence: 0.0999 k= 0.019469 lr = 0.0000077\n",
      "[15/25][5200/9765] Loss_D: 0.0993 Loss_G: 0.0402 Convergence: 0.1002 k= 0.019462 lr = 0.0000077\n",
      "[15/25][5210/9765] Loss_D: 0.0922 Loss_G: 0.0365 Convergence: 0.0937 k= 0.019469 lr = 0.0000077\n",
      "[15/25][5220/9765] Loss_D: 0.0991 Loss_G: 0.0379 Convergence: 0.1018 k= 0.019487 lr = 0.0000077\n",
      "[15/25][5230/9765] Loss_D: 0.0952 Loss_G: 0.0368 Convergence: 0.0975 k= 0.019507 lr = 0.0000077\n",
      "[15/25][5240/9765] Loss_D: 0.0986 Loss_G: 0.0387 Convergence: 0.1004 k= 0.019524 lr = 0.0000077\n",
      "[15/25][5250/9765] Loss_D: 0.1012 Loss_G: 0.0371 Convergence: 0.1055 k= 0.019541 lr = 0.0000077\n",
      "[15/25][5260/9765] Loss_D: 0.0964 Loss_G: 0.0405 Convergence: 0.0988 k= 0.019528 lr = 0.0000077\n",
      "[15/25][5270/9765] Loss_D: 0.0903 Loss_G: 0.0387 Convergence: 0.0933 k= 0.019521 lr = 0.0000077\n",
      "[15/25][5280/9765] Loss_D: 0.1011 Loss_G: 0.0399 Convergence: 0.1027 k= 0.019515 lr = 0.0000077\n",
      "[15/25][5290/9765] Loss_D: 0.0967 Loss_G: 0.0392 Convergence: 0.0977 k= 0.019501 lr = 0.0000077\n",
      "[15/25][5300/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0994 k= 0.019492 lr = 0.0000077\n",
      "[15/25][5310/9765] Loss_D: 0.0995 Loss_G: 0.0366 Convergence: 0.1037 k= 0.019506 lr = 0.0000077\n",
      "[15/25][5320/9765] Loss_D: 0.0926 Loss_G: 0.0355 Convergence: 0.0952 k= 0.019521 lr = 0.0000077\n",
      "[15/25][5330/9765] Loss_D: 0.0970 Loss_G: 0.0371 Convergence: 0.0997 k= 0.019520 lr = 0.0000077\n",
      "[15/25][5340/9765] Loss_D: 0.1002 Loss_G: 0.0404 Convergence: 0.1010 k= 0.019523 lr = 0.0000077\n",
      "[15/25][5350/9765] Loss_D: 0.0921 Loss_G: 0.0388 Convergence: 0.0945 k= 0.019501 lr = 0.0000077\n",
      "[15/25][5360/9765] Loss_D: 0.1007 Loss_G: 0.0398 Convergence: 0.1022 k= 0.019484 lr = 0.0000077\n",
      "[15/25][5370/9765] Loss_D: 0.0948 Loss_G: 0.0378 Convergence: 0.0960 k= 0.019482 lr = 0.0000077\n",
      "[15/25][5380/9765] Loss_D: 0.0931 Loss_G: 0.0392 Convergence: 0.0955 k= 0.019483 lr = 0.0000077\n",
      "[15/25][5390/9765] Loss_D: 0.0909 Loss_G: 0.0360 Convergence: 0.0923 k= 0.019489 lr = 0.0000077\n",
      "[15/25][5400/9765] Loss_D: 0.1015 Loss_G: 0.0389 Convergence: 0.1043 k= 0.019523 lr = 0.0000077\n",
      "[15/25][5410/9765] Loss_D: 0.1008 Loss_G: 0.0382 Convergence: 0.1039 k= 0.019520 lr = 0.0000077\n",
      "[15/25][5420/9765] Loss_D: 0.0951 Loss_G: 0.0377 Convergence: 0.0964 k= 0.019522 lr = 0.0000077\n",
      "[15/25][5430/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1005 k= 0.019527 lr = 0.0000077\n",
      "[15/25][5440/9765] Loss_D: 0.0979 Loss_G: 0.0397 Convergence: 0.0989 k= 0.019523 lr = 0.0000077\n",
      "[15/25][5450/9765] Loss_D: 0.1010 Loss_G: 0.0400 Convergence: 0.1024 k= 0.019507 lr = 0.0000077\n",
      "[15/25][5460/9765] Loss_D: 0.0939 Loss_G: 0.0406 Convergence: 0.0975 k= 0.019489 lr = 0.0000077\n",
      "[15/25][5470/9765] Loss_D: 0.0993 Loss_G: 0.0399 Convergence: 0.1002 k= 0.019478 lr = 0.0000077\n",
      "[15/25][5480/9765] Loss_D: 0.1012 Loss_G: 0.0387 Convergence: 0.1040 k= 0.019485 lr = 0.0000077\n",
      "[15/25][5490/9765] Loss_D: 0.0985 Loss_G: 0.0382 Convergence: 0.1007 k= 0.019490 lr = 0.0000077\n",
      "[15/25][5500/9765] Loss_D: 0.0960 Loss_G: 0.0379 Convergence: 0.0975 k= 0.019507 lr = 0.0000077\n",
      "[15/25][5510/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.019515 lr = 0.0000077\n",
      "[15/25][5520/9765] Loss_D: 0.0964 Loss_G: 0.0380 Convergence: 0.0981 k= 0.019516 lr = 0.0000077\n",
      "[15/25][5530/9765] Loss_D: 0.1167 Loss_G: 0.0395 Convergence: 0.1250 k= 0.019531 lr = 0.0000077\n",
      "[15/25][5540/9765] Loss_D: 0.0926 Loss_G: 0.0390 Convergence: 0.0950 k= 0.019522 lr = 0.0000077\n",
      "[15/25][5550/9765] Loss_D: 0.1111 Loss_G: 0.0409 Convergence: 0.1157 k= 0.019516 lr = 0.0000077\n",
      "[15/25][5560/9765] Loss_D: 0.0966 Loss_G: 0.0414 Convergence: 0.0999 k= 0.019504 lr = 0.0000077\n",
      "[15/25][5570/9765] Loss_D: 0.0957 Loss_G: 0.0396 Convergence: 0.0975 k= 0.019480 lr = 0.0000077\n",
      "[15/25][5580/9765] Loss_D: 0.1009 Loss_G: 0.0357 Convergence: 0.1065 k= 0.019489 lr = 0.0000077\n",
      "[15/25][5590/9765] Loss_D: 0.0969 Loss_G: 0.0374 Convergence: 0.0993 k= 0.019490 lr = 0.0000077\n",
      "[15/25][5600/9765] Loss_D: 0.1078 Loss_G: 0.0376 Convergence: 0.1144 k= 0.019495 lr = 0.0000077\n",
      "[15/25][5610/9765] Loss_D: 0.0983 Loss_G: 0.0395 Convergence: 0.0992 k= 0.019518 lr = 0.0000077\n",
      "[15/25][5620/9765] Loss_D: 0.0953 Loss_G: 0.0393 Convergence: 0.0969 k= 0.019515 lr = 0.0000077\n",
      "[15/25][5630/9765] Loss_D: 0.0954 Loss_G: 0.0381 Convergence: 0.0965 k= 0.019509 lr = 0.0000077\n",
      "[15/25][5640/9765] Loss_D: 0.0983 Loss_G: 0.0385 Convergence: 0.1001 k= 0.019514 lr = 0.0000077\n",
      "[15/25][5650/9765] Loss_D: 0.0864 Loss_G: 0.0383 Convergence: 0.0906 k= 0.019506 lr = 0.0000077\n",
      "[15/25][5660/9765] Loss_D: 0.0927 Loss_G: 0.0366 Convergence: 0.0941 k= 0.019510 lr = 0.0000077\n",
      "[15/25][5670/9765] Loss_D: 0.0969 Loss_G: 0.0387 Convergence: 0.0980 k= 0.019522 lr = 0.0000077\n",
      "[15/25][5680/9765] Loss_D: 0.1029 Loss_G: 0.0409 Convergence: 0.1043 k= 0.019521 lr = 0.0000077\n",
      "[15/25][5690/9765] Loss_D: 0.0874 Loss_G: 0.0384 Convergence: 0.0914 k= 0.019525 lr = 0.0000077\n",
      "[15/25][5700/9765] Loss_D: 0.0985 Loss_G: 0.0376 Convergence: 0.1014 k= 0.019534 lr = 0.0000077\n",
      "[15/25][5710/9765] Loss_D: 0.1111 Loss_G: 0.0378 Convergence: 0.1187 k= 0.019541 lr = 0.0000077\n",
      "[15/25][5720/9765] Loss_D: 0.0950 Loss_G: 0.0376 Convergence: 0.0964 k= 0.019536 lr = 0.0000077\n",
      "[15/25][5730/9765] Loss_D: 0.1073 Loss_G: 0.0397 Convergence: 0.1116 k= 0.019563 lr = 0.0000077\n",
      "[15/25][5740/9765] Loss_D: 0.0962 Loss_G: 0.0401 Convergence: 0.0983 k= 0.019540 lr = 0.0000077\n",
      "[15/25][5750/9765] Loss_D: 0.0969 Loss_G: 0.0371 Convergence: 0.0996 k= 0.019534 lr = 0.0000077\n",
      "[15/25][5760/9765] Loss_D: 0.0980 Loss_G: 0.0415 Convergence: 0.1008 k= 0.019530 lr = 0.0000077\n",
      "[15/25][5770/9765] Loss_D: 0.1064 Loss_G: 0.0383 Convergence: 0.1117 k= 0.019528 lr = 0.0000077\n",
      "[15/25][5780/9765] Loss_D: 0.0999 Loss_G: 0.0365 Convergence: 0.1043 k= 0.019545 lr = 0.0000077\n",
      "[15/25][5790/9765] Loss_D: 0.0939 Loss_G: 0.0397 Convergence: 0.0965 k= 0.019554 lr = 0.0000077\n",
      "[15/25][5800/9765] Loss_D: 0.0904 Loss_G: 0.0371 Convergence: 0.0918 k= 0.019545 lr = 0.0000077\n",
      "[15/25][5810/9765] Loss_D: 0.0947 Loss_G: 0.0407 Convergence: 0.0979 k= 0.019541 lr = 0.0000077\n",
      "[15/25][5820/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1008 k= 0.019548 lr = 0.0000077\n",
      "[15/25][5830/9765] Loss_D: 0.0948 Loss_G: 0.0389 Convergence: 0.0963 k= 0.019539 lr = 0.0000077\n",
      "[15/25][5840/9765] Loss_D: 0.1010 Loss_G: 0.0369 Convergence: 0.1055 k= 0.019556 lr = 0.0000077\n",
      "[15/25][5850/9765] Loss_D: 0.0865 Loss_G: 0.0365 Convergence: 0.0889 k= 0.019560 lr = 0.0000077\n",
      "[15/25][5860/9765] Loss_D: 0.0997 Loss_G: 0.0379 Convergence: 0.1027 k= 0.019576 lr = 0.0000077\n",
      "[15/25][5870/9765] Loss_D: 0.0988 Loss_G: 0.0384 Convergence: 0.1010 k= 0.019572 lr = 0.0000077\n",
      "[15/25][5880/9765] Loss_D: 0.0956 Loss_G: 0.0372 Convergence: 0.0977 k= 0.019572 lr = 0.0000077\n",
      "[15/25][5890/9765] Loss_D: 0.0953 Loss_G: 0.0390 Convergence: 0.0966 k= 0.019565 lr = 0.0000077\n",
      "[15/25][5900/9765] Loss_D: 0.1023 Loss_G: 0.0394 Convergence: 0.1049 k= 0.019583 lr = 0.0000077\n",
      "[15/25][5910/9765] Loss_D: 0.1000 Loss_G: 0.0391 Convergence: 0.1019 k= 0.019591 lr = 0.0000077\n",
      "[15/25][5920/9765] Loss_D: 0.0970 Loss_G: 0.0407 Convergence: 0.0994 k= 0.019579 lr = 0.0000077\n",
      "[15/25][5930/9765] Loss_D: 0.1007 Loss_G: 0.0409 Convergence: 0.1017 k= 0.019565 lr = 0.0000077\n",
      "[15/25][5940/9765] Loss_D: 0.0927 Loss_G: 0.0424 Convergence: 0.0985 k= 0.019544 lr = 0.0000077\n",
      "[15/25][5950/9765] Loss_D: 0.0900 Loss_G: 0.0381 Convergence: 0.0926 k= 0.019531 lr = 0.0000077\n",
      "[15/25][5960/9765] Loss_D: 0.0986 Loss_G: 0.0393 Convergence: 0.0998 k= 0.019533 lr = 0.0000077\n",
      "[15/25][5970/9765] Loss_D: 0.0941 Loss_G: 0.0405 Convergence: 0.0974 k= 0.019540 lr = 0.0000077\n",
      "[15/25][5980/9765] Loss_D: 0.0978 Loss_G: 0.0396 Convergence: 0.0987 k= 0.019524 lr = 0.0000077\n",
      "[15/25][5990/9765] Loss_D: 0.1027 Loss_G: 0.0392 Convergence: 0.1056 k= 0.019525 lr = 0.0000077\n",
      "[15/25][6000/9765] Loss_D: 0.0994 Loss_G: 0.0387 Convergence: 0.1015 k= 0.019530 lr = 0.0000077\n",
      "[15/25][6010/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0974 k= 0.019539 lr = 0.0000077\n",
      "[15/25][6020/9765] Loss_D: 0.0927 Loss_G: 0.0383 Convergence: 0.0943 k= 0.019549 lr = 0.0000077\n",
      "[15/25][6030/9765] Loss_D: 0.0932 Loss_G: 0.0391 Convergence: 0.0954 k= 0.019546 lr = 0.0000077\n",
      "[15/25][6040/9765] Loss_D: 0.0988 Loss_G: 0.0392 Convergence: 0.1001 k= 0.019546 lr = 0.0000077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][6050/9765] Loss_D: 0.1007 Loss_G: 0.0389 Convergence: 0.1031 k= 0.019548 lr = 0.0000077\n",
      "[15/25][6060/9765] Loss_D: 0.1000 Loss_G: 0.0399 Convergence: 0.1011 k= 0.019554 lr = 0.0000077\n",
      "[15/25][6070/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0994 k= 0.019550 lr = 0.0000077\n",
      "[15/25][6080/9765] Loss_D: 0.0945 Loss_G: 0.0397 Convergence: 0.0969 k= 0.019545 lr = 0.0000077\n",
      "[15/25][6090/9765] Loss_D: 0.0959 Loss_G: 0.0408 Convergence: 0.0988 k= 0.019531 lr = 0.0000077\n",
      "[15/25][6100/9765] Loss_D: 0.0982 Loss_G: 0.0376 Convergence: 0.1009 k= 0.019531 lr = 0.0000077\n",
      "[15/25][6110/9765] Loss_D: 0.0997 Loss_G: 0.0374 Convergence: 0.1032 k= 0.019536 lr = 0.0000077\n",
      "[15/25][6120/9765] Loss_D: 0.0976 Loss_G: 0.0360 Convergence: 0.1016 k= 0.019560 lr = 0.0000077\n",
      "[15/25][6130/9765] Loss_D: 0.0994 Loss_G: 0.0373 Convergence: 0.1029 k= 0.019572 lr = 0.0000077\n",
      "[15/25][6140/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0923 k= 0.019584 lr = 0.0000077\n",
      "[15/25][6150/9765] Loss_D: 0.1052 Loss_G: 0.0391 Convergence: 0.1093 k= 0.019599 lr = 0.0000077\n",
      "[15/25][6160/9765] Loss_D: 0.0932 Loss_G: 0.0385 Convergence: 0.0949 k= 0.019585 lr = 0.0000077\n",
      "[15/25][6170/9765] Loss_D: 0.1067 Loss_G: 0.0392 Convergence: 0.1112 k= 0.019575 lr = 0.0000077\n",
      "[15/25][6180/9765] Loss_D: 0.0984 Loss_G: 0.0385 Convergence: 0.1003 k= 0.019585 lr = 0.0000077\n",
      "[15/25][6190/9765] Loss_D: 0.1053 Loss_G: 0.0391 Convergence: 0.1094 k= 0.019594 lr = 0.0000077\n",
      "[15/25][6200/9765] Loss_D: 0.0956 Loss_G: 0.0358 Convergence: 0.0991 k= 0.019622 lr = 0.0000077\n",
      "[15/25][6210/9765] Loss_D: 0.0874 Loss_G: 0.0397 Convergence: 0.0926 k= 0.019630 lr = 0.0000077\n",
      "[15/25][6220/9765] Loss_D: 0.1033 Loss_G: 0.0386 Convergence: 0.1070 k= 0.019633 lr = 0.0000077\n",
      "[15/25][6230/9765] Loss_D: 0.1048 Loss_G: 0.0402 Convergence: 0.1075 k= 0.019635 lr = 0.0000077\n",
      "[15/25][6240/9765] Loss_D: 0.0888 Loss_G: 0.0389 Convergence: 0.0926 k= 0.019633 lr = 0.0000077\n",
      "[15/25][6250/9765] Loss_D: 0.0901 Loss_G: 0.0409 Convergence: 0.0955 k= 0.019621 lr = 0.0000077\n",
      "[15/25][6260/9765] Loss_D: 0.0924 Loss_G: 0.0413 Convergence: 0.0972 k= 0.019606 lr = 0.0000077\n",
      "[15/25][6270/9765] Loss_D: 0.1025 Loss_G: 0.0384 Convergence: 0.1061 k= 0.019597 lr = 0.0000077\n",
      "[15/25][6280/9765] Loss_D: 0.0995 Loss_G: 0.0399 Convergence: 0.1005 k= 0.019584 lr = 0.0000077\n",
      "[15/25][6290/9765] Loss_D: 0.0909 Loss_G: 0.0392 Convergence: 0.0942 k= 0.019584 lr = 0.0000077\n",
      "[15/25][6300/9765] Loss_D: 0.0993 Loss_G: 0.0374 Convergence: 0.1027 k= 0.019591 lr = 0.0000077\n",
      "[15/25][6310/9765] Loss_D: 0.0985 Loss_G: 0.0397 Convergence: 0.0993 k= 0.019603 lr = 0.0000077\n",
      "[15/25][6320/9765] Loss_D: 0.1049 Loss_G: 0.0387 Convergence: 0.1092 k= 0.019604 lr = 0.0000077\n",
      "[15/25][6330/9765] Loss_D: 0.0929 Loss_G: 0.0399 Convergence: 0.0961 k= 0.019608 lr = 0.0000077\n",
      "[15/25][6340/9765] Loss_D: 0.0985 Loss_G: 0.0381 Convergence: 0.1009 k= 0.019613 lr = 0.0000077\n",
      "[15/25][6350/9765] Loss_D: 0.0934 Loss_G: 0.0394 Convergence: 0.0959 k= 0.019607 lr = 0.0000077\n",
      "[15/25][6360/9765] Loss_D: 0.0942 Loss_G: 0.0402 Convergence: 0.0972 k= 0.019605 lr = 0.0000077\n",
      "[15/25][6370/9765] Loss_D: 0.0919 Loss_G: 0.0394 Convergence: 0.0951 k= 0.019609 lr = 0.0000077\n",
      "[15/25][6380/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0955 k= 0.019597 lr = 0.0000077\n",
      "[15/25][6390/9765] Loss_D: 0.0988 Loss_G: 0.0405 Convergence: 0.1002 k= 0.019594 lr = 0.0000077\n",
      "[15/25][6400/9765] Loss_D: 0.0965 Loss_G: 0.0393 Convergence: 0.0977 k= 0.019590 lr = 0.0000077\n",
      "[15/25][6410/9765] Loss_D: 0.0899 Loss_G: 0.0389 Convergence: 0.0933 k= 0.019604 lr = 0.0000077\n",
      "[15/25][6420/9765] Loss_D: 0.0935 Loss_G: 0.0390 Convergence: 0.0956 k= 0.019619 lr = 0.0000077\n",
      "[15/25][6430/9765] Loss_D: 0.0909 Loss_G: 0.0380 Convergence: 0.0930 k= 0.019635 lr = 0.0000077\n",
      "[15/25][6440/9765] Loss_D: 0.0849 Loss_G: 0.0385 Convergence: 0.0898 k= 0.019632 lr = 0.0000077\n",
      "[15/25][6450/9765] Loss_D: 0.0978 Loss_G: 0.0419 Convergence: 0.1011 k= 0.019639 lr = 0.0000077\n",
      "[15/25][6460/9765] Loss_D: 0.0846 Loss_G: 0.0374 Convergence: 0.0887 k= 0.019618 lr = 0.0000077\n",
      "[15/25][6470/9765] Loss_D: 0.0934 Loss_G: 0.0380 Convergence: 0.0945 k= 0.019624 lr = 0.0000077\n",
      "[15/25][6480/9765] Loss_D: 0.1001 Loss_G: 0.0405 Convergence: 0.1010 k= 0.019625 lr = 0.0000077\n",
      "[15/25][6490/9765] Loss_D: 0.0892 Loss_G: 0.0373 Convergence: 0.0913 k= 0.019623 lr = 0.0000077\n",
      "[15/25][6500/9765] Loss_D: 0.0995 Loss_G: 0.0392 Convergence: 0.1012 k= 0.019624 lr = 0.0000077\n",
      "[15/25][6510/9765] Loss_D: 0.0968 Loss_G: 0.0380 Convergence: 0.0986 k= 0.019634 lr = 0.0000077\n",
      "[15/25][6520/9765] Loss_D: 0.1031 Loss_G: 0.0376 Convergence: 0.1077 k= 0.019643 lr = 0.0000077\n",
      "[15/25][6530/9765] Loss_D: 0.0896 Loss_G: 0.0381 Convergence: 0.0923 k= 0.019645 lr = 0.0000073\n",
      "[15/25][6540/9765] Loss_D: 0.0934 Loss_G: 0.0385 Convergence: 0.0950 k= 0.019642 lr = 0.0000073\n",
      "[15/25][6550/9765] Loss_D: 0.0898 Loss_G: 0.0380 Convergence: 0.0923 k= 0.019648 lr = 0.0000073\n",
      "[15/25][6560/9765] Loss_D: 0.0936 Loss_G: 0.0391 Convergence: 0.0957 k= 0.019650 lr = 0.0000073\n",
      "[15/25][6570/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.019662 lr = 0.0000073\n",
      "[15/25][6580/9765] Loss_D: 0.1059 Loss_G: 0.0396 Convergence: 0.1097 k= 0.019691 lr = 0.0000073\n",
      "[15/25][6590/9765] Loss_D: 0.0975 Loss_G: 0.0386 Convergence: 0.0989 k= 0.019684 lr = 0.0000073\n",
      "[15/25][6600/9765] Loss_D: 0.0904 Loss_G: 0.0382 Convergence: 0.0929 k= 0.019691 lr = 0.0000073\n",
      "[15/25][6610/9765] Loss_D: 0.0919 Loss_G: 0.0389 Convergence: 0.0946 k= 0.019686 lr = 0.0000073\n",
      "[15/25][6620/9765] Loss_D: 0.1029 Loss_G: 0.0402 Convergence: 0.1050 k= 0.019697 lr = 0.0000073\n",
      "[15/25][6630/9765] Loss_D: 0.0979 Loss_G: 0.0399 Convergence: 0.0991 k= 0.019683 lr = 0.0000073\n",
      "[15/25][6640/9765] Loss_D: 0.0974 Loss_G: 0.0397 Convergence: 0.0986 k= 0.019680 lr = 0.0000073\n",
      "[15/25][6650/9765] Loss_D: 0.1010 Loss_G: 0.0404 Convergence: 0.1021 k= 0.019681 lr = 0.0000073\n",
      "[15/25][6660/9765] Loss_D: 0.1038 Loss_G: 0.0397 Convergence: 0.1067 k= 0.019670 lr = 0.0000073\n",
      "[15/25][6670/9765] Loss_D: 0.0913 Loss_G: 0.0383 Convergence: 0.0936 k= 0.019660 lr = 0.0000073\n",
      "[15/25][6680/9765] Loss_D: 0.1016 Loss_G: 0.0409 Convergence: 0.1025 k= 0.019661 lr = 0.0000073\n",
      "[15/25][6690/9765] Loss_D: 0.0941 Loss_G: 0.0405 Convergence: 0.0974 k= 0.019654 lr = 0.0000073\n",
      "[15/25][6700/9765] Loss_D: 0.1026 Loss_G: 0.0393 Convergence: 0.1054 k= 0.019657 lr = 0.0000073\n",
      "[15/25][6710/9765] Loss_D: 0.1058 Loss_G: 0.0402 Convergence: 0.1090 k= 0.019669 lr = 0.0000073\n",
      "[15/25][6720/9765] Loss_D: 0.0992 Loss_G: 0.0386 Convergence: 0.1013 k= 0.019664 lr = 0.0000073\n",
      "[15/25][6730/9765] Loss_D: 0.1020 Loss_G: 0.0391 Convergence: 0.1048 k= 0.019662 lr = 0.0000073\n",
      "[15/25][6740/9765] Loss_D: 0.0956 Loss_G: 0.0386 Convergence: 0.0965 k= 0.019658 lr = 0.0000073\n",
      "[15/25][6750/9765] Loss_D: 0.0892 Loss_G: 0.0384 Convergence: 0.0924 k= 0.019667 lr = 0.0000073\n",
      "[15/25][6760/9765] Loss_D: 0.1178 Loss_G: 0.0373 Convergence: 0.1286 k= 0.019688 lr = 0.0000073\n",
      "[15/25][6770/9765] Loss_D: 0.1031 Loss_G: 0.0355 Convergence: 0.1099 k= 0.019712 lr = 0.0000073\n",
      "[15/25][6780/9765] Loss_D: 0.0969 Loss_G: 0.0361 Convergence: 0.1006 k= 0.019748 lr = 0.0000073\n",
      "[15/25][6790/9765] Loss_D: 0.0949 Loss_G: 0.0386 Convergence: 0.0959 k= 0.019762 lr = 0.0000073\n",
      "[15/25][6800/9765] Loss_D: 0.0938 Loss_G: 0.0394 Convergence: 0.0962 k= 0.019753 lr = 0.0000073\n",
      "[15/25][6810/9765] Loss_D: 0.1035 Loss_G: 0.0406 Convergence: 0.1053 k= 0.019758 lr = 0.0000073\n",
      "[15/25][6820/9765] Loss_D: 0.0989 Loss_G: 0.0397 Convergence: 0.0999 k= 0.019733 lr = 0.0000073\n",
      "[15/25][6830/9765] Loss_D: 0.1011 Loss_G: 0.0390 Convergence: 0.1036 k= 0.019731 lr = 0.0000073\n",
      "[15/25][6840/9765] Loss_D: 0.0934 Loss_G: 0.0393 Convergence: 0.0958 k= 0.019719 lr = 0.0000073\n",
      "[15/25][6850/9765] Loss_D: 0.1053 Loss_G: 0.0396 Convergence: 0.1089 k= 0.019714 lr = 0.0000073\n",
      "[15/25][6860/9765] Loss_D: 0.0994 Loss_G: 0.0393 Convergence: 0.1009 k= 0.019707 lr = 0.0000073\n",
      "[15/25][6870/9765] Loss_D: 0.0960 Loss_G: 0.0391 Convergence: 0.0971 k= 0.019711 lr = 0.0000073\n",
      "[15/25][6880/9765] Loss_D: 0.0993 Loss_G: 0.0409 Convergence: 0.1010 k= 0.019702 lr = 0.0000073\n",
      "[15/25][6890/9765] Loss_D: 0.1015 Loss_G: 0.0405 Convergence: 0.1028 k= 0.019680 lr = 0.0000073\n",
      "[15/25][6900/9765] Loss_D: 0.0901 Loss_G: 0.0371 Convergence: 0.0916 k= 0.019687 lr = 0.0000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][6910/9765] Loss_D: 0.1093 Loss_G: 0.0394 Convergence: 0.1147 k= 0.019711 lr = 0.0000073\n",
      "[15/25][6920/9765] Loss_D: 0.1014 Loss_G: 0.0378 Convergence: 0.1052 k= 0.019715 lr = 0.0000073\n",
      "[15/25][6930/9765] Loss_D: 0.1013 Loss_G: 0.0392 Convergence: 0.1037 k= 0.019723 lr = 0.0000073\n",
      "[15/25][6940/9765] Loss_D: 0.0978 Loss_G: 0.0392 Convergence: 0.0988 k= 0.019719 lr = 0.0000073\n",
      "[15/25][6950/9765] Loss_D: 0.0999 Loss_G: 0.0391 Convergence: 0.1018 k= 0.019724 lr = 0.0000073\n",
      "[15/25][6960/9765] Loss_D: 0.0983 Loss_G: 0.0383 Convergence: 0.1003 k= 0.019732 lr = 0.0000073\n",
      "[15/25][6970/9765] Loss_D: 0.0875 Loss_G: 0.0376 Convergence: 0.0906 k= 0.019736 lr = 0.0000073\n",
      "[15/25][6980/9765] Loss_D: 0.0956 Loss_G: 0.0386 Convergence: 0.0965 k= 0.019753 lr = 0.0000073\n",
      "[15/25][6990/9765] Loss_D: 0.0904 Loss_G: 0.0365 Convergence: 0.0912 k= 0.019754 lr = 0.0000073\n",
      "[15/25][7000/9765] Loss_D: 0.0989 Loss_G: 0.0373 Convergence: 0.1021 k= 0.019762 lr = 0.0000073\n",
      "[15/25][7010/9765] Loss_D: 0.0949 Loss_G: 0.0402 Convergence: 0.0977 k= 0.019773 lr = 0.0000073\n",
      "[15/25][7020/9765] Loss_D: 0.0927 Loss_G: 0.0367 Convergence: 0.0941 k= 0.019771 lr = 0.0000073\n",
      "[15/25][7030/9765] Loss_D: 0.1026 Loss_G: 0.0374 Convergence: 0.1073 k= 0.019782 lr = 0.0000073\n",
      "[15/25][7040/9765] Loss_D: 0.1037 Loss_G: 0.0355 Convergence: 0.1106 k= 0.019795 lr = 0.0000073\n",
      "[15/25][7050/9765] Loss_D: 0.0978 Loss_G: 0.0384 Convergence: 0.0997 k= 0.019805 lr = 0.0000073\n",
      "[15/25][7060/9765] Loss_D: 0.0873 Loss_G: 0.0409 Convergence: 0.0938 k= 0.019796 lr = 0.0000073\n",
      "[15/25][7070/9765] Loss_D: 0.0966 Loss_G: 0.0387 Convergence: 0.0977 k= 0.019795 lr = 0.0000073\n",
      "[15/25][7080/9765] Loss_D: 0.1019 Loss_G: 0.0384 Convergence: 0.1053 k= 0.019792 lr = 0.0000073\n",
      "[15/25][7090/9765] Loss_D: 0.0912 Loss_G: 0.0381 Convergence: 0.0933 k= 0.019800 lr = 0.0000073\n",
      "[15/25][7100/9765] Loss_D: 0.0918 Loss_G: 0.0392 Convergence: 0.0948 k= 0.019792 lr = 0.0000073\n",
      "[15/25][7110/9765] Loss_D: 0.1008 Loss_G: 0.0401 Convergence: 0.1021 k= 0.019787 lr = 0.0000073\n",
      "[15/25][7120/9765] Loss_D: 0.1035 Loss_G: 0.0425 Convergence: 0.1051 k= 0.019766 lr = 0.0000073\n",
      "[15/25][7130/9765] Loss_D: 0.1078 Loss_G: 0.0401 Convergence: 0.1118 k= 0.019751 lr = 0.0000073\n",
      "[15/25][7140/9765] Loss_D: 0.0919 Loss_G: 0.0394 Convergence: 0.0950 k= 0.019747 lr = 0.0000073\n",
      "[15/25][7150/9765] Loss_D: 0.0956 Loss_G: 0.0376 Convergence: 0.0973 k= 0.019753 lr = 0.0000073\n",
      "[15/25][7160/9765] Loss_D: 0.0949 Loss_G: 0.0366 Convergence: 0.0972 k= 0.019751 lr = 0.0000073\n",
      "[15/25][7170/9765] Loss_D: 0.0943 Loss_G: 0.0381 Convergence: 0.0952 k= 0.019764 lr = 0.0000073\n",
      "[15/25][7180/9765] Loss_D: 0.0980 Loss_G: 0.0380 Convergence: 0.1002 k= 0.019792 lr = 0.0000073\n",
      "[15/25][7190/9765] Loss_D: 0.0893 Loss_G: 0.0398 Convergence: 0.0938 k= 0.019793 lr = 0.0000073\n",
      "[15/25][7200/9765] Loss_D: 0.0914 Loss_G: 0.0411 Convergence: 0.0964 k= 0.019783 lr = 0.0000073\n",
      "[15/25][7210/9765] Loss_D: 0.0908 Loss_G: 0.0413 Convergence: 0.0963 k= 0.019774 lr = 0.0000073\n",
      "[15/25][7220/9765] Loss_D: 0.1040 Loss_G: 0.0398 Convergence: 0.1069 k= 0.019779 lr = 0.0000073\n",
      "[15/25][7230/9765] Loss_D: 0.0958 Loss_G: 0.0404 Convergence: 0.0984 k= 0.019779 lr = 0.0000073\n",
      "[15/25][7240/9765] Loss_D: 0.1023 Loss_G: 0.0413 Convergence: 0.1032 k= 0.019766 lr = 0.0000073\n",
      "[15/25][7250/9765] Loss_D: 0.0954 Loss_G: 0.0411 Convergence: 0.0988 k= 0.019743 lr = 0.0000073\n",
      "[15/25][7260/9765] Loss_D: 0.1084 Loss_G: 0.0399 Convergence: 0.1129 k= 0.019739 lr = 0.0000073\n",
      "[15/25][7270/9765] Loss_D: 0.0901 Loss_G: 0.0402 Convergence: 0.0947 k= 0.019732 lr = 0.0000073\n",
      "[15/25][7280/9765] Loss_D: 0.1030 Loss_G: 0.0404 Convergence: 0.1049 k= 0.019738 lr = 0.0000073\n",
      "[15/25][7290/9765] Loss_D: 0.0944 Loss_G: 0.0368 Convergence: 0.0964 k= 0.019746 lr = 0.0000073\n",
      "[15/25][7300/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0984 k= 0.019760 lr = 0.0000073\n",
      "[15/25][7310/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0996 k= 0.019756 lr = 0.0000073\n",
      "[15/25][7320/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0998 k= 0.019752 lr = 0.0000073\n",
      "[15/25][7330/9765] Loss_D: 0.0876 Loss_G: 0.0396 Convergence: 0.0926 k= 0.019741 lr = 0.0000073\n",
      "[15/25][7340/9765] Loss_D: 0.1029 Loss_G: 0.0403 Convergence: 0.1049 k= 0.019740 lr = 0.0000073\n",
      "[15/25][7350/9765] Loss_D: 0.0901 Loss_G: 0.0402 Convergence: 0.0947 k= 0.019727 lr = 0.0000073\n",
      "[15/25][7360/9765] Loss_D: 0.0903 Loss_G: 0.0380 Convergence: 0.0926 k= 0.019715 lr = 0.0000073\n",
      "[15/25][7370/9765] Loss_D: 0.0901 Loss_G: 0.0351 Convergence: 0.0920 k= 0.019736 lr = 0.0000073\n",
      "[15/25][7380/9765] Loss_D: 0.0934 Loss_G: 0.0364 Convergence: 0.0954 k= 0.019755 lr = 0.0000073\n",
      "[15/25][7390/9765] Loss_D: 0.1068 Loss_G: 0.0369 Convergence: 0.1136 k= 0.019758 lr = 0.0000073\n",
      "[15/25][7400/9765] Loss_D: 0.0916 Loss_G: 0.0390 Convergence: 0.0944 k= 0.019755 lr = 0.0000073\n",
      "[15/25][7410/9765] Loss_D: 0.0828 Loss_G: 0.0393 Convergence: 0.0894 k= 0.019741 lr = 0.0000073\n",
      "[15/25][7420/9765] Loss_D: 0.0970 Loss_G: 0.0386 Convergence: 0.0982 k= 0.019740 lr = 0.0000073\n",
      "[15/25][7430/9765] Loss_D: 0.1007 Loss_G: 0.0399 Convergence: 0.1022 k= 0.019726 lr = 0.0000073\n",
      "[15/25][7440/9765] Loss_D: 0.0947 Loss_G: 0.0364 Convergence: 0.0973 k= 0.019725 lr = 0.0000073\n",
      "[15/25][7450/9765] Loss_D: 0.0917 Loss_G: 0.0365 Convergence: 0.0928 k= 0.019735 lr = 0.0000073\n",
      "[15/25][7460/9765] Loss_D: 0.1064 Loss_G: 0.0351 Convergence: 0.1148 k= 0.019765 lr = 0.0000073\n",
      "[15/25][7470/9765] Loss_D: 0.0886 Loss_G: 0.0386 Convergence: 0.0922 k= 0.019782 lr = 0.0000073\n",
      "[15/25][7480/9765] Loss_D: 0.0939 Loss_G: 0.0382 Convergence: 0.0950 k= 0.019792 lr = 0.0000073\n",
      "[15/25][7490/9765] Loss_D: 0.0978 Loss_G: 0.0381 Convergence: 0.1000 k= 0.019794 lr = 0.0000073\n",
      "[15/25][7500/9765] Loss_D: 0.0944 Loss_G: 0.0390 Convergence: 0.0961 k= 0.019807 lr = 0.0000073\n",
      "[15/25][7510/9765] Loss_D: 0.1072 Loss_G: 0.0406 Convergence: 0.1106 k= 0.019822 lr = 0.0000073\n",
      "[15/25][7520/9765] Loss_D: 0.1076 Loss_G: 0.0414 Convergence: 0.1104 k= 0.019816 lr = 0.0000073\n",
      "[15/25][7530/9765] Loss_D: 0.0988 Loss_G: 0.0378 Convergence: 0.1017 k= 0.019808 lr = 0.0000073\n",
      "[15/25][7540/9765] Loss_D: 0.0961 Loss_G: 0.0404 Convergence: 0.0985 k= 0.019788 lr = 0.0000073\n",
      "[15/25][7550/9765] Loss_D: 0.1065 Loss_G: 0.0406 Convergence: 0.1097 k= 0.019776 lr = 0.0000073\n",
      "[15/25][7560/9765] Loss_D: 0.0985 Loss_G: 0.0417 Convergence: 0.1013 k= 0.019766 lr = 0.0000073\n",
      "[15/25][7570/9765] Loss_D: 0.1016 Loss_G: 0.0359 Convergence: 0.1074 k= 0.019764 lr = 0.0000073\n",
      "[15/25][7580/9765] Loss_D: 0.0947 Loss_G: 0.0368 Convergence: 0.0968 k= 0.019775 lr = 0.0000073\n",
      "[15/25][7590/9765] Loss_D: 0.1033 Loss_G: 0.0361 Convergence: 0.1096 k= 0.019814 lr = 0.0000073\n",
      "[15/25][7600/9765] Loss_D: 0.0851 Loss_G: 0.0375 Convergence: 0.0890 k= 0.019838 lr = 0.0000073\n",
      "[15/25][7610/9765] Loss_D: 0.0958 Loss_G: 0.0387 Convergence: 0.0967 k= 0.019846 lr = 0.0000073\n",
      "[15/25][7620/9765] Loss_D: 0.1081 Loss_G: 0.0419 Convergence: 0.1106 k= 0.019836 lr = 0.0000073\n",
      "[15/25][7630/9765] Loss_D: 0.0870 Loss_G: 0.0390 Convergence: 0.0917 k= 0.019821 lr = 0.0000073\n",
      "[15/25][7640/9765] Loss_D: 0.0941 Loss_G: 0.0376 Convergence: 0.0952 k= 0.019814 lr = 0.0000073\n",
      "[15/25][7650/9765] Loss_D: 0.1097 Loss_G: 0.0399 Convergence: 0.1148 k= 0.019823 lr = 0.0000073\n",
      "[15/25][7660/9765] Loss_D: 0.0947 Loss_G: 0.0388 Convergence: 0.0961 k= 0.019818 lr = 0.0000073\n",
      "[15/25][7670/9765] Loss_D: 0.0947 Loss_G: 0.0379 Convergence: 0.0957 k= 0.019814 lr = 0.0000073\n",
      "[15/25][7680/9765] Loss_D: 0.0976 Loss_G: 0.0388 Convergence: 0.0990 k= 0.019820 lr = 0.0000073\n",
      "[15/25][7690/9765] Loss_D: 0.1135 Loss_G: 0.0374 Convergence: 0.1225 k= 0.019832 lr = 0.0000073\n",
      "[15/25][7700/9765] Loss_D: 0.0877 Loss_G: 0.0391 Convergence: 0.0922 k= 0.019830 lr = 0.0000073\n",
      "[15/25][7710/9765] Loss_D: 0.1011 Loss_G: 0.0399 Convergence: 0.1027 k= 0.019842 lr = 0.0000073\n",
      "[15/25][7720/9765] Loss_D: 0.0990 Loss_G: 0.0397 Convergence: 0.1001 k= 0.019822 lr = 0.0000073\n",
      "[15/25][7730/9765] Loss_D: 0.0906 Loss_G: 0.0402 Convergence: 0.0950 k= 0.019819 lr = 0.0000073\n",
      "[15/25][7740/9765] Loss_D: 0.0999 Loss_G: 0.0393 Convergence: 0.1016 k= 0.019805 lr = 0.0000073\n",
      "[15/25][7750/9765] Loss_D: 0.0991 Loss_G: 0.0369 Convergence: 0.1028 k= 0.019806 lr = 0.0000073\n",
      "[15/25][7760/9765] Loss_D: 0.1041 Loss_G: 0.0408 Convergence: 0.1060 k= 0.019807 lr = 0.0000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][7770/9765] Loss_D: 0.0953 Loss_G: 0.0397 Convergence: 0.0973 k= 0.019791 lr = 0.0000073\n",
      "[15/25][7780/9765] Loss_D: 0.0931 Loss_G: 0.0383 Convergence: 0.0946 k= 0.019797 lr = 0.0000073\n",
      "[15/25][7790/9765] Loss_D: 0.0980 Loss_G: 0.0411 Convergence: 0.1004 k= 0.019795 lr = 0.0000073\n",
      "[15/25][7800/9765] Loss_D: 0.0884 Loss_G: 0.0388 Convergence: 0.0923 k= 0.019777 lr = 0.0000073\n",
      "[15/25][7810/9765] Loss_D: 0.0970 Loss_G: 0.0403 Convergence: 0.0989 k= 0.019790 lr = 0.0000073\n",
      "[15/25][7820/9765] Loss_D: 0.0945 Loss_G: 0.0400 Convergence: 0.0972 k= 0.019767 lr = 0.0000073\n",
      "[15/25][7830/9765] Loss_D: 0.1062 Loss_G: 0.0400 Convergence: 0.1097 k= 0.019760 lr = 0.0000073\n",
      "[15/25][7840/9765] Loss_D: 0.0925 Loss_G: 0.0380 Convergence: 0.0940 k= 0.019747 lr = 0.0000073\n",
      "[15/25][7850/9765] Loss_D: 0.0949 Loss_G: 0.0396 Convergence: 0.0970 k= 0.019746 lr = 0.0000073\n",
      "[15/25][7860/9765] Loss_D: 0.1052 Loss_G: 0.0380 Convergence: 0.1104 k= 0.019759 lr = 0.0000073\n",
      "[15/25][7870/9765] Loss_D: 0.0998 Loss_G: 0.0394 Convergence: 0.1014 k= 0.019762 lr = 0.0000073\n",
      "[15/25][7880/9765] Loss_D: 0.0996 Loss_G: 0.0378 Convergence: 0.1027 k= 0.019771 lr = 0.0000073\n",
      "[15/25][7890/9765] Loss_D: 0.0997 Loss_G: 0.0401 Convergence: 0.1006 k= 0.019781 lr = 0.0000073\n",
      "[15/25][7900/9765] Loss_D: 0.0963 Loss_G: 0.0399 Convergence: 0.0981 k= 0.019780 lr = 0.0000073\n",
      "[15/25][7910/9765] Loss_D: 0.1062 Loss_G: 0.0399 Convergence: 0.1098 k= 0.019782 lr = 0.0000073\n",
      "[15/25][7920/9765] Loss_D: 0.0930 Loss_G: 0.0385 Convergence: 0.0947 k= 0.019784 lr = 0.0000073\n",
      "[15/25][7930/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0972 k= 0.019798 lr = 0.0000073\n",
      "[15/25][7940/9765] Loss_D: 0.0929 Loss_G: 0.0384 Convergence: 0.0946 k= 0.019809 lr = 0.0000073\n",
      "[15/25][7950/9765] Loss_D: 0.0997 Loss_G: 0.0381 Convergence: 0.1025 k= 0.019809 lr = 0.0000073\n",
      "[15/25][7960/9765] Loss_D: 0.0989 Loss_G: 0.0384 Convergence: 0.1012 k= 0.019823 lr = 0.0000073\n",
      "[15/25][7970/9765] Loss_D: 0.0965 Loss_G: 0.0383 Convergence: 0.0978 k= 0.019819 lr = 0.0000073\n",
      "[15/25][7980/9765] Loss_D: 0.0973 Loss_G: 0.0378 Convergence: 0.0994 k= 0.019813 lr = 0.0000073\n",
      "[15/25][7990/9765] Loss_D: 0.0985 Loss_G: 0.0359 Convergence: 0.1030 k= 0.019842 lr = 0.0000073\n",
      "[15/25][8000/9765] Loss_D: 0.0902 Loss_G: 0.0386 Convergence: 0.0932 k= 0.019852 lr = 0.0000073\n",
      "[15/25][8010/9765] Loss_D: 0.0936 Loss_G: 0.0390 Convergence: 0.0956 k= 0.019842 lr = 0.0000073\n",
      "[15/25][8020/9765] Loss_D: 0.0950 Loss_G: 0.0384 Convergence: 0.0958 k= 0.019847 lr = 0.0000073\n",
      "[15/25][8030/9765] Loss_D: 0.0920 Loss_G: 0.0384 Convergence: 0.0941 k= 0.019846 lr = 0.0000073\n",
      "[15/25][8040/9765] Loss_D: 0.0955 Loss_G: 0.0386 Convergence: 0.0963 k= 0.019850 lr = 0.0000073\n",
      "[15/25][8050/9765] Loss_D: 0.0947 Loss_G: 0.0381 Convergence: 0.0955 k= 0.019865 lr = 0.0000073\n",
      "[15/25][8060/9765] Loss_D: 0.0976 Loss_G: 0.0403 Convergence: 0.0993 k= 0.019881 lr = 0.0000073\n",
      "[15/25][8070/9765] Loss_D: 0.0992 Loss_G: 0.0382 Convergence: 0.1018 k= 0.019880 lr = 0.0000073\n",
      "[15/25][8080/9765] Loss_D: 0.0952 Loss_G: 0.0414 Convergence: 0.0990 k= 0.019867 lr = 0.0000073\n",
      "[15/25][8090/9765] Loss_D: 0.0912 Loss_G: 0.0399 Convergence: 0.0951 k= 0.019862 lr = 0.0000073\n",
      "[15/25][8100/9765] Loss_D: 0.1031 Loss_G: 0.0366 Convergence: 0.1088 k= 0.019865 lr = 0.0000073\n",
      "[15/25][8110/9765] Loss_D: 0.0925 Loss_G: 0.0394 Convergence: 0.0954 k= 0.019875 lr = 0.0000073\n",
      "[15/25][8120/9765] Loss_D: 0.1018 Loss_G: 0.0397 Convergence: 0.1039 k= 0.019871 lr = 0.0000073\n",
      "[15/25][8130/9765] Loss_D: 0.0980 Loss_G: 0.0399 Convergence: 0.0992 k= 0.019867 lr = 0.0000073\n",
      "[15/25][8140/9765] Loss_D: 0.0995 Loss_G: 0.0389 Convergence: 0.1015 k= 0.019856 lr = 0.0000073\n",
      "[15/25][8150/9765] Loss_D: 0.0985 Loss_G: 0.0397 Convergence: 0.0994 k= 0.019867 lr = 0.0000073\n",
      "[15/25][8160/9765] Loss_D: 0.1011 Loss_G: 0.0384 Convergence: 0.1041 k= 0.019863 lr = 0.0000073\n",
      "[15/25][8170/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.019862 lr = 0.0000073\n",
      "[15/25][8180/9765] Loss_D: 0.1043 Loss_G: 0.0346 Convergence: 0.1124 k= 0.019898 lr = 0.0000073\n",
      "[15/25][8190/9765] Loss_D: 0.0903 Loss_G: 0.0350 Convergence: 0.0924 k= 0.019930 lr = 0.0000073\n",
      "[15/25][8200/9765] Loss_D: 0.0930 Loss_G: 0.0384 Convergence: 0.0946 k= 0.019946 lr = 0.0000073\n",
      "[15/25][8210/9765] Loss_D: 0.0949 Loss_G: 0.0400 Convergence: 0.0975 k= 0.019954 lr = 0.0000073\n",
      "[15/25][8220/9765] Loss_D: 0.0955 Loss_G: 0.0377 Convergence: 0.0971 k= 0.019935 lr = 0.0000073\n",
      "[15/25][8230/9765] Loss_D: 0.0893 Loss_G: 0.0440 Convergence: 0.0981 k= 0.019902 lr = 0.0000073\n",
      "[15/25][8240/9765] Loss_D: 0.0920 Loss_G: 0.0459 Convergence: 0.1017 k= 0.019835 lr = 0.0000073\n",
      "[15/25][8250/9765] Loss_D: 0.0984 Loss_G: 0.0436 Convergence: 0.1032 k= 0.019795 lr = 0.0000073\n",
      "[15/25][8260/9765] Loss_D: 0.0926 Loss_G: 0.0401 Convergence: 0.0962 k= 0.019758 lr = 0.0000073\n",
      "[15/25][8270/9765] Loss_D: 0.1066 Loss_G: 0.0401 Convergence: 0.1102 k= 0.019745 lr = 0.0000073\n",
      "[15/25][8280/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1011 k= 0.019753 lr = 0.0000073\n",
      "[15/25][8290/9765] Loss_D: 0.0987 Loss_G: 0.0348 Convergence: 0.1043 k= 0.019772 lr = 0.0000073\n",
      "[15/25][8300/9765] Loss_D: 0.1003 Loss_G: 0.0350 Convergence: 0.1064 k= 0.019814 lr = 0.0000073\n",
      "[15/25][8310/9765] Loss_D: 0.1004 Loss_G: 0.0368 Convergence: 0.1049 k= 0.019836 lr = 0.0000073\n",
      "[15/25][8320/9765] Loss_D: 0.0969 Loss_G: 0.0391 Convergence: 0.0977 k= 0.019855 lr = 0.0000073\n",
      "[15/25][8330/9765] Loss_D: 0.0939 Loss_G: 0.0398 Convergence: 0.0966 k= 0.019847 lr = 0.0000073\n",
      "[15/25][8340/9765] Loss_D: 0.0846 Loss_G: 0.0405 Convergence: 0.0917 k= 0.019837 lr = 0.0000073\n",
      "[15/25][8350/9765] Loss_D: 0.0986 Loss_G: 0.0418 Convergence: 0.1014 k= 0.019826 lr = 0.0000073\n",
      "[15/25][8360/9765] Loss_D: 0.1001 Loss_G: 0.0413 Convergence: 0.1018 k= 0.019820 lr = 0.0000073\n",
      "[15/25][8370/9765] Loss_D: 0.0980 Loss_G: 0.0409 Convergence: 0.1001 k= 0.019813 lr = 0.0000073\n",
      "[15/25][8380/9765] Loss_D: 0.0871 Loss_G: 0.0374 Convergence: 0.0901 k= 0.019813 lr = 0.0000073\n",
      "[15/25][8390/9765] Loss_D: 0.1018 Loss_G: 0.0389 Convergence: 0.1046 k= 0.019826 lr = 0.0000073\n",
      "[15/25][8400/9765] Loss_D: 0.1005 Loss_G: 0.0394 Convergence: 0.1023 k= 0.019841 lr = 0.0000073\n",
      "[15/25][8410/9765] Loss_D: 0.0925 Loss_G: 0.0377 Convergence: 0.0936 k= 0.019850 lr = 0.0000073\n",
      "[15/25][8420/9765] Loss_D: 0.0953 Loss_G: 0.0400 Convergence: 0.0976 k= 0.019866 lr = 0.0000073\n",
      "[15/25][8430/9765] Loss_D: 0.1026 Loss_G: 0.0395 Convergence: 0.1052 k= 0.019868 lr = 0.0000073\n",
      "[15/25][8440/9765] Loss_D: 0.1053 Loss_G: 0.0378 Convergence: 0.1106 k= 0.019884 lr = 0.0000073\n",
      "[15/25][8450/9765] Loss_D: 0.0917 Loss_G: 0.0371 Convergence: 0.0926 k= 0.019894 lr = 0.0000073\n",
      "[15/25][8460/9765] Loss_D: 0.0885 Loss_G: 0.0389 Convergence: 0.0925 k= 0.019889 lr = 0.0000073\n",
      "[15/25][8470/9765] Loss_D: 0.0949 Loss_G: 0.0382 Convergence: 0.0956 k= 0.019894 lr = 0.0000073\n",
      "[15/25][8480/9765] Loss_D: 0.0984 Loss_G: 0.0391 Convergence: 0.0998 k= 0.019908 lr = 0.0000073\n",
      "[15/25][8490/9765] Loss_D: 0.0919 Loss_G: 0.0372 Convergence: 0.0928 k= 0.019906 lr = 0.0000073\n",
      "[15/25][8500/9765] Loss_D: 0.0902 Loss_G: 0.0392 Convergence: 0.0938 k= 0.019909 lr = 0.0000073\n",
      "[15/25][8510/9765] Loss_D: 0.1041 Loss_G: 0.0382 Convergence: 0.1086 k= 0.019912 lr = 0.0000073\n",
      "[15/25][8520/9765] Loss_D: 0.0951 Loss_G: 0.0380 Convergence: 0.0961 k= 0.019930 lr = 0.0000073\n",
      "[15/25][8530/9765] Loss_D: 0.0976 Loss_G: 0.0381 Convergence: 0.0995 k= 0.019947 lr = 0.0000073\n",
      "[15/25][8540/9765] Loss_D: 0.0932 Loss_G: 0.0385 Convergence: 0.0949 k= 0.019963 lr = 0.0000073\n",
      "[15/25][8550/9765] Loss_D: 0.0999 Loss_G: 0.0402 Convergence: 0.1008 k= 0.019974 lr = 0.0000073\n",
      "[15/25][8560/9765] Loss_D: 0.1069 Loss_G: 0.0384 Convergence: 0.1124 k= 0.019979 lr = 0.0000073\n",
      "[15/25][8570/9765] Loss_D: 0.0981 Loss_G: 0.0362 Convergence: 0.1021 k= 0.020004 lr = 0.0000073\n",
      "[15/25][8580/9765] Loss_D: 0.0938 Loss_G: 0.0371 Convergence: 0.0953 k= 0.020021 lr = 0.0000073\n",
      "[15/25][8590/9765] Loss_D: 0.0942 Loss_G: 0.0399 Convergence: 0.0969 k= 0.020027 lr = 0.0000073\n",
      "[15/25][8600/9765] Loss_D: 0.1067 Loss_G: 0.0417 Convergence: 0.1088 k= 0.020021 lr = 0.0000073\n",
      "[15/25][8610/9765] Loss_D: 0.0937 Loss_G: 0.0402 Convergence: 0.0969 k= 0.020007 lr = 0.0000073\n",
      "[15/25][8620/9765] Loss_D: 0.0994 Loss_G: 0.0378 Convergence: 0.1024 k= 0.020000 lr = 0.0000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][8630/9765] Loss_D: 0.0915 Loss_G: 0.0381 Convergence: 0.0935 k= 0.019989 lr = 0.0000073\n",
      "[15/25][8640/9765] Loss_D: 0.1016 Loss_G: 0.0386 Convergence: 0.1047 k= 0.019990 lr = 0.0000073\n",
      "[15/25][8650/9765] Loss_D: 0.0878 Loss_G: 0.0399 Convergence: 0.0930 k= 0.019995 lr = 0.0000073\n",
      "[15/25][8660/9765] Loss_D: 0.0956 Loss_G: 0.0388 Convergence: 0.0966 k= 0.019983 lr = 0.0000073\n",
      "[15/25][8670/9765] Loss_D: 0.1003 Loss_G: 0.0389 Convergence: 0.1027 k= 0.019980 lr = 0.0000073\n",
      "[15/25][8680/9765] Loss_D: 0.0996 Loss_G: 0.0402 Convergence: 0.1004 k= 0.019979 lr = 0.0000073\n",
      "[15/25][8690/9765] Loss_D: 0.0927 Loss_G: 0.0410 Convergence: 0.0971 k= 0.019974 lr = 0.0000073\n",
      "[15/25][8700/9765] Loss_D: 0.1037 Loss_G: 0.0405 Convergence: 0.1059 k= 0.019969 lr = 0.0000073\n",
      "[15/25][8710/9765] Loss_D: 0.1008 Loss_G: 0.0398 Convergence: 0.1024 k= 0.019941 lr = 0.0000073\n",
      "[15/25][8720/9765] Loss_D: 0.0983 Loss_G: 0.0394 Convergence: 0.0994 k= 0.019934 lr = 0.0000073\n",
      "[15/25][8730/9765] Loss_D: 0.0991 Loss_G: 0.0380 Convergence: 0.1019 k= 0.019948 lr = 0.0000073\n",
      "[15/25][8740/9765] Loss_D: 0.0968 Loss_G: 0.0371 Convergence: 0.0995 k= 0.019971 lr = 0.0000073\n",
      "[15/25][8750/9765] Loss_D: 0.0906 Loss_G: 0.0388 Convergence: 0.0936 k= 0.019988 lr = 0.0000073\n",
      "[15/25][8760/9765] Loss_D: 0.0994 Loss_G: 0.0370 Convergence: 0.1032 k= 0.019985 lr = 0.0000073\n",
      "[15/25][8770/9765] Loss_D: 0.0949 Loss_G: 0.0384 Convergence: 0.0958 k= 0.020008 lr = 0.0000073\n",
      "[15/25][8780/9765] Loss_D: 0.0937 Loss_G: 0.0413 Convergence: 0.0981 k= 0.020004 lr = 0.0000073\n",
      "[15/25][8790/9765] Loss_D: 0.1023 Loss_G: 0.0419 Convergence: 0.1037 k= 0.019970 lr = 0.0000073\n",
      "[15/25][8800/9765] Loss_D: 0.1061 Loss_G: 0.0393 Convergence: 0.1104 k= 0.019957 lr = 0.0000073\n",
      "[15/25][8810/9765] Loss_D: 0.0884 Loss_G: 0.0371 Convergence: 0.0906 k= 0.019955 lr = 0.0000073\n",
      "[15/25][8820/9765] Loss_D: 0.1032 Loss_G: 0.0377 Convergence: 0.1079 k= 0.019969 lr = 0.0000073\n",
      "[15/25][8830/9765] Loss_D: 0.0836 Loss_G: 0.0378 Convergence: 0.0884 k= 0.019985 lr = 0.0000073\n",
      "[15/25][8840/9765] Loss_D: 0.0935 Loss_G: 0.0374 Convergence: 0.0946 k= 0.019996 lr = 0.0000073\n",
      "[15/25][8850/9765] Loss_D: 0.0867 Loss_G: 0.0375 Convergence: 0.0899 k= 0.019993 lr = 0.0000073\n",
      "[15/25][8860/9765] Loss_D: 0.0993 Loss_G: 0.0389 Convergence: 0.1012 k= 0.020001 lr = 0.0000073\n",
      "[15/25][8870/9765] Loss_D: 0.0978 Loss_G: 0.0402 Convergence: 0.0994 k= 0.019994 lr = 0.0000073\n",
      "[15/25][8880/9765] Loss_D: 0.0926 Loss_G: 0.0404 Convergence: 0.0964 k= 0.019973 lr = 0.0000073\n",
      "[15/25][8890/9765] Loss_D: 0.0843 Loss_G: 0.0366 Convergence: 0.0876 k= 0.019957 lr = 0.0000073\n",
      "[15/25][8900/9765] Loss_D: 0.0983 Loss_G: 0.0374 Convergence: 0.1013 k= 0.019979 lr = 0.0000073\n",
      "[15/25][8910/9765] Loss_D: 0.0947 Loss_G: 0.0366 Convergence: 0.0970 k= 0.019993 lr = 0.0000073\n",
      "[15/25][8920/9765] Loss_D: 0.1030 Loss_G: 0.0357 Convergence: 0.1095 k= 0.020007 lr = 0.0000073\n",
      "[15/25][8930/9765] Loss_D: 0.0995 Loss_G: 0.0387 Convergence: 0.1017 k= 0.020018 lr = 0.0000073\n",
      "[15/25][8940/9765] Loss_D: 0.1024 Loss_G: 0.0376 Convergence: 0.1068 k= 0.020016 lr = 0.0000073\n",
      "[15/25][8950/9765] Loss_D: 0.1030 Loss_G: 0.0393 Convergence: 0.1060 k= 0.020026 lr = 0.0000073\n",
      "[15/25][8960/9765] Loss_D: 0.1095 Loss_G: 0.0399 Convergence: 0.1146 k= 0.020038 lr = 0.0000073\n",
      "[15/25][8970/9765] Loss_D: 0.0966 Loss_G: 0.0426 Convergence: 0.1010 k= 0.020010 lr = 0.0000073\n",
      "[15/25][8980/9765] Loss_D: 0.0944 Loss_G: 0.0392 Convergence: 0.0962 k= 0.019989 lr = 0.0000073\n",
      "[15/25][8990/9765] Loss_D: 0.0944 Loss_G: 0.0363 Convergence: 0.0969 k= 0.019974 lr = 0.0000073\n",
      "[15/25][9000/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1036 k= 0.019976 lr = 0.0000073\n",
      "[15/25][9010/9765] Loss_D: 0.0915 Loss_G: 0.0363 Convergence: 0.0927 k= 0.019972 lr = 0.0000073\n",
      "[15/25][9020/9765] Loss_D: 0.0934 Loss_G: 0.0384 Convergence: 0.0949 k= 0.019984 lr = 0.0000073\n",
      "[15/25][9030/9765] Loss_D: 0.0951 Loss_G: 0.0376 Convergence: 0.0965 k= 0.019990 lr = 0.0000073\n",
      "[15/25][9040/9765] Loss_D: 0.0978 Loss_G: 0.0413 Convergence: 0.1004 k= 0.019978 lr = 0.0000073\n",
      "[15/25][9050/9765] Loss_D: 0.0971 Loss_G: 0.0383 Convergence: 0.0988 k= 0.019974 lr = 0.0000073\n",
      "[15/25][9060/9765] Loss_D: 0.0919 Loss_G: 0.0385 Convergence: 0.0941 k= 0.019973 lr = 0.0000073\n",
      "[15/25][9070/9765] Loss_D: 0.0929 Loss_G: 0.0404 Convergence: 0.0966 k= 0.019979 lr = 0.0000073\n",
      "[15/25][9080/9765] Loss_D: 0.0910 Loss_G: 0.0398 Convergence: 0.0949 k= 0.019970 lr = 0.0000073\n",
      "[15/25][9090/9765] Loss_D: 0.1019 Loss_G: 0.0391 Convergence: 0.1047 k= 0.019954 lr = 0.0000073\n",
      "[15/25][9100/9765] Loss_D: 0.1054 Loss_G: 0.0397 Convergence: 0.1089 k= 0.019936 lr = 0.0000073\n",
      "[15/25][9110/9765] Loss_D: 0.0907 Loss_G: 0.0410 Convergence: 0.0959 k= 0.019933 lr = 0.0000073\n",
      "[15/25][9120/9765] Loss_D: 0.0949 Loss_G: 0.0369 Convergence: 0.0969 k= 0.019930 lr = 0.0000073\n",
      "[15/25][9130/9765] Loss_D: 0.0958 Loss_G: 0.0384 Convergence: 0.0967 k= 0.019931 lr = 0.0000073\n",
      "[15/25][9140/9765] Loss_D: 0.1005 Loss_G: 0.0377 Convergence: 0.1040 k= 0.019933 lr = 0.0000073\n",
      "[15/25][9150/9765] Loss_D: 0.0853 Loss_G: 0.0368 Convergence: 0.0885 k= 0.019962 lr = 0.0000073\n",
      "[15/25][9160/9765] Loss_D: 0.0933 Loss_G: 0.0388 Convergence: 0.0953 k= 0.019963 lr = 0.0000073\n",
      "[15/25][9170/9765] Loss_D: 0.0839 Loss_G: 0.0353 Convergence: 0.0861 k= 0.019961 lr = 0.0000073\n",
      "[15/25][9180/9765] Loss_D: 0.0998 Loss_G: 0.0381 Convergence: 0.1027 k= 0.019992 lr = 0.0000073\n",
      "[15/25][9190/9765] Loss_D: 0.1016 Loss_G: 0.0407 Convergence: 0.1026 k= 0.020015 lr = 0.0000073\n",
      "[15/25][9200/9765] Loss_D: 0.1014 Loss_G: 0.0386 Convergence: 0.1044 k= 0.020000 lr = 0.0000073\n",
      "[15/25][9210/9765] Loss_D: 0.0990 Loss_G: 0.0374 Convergence: 0.1022 k= 0.020004 lr = 0.0000073\n",
      "[15/25][9220/9765] Loss_D: 0.0920 Loss_G: 0.0405 Convergence: 0.0962 k= 0.020000 lr = 0.0000073\n",
      "[15/25][9230/9765] Loss_D: 0.0884 Loss_G: 0.0402 Convergence: 0.0937 k= 0.020001 lr = 0.0000073\n",
      "[15/25][9240/9765] Loss_D: 0.0929 Loss_G: 0.0397 Convergence: 0.0960 k= 0.019988 lr = 0.0000073\n",
      "[15/25][9250/9765] Loss_D: 0.0971 Loss_G: 0.0396 Convergence: 0.0983 k= 0.019993 lr = 0.0000073\n",
      "[15/25][9260/9765] Loss_D: 0.1008 Loss_G: 0.0393 Convergence: 0.1029 k= 0.019986 lr = 0.0000073\n",
      "[15/25][9270/9765] Loss_D: 0.0929 Loss_G: 0.0391 Convergence: 0.0953 k= 0.019994 lr = 0.0000073\n",
      "[15/25][9280/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0947 k= 0.020008 lr = 0.0000073\n",
      "[15/25][9290/9765] Loss_D: 0.0919 Loss_G: 0.0398 Convergence: 0.0954 k= 0.020009 lr = 0.0000073\n",
      "[15/25][9300/9765] Loss_D: 0.0982 Loss_G: 0.0388 Convergence: 0.0998 k= 0.020013 lr = 0.0000073\n",
      "[15/25][9310/9765] Loss_D: 0.0890 Loss_G: 0.0401 Convergence: 0.0940 k= 0.020021 lr = 0.0000073\n",
      "[15/25][9320/9765] Loss_D: 0.0885 Loss_G: 0.0381 Convergence: 0.0918 k= 0.020001 lr = 0.0000073\n",
      "[15/25][9330/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0964 k= 0.020023 lr = 0.0000073\n",
      "[15/25][9340/9765] Loss_D: 0.1018 Loss_G: 0.0402 Convergence: 0.1033 k= 0.020012 lr = 0.0000073\n",
      "[15/25][9350/9765] Loss_D: 0.0919 Loss_G: 0.0376 Convergence: 0.0932 k= 0.020010 lr = 0.0000073\n",
      "[15/25][9360/9765] Loss_D: 0.1085 Loss_G: 0.0379 Convergence: 0.1151 k= 0.020031 lr = 0.0000073\n",
      "[15/25][9370/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0960 k= 0.020045 lr = 0.0000073\n",
      "[15/25][9380/9765] Loss_D: 0.1028 Loss_G: 0.0388 Convergence: 0.1063 k= 0.020040 lr = 0.0000073\n",
      "[15/25][9390/9765] Loss_D: 0.0928 Loss_G: 0.0395 Convergence: 0.0957 k= 0.020042 lr = 0.0000073\n",
      "[15/25][9400/9765] Loss_D: 0.0926 Loss_G: 0.0404 Convergence: 0.0964 k= 0.020030 lr = 0.0000073\n",
      "[15/25][9410/9765] Loss_D: 0.1020 Loss_G: 0.0384 Convergence: 0.1055 k= 0.020027 lr = 0.0000073\n",
      "[15/25][9420/9765] Loss_D: 0.0971 Loss_G: 0.0384 Convergence: 0.0986 k= 0.020036 lr = 0.0000073\n",
      "[15/25][9430/9765] Loss_D: 0.0942 Loss_G: 0.0364 Convergence: 0.0966 k= 0.020055 lr = 0.0000073\n",
      "[15/25][9440/9765] Loss_D: 0.0927 Loss_G: 0.0355 Convergence: 0.0953 k= 0.020063 lr = 0.0000073\n",
      "[15/25][9450/9765] Loss_D: 0.0980 Loss_G: 0.0388 Convergence: 0.0995 k= 0.020072 lr = 0.0000073\n",
      "[15/25][9460/9765] Loss_D: 0.0990 Loss_G: 0.0363 Convergence: 0.1032 k= 0.020103 lr = 0.0000073\n",
      "[15/25][9470/9765] Loss_D: 0.0958 Loss_G: 0.0370 Convergence: 0.0981 k= 0.020115 lr = 0.0000073\n",
      "[15/25][9480/9765] Loss_D: 0.1044 Loss_G: 0.0409 Convergence: 0.1064 k= 0.020115 lr = 0.0000073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/25][9490/9765] Loss_D: 0.0895 Loss_G: 0.0409 Convergence: 0.0951 k= 0.020107 lr = 0.0000073\n",
      "[15/25][9500/9765] Loss_D: 0.0933 Loss_G: 0.0388 Convergence: 0.0952 k= 0.020098 lr = 0.0000073\n",
      "[15/25][9510/9765] Loss_D: 0.0923 Loss_G: 0.0389 Convergence: 0.0948 k= 0.020091 lr = 0.0000073\n",
      "[15/25][9520/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0941 k= 0.020105 lr = 0.0000073\n",
      "[15/25][9530/9765] Loss_D: 0.0914 Loss_G: 0.0375 Convergence: 0.0928 k= 0.020119 lr = 0.0000069\n",
      "[15/25][9540/9765] Loss_D: 0.1034 Loss_G: 0.0385 Convergence: 0.1074 k= 0.020121 lr = 0.0000069\n",
      "[15/25][9550/9765] Loss_D: 0.1029 Loss_G: 0.0399 Convergence: 0.1053 k= 0.020126 lr = 0.0000069\n",
      "[15/25][9560/9765] Loss_D: 0.0954 Loss_G: 0.0395 Convergence: 0.0973 k= 0.020120 lr = 0.0000069\n",
      "[15/25][9570/9765] Loss_D: 0.0967 Loss_G: 0.0357 Convergence: 0.1006 k= 0.020125 lr = 0.0000069\n",
      "[15/25][9580/9765] Loss_D: 0.0904 Loss_G: 0.0392 Convergence: 0.0939 k= 0.020145 lr = 0.0000069\n",
      "[15/25][9590/9765] Loss_D: 0.0894 Loss_G: 0.0389 Convergence: 0.0931 k= 0.020151 lr = 0.0000069\n",
      "[15/25][9600/9765] Loss_D: 0.0886 Loss_G: 0.0386 Convergence: 0.0922 k= 0.020158 lr = 0.0000069\n",
      "[15/25][9610/9765] Loss_D: 0.0948 Loss_G: 0.0382 Convergence: 0.0956 k= 0.020165 lr = 0.0000069\n",
      "[15/25][9620/9765] Loss_D: 0.1023 Loss_G: 0.0380 Convergence: 0.1064 k= 0.020162 lr = 0.0000069\n",
      "[15/25][9630/9765] Loss_D: 0.0970 Loss_G: 0.0356 Convergence: 0.1012 k= 0.020186 lr = 0.0000069\n",
      "[15/25][9640/9765] Loss_D: 0.0973 Loss_G: 0.0386 Convergence: 0.0987 k= 0.020202 lr = 0.0000069\n",
      "[15/25][9650/9765] Loss_D: 0.1104 Loss_G: 0.0373 Convergence: 0.1183 k= 0.020203 lr = 0.0000069\n",
      "[15/25][9660/9765] Loss_D: 0.1082 Loss_G: 0.0374 Convergence: 0.1151 k= 0.020220 lr = 0.0000069\n",
      "[15/25][9670/9765] Loss_D: 0.0899 Loss_G: 0.0395 Convergence: 0.0939 k= 0.020215 lr = 0.0000069\n",
      "[15/25][9680/9765] Loss_D: 0.0983 Loss_G: 0.0406 Convergence: 0.1001 k= 0.020208 lr = 0.0000069\n",
      "[15/25][9690/9765] Loss_D: 0.1066 Loss_G: 0.0384 Convergence: 0.1119 k= 0.020209 lr = 0.0000069\n",
      "[15/25][9700/9765] Loss_D: 0.0915 Loss_G: 0.0381 Convergence: 0.0934 k= 0.020198 lr = 0.0000069\n",
      "[15/25][9710/9765] Loss_D: 0.1013 Loss_G: 0.0393 Convergence: 0.1036 k= 0.020193 lr = 0.0000069\n",
      "[15/25][9720/9765] Loss_D: 0.0948 Loss_G: 0.0403 Convergence: 0.0977 k= 0.020182 lr = 0.0000069\n",
      "[15/25][9730/9765] Loss_D: 0.0878 Loss_G: 0.0407 Convergence: 0.0939 k= 0.020161 lr = 0.0000069\n",
      "[15/25][9740/9765] Loss_D: 0.0972 Loss_G: 0.0417 Convergence: 0.1005 k= 0.020147 lr = 0.0000069\n",
      "[15/25][9750/9765] Loss_D: 0.0899 Loss_G: 0.0391 Convergence: 0.0935 k= 0.020133 lr = 0.0000069\n",
      "[15/25][9760/9765] Loss_D: 0.0992 Loss_G: 0.0389 Convergence: 0.1011 k= 0.020141 lr = 0.0000069\n",
      "[16/25][0/9765] Loss_D: 0.0945 Loss_G: 0.0382 Convergence: 0.0954 k= 0.020140 lr = 0.0000069\n",
      "[16/25][10/9765] Loss_D: 0.1009 Loss_G: 0.0371 Convergence: 0.1052 k= 0.020129 lr = 0.0000069\n",
      "[16/25][20/9765] Loss_D: 0.0919 Loss_G: 0.0379 Convergence: 0.0935 k= 0.020129 lr = 0.0000069\n",
      "[16/25][30/9765] Loss_D: 0.1080 Loss_G: 0.0391 Convergence: 0.1133 k= 0.020128 lr = 0.0000069\n",
      "[16/25][40/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0958 k= 0.020122 lr = 0.0000069\n",
      "[16/25][50/9765] Loss_D: 0.0971 Loss_G: 0.0381 Convergence: 0.0989 k= 0.020121 lr = 0.0000069\n",
      "[16/25][60/9765] Loss_D: 0.0980 Loss_G: 0.0364 Convergence: 0.1018 k= 0.020133 lr = 0.0000069\n",
      "[16/25][70/9765] Loss_D: 0.1021 Loss_G: 0.0397 Convergence: 0.1043 k= 0.020136 lr = 0.0000069\n",
      "[16/25][80/9765] Loss_D: 0.0982 Loss_G: 0.0388 Convergence: 0.0998 k= 0.020114 lr = 0.0000069\n",
      "[16/25][90/9765] Loss_D: 0.0930 Loss_G: 0.0389 Convergence: 0.0952 k= 0.020104 lr = 0.0000069\n",
      "[16/25][100/9765] Loss_D: 0.1080 Loss_G: 0.0379 Convergence: 0.1143 k= 0.020109 lr = 0.0000069\n",
      "[16/25][110/9765] Loss_D: 0.0930 Loss_G: 0.0394 Convergence: 0.0956 k= 0.020105 lr = 0.0000069\n",
      "[16/25][120/9765] Loss_D: 0.0870 Loss_G: 0.0374 Convergence: 0.0901 k= 0.020109 lr = 0.0000069\n",
      "[16/25][130/9765] Loss_D: 0.1078 Loss_G: 0.0368 Convergence: 0.1151 k= 0.020139 lr = 0.0000069\n",
      "[16/25][140/9765] Loss_D: 0.0969 Loss_G: 0.0394 Convergence: 0.0980 k= 0.020154 lr = 0.0000069\n",
      "[16/25][150/9765] Loss_D: 0.0927 Loss_G: 0.0377 Convergence: 0.0938 k= 0.020159 lr = 0.0000069\n",
      "[16/25][160/9765] Loss_D: 0.0961 Loss_G: 0.0392 Convergence: 0.0973 k= 0.020175 lr = 0.0000069\n",
      "[16/25][170/9765] Loss_D: 0.0872 Loss_G: 0.0377 Convergence: 0.0905 k= 0.020183 lr = 0.0000069\n",
      "[16/25][180/9765] Loss_D: 0.0991 Loss_G: 0.0373 Convergence: 0.1026 k= 0.020187 lr = 0.0000069\n",
      "[16/25][190/9765] Loss_D: 0.0904 Loss_G: 0.0397 Convergence: 0.0944 k= 0.020178 lr = 0.0000069\n",
      "[16/25][200/9765] Loss_D: 0.1023 Loss_G: 0.0411 Convergence: 0.1033 k= 0.020170 lr = 0.0000069\n",
      "[16/25][210/9765] Loss_D: 0.1042 Loss_G: 0.0401 Convergence: 0.1069 k= 0.020155 lr = 0.0000069\n",
      "[16/25][220/9765] Loss_D: 0.0812 Loss_G: 0.0381 Convergence: 0.0873 k= 0.020140 lr = 0.0000069\n",
      "[16/25][230/9765] Loss_D: 0.0914 Loss_G: 0.0403 Convergence: 0.0957 k= 0.020122 lr = 0.0000069\n",
      "[16/25][240/9765] Loss_D: 0.0833 Loss_G: 0.0391 Convergence: 0.0895 k= 0.020113 lr = 0.0000069\n",
      "[16/25][250/9765] Loss_D: 0.0975 Loss_G: 0.0383 Convergence: 0.0993 k= 0.020121 lr = 0.0000069\n",
      "[16/25][260/9765] Loss_D: 0.0988 Loss_G: 0.0365 Convergence: 0.1029 k= 0.020135 lr = 0.0000069\n",
      "[16/25][270/9765] Loss_D: 0.0971 Loss_G: 0.0383 Convergence: 0.0987 k= 0.020155 lr = 0.0000069\n",
      "[16/25][280/9765] Loss_D: 0.1057 Loss_G: 0.0362 Convergence: 0.1128 k= 0.020167 lr = 0.0000069\n",
      "[16/25][290/9765] Loss_D: 0.0966 Loss_G: 0.0383 Convergence: 0.0981 k= 0.020181 lr = 0.0000069\n",
      "[16/25][300/9765] Loss_D: 0.0903 Loss_G: 0.0392 Convergence: 0.0939 k= 0.020181 lr = 0.0000069\n",
      "[16/25][310/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.020170 lr = 0.0000069\n",
      "[16/25][320/9765] Loss_D: 0.0886 Loss_G: 0.0430 Convergence: 0.0967 k= 0.020143 lr = 0.0000069\n",
      "[16/25][330/9765] Loss_D: 0.1019 Loss_G: 0.0417 Convergence: 0.1034 k= 0.020118 lr = 0.0000069\n",
      "[16/25][340/9765] Loss_D: 0.0962 Loss_G: 0.0406 Convergence: 0.0988 k= 0.020099 lr = 0.0000069\n",
      "[16/25][350/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0993 k= 0.020110 lr = 0.0000069\n",
      "[16/25][360/9765] Loss_D: 0.0942 Loss_G: 0.0383 Convergence: 0.0953 k= 0.020107 lr = 0.0000069\n",
      "[16/25][370/9765] Loss_D: 0.0937 Loss_G: 0.0366 Convergence: 0.0957 k= 0.020120 lr = 0.0000069\n",
      "[16/25][380/9765] Loss_D: 0.1061 Loss_G: 0.0399 Convergence: 0.1097 k= 0.020134 lr = 0.0000069\n",
      "[16/25][390/9765] Loss_D: 0.0965 Loss_G: 0.0397 Convergence: 0.0981 k= 0.020149 lr = 0.0000069\n",
      "[16/25][400/9765] Loss_D: 0.0951 Loss_G: 0.0387 Convergence: 0.0962 k= 0.020143 lr = 0.0000069\n",
      "[16/25][410/9765] Loss_D: 0.0897 Loss_G: 0.0412 Convergence: 0.0955 k= 0.020128 lr = 0.0000069\n",
      "[16/25][420/9765] Loss_D: 0.0989 Loss_G: 0.0404 Convergence: 0.1002 k= 0.020108 lr = 0.0000069\n",
      "[16/25][430/9765] Loss_D: 0.0919 Loss_G: 0.0391 Convergence: 0.0948 k= 0.020083 lr = 0.0000069\n",
      "[16/25][440/9765] Loss_D: 0.0869 Loss_G: 0.0378 Convergence: 0.0904 k= 0.020079 lr = 0.0000069\n",
      "[16/25][450/9765] Loss_D: 0.0966 Loss_G: 0.0419 Convergence: 0.1004 k= 0.020079 lr = 0.0000069\n",
      "[16/25][460/9765] Loss_D: 0.0982 Loss_G: 0.0387 Convergence: 0.0999 k= 0.020075 lr = 0.0000069\n",
      "[16/25][470/9765] Loss_D: 0.0947 Loss_G: 0.0363 Convergence: 0.0972 k= 0.020089 lr = 0.0000069\n",
      "[16/25][480/9765] Loss_D: 0.0944 Loss_G: 0.0372 Convergence: 0.0959 k= 0.020106 lr = 0.0000069\n",
      "[16/25][490/9765] Loss_D: 0.0945 Loss_G: 0.0378 Convergence: 0.0956 k= 0.020101 lr = 0.0000069\n",
      "[16/25][500/9765] Loss_D: 0.0953 Loss_G: 0.0387 Convergence: 0.0964 k= 0.020108 lr = 0.0000069\n",
      "[16/25][510/9765] Loss_D: 0.0967 Loss_G: 0.0382 Convergence: 0.0982 k= 0.020125 lr = 0.0000069\n",
      "[16/25][520/9765] Loss_D: 0.1030 Loss_G: 0.0373 Convergence: 0.1079 k= 0.020141 lr = 0.0000069\n",
      "[16/25][530/9765] Loss_D: 0.0922 Loss_G: 0.0392 Convergence: 0.0949 k= 0.020137 lr = 0.0000069\n",
      "[16/25][540/9765] Loss_D: 0.0998 Loss_G: 0.0399 Convergence: 0.1009 k= 0.020136 lr = 0.0000069\n",
      "[16/25][550/9765] Loss_D: 0.1012 Loss_G: 0.0400 Convergence: 0.1028 k= 0.020132 lr = 0.0000069\n",
      "[16/25][560/9765] Loss_D: 0.0961 Loss_G: 0.0372 Convergence: 0.0984 k= 0.020125 lr = 0.0000069\n",
      "[16/25][570/9765] Loss_D: 0.0998 Loss_G: 0.0371 Convergence: 0.1036 k= 0.020136 lr = 0.0000069\n",
      "[16/25][580/9765] Loss_D: 0.0941 Loss_G: 0.0398 Convergence: 0.0967 k= 0.020136 lr = 0.0000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][590/9765] Loss_D: 0.0972 Loss_G: 0.0389 Convergence: 0.0983 k= 0.020144 lr = 0.0000069\n",
      "[16/25][600/9765] Loss_D: 0.0918 Loss_G: 0.0374 Convergence: 0.0929 k= 0.020154 lr = 0.0000069\n",
      "[16/25][610/9765] Loss_D: 0.1045 Loss_G: 0.0386 Convergence: 0.1088 k= 0.020174 lr = 0.0000069\n",
      "[16/25][620/9765] Loss_D: 0.0947 Loss_G: 0.0381 Convergence: 0.0956 k= 0.020167 lr = 0.0000069\n",
      "[16/25][630/9765] Loss_D: 0.0999 Loss_G: 0.0407 Convergence: 0.1011 k= 0.020176 lr = 0.0000069\n",
      "[16/25][640/9765] Loss_D: 0.0942 Loss_G: 0.0395 Convergence: 0.0965 k= 0.020173 lr = 0.0000069\n",
      "[16/25][650/9765] Loss_D: 0.0889 Loss_G: 0.0389 Convergence: 0.0928 k= 0.020156 lr = 0.0000069\n",
      "[16/25][660/9765] Loss_D: 0.0928 Loss_G: 0.0386 Convergence: 0.0948 k= 0.020157 lr = 0.0000069\n",
      "[16/25][670/9765] Loss_D: 0.0929 Loss_G: 0.0396 Convergence: 0.0958 k= 0.020150 lr = 0.0000069\n",
      "[16/25][680/9765] Loss_D: 0.1048 Loss_G: 0.0389 Convergence: 0.1090 k= 0.020144 lr = 0.0000069\n",
      "[16/25][690/9765] Loss_D: 0.0888 Loss_G: 0.0384 Convergence: 0.0922 k= 0.020146 lr = 0.0000069\n",
      "[16/25][700/9765] Loss_D: 0.1011 Loss_G: 0.0396 Convergence: 0.1030 k= 0.020147 lr = 0.0000069\n",
      "[16/25][710/9765] Loss_D: 0.0915 Loss_G: 0.0420 Convergence: 0.0974 k= 0.020130 lr = 0.0000069\n",
      "[16/25][720/9765] Loss_D: 0.0963 Loss_G: 0.0398 Convergence: 0.0981 k= 0.020125 lr = 0.0000069\n",
      "[16/25][730/9765] Loss_D: 0.0848 Loss_G: 0.0413 Convergence: 0.0926 k= 0.020102 lr = 0.0000069\n",
      "[16/25][740/9765] Loss_D: 0.1042 Loss_G: 0.0400 Convergence: 0.1070 k= 0.020093 lr = 0.0000069\n",
      "[16/25][750/9765] Loss_D: 0.1033 Loss_G: 0.0409 Convergence: 0.1048 k= 0.020091 lr = 0.0000069\n",
      "[16/25][760/9765] Loss_D: 0.0955 Loss_G: 0.0375 Convergence: 0.0973 k= 0.020101 lr = 0.0000069\n",
      "[16/25][770/9765] Loss_D: 0.0911 Loss_G: 0.0394 Convergence: 0.0945 k= 0.020106 lr = 0.0000069\n",
      "[16/25][780/9765] Loss_D: 0.1014 Loss_G: 0.0392 Convergence: 0.1039 k= 0.020111 lr = 0.0000069\n",
      "[16/25][790/9765] Loss_D: 0.0936 Loss_G: 0.0372 Convergence: 0.0948 k= 0.020111 lr = 0.0000069\n",
      "[16/25][800/9765] Loss_D: 0.0894 Loss_G: 0.0390 Convergence: 0.0931 k= 0.020106 lr = 0.0000069\n",
      "[16/25][810/9765] Loss_D: 0.1000 Loss_G: 0.0435 Convergence: 0.1040 k= 0.020086 lr = 0.0000069\n",
      "[16/25][820/9765] Loss_D: 0.1035 Loss_G: 0.0414 Convergence: 0.1047 k= 0.020082 lr = 0.0000069\n",
      "[16/25][830/9765] Loss_D: 0.0992 Loss_G: 0.0395 Convergence: 0.1005 k= 0.020068 lr = 0.0000069\n",
      "[16/25][840/9765] Loss_D: 0.0958 Loss_G: 0.0384 Convergence: 0.0967 k= 0.020054 lr = 0.0000069\n",
      "[16/25][850/9765] Loss_D: 0.0981 Loss_G: 0.0365 Convergence: 0.1019 k= 0.020064 lr = 0.0000069\n",
      "[16/25][860/9765] Loss_D: 0.0999 Loss_G: 0.0367 Convergence: 0.1042 k= 0.020075 lr = 0.0000069\n",
      "[16/25][870/9765] Loss_D: 0.0903 Loss_G: 0.0393 Convergence: 0.0940 k= 0.020070 lr = 0.0000069\n",
      "[16/25][880/9765] Loss_D: 0.0972 Loss_G: 0.0369 Convergence: 0.1002 k= 0.020080 lr = 0.0000069\n",
      "[16/25][890/9765] Loss_D: 0.0983 Loss_G: 0.0398 Convergence: 0.0993 k= 0.020090 lr = 0.0000069\n",
      "[16/25][900/9765] Loss_D: 0.0974 Loss_G: 0.0408 Convergence: 0.0998 k= 0.020086 lr = 0.0000069\n",
      "[16/25][910/9765] Loss_D: 0.1049 Loss_G: 0.0401 Convergence: 0.1079 k= 0.020075 lr = 0.0000069\n",
      "[16/25][920/9765] Loss_D: 0.0947 Loss_G: 0.0366 Convergence: 0.0969 k= 0.020086 lr = 0.0000069\n",
      "[16/25][930/9765] Loss_D: 0.0887 Loss_G: 0.0366 Convergence: 0.0903 k= 0.020105 lr = 0.0000069\n",
      "[16/25][940/9765] Loss_D: 0.0935 Loss_G: 0.0380 Convergence: 0.0946 k= 0.020116 lr = 0.0000069\n",
      "[16/25][950/9765] Loss_D: 0.0943 Loss_G: 0.0372 Convergence: 0.0958 k= 0.020123 lr = 0.0000069\n",
      "[16/25][960/9765] Loss_D: 0.0972 Loss_G: 0.0384 Convergence: 0.0987 k= 0.020134 lr = 0.0000069\n",
      "[16/25][970/9765] Loss_D: 0.0946 Loss_G: 0.0401 Convergence: 0.0973 k= 0.020132 lr = 0.0000069\n",
      "[16/25][980/9765] Loss_D: 0.0974 Loss_G: 0.0384 Convergence: 0.0991 k= 0.020117 lr = 0.0000069\n",
      "[16/25][990/9765] Loss_D: 0.0962 Loss_G: 0.0369 Convergence: 0.0988 k= 0.020135 lr = 0.0000069\n",
      "[16/25][1000/9765] Loss_D: 0.0940 Loss_G: 0.0374 Convergence: 0.0953 k= 0.020140 lr = 0.0000069\n",
      "[16/25][1010/9765] Loss_D: 0.1011 Loss_G: 0.0398 Convergence: 0.1028 k= 0.020147 lr = 0.0000069\n",
      "[16/25][1020/9765] Loss_D: 0.0912 Loss_G: 0.0399 Convergence: 0.0951 k= 0.020132 lr = 0.0000069\n",
      "[16/25][1030/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.0989 k= 0.020127 lr = 0.0000069\n",
      "[16/25][1040/9765] Loss_D: 0.0923 Loss_G: 0.0392 Convergence: 0.0950 k= 0.020128 lr = 0.0000069\n",
      "[16/25][1050/9765] Loss_D: 0.0946 Loss_G: 0.0398 Convergence: 0.0971 k= 0.020120 lr = 0.0000069\n",
      "[16/25][1060/9765] Loss_D: 0.1113 Loss_G: 0.0416 Convergence: 0.1154 k= 0.020125 lr = 0.0000069\n",
      "[16/25][1070/9765] Loss_D: 0.1117 Loss_G: 0.0393 Convergence: 0.1182 k= 0.020130 lr = 0.0000069\n",
      "[16/25][1080/9765] Loss_D: 0.1035 Loss_G: 0.0395 Convergence: 0.1066 k= 0.020139 lr = 0.0000069\n",
      "[16/25][1090/9765] Loss_D: 0.0855 Loss_G: 0.0389 Convergence: 0.0907 k= 0.020133 lr = 0.0000069\n",
      "[16/25][1100/9765] Loss_D: 0.0963 Loss_G: 0.0399 Convergence: 0.0982 k= 0.020136 lr = 0.0000069\n",
      "[16/25][1110/9765] Loss_D: 0.1105 Loss_G: 0.0372 Convergence: 0.1185 k= 0.020153 lr = 0.0000069\n",
      "[16/25][1120/9765] Loss_D: 0.0927 Loss_G: 0.0366 Convergence: 0.0942 k= 0.020174 lr = 0.0000069\n",
      "[16/25][1130/9765] Loss_D: 0.1016 Loss_G: 0.0382 Convergence: 0.1051 k= 0.020186 lr = 0.0000069\n",
      "[16/25][1140/9765] Loss_D: 0.0996 Loss_G: 0.0380 Convergence: 0.1026 k= 0.020190 lr = 0.0000069\n",
      "[16/25][1150/9765] Loss_D: 0.0966 Loss_G: 0.0383 Convergence: 0.0980 k= 0.020198 lr = 0.0000069\n",
      "[16/25][1160/9765] Loss_D: 0.0945 Loss_G: 0.0381 Convergence: 0.0952 k= 0.020206 lr = 0.0000069\n",
      "[16/25][1170/9765] Loss_D: 0.1008 Loss_G: 0.0374 Convergence: 0.1048 k= 0.020213 lr = 0.0000069\n",
      "[16/25][1180/9765] Loss_D: 0.1041 Loss_G: 0.0401 Convergence: 0.1067 k= 0.020218 lr = 0.0000069\n",
      "[16/25][1190/9765] Loss_D: 0.0936 Loss_G: 0.0393 Convergence: 0.0959 k= 0.020214 lr = 0.0000069\n",
      "[16/25][1200/9765] Loss_D: 0.0964 Loss_G: 0.0403 Convergence: 0.0987 k= 0.020212 lr = 0.0000069\n",
      "[16/25][1210/9765] Loss_D: 0.0942 Loss_G: 0.0382 Convergence: 0.0952 k= 0.020204 lr = 0.0000069\n",
      "[16/25][1220/9765] Loss_D: 0.0893 Loss_G: 0.0393 Convergence: 0.0934 k= 0.020208 lr = 0.0000069\n",
      "[16/25][1230/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.020207 lr = 0.0000069\n",
      "[16/25][1240/9765] Loss_D: 0.0989 Loss_G: 0.0358 Convergence: 0.1037 k= 0.020231 lr = 0.0000069\n",
      "[16/25][1250/9765] Loss_D: 0.0933 Loss_G: 0.0381 Convergence: 0.0945 k= 0.020258 lr = 0.0000069\n",
      "[16/25][1260/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0975 k= 0.020266 lr = 0.0000069\n",
      "[16/25][1270/9765] Loss_D: 0.0991 Loss_G: 0.0410 Convergence: 0.1009 k= 0.020253 lr = 0.0000069\n",
      "[16/25][1280/9765] Loss_D: 0.1015 Loss_G: 0.0412 Convergence: 0.1026 k= 0.020240 lr = 0.0000069\n",
      "[16/25][1290/9765] Loss_D: 0.1014 Loss_G: 0.0409 Convergence: 0.1022 k= 0.020218 lr = 0.0000069\n",
      "[16/25][1300/9765] Loss_D: 0.1003 Loss_G: 0.0396 Convergence: 0.1020 k= 0.020204 lr = 0.0000069\n",
      "[16/25][1310/9765] Loss_D: 0.0990 Loss_G: 0.0397 Convergence: 0.1000 k= 0.020194 lr = 0.0000069\n",
      "[16/25][1320/9765] Loss_D: 0.0946 Loss_G: 0.0400 Convergence: 0.0973 k= 0.020181 lr = 0.0000069\n",
      "[16/25][1330/9765] Loss_D: 0.0964 Loss_G: 0.0406 Convergence: 0.0990 k= 0.020177 lr = 0.0000069\n",
      "[16/25][1340/9765] Loss_D: 0.0990 Loss_G: 0.0373 Convergence: 0.1023 k= 0.020192 lr = 0.0000069\n",
      "[16/25][1350/9765] Loss_D: 0.0983 Loss_G: 0.0389 Convergence: 0.0999 k= 0.020201 lr = 0.0000069\n",
      "[16/25][1360/9765] Loss_D: 0.0940 Loss_G: 0.0375 Convergence: 0.0951 k= 0.020204 lr = 0.0000069\n",
      "[16/25][1370/9765] Loss_D: 0.0964 Loss_G: 0.0401 Convergence: 0.0984 k= 0.020203 lr = 0.0000069\n",
      "[16/25][1380/9765] Loss_D: 0.0999 Loss_G: 0.0422 Convergence: 0.1027 k= 0.020177 lr = 0.0000069\n",
      "[16/25][1390/9765] Loss_D: 0.0978 Loss_G: 0.0421 Convergence: 0.1013 k= 0.020145 lr = 0.0000069\n",
      "[16/25][1400/9765] Loss_D: 0.0940 Loss_G: 0.0407 Convergence: 0.0976 k= 0.020120 lr = 0.0000069\n",
      "[16/25][1410/9765] Loss_D: 0.0956 Loss_G: 0.0407 Convergence: 0.0985 k= 0.020098 lr = 0.0000069\n",
      "[16/25][1420/9765] Loss_D: 0.0887 Loss_G: 0.0402 Convergence: 0.0940 k= 0.020096 lr = 0.0000069\n",
      "[16/25][1430/9765] Loss_D: 0.0938 Loss_G: 0.0391 Convergence: 0.0959 k= 0.020093 lr = 0.0000069\n",
      "[16/25][1440/9765] Loss_D: 0.1037 Loss_G: 0.0394 Convergence: 0.1069 k= 0.020090 lr = 0.0000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][1450/9765] Loss_D: 0.0987 Loss_G: 0.0401 Convergence: 0.0998 k= 0.020092 lr = 0.0000069\n",
      "[16/25][1460/9765] Loss_D: 0.1041 Loss_G: 0.0397 Convergence: 0.1072 k= 0.020103 lr = 0.0000069\n",
      "[16/25][1470/9765] Loss_D: 0.0928 Loss_G: 0.0400 Convergence: 0.0962 k= 0.020092 lr = 0.0000069\n",
      "[16/25][1480/9765] Loss_D: 0.0951 Loss_G: 0.0390 Convergence: 0.0966 k= 0.020093 lr = 0.0000069\n",
      "[16/25][1490/9765] Loss_D: 0.0918 Loss_G: 0.0374 Convergence: 0.0930 k= 0.020092 lr = 0.0000069\n",
      "[16/25][1500/9765] Loss_D: 0.1009 Loss_G: 0.0384 Convergence: 0.1040 k= 0.020101 lr = 0.0000069\n",
      "[16/25][1510/9765] Loss_D: 0.0985 Loss_G: 0.0402 Convergence: 0.0997 k= 0.020092 lr = 0.0000069\n",
      "[16/25][1520/9765] Loss_D: 0.0893 Loss_G: 0.0395 Convergence: 0.0936 k= 0.020091 lr = 0.0000069\n",
      "[16/25][1530/9765] Loss_D: 0.0887 Loss_G: 0.0407 Convergence: 0.0944 k= 0.020082 lr = 0.0000069\n",
      "[16/25][1540/9765] Loss_D: 0.0958 Loss_G: 0.0385 Convergence: 0.0967 k= 0.020081 lr = 0.0000069\n",
      "[16/25][1550/9765] Loss_D: 0.0876 Loss_G: 0.0382 Convergence: 0.0912 k= 0.020086 lr = 0.0000069\n",
      "[16/25][1560/9765] Loss_D: 0.0983 Loss_G: 0.0395 Convergence: 0.0993 k= 0.020081 lr = 0.0000069\n",
      "[16/25][1570/9765] Loss_D: 0.0928 Loss_G: 0.0376 Convergence: 0.0938 k= 0.020077 lr = 0.0000069\n",
      "[16/25][1580/9765] Loss_D: 0.0998 Loss_G: 0.0392 Convergence: 0.1016 k= 0.020076 lr = 0.0000069\n",
      "[16/25][1590/9765] Loss_D: 0.0965 Loss_G: 0.0391 Convergence: 0.0975 k= 0.020088 lr = 0.0000069\n",
      "[16/25][1600/9765] Loss_D: 0.0911 Loss_G: 0.0391 Convergence: 0.0942 k= 0.020084 lr = 0.0000069\n",
      "[16/25][1610/9765] Loss_D: 0.0906 Loss_G: 0.0376 Convergence: 0.0924 k= 0.020078 lr = 0.0000069\n",
      "[16/25][1620/9765] Loss_D: 0.0995 Loss_G: 0.0406 Convergence: 0.1008 k= 0.020085 lr = 0.0000069\n",
      "[16/25][1630/9765] Loss_D: 0.0911 Loss_G: 0.0393 Convergence: 0.0944 k= 0.020080 lr = 0.0000069\n",
      "[16/25][1640/9765] Loss_D: 0.0925 Loss_G: 0.0380 Convergence: 0.0940 k= 0.020078 lr = 0.0000069\n",
      "[16/25][1650/9765] Loss_D: 0.0867 Loss_G: 0.0401 Convergence: 0.0926 k= 0.020059 lr = 0.0000069\n",
      "[16/25][1660/9765] Loss_D: 0.0955 Loss_G: 0.0373 Convergence: 0.0974 k= 0.020045 lr = 0.0000069\n",
      "[16/25][1670/9765] Loss_D: 0.0860 Loss_G: 0.0400 Convergence: 0.0921 k= 0.020039 lr = 0.0000069\n",
      "[16/25][1680/9765] Loss_D: 0.0998 Loss_G: 0.0393 Convergence: 0.1016 k= 0.020033 lr = 0.0000069\n",
      "[16/25][1690/9765] Loss_D: 0.0983 Loss_G: 0.0407 Convergence: 0.1002 k= 0.020032 lr = 0.0000069\n",
      "[16/25][1700/9765] Loss_D: 0.1032 Loss_G: 0.0406 Convergence: 0.1050 k= 0.020025 lr = 0.0000069\n",
      "[16/25][1710/9765] Loss_D: 0.1046 Loss_G: 0.0384 Convergence: 0.1092 k= 0.020016 lr = 0.0000069\n",
      "[16/25][1720/9765] Loss_D: 0.1088 Loss_G: 0.0390 Convergence: 0.1144 k= 0.020027 lr = 0.0000069\n",
      "[16/25][1730/9765] Loss_D: 0.0868 Loss_G: 0.0383 Convergence: 0.0909 k= 0.020024 lr = 0.0000069\n",
      "[16/25][1740/9765] Loss_D: 0.0995 Loss_G: 0.0408 Convergence: 0.1009 k= 0.020011 lr = 0.0000069\n",
      "[16/25][1750/9765] Loss_D: 0.0906 Loss_G: 0.0379 Convergence: 0.0927 k= 0.020014 lr = 0.0000069\n",
      "[16/25][1760/9765] Loss_D: 0.0982 Loss_G: 0.0379 Convergence: 0.1006 k= 0.020025 lr = 0.0000069\n",
      "[16/25][1770/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1000 k= 0.020042 lr = 0.0000069\n",
      "[16/25][1780/9765] Loss_D: 0.0955 Loss_G: 0.0379 Convergence: 0.0969 k= 0.020055 lr = 0.0000069\n",
      "[16/25][1790/9765] Loss_D: 0.0977 Loss_G: 0.0363 Convergence: 0.1015 k= 0.020066 lr = 0.0000069\n",
      "[16/25][1800/9765] Loss_D: 0.0983 Loss_G: 0.0376 Convergence: 0.1011 k= 0.020076 lr = 0.0000069\n",
      "[16/25][1810/9765] Loss_D: 0.0978 Loss_G: 0.0377 Convergence: 0.1002 k= 0.020081 lr = 0.0000069\n",
      "[16/25][1820/9765] Loss_D: 0.0997 Loss_G: 0.0392 Convergence: 0.1015 k= 0.020087 lr = 0.0000069\n",
      "[16/25][1830/9765] Loss_D: 0.0932 Loss_G: 0.0406 Convergence: 0.0970 k= 0.020084 lr = 0.0000069\n",
      "[16/25][1840/9765] Loss_D: 0.0903 Loss_G: 0.0382 Convergence: 0.0928 k= 0.020088 lr = 0.0000069\n",
      "[16/25][1850/9765] Loss_D: 0.0918 Loss_G: 0.0382 Convergence: 0.0938 k= 0.020082 lr = 0.0000069\n",
      "[16/25][1860/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0964 k= 0.020082 lr = 0.0000069\n",
      "[16/25][1870/9765] Loss_D: 0.0924 Loss_G: 0.0390 Convergence: 0.0949 k= 0.020079 lr = 0.0000069\n",
      "[16/25][1880/9765] Loss_D: 0.0968 Loss_G: 0.0388 Convergence: 0.0978 k= 0.020079 lr = 0.0000069\n",
      "[16/25][1890/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0988 k= 0.020095 lr = 0.0000069\n",
      "[16/25][1900/9765] Loss_D: 0.1074 Loss_G: 0.0389 Convergence: 0.1126 k= 0.020085 lr = 0.0000069\n",
      "[16/25][1910/9765] Loss_D: 0.1037 Loss_G: 0.0381 Convergence: 0.1083 k= 0.020080 lr = 0.0000069\n",
      "[16/25][1920/9765] Loss_D: 0.0952 Loss_G: 0.0383 Convergence: 0.0961 k= 0.020079 lr = 0.0000069\n",
      "[16/25][1930/9765] Loss_D: 0.0930 Loss_G: 0.0381 Convergence: 0.0943 k= 0.020082 lr = 0.0000069\n",
      "[16/25][1940/9765] Loss_D: 0.1026 Loss_G: 0.0406 Convergence: 0.1042 k= 0.020093 lr = 0.0000069\n",
      "[16/25][1950/9765] Loss_D: 0.0979 Loss_G: 0.0409 Convergence: 0.1002 k= 0.020064 lr = 0.0000069\n",
      "[16/25][1960/9765] Loss_D: 0.0974 Loss_G: 0.0398 Convergence: 0.0987 k= 0.020038 lr = 0.0000069\n",
      "[16/25][1970/9765] Loss_D: 0.1020 Loss_G: 0.0419 Convergence: 0.1036 k= 0.020020 lr = 0.0000069\n",
      "[16/25][1980/9765] Loss_D: 0.0972 Loss_G: 0.0399 Convergence: 0.0987 k= 0.020010 lr = 0.0000069\n",
      "[16/25][1990/9765] Loss_D: 0.0950 Loss_G: 0.0384 Convergence: 0.0959 k= 0.020024 lr = 0.0000069\n",
      "[16/25][2000/9765] Loss_D: 0.0969 Loss_G: 0.0383 Convergence: 0.0985 k= 0.020036 lr = 0.0000069\n",
      "[16/25][2010/9765] Loss_D: 0.0852 Loss_G: 0.0359 Convergence: 0.0874 k= 0.020046 lr = 0.0000069\n",
      "[16/25][2020/9765] Loss_D: 0.1070 Loss_G: 0.0391 Convergence: 0.1117 k= 0.020065 lr = 0.0000069\n",
      "[16/25][2030/9765] Loss_D: 0.1003 Loss_G: 0.0379 Convergence: 0.1036 k= 0.020066 lr = 0.0000069\n",
      "[16/25][2040/9765] Loss_D: 0.1024 Loss_G: 0.0390 Convergence: 0.1054 k= 0.020067 lr = 0.0000069\n",
      "[16/25][2050/9765] Loss_D: 0.1025 Loss_G: 0.0409 Convergence: 0.1038 k= 0.020061 lr = 0.0000069\n",
      "[16/25][2060/9765] Loss_D: 0.1019 Loss_G: 0.0420 Convergence: 0.1037 k= 0.020017 lr = 0.0000069\n",
      "[16/25][2070/9765] Loss_D: 0.0999 Loss_G: 0.0373 Convergence: 0.1036 k= 0.019998 lr = 0.0000069\n",
      "[16/25][2080/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0986 k= 0.020003 lr = 0.0000069\n",
      "[16/25][2090/9765] Loss_D: 0.0973 Loss_G: 0.0385 Convergence: 0.0989 k= 0.019995 lr = 0.0000069\n",
      "[16/25][2100/9765] Loss_D: 0.1004 Loss_G: 0.0379 Convergence: 0.1037 k= 0.019995 lr = 0.0000069\n",
      "[16/25][2110/9765] Loss_D: 0.1036 Loss_G: 0.0387 Convergence: 0.1074 k= 0.020012 lr = 0.0000069\n",
      "[16/25][2120/9765] Loss_D: 0.1023 Loss_G: 0.0402 Convergence: 0.1041 k= 0.020023 lr = 0.0000069\n",
      "[16/25][2130/9765] Loss_D: 0.0990 Loss_G: 0.0384 Convergence: 0.1012 k= 0.020016 lr = 0.0000069\n",
      "[16/25][2140/9765] Loss_D: 0.0930 Loss_G: 0.0408 Convergence: 0.0971 k= 0.020008 lr = 0.0000069\n",
      "[16/25][2150/9765] Loss_D: 0.0983 Loss_G: 0.0411 Convergence: 0.1006 k= 0.019992 lr = 0.0000069\n",
      "[16/25][2160/9765] Loss_D: 0.0931 Loss_G: 0.0413 Convergence: 0.0977 k= 0.019969 lr = 0.0000069\n",
      "[16/25][2170/9765] Loss_D: 0.0986 Loss_G: 0.0401 Convergence: 0.0998 k= 0.019967 lr = 0.0000069\n",
      "[16/25][2180/9765] Loss_D: 0.0953 Loss_G: 0.0393 Convergence: 0.0970 k= 0.019962 lr = 0.0000069\n",
      "[16/25][2190/9765] Loss_D: 0.0988 Loss_G: 0.0365 Convergence: 0.1029 k= 0.019962 lr = 0.0000069\n",
      "[16/25][2200/9765] Loss_D: 0.0892 Loss_G: 0.0387 Convergence: 0.0928 k= 0.019979 lr = 0.0000069\n",
      "[16/25][2210/9765] Loss_D: 0.0991 Loss_G: 0.0383 Convergence: 0.1015 k= 0.019979 lr = 0.0000069\n",
      "[16/25][2220/9765] Loss_D: 0.0953 Loss_G: 0.0371 Convergence: 0.0974 k= 0.019985 lr = 0.0000069\n",
      "[16/25][2230/9765] Loss_D: 0.0957 Loss_G: 0.0400 Convergence: 0.0979 k= 0.019980 lr = 0.0000069\n",
      "[16/25][2240/9765] Loss_D: 0.1011 Loss_G: 0.0399 Convergence: 0.1028 k= 0.019966 lr = 0.0000069\n",
      "[16/25][2250/9765] Loss_D: 0.0969 Loss_G: 0.0390 Convergence: 0.0978 k= 0.019954 lr = 0.0000069\n",
      "[16/25][2260/9765] Loss_D: 0.0991 Loss_G: 0.0409 Convergence: 0.1008 k= 0.019937 lr = 0.0000069\n",
      "[16/25][2270/9765] Loss_D: 0.0892 Loss_G: 0.0386 Convergence: 0.0925 k= 0.019925 lr = 0.0000069\n",
      "[16/25][2280/9765] Loss_D: 0.1112 Loss_G: 0.0415 Convergence: 0.1153 k= 0.019921 lr = 0.0000069\n",
      "[16/25][2290/9765] Loss_D: 0.0957 Loss_G: 0.0397 Convergence: 0.0976 k= 0.019910 lr = 0.0000069\n",
      "[16/25][2300/9765] Loss_D: 0.0970 Loss_G: 0.0391 Convergence: 0.0978 k= 0.019916 lr = 0.0000069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][2310/9765] Loss_D: 0.0939 Loss_G: 0.0355 Convergence: 0.0969 k= 0.019922 lr = 0.0000069\n",
      "[16/25][2320/9765] Loss_D: 0.0944 Loss_G: 0.0380 Convergence: 0.0953 k= 0.019932 lr = 0.0000069\n",
      "[16/25][2330/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1010 k= 0.019946 lr = 0.0000069\n",
      "[16/25][2340/9765] Loss_D: 0.0923 Loss_G: 0.0406 Convergence: 0.0964 k= 0.019929 lr = 0.0000069\n",
      "[16/25][2350/9765] Loss_D: 0.1001 Loss_G: 0.0413 Convergence: 0.1018 k= 0.019908 lr = 0.0000069\n",
      "[16/25][2360/9765] Loss_D: 0.0881 Loss_G: 0.0384 Convergence: 0.0917 k= 0.019895 lr = 0.0000069\n",
      "[16/25][2370/9765] Loss_D: 0.0896 Loss_G: 0.0400 Convergence: 0.0942 k= 0.019894 lr = 0.0000069\n",
      "[16/25][2380/9765] Loss_D: 0.1015 Loss_G: 0.0408 Convergence: 0.1023 k= 0.019894 lr = 0.0000069\n",
      "[16/25][2390/9765] Loss_D: 0.1049 Loss_G: 0.0406 Convergence: 0.1074 k= 0.019876 lr = 0.0000069\n",
      "[16/25][2400/9765] Loss_D: 0.0936 Loss_G: 0.0382 Convergence: 0.0949 k= 0.019860 lr = 0.0000069\n",
      "[16/25][2410/9765] Loss_D: 0.0992 Loss_G: 0.0368 Convergence: 0.1031 k= 0.019864 lr = 0.0000069\n",
      "[16/25][2420/9765] Loss_D: 0.0958 Loss_G: 0.0387 Convergence: 0.0966 k= 0.019877 lr = 0.0000069\n",
      "[16/25][2430/9765] Loss_D: 0.1055 Loss_G: 0.0387 Convergence: 0.1101 k= 0.019884 lr = 0.0000069\n",
      "[16/25][2440/9765] Loss_D: 0.1040 Loss_G: 0.0405 Convergence: 0.1062 k= 0.019886 lr = 0.0000069\n",
      "[16/25][2450/9765] Loss_D: 0.0874 Loss_G: 0.0380 Convergence: 0.0909 k= 0.019894 lr = 0.0000069\n",
      "[16/25][2460/9765] Loss_D: 0.1021 Loss_G: 0.0367 Convergence: 0.1073 k= 0.019921 lr = 0.0000069\n",
      "[16/25][2470/9765] Loss_D: 0.0921 Loss_G: 0.0380 Convergence: 0.0937 k= 0.019921 lr = 0.0000069\n",
      "[16/25][2480/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0970 k= 0.019922 lr = 0.0000069\n",
      "[16/25][2490/9765] Loss_D: 0.1028 Loss_G: 0.0400 Convergence: 0.1051 k= 0.019917 lr = 0.0000069\n",
      "[16/25][2500/9765] Loss_D: 0.0961 Loss_G: 0.0404 Convergence: 0.0985 k= 0.019910 lr = 0.0000069\n",
      "[16/25][2510/9765] Loss_D: 0.1059 Loss_G: 0.0389 Convergence: 0.1103 k= 0.019916 lr = 0.0000069\n",
      "[16/25][2520/9765] Loss_D: 0.0913 Loss_G: 0.0378 Convergence: 0.0930 k= 0.019914 lr = 0.0000069\n",
      "[16/25][2530/9765] Loss_D: 0.0989 Loss_G: 0.0360 Convergence: 0.1036 k= 0.019934 lr = 0.0000069\n",
      "[16/25][2540/9765] Loss_D: 0.0951 Loss_G: 0.0379 Convergence: 0.0964 k= 0.019944 lr = 0.0000069\n",
      "[16/25][2550/9765] Loss_D: 0.0978 Loss_G: 0.0359 Convergence: 0.1020 k= 0.019953 lr = 0.0000069\n",
      "[16/25][2560/9765] Loss_D: 0.0944 Loss_G: 0.0396 Convergence: 0.0967 k= 0.019977 lr = 0.0000069\n",
      "[16/25][2570/9765] Loss_D: 0.0994 Loss_G: 0.0407 Convergence: 0.1009 k= 0.019976 lr = 0.0000069\n",
      "[16/25][2580/9765] Loss_D: 0.0922 Loss_G: 0.0383 Convergence: 0.0941 k= 0.019978 lr = 0.0000069\n",
      "[16/25][2590/9765] Loss_D: 0.0973 Loss_G: 0.0397 Convergence: 0.0986 k= 0.019970 lr = 0.0000069\n",
      "[16/25][2600/9765] Loss_D: 0.1012 Loss_G: 0.0427 Convergence: 0.1039 k= 0.019954 lr = 0.0000069\n",
      "[16/25][2610/9765] Loss_D: 0.1007 Loss_G: 0.0397 Convergence: 0.1024 k= 0.019944 lr = 0.0000069\n",
      "[16/25][2620/9765] Loss_D: 0.0918 Loss_G: 0.0389 Convergence: 0.0945 k= 0.019927 lr = 0.0000069\n",
      "[16/25][2630/9765] Loss_D: 0.0902 Loss_G: 0.0359 Convergence: 0.0914 k= 0.019932 lr = 0.0000069\n",
      "[16/25][2640/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.019933 lr = 0.0000069\n",
      "[16/25][2650/9765] Loss_D: 0.0894 Loss_G: 0.0396 Convergence: 0.0937 k= 0.019925 lr = 0.0000069\n",
      "[16/25][2660/9765] Loss_D: 0.0881 Loss_G: 0.0388 Convergence: 0.0921 k= 0.019926 lr = 0.0000069\n",
      "[16/25][2670/9765] Loss_D: 0.0919 Loss_G: 0.0393 Convergence: 0.0950 k= 0.019926 lr = 0.0000069\n",
      "[16/25][2680/9765] Loss_D: 0.0949 Loss_G: 0.0380 Convergence: 0.0959 k= 0.019945 lr = 0.0000069\n",
      "[16/25][2690/9765] Loss_D: 0.0965 Loss_G: 0.0398 Convergence: 0.0982 k= 0.019949 lr = 0.0000069\n",
      "[16/25][2700/9765] Loss_D: 0.0993 Loss_G: 0.0409 Convergence: 0.1009 k= 0.019948 lr = 0.0000069\n",
      "[16/25][2710/9765] Loss_D: 0.1133 Loss_G: 0.0409 Convergence: 0.1188 k= 0.019954 lr = 0.0000069\n",
      "[16/25][2720/9765] Loss_D: 0.0991 Loss_G: 0.0412 Convergence: 0.1011 k= 0.019947 lr = 0.0000069\n",
      "[16/25][2730/9765] Loss_D: 0.0954 Loss_G: 0.0388 Convergence: 0.0965 k= 0.019944 lr = 0.0000069\n",
      "[16/25][2740/9765] Loss_D: 0.0946 Loss_G: 0.0397 Convergence: 0.0969 k= 0.019935 lr = 0.0000069\n",
      "[16/25][2750/9765] Loss_D: 0.0953 Loss_G: 0.0390 Convergence: 0.0967 k= 0.019935 lr = 0.0000069\n",
      "[16/25][2760/9765] Loss_D: 0.0988 Loss_G: 0.0384 Convergence: 0.1010 k= 0.019933 lr = 0.0000066\n",
      "[16/25][2770/9765] Loss_D: 0.0939 Loss_G: 0.0397 Convergence: 0.0966 k= 0.019924 lr = 0.0000066\n",
      "[16/25][2780/9765] Loss_D: 0.0966 Loss_G: 0.0399 Convergence: 0.0984 k= 0.019917 lr = 0.0000066\n",
      "[16/25][2790/9765] Loss_D: 0.1063 Loss_G: 0.0396 Convergence: 0.1102 k= 0.019915 lr = 0.0000066\n",
      "[16/25][2800/9765] Loss_D: 0.1051 Loss_G: 0.0402 Convergence: 0.1081 k= 0.019920 lr = 0.0000066\n",
      "[16/25][2810/9765] Loss_D: 0.0975 Loss_G: 0.0395 Convergence: 0.0985 k= 0.019929 lr = 0.0000066\n",
      "[16/25][2820/9765] Loss_D: 0.0881 Loss_G: 0.0384 Convergence: 0.0917 k= 0.019925 lr = 0.0000066\n",
      "[16/25][2830/9765] Loss_D: 0.1015 Loss_G: 0.0374 Convergence: 0.1057 k= 0.019945 lr = 0.0000066\n",
      "[16/25][2840/9765] Loss_D: 0.1017 Loss_G: 0.0381 Convergence: 0.1054 k= 0.019948 lr = 0.0000066\n",
      "[16/25][2850/9765] Loss_D: 0.0995 Loss_G: 0.0403 Convergence: 0.1005 k= 0.019946 lr = 0.0000066\n",
      "[16/25][2860/9765] Loss_D: 0.0943 Loss_G: 0.0408 Convergence: 0.0978 k= 0.019932 lr = 0.0000066\n",
      "[16/25][2870/9765] Loss_D: 0.1046 Loss_G: 0.0404 Convergence: 0.1072 k= 0.019923 lr = 0.0000066\n",
      "[16/25][2880/9765] Loss_D: 0.0953 Loss_G: 0.0402 Convergence: 0.0979 k= 0.019918 lr = 0.0000066\n",
      "[16/25][2890/9765] Loss_D: 0.1010 Loss_G: 0.0390 Convergence: 0.1035 k= 0.019908 lr = 0.0000066\n",
      "[16/25][2900/9765] Loss_D: 0.0912 Loss_G: 0.0378 Convergence: 0.0930 k= 0.019899 lr = 0.0000066\n",
      "[16/25][2910/9765] Loss_D: 0.1040 Loss_G: 0.0403 Convergence: 0.1065 k= 0.019903 lr = 0.0000066\n",
      "[16/25][2920/9765] Loss_D: 0.0983 Loss_G: 0.0417 Convergence: 0.1012 k= 0.019906 lr = 0.0000066\n",
      "[16/25][2930/9765] Loss_D: 0.1017 Loss_G: 0.0414 Convergence: 0.1029 k= 0.019904 lr = 0.0000066\n",
      "[16/25][2940/9765] Loss_D: 0.0893 Loss_G: 0.0379 Convergence: 0.0919 k= 0.019892 lr = 0.0000066\n",
      "[16/25][2950/9765] Loss_D: 0.1051 Loss_G: 0.0401 Convergence: 0.1081 k= 0.019901 lr = 0.0000066\n",
      "[16/25][2960/9765] Loss_D: 0.0998 Loss_G: 0.0402 Convergence: 0.1007 k= 0.019888 lr = 0.0000066\n",
      "[16/25][2970/9765] Loss_D: 0.0909 Loss_G: 0.0365 Convergence: 0.0918 k= 0.019893 lr = 0.0000066\n",
      "[16/25][2980/9765] Loss_D: 0.0935 Loss_G: 0.0386 Convergence: 0.0951 k= 0.019903 lr = 0.0000066\n",
      "[16/25][2990/9765] Loss_D: 0.0963 Loss_G: 0.0417 Convergence: 0.1000 k= 0.019904 lr = 0.0000066\n",
      "[16/25][3000/9765] Loss_D: 0.0977 Loss_G: 0.0448 Convergence: 0.1039 k= 0.019869 lr = 0.0000066\n",
      "[16/25][3010/9765] Loss_D: 0.0923 Loss_G: 0.0418 Convergence: 0.0977 k= 0.019829 lr = 0.0000066\n",
      "[16/25][3020/9765] Loss_D: 0.0980 Loss_G: 0.0409 Convergence: 0.1002 k= 0.019818 lr = 0.0000066\n",
      "[16/25][3030/9765] Loss_D: 0.0930 Loss_G: 0.0384 Convergence: 0.0946 k= 0.019806 lr = 0.0000066\n",
      "[16/25][3040/9765] Loss_D: 0.1023 Loss_G: 0.0379 Convergence: 0.1064 k= 0.019810 lr = 0.0000066\n",
      "[16/25][3050/9765] Loss_D: 0.0942 Loss_G: 0.0366 Convergence: 0.0963 k= 0.019816 lr = 0.0000066\n",
      "[16/25][3060/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0994 k= 0.019835 lr = 0.0000066\n",
      "[16/25][3070/9765] Loss_D: 0.1020 Loss_G: 0.0390 Convergence: 0.1049 k= 0.019853 lr = 0.0000066\n",
      "[16/25][3080/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0965 k= 0.019871 lr = 0.0000066\n",
      "[16/25][3090/9765] Loss_D: 0.0926 Loss_G: 0.0338 Convergence: 0.0968 k= 0.019885 lr = 0.0000066\n",
      "[16/25][3100/9765] Loss_D: 0.0932 Loss_G: 0.0381 Convergence: 0.0945 k= 0.019910 lr = 0.0000066\n",
      "[16/25][3110/9765] Loss_D: 0.0941 Loss_G: 0.0405 Convergence: 0.0974 k= 0.019909 lr = 0.0000066\n",
      "[16/25][3120/9765] Loss_D: 0.1001 Loss_G: 0.0393 Convergence: 0.1019 k= 0.019896 lr = 0.0000066\n",
      "[16/25][3130/9765] Loss_D: 0.1067 Loss_G: 0.0399 Convergence: 0.1106 k= 0.019883 lr = 0.0000066\n",
      "[16/25][3140/9765] Loss_D: 0.0980 Loss_G: 0.0402 Convergence: 0.0995 k= 0.019881 lr = 0.0000066\n",
      "[16/25][3150/9765] Loss_D: 0.1007 Loss_G: 0.0396 Convergence: 0.1025 k= 0.019870 lr = 0.0000066\n",
      "[16/25][3160/9765] Loss_D: 0.0910 Loss_G: 0.0388 Convergence: 0.0938 k= 0.019871 lr = 0.0000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][3170/9765] Loss_D: 0.1039 Loss_G: 0.0408 Convergence: 0.1058 k= 0.019854 lr = 0.0000066\n",
      "[16/25][3180/9765] Loss_D: 0.0989 Loss_G: 0.0389 Convergence: 0.1006 k= 0.019849 lr = 0.0000066\n",
      "[16/25][3190/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0994 k= 0.019856 lr = 0.0000066\n",
      "[16/25][3200/9765] Loss_D: 0.0987 Loss_G: 0.0388 Convergence: 0.1005 k= 0.019852 lr = 0.0000066\n",
      "[16/25][3210/9765] Loss_D: 0.0984 Loss_G: 0.0382 Convergence: 0.1006 k= 0.019861 lr = 0.0000066\n",
      "[16/25][3220/9765] Loss_D: 0.0956 Loss_G: 0.0391 Convergence: 0.0969 k= 0.019868 lr = 0.0000066\n",
      "[16/25][3230/9765] Loss_D: 0.0978 Loss_G: 0.0385 Convergence: 0.0995 k= 0.019872 lr = 0.0000066\n",
      "[16/25][3240/9765] Loss_D: 0.0931 Loss_G: 0.0395 Convergence: 0.0958 k= 0.019880 lr = 0.0000066\n",
      "[16/25][3250/9765] Loss_D: 0.1020 Loss_G: 0.0387 Convergence: 0.1052 k= 0.019895 lr = 0.0000066\n",
      "[16/25][3260/9765] Loss_D: 0.0984 Loss_G: 0.0380 Convergence: 0.1007 k= 0.019903 lr = 0.0000066\n",
      "[16/25][3270/9765] Loss_D: 0.0888 Loss_G: 0.0374 Convergence: 0.0911 k= 0.019905 lr = 0.0000066\n",
      "[16/25][3280/9765] Loss_D: 0.0939 Loss_G: 0.0382 Convergence: 0.0950 k= 0.019920 lr = 0.0000066\n",
      "[16/25][3290/9765] Loss_D: 0.0860 Loss_G: 0.0372 Convergence: 0.0892 k= 0.019921 lr = 0.0000066\n",
      "[16/25][3300/9765] Loss_D: 0.0969 Loss_G: 0.0370 Convergence: 0.0997 k= 0.019940 lr = 0.0000066\n",
      "[16/25][3310/9765] Loss_D: 0.0916 Loss_G: 0.0383 Convergence: 0.0938 k= 0.019935 lr = 0.0000066\n",
      "[16/25][3320/9765] Loss_D: 0.0982 Loss_G: 0.0377 Convergence: 0.1008 k= 0.019945 lr = 0.0000066\n",
      "[16/25][3330/9765] Loss_D: 0.0925 Loss_G: 0.0384 Convergence: 0.0944 k= 0.019952 lr = 0.0000066\n",
      "[16/25][3340/9765] Loss_D: 0.1054 Loss_G: 0.0391 Convergence: 0.1095 k= 0.019969 lr = 0.0000066\n",
      "[16/25][3350/9765] Loss_D: 0.1031 Loss_G: 0.0392 Convergence: 0.1062 k= 0.019959 lr = 0.0000066\n",
      "[16/25][3360/9765] Loss_D: 0.0925 Loss_G: 0.0389 Convergence: 0.0948 k= 0.019957 lr = 0.0000066\n",
      "[16/25][3370/9765] Loss_D: 0.0947 Loss_G: 0.0373 Convergence: 0.0963 k= 0.019959 lr = 0.0000066\n",
      "[16/25][3380/9765] Loss_D: 0.1070 Loss_G: 0.0394 Convergence: 0.1115 k= 0.019960 lr = 0.0000066\n",
      "[16/25][3390/9765] Loss_D: 0.0994 Loss_G: 0.0393 Convergence: 0.1010 k= 0.019956 lr = 0.0000066\n",
      "[16/25][3400/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.0988 k= 0.019961 lr = 0.0000066\n",
      "[16/25][3410/9765] Loss_D: 0.1061 Loss_G: 0.0377 Convergence: 0.1119 k= 0.019981 lr = 0.0000066\n",
      "[16/25][3420/9765] Loss_D: 0.1004 Loss_G: 0.0403 Convergence: 0.1014 k= 0.019992 lr = 0.0000066\n",
      "[16/25][3430/9765] Loss_D: 0.0939 Loss_G: 0.0384 Convergence: 0.0952 k= 0.019983 lr = 0.0000066\n",
      "[16/25][3440/9765] Loss_D: 0.0857 Loss_G: 0.0381 Convergence: 0.0900 k= 0.019989 lr = 0.0000066\n",
      "[16/25][3450/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.0996 k= 0.020001 lr = 0.0000066\n",
      "[16/25][3460/9765] Loss_D: 0.1059 Loss_G: 0.0392 Convergence: 0.1102 k= 0.020002 lr = 0.0000066\n",
      "[16/25][3470/9765] Loss_D: 0.0942 Loss_G: 0.0401 Convergence: 0.0971 k= 0.019995 lr = 0.0000066\n",
      "[16/25][3480/9765] Loss_D: 0.0991 Loss_G: 0.0388 Convergence: 0.1010 k= 0.019986 lr = 0.0000066\n",
      "[16/25][3490/9765] Loss_D: 0.0998 Loss_G: 0.0393 Convergence: 0.1015 k= 0.019985 lr = 0.0000066\n",
      "[16/25][3500/9765] Loss_D: 0.0986 Loss_G: 0.0374 Convergence: 0.1016 k= 0.019996 lr = 0.0000066\n",
      "[16/25][3510/9765] Loss_D: 0.0983 Loss_G: 0.0388 Convergence: 0.0999 k= 0.019992 lr = 0.0000066\n",
      "[16/25][3520/9765] Loss_D: 0.0917 Loss_G: 0.0373 Convergence: 0.0928 k= 0.020001 lr = 0.0000066\n",
      "[16/25][3530/9765] Loss_D: 0.0960 Loss_G: 0.0390 Convergence: 0.0971 k= 0.020005 lr = 0.0000066\n",
      "[16/25][3540/9765] Loss_D: 0.0987 Loss_G: 0.0371 Convergence: 0.1020 k= 0.020017 lr = 0.0000066\n",
      "[16/25][3550/9765] Loss_D: 0.0991 Loss_G: 0.0394 Convergence: 0.1004 k= 0.020029 lr = 0.0000066\n",
      "[16/25][3560/9765] Loss_D: 0.0944 Loss_G: 0.0408 Convergence: 0.0979 k= 0.020034 lr = 0.0000066\n",
      "[16/25][3570/9765] Loss_D: 0.0908 Loss_G: 0.0393 Convergence: 0.0943 k= 0.020020 lr = 0.0000066\n",
      "[16/25][3580/9765] Loss_D: 0.0973 Loss_G: 0.0400 Convergence: 0.0988 k= 0.020013 lr = 0.0000066\n",
      "[16/25][3590/9765] Loss_D: 0.1017 Loss_G: 0.0388 Convergence: 0.1046 k= 0.019998 lr = 0.0000066\n",
      "[16/25][3600/9765] Loss_D: 0.0958 Loss_G: 0.0415 Convergence: 0.0995 k= 0.020000 lr = 0.0000066\n",
      "[16/25][3610/9765] Loss_D: 0.0929 Loss_G: 0.0384 Convergence: 0.0946 k= 0.019997 lr = 0.0000066\n",
      "[16/25][3620/9765] Loss_D: 0.0934 Loss_G: 0.0384 Convergence: 0.0949 k= 0.019999 lr = 0.0000066\n",
      "[16/25][3630/9765] Loss_D: 0.1036 Loss_G: 0.0390 Convergence: 0.1071 k= 0.020004 lr = 0.0000066\n",
      "[16/25][3640/9765] Loss_D: 0.0910 Loss_G: 0.0381 Convergence: 0.0932 k= 0.019995 lr = 0.0000066\n",
      "[16/25][3650/9765] Loss_D: 0.0956 Loss_G: 0.0379 Convergence: 0.0970 k= 0.019994 lr = 0.0000066\n",
      "[16/25][3660/9765] Loss_D: 0.0906 Loss_G: 0.0375 Convergence: 0.0923 k= 0.019995 lr = 0.0000066\n",
      "[16/25][3670/9765] Loss_D: 0.0952 Loss_G: 0.0378 Convergence: 0.0966 k= 0.020014 lr = 0.0000066\n",
      "[16/25][3680/9765] Loss_D: 0.1036 Loss_G: 0.0382 Convergence: 0.1079 k= 0.020009 lr = 0.0000066\n",
      "[16/25][3690/9765] Loss_D: 0.1011 Loss_G: 0.0392 Convergence: 0.1035 k= 0.020006 lr = 0.0000066\n",
      "[16/25][3700/9765] Loss_D: 0.1014 Loss_G: 0.0387 Convergence: 0.1043 k= 0.020008 lr = 0.0000066\n",
      "[16/25][3710/9765] Loss_D: 0.1033 Loss_G: 0.0389 Convergence: 0.1067 k= 0.020011 lr = 0.0000066\n",
      "[16/25][3720/9765] Loss_D: 0.0988 Loss_G: 0.0394 Convergence: 0.1001 k= 0.020015 lr = 0.0000066\n",
      "[16/25][3730/9765] Loss_D: 0.0924 Loss_G: 0.0396 Convergence: 0.0955 k= 0.019998 lr = 0.0000066\n",
      "[16/25][3740/9765] Loss_D: 0.0894 Loss_G: 0.0376 Convergence: 0.0917 k= 0.019995 lr = 0.0000066\n",
      "[16/25][3750/9765] Loss_D: 0.0994 Loss_G: 0.0398 Convergence: 0.1004 k= 0.020013 lr = 0.0000066\n",
      "[16/25][3760/9765] Loss_D: 0.0889 Loss_G: 0.0378 Convergence: 0.0916 k= 0.020017 lr = 0.0000066\n",
      "[16/25][3770/9765] Loss_D: 0.0963 Loss_G: 0.0376 Convergence: 0.0983 k= 0.020033 lr = 0.0000066\n",
      "[16/25][3780/9765] Loss_D: 0.0977 Loss_G: 0.0374 Convergence: 0.1004 k= 0.020044 lr = 0.0000066\n",
      "[16/25][3790/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0941 k= 0.020046 lr = 0.0000066\n",
      "[16/25][3800/9765] Loss_D: 0.1046 Loss_G: 0.0377 Convergence: 0.1099 k= 0.020049 lr = 0.0000066\n",
      "[16/25][3810/9765] Loss_D: 0.1101 Loss_G: 0.0397 Convergence: 0.1155 k= 0.020031 lr = 0.0000066\n",
      "[16/25][3820/9765] Loss_D: 0.0876 Loss_G: 0.0376 Convergence: 0.0906 k= 0.020016 lr = 0.0000066\n",
      "[16/25][3830/9765] Loss_D: 0.0955 Loss_G: 0.0387 Convergence: 0.0965 k= 0.020006 lr = 0.0000066\n",
      "[16/25][3840/9765] Loss_D: 0.1021 Loss_G: 0.0399 Convergence: 0.1042 k= 0.019990 lr = 0.0000066\n",
      "[16/25][3850/9765] Loss_D: 0.1004 Loss_G: 0.0386 Convergence: 0.1031 k= 0.019989 lr = 0.0000066\n",
      "[16/25][3860/9765] Loss_D: 0.0945 Loss_G: 0.0396 Convergence: 0.0968 k= 0.019977 lr = 0.0000066\n",
      "[16/25][3870/9765] Loss_D: 0.0991 Loss_G: 0.0414 Convergence: 0.1013 k= 0.019971 lr = 0.0000066\n",
      "[16/25][3880/9765] Loss_D: 0.0992 Loss_G: 0.0368 Convergence: 0.1032 k= 0.019965 lr = 0.0000066\n",
      "[16/25][3890/9765] Loss_D: 0.0971 Loss_G: 0.0376 Convergence: 0.0993 k= 0.019975 lr = 0.0000066\n",
      "[16/25][3900/9765] Loss_D: 0.0940 Loss_G: 0.0381 Convergence: 0.0950 k= 0.019991 lr = 0.0000066\n",
      "[16/25][3910/9765] Loss_D: 0.0954 Loss_G: 0.0381 Convergence: 0.0966 k= 0.020007 lr = 0.0000066\n",
      "[16/25][3920/9765] Loss_D: 0.1154 Loss_G: 0.0414 Convergence: 0.1213 k= 0.020014 lr = 0.0000066\n",
      "[16/25][3930/9765] Loss_D: 0.0880 Loss_G: 0.0415 Convergence: 0.0948 k= 0.019989 lr = 0.0000066\n",
      "[16/25][3940/9765] Loss_D: 0.0913 Loss_G: 0.0391 Convergence: 0.0944 k= 0.019966 lr = 0.0000066\n",
      "[16/25][3950/9765] Loss_D: 0.0930 Loss_G: 0.0417 Convergence: 0.0979 k= 0.019951 lr = 0.0000066\n",
      "[16/25][3960/9765] Loss_D: 0.0976 Loss_G: 0.0416 Convergence: 0.1007 k= 0.019924 lr = 0.0000066\n",
      "[16/25][3970/9765] Loss_D: 0.0969 Loss_G: 0.0410 Convergence: 0.0997 k= 0.019894 lr = 0.0000066\n",
      "[16/25][3980/9765] Loss_D: 0.1007 Loss_G: 0.0410 Convergence: 0.1019 k= 0.019873 lr = 0.0000066\n",
      "[16/25][3990/9765] Loss_D: 0.0917 Loss_G: 0.0404 Convergence: 0.0959 k= 0.019858 lr = 0.0000066\n",
      "[16/25][4000/9765] Loss_D: 0.0847 Loss_G: 0.0374 Convergence: 0.0886 k= 0.019852 lr = 0.0000066\n",
      "[16/25][4010/9765] Loss_D: 0.0939 Loss_G: 0.0384 Convergence: 0.0952 k= 0.019854 lr = 0.0000066\n",
      "[16/25][4020/9765] Loss_D: 0.0971 Loss_G: 0.0382 Convergence: 0.0988 k= 0.019867 lr = 0.0000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][4030/9765] Loss_D: 0.0954 Loss_G: 0.0341 Convergence: 0.1004 k= 0.019889 lr = 0.0000066\n",
      "[16/25][4040/9765] Loss_D: 0.0978 Loss_G: 0.0369 Convergence: 0.1011 k= 0.019933 lr = 0.0000066\n",
      "[16/25][4050/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0952 k= 0.019944 lr = 0.0000066\n",
      "[16/25][4060/9765] Loss_D: 0.1077 Loss_G: 0.0397 Convergence: 0.1121 k= 0.019948 lr = 0.0000066\n",
      "[16/25][4070/9765] Loss_D: 0.0912 Loss_G: 0.0380 Convergence: 0.0931 k= 0.019946 lr = 0.0000066\n",
      "[16/25][4080/9765] Loss_D: 0.0945 Loss_G: 0.0413 Convergence: 0.0985 k= 0.019929 lr = 0.0000066\n",
      "[16/25][4090/9765] Loss_D: 0.0933 Loss_G: 0.0398 Convergence: 0.0962 k= 0.019929 lr = 0.0000066\n",
      "[16/25][4100/9765] Loss_D: 0.0961 Loss_G: 0.0397 Convergence: 0.0978 k= 0.019930 lr = 0.0000066\n",
      "[16/25][4110/9765] Loss_D: 0.1065 Loss_G: 0.0396 Convergence: 0.1105 k= 0.019919 lr = 0.0000066\n",
      "[16/25][4120/9765] Loss_D: 0.1019 Loss_G: 0.0386 Convergence: 0.1051 k= 0.019929 lr = 0.0000066\n",
      "[16/25][4130/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1020 k= 0.019923 lr = 0.0000066\n",
      "[16/25][4140/9765] Loss_D: 0.0996 Loss_G: 0.0385 Convergence: 0.1020 k= 0.019919 lr = 0.0000066\n",
      "[16/25][4150/9765] Loss_D: 0.1033 Loss_G: 0.0386 Convergence: 0.1070 k= 0.019928 lr = 0.0000066\n",
      "[16/25][4160/9765] Loss_D: 0.0994 Loss_G: 0.0387 Convergence: 0.1015 k= 0.019945 lr = 0.0000066\n",
      "[16/25][4170/9765] Loss_D: 0.0884 Loss_G: 0.0376 Convergence: 0.0911 k= 0.019958 lr = 0.0000066\n",
      "[16/25][4180/9765] Loss_D: 0.1014 Loss_G: 0.0395 Convergence: 0.1037 k= 0.019963 lr = 0.0000066\n",
      "[16/25][4190/9765] Loss_D: 0.0884 Loss_G: 0.0395 Convergence: 0.0931 k= 0.019981 lr = 0.0000066\n",
      "[16/25][4200/9765] Loss_D: 0.0939 Loss_G: 0.0398 Convergence: 0.0966 k= 0.019970 lr = 0.0000066\n",
      "[16/25][4210/9765] Loss_D: 0.0907 Loss_G: 0.0404 Convergence: 0.0953 k= 0.019950 lr = 0.0000066\n",
      "[16/25][4220/9765] Loss_D: 0.0863 Loss_G: 0.0418 Convergence: 0.0941 k= 0.019921 lr = 0.0000066\n",
      "[16/25][4230/9765] Loss_D: 0.0936 Loss_G: 0.0446 Convergence: 0.1013 k= 0.019884 lr = 0.0000066\n",
      "[16/25][4240/9765] Loss_D: 0.1019 Loss_G: 0.0442 Convergence: 0.1058 k= 0.019835 lr = 0.0000066\n",
      "[16/25][4250/9765] Loss_D: 0.0862 Loss_G: 0.0392 Convergence: 0.0914 k= 0.019824 lr = 0.0000066\n",
      "[16/25][4260/9765] Loss_D: 0.1083 Loss_G: 0.0382 Convergence: 0.1144 k= 0.019845 lr = 0.0000066\n",
      "[16/25][4270/9765] Loss_D: 0.1052 Loss_G: 0.0380 Convergence: 0.1103 k= 0.019863 lr = 0.0000066\n",
      "[16/25][4280/9765] Loss_D: 0.0944 Loss_G: 0.0360 Convergence: 0.0971 k= 0.019893 lr = 0.0000066\n",
      "[16/25][4290/9765] Loss_D: 0.1064 Loss_G: 0.0373 Convergence: 0.1127 k= 0.019922 lr = 0.0000066\n",
      "[16/25][4300/9765] Loss_D: 0.0993 Loss_G: 0.0381 Convergence: 0.1020 k= 0.019930 lr = 0.0000066\n",
      "[16/25][4310/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0991 k= 0.019929 lr = 0.0000066\n",
      "[16/25][4320/9765] Loss_D: 0.0992 Loss_G: 0.0417 Convergence: 0.1018 k= 0.019912 lr = 0.0000066\n",
      "[16/25][4330/9765] Loss_D: 0.0947 Loss_G: 0.0391 Convergence: 0.0964 k= 0.019894 lr = 0.0000066\n",
      "[16/25][4340/9765] Loss_D: 0.0980 Loss_G: 0.0386 Convergence: 0.0997 k= 0.019902 lr = 0.0000066\n",
      "[16/25][4350/9765] Loss_D: 0.1003 Loss_G: 0.0407 Convergence: 0.1014 k= 0.019890 lr = 0.0000066\n",
      "[16/25][4360/9765] Loss_D: 0.0988 Loss_G: 0.0406 Convergence: 0.1004 k= 0.019884 lr = 0.0000066\n",
      "[16/25][4370/9765] Loss_D: 0.1041 Loss_G: 0.0409 Convergence: 0.1059 k= 0.019892 lr = 0.0000066\n",
      "[16/25][4380/9765] Loss_D: 0.1005 Loss_G: 0.0384 Convergence: 0.1033 k= 0.019885 lr = 0.0000066\n",
      "[16/25][4390/9765] Loss_D: 0.0972 Loss_G: 0.0374 Convergence: 0.0998 k= 0.019883 lr = 0.0000066\n",
      "[16/25][4400/9765] Loss_D: 0.0944 Loss_G: 0.0386 Convergence: 0.0957 k= 0.019890 lr = 0.0000066\n",
      "[16/25][4410/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0955 k= 0.019882 lr = 0.0000066\n",
      "[16/25][4420/9765] Loss_D: 0.0998 Loss_G: 0.0392 Convergence: 0.1016 k= 0.019898 lr = 0.0000066\n",
      "[16/25][4430/9765] Loss_D: 0.0961 Loss_G: 0.0394 Convergence: 0.0976 k= 0.019898 lr = 0.0000066\n",
      "[16/25][4440/9765] Loss_D: 0.1054 Loss_G: 0.0396 Convergence: 0.1090 k= 0.019897 lr = 0.0000066\n",
      "[16/25][4450/9765] Loss_D: 0.0898 Loss_G: 0.0360 Convergence: 0.0907 k= 0.019898 lr = 0.0000066\n",
      "[16/25][4460/9765] Loss_D: 0.0879 Loss_G: 0.0400 Convergence: 0.0932 k= 0.019907 lr = 0.0000066\n",
      "[16/25][4470/9765] Loss_D: 0.0952 Loss_G: 0.0381 Convergence: 0.0963 k= 0.019908 lr = 0.0000066\n",
      "[16/25][4480/9765] Loss_D: 0.0928 Loss_G: 0.0392 Convergence: 0.0954 k= 0.019909 lr = 0.0000066\n",
      "[16/25][4490/9765] Loss_D: 0.0991 Loss_G: 0.0376 Convergence: 0.1021 k= 0.019907 lr = 0.0000066\n",
      "[16/25][4500/9765] Loss_D: 0.0997 Loss_G: 0.0374 Convergence: 0.1032 k= 0.019922 lr = 0.0000066\n",
      "[16/25][4510/9765] Loss_D: 0.0955 Loss_G: 0.0389 Convergence: 0.0966 k= 0.019931 lr = 0.0000066\n",
      "[16/25][4520/9765] Loss_D: 0.0926 Loss_G: 0.0414 Convergence: 0.0975 k= 0.019926 lr = 0.0000066\n",
      "[16/25][4530/9765] Loss_D: 0.0925 Loss_G: 0.0388 Convergence: 0.0947 k= 0.019926 lr = 0.0000066\n",
      "[16/25][4540/9765] Loss_D: 0.0947 Loss_G: 0.0393 Convergence: 0.0966 k= 0.019902 lr = 0.0000066\n",
      "[16/25][4550/9765] Loss_D: 0.0953 Loss_G: 0.0401 Convergence: 0.0978 k= 0.019902 lr = 0.0000066\n",
      "[16/25][4560/9765] Loss_D: 0.0871 Loss_G: 0.0406 Convergence: 0.0934 k= 0.019899 lr = 0.0000066\n",
      "[16/25][4570/9765] Loss_D: 0.0921 Loss_G: 0.0388 Convergence: 0.0945 k= 0.019894 lr = 0.0000066\n",
      "[16/25][4580/9765] Loss_D: 0.1050 Loss_G: 0.0388 Convergence: 0.1093 k= 0.019896 lr = 0.0000066\n",
      "[16/25][4590/9765] Loss_D: 0.1041 Loss_G: 0.0382 Convergence: 0.1086 k= 0.019907 lr = 0.0000066\n",
      "[16/25][4600/9765] Loss_D: 0.0891 Loss_G: 0.0382 Convergence: 0.0920 k= 0.019904 lr = 0.0000066\n",
      "[16/25][4610/9765] Loss_D: 0.0994 Loss_G: 0.0402 Convergence: 0.1004 k= 0.019904 lr = 0.0000066\n",
      "[16/25][4620/9765] Loss_D: 0.1000 Loss_G: 0.0391 Convergence: 0.1019 k= 0.019920 lr = 0.0000066\n",
      "[16/25][4630/9765] Loss_D: 0.1034 Loss_G: 0.0383 Convergence: 0.1075 k= 0.019917 lr = 0.0000066\n",
      "[16/25][4640/9765] Loss_D: 0.0998 Loss_G: 0.0379 Convergence: 0.1029 k= 0.019923 lr = 0.0000066\n",
      "[16/25][4650/9765] Loss_D: 0.1063 Loss_G: 0.0408 Convergence: 0.1092 k= 0.019921 lr = 0.0000066\n",
      "[16/25][4660/9765] Loss_D: 0.0923 Loss_G: 0.0440 Convergence: 0.0998 k= 0.019895 lr = 0.0000066\n",
      "[16/25][4670/9765] Loss_D: 0.0891 Loss_G: 0.0407 Convergence: 0.0947 k= 0.019882 lr = 0.0000066\n",
      "[16/25][4680/9765] Loss_D: 0.0998 Loss_G: 0.0418 Convergence: 0.1022 k= 0.019871 lr = 0.0000066\n",
      "[16/25][4690/9765] Loss_D: 0.1028 Loss_G: 0.0402 Convergence: 0.1048 k= 0.019855 lr = 0.0000066\n",
      "[16/25][4700/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0992 k= 0.019857 lr = 0.0000066\n",
      "[16/25][4710/9765] Loss_D: 0.0933 Loss_G: 0.0359 Convergence: 0.0957 k= 0.019861 lr = 0.0000066\n",
      "[16/25][4720/9765] Loss_D: 0.0976 Loss_G: 0.0372 Convergence: 0.1004 k= 0.019874 lr = 0.0000066\n",
      "[16/25][4730/9765] Loss_D: 0.0947 Loss_G: 0.0386 Convergence: 0.0959 k= 0.019892 lr = 0.0000066\n",
      "[16/25][4740/9765] Loss_D: 0.1003 Loss_G: 0.0398 Convergence: 0.1018 k= 0.019897 lr = 0.0000066\n",
      "[16/25][4750/9765] Loss_D: 0.0993 Loss_G: 0.0382 Convergence: 0.1019 k= 0.019896 lr = 0.0000066\n",
      "[16/25][4760/9765] Loss_D: 0.1015 Loss_G: 0.0411 Convergence: 0.1025 k= 0.019883 lr = 0.0000066\n",
      "[16/25][4770/9765] Loss_D: 0.1065 Loss_G: 0.0435 Convergence: 0.1078 k= 0.019866 lr = 0.0000066\n",
      "[16/25][4780/9765] Loss_D: 0.0972 Loss_G: 0.0425 Convergence: 0.1014 k= 0.019832 lr = 0.0000066\n",
      "[16/25][4790/9765] Loss_D: 0.0979 Loss_G: 0.0392 Convergence: 0.0989 k= 0.019808 lr = 0.0000066\n",
      "[16/25][4800/9765] Loss_D: 0.0917 Loss_G: 0.0370 Convergence: 0.0925 k= 0.019806 lr = 0.0000066\n",
      "[16/25][4810/9765] Loss_D: 0.0880 Loss_G: 0.0381 Convergence: 0.0914 k= 0.019803 lr = 0.0000066\n",
      "[16/25][4820/9765] Loss_D: 0.0918 Loss_G: 0.0382 Convergence: 0.0938 k= 0.019812 lr = 0.0000066\n",
      "[16/25][4830/9765] Loss_D: 0.0972 Loss_G: 0.0384 Convergence: 0.0988 k= 0.019809 lr = 0.0000066\n",
      "[16/25][4840/9765] Loss_D: 0.1024 Loss_G: 0.0376 Convergence: 0.1068 k= 0.019822 lr = 0.0000066\n",
      "[16/25][4850/9765] Loss_D: 0.0898 Loss_G: 0.0396 Convergence: 0.0939 k= 0.019825 lr = 0.0000066\n",
      "[16/25][4860/9765] Loss_D: 0.0974 Loss_G: 0.0391 Convergence: 0.0983 k= 0.019831 lr = 0.0000066\n",
      "[16/25][4870/9765] Loss_D: 0.1004 Loss_G: 0.0381 Convergence: 0.1035 k= 0.019830 lr = 0.0000066\n",
      "[16/25][4880/9765] Loss_D: 0.1010 Loss_G: 0.0378 Convergence: 0.1046 k= 0.019837 lr = 0.0000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][4890/9765] Loss_D: 0.0949 Loss_G: 0.0391 Convergence: 0.0965 k= 0.019831 lr = 0.0000066\n",
      "[16/25][4900/9765] Loss_D: 0.1109 Loss_G: 0.0374 Convergence: 0.1189 k= 0.019835 lr = 0.0000066\n",
      "[16/25][4910/9765] Loss_D: 0.0922 Loss_G: 0.0391 Convergence: 0.0948 k= 0.019839 lr = 0.0000066\n",
      "[16/25][4920/9765] Loss_D: 0.0927 Loss_G: 0.0393 Convergence: 0.0955 k= 0.019822 lr = 0.0000066\n",
      "[16/25][4930/9765] Loss_D: 0.0914 Loss_G: 0.0385 Convergence: 0.0938 k= 0.019814 lr = 0.0000066\n",
      "[16/25][4940/9765] Loss_D: 0.0918 Loss_G: 0.0377 Convergence: 0.0932 k= 0.019816 lr = 0.0000066\n",
      "[16/25][4950/9765] Loss_D: 0.0973 Loss_G: 0.0390 Convergence: 0.0984 k= 0.019820 lr = 0.0000066\n",
      "[16/25][4960/9765] Loss_D: 0.0974 Loss_G: 0.0395 Convergence: 0.0984 k= 0.019808 lr = 0.0000066\n",
      "[16/25][4970/9765] Loss_D: 0.1041 Loss_G: 0.0394 Convergence: 0.1073 k= 0.019806 lr = 0.0000066\n",
      "[16/25][4980/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0953 k= 0.019794 lr = 0.0000066\n",
      "[16/25][4990/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1006 k= 0.019793 lr = 0.0000066\n",
      "[16/25][5000/9765] Loss_D: 0.0965 Loss_G: 0.0396 Convergence: 0.0979 k= 0.019799 lr = 0.0000066\n",
      "[16/25][5010/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0969 k= 0.019794 lr = 0.0000066\n",
      "[16/25][5020/9765] Loss_D: 0.0995 Loss_G: 0.0391 Convergence: 0.1013 k= 0.019788 lr = 0.0000066\n",
      "[16/25][5030/9765] Loss_D: 0.0963 Loss_G: 0.0378 Convergence: 0.0982 k= 0.019772 lr = 0.0000066\n",
      "[16/25][5040/9765] Loss_D: 0.0902 Loss_G: 0.0398 Convergence: 0.0943 k= 0.019777 lr = 0.0000066\n",
      "[16/25][5050/9765] Loss_D: 0.0941 Loss_G: 0.0376 Convergence: 0.0953 k= 0.019768 lr = 0.0000066\n",
      "[16/25][5060/9765] Loss_D: 0.1017 Loss_G: 0.0414 Convergence: 0.1029 k= 0.019787 lr = 0.0000066\n",
      "[16/25][5070/9765] Loss_D: 0.0910 Loss_G: 0.0375 Convergence: 0.0926 k= 0.019795 lr = 0.0000066\n",
      "[16/25][5080/9765] Loss_D: 0.0896 Loss_G: 0.0374 Convergence: 0.0915 k= 0.019797 lr = 0.0000066\n",
      "[16/25][5090/9765] Loss_D: 0.1010 Loss_G: 0.0390 Convergence: 0.1035 k= 0.019811 lr = 0.0000066\n",
      "[16/25][5100/9765] Loss_D: 0.1034 Loss_G: 0.0380 Convergence: 0.1078 k= 0.019814 lr = 0.0000066\n",
      "[16/25][5110/9765] Loss_D: 0.0979 Loss_G: 0.0409 Convergence: 0.1001 k= 0.019810 lr = 0.0000066\n",
      "[16/25][5120/9765] Loss_D: 0.0999 Loss_G: 0.0378 Convergence: 0.1031 k= 0.019798 lr = 0.0000066\n",
      "[16/25][5130/9765] Loss_D: 0.1019 Loss_G: 0.0377 Convergence: 0.1060 k= 0.019792 lr = 0.0000066\n",
      "[16/25][5140/9765] Loss_D: 0.0918 Loss_G: 0.0391 Convergence: 0.0946 k= 0.019780 lr = 0.0000066\n",
      "[16/25][5150/9765] Loss_D: 0.1165 Loss_G: 0.0397 Convergence: 0.1245 k= 0.019781 lr = 0.0000066\n",
      "[16/25][5160/9765] Loss_D: 0.0957 Loss_G: 0.0414 Convergence: 0.0994 k= 0.019782 lr = 0.0000066\n",
      "[16/25][5170/9765] Loss_D: 0.0939 Loss_G: 0.0404 Convergence: 0.0972 k= 0.019771 lr = 0.0000066\n",
      "[16/25][5180/9765] Loss_D: 0.0995 Loss_G: 0.0395 Convergence: 0.1009 k= 0.019769 lr = 0.0000066\n",
      "[16/25][5190/9765] Loss_D: 0.0956 Loss_G: 0.0396 Convergence: 0.0974 k= 0.019754 lr = 0.0000066\n",
      "[16/25][5200/9765] Loss_D: 0.0912 Loss_G: 0.0393 Convergence: 0.0945 k= 0.019740 lr = 0.0000066\n",
      "[16/25][5210/9765] Loss_D: 0.0910 Loss_G: 0.0394 Convergence: 0.0945 k= 0.019727 lr = 0.0000066\n",
      "[16/25][5220/9765] Loss_D: 0.0919 Loss_G: 0.0398 Convergence: 0.0954 k= 0.019719 lr = 0.0000066\n",
      "[16/25][5230/9765] Loss_D: 0.0905 Loss_G: 0.0400 Convergence: 0.0948 k= 0.019723 lr = 0.0000066\n",
      "[16/25][5240/9765] Loss_D: 0.0954 Loss_G: 0.0394 Convergence: 0.0971 k= 0.019720 lr = 0.0000066\n",
      "[16/25][5250/9765] Loss_D: 0.1018 Loss_G: 0.0388 Convergence: 0.1048 k= 0.019708 lr = 0.0000066\n",
      "[16/25][5260/9765] Loss_D: 0.0886 Loss_G: 0.0377 Convergence: 0.0913 k= 0.019720 lr = 0.0000066\n",
      "[16/25][5270/9765] Loss_D: 0.0914 Loss_G: 0.0390 Convergence: 0.0943 k= 0.019732 lr = 0.0000066\n",
      "[16/25][5280/9765] Loss_D: 0.0986 Loss_G: 0.0386 Convergence: 0.1004 k= 0.019748 lr = 0.0000066\n",
      "[16/25][5290/9765] Loss_D: 0.1000 Loss_G: 0.0390 Convergence: 0.1021 k= 0.019756 lr = 0.0000066\n",
      "[16/25][5300/9765] Loss_D: 0.1003 Loss_G: 0.0381 Convergence: 0.1034 k= 0.019750 lr = 0.0000066\n",
      "[16/25][5310/9765] Loss_D: 0.0933 Loss_G: 0.0402 Convergence: 0.0966 k= 0.019756 lr = 0.0000066\n",
      "[16/25][5320/9765] Loss_D: 0.0972 Loss_G: 0.0380 Convergence: 0.0991 k= 0.019750 lr = 0.0000066\n",
      "[16/25][5330/9765] Loss_D: 0.1012 Loss_G: 0.0410 Convergence: 0.1022 k= 0.019753 lr = 0.0000066\n",
      "[16/25][5340/9765] Loss_D: 0.0936 Loss_G: 0.0439 Convergence: 0.1005 k= 0.019720 lr = 0.0000066\n",
      "[16/25][5350/9765] Loss_D: 0.0967 Loss_G: 0.0455 Convergence: 0.1041 k= 0.019661 lr = 0.0000066\n",
      "[16/25][5360/9765] Loss_D: 0.0966 Loss_G: 0.0520 Convergence: 0.1105 k= 0.019525 lr = 0.0000066\n",
      "[16/25][5370/9765] Loss_D: 0.0957 Loss_G: 0.0485 Convergence: 0.1065 k= 0.019410 lr = 0.0000066\n",
      "[16/25][5380/9765] Loss_D: 0.1028 Loss_G: 0.0403 Convergence: 0.1047 k= 0.019365 lr = 0.0000066\n",
      "[16/25][5390/9765] Loss_D: 0.1000 Loss_G: 0.0369 Convergence: 0.1041 k= 0.019374 lr = 0.0000066\n",
      "[16/25][5400/9765] Loss_D: 0.1020 Loss_G: 0.0360 Convergence: 0.1078 k= 0.019403 lr = 0.0000066\n",
      "[16/25][5410/9765] Loss_D: 0.0905 Loss_G: 0.0340 Convergence: 0.0936 k= 0.019451 lr = 0.0000066\n",
      "[16/25][5420/9765] Loss_D: 0.0987 Loss_G: 0.0346 Convergence: 0.1046 k= 0.019492 lr = 0.0000066\n",
      "[16/25][5430/9765] Loss_D: 0.0889 Loss_G: 0.0363 Convergence: 0.0901 k= 0.019526 lr = 0.0000066\n",
      "[16/25][5440/9765] Loss_D: 0.0986 Loss_G: 0.0387 Convergence: 0.1004 k= 0.019525 lr = 0.0000066\n",
      "[16/25][5450/9765] Loss_D: 0.0913 Loss_G: 0.0409 Convergence: 0.0962 k= 0.019513 lr = 0.0000066\n",
      "[16/25][5460/9765] Loss_D: 0.0921 Loss_G: 0.0402 Convergence: 0.0959 k= 0.019503 lr = 0.0000066\n",
      "[16/25][5470/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0955 k= 0.019501 lr = 0.0000066\n",
      "[16/25][5480/9765] Loss_D: 0.0994 Loss_G: 0.0391 Convergence: 0.1011 k= 0.019502 lr = 0.0000066\n",
      "[16/25][5490/9765] Loss_D: 0.0992 Loss_G: 0.0368 Convergence: 0.1030 k= 0.019499 lr = 0.0000066\n",
      "[16/25][5500/9765] Loss_D: 0.0842 Loss_G: 0.0400 Convergence: 0.0910 k= 0.019491 lr = 0.0000066\n",
      "[16/25][5510/9765] Loss_D: 0.0975 Loss_G: 0.0392 Convergence: 0.0984 k= 0.019487 lr = 0.0000066\n",
      "[16/25][5520/9765] Loss_D: 0.0991 Loss_G: 0.0410 Convergence: 0.1010 k= 0.019492 lr = 0.0000066\n",
      "[16/25][5530/9765] Loss_D: 0.0905 Loss_G: 0.0391 Convergence: 0.0939 k= 0.019480 lr = 0.0000066\n",
      "[16/25][5540/9765] Loss_D: 0.0911 Loss_G: 0.0387 Convergence: 0.0938 k= 0.019467 lr = 0.0000066\n",
      "[16/25][5550/9765] Loss_D: 0.0945 Loss_G: 0.0374 Convergence: 0.0959 k= 0.019465 lr = 0.0000066\n",
      "[16/25][5560/9765] Loss_D: 0.0998 Loss_G: 0.0405 Convergence: 0.1008 k= 0.019454 lr = 0.0000066\n",
      "[16/25][5570/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0983 k= 0.019451 lr = 0.0000066\n",
      "[16/25][5580/9765] Loss_D: 0.0984 Loss_G: 0.0388 Convergence: 0.1001 k= 0.019450 lr = 0.0000066\n",
      "[16/25][5590/9765] Loss_D: 0.0923 Loss_G: 0.0398 Convergence: 0.0956 k= 0.019450 lr = 0.0000066\n",
      "[16/25][5600/9765] Loss_D: 0.0935 Loss_G: 0.0381 Convergence: 0.0947 k= 0.019438 lr = 0.0000066\n",
      "[16/25][5610/9765] Loss_D: 0.0973 Loss_G: 0.0370 Convergence: 0.1002 k= 0.019455 lr = 0.0000066\n",
      "[16/25][5620/9765] Loss_D: 0.0923 Loss_G: 0.0402 Convergence: 0.0961 k= 0.019466 lr = 0.0000066\n",
      "[16/25][5630/9765] Loss_D: 0.0842 Loss_G: 0.0386 Convergence: 0.0895 k= 0.019450 lr = 0.0000066\n",
      "[16/25][5640/9765] Loss_D: 0.0986 Loss_G: 0.0403 Convergence: 0.0999 k= 0.019438 lr = 0.0000066\n",
      "[16/25][5650/9765] Loss_D: 0.0928 Loss_G: 0.0368 Convergence: 0.0941 k= 0.019434 lr = 0.0000066\n",
      "[16/25][5660/9765] Loss_D: 0.0902 Loss_G: 0.0413 Convergence: 0.0959 k= 0.019445 lr = 0.0000066\n",
      "[16/25][5670/9765] Loss_D: 0.0926 Loss_G: 0.0389 Convergence: 0.0949 k= 0.019444 lr = 0.0000066\n",
      "[16/25][5680/9765] Loss_D: 0.0923 Loss_G: 0.0384 Convergence: 0.0943 k= 0.019444 lr = 0.0000066\n",
      "[16/25][5690/9765] Loss_D: 0.0962 Loss_G: 0.0388 Convergence: 0.0970 k= 0.019448 lr = 0.0000066\n",
      "[16/25][5700/9765] Loss_D: 0.1025 Loss_G: 0.0384 Convergence: 0.1062 k= 0.019442 lr = 0.0000066\n",
      "[16/25][5710/9765] Loss_D: 0.1025 Loss_G: 0.0387 Convergence: 0.1059 k= 0.019451 lr = 0.0000066\n",
      "[16/25][5720/9765] Loss_D: 0.1046 Loss_G: 0.0374 Convergence: 0.1100 k= 0.019461 lr = 0.0000066\n",
      "[16/25][5730/9765] Loss_D: 0.0864 Loss_G: 0.0381 Convergence: 0.0904 k= 0.019463 lr = 0.0000066\n",
      "[16/25][5740/9765] Loss_D: 0.0966 Loss_G: 0.0386 Convergence: 0.0977 k= 0.019454 lr = 0.0000066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][5750/9765] Loss_D: 0.0965 Loss_G: 0.0389 Convergence: 0.0973 k= 0.019456 lr = 0.0000066\n",
      "[16/25][5760/9765] Loss_D: 0.0900 Loss_G: 0.0389 Convergence: 0.0934 k= 0.019446 lr = 0.0000063\n",
      "[16/25][5770/9765] Loss_D: 0.0987 Loss_G: 0.0393 Convergence: 0.1000 k= 0.019453 lr = 0.0000063\n",
      "[16/25][5780/9765] Loss_D: 0.1071 Loss_G: 0.0395 Convergence: 0.1115 k= 0.019455 lr = 0.0000063\n",
      "[16/25][5790/9765] Loss_D: 0.0966 Loss_G: 0.0384 Convergence: 0.0979 k= 0.019455 lr = 0.0000063\n",
      "[16/25][5800/9765] Loss_D: 0.1062 Loss_G: 0.0386 Convergence: 0.1110 k= 0.019459 lr = 0.0000063\n",
      "[16/25][5810/9765] Loss_D: 0.0940 Loss_G: 0.0379 Convergence: 0.0948 k= 0.019472 lr = 0.0000063\n",
      "[16/25][5820/9765] Loss_D: 0.0949 Loss_G: 0.0379 Convergence: 0.0960 k= 0.019495 lr = 0.0000063\n",
      "[16/25][5830/9765] Loss_D: 0.1017 Loss_G: 0.0395 Convergence: 0.1040 k= 0.019499 lr = 0.0000063\n",
      "[16/25][5840/9765] Loss_D: 0.1006 Loss_G: 0.0390 Convergence: 0.1029 k= 0.019478 lr = 0.0000063\n",
      "[16/25][5850/9765] Loss_D: 0.0976 Loss_G: 0.0400 Convergence: 0.0990 k= 0.019469 lr = 0.0000063\n",
      "[16/25][5860/9765] Loss_D: 0.1001 Loss_G: 0.0390 Convergence: 0.1022 k= 0.019470 lr = 0.0000063\n",
      "[16/25][5870/9765] Loss_D: 0.1018 Loss_G: 0.0402 Convergence: 0.1034 k= 0.019469 lr = 0.0000063\n",
      "[16/25][5880/9765] Loss_D: 0.0937 Loss_G: 0.0398 Convergence: 0.0964 k= 0.019460 lr = 0.0000063\n",
      "[16/25][5890/9765] Loss_D: 0.0987 Loss_G: 0.0408 Convergence: 0.1005 k= 0.019458 lr = 0.0000063\n",
      "[16/25][5900/9765] Loss_D: 0.0962 Loss_G: 0.0399 Convergence: 0.0981 k= 0.019445 lr = 0.0000063\n",
      "[16/25][5910/9765] Loss_D: 0.0835 Loss_G: 0.0397 Convergence: 0.0903 k= 0.019425 lr = 0.0000063\n",
      "[16/25][5920/9765] Loss_D: 0.0818 Loss_G: 0.0367 Convergence: 0.0862 k= 0.019412 lr = 0.0000063\n",
      "[16/25][5930/9765] Loss_D: 0.0895 Loss_G: 0.0378 Convergence: 0.0919 k= 0.019423 lr = 0.0000063\n",
      "[16/25][5940/9765] Loss_D: 0.0912 Loss_G: 0.0374 Convergence: 0.0926 k= 0.019435 lr = 0.0000063\n",
      "[16/25][5950/9765] Loss_D: 0.0951 Loss_G: 0.0404 Convergence: 0.0979 k= 0.019443 lr = 0.0000063\n",
      "[16/25][5960/9765] Loss_D: 0.1005 Loss_G: 0.0391 Convergence: 0.1027 k= 0.019438 lr = 0.0000063\n",
      "[16/25][5970/9765] Loss_D: 0.1000 Loss_G: 0.0366 Convergence: 0.1045 k= 0.019444 lr = 0.0000063\n",
      "[16/25][5980/9765] Loss_D: 0.0996 Loss_G: 0.0404 Convergence: 0.1007 k= 0.019450 lr = 0.0000063\n",
      "[16/25][5990/9765] Loss_D: 0.0945 Loss_G: 0.0373 Convergence: 0.0959 k= 0.019456 lr = 0.0000063\n",
      "[16/25][6000/9765] Loss_D: 0.0963 Loss_G: 0.0403 Convergence: 0.0986 k= 0.019466 lr = 0.0000063\n",
      "[16/25][6010/9765] Loss_D: 0.0902 Loss_G: 0.0397 Convergence: 0.0942 k= 0.019457 lr = 0.0000063\n",
      "[16/25][6020/9765] Loss_D: 0.0973 Loss_G: 0.0392 Convergence: 0.0981 k= 0.019441 lr = 0.0000063\n",
      "[16/25][6030/9765] Loss_D: 0.1040 Loss_G: 0.0394 Convergence: 0.1073 k= 0.019437 lr = 0.0000063\n",
      "[16/25][6040/9765] Loss_D: 0.0989 Loss_G: 0.0389 Convergence: 0.1005 k= 0.019437 lr = 0.0000063\n",
      "[16/25][6050/9765] Loss_D: 0.0999 Loss_G: 0.0389 Convergence: 0.1020 k= 0.019442 lr = 0.0000063\n",
      "[16/25][6060/9765] Loss_D: 0.0990 Loss_G: 0.0401 Convergence: 0.0999 k= 0.019432 lr = 0.0000063\n",
      "[16/25][6070/9765] Loss_D: 0.0920 Loss_G: 0.0382 Convergence: 0.0938 k= 0.019423 lr = 0.0000063\n",
      "[16/25][6080/9765] Loss_D: 0.0900 Loss_G: 0.0361 Convergence: 0.0909 k= 0.019424 lr = 0.0000063\n",
      "[16/25][6090/9765] Loss_D: 0.0999 Loss_G: 0.0383 Convergence: 0.1025 k= 0.019437 lr = 0.0000063\n",
      "[16/25][6100/9765] Loss_D: 0.0944 Loss_G: 0.0367 Convergence: 0.0965 k= 0.019442 lr = 0.0000063\n",
      "[16/25][6110/9765] Loss_D: 0.0884 Loss_G: 0.0375 Convergence: 0.0910 k= 0.019455 lr = 0.0000063\n",
      "[16/25][6120/9765] Loss_D: 0.1060 Loss_G: 0.0410 Convergence: 0.1085 k= 0.019459 lr = 0.0000063\n",
      "[16/25][6130/9765] Loss_D: 0.0946 Loss_G: 0.0387 Convergence: 0.0959 k= 0.019447 lr = 0.0000063\n",
      "[16/25][6140/9765] Loss_D: 0.0901 Loss_G: 0.0386 Convergence: 0.0931 k= 0.019453 lr = 0.0000063\n",
      "[16/25][6150/9765] Loss_D: 0.0991 Loss_G: 0.0399 Convergence: 0.1000 k= 0.019442 lr = 0.0000063\n",
      "[16/25][6160/9765] Loss_D: 0.1009 Loss_G: 0.0377 Convergence: 0.1046 k= 0.019432 lr = 0.0000063\n",
      "[16/25][6170/9765] Loss_D: 0.0913 Loss_G: 0.0396 Convergence: 0.0948 k= 0.019426 lr = 0.0000063\n",
      "[16/25][6180/9765] Loss_D: 0.1062 Loss_G: 0.0399 Convergence: 0.1098 k= 0.019429 lr = 0.0000063\n",
      "[16/25][6190/9765] Loss_D: 0.0838 Loss_G: 0.0378 Convergence: 0.0885 k= 0.019438 lr = 0.0000063\n",
      "[16/25][6200/9765] Loss_D: 0.0947 Loss_G: 0.0370 Convergence: 0.0966 k= 0.019450 lr = 0.0000063\n",
      "[16/25][6210/9765] Loss_D: 0.0890 Loss_G: 0.0359 Convergence: 0.0898 k= 0.019464 lr = 0.0000063\n",
      "[16/25][6220/9765] Loss_D: 0.0994 Loss_G: 0.0391 Convergence: 0.1011 k= 0.019477 lr = 0.0000063\n",
      "[16/25][6230/9765] Loss_D: 0.0931 Loss_G: 0.0359 Convergence: 0.0953 k= 0.019494 lr = 0.0000063\n",
      "[16/25][6240/9765] Loss_D: 0.0902 Loss_G: 0.0386 Convergence: 0.0931 k= 0.019505 lr = 0.0000063\n",
      "[16/25][6250/9765] Loss_D: 0.1041 Loss_G: 0.0403 Convergence: 0.1065 k= 0.019508 lr = 0.0000063\n",
      "[16/25][6260/9765] Loss_D: 0.1051 Loss_G: 0.0435 Convergence: 0.1071 k= 0.019476 lr = 0.0000063\n",
      "[16/25][6270/9765] Loss_D: 0.0949 Loss_G: 0.0430 Convergence: 0.1004 k= 0.019442 lr = 0.0000063\n",
      "[16/25][6280/9765] Loss_D: 0.0971 Loss_G: 0.0421 Convergence: 0.1009 k= 0.019414 lr = 0.0000063\n",
      "[16/25][6290/9765] Loss_D: 0.0893 Loss_G: 0.0413 Convergence: 0.0954 k= 0.019376 lr = 0.0000063\n",
      "[16/25][6300/9765] Loss_D: 0.0906 Loss_G: 0.0393 Convergence: 0.0941 k= 0.019367 lr = 0.0000063\n",
      "[16/25][6310/9765] Loss_D: 0.0882 Loss_G: 0.0364 Convergence: 0.0898 k= 0.019381 lr = 0.0000063\n",
      "[16/25][6320/9765] Loss_D: 0.0918 Loss_G: 0.0357 Convergence: 0.0938 k= 0.019402 lr = 0.0000063\n",
      "[16/25][6330/9765] Loss_D: 0.0996 Loss_G: 0.0351 Convergence: 0.1053 k= 0.019441 lr = 0.0000063\n",
      "[16/25][6340/9765] Loss_D: 0.0919 Loss_G: 0.0369 Convergence: 0.0928 k= 0.019467 lr = 0.0000063\n",
      "[16/25][6350/9765] Loss_D: 0.0965 Loss_G: 0.0356 Convergence: 0.1004 k= 0.019490 lr = 0.0000063\n",
      "[16/25][6360/9765] Loss_D: 0.1031 Loss_G: 0.0371 Convergence: 0.1083 k= 0.019508 lr = 0.0000063\n",
      "[16/25][6370/9765] Loss_D: 0.0904 Loss_G: 0.0375 Convergence: 0.0921 k= 0.019513 lr = 0.0000063\n",
      "[16/25][6380/9765] Loss_D: 0.1004 Loss_G: 0.0403 Convergence: 0.1014 k= 0.019514 lr = 0.0000063\n",
      "[16/25][6390/9765] Loss_D: 0.0968 Loss_G: 0.0403 Convergence: 0.0988 k= 0.019505 lr = 0.0000063\n",
      "[16/25][6400/9765] Loss_D: 0.0926 Loss_G: 0.0413 Convergence: 0.0973 k= 0.019501 lr = 0.0000063\n",
      "[16/25][6410/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0947 k= 0.019496 lr = 0.0000063\n",
      "[16/25][6420/9765] Loss_D: 0.0995 Loss_G: 0.0380 Convergence: 0.1024 k= 0.019510 lr = 0.0000063\n",
      "[16/25][6430/9765] Loss_D: 0.0942 Loss_G: 0.0348 Convergence: 0.0980 k= 0.019531 lr = 0.0000063\n",
      "[16/25][6440/9765] Loss_D: 0.0932 Loss_G: 0.0356 Convergence: 0.0959 k= 0.019552 lr = 0.0000063\n",
      "[16/25][6450/9765] Loss_D: 0.0946 Loss_G: 0.0372 Convergence: 0.0963 k= 0.019574 lr = 0.0000063\n",
      "[16/25][6460/9765] Loss_D: 0.1108 Loss_G: 0.0387 Convergence: 0.1175 k= 0.019588 lr = 0.0000063\n",
      "[16/25][6470/9765] Loss_D: 0.0955 Loss_G: 0.0380 Convergence: 0.0967 k= 0.019595 lr = 0.0000063\n",
      "[16/25][6480/9765] Loss_D: 0.0944 Loss_G: 0.0384 Convergence: 0.0955 k= 0.019584 lr = 0.0000063\n",
      "[16/25][6490/9765] Loss_D: 0.0868 Loss_G: 0.0399 Convergence: 0.0924 k= 0.019580 lr = 0.0000063\n",
      "[16/25][6500/9765] Loss_D: 0.0920 Loss_G: 0.0403 Convergence: 0.0960 k= 0.019559 lr = 0.0000063\n",
      "[16/25][6510/9765] Loss_D: 0.0991 Loss_G: 0.0407 Convergence: 0.1007 k= 0.019559 lr = 0.0000063\n",
      "[16/25][6520/9765] Loss_D: 0.1001 Loss_G: 0.0363 Convergence: 0.1049 k= 0.019560 lr = 0.0000063\n",
      "[16/25][6530/9765] Loss_D: 0.0931 Loss_G: 0.0399 Convergence: 0.0962 k= 0.019558 lr = 0.0000063\n",
      "[16/25][6540/9765] Loss_D: 0.1019 Loss_G: 0.0392 Convergence: 0.1045 k= 0.019571 lr = 0.0000063\n",
      "[16/25][6550/9765] Loss_D: 0.0976 Loss_G: 0.0390 Convergence: 0.0987 k= 0.019581 lr = 0.0000063\n",
      "[16/25][6560/9765] Loss_D: 0.0983 Loss_G: 0.0373 Convergence: 0.1015 k= 0.019589 lr = 0.0000063\n",
      "[16/25][6570/9765] Loss_D: 0.0963 Loss_G: 0.0375 Convergence: 0.0983 k= 0.019590 lr = 0.0000063\n",
      "[16/25][6580/9765] Loss_D: 0.1015 Loss_G: 0.0384 Convergence: 0.1047 k= 0.019601 lr = 0.0000063\n",
      "[16/25][6590/9765] Loss_D: 0.1070 Loss_G: 0.0394 Convergence: 0.1114 k= 0.019616 lr = 0.0000063\n",
      "[16/25][6600/9765] Loss_D: 0.1005 Loss_G: 0.0392 Convergence: 0.1025 k= 0.019625 lr = 0.0000063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][6610/9765] Loss_D: 0.0961 Loss_G: 0.0391 Convergence: 0.0972 k= 0.019623 lr = 0.0000063\n",
      "[16/25][6620/9765] Loss_D: 0.0976 Loss_G: 0.0398 Convergence: 0.0989 k= 0.019614 lr = 0.0000063\n",
      "[16/25][6630/9765] Loss_D: 0.0922 Loss_G: 0.0391 Convergence: 0.0949 k= 0.019615 lr = 0.0000063\n",
      "[16/25][6640/9765] Loss_D: 0.0965 Loss_G: 0.0395 Convergence: 0.0979 k= 0.019609 lr = 0.0000063\n",
      "[16/25][6650/9765] Loss_D: 0.1001 Loss_G: 0.0385 Convergence: 0.1027 k= 0.019610 lr = 0.0000063\n",
      "[16/25][6660/9765] Loss_D: 0.0938 Loss_G: 0.0377 Convergence: 0.0947 k= 0.019637 lr = 0.0000063\n",
      "[16/25][6670/9765] Loss_D: 0.0927 Loss_G: 0.0380 Convergence: 0.0941 k= 0.019645 lr = 0.0000063\n",
      "[16/25][6680/9765] Loss_D: 0.0997 Loss_G: 0.0386 Convergence: 0.1021 k= 0.019648 lr = 0.0000063\n",
      "[16/25][6690/9765] Loss_D: 0.0941 Loss_G: 0.0388 Convergence: 0.0957 k= 0.019639 lr = 0.0000063\n",
      "[16/25][6700/9765] Loss_D: 0.0922 Loss_G: 0.0388 Convergence: 0.0946 k= 0.019630 lr = 0.0000063\n",
      "[16/25][6710/9765] Loss_D: 0.0855 Loss_G: 0.0378 Convergence: 0.0896 k= 0.019627 lr = 0.0000063\n",
      "[16/25][6720/9765] Loss_D: 0.0883 Loss_G: 0.0390 Convergence: 0.0924 k= 0.019624 lr = 0.0000063\n",
      "[16/25][6730/9765] Loss_D: 0.0971 Loss_G: 0.0381 Convergence: 0.0989 k= 0.019634 lr = 0.0000063\n",
      "[16/25][6740/9765] Loss_D: 0.1019 Loss_G: 0.0396 Convergence: 0.1041 k= 0.019635 lr = 0.0000063\n",
      "[16/25][6750/9765] Loss_D: 0.0930 Loss_G: 0.0383 Convergence: 0.0945 k= 0.019621 lr = 0.0000063\n",
      "[16/25][6760/9765] Loss_D: 0.0928 Loss_G: 0.0407 Convergence: 0.0968 k= 0.019623 lr = 0.0000063\n",
      "[16/25][6770/9765] Loss_D: 0.0980 Loss_G: 0.0395 Convergence: 0.0988 k= 0.019611 lr = 0.0000063\n",
      "[16/25][6780/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0980 k= 0.019608 lr = 0.0000063\n",
      "[16/25][6790/9765] Loss_D: 0.0947 Loss_G: 0.0383 Convergence: 0.0956 k= 0.019622 lr = 0.0000063\n",
      "[16/25][6800/9765] Loss_D: 0.0949 Loss_G: 0.0379 Convergence: 0.0961 k= 0.019629 lr = 0.0000063\n",
      "[16/25][6810/9765] Loss_D: 0.0996 Loss_G: 0.0386 Convergence: 0.1018 k= 0.019624 lr = 0.0000063\n",
      "[16/25][6820/9765] Loss_D: 0.0875 Loss_G: 0.0389 Convergence: 0.0918 k= 0.019614 lr = 0.0000063\n",
      "[16/25][6830/9765] Loss_D: 0.0967 Loss_G: 0.0373 Convergence: 0.0991 k= 0.019614 lr = 0.0000063\n",
      "[16/25][6840/9765] Loss_D: 0.1058 Loss_G: 0.0387 Convergence: 0.1105 k= 0.019626 lr = 0.0000063\n",
      "[16/25][6850/9765] Loss_D: 0.0982 Loss_G: 0.0390 Convergence: 0.0996 k= 0.019630 lr = 0.0000063\n",
      "[16/25][6860/9765] Loss_D: 0.0971 Loss_G: 0.0395 Convergence: 0.0983 k= 0.019620 lr = 0.0000063\n",
      "[16/25][6870/9765] Loss_D: 0.1019 Loss_G: 0.0388 Convergence: 0.1049 k= 0.019623 lr = 0.0000063\n",
      "[16/25][6880/9765] Loss_D: 0.0983 Loss_G: 0.0385 Convergence: 0.1002 k= 0.019622 lr = 0.0000063\n",
      "[16/25][6890/9765] Loss_D: 0.0963 Loss_G: 0.0376 Convergence: 0.0983 k= 0.019634 lr = 0.0000063\n",
      "[16/25][6900/9765] Loss_D: 0.0949 Loss_G: 0.0384 Convergence: 0.0958 k= 0.019644 lr = 0.0000063\n",
      "[16/25][6910/9765] Loss_D: 0.0973 Loss_G: 0.0375 Convergence: 0.0997 k= 0.019650 lr = 0.0000063\n",
      "[16/25][6920/9765] Loss_D: 0.0913 Loss_G: 0.0379 Convergence: 0.0931 k= 0.019655 lr = 0.0000063\n",
      "[16/25][6930/9765] Loss_D: 0.1027 Loss_G: 0.0404 Convergence: 0.1045 k= 0.019655 lr = 0.0000063\n",
      "[16/25][6940/9765] Loss_D: 0.0972 Loss_G: 0.0388 Convergence: 0.0984 k= 0.019638 lr = 0.0000063\n",
      "[16/25][6950/9765] Loss_D: 0.1040 Loss_G: 0.0402 Convergence: 0.1065 k= 0.019654 lr = 0.0000063\n",
      "[16/25][6960/9765] Loss_D: 0.1082 Loss_G: 0.0386 Convergence: 0.1140 k= 0.019658 lr = 0.0000063\n",
      "[16/25][6970/9765] Loss_D: 0.0954 Loss_G: 0.0398 Convergence: 0.0975 k= 0.019657 lr = 0.0000063\n",
      "[16/25][6980/9765] Loss_D: 0.1082 Loss_G: 0.0377 Convergence: 0.1149 k= 0.019661 lr = 0.0000063\n",
      "[16/25][6990/9765] Loss_D: 0.0949 Loss_G: 0.0392 Convergence: 0.0966 k= 0.019663 lr = 0.0000063\n",
      "[16/25][7000/9765] Loss_D: 0.1008 Loss_G: 0.0391 Convergence: 0.1030 k= 0.019672 lr = 0.0000063\n",
      "[16/25][7010/9765] Loss_D: 0.0944 Loss_G: 0.0380 Convergence: 0.0952 k= 0.019682 lr = 0.0000063\n",
      "[16/25][7020/9765] Loss_D: 0.1041 Loss_G: 0.0389 Convergence: 0.1079 k= 0.019694 lr = 0.0000063\n",
      "[16/25][7030/9765] Loss_D: 0.0968 Loss_G: 0.0387 Convergence: 0.0979 k= 0.019699 lr = 0.0000063\n",
      "[16/25][7040/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0953 k= 0.019697 lr = 0.0000063\n",
      "[16/25][7050/9765] Loss_D: 0.1035 Loss_G: 0.0393 Convergence: 0.1066 k= 0.019706 lr = 0.0000063\n",
      "[16/25][7060/9765] Loss_D: 0.0905 Loss_G: 0.0374 Convergence: 0.0922 k= 0.019700 lr = 0.0000063\n",
      "[16/25][7070/9765] Loss_D: 0.1093 Loss_G: 0.0375 Convergence: 0.1166 k= 0.019721 lr = 0.0000063\n",
      "[16/25][7080/9765] Loss_D: 0.0999 Loss_G: 0.0388 Convergence: 0.1021 k= 0.019747 lr = 0.0000063\n",
      "[16/25][7090/9765] Loss_D: 0.0945 Loss_G: 0.0400 Convergence: 0.0971 k= 0.019738 lr = 0.0000063\n",
      "[16/25][7100/9765] Loss_D: 0.0946 Loss_G: 0.0393 Convergence: 0.0965 k= 0.019741 lr = 0.0000063\n",
      "[16/25][7110/9765] Loss_D: 0.1042 Loss_G: 0.0410 Convergence: 0.1060 k= 0.019744 lr = 0.0000063\n",
      "[16/25][7120/9765] Loss_D: 0.0905 Loss_G: 0.0409 Convergence: 0.0957 k= 0.019746 lr = 0.0000063\n",
      "[16/25][7130/9765] Loss_D: 0.1028 Loss_G: 0.0404 Convergence: 0.1046 k= 0.019735 lr = 0.0000063\n",
      "[16/25][7140/9765] Loss_D: 0.1080 Loss_G: 0.0414 Convergence: 0.1109 k= 0.019732 lr = 0.0000063\n",
      "[16/25][7150/9765] Loss_D: 0.0970 Loss_G: 0.0369 Convergence: 0.1000 k= 0.019731 lr = 0.0000063\n",
      "[16/25][7160/9765] Loss_D: 0.1048 Loss_G: 0.0371 Convergence: 0.1107 k= 0.019747 lr = 0.0000063\n",
      "[16/25][7170/9765] Loss_D: 0.1039 Loss_G: 0.0371 Convergence: 0.1094 k= 0.019764 lr = 0.0000063\n",
      "[16/25][7180/9765] Loss_D: 0.1040 Loss_G: 0.0394 Convergence: 0.1072 k= 0.019775 lr = 0.0000063\n",
      "[16/25][7190/9765] Loss_D: 0.0956 Loss_G: 0.0392 Convergence: 0.0970 k= 0.019780 lr = 0.0000063\n",
      "[16/25][7200/9765] Loss_D: 0.0946 Loss_G: 0.0386 Convergence: 0.0958 k= 0.019770 lr = 0.0000063\n",
      "[16/25][7210/9765] Loss_D: 0.0986 Loss_G: 0.0386 Convergence: 0.1005 k= 0.019773 lr = 0.0000063\n",
      "[16/25][7220/9765] Loss_D: 0.0937 Loss_G: 0.0396 Convergence: 0.0963 k= 0.019774 lr = 0.0000063\n",
      "[16/25][7230/9765] Loss_D: 0.0982 Loss_G: 0.0396 Convergence: 0.0990 k= 0.019777 lr = 0.0000063\n",
      "[16/25][7240/9765] Loss_D: 0.0962 Loss_G: 0.0392 Convergence: 0.0975 k= 0.019767 lr = 0.0000063\n",
      "[16/25][7250/9765] Loss_D: 0.0982 Loss_G: 0.0398 Convergence: 0.0991 k= 0.019762 lr = 0.0000063\n",
      "[16/25][7260/9765] Loss_D: 0.0917 Loss_G: 0.0387 Convergence: 0.0942 k= 0.019761 lr = 0.0000063\n",
      "[16/25][7270/9765] Loss_D: 0.1064 Loss_G: 0.0361 Convergence: 0.1139 k= 0.019781 lr = 0.0000063\n",
      "[16/25][7280/9765] Loss_D: 0.0957 Loss_G: 0.0363 Convergence: 0.0988 k= 0.019801 lr = 0.0000063\n",
      "[16/25][7290/9765] Loss_D: 0.0900 Loss_G: 0.0373 Convergence: 0.0918 k= 0.019830 lr = 0.0000063\n",
      "[16/25][7300/9765] Loss_D: 0.0922 Loss_G: 0.0382 Convergence: 0.0940 k= 0.019844 lr = 0.0000063\n",
      "[16/25][7310/9765] Loss_D: 0.0961 Loss_G: 0.0396 Convergence: 0.0977 k= 0.019836 lr = 0.0000063\n",
      "[16/25][7320/9765] Loss_D: 0.0988 Loss_G: 0.0443 Convergence: 0.1041 k= 0.019804 lr = 0.0000063\n",
      "[16/25][7330/9765] Loss_D: 0.0979 Loss_G: 0.0494 Convergence: 0.1087 k= 0.019717 lr = 0.0000063\n",
      "[16/25][7340/9765] Loss_D: 0.0971 Loss_G: 0.0478 Convergence: 0.1067 k= 0.019615 lr = 0.0000063\n",
      "[16/25][7350/9765] Loss_D: 0.0978 Loss_G: 0.0462 Convergence: 0.1054 k= 0.019534 lr = 0.0000063\n",
      "[16/25][7360/9765] Loss_D: 0.1033 Loss_G: 0.0410 Convergence: 0.1048 k= 0.019489 lr = 0.0000063\n",
      "[16/25][7370/9765] Loss_D: 0.1025 Loss_G: 0.0388 Convergence: 0.1057 k= 0.019495 lr = 0.0000063\n",
      "[16/25][7380/9765] Loss_D: 0.0980 Loss_G: 0.0351 Convergence: 0.1030 k= 0.019518 lr = 0.0000063\n",
      "[16/25][7390/9765] Loss_D: 0.0973 Loss_G: 0.0340 Convergence: 0.1032 k= 0.019567 lr = 0.0000063\n",
      "[16/25][7400/9765] Loss_D: 0.0990 Loss_G: 0.0361 Convergence: 0.1035 k= 0.019606 lr = 0.0000063\n",
      "[16/25][7410/9765] Loss_D: 0.0937 Loss_G: 0.0369 Convergence: 0.0953 k= 0.019629 lr = 0.0000063\n",
      "[16/25][7420/9765] Loss_D: 0.1012 Loss_G: 0.0362 Convergence: 0.1065 k= 0.019647 lr = 0.0000063\n",
      "[16/25][7430/9765] Loss_D: 0.0943 Loss_G: 0.0395 Convergence: 0.0966 k= 0.019656 lr = 0.0000063\n",
      "[16/25][7440/9765] Loss_D: 0.0916 Loss_G: 0.0435 Convergence: 0.0990 k= 0.019631 lr = 0.0000063\n",
      "[16/25][7450/9765] Loss_D: 0.0936 Loss_G: 0.0430 Convergence: 0.0996 k= 0.019603 lr = 0.0000063\n",
      "[16/25][7460/9765] Loss_D: 0.0999 Loss_G: 0.0401 Convergence: 0.1009 k= 0.019586 lr = 0.0000063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][7470/9765] Loss_D: 0.0969 Loss_G: 0.0388 Convergence: 0.0980 k= 0.019575 lr = 0.0000063\n",
      "[16/25][7480/9765] Loss_D: 0.0916 Loss_G: 0.0396 Convergence: 0.0950 k= 0.019587 lr = 0.0000063\n",
      "[16/25][7490/9765] Loss_D: 0.0922 Loss_G: 0.0378 Convergence: 0.0936 k= 0.019604 lr = 0.0000063\n",
      "[16/25][7500/9765] Loss_D: 0.0948 Loss_G: 0.0366 Convergence: 0.0972 k= 0.019614 lr = 0.0000063\n",
      "[16/25][7510/9765] Loss_D: 0.0896 Loss_G: 0.0377 Convergence: 0.0919 k= 0.019629 lr = 0.0000063\n",
      "[16/25][7520/9765] Loss_D: 0.0951 Loss_G: 0.0378 Convergence: 0.0964 k= 0.019651 lr = 0.0000063\n",
      "[16/25][7530/9765] Loss_D: 0.0969 Loss_G: 0.0391 Convergence: 0.0977 k= 0.019658 lr = 0.0000063\n",
      "[16/25][7540/9765] Loss_D: 0.0997 Loss_G: 0.0388 Convergence: 0.1018 k= 0.019664 lr = 0.0000063\n",
      "[16/25][7550/9765] Loss_D: 0.0935 Loss_G: 0.0396 Convergence: 0.0961 k= 0.019667 lr = 0.0000063\n",
      "[16/25][7560/9765] Loss_D: 0.0902 Loss_G: 0.0403 Convergence: 0.0949 k= 0.019661 lr = 0.0000063\n",
      "[16/25][7570/9765] Loss_D: 0.0971 Loss_G: 0.0409 Convergence: 0.0996 k= 0.019656 lr = 0.0000063\n",
      "[16/25][7580/9765] Loss_D: 0.1011 Loss_G: 0.0391 Convergence: 0.1035 k= 0.019640 lr = 0.0000063\n",
      "[16/25][7590/9765] Loss_D: 0.0941 Loss_G: 0.0407 Convergence: 0.0977 k= 0.019625 lr = 0.0000063\n",
      "[16/25][7600/9765] Loss_D: 0.0914 Loss_G: 0.0408 Convergence: 0.0961 k= 0.019600 lr = 0.0000063\n",
      "[16/25][7610/9765] Loss_D: 0.1142 Loss_G: 0.0424 Convergence: 0.1186 k= 0.019578 lr = 0.0000063\n",
      "[16/25][7620/9765] Loss_D: 0.0991 Loss_G: 0.0401 Convergence: 0.1000 k= 0.019565 lr = 0.0000063\n",
      "[16/25][7630/9765] Loss_D: 0.0916 Loss_G: 0.0398 Convergence: 0.0952 k= 0.019557 lr = 0.0000063\n",
      "[16/25][7640/9765] Loss_D: 0.0928 Loss_G: 0.0394 Convergence: 0.0956 k= 0.019565 lr = 0.0000063\n",
      "[16/25][7650/9765] Loss_D: 0.1017 Loss_G: 0.0410 Convergence: 0.1026 k= 0.019571 lr = 0.0000063\n",
      "[16/25][7660/9765] Loss_D: 0.0953 Loss_G: 0.0356 Convergence: 0.0987 k= 0.019586 lr = 0.0000063\n",
      "[16/25][7670/9765] Loss_D: 0.0961 Loss_G: 0.0386 Convergence: 0.0971 k= 0.019606 lr = 0.0000063\n",
      "[16/25][7680/9765] Loss_D: 0.0878 Loss_G: 0.0385 Convergence: 0.0916 k= 0.019615 lr = 0.0000063\n",
      "[16/25][7690/9765] Loss_D: 0.0999 Loss_G: 0.0388 Convergence: 0.1021 k= 0.019614 lr = 0.0000063\n",
      "[16/25][7700/9765] Loss_D: 0.0995 Loss_G: 0.0397 Convergence: 0.1007 k= 0.019600 lr = 0.0000063\n",
      "[16/25][7710/9765] Loss_D: 0.0936 Loss_G: 0.0403 Convergence: 0.0969 k= 0.019603 lr = 0.0000063\n",
      "[16/25][7720/9765] Loss_D: 0.1018 Loss_G: 0.0385 Convergence: 0.1051 k= 0.019594 lr = 0.0000063\n",
      "[16/25][7730/9765] Loss_D: 0.0954 Loss_G: 0.0384 Convergence: 0.0962 k= 0.019600 lr = 0.0000063\n",
      "[16/25][7740/9765] Loss_D: 0.0930 Loss_G: 0.0375 Convergence: 0.0937 k= 0.019599 lr = 0.0000063\n",
      "[16/25][7750/9765] Loss_D: 0.0931 Loss_G: 0.0381 Convergence: 0.0944 k= 0.019609 lr = 0.0000063\n",
      "[16/25][7760/9765] Loss_D: 0.0932 Loss_G: 0.0393 Convergence: 0.0957 k= 0.019605 lr = 0.0000063\n",
      "[16/25][7770/9765] Loss_D: 0.0920 Loss_G: 0.0381 Convergence: 0.0937 k= 0.019622 lr = 0.0000063\n",
      "[16/25][7780/9765] Loss_D: 0.1015 Loss_G: 0.0388 Convergence: 0.1044 k= 0.019641 lr = 0.0000063\n",
      "[16/25][7790/9765] Loss_D: 0.0986 Loss_G: 0.0382 Convergence: 0.1009 k= 0.019655 lr = 0.0000063\n",
      "[16/25][7800/9765] Loss_D: 0.0941 Loss_G: 0.0404 Convergence: 0.0973 k= 0.019631 lr = 0.0000063\n",
      "[16/25][7810/9765] Loss_D: 0.0841 Loss_G: 0.0408 Convergence: 0.0917 k= 0.019613 lr = 0.0000063\n",
      "[16/25][7820/9765] Loss_D: 0.0948 Loss_G: 0.0409 Convergence: 0.0982 k= 0.019605 lr = 0.0000063\n",
      "[16/25][7830/9765] Loss_D: 0.0966 Loss_G: 0.0387 Convergence: 0.0976 k= 0.019579 lr = 0.0000063\n",
      "[16/25][7840/9765] Loss_D: 0.0955 Loss_G: 0.0395 Convergence: 0.0973 k= 0.019582 lr = 0.0000063\n",
      "[16/25][7850/9765] Loss_D: 0.1105 Loss_G: 0.0399 Convergence: 0.1159 k= 0.019594 lr = 0.0000063\n",
      "[16/25][7860/9765] Loss_D: 0.0981 Loss_G: 0.0395 Convergence: 0.0989 k= 0.019605 lr = 0.0000063\n",
      "[16/25][7870/9765] Loss_D: 0.0952 Loss_G: 0.0381 Convergence: 0.0962 k= 0.019620 lr = 0.0000063\n",
      "[16/25][7880/9765] Loss_D: 0.0888 Loss_G: 0.0378 Convergence: 0.0916 k= 0.019615 lr = 0.0000063\n",
      "[16/25][7890/9765] Loss_D: 0.1050 Loss_G: 0.0386 Convergence: 0.1095 k= 0.019623 lr = 0.0000063\n",
      "[16/25][7900/9765] Loss_D: 0.1056 Loss_G: 0.0390 Convergence: 0.1099 k= 0.019615 lr = 0.0000063\n",
      "[16/25][7910/9765] Loss_D: 0.1014 Loss_G: 0.0407 Convergence: 0.1024 k= 0.019624 lr = 0.0000063\n",
      "[16/25][7920/9765] Loss_D: 0.0907 Loss_G: 0.0399 Convergence: 0.0948 k= 0.019606 lr = 0.0000063\n",
      "[16/25][7930/9765] Loss_D: 0.0958 Loss_G: 0.0409 Convergence: 0.0989 k= 0.019610 lr = 0.0000063\n",
      "[16/25][7940/9765] Loss_D: 0.1034 Loss_G: 0.0402 Convergence: 0.1057 k= 0.019609 lr = 0.0000063\n",
      "[16/25][7950/9765] Loss_D: 0.1037 Loss_G: 0.0399 Convergence: 0.1063 k= 0.019605 lr = 0.0000063\n",
      "[16/25][7960/9765] Loss_D: 0.0982 Loss_G: 0.0410 Convergence: 0.1004 k= 0.019601 lr = 0.0000063\n",
      "[16/25][7970/9765] Loss_D: 0.0947 Loss_G: 0.0388 Convergence: 0.0961 k= 0.019609 lr = 0.0000063\n",
      "[16/25][7980/9765] Loss_D: 0.0968 Loss_G: 0.0393 Convergence: 0.0978 k= 0.019617 lr = 0.0000063\n",
      "[16/25][7990/9765] Loss_D: 0.0980 Loss_G: 0.0403 Convergence: 0.0995 k= 0.019626 lr = 0.0000063\n",
      "[16/25][8000/9765] Loss_D: 0.1048 Loss_G: 0.0393 Convergence: 0.1085 k= 0.019635 lr = 0.0000063\n",
      "[16/25][8010/9765] Loss_D: 0.0945 Loss_G: 0.0388 Convergence: 0.0960 k= 0.019624 lr = 0.0000063\n",
      "[16/25][8020/9765] Loss_D: 0.0916 Loss_G: 0.0388 Convergence: 0.0942 k= 0.019621 lr = 0.0000063\n",
      "[16/25][8030/9765] Loss_D: 0.0923 Loss_G: 0.0404 Convergence: 0.0963 k= 0.019622 lr = 0.0000063\n",
      "[16/25][8040/9765] Loss_D: 0.0967 Loss_G: 0.0411 Convergence: 0.0996 k= 0.019613 lr = 0.0000063\n",
      "[16/25][8050/9765] Loss_D: 0.0963 Loss_G: 0.0378 Convergence: 0.0981 k= 0.019618 lr = 0.0000063\n",
      "[16/25][8060/9765] Loss_D: 0.0987 Loss_G: 0.0399 Convergence: 0.0996 k= 0.019622 lr = 0.0000063\n",
      "[16/25][8070/9765] Loss_D: 0.0928 Loss_G: 0.0389 Convergence: 0.0950 k= 0.019612 lr = 0.0000063\n",
      "[16/25][8080/9765] Loss_D: 0.1131 Loss_G: 0.0402 Convergence: 0.1192 k= 0.019612 lr = 0.0000063\n",
      "[16/25][8090/9765] Loss_D: 0.0962 Loss_G: 0.0383 Convergence: 0.0974 k= 0.019606 lr = 0.0000063\n",
      "[16/25][8100/9765] Loss_D: 0.0946 Loss_G: 0.0385 Convergence: 0.0957 k= 0.019602 lr = 0.0000063\n",
      "[16/25][8110/9765] Loss_D: 0.1001 Loss_G: 0.0383 Convergence: 0.1029 k= 0.019612 lr = 0.0000063\n",
      "[16/25][8120/9765] Loss_D: 0.1021 Loss_G: 0.0377 Convergence: 0.1062 k= 0.019615 lr = 0.0000063\n",
      "[16/25][8130/9765] Loss_D: 0.1016 Loss_G: 0.0381 Convergence: 0.1052 k= 0.019632 lr = 0.0000063\n",
      "[16/25][8140/9765] Loss_D: 0.1035 Loss_G: 0.0381 Convergence: 0.1079 k= 0.019642 lr = 0.0000063\n",
      "[16/25][8150/9765] Loss_D: 0.0972 Loss_G: 0.0404 Convergence: 0.0991 k= 0.019640 lr = 0.0000063\n",
      "[16/25][8160/9765] Loss_D: 0.0895 Loss_G: 0.0375 Convergence: 0.0916 k= 0.019642 lr = 0.0000063\n",
      "[16/25][8170/9765] Loss_D: 0.0914 Loss_G: 0.0401 Convergence: 0.0954 k= 0.019640 lr = 0.0000063\n",
      "[16/25][8180/9765] Loss_D: 0.0920 Loss_G: 0.0398 Convergence: 0.0955 k= 0.019617 lr = 0.0000063\n",
      "[16/25][8190/9765] Loss_D: 0.1073 Loss_G: 0.0414 Convergence: 0.1098 k= 0.019601 lr = 0.0000063\n",
      "[16/25][8200/9765] Loss_D: 0.1002 Loss_G: 0.0372 Convergence: 0.1041 k= 0.019618 lr = 0.0000063\n",
      "[16/25][8210/9765] Loss_D: 0.0890 Loss_G: 0.0361 Convergence: 0.0899 k= 0.019639 lr = 0.0000063\n",
      "[16/25][8220/9765] Loss_D: 0.0995 Loss_G: 0.0378 Convergence: 0.1025 k= 0.019655 lr = 0.0000063\n",
      "[16/25][8230/9765] Loss_D: 0.0916 Loss_G: 0.0368 Convergence: 0.0925 k= 0.019656 lr = 0.0000063\n",
      "[16/25][8240/9765] Loss_D: 0.1039 Loss_G: 0.0363 Convergence: 0.1102 k= 0.019682 lr = 0.0000063\n",
      "[16/25][8250/9765] Loss_D: 0.0909 Loss_G: 0.0385 Convergence: 0.0935 k= 0.019691 lr = 0.0000063\n",
      "[16/25][8260/9765] Loss_D: 0.0987 Loss_G: 0.0377 Convergence: 0.1015 k= 0.019699 lr = 0.0000063\n",
      "[16/25][8270/9765] Loss_D: 0.1030 Loss_G: 0.0383 Convergence: 0.1070 k= 0.019714 lr = 0.0000063\n",
      "[16/25][8280/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.0996 k= 0.019720 lr = 0.0000063\n",
      "[16/25][8290/9765] Loss_D: 0.0967 Loss_G: 0.0379 Convergence: 0.0984 k= 0.019710 lr = 0.0000063\n",
      "[16/25][8300/9765] Loss_D: 0.0980 Loss_G: 0.0379 Convergence: 0.1004 k= 0.019710 lr = 0.0000063\n",
      "[16/25][8310/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0967 k= 0.019716 lr = 0.0000063\n",
      "[16/25][8320/9765] Loss_D: 0.0929 Loss_G: 0.0405 Convergence: 0.0967 k= 0.019712 lr = 0.0000063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][8330/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1022 k= 0.019714 lr = 0.0000063\n",
      "[16/25][8340/9765] Loss_D: 0.0935 Loss_G: 0.0378 Convergence: 0.0944 k= 0.019718 lr = 0.0000063\n",
      "[16/25][8350/9765] Loss_D: 0.0882 Loss_G: 0.0394 Convergence: 0.0928 k= 0.019719 lr = 0.0000063\n",
      "[16/25][8360/9765] Loss_D: 0.0934 Loss_G: 0.0372 Convergence: 0.0946 k= 0.019712 lr = 0.0000063\n",
      "[16/25][8370/9765] Loss_D: 0.0913 Loss_G: 0.0378 Convergence: 0.0931 k= 0.019722 lr = 0.0000063\n",
      "[16/25][8380/9765] Loss_D: 0.0957 Loss_G: 0.0403 Convergence: 0.0981 k= 0.019713 lr = 0.0000063\n",
      "[16/25][8390/9765] Loss_D: 0.0975 Loss_G: 0.0400 Convergence: 0.0990 k= 0.019714 lr = 0.0000063\n",
      "[16/25][8400/9765] Loss_D: 0.1031 Loss_G: 0.0401 Convergence: 0.1054 k= 0.019721 lr = 0.0000063\n",
      "[16/25][8410/9765] Loss_D: 0.0941 Loss_G: 0.0374 Convergence: 0.0953 k= 0.019728 lr = 0.0000063\n",
      "[16/25][8420/9765] Loss_D: 0.0957 Loss_G: 0.0407 Convergence: 0.0986 k= 0.019715 lr = 0.0000063\n",
      "[16/25][8430/9765] Loss_D: 0.0995 Loss_G: 0.0393 Convergence: 0.1011 k= 0.019719 lr = 0.0000063\n",
      "[16/25][8440/9765] Loss_D: 0.0934 Loss_G: 0.0396 Convergence: 0.0961 k= 0.019708 lr = 0.0000063\n",
      "[16/25][8450/9765] Loss_D: 0.1051 Loss_G: 0.0398 Convergence: 0.1084 k= 0.019700 lr = 0.0000063\n",
      "[16/25][8460/9765] Loss_D: 0.0885 Loss_G: 0.0374 Convergence: 0.0910 k= 0.019700 lr = 0.0000063\n",
      "[16/25][8470/9765] Loss_D: 0.0894 Loss_G: 0.0400 Convergence: 0.0942 k= 0.019698 lr = 0.0000063\n",
      "[16/25][8480/9765] Loss_D: 0.1009 Loss_G: 0.0389 Convergence: 0.1033 k= 0.019690 lr = 0.0000063\n",
      "[16/25][8490/9765] Loss_D: 0.0861 Loss_G: 0.0364 Convergence: 0.0885 k= 0.019690 lr = 0.0000063\n",
      "[16/25][8500/9765] Loss_D: 0.0990 Loss_G: 0.0381 Convergence: 0.1016 k= 0.019702 lr = 0.0000063\n",
      "[16/25][8510/9765] Loss_D: 0.1022 Loss_G: 0.0376 Convergence: 0.1065 k= 0.019715 lr = 0.0000063\n",
      "[16/25][8520/9765] Loss_D: 0.1030 Loss_G: 0.0402 Convergence: 0.1051 k= 0.019727 lr = 0.0000063\n",
      "[16/25][8530/9765] Loss_D: 0.0925 Loss_G: 0.0361 Convergence: 0.0945 k= 0.019722 lr = 0.0000063\n",
      "[16/25][8540/9765] Loss_D: 0.0926 Loss_G: 0.0370 Convergence: 0.0937 k= 0.019735 lr = 0.0000063\n",
      "[16/25][8550/9765] Loss_D: 0.0884 Loss_G: 0.0365 Convergence: 0.0900 k= 0.019741 lr = 0.0000063\n",
      "[16/25][8560/9765] Loss_D: 0.0909 Loss_G: 0.0382 Convergence: 0.0932 k= 0.019749 lr = 0.0000063\n",
      "[16/25][8570/9765] Loss_D: 0.1032 Loss_G: 0.0405 Convergence: 0.1050 k= 0.019761 lr = 0.0000063\n",
      "[16/25][8580/9765] Loss_D: 0.0975 Loss_G: 0.0387 Convergence: 0.0988 k= 0.019742 lr = 0.0000063\n",
      "[16/25][8590/9765] Loss_D: 0.1019 Loss_G: 0.0387 Convergence: 0.1050 k= 0.019753 lr = 0.0000063\n",
      "[16/25][8600/9765] Loss_D: 0.0983 Loss_G: 0.0399 Convergence: 0.0993 k= 0.019741 lr = 0.0000063\n",
      "[16/25][8610/9765] Loss_D: 0.0999 Loss_G: 0.0373 Convergence: 0.1036 k= 0.019743 lr = 0.0000063\n",
      "[16/25][8620/9765] Loss_D: 0.0969 Loss_G: 0.0371 Convergence: 0.0995 k= 0.019751 lr = 0.0000063\n",
      "[16/25][8630/9765] Loss_D: 0.0986 Loss_G: 0.0374 Convergence: 0.1016 k= 0.019756 lr = 0.0000063\n",
      "[16/25][8640/9765] Loss_D: 0.0863 Loss_G: 0.0386 Convergence: 0.0909 k= 0.019746 lr = 0.0000063\n",
      "[16/25][8650/9765] Loss_D: 0.1026 Loss_G: 0.0374 Convergence: 0.1073 k= 0.019750 lr = 0.0000063\n",
      "[16/25][8660/9765] Loss_D: 0.1009 Loss_G: 0.0412 Convergence: 0.1022 k= 0.019747 lr = 0.0000063\n",
      "[16/25][8670/9765] Loss_D: 0.0958 Loss_G: 0.0413 Convergence: 0.0993 k= 0.019740 lr = 0.0000063\n",
      "[16/25][8680/9765] Loss_D: 0.0939 Loss_G: 0.0411 Convergence: 0.0979 k= 0.019719 lr = 0.0000063\n",
      "[16/25][8690/9765] Loss_D: 0.0944 Loss_G: 0.0367 Convergence: 0.0965 k= 0.019704 lr = 0.0000063\n",
      "[16/25][8700/9765] Loss_D: 0.1045 Loss_G: 0.0403 Convergence: 0.1070 k= 0.019704 lr = 0.0000063\n",
      "[16/25][8710/9765] Loss_D: 0.0961 Loss_G: 0.0381 Convergence: 0.0975 k= 0.019694 lr = 0.0000063\n",
      "[16/25][8720/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0979 k= 0.019690 lr = 0.0000063\n",
      "[16/25][8730/9765] Loss_D: 0.0977 Loss_G: 0.0390 Convergence: 0.0988 k= 0.019689 lr = 0.0000063\n",
      "[16/25][8740/9765] Loss_D: 0.0916 Loss_G: 0.0384 Convergence: 0.0938 k= 0.019695 lr = 0.0000063\n",
      "[16/25][8750/9765] Loss_D: 0.0884 Loss_G: 0.0383 Convergence: 0.0918 k= 0.019694 lr = 0.0000063\n",
      "[16/25][8760/9765] Loss_D: 0.0930 Loss_G: 0.0392 Convergence: 0.0955 k= 0.019706 lr = 0.0000060\n",
      "[16/25][8770/9765] Loss_D: 0.1012 Loss_G: 0.0378 Convergence: 0.1049 k= 0.019703 lr = 0.0000060\n",
      "[16/25][8780/9765] Loss_D: 0.0991 Loss_G: 0.0395 Convergence: 0.1003 k= 0.019701 lr = 0.0000060\n",
      "[16/25][8790/9765] Loss_D: 0.0933 Loss_G: 0.0395 Convergence: 0.0960 k= 0.019695 lr = 0.0000060\n",
      "[16/25][8800/9765] Loss_D: 0.0956 Loss_G: 0.0377 Convergence: 0.0973 k= 0.019680 lr = 0.0000060\n",
      "[16/25][8810/9765] Loss_D: 0.1083 Loss_G: 0.0392 Convergence: 0.1135 k= 0.019680 lr = 0.0000060\n",
      "[16/25][8820/9765] Loss_D: 0.0926 Loss_G: 0.0392 Convergence: 0.0952 k= 0.019658 lr = 0.0000060\n",
      "[16/25][8830/9765] Loss_D: 0.0990 Loss_G: 0.0370 Convergence: 0.1026 k= 0.019661 lr = 0.0000060\n",
      "[16/25][8840/9765] Loss_D: 0.0921 Loss_G: 0.0384 Convergence: 0.0941 k= 0.019671 lr = 0.0000060\n",
      "[16/25][8850/9765] Loss_D: 0.0986 Loss_G: 0.0383 Convergence: 0.1007 k= 0.019676 lr = 0.0000060\n",
      "[16/25][8860/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1006 k= 0.019675 lr = 0.0000060\n",
      "[16/25][8870/9765] Loss_D: 0.0968 Loss_G: 0.0384 Convergence: 0.0981 k= 0.019666 lr = 0.0000060\n",
      "[16/25][8880/9765] Loss_D: 0.0956 Loss_G: 0.0366 Convergence: 0.0983 k= 0.019671 lr = 0.0000060\n",
      "[16/25][8890/9765] Loss_D: 0.1015 Loss_G: 0.0384 Convergence: 0.1048 k= 0.019683 lr = 0.0000060\n",
      "[16/25][8900/9765] Loss_D: 0.0928 Loss_G: 0.0380 Convergence: 0.0941 k= 0.019689 lr = 0.0000060\n",
      "[16/25][8910/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.019705 lr = 0.0000060\n",
      "[16/25][8920/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.019707 lr = 0.0000060\n",
      "[16/25][8930/9765] Loss_D: 0.0974 Loss_G: 0.0385 Convergence: 0.0990 k= 0.019700 lr = 0.0000060\n",
      "[16/25][8940/9765] Loss_D: 0.0958 Loss_G: 0.0394 Convergence: 0.0974 k= 0.019711 lr = 0.0000060\n",
      "[16/25][8950/9765] Loss_D: 0.0899 Loss_G: 0.0378 Convergence: 0.0922 k= 0.019706 lr = 0.0000060\n",
      "[16/25][8960/9765] Loss_D: 0.1017 Loss_G: 0.0384 Convergence: 0.1052 k= 0.019708 lr = 0.0000060\n",
      "[16/25][8970/9765] Loss_D: 0.0917 Loss_G: 0.0378 Convergence: 0.0933 k= 0.019711 lr = 0.0000060\n",
      "[16/25][8980/9765] Loss_D: 0.0991 Loss_G: 0.0385 Convergence: 0.1013 k= 0.019723 lr = 0.0000060\n",
      "[16/25][8990/9765] Loss_D: 0.1070 Loss_G: 0.0383 Convergence: 0.1125 k= 0.019732 lr = 0.0000060\n",
      "[16/25][9000/9765] Loss_D: 0.0932 Loss_G: 0.0399 Convergence: 0.0962 k= 0.019734 lr = 0.0000060\n",
      "[16/25][9010/9765] Loss_D: 0.1064 Loss_G: 0.0376 Convergence: 0.1124 k= 0.019749 lr = 0.0000060\n",
      "[16/25][9020/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0990 k= 0.019752 lr = 0.0000060\n",
      "[16/25][9030/9765] Loss_D: 0.0922 Loss_G: 0.0389 Convergence: 0.0947 k= 0.019746 lr = 0.0000060\n",
      "[16/25][9040/9765] Loss_D: 0.0951 Loss_G: 0.0381 Convergence: 0.0961 k= 0.019745 lr = 0.0000060\n",
      "[16/25][9050/9765] Loss_D: 0.1028 Loss_G: 0.0396 Convergence: 0.1053 k= 0.019743 lr = 0.0000060\n",
      "[16/25][9060/9765] Loss_D: 0.0936 Loss_G: 0.0393 Convergence: 0.0959 k= 0.019742 lr = 0.0000060\n",
      "[16/25][9070/9765] Loss_D: 0.1005 Loss_G: 0.0390 Convergence: 0.1028 k= 0.019745 lr = 0.0000060\n",
      "[16/25][9080/9765] Loss_D: 0.1016 Loss_G: 0.0396 Convergence: 0.1038 k= 0.019748 lr = 0.0000060\n",
      "[16/25][9090/9765] Loss_D: 0.0999 Loss_G: 0.0412 Convergence: 0.1016 k= 0.019746 lr = 0.0000060\n",
      "[16/25][9100/9765] Loss_D: 0.0946 Loss_G: 0.0418 Convergence: 0.0990 k= 0.019719 lr = 0.0000060\n",
      "[16/25][9110/9765] Loss_D: 0.0991 Loss_G: 0.0415 Convergence: 0.1015 k= 0.019697 lr = 0.0000060\n",
      "[16/25][9120/9765] Loss_D: 0.0970 Loss_G: 0.0368 Convergence: 0.1001 k= 0.019694 lr = 0.0000060\n",
      "[16/25][9130/9765] Loss_D: 0.0953 Loss_G: 0.0403 Convergence: 0.0980 k= 0.019687 lr = 0.0000060\n",
      "[16/25][9140/9765] Loss_D: 0.0947 Loss_G: 0.0351 Convergence: 0.0985 k= 0.019706 lr = 0.0000060\n",
      "[16/25][9150/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.019716 lr = 0.0000060\n",
      "[16/25][9160/9765] Loss_D: 0.0934 Loss_G: 0.0404 Convergence: 0.0970 k= 0.019703 lr = 0.0000060\n",
      "[16/25][9170/9765] Loss_D: 0.0984 Loss_G: 0.0401 Convergence: 0.0997 k= 0.019694 lr = 0.0000060\n",
      "[16/25][9180/9765] Loss_D: 0.0957 Loss_G: 0.0389 Convergence: 0.0969 k= 0.019682 lr = 0.0000060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/25][9190/9765] Loss_D: 0.1024 Loss_G: 0.0383 Convergence: 0.1061 k= 0.019694 lr = 0.0000060\n",
      "[16/25][9200/9765] Loss_D: 0.0971 Loss_G: 0.0386 Convergence: 0.0984 k= 0.019698 lr = 0.0000060\n",
      "[16/25][9210/9765] Loss_D: 0.0909 Loss_G: 0.0387 Convergence: 0.0937 k= 0.019686 lr = 0.0000060\n",
      "[16/25][9220/9765] Loss_D: 0.0929 Loss_G: 0.0397 Convergence: 0.0959 k= 0.019681 lr = 0.0000060\n",
      "[16/25][9230/9765] Loss_D: 0.0867 Loss_G: 0.0370 Convergence: 0.0894 k= 0.019691 lr = 0.0000060\n",
      "[16/25][9240/9765] Loss_D: 0.0983 Loss_G: 0.0371 Convergence: 0.1016 k= 0.019691 lr = 0.0000060\n",
      "[16/25][9250/9765] Loss_D: 0.0934 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019693 lr = 0.0000060\n",
      "[16/25][9260/9765] Loss_D: 0.0908 Loss_G: 0.0416 Convergence: 0.0965 k= 0.019677 lr = 0.0000060\n",
      "[16/25][9270/9765] Loss_D: 0.0894 Loss_G: 0.0394 Convergence: 0.0935 k= 0.019654 lr = 0.0000060\n",
      "[16/25][9280/9765] Loss_D: 0.1101 Loss_G: 0.0428 Convergence: 0.1125 k= 0.019643 lr = 0.0000060\n",
      "[16/25][9290/9765] Loss_D: 0.0944 Loss_G: 0.0407 Convergence: 0.0978 k= 0.019623 lr = 0.0000060\n",
      "[16/25][9300/9765] Loss_D: 0.0998 Loss_G: 0.0404 Convergence: 0.1007 k= 0.019618 lr = 0.0000060\n",
      "[16/25][9310/9765] Loss_D: 0.0951 Loss_G: 0.0415 Convergence: 0.0990 k= 0.019604 lr = 0.0000060\n",
      "[16/25][9320/9765] Loss_D: 0.0976 Loss_G: 0.0408 Convergence: 0.0998 k= 0.019586 lr = 0.0000060\n",
      "[16/25][9330/9765] Loss_D: 0.1005 Loss_G: 0.0394 Convergence: 0.1025 k= 0.019566 lr = 0.0000060\n",
      "[16/25][9340/9765] Loss_D: 0.0956 Loss_G: 0.0368 Convergence: 0.0980 k= 0.019560 lr = 0.0000060\n",
      "[16/25][9350/9765] Loss_D: 0.0929 Loss_G: 0.0379 Convergence: 0.0940 k= 0.019559 lr = 0.0000060\n",
      "[16/25][9360/9765] Loss_D: 0.0884 Loss_G: 0.0382 Convergence: 0.0916 k= 0.019566 lr = 0.0000060\n",
      "[16/25][9370/9765] Loss_D: 0.0895 Loss_G: 0.0386 Convergence: 0.0928 k= 0.019566 lr = 0.0000060\n",
      "[16/25][9380/9765] Loss_D: 0.0925 Loss_G: 0.0383 Convergence: 0.0943 k= 0.019558 lr = 0.0000060\n",
      "[16/25][9390/9765] Loss_D: 0.0974 Loss_G: 0.0398 Convergence: 0.0987 k= 0.019553 lr = 0.0000060\n",
      "[16/25][9400/9765] Loss_D: 0.0986 Loss_G: 0.0392 Convergence: 0.0999 k= 0.019534 lr = 0.0000060\n",
      "[16/25][9410/9765] Loss_D: 0.0936 Loss_G: 0.0408 Convergence: 0.0974 k= 0.019533 lr = 0.0000060\n",
      "[16/25][9420/9765] Loss_D: 0.0962 Loss_G: 0.0419 Convergence: 0.1001 k= 0.019519 lr = 0.0000060\n",
      "[16/25][9430/9765] Loss_D: 0.1039 Loss_G: 0.0387 Convergence: 0.1078 k= 0.019512 lr = 0.0000060\n",
      "[16/25][9440/9765] Loss_D: 0.0971 Loss_G: 0.0383 Convergence: 0.0987 k= 0.019507 lr = 0.0000060\n",
      "[16/25][9450/9765] Loss_D: 0.0944 Loss_G: 0.0381 Convergence: 0.0952 k= 0.019515 lr = 0.0000060\n",
      "[16/25][9460/9765] Loss_D: 0.0882 Loss_G: 0.0378 Convergence: 0.0912 k= 0.019518 lr = 0.0000060\n",
      "[16/25][9470/9765] Loss_D: 0.0980 Loss_G: 0.0398 Convergence: 0.0991 k= 0.019514 lr = 0.0000060\n",
      "[16/25][9480/9765] Loss_D: 0.0931 Loss_G: 0.0379 Convergence: 0.0942 k= 0.019522 lr = 0.0000060\n",
      "[16/25][9490/9765] Loss_D: 0.0986 Loss_G: 0.0364 Convergence: 0.1027 k= 0.019538 lr = 0.0000060\n",
      "[16/25][9500/9765] Loss_D: 0.1011 Loss_G: 0.0386 Convergence: 0.1040 k= 0.019554 lr = 0.0000060\n",
      "[16/25][9510/9765] Loss_D: 0.0978 Loss_G: 0.0392 Convergence: 0.0988 k= 0.019569 lr = 0.0000060\n",
      "[16/25][9520/9765] Loss_D: 0.0879 Loss_G: 0.0382 Convergence: 0.0913 k= 0.019568 lr = 0.0000060\n",
      "[16/25][9530/9765] Loss_D: 0.1065 Loss_G: 0.0400 Convergence: 0.1101 k= 0.019575 lr = 0.0000060\n",
      "[16/25][9540/9765] Loss_D: 0.0982 Loss_G: 0.0415 Convergence: 0.1009 k= 0.019549 lr = 0.0000060\n",
      "[16/25][9550/9765] Loss_D: 0.1032 Loss_G: 0.0401 Convergence: 0.1055 k= 0.019542 lr = 0.0000060\n",
      "[16/25][9560/9765] Loss_D: 0.0970 Loss_G: 0.0385 Convergence: 0.0983 k= 0.019535 lr = 0.0000060\n",
      "[16/25][9570/9765] Loss_D: 0.1004 Loss_G: 0.0367 Convergence: 0.1049 k= 0.019536 lr = 0.0000060\n",
      "[16/25][9580/9765] Loss_D: 0.0992 Loss_G: 0.0390 Convergence: 0.1008 k= 0.019545 lr = 0.0000060\n",
      "[16/25][9590/9765] Loss_D: 0.0889 Loss_G: 0.0400 Convergence: 0.0938 k= 0.019554 lr = 0.0000060\n",
      "[16/25][9600/9765] Loss_D: 0.0964 Loss_G: 0.0385 Convergence: 0.0974 k= 0.019549 lr = 0.0000060\n",
      "[16/25][9610/9765] Loss_D: 0.0974 Loss_G: 0.0386 Convergence: 0.0988 k= 0.019546 lr = 0.0000060\n",
      "[16/25][9620/9765] Loss_D: 0.0886 Loss_G: 0.0395 Convergence: 0.0931 k= 0.019548 lr = 0.0000060\n",
      "[16/25][9630/9765] Loss_D: 0.0972 Loss_G: 0.0397 Convergence: 0.0985 k= 0.019542 lr = 0.0000060\n",
      "[16/25][9640/9765] Loss_D: 0.0980 Loss_G: 0.0410 Convergence: 0.1003 k= 0.019529 lr = 0.0000060\n",
      "[16/25][9650/9765] Loss_D: 0.1009 Loss_G: 0.0396 Convergence: 0.1028 k= 0.019508 lr = 0.0000060\n",
      "[16/25][9660/9765] Loss_D: 0.1037 Loss_G: 0.0400 Convergence: 0.1062 k= 0.019510 lr = 0.0000060\n",
      "[16/25][9670/9765] Loss_D: 0.0989 Loss_G: 0.0422 Convergence: 0.1021 k= 0.019493 lr = 0.0000060\n",
      "[16/25][9680/9765] Loss_D: 0.0890 Loss_G: 0.0427 Convergence: 0.0966 k= 0.019465 lr = 0.0000060\n",
      "[16/25][9690/9765] Loss_D: 0.1049 Loss_G: 0.0428 Convergence: 0.1062 k= 0.019444 lr = 0.0000060\n",
      "[16/25][9700/9765] Loss_D: 0.0992 Loss_G: 0.0400 Convergence: 0.1000 k= 0.019427 lr = 0.0000060\n",
      "[16/25][9710/9765] Loss_D: 0.0898 Loss_G: 0.0390 Convergence: 0.0933 k= 0.019415 lr = 0.0000060\n",
      "[16/25][9720/9765] Loss_D: 0.1031 Loss_G: 0.0390 Convergence: 0.1063 k= 0.019420 lr = 0.0000060\n",
      "[16/25][9730/9765] Loss_D: 0.1007 Loss_G: 0.0376 Convergence: 0.1044 k= 0.019446 lr = 0.0000060\n",
      "[16/25][9740/9765] Loss_D: 0.0930 Loss_G: 0.0371 Convergence: 0.0940 k= 0.019461 lr = 0.0000060\n",
      "[16/25][9750/9765] Loss_D: 0.0902 Loss_G: 0.0381 Convergence: 0.0926 k= 0.019475 lr = 0.0000060\n",
      "[16/25][9760/9765] Loss_D: 0.1002 Loss_G: 0.0385 Convergence: 0.1028 k= 0.019501 lr = 0.0000060\n",
      "[17/25][0/9765] Loss_D: 0.0921 Loss_G: 0.0357 Convergence: 0.0942 k= 0.019500 lr = 0.0000060\n",
      "[17/25][10/9765] Loss_D: 0.0961 Loss_G: 0.0396 Convergence: 0.0978 k= 0.019495 lr = 0.0000060\n",
      "[17/25][20/9765] Loss_D: 0.1028 Loss_G: 0.0436 Convergence: 0.1058 k= 0.019459 lr = 0.0000060\n",
      "[17/25][30/9765] Loss_D: 0.0945 Loss_G: 0.0463 Convergence: 0.1035 k= 0.019397 lr = 0.0000060\n",
      "[17/25][40/9765] Loss_D: 0.1005 Loss_G: 0.0456 Convergence: 0.1065 k= 0.019320 lr = 0.0000060\n",
      "[17/25][50/9765] Loss_D: 0.0920 Loss_G: 0.0451 Convergence: 0.1008 k= 0.019257 lr = 0.0000060\n",
      "[17/25][60/9765] Loss_D: 0.0959 Loss_G: 0.0405 Convergence: 0.0985 k= 0.019213 lr = 0.0000060\n",
      "[17/25][70/9765] Loss_D: 0.0997 Loss_G: 0.0389 Convergence: 0.1017 k= 0.019210 lr = 0.0000060\n",
      "[17/25][80/9765] Loss_D: 0.0940 Loss_G: 0.0379 Convergence: 0.0948 k= 0.019217 lr = 0.0000060\n",
      "[17/25][90/9765] Loss_D: 0.0966 Loss_G: 0.0380 Convergence: 0.0982 k= 0.019229 lr = 0.0000060\n",
      "[17/25][100/9765] Loss_D: 0.0894 Loss_G: 0.0360 Convergence: 0.0902 k= 0.019249 lr = 0.0000060\n",
      "[17/25][110/9765] Loss_D: 0.0915 Loss_G: 0.0366 Convergence: 0.0925 k= 0.019272 lr = 0.0000060\n",
      "[17/25][120/9765] Loss_D: 0.0995 Loss_G: 0.0380 Convergence: 0.1024 k= 0.019270 lr = 0.0000060\n",
      "[17/25][130/9765] Loss_D: 0.0978 Loss_G: 0.0377 Convergence: 0.1003 k= 0.019284 lr = 0.0000060\n",
      "[17/25][140/9765] Loss_D: 0.0896 Loss_G: 0.0392 Convergence: 0.0934 k= 0.019290 lr = 0.0000060\n",
      "[17/25][150/9765] Loss_D: 0.0902 Loss_G: 0.0396 Convergence: 0.0942 k= 0.019288 lr = 0.0000060\n",
      "[17/25][160/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0992 k= 0.019286 lr = 0.0000060\n",
      "[17/25][170/9765] Loss_D: 0.0918 Loss_G: 0.0393 Convergence: 0.0948 k= 0.019269 lr = 0.0000060\n",
      "[17/25][180/9765] Loss_D: 0.0954 Loss_G: 0.0412 Convergence: 0.0989 k= 0.019263 lr = 0.0000060\n",
      "[17/25][190/9765] Loss_D: 0.1063 Loss_G: 0.0392 Convergence: 0.1106 k= 0.019265 lr = 0.0000060\n",
      "[17/25][200/9765] Loss_D: 0.1009 Loss_G: 0.0379 Convergence: 0.1044 k= 0.019262 lr = 0.0000060\n",
      "[17/25][210/9765] Loss_D: 0.0974 Loss_G: 0.0392 Convergence: 0.0983 k= 0.019268 lr = 0.0000060\n",
      "[17/25][220/9765] Loss_D: 0.0947 Loss_G: 0.0381 Convergence: 0.0955 k= 0.019253 lr = 0.0000060\n",
      "[17/25][230/9765] Loss_D: 0.0952 Loss_G: 0.0390 Convergence: 0.0966 k= 0.019257 lr = 0.0000060\n",
      "[17/25][240/9765] Loss_D: 0.0923 Loss_G: 0.0372 Convergence: 0.0930 k= 0.019265 lr = 0.0000060\n",
      "[17/25][250/9765] Loss_D: 0.1015 Loss_G: 0.0389 Convergence: 0.1043 k= 0.019275 lr = 0.0000060\n",
      "[17/25][260/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0981 k= 0.019274 lr = 0.0000060\n",
      "[17/25][270/9765] Loss_D: 0.0935 Loss_G: 0.0380 Convergence: 0.0946 k= 0.019275 lr = 0.0000060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][280/9765] Loss_D: 0.1059 Loss_G: 0.0382 Convergence: 0.1111 k= 0.019276 lr = 0.0000060\n",
      "[17/25][290/9765] Loss_D: 0.0942 Loss_G: 0.0379 Convergence: 0.0951 k= 0.019286 lr = 0.0000060\n",
      "[17/25][300/9765] Loss_D: 0.0945 Loss_G: 0.0384 Convergence: 0.0956 k= 0.019291 lr = 0.0000060\n",
      "[17/25][310/9765] Loss_D: 0.0991 Loss_G: 0.0388 Convergence: 0.1010 k= 0.019306 lr = 0.0000060\n",
      "[17/25][320/9765] Loss_D: 0.0928 Loss_G: 0.0384 Convergence: 0.0946 k= 0.019297 lr = 0.0000060\n",
      "[17/25][330/9765] Loss_D: 0.0938 Loss_G: 0.0385 Convergence: 0.0953 k= 0.019294 lr = 0.0000060\n",
      "[17/25][340/9765] Loss_D: 0.0890 Loss_G: 0.0382 Convergence: 0.0920 k= 0.019293 lr = 0.0000060\n",
      "[17/25][350/9765] Loss_D: 0.0969 Loss_G: 0.0400 Convergence: 0.0986 k= 0.019286 lr = 0.0000060\n",
      "[17/25][360/9765] Loss_D: 0.1014 Loss_G: 0.0400 Convergence: 0.1031 k= 0.019275 lr = 0.0000060\n",
      "[17/25][370/9765] Loss_D: 0.0946 Loss_G: 0.0384 Convergence: 0.0956 k= 0.019270 lr = 0.0000060\n",
      "[17/25][380/9765] Loss_D: 0.0955 Loss_G: 0.0380 Convergence: 0.0968 k= 0.019279 lr = 0.0000060\n",
      "[17/25][390/9765] Loss_D: 0.0918 Loss_G: 0.0372 Convergence: 0.0926 k= 0.019284 lr = 0.0000060\n",
      "[17/25][400/9765] Loss_D: 0.0925 Loss_G: 0.0380 Convergence: 0.0940 k= 0.019292 lr = 0.0000060\n",
      "[17/25][410/9765] Loss_D: 0.1022 Loss_G: 0.0379 Convergence: 0.1062 k= 0.019305 lr = 0.0000060\n",
      "[17/25][420/9765] Loss_D: 0.1042 Loss_G: 0.0361 Convergence: 0.1108 k= 0.019322 lr = 0.0000060\n",
      "[17/25][430/9765] Loss_D: 0.0943 Loss_G: 0.0374 Convergence: 0.0955 k= 0.019346 lr = 0.0000060\n",
      "[17/25][440/9765] Loss_D: 0.0917 Loss_G: 0.0383 Convergence: 0.0938 k= 0.019356 lr = 0.0000060\n",
      "[17/25][450/9765] Loss_D: 0.1177 Loss_G: 0.0378 Convergence: 0.1281 k= 0.019357 lr = 0.0000060\n",
      "[17/25][460/9765] Loss_D: 0.0990 Loss_G: 0.0395 Convergence: 0.1002 k= 0.019351 lr = 0.0000060\n",
      "[17/25][470/9765] Loss_D: 0.0961 Loss_G: 0.0362 Convergence: 0.0994 k= 0.019345 lr = 0.0000060\n",
      "[17/25][480/9765] Loss_D: 0.0971 Loss_G: 0.0377 Convergence: 0.0992 k= 0.019368 lr = 0.0000060\n",
      "[17/25][490/9765] Loss_D: 0.1016 Loss_G: 0.0389 Convergence: 0.1045 k= 0.019355 lr = 0.0000060\n",
      "[17/25][500/9765] Loss_D: 0.0951 Loss_G: 0.0406 Convergence: 0.0981 k= 0.019342 lr = 0.0000060\n",
      "[17/25][510/9765] Loss_D: 0.1034 Loss_G: 0.0394 Convergence: 0.1064 k= 0.019343 lr = 0.0000060\n",
      "[17/25][520/9765] Loss_D: 0.0997 Loss_G: 0.0395 Convergence: 0.1012 k= 0.019337 lr = 0.0000060\n",
      "[17/25][530/9765] Loss_D: 0.0955 Loss_G: 0.0409 Convergence: 0.0987 k= 0.019316 lr = 0.0000060\n",
      "[17/25][540/9765] Loss_D: 0.0938 Loss_G: 0.0391 Convergence: 0.0959 k= 0.019311 lr = 0.0000060\n",
      "[17/25][550/9765] Loss_D: 0.0965 Loss_G: 0.0356 Convergence: 0.1005 k= 0.019314 lr = 0.0000060\n",
      "[17/25][560/9765] Loss_D: 0.1030 Loss_G: 0.0378 Convergence: 0.1075 k= 0.019337 lr = 0.0000060\n",
      "[17/25][570/9765] Loss_D: 0.0899 Loss_G: 0.0362 Convergence: 0.0906 k= 0.019346 lr = 0.0000060\n",
      "[17/25][580/9765] Loss_D: 0.0954 Loss_G: 0.0368 Convergence: 0.0977 k= 0.019354 lr = 0.0000060\n",
      "[17/25][590/9765] Loss_D: 0.1071 Loss_G: 0.0395 Convergence: 0.1115 k= 0.019361 lr = 0.0000060\n",
      "[17/25][600/9765] Loss_D: 0.0988 Loss_G: 0.0396 Convergence: 0.0998 k= 0.019352 lr = 0.0000060\n",
      "[17/25][610/9765] Loss_D: 0.1002 Loss_G: 0.0383 Convergence: 0.1029 k= 0.019354 lr = 0.0000060\n",
      "[17/25][620/9765] Loss_D: 0.0936 Loss_G: 0.0376 Convergence: 0.0944 k= 0.019354 lr = 0.0000060\n",
      "[17/25][630/9765] Loss_D: 0.0986 Loss_G: 0.0375 Convergence: 0.1015 k= 0.019359 lr = 0.0000060\n",
      "[17/25][640/9765] Loss_D: 0.1042 Loss_G: 0.0379 Convergence: 0.1090 k= 0.019364 lr = 0.0000060\n",
      "[17/25][650/9765] Loss_D: 0.0967 Loss_G: 0.0403 Convergence: 0.0988 k= 0.019362 lr = 0.0000060\n",
      "[17/25][660/9765] Loss_D: 0.1027 Loss_G: 0.0391 Convergence: 0.1058 k= 0.019351 lr = 0.0000060\n",
      "[17/25][670/9765] Loss_D: 0.0972 Loss_G: 0.0386 Convergence: 0.0986 k= 0.019337 lr = 0.0000060\n",
      "[17/25][680/9765] Loss_D: 0.0921 Loss_G: 0.0388 Convergence: 0.0945 k= 0.019333 lr = 0.0000060\n",
      "[17/25][690/9765] Loss_D: 0.0970 Loss_G: 0.0378 Convergence: 0.0989 k= 0.019339 lr = 0.0000060\n",
      "[17/25][700/9765] Loss_D: 0.1030 Loss_G: 0.0385 Convergence: 0.1068 k= 0.019338 lr = 0.0000060\n",
      "[17/25][710/9765] Loss_D: 0.1110 Loss_G: 0.0366 Convergence: 0.1199 k= 0.019350 lr = 0.0000060\n",
      "[17/25][720/9765] Loss_D: 0.0926 Loss_G: 0.0397 Convergence: 0.0958 k= 0.019351 lr = 0.0000060\n",
      "[17/25][730/9765] Loss_D: 0.0903 Loss_G: 0.0392 Convergence: 0.0939 k= 0.019346 lr = 0.0000060\n",
      "[17/25][740/9765] Loss_D: 0.0949 Loss_G: 0.0383 Convergence: 0.0956 k= 0.019345 lr = 0.0000060\n",
      "[17/25][750/9765] Loss_D: 0.1052 Loss_G: 0.0373 Convergence: 0.1109 k= 0.019347 lr = 0.0000060\n",
      "[17/25][760/9765] Loss_D: 0.0998 Loss_G: 0.0382 Convergence: 0.1025 k= 0.019369 lr = 0.0000060\n",
      "[17/25][770/9765] Loss_D: 0.0952 Loss_G: 0.0380 Convergence: 0.0964 k= 0.019368 lr = 0.0000060\n",
      "[17/25][780/9765] Loss_D: 0.0988 Loss_G: 0.0388 Convergence: 0.1005 k= 0.019368 lr = 0.0000060\n",
      "[17/25][790/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0993 k= 0.019347 lr = 0.0000060\n",
      "[17/25][800/9765] Loss_D: 0.0980 Loss_G: 0.0402 Convergence: 0.0994 k= 0.019341 lr = 0.0000060\n",
      "[17/25][810/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0953 k= 0.019331 lr = 0.0000060\n",
      "[17/25][820/9765] Loss_D: 0.1028 Loss_G: 0.0383 Convergence: 0.1067 k= 0.019331 lr = 0.0000060\n",
      "[17/25][830/9765] Loss_D: 0.1156 Loss_G: 0.0395 Convergence: 0.1234 k= 0.019346 lr = 0.0000060\n",
      "[17/25][840/9765] Loss_D: 0.0931 Loss_G: 0.0413 Convergence: 0.0976 k= 0.019341 lr = 0.0000060\n",
      "[17/25][850/9765] Loss_D: 0.0906 Loss_G: 0.0397 Convergence: 0.0945 k= 0.019325 lr = 0.0000060\n",
      "[17/25][860/9765] Loss_D: 0.0887 Loss_G: 0.0382 Convergence: 0.0919 k= 0.019310 lr = 0.0000060\n",
      "[17/25][870/9765] Loss_D: 0.0933 Loss_G: 0.0377 Convergence: 0.0941 k= 0.019313 lr = 0.0000060\n",
      "[17/25][880/9765] Loss_D: 0.1025 Loss_G: 0.0372 Convergence: 0.1072 k= 0.019334 lr = 0.0000060\n",
      "[17/25][890/9765] Loss_D: 0.0894 Loss_G: 0.0391 Convergence: 0.0931 k= 0.019337 lr = 0.0000060\n",
      "[17/25][900/9765] Loss_D: 0.0978 Loss_G: 0.0395 Convergence: 0.0986 k= 0.019339 lr = 0.0000060\n",
      "[17/25][910/9765] Loss_D: 0.0929 Loss_G: 0.0392 Convergence: 0.0954 k= 0.019329 lr = 0.0000060\n",
      "[17/25][920/9765] Loss_D: 0.1037 Loss_G: 0.0392 Convergence: 0.1070 k= 0.019329 lr = 0.0000060\n",
      "[17/25][930/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0960 k= 0.019322 lr = 0.0000060\n",
      "[17/25][940/9765] Loss_D: 0.0879 Loss_G: 0.0398 Convergence: 0.0930 k= 0.019309 lr = 0.0000060\n",
      "[17/25][950/9765] Loss_D: 0.0957 Loss_G: 0.0365 Convergence: 0.0985 k= 0.019309 lr = 0.0000060\n",
      "[17/25][960/9765] Loss_D: 0.0944 Loss_G: 0.0380 Convergence: 0.0951 k= 0.019308 lr = 0.0000060\n",
      "[17/25][970/9765] Loss_D: 0.0999 Loss_G: 0.0377 Convergence: 0.1032 k= 0.019315 lr = 0.0000060\n",
      "[17/25][980/9765] Loss_D: 0.0972 Loss_G: 0.0384 Convergence: 0.0988 k= 0.019318 lr = 0.0000060\n",
      "[17/25][990/9765] Loss_D: 0.1012 Loss_G: 0.0391 Convergence: 0.1036 k= 0.019327 lr = 0.0000060\n",
      "[17/25][1000/9765] Loss_D: 0.0936 Loss_G: 0.0366 Convergence: 0.0954 k= 0.019334 lr = 0.0000060\n",
      "[17/25][1010/9765] Loss_D: 0.0898 Loss_G: 0.0373 Convergence: 0.0916 k= 0.019337 lr = 0.0000060\n",
      "[17/25][1020/9765] Loss_D: 0.1049 Loss_G: 0.0384 Convergence: 0.1094 k= 0.019348 lr = 0.0000060\n",
      "[17/25][1030/9765] Loss_D: 0.0931 Loss_G: 0.0377 Convergence: 0.0940 k= 0.019363 lr = 0.0000060\n",
      "[17/25][1040/9765] Loss_D: 0.0984 Loss_G: 0.0380 Convergence: 0.1007 k= 0.019368 lr = 0.0000060\n",
      "[17/25][1050/9765] Loss_D: 0.1005 Loss_G: 0.0393 Convergence: 0.1024 k= 0.019382 lr = 0.0000060\n",
      "[17/25][1060/9765] Loss_D: 0.0983 Loss_G: 0.0422 Convergence: 0.1016 k= 0.019359 lr = 0.0000060\n",
      "[17/25][1070/9765] Loss_D: 0.0944 Loss_G: 0.0424 Convergence: 0.0995 k= 0.019338 lr = 0.0000060\n",
      "[17/25][1080/9765] Loss_D: 0.0874 Loss_G: 0.0377 Convergence: 0.0907 k= 0.019314 lr = 0.0000060\n",
      "[17/25][1090/9765] Loss_D: 0.0988 Loss_G: 0.0371 Convergence: 0.1023 k= 0.019322 lr = 0.0000060\n",
      "[17/25][1100/9765] Loss_D: 0.0907 Loss_G: 0.0362 Convergence: 0.0917 k= 0.019338 lr = 0.0000060\n",
      "[17/25][1110/9765] Loss_D: 0.0992 Loss_G: 0.0344 Convergence: 0.1055 k= 0.019361 lr = 0.0000060\n",
      "[17/25][1120/9765] Loss_D: 0.0935 Loss_G: 0.0328 Convergence: 0.0990 k= 0.019399 lr = 0.0000060\n",
      "[17/25][1130/9765] Loss_D: 0.0930 Loss_G: 0.0363 Convergence: 0.0949 k= 0.019453 lr = 0.0000060\n",
      "[17/25][1140/9765] Loss_D: 0.0917 Loss_G: 0.0400 Convergence: 0.0955 k= 0.019459 lr = 0.0000060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][1150/9765] Loss_D: 0.0970 Loss_G: 0.0371 Convergence: 0.0998 k= 0.019453 lr = 0.0000060\n",
      "[17/25][1160/9765] Loss_D: 0.0940 Loss_G: 0.0428 Convergence: 0.0997 k= 0.019439 lr = 0.0000060\n",
      "[17/25][1170/9765] Loss_D: 0.0962 Loss_G: 0.0397 Convergence: 0.0979 k= 0.019416 lr = 0.0000060\n",
      "[17/25][1180/9765] Loss_D: 0.0927 Loss_G: 0.0414 Convergence: 0.0975 k= 0.019412 lr = 0.0000060\n",
      "[17/25][1190/9765] Loss_D: 0.0902 Loss_G: 0.0392 Convergence: 0.0938 k= 0.019388 lr = 0.0000060\n",
      "[17/25][1200/9765] Loss_D: 0.0904 Loss_G: 0.0395 Convergence: 0.0942 k= 0.019379 lr = 0.0000060\n",
      "[17/25][1210/9765] Loss_D: 0.0893 Loss_G: 0.0397 Convergence: 0.0938 k= 0.019369 lr = 0.0000060\n",
      "[17/25][1220/9765] Loss_D: 0.1012 Loss_G: 0.0386 Convergence: 0.1042 k= 0.019367 lr = 0.0000060\n",
      "[17/25][1230/9765] Loss_D: 0.0971 Loss_G: 0.0394 Convergence: 0.0981 k= 0.019368 lr = 0.0000060\n",
      "[17/25][1240/9765] Loss_D: 0.1102 Loss_G: 0.0394 Convergence: 0.1159 k= 0.019380 lr = 0.0000060\n",
      "[17/25][1250/9765] Loss_D: 0.0967 Loss_G: 0.0388 Convergence: 0.0976 k= 0.019378 lr = 0.0000060\n",
      "[17/25][1260/9765] Loss_D: 0.0926 Loss_G: 0.0383 Convergence: 0.0943 k= 0.019384 lr = 0.0000060\n",
      "[17/25][1270/9765] Loss_D: 0.0948 Loss_G: 0.0395 Convergence: 0.0969 k= 0.019384 lr = 0.0000060\n",
      "[17/25][1280/9765] Loss_D: 0.0954 Loss_G: 0.0383 Convergence: 0.0963 k= 0.019374 lr = 0.0000060\n",
      "[17/25][1290/9765] Loss_D: 0.0934 Loss_G: 0.0400 Convergence: 0.0965 k= 0.019373 lr = 0.0000060\n",
      "[17/25][1300/9765] Loss_D: 0.0922 Loss_G: 0.0417 Convergence: 0.0975 k= 0.019373 lr = 0.0000060\n",
      "[17/25][1310/9765] Loss_D: 0.1027 Loss_G: 0.0391 Convergence: 0.1057 k= 0.019368 lr = 0.0000060\n",
      "[17/25][1320/9765] Loss_D: 0.0952 Loss_G: 0.0372 Convergence: 0.0971 k= 0.019361 lr = 0.0000060\n",
      "[17/25][1330/9765] Loss_D: 0.0924 Loss_G: 0.0376 Convergence: 0.0934 k= 0.019360 lr = 0.0000060\n",
      "[17/25][1340/9765] Loss_D: 0.0976 Loss_G: 0.0383 Convergence: 0.0994 k= 0.019369 lr = 0.0000060\n",
      "[17/25][1350/9765] Loss_D: 0.0977 Loss_G: 0.0375 Convergence: 0.1003 k= 0.019371 lr = 0.0000060\n",
      "[17/25][1360/9765] Loss_D: 0.0908 Loss_G: 0.0372 Convergence: 0.0921 k= 0.019386 lr = 0.0000060\n",
      "[17/25][1370/9765] Loss_D: 0.0886 Loss_G: 0.0382 Convergence: 0.0918 k= 0.019406 lr = 0.0000060\n",
      "[17/25][1380/9765] Loss_D: 0.0837 Loss_G: 0.0372 Convergence: 0.0878 k= 0.019402 lr = 0.0000060\n",
      "[17/25][1390/9765] Loss_D: 0.0868 Loss_G: 0.0375 Convergence: 0.0901 k= 0.019412 lr = 0.0000060\n",
      "[17/25][1400/9765] Loss_D: 0.0951 Loss_G: 0.0406 Convergence: 0.0981 k= 0.019420 lr = 0.0000060\n",
      "[17/25][1410/9765] Loss_D: 0.0936 Loss_G: 0.0375 Convergence: 0.0946 k= 0.019426 lr = 0.0000060\n",
      "[17/25][1420/9765] Loss_D: 0.1046 Loss_G: 0.0382 Convergence: 0.1093 k= 0.019433 lr = 0.0000060\n",
      "[17/25][1430/9765] Loss_D: 0.0900 Loss_G: 0.0381 Convergence: 0.0926 k= 0.019432 lr = 0.0000060\n",
      "[17/25][1440/9765] Loss_D: 0.1014 Loss_G: 0.0404 Convergence: 0.1026 k= 0.019434 lr = 0.0000060\n",
      "[17/25][1450/9765] Loss_D: 0.0981 Loss_G: 0.0377 Convergence: 0.1007 k= 0.019438 lr = 0.0000060\n",
      "[17/25][1460/9765] Loss_D: 0.0900 Loss_G: 0.0363 Convergence: 0.0907 k= 0.019446 lr = 0.0000060\n",
      "[17/25][1470/9765] Loss_D: 0.0949 Loss_G: 0.0352 Convergence: 0.0986 k= 0.019468 lr = 0.0000060\n",
      "[17/25][1480/9765] Loss_D: 0.0942 Loss_G: 0.0364 Convergence: 0.0964 k= 0.019494 lr = 0.0000060\n",
      "[17/25][1490/9765] Loss_D: 0.0993 Loss_G: 0.0380 Convergence: 0.1021 k= 0.019505 lr = 0.0000060\n",
      "[17/25][1500/9765] Loss_D: 0.0992 Loss_G: 0.0374 Convergence: 0.1026 k= 0.019509 lr = 0.0000060\n",
      "[17/25][1510/9765] Loss_D: 0.0967 Loss_G: 0.0414 Convergence: 0.1000 k= 0.019511 lr = 0.0000060\n",
      "[17/25][1520/9765] Loss_D: 0.1012 Loss_G: 0.0420 Convergence: 0.1032 k= 0.019491 lr = 0.0000060\n",
      "[17/25][1530/9765] Loss_D: 0.0874 Loss_G: 0.0405 Convergence: 0.0935 k= 0.019485 lr = 0.0000060\n",
      "[17/25][1540/9765] Loss_D: 0.1011 Loss_G: 0.0395 Convergence: 0.1031 k= 0.019476 lr = 0.0000060\n",
      "[17/25][1550/9765] Loss_D: 0.0990 Loss_G: 0.0385 Convergence: 0.1011 k= 0.019480 lr = 0.0000060\n",
      "[17/25][1560/9765] Loss_D: 0.0995 Loss_G: 0.0367 Convergence: 0.1037 k= 0.019501 lr = 0.0000060\n",
      "[17/25][1570/9765] Loss_D: 0.1033 Loss_G: 0.0399 Convergence: 0.1058 k= 0.019514 lr = 0.0000060\n",
      "[17/25][1580/9765] Loss_D: 0.0933 Loss_G: 0.0376 Convergence: 0.0941 k= 0.019533 lr = 0.0000060\n",
      "[17/25][1590/9765] Loss_D: 0.0981 Loss_G: 0.0366 Convergence: 0.1017 k= 0.019542 lr = 0.0000060\n",
      "[17/25][1600/9765] Loss_D: 0.0901 Loss_G: 0.0394 Convergence: 0.0939 k= 0.019553 lr = 0.0000060\n",
      "[17/25][1610/9765] Loss_D: 0.0952 Loss_G: 0.0384 Convergence: 0.0960 k= 0.019553 lr = 0.0000060\n",
      "[17/25][1620/9765] Loss_D: 0.1001 Loss_G: 0.0399 Convergence: 0.1014 k= 0.019558 lr = 0.0000060\n",
      "[17/25][1630/9765] Loss_D: 0.0991 Loss_G: 0.0417 Convergence: 0.1016 k= 0.019539 lr = 0.0000060\n",
      "[17/25][1640/9765] Loss_D: 0.1127 Loss_G: 0.0402 Convergence: 0.1187 k= 0.019523 lr = 0.0000060\n",
      "[17/25][1650/9765] Loss_D: 0.1020 Loss_G: 0.0399 Convergence: 0.1040 k= 0.019507 lr = 0.0000060\n",
      "[17/25][1660/9765] Loss_D: 0.1006 Loss_G: 0.0382 Convergence: 0.1036 k= 0.019494 lr = 0.0000060\n",
      "[17/25][1670/9765] Loss_D: 0.0968 Loss_G: 0.0384 Convergence: 0.0981 k= 0.019496 lr = 0.0000060\n",
      "[17/25][1680/9765] Loss_D: 0.0986 Loss_G: 0.0396 Convergence: 0.0995 k= 0.019504 lr = 0.0000060\n",
      "[17/25][1690/9765] Loss_D: 0.0949 Loss_G: 0.0375 Convergence: 0.0965 k= 0.019490 lr = 0.0000060\n",
      "[17/25][1700/9765] Loss_D: 0.0925 Loss_G: 0.0401 Convergence: 0.0960 k= 0.019492 lr = 0.0000060\n",
      "[17/25][1710/9765] Loss_D: 0.0992 Loss_G: 0.0396 Convergence: 0.1004 k= 0.019494 lr = 0.0000060\n",
      "[17/25][1720/9765] Loss_D: 0.0922 Loss_G: 0.0393 Convergence: 0.0951 k= 0.019475 lr = 0.0000060\n",
      "[17/25][1730/9765] Loss_D: 0.1025 Loss_G: 0.0403 Convergence: 0.1042 k= 0.019471 lr = 0.0000060\n",
      "[17/25][1740/9765] Loss_D: 0.0930 Loss_G: 0.0407 Convergence: 0.0970 k= 0.019445 lr = 0.0000060\n",
      "[17/25][1750/9765] Loss_D: 0.1057 Loss_G: 0.0403 Convergence: 0.1088 k= 0.019428 lr = 0.0000060\n",
      "[17/25][1760/9765] Loss_D: 0.1003 Loss_G: 0.0399 Convergence: 0.1017 k= 0.019423 lr = 0.0000060\n",
      "[17/25][1770/9765] Loss_D: 0.0901 Loss_G: 0.0400 Convergence: 0.0946 k= 0.019417 lr = 0.0000060\n",
      "[17/25][1780/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1017 k= 0.019407 lr = 0.0000060\n",
      "[17/25][1790/9765] Loss_D: 0.0938 Loss_G: 0.0401 Convergence: 0.0968 k= 0.019405 lr = 0.0000060\n",
      "[17/25][1800/9765] Loss_D: 0.0984 Loss_G: 0.0376 Convergence: 0.1012 k= 0.019404 lr = 0.0000060\n",
      "[17/25][1810/9765] Loss_D: 0.0941 Loss_G: 0.0378 Convergence: 0.0950 k= 0.019395 lr = 0.0000060\n",
      "[17/25][1820/9765] Loss_D: 0.0876 Loss_G: 0.0377 Convergence: 0.0906 k= 0.019399 lr = 0.0000060\n",
      "[17/25][1830/9765] Loss_D: 0.0949 Loss_G: 0.0391 Convergence: 0.0965 k= 0.019402 lr = 0.0000060\n",
      "[17/25][1840/9765] Loss_D: 0.0939 Loss_G: 0.0393 Convergence: 0.0961 k= 0.019379 lr = 0.0000060\n",
      "[17/25][1850/9765] Loss_D: 0.0972 Loss_G: 0.0407 Convergence: 0.0995 k= 0.019375 lr = 0.0000060\n",
      "[17/25][1860/9765] Loss_D: 0.0971 Loss_G: 0.0411 Convergence: 0.0999 k= 0.019367 lr = 0.0000060\n",
      "[17/25][1870/9765] Loss_D: 0.0989 Loss_G: 0.0371 Convergence: 0.1024 k= 0.019355 lr = 0.0000060\n",
      "[17/25][1880/9765] Loss_D: 0.0960 Loss_G: 0.0379 Convergence: 0.0975 k= 0.019364 lr = 0.0000060\n",
      "[17/25][1890/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0973 k= 0.019373 lr = 0.0000060\n",
      "[17/25][1900/9765] Loss_D: 0.0965 Loss_G: 0.0368 Convergence: 0.0993 k= 0.019369 lr = 0.0000060\n",
      "[17/25][1910/9765] Loss_D: 0.0994 Loss_G: 0.0400 Convergence: 0.1003 k= 0.019393 lr = 0.0000060\n",
      "[17/25][1920/9765] Loss_D: 0.0966 Loss_G: 0.0367 Convergence: 0.0996 k= 0.019392 lr = 0.0000060\n",
      "[17/25][1930/9765] Loss_D: 0.0951 Loss_G: 0.0400 Convergence: 0.0975 k= 0.019401 lr = 0.0000060\n",
      "[17/25][1940/9765] Loss_D: 0.0930 Loss_G: 0.0392 Convergence: 0.0954 k= 0.019414 lr = 0.0000060\n",
      "[17/25][1950/9765] Loss_D: 0.0934 Loss_G: 0.0415 Convergence: 0.0980 k= 0.019423 lr = 0.0000060\n",
      "[17/25][1960/9765] Loss_D: 0.0952 Loss_G: 0.0395 Convergence: 0.0971 k= 0.019400 lr = 0.0000060\n",
      "[17/25][1970/9765] Loss_D: 0.0923 Loss_G: 0.0386 Convergence: 0.0944 k= 0.019410 lr = 0.0000060\n",
      "[17/25][1980/9765] Loss_D: 0.0944 Loss_G: 0.0389 Convergence: 0.0960 k= 0.019414 lr = 0.0000060\n",
      "[17/25][1990/9765] Loss_D: 0.0990 Loss_G: 0.0407 Convergence: 0.1006 k= 0.019415 lr = 0.0000060\n",
      "[17/25][2000/9765] Loss_D: 0.0973 Loss_G: 0.0375 Convergence: 0.0997 k= 0.019423 lr = 0.0000057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][2010/9765] Loss_D: 0.1013 Loss_G: 0.0382 Convergence: 0.1046 k= 0.019438 lr = 0.0000057\n",
      "[17/25][2020/9765] Loss_D: 0.0930 Loss_G: 0.0386 Convergence: 0.0948 k= 0.019450 lr = 0.0000057\n",
      "[17/25][2030/9765] Loss_D: 0.0864 Loss_G: 0.0394 Convergence: 0.0917 k= 0.019445 lr = 0.0000057\n",
      "[17/25][2040/9765] Loss_D: 0.1012 Loss_G: 0.0393 Convergence: 0.1034 k= 0.019450 lr = 0.0000057\n",
      "[17/25][2050/9765] Loss_D: 0.0888 Loss_G: 0.0383 Convergence: 0.0920 k= 0.019438 lr = 0.0000057\n",
      "[17/25][2060/9765] Loss_D: 0.1008 Loss_G: 0.0380 Convergence: 0.1042 k= 0.019460 lr = 0.0000057\n",
      "[17/25][2070/9765] Loss_D: 0.0906 Loss_G: 0.0371 Convergence: 0.0919 k= 0.019479 lr = 0.0000057\n",
      "[17/25][2080/9765] Loss_D: 0.0936 Loss_G: 0.0390 Convergence: 0.0956 k= 0.019482 lr = 0.0000057\n",
      "[17/25][2090/9765] Loss_D: 0.0958 Loss_G: 0.0401 Convergence: 0.0980 k= 0.019495 lr = 0.0000057\n",
      "[17/25][2100/9765] Loss_D: 0.1046 Loss_G: 0.0388 Convergence: 0.1086 k= 0.019502 lr = 0.0000057\n",
      "[17/25][2110/9765] Loss_D: 0.0975 Loss_G: 0.0396 Convergence: 0.0985 k= 0.019511 lr = 0.0000057\n",
      "[17/25][2120/9765] Loss_D: 0.0932 Loss_G: 0.0413 Convergence: 0.0977 k= 0.019492 lr = 0.0000057\n",
      "[17/25][2130/9765] Loss_D: 0.0963 Loss_G: 0.0387 Convergence: 0.0973 k= 0.019479 lr = 0.0000057\n",
      "[17/25][2140/9765] Loss_D: 0.1104 Loss_G: 0.0410 Convergence: 0.1146 k= 0.019477 lr = 0.0000057\n",
      "[17/25][2150/9765] Loss_D: 0.0843 Loss_G: 0.0405 Convergence: 0.0915 k= 0.019447 lr = 0.0000057\n",
      "[17/25][2160/9765] Loss_D: 0.1054 Loss_G: 0.0410 Convergence: 0.1077 k= 0.019428 lr = 0.0000057\n",
      "[17/25][2170/9765] Loss_D: 0.0915 Loss_G: 0.0395 Convergence: 0.0949 k= 0.019404 lr = 0.0000057\n",
      "[17/25][2180/9765] Loss_D: 0.0923 Loss_G: 0.0392 Convergence: 0.0950 k= 0.019417 lr = 0.0000057\n",
      "[17/25][2190/9765] Loss_D: 0.1010 Loss_G: 0.0385 Convergence: 0.1040 k= 0.019431 lr = 0.0000057\n",
      "[17/25][2200/9765] Loss_D: 0.0896 Loss_G: 0.0360 Convergence: 0.0904 k= 0.019447 lr = 0.0000057\n",
      "[17/25][2210/9765] Loss_D: 0.0918 Loss_G: 0.0366 Convergence: 0.0930 k= 0.019481 lr = 0.0000057\n",
      "[17/25][2220/9765] Loss_D: 0.0901 Loss_G: 0.0361 Convergence: 0.0910 k= 0.019505 lr = 0.0000057\n",
      "[17/25][2230/9765] Loss_D: 0.0930 Loss_G: 0.0380 Convergence: 0.0942 k= 0.019532 lr = 0.0000057\n",
      "[17/25][2240/9765] Loss_D: 0.1115 Loss_G: 0.0399 Convergence: 0.1172 k= 0.019535 lr = 0.0000057\n",
      "[17/25][2250/9765] Loss_D: 0.0938 Loss_G: 0.0410 Convergence: 0.0978 k= 0.019510 lr = 0.0000057\n",
      "[17/25][2260/9765] Loss_D: 0.0908 Loss_G: 0.0388 Convergence: 0.0938 k= 0.019505 lr = 0.0000057\n",
      "[17/25][2270/9765] Loss_D: 0.0979 Loss_G: 0.0396 Convergence: 0.0988 k= 0.019498 lr = 0.0000057\n",
      "[17/25][2280/9765] Loss_D: 0.0922 Loss_G: 0.0414 Convergence: 0.0972 k= 0.019477 lr = 0.0000057\n",
      "[17/25][2290/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0978 k= 0.019468 lr = 0.0000057\n",
      "[17/25][2300/9765] Loss_D: 0.0977 Loss_G: 0.0392 Convergence: 0.0987 k= 0.019461 lr = 0.0000057\n",
      "[17/25][2310/9765] Loss_D: 0.0997 Loss_G: 0.0387 Convergence: 0.1020 k= 0.019465 lr = 0.0000057\n",
      "[17/25][2320/9765] Loss_D: 0.0955 Loss_G: 0.0388 Convergence: 0.0965 k= 0.019468 lr = 0.0000057\n",
      "[17/25][2330/9765] Loss_D: 0.0935 Loss_G: 0.0391 Convergence: 0.0956 k= 0.019480 lr = 0.0000057\n",
      "[17/25][2340/9765] Loss_D: 0.1034 Loss_G: 0.0382 Convergence: 0.1075 k= 0.019487 lr = 0.0000057\n",
      "[17/25][2350/9765] Loss_D: 0.0937 Loss_G: 0.0388 Convergence: 0.0955 k= 0.019494 lr = 0.0000057\n",
      "[17/25][2360/9765] Loss_D: 0.0983 Loss_G: 0.0385 Convergence: 0.1001 k= 0.019506 lr = 0.0000057\n",
      "[17/25][2370/9765] Loss_D: 0.0880 Loss_G: 0.0394 Convergence: 0.0927 k= 0.019504 lr = 0.0000057\n",
      "[17/25][2380/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0991 k= 0.019502 lr = 0.0000057\n",
      "[17/25][2390/9765] Loss_D: 0.0924 Loss_G: 0.0411 Convergence: 0.0970 k= 0.019486 lr = 0.0000057\n",
      "[17/25][2400/9765] Loss_D: 0.0940 Loss_G: 0.0407 Convergence: 0.0976 k= 0.019468 lr = 0.0000057\n",
      "[17/25][2410/9765] Loss_D: 0.0937 Loss_G: 0.0412 Convergence: 0.0979 k= 0.019436 lr = 0.0000057\n",
      "[17/25][2420/9765] Loss_D: 0.0957 Loss_G: 0.0407 Convergence: 0.0986 k= 0.019424 lr = 0.0000057\n",
      "[17/25][2430/9765] Loss_D: 0.1010 Loss_G: 0.0395 Convergence: 0.1029 k= 0.019417 lr = 0.0000057\n",
      "[17/25][2440/9765] Loss_D: 0.0908 Loss_G: 0.0366 Convergence: 0.0915 k= 0.019429 lr = 0.0000057\n",
      "[17/25][2450/9765] Loss_D: 0.0997 Loss_G: 0.0397 Convergence: 0.1009 k= 0.019447 lr = 0.0000057\n",
      "[17/25][2460/9765] Loss_D: 0.0953 Loss_G: 0.0397 Convergence: 0.0974 k= 0.019444 lr = 0.0000057\n",
      "[17/25][2470/9765] Loss_D: 0.1053 Loss_G: 0.0380 Convergence: 0.1104 k= 0.019452 lr = 0.0000057\n",
      "[17/25][2480/9765] Loss_D: 0.0952 Loss_G: 0.0362 Convergence: 0.0980 k= 0.019472 lr = 0.0000057\n",
      "[17/25][2490/9765] Loss_D: 0.0921 Loss_G: 0.0364 Convergence: 0.0935 k= 0.019492 lr = 0.0000057\n",
      "[17/25][2500/9765] Loss_D: 0.1003 Loss_G: 0.0358 Convergence: 0.1056 k= 0.019521 lr = 0.0000057\n",
      "[17/25][2510/9765] Loss_D: 0.0955 Loss_G: 0.0380 Convergence: 0.0968 k= 0.019540 lr = 0.0000057\n",
      "[17/25][2520/9765] Loss_D: 0.0891 Loss_G: 0.0400 Convergence: 0.0940 k= 0.019536 lr = 0.0000057\n",
      "[17/25][2530/9765] Loss_D: 0.0945 Loss_G: 0.0388 Convergence: 0.0959 k= 0.019531 lr = 0.0000057\n",
      "[17/25][2540/9765] Loss_D: 0.0999 Loss_G: 0.0399 Convergence: 0.1010 k= 0.019520 lr = 0.0000057\n",
      "[17/25][2550/9765] Loss_D: 0.0984 Loss_G: 0.0405 Convergence: 0.1001 k= 0.019512 lr = 0.0000057\n",
      "[17/25][2560/9765] Loss_D: 0.1029 Loss_G: 0.0408 Convergence: 0.1043 k= 0.019509 lr = 0.0000057\n",
      "[17/25][2570/9765] Loss_D: 0.0973 Loss_G: 0.0376 Convergence: 0.0996 k= 0.019502 lr = 0.0000057\n",
      "[17/25][2580/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0946 k= 0.019514 lr = 0.0000057\n",
      "[17/25][2590/9765] Loss_D: 0.0948 Loss_G: 0.0392 Convergence: 0.0966 k= 0.019517 lr = 0.0000057\n",
      "[17/25][2600/9765] Loss_D: 0.1091 Loss_G: 0.0389 Convergence: 0.1150 k= 0.019530 lr = 0.0000057\n",
      "[17/25][2610/9765] Loss_D: 0.0922 Loss_G: 0.0381 Convergence: 0.0939 k= 0.019533 lr = 0.0000057\n",
      "[17/25][2620/9765] Loss_D: 0.0954 Loss_G: 0.0382 Convergence: 0.0964 k= 0.019544 lr = 0.0000057\n",
      "[17/25][2630/9765] Loss_D: 0.0927 Loss_G: 0.0407 Convergence: 0.0968 k= 0.019540 lr = 0.0000057\n",
      "[17/25][2640/9765] Loss_D: 0.0896 Loss_G: 0.0384 Convergence: 0.0926 k= 0.019532 lr = 0.0000057\n",
      "[17/25][2650/9765] Loss_D: 0.0965 Loss_G: 0.0396 Convergence: 0.0980 k= 0.019512 lr = 0.0000057\n",
      "[17/25][2660/9765] Loss_D: 0.0891 Loss_G: 0.0385 Convergence: 0.0925 k= 0.019514 lr = 0.0000057\n",
      "[17/25][2670/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1003 k= 0.019520 lr = 0.0000057\n",
      "[17/25][2680/9765] Loss_D: 0.1041 Loss_G: 0.0383 Convergence: 0.1084 k= 0.019524 lr = 0.0000057\n",
      "[17/25][2690/9765] Loss_D: 0.1111 Loss_G: 0.0402 Convergence: 0.1165 k= 0.019533 lr = 0.0000057\n",
      "[17/25][2700/9765] Loss_D: 0.0984 Loss_G: 0.0374 Convergence: 0.1014 k= 0.019534 lr = 0.0000057\n",
      "[17/25][2710/9765] Loss_D: 0.0905 Loss_G: 0.0381 Convergence: 0.0928 k= 0.019545 lr = 0.0000057\n",
      "[17/25][2720/9765] Loss_D: 0.0976 Loss_G: 0.0383 Convergence: 0.0994 k= 0.019554 lr = 0.0000057\n",
      "[17/25][2730/9765] Loss_D: 0.0952 Loss_G: 0.0405 Convergence: 0.0982 k= 0.019549 lr = 0.0000057\n",
      "[17/25][2740/9765] Loss_D: 0.0962 Loss_G: 0.0375 Convergence: 0.0981 k= 0.019559 lr = 0.0000057\n",
      "[17/25][2750/9765] Loss_D: 0.0979 Loss_G: 0.0373 Convergence: 0.1008 k= 0.019579 lr = 0.0000057\n",
      "[17/25][2760/9765] Loss_D: 0.0959 Loss_G: 0.0365 Convergence: 0.0989 k= 0.019587 lr = 0.0000057\n",
      "[17/25][2770/9765] Loss_D: 0.0838 Loss_G: 0.0373 Convergence: 0.0880 k= 0.019591 lr = 0.0000057\n",
      "[17/25][2780/9765] Loss_D: 0.1007 Loss_G: 0.0397 Convergence: 0.1024 k= 0.019600 lr = 0.0000057\n",
      "[17/25][2790/9765] Loss_D: 0.0940 Loss_G: 0.0376 Convergence: 0.0950 k= 0.019609 lr = 0.0000057\n",
      "[17/25][2800/9765] Loss_D: 0.1011 Loss_G: 0.0370 Convergence: 0.1055 k= 0.019618 lr = 0.0000057\n",
      "[17/25][2810/9765] Loss_D: 0.1030 Loss_G: 0.0376 Convergence: 0.1076 k= 0.019628 lr = 0.0000057\n",
      "[17/25][2820/9765] Loss_D: 0.0923 Loss_G: 0.0400 Convergence: 0.0958 k= 0.019647 lr = 0.0000057\n",
      "[17/25][2830/9765] Loss_D: 0.0930 Loss_G: 0.0376 Convergence: 0.0939 k= 0.019644 lr = 0.0000057\n",
      "[17/25][2840/9765] Loss_D: 0.0983 Loss_G: 0.0399 Convergence: 0.0993 k= 0.019658 lr = 0.0000057\n",
      "[17/25][2850/9765] Loss_D: 0.0936 Loss_G: 0.0377 Convergence: 0.0944 k= 0.019648 lr = 0.0000057\n",
      "[17/25][2860/9765] Loss_D: 0.0914 Loss_G: 0.0400 Convergence: 0.0953 k= 0.019639 lr = 0.0000057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][2870/9765] Loss_D: 0.0980 Loss_G: 0.0396 Convergence: 0.0989 k= 0.019621 lr = 0.0000057\n",
      "[17/25][2880/9765] Loss_D: 0.0963 Loss_G: 0.0381 Convergence: 0.0979 k= 0.019615 lr = 0.0000057\n",
      "[17/25][2890/9765] Loss_D: 0.0973 Loss_G: 0.0399 Convergence: 0.0987 k= 0.019606 lr = 0.0000057\n",
      "[17/25][2900/9765] Loss_D: 0.1035 Loss_G: 0.0396 Convergence: 0.1064 k= 0.019611 lr = 0.0000057\n",
      "[17/25][2910/9765] Loss_D: 0.1009 Loss_G: 0.0404 Convergence: 0.1020 k= 0.019613 lr = 0.0000057\n",
      "[17/25][2920/9765] Loss_D: 0.0986 Loss_G: 0.0366 Convergence: 0.1025 k= 0.019622 lr = 0.0000057\n",
      "[17/25][2930/9765] Loss_D: 0.1002 Loss_G: 0.0403 Convergence: 0.1011 k= 0.019625 lr = 0.0000057\n",
      "[17/25][2940/9765] Loss_D: 0.1123 Loss_G: 0.0404 Convergence: 0.1180 k= 0.019623 lr = 0.0000057\n",
      "[17/25][2950/9765] Loss_D: 0.0943 Loss_G: 0.0409 Convergence: 0.0980 k= 0.019612 lr = 0.0000057\n",
      "[17/25][2960/9765] Loss_D: 0.0947 Loss_G: 0.0398 Convergence: 0.0971 k= 0.019608 lr = 0.0000057\n",
      "[17/25][2970/9765] Loss_D: 0.1099 Loss_G: 0.0392 Convergence: 0.1157 k= 0.019610 lr = 0.0000057\n",
      "[17/25][2980/9765] Loss_D: 0.1021 Loss_G: 0.0389 Convergence: 0.1051 k= 0.019622 lr = 0.0000057\n",
      "[17/25][2990/9765] Loss_D: 0.0908 Loss_G: 0.0384 Convergence: 0.0934 k= 0.019620 lr = 0.0000057\n",
      "[17/25][3000/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0990 k= 0.019620 lr = 0.0000057\n",
      "[17/25][3010/9765] Loss_D: 0.0927 Loss_G: 0.0399 Convergence: 0.0960 k= 0.019619 lr = 0.0000057\n",
      "[17/25][3020/9765] Loss_D: 0.0977 Loss_G: 0.0384 Convergence: 0.0994 k= 0.019621 lr = 0.0000057\n",
      "[17/25][3030/9765] Loss_D: 0.1079 Loss_G: 0.0407 Convergence: 0.1115 k= 0.019620 lr = 0.0000057\n",
      "[17/25][3040/9765] Loss_D: 0.0955 Loss_G: 0.0395 Convergence: 0.0972 k= 0.019607 lr = 0.0000057\n",
      "[17/25][3050/9765] Loss_D: 0.0967 Loss_G: 0.0412 Convergence: 0.0997 k= 0.019583 lr = 0.0000057\n",
      "[17/25][3060/9765] Loss_D: 0.0953 Loss_G: 0.0390 Convergence: 0.0967 k= 0.019568 lr = 0.0000057\n",
      "[17/25][3070/9765] Loss_D: 0.1002 Loss_G: 0.0390 Convergence: 0.1023 k= 0.019560 lr = 0.0000057\n",
      "[17/25][3080/9765] Loss_D: 0.0840 Loss_G: 0.0392 Convergence: 0.0901 k= 0.019556 lr = 0.0000057\n",
      "[17/25][3090/9765] Loss_D: 0.0932 Loss_G: 0.0370 Convergence: 0.0945 k= 0.019560 lr = 0.0000057\n",
      "[17/25][3100/9765] Loss_D: 0.1055 Loss_G: 0.0365 Convergence: 0.1122 k= 0.019582 lr = 0.0000057\n",
      "[17/25][3110/9765] Loss_D: 0.0945 Loss_G: 0.0377 Convergence: 0.0956 k= 0.019599 lr = 0.0000057\n",
      "[17/25][3120/9765] Loss_D: 0.0985 Loss_G: 0.0382 Convergence: 0.1008 k= 0.019608 lr = 0.0000057\n",
      "[17/25][3130/9765] Loss_D: 0.1003 Loss_G: 0.0386 Convergence: 0.1028 k= 0.019615 lr = 0.0000057\n",
      "[17/25][3140/9765] Loss_D: 0.0979 Loss_G: 0.0425 Convergence: 0.1017 k= 0.019591 lr = 0.0000057\n",
      "[17/25][3150/9765] Loss_D: 0.0944 Loss_G: 0.0425 Convergence: 0.0996 k= 0.019568 lr = 0.0000057\n",
      "[17/25][3160/9765] Loss_D: 0.0964 Loss_G: 0.0401 Convergence: 0.0984 k= 0.019561 lr = 0.0000057\n",
      "[17/25][3170/9765] Loss_D: 0.0874 Loss_G: 0.0381 Convergence: 0.0910 k= 0.019554 lr = 0.0000057\n",
      "[17/25][3180/9765] Loss_D: 0.0915 Loss_G: 0.0389 Convergence: 0.0943 k= 0.019554 lr = 0.0000057\n",
      "[17/25][3190/9765] Loss_D: 0.0919 Loss_G: 0.0376 Convergence: 0.0932 k= 0.019565 lr = 0.0000057\n",
      "[17/25][3200/9765] Loss_D: 0.1048 Loss_G: 0.0380 Convergence: 0.1098 k= 0.019584 lr = 0.0000057\n",
      "[17/25][3210/9765] Loss_D: 0.0883 Loss_G: 0.0397 Convergence: 0.0931 k= 0.019584 lr = 0.0000057\n",
      "[17/25][3220/9765] Loss_D: 0.0977 Loss_G: 0.0407 Convergence: 0.0998 k= 0.019565 lr = 0.0000057\n",
      "[17/25][3230/9765] Loss_D: 0.1009 Loss_G: 0.0406 Convergence: 0.1018 k= 0.019542 lr = 0.0000057\n",
      "[17/25][3240/9765] Loss_D: 0.0962 Loss_G: 0.0431 Convergence: 0.1013 k= 0.019514 lr = 0.0000057\n",
      "[17/25][3250/9765] Loss_D: 0.0954 Loss_G: 0.0411 Convergence: 0.0988 k= 0.019491 lr = 0.0000057\n",
      "[17/25][3260/9765] Loss_D: 0.0948 Loss_G: 0.0389 Convergence: 0.0963 k= 0.019472 lr = 0.0000057\n",
      "[17/25][3270/9765] Loss_D: 0.0907 Loss_G: 0.0388 Convergence: 0.0937 k= 0.019454 lr = 0.0000057\n",
      "[17/25][3280/9765] Loss_D: 0.1012 Loss_G: 0.0387 Convergence: 0.1040 k= 0.019454 lr = 0.0000057\n",
      "[17/25][3290/9765] Loss_D: 0.0966 Loss_G: 0.0382 Convergence: 0.0980 k= 0.019461 lr = 0.0000057\n",
      "[17/25][3300/9765] Loss_D: 0.0941 Loss_G: 0.0390 Convergence: 0.0959 k= 0.019469 lr = 0.0000057\n",
      "[17/25][3310/9765] Loss_D: 0.0960 Loss_G: 0.0411 Convergence: 0.0991 k= 0.019464 lr = 0.0000057\n",
      "[17/25][3320/9765] Loss_D: 0.0941 Loss_G: 0.0399 Convergence: 0.0968 k= 0.019432 lr = 0.0000057\n",
      "[17/25][3330/9765] Loss_D: 0.1033 Loss_G: 0.0401 Convergence: 0.1056 k= 0.019440 lr = 0.0000057\n",
      "[17/25][3340/9765] Loss_D: 0.0981 Loss_G: 0.0385 Convergence: 0.0999 k= 0.019437 lr = 0.0000057\n",
      "[17/25][3350/9765] Loss_D: 0.1015 Loss_G: 0.0400 Convergence: 0.1032 k= 0.019433 lr = 0.0000057\n",
      "[17/25][3360/9765] Loss_D: 0.0980 Loss_G: 0.0394 Convergence: 0.0989 k= 0.019431 lr = 0.0000057\n",
      "[17/25][3370/9765] Loss_D: 0.1062 Loss_G: 0.0390 Convergence: 0.1107 k= 0.019419 lr = 0.0000057\n",
      "[17/25][3380/9765] Loss_D: 0.0971 Loss_G: 0.0380 Convergence: 0.0989 k= 0.019428 lr = 0.0000057\n",
      "[17/25][3390/9765] Loss_D: 0.1078 Loss_G: 0.0390 Convergence: 0.1130 k= 0.019434 lr = 0.0000057\n",
      "[17/25][3400/9765] Loss_D: 0.0911 Loss_G: 0.0394 Convergence: 0.0945 k= 0.019444 lr = 0.0000057\n",
      "[17/25][3410/9765] Loss_D: 0.0942 Loss_G: 0.0408 Convergence: 0.0978 k= 0.019457 lr = 0.0000057\n",
      "[17/25][3420/9765] Loss_D: 0.1033 Loss_G: 0.0391 Convergence: 0.1066 k= 0.019447 lr = 0.0000057\n",
      "[17/25][3430/9765] Loss_D: 0.0934 Loss_G: 0.0376 Convergence: 0.0941 k= 0.019454 lr = 0.0000057\n",
      "[17/25][3440/9765] Loss_D: 0.0885 Loss_G: 0.0377 Convergence: 0.0913 k= 0.019478 lr = 0.0000057\n",
      "[17/25][3450/9765] Loss_D: 0.0996 Loss_G: 0.0381 Convergence: 0.1025 k= 0.019488 lr = 0.0000057\n",
      "[17/25][3460/9765] Loss_D: 0.0942 Loss_G: 0.0390 Convergence: 0.0960 k= 0.019479 lr = 0.0000057\n",
      "[17/25][3470/9765] Loss_D: 0.0895 Loss_G: 0.0412 Convergence: 0.0953 k= 0.019481 lr = 0.0000057\n",
      "[17/25][3480/9765] Loss_D: 0.0966 Loss_G: 0.0408 Convergence: 0.0993 k= 0.019459 lr = 0.0000057\n",
      "[17/25][3490/9765] Loss_D: 0.0997 Loss_G: 0.0384 Convergence: 0.1022 k= 0.019446 lr = 0.0000057\n",
      "[17/25][3500/9765] Loss_D: 0.0934 Loss_G: 0.0397 Convergence: 0.0962 k= 0.019459 lr = 0.0000057\n",
      "[17/25][3510/9765] Loss_D: 0.0927 Loss_G: 0.0401 Convergence: 0.0962 k= 0.019445 lr = 0.0000057\n",
      "[17/25][3520/9765] Loss_D: 0.0984 Loss_G: 0.0384 Convergence: 0.1005 k= 0.019431 lr = 0.0000057\n",
      "[17/25][3530/9765] Loss_D: 0.0915 Loss_G: 0.0402 Convergence: 0.0956 k= 0.019423 lr = 0.0000057\n",
      "[17/25][3540/9765] Loss_D: 0.0936 Loss_G: 0.0385 Convergence: 0.0951 k= 0.019399 lr = 0.0000057\n",
      "[17/25][3550/9765] Loss_D: 0.0936 Loss_G: 0.0405 Convergence: 0.0971 k= 0.019396 lr = 0.0000057\n",
      "[17/25][3560/9765] Loss_D: 0.0907 Loss_G: 0.0376 Convergence: 0.0924 k= 0.019395 lr = 0.0000057\n",
      "[17/25][3570/9765] Loss_D: 0.0953 Loss_G: 0.0379 Convergence: 0.0966 k= 0.019417 lr = 0.0000057\n",
      "[17/25][3580/9765] Loss_D: 0.0925 Loss_G: 0.0390 Convergence: 0.0949 k= 0.019421 lr = 0.0000057\n",
      "[17/25][3590/9765] Loss_D: 0.0973 Loss_G: 0.0359 Convergence: 0.1014 k= 0.019410 lr = 0.0000057\n",
      "[17/25][3600/9765] Loss_D: 0.0954 Loss_G: 0.0376 Convergence: 0.0970 k= 0.019436 lr = 0.0000057\n",
      "[17/25][3610/9765] Loss_D: 0.0930 Loss_G: 0.0384 Convergence: 0.0947 k= 0.019435 lr = 0.0000057\n",
      "[17/25][3620/9765] Loss_D: 0.0936 Loss_G: 0.0397 Convergence: 0.0963 k= 0.019438 lr = 0.0000057\n",
      "[17/25][3630/9765] Loss_D: 0.0959 Loss_G: 0.0410 Convergence: 0.0990 k= 0.019422 lr = 0.0000057\n",
      "[17/25][3640/9765] Loss_D: 0.0938 Loss_G: 0.0407 Convergence: 0.0975 k= 0.019411 lr = 0.0000057\n",
      "[17/25][3650/9765] Loss_D: 0.0894 Loss_G: 0.0395 Convergence: 0.0936 k= 0.019396 lr = 0.0000057\n",
      "[17/25][3660/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0955 k= 0.019376 lr = 0.0000057\n",
      "[17/25][3670/9765] Loss_D: 0.0993 Loss_G: 0.0395 Convergence: 0.1006 k= 0.019380 lr = 0.0000057\n",
      "[17/25][3680/9765] Loss_D: 0.0946 Loss_G: 0.0404 Convergence: 0.0976 k= 0.019366 lr = 0.0000057\n",
      "[17/25][3690/9765] Loss_D: 0.0995 Loss_G: 0.0394 Convergence: 0.1010 k= 0.019340 lr = 0.0000057\n",
      "[17/25][3700/9765] Loss_D: 0.0988 Loss_G: 0.0371 Convergence: 0.1022 k= 0.019338 lr = 0.0000057\n",
      "[17/25][3710/9765] Loss_D: 0.0997 Loss_G: 0.0366 Convergence: 0.1041 k= 0.019349 lr = 0.0000057\n",
      "[17/25][3720/9765] Loss_D: 0.0903 Loss_G: 0.0371 Convergence: 0.0917 k= 0.019364 lr = 0.0000057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][3730/9765] Loss_D: 0.0940 Loss_G: 0.0361 Convergence: 0.0965 k= 0.019381 lr = 0.0000057\n",
      "[17/25][3740/9765] Loss_D: 0.0944 Loss_G: 0.0361 Convergence: 0.0970 k= 0.019401 lr = 0.0000057\n",
      "[17/25][3750/9765] Loss_D: 0.0981 Loss_G: 0.0374 Convergence: 0.1009 k= 0.019412 lr = 0.0000057\n",
      "[17/25][3760/9765] Loss_D: 0.0941 Loss_G: 0.0395 Convergence: 0.0964 k= 0.019405 lr = 0.0000057\n",
      "[17/25][3770/9765] Loss_D: 0.1041 Loss_G: 0.0433 Convergence: 0.1063 k= 0.019386 lr = 0.0000057\n",
      "[17/25][3780/9765] Loss_D: 0.1016 Loss_G: 0.0457 Convergence: 0.1071 k= 0.019355 lr = 0.0000057\n",
      "[17/25][3790/9765] Loss_D: 0.0989 Loss_G: 0.0443 Convergence: 0.1042 k= 0.019298 lr = 0.0000057\n",
      "[17/25][3800/9765] Loss_D: 0.0906 Loss_G: 0.0419 Convergence: 0.0968 k= 0.019250 lr = 0.0000057\n",
      "[17/25][3810/9765] Loss_D: 0.0884 Loss_G: 0.0400 Convergence: 0.0934 k= 0.019222 lr = 0.0000057\n",
      "[17/25][3820/9765] Loss_D: 0.1028 Loss_G: 0.0384 Convergence: 0.1066 k= 0.019217 lr = 0.0000057\n",
      "[17/25][3830/9765] Loss_D: 0.1085 Loss_G: 0.0381 Convergence: 0.1149 k= 0.019218 lr = 0.0000057\n",
      "[17/25][3840/9765] Loss_D: 0.0940 Loss_G: 0.0370 Convergence: 0.0955 k= 0.019228 lr = 0.0000057\n",
      "[17/25][3850/9765] Loss_D: 0.0947 Loss_G: 0.0366 Convergence: 0.0969 k= 0.019258 lr = 0.0000057\n",
      "[17/25][3860/9765] Loss_D: 0.1005 Loss_G: 0.0338 Convergence: 0.1079 k= 0.019295 lr = 0.0000057\n",
      "[17/25][3870/9765] Loss_D: 0.1039 Loss_G: 0.0338 Convergence: 0.1126 k= 0.019344 lr = 0.0000057\n",
      "[17/25][3880/9765] Loss_D: 0.0974 Loss_G: 0.0354 Convergence: 0.1020 k= 0.019383 lr = 0.0000057\n",
      "[17/25][3890/9765] Loss_D: 0.0976 Loss_G: 0.0381 Convergence: 0.0995 k= 0.019396 lr = 0.0000057\n",
      "[17/25][3900/9765] Loss_D: 0.0930 Loss_G: 0.0388 Convergence: 0.0950 k= 0.019400 lr = 0.0000057\n",
      "[17/25][3910/9765] Loss_D: 0.1011 Loss_G: 0.0404 Convergence: 0.1023 k= 0.019404 lr = 0.0000057\n",
      "[17/25][3920/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0934 k= 0.019394 lr = 0.0000057\n",
      "[17/25][3930/9765] Loss_D: 0.0943 Loss_G: 0.0401 Convergence: 0.0972 k= 0.019404 lr = 0.0000057\n",
      "[17/25][3940/9765] Loss_D: 0.1074 Loss_G: 0.0397 Convergence: 0.1117 k= 0.019400 lr = 0.0000057\n",
      "[17/25][3950/9765] Loss_D: 0.0887 Loss_G: 0.0384 Convergence: 0.0921 k= 0.019380 lr = 0.0000057\n",
      "[17/25][3960/9765] Loss_D: 0.0942 Loss_G: 0.0400 Convergence: 0.0970 k= 0.019387 lr = 0.0000057\n",
      "[17/25][3970/9765] Loss_D: 0.0941 Loss_G: 0.0411 Convergence: 0.0980 k= 0.019376 lr = 0.0000057\n",
      "[17/25][3980/9765] Loss_D: 0.0953 Loss_G: 0.0383 Convergence: 0.0961 k= 0.019382 lr = 0.0000057\n",
      "[17/25][3990/9765] Loss_D: 0.1044 Loss_G: 0.0389 Convergence: 0.1083 k= 0.019371 lr = 0.0000057\n",
      "[17/25][4000/9765] Loss_D: 0.1031 Loss_G: 0.0383 Convergence: 0.1071 k= 0.019368 lr = 0.0000057\n",
      "[17/25][4010/9765] Loss_D: 0.0935 Loss_G: 0.0375 Convergence: 0.0944 k= 0.019371 lr = 0.0000057\n",
      "[17/25][4020/9765] Loss_D: 0.1030 Loss_G: 0.0394 Convergence: 0.1058 k= 0.019375 lr = 0.0000057\n",
      "[17/25][4030/9765] Loss_D: 0.1112 Loss_G: 0.0399 Convergence: 0.1169 k= 0.019376 lr = 0.0000057\n",
      "[17/25][4040/9765] Loss_D: 0.1033 Loss_G: 0.0391 Convergence: 0.1065 k= 0.019370 lr = 0.0000057\n",
      "[17/25][4050/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1002 k= 0.019361 lr = 0.0000057\n",
      "[17/25][4060/9765] Loss_D: 0.0971 Loss_G: 0.0395 Convergence: 0.0983 k= 0.019361 lr = 0.0000057\n",
      "[17/25][4070/9765] Loss_D: 0.0937 Loss_G: 0.0387 Convergence: 0.0953 k= 0.019363 lr = 0.0000057\n",
      "[17/25][4080/9765] Loss_D: 0.0881 Loss_G: 0.0385 Convergence: 0.0918 k= 0.019366 lr = 0.0000057\n",
      "[17/25][4090/9765] Loss_D: 0.0854 Loss_G: 0.0351 Convergence: 0.0867 k= 0.019385 lr = 0.0000057\n",
      "[17/25][4100/9765] Loss_D: 0.0953 Loss_G: 0.0360 Convergence: 0.0983 k= 0.019403 lr = 0.0000057\n",
      "[17/25][4110/9765] Loss_D: 0.0887 Loss_G: 0.0355 Convergence: 0.0897 k= 0.019412 lr = 0.0000057\n",
      "[17/25][4120/9765] Loss_D: 0.0967 Loss_G: 0.0357 Convergence: 0.1007 k= 0.019433 lr = 0.0000057\n",
      "[17/25][4130/9765] Loss_D: 0.1027 Loss_G: 0.0384 Convergence: 0.1064 k= 0.019447 lr = 0.0000057\n",
      "[17/25][4140/9765] Loss_D: 0.1003 Loss_G: 0.0392 Convergence: 0.1022 k= 0.019460 lr = 0.0000057\n",
      "[17/25][4150/9765] Loss_D: 0.1012 Loss_G: 0.0384 Convergence: 0.1043 k= 0.019464 lr = 0.0000057\n",
      "[17/25][4160/9765] Loss_D: 0.0908 Loss_G: 0.0378 Convergence: 0.0927 k= 0.019469 lr = 0.0000057\n",
      "[17/25][4170/9765] Loss_D: 0.0949 Loss_G: 0.0398 Convergence: 0.0972 k= 0.019470 lr = 0.0000057\n",
      "[17/25][4180/9765] Loss_D: 0.0996 Loss_G: 0.0394 Convergence: 0.1010 k= 0.019465 lr = 0.0000057\n",
      "[17/25][4190/9765] Loss_D: 0.1017 Loss_G: 0.0393 Convergence: 0.1041 k= 0.019460 lr = 0.0000057\n",
      "[17/25][4200/9765] Loss_D: 0.0816 Loss_G: 0.0390 Convergence: 0.0885 k= 0.019435 lr = 0.0000057\n",
      "[17/25][4210/9765] Loss_D: 0.0926 Loss_G: 0.0382 Convergence: 0.0942 k= 0.019440 lr = 0.0000057\n",
      "[17/25][4220/9765] Loss_D: 0.1035 Loss_G: 0.0396 Convergence: 0.1063 k= 0.019430 lr = 0.0000057\n",
      "[17/25][4230/9765] Loss_D: 0.0998 Loss_G: 0.0407 Convergence: 0.1010 k= 0.019429 lr = 0.0000057\n",
      "[17/25][4240/9765] Loss_D: 0.0962 Loss_G: 0.0395 Convergence: 0.0977 k= 0.019434 lr = 0.0000057\n",
      "[17/25][4250/9765] Loss_D: 0.0936 Loss_G: 0.0384 Convergence: 0.0950 k= 0.019442 lr = 0.0000057\n",
      "[17/25][4260/9765] Loss_D: 0.0933 Loss_G: 0.0366 Convergence: 0.0950 k= 0.019454 lr = 0.0000057\n",
      "[17/25][4270/9765] Loss_D: 0.0899 Loss_G: 0.0372 Convergence: 0.0916 k= 0.019465 lr = 0.0000057\n",
      "[17/25][4280/9765] Loss_D: 0.0951 Loss_G: 0.0387 Convergence: 0.0962 k= 0.019481 lr = 0.0000057\n",
      "[17/25][4290/9765] Loss_D: 0.0992 Loss_G: 0.0388 Convergence: 0.1011 k= 0.019489 lr = 0.0000057\n",
      "[17/25][4300/9765] Loss_D: 0.0943 Loss_G: 0.0393 Convergence: 0.0964 k= 0.019481 lr = 0.0000057\n",
      "[17/25][4310/9765] Loss_D: 0.0976 Loss_G: 0.0394 Convergence: 0.0984 k= 0.019467 lr = 0.0000057\n",
      "[17/25][4320/9765] Loss_D: 0.0885 Loss_G: 0.0356 Convergence: 0.0893 k= 0.019474 lr = 0.0000057\n",
      "[17/25][4330/9765] Loss_D: 0.1051 Loss_G: 0.0373 Convergence: 0.1108 k= 0.019508 lr = 0.0000057\n",
      "[17/25][4340/9765] Loss_D: 0.1014 Loss_G: 0.0388 Convergence: 0.1041 k= 0.019512 lr = 0.0000057\n",
      "[17/25][4350/9765] Loss_D: 0.0942 Loss_G: 0.0376 Convergence: 0.0954 k= 0.019522 lr = 0.0000057\n",
      "[17/25][4360/9765] Loss_D: 0.0884 Loss_G: 0.0390 Convergence: 0.0925 k= 0.019531 lr = 0.0000057\n",
      "[17/25][4370/9765] Loss_D: 0.0958 Loss_G: 0.0374 Convergence: 0.0977 k= 0.019532 lr = 0.0000057\n",
      "[17/25][4380/9765] Loss_D: 0.0947 Loss_G: 0.0410 Convergence: 0.0983 k= 0.019526 lr = 0.0000057\n",
      "[17/25][4390/9765] Loss_D: 0.0955 Loss_G: 0.0404 Convergence: 0.0982 k= 0.019518 lr = 0.0000057\n",
      "[17/25][4400/9765] Loss_D: 0.1007 Loss_G: 0.0400 Convergence: 0.1021 k= 0.019510 lr = 0.0000057\n",
      "[17/25][4410/9765] Loss_D: 0.0956 Loss_G: 0.0390 Convergence: 0.0969 k= 0.019508 lr = 0.0000057\n",
      "[17/25][4420/9765] Loss_D: 0.0952 Loss_G: 0.0377 Convergence: 0.0967 k= 0.019502 lr = 0.0000057\n",
      "[17/25][4430/9765] Loss_D: 0.1000 Loss_G: 0.0402 Convergence: 0.1009 k= 0.019491 lr = 0.0000057\n",
      "[17/25][4440/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0966 k= 0.019485 lr = 0.0000057\n",
      "[17/25][4450/9765] Loss_D: 0.0948 Loss_G: 0.0385 Convergence: 0.0958 k= 0.019484 lr = 0.0000057\n",
      "[17/25][4460/9765] Loss_D: 0.1069 Loss_G: 0.0372 Convergence: 0.1135 k= 0.019489 lr = 0.0000057\n",
      "[17/25][4470/9765] Loss_D: 0.1052 Loss_G: 0.0375 Convergence: 0.1107 k= 0.019503 lr = 0.0000057\n",
      "[17/25][4480/9765] Loss_D: 0.0926 Loss_G: 0.0371 Convergence: 0.0936 k= 0.019509 lr = 0.0000057\n",
      "[17/25][4490/9765] Loss_D: 0.0890 Loss_G: 0.0380 Convergence: 0.0918 k= 0.019514 lr = 0.0000057\n",
      "[17/25][4500/9765] Loss_D: 0.0943 Loss_G: 0.0385 Convergence: 0.0955 k= 0.019513 lr = 0.0000057\n",
      "[17/25][4510/9765] Loss_D: 0.0988 Loss_G: 0.0407 Convergence: 0.1004 k= 0.019512 lr = 0.0000057\n",
      "[17/25][4520/9765] Loss_D: 0.0957 Loss_G: 0.0385 Convergence: 0.0965 k= 0.019521 lr = 0.0000057\n",
      "[17/25][4530/9765] Loss_D: 0.0950 Loss_G: 0.0387 Convergence: 0.0961 k= 0.019521 lr = 0.0000057\n",
      "[17/25][4540/9765] Loss_D: 0.0904 Loss_G: 0.0371 Convergence: 0.0917 k= 0.019539 lr = 0.0000057\n",
      "[17/25][4550/9765] Loss_D: 0.0965 Loss_G: 0.0389 Convergence: 0.0974 k= 0.019540 lr = 0.0000057\n",
      "[17/25][4560/9765] Loss_D: 0.0921 Loss_G: 0.0413 Convergence: 0.0971 k= 0.019533 lr = 0.0000057\n",
      "[17/25][4570/9765] Loss_D: 0.0942 Loss_G: 0.0416 Convergence: 0.0986 k= 0.019525 lr = 0.0000057\n",
      "[17/25][4580/9765] Loss_D: 0.0845 Loss_G: 0.0391 Convergence: 0.0903 k= 0.019513 lr = 0.0000057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][4590/9765] Loss_D: 0.0990 Loss_G: 0.0396 Convergence: 0.1002 k= 0.019505 lr = 0.0000057\n",
      "[17/25][4600/9765] Loss_D: 0.0938 Loss_G: 0.0402 Convergence: 0.0969 k= 0.019490 lr = 0.0000057\n",
      "[17/25][4610/9765] Loss_D: 0.0970 Loss_G: 0.0417 Convergence: 0.1004 k= 0.019477 lr = 0.0000057\n",
      "[17/25][4620/9765] Loss_D: 0.0987 Loss_G: 0.0395 Convergence: 0.0997 k= 0.019472 lr = 0.0000057\n",
      "[17/25][4630/9765] Loss_D: 0.0993 Loss_G: 0.0385 Convergence: 0.1016 k= 0.019483 lr = 0.0000057\n",
      "[17/25][4640/9765] Loss_D: 0.1009 Loss_G: 0.0398 Convergence: 0.1025 k= 0.019486 lr = 0.0000057\n",
      "[17/25][4650/9765] Loss_D: 0.0904 Loss_G: 0.0393 Convergence: 0.0940 k= 0.019479 lr = 0.0000057\n",
      "[17/25][4660/9765] Loss_D: 0.0984 Loss_G: 0.0378 Convergence: 0.1010 k= 0.019484 lr = 0.0000057\n",
      "[17/25][4670/9765] Loss_D: 0.0967 Loss_G: 0.0379 Convergence: 0.0985 k= 0.019491 lr = 0.0000057\n",
      "[17/25][4680/9765] Loss_D: 0.0963 Loss_G: 0.0364 Convergence: 0.0995 k= 0.019497 lr = 0.0000057\n",
      "[17/25][4690/9765] Loss_D: 0.1046 Loss_G: 0.0376 Convergence: 0.1098 k= 0.019525 lr = 0.0000057\n",
      "[17/25][4700/9765] Loss_D: 0.1009 Loss_G: 0.0385 Convergence: 0.1039 k= 0.019530 lr = 0.0000057\n",
      "[17/25][4710/9765] Loss_D: 0.0967 Loss_G: 0.0404 Convergence: 0.0988 k= 0.019534 lr = 0.0000057\n",
      "[17/25][4720/9765] Loss_D: 0.0926 Loss_G: 0.0410 Convergence: 0.0970 k= 0.019520 lr = 0.0000057\n",
      "[17/25][4730/9765] Loss_D: 0.0912 Loss_G: 0.0431 Convergence: 0.0983 k= 0.019480 lr = 0.0000057\n",
      "[17/25][4740/9765] Loss_D: 0.0896 Loss_G: 0.0415 Convergence: 0.0957 k= 0.019448 lr = 0.0000057\n",
      "[17/25][4750/9765] Loss_D: 0.1006 Loss_G: 0.0423 Convergence: 0.1031 k= 0.019429 lr = 0.0000057\n",
      "[17/25][4760/9765] Loss_D: 0.0893 Loss_G: 0.0394 Convergence: 0.0935 k= 0.019411 lr = 0.0000057\n",
      "[17/25][4770/9765] Loss_D: 0.0992 Loss_G: 0.0390 Convergence: 0.1009 k= 0.019403 lr = 0.0000057\n",
      "[17/25][4780/9765] Loss_D: 0.0965 Loss_G: 0.0390 Convergence: 0.0973 k= 0.019396 lr = 0.0000057\n",
      "[17/25][4790/9765] Loss_D: 0.0993 Loss_G: 0.0374 Convergence: 0.1026 k= 0.019392 lr = 0.0000057\n",
      "[17/25][4800/9765] Loss_D: 0.0963 Loss_G: 0.0377 Convergence: 0.0981 k= 0.019395 lr = 0.0000057\n",
      "[17/25][4810/9765] Loss_D: 0.0952 Loss_G: 0.0394 Convergence: 0.0969 k= 0.019393 lr = 0.0000057\n",
      "[17/25][4820/9765] Loss_D: 0.0993 Loss_G: 0.0378 Convergence: 0.1023 k= 0.019400 lr = 0.0000057\n",
      "[17/25][4830/9765] Loss_D: 0.0948 Loss_G: 0.0400 Convergence: 0.0974 k= 0.019401 lr = 0.0000057\n",
      "[17/25][4840/9765] Loss_D: 0.0955 Loss_G: 0.0411 Convergence: 0.0989 k= 0.019399 lr = 0.0000057\n",
      "[17/25][4850/9765] Loss_D: 0.0951 Loss_G: 0.0404 Convergence: 0.0979 k= 0.019370 lr = 0.0000057\n",
      "[17/25][4860/9765] Loss_D: 0.1017 Loss_G: 0.0376 Convergence: 0.1058 k= 0.019354 lr = 0.0000057\n",
      "[17/25][4870/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1055 k= 0.019363 lr = 0.0000057\n",
      "[17/25][4880/9765] Loss_D: 0.0969 Loss_G: 0.0390 Convergence: 0.0977 k= 0.019361 lr = 0.0000057\n",
      "[17/25][4890/9765] Loss_D: 0.0981 Loss_G: 0.0384 Convergence: 0.1000 k= 0.019384 lr = 0.0000057\n",
      "[17/25][4900/9765] Loss_D: 0.0948 Loss_G: 0.0381 Convergence: 0.0957 k= 0.019399 lr = 0.0000057\n",
      "[17/25][4910/9765] Loss_D: 0.0952 Loss_G: 0.0363 Convergence: 0.0979 k= 0.019406 lr = 0.0000057\n",
      "[17/25][4920/9765] Loss_D: 0.0899 Loss_G: 0.0366 Convergence: 0.0910 k= 0.019419 lr = 0.0000057\n",
      "[17/25][4930/9765] Loss_D: 0.0968 Loss_G: 0.0376 Convergence: 0.0989 k= 0.019420 lr = 0.0000057\n",
      "[17/25][4940/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1012 k= 0.019440 lr = 0.0000057\n",
      "[17/25][4950/9765] Loss_D: 0.1004 Loss_G: 0.0403 Convergence: 0.1013 k= 0.019427 lr = 0.0000057\n",
      "[17/25][4960/9765] Loss_D: 0.0923 Loss_G: 0.0398 Convergence: 0.0957 k= 0.019408 lr = 0.0000057\n",
      "[17/25][4970/9765] Loss_D: 0.0864 Loss_G: 0.0377 Convergence: 0.0899 k= 0.019408 lr = 0.0000057\n",
      "[17/25][4980/9765] Loss_D: 0.0920 Loss_G: 0.0394 Convergence: 0.0950 k= 0.019405 lr = 0.0000057\n",
      "[17/25][4990/9765] Loss_D: 0.0981 Loss_G: 0.0389 Convergence: 0.0995 k= 0.019398 lr = 0.0000057\n",
      "[17/25][5000/9765] Loss_D: 0.0931 Loss_G: 0.0373 Convergence: 0.0940 k= 0.019406 lr = 0.0000054\n",
      "[17/25][5010/9765] Loss_D: 0.1014 Loss_G: 0.0393 Convergence: 0.1037 k= 0.019414 lr = 0.0000054\n",
      "[17/25][5020/9765] Loss_D: 0.1067 Loss_G: 0.0400 Convergence: 0.1105 k= 0.019411 lr = 0.0000054\n",
      "[17/25][5030/9765] Loss_D: 0.1102 Loss_G: 0.0395 Convergence: 0.1158 k= 0.019397 lr = 0.0000054\n",
      "[17/25][5040/9765] Loss_D: 0.1021 Loss_G: 0.0382 Convergence: 0.1058 k= 0.019393 lr = 0.0000054\n",
      "[17/25][5050/9765] Loss_D: 0.0996 Loss_G: 0.0381 Convergence: 0.1025 k= 0.019411 lr = 0.0000054\n",
      "[17/25][5060/9765] Loss_D: 0.0991 Loss_G: 0.0372 Convergence: 0.1026 k= 0.019419 lr = 0.0000054\n",
      "[17/25][5070/9765] Loss_D: 0.0935 Loss_G: 0.0368 Convergence: 0.0951 k= 0.019419 lr = 0.0000054\n",
      "[17/25][5080/9765] Loss_D: 0.0985 Loss_G: 0.0371 Convergence: 0.1018 k= 0.019429 lr = 0.0000054\n",
      "[17/25][5090/9765] Loss_D: 0.0947 Loss_G: 0.0374 Convergence: 0.0962 k= 0.019447 lr = 0.0000054\n",
      "[17/25][5100/9765] Loss_D: 0.1055 Loss_G: 0.0383 Convergence: 0.1104 k= 0.019462 lr = 0.0000054\n",
      "[17/25][5110/9765] Loss_D: 0.0989 Loss_G: 0.0382 Convergence: 0.1012 k= 0.019476 lr = 0.0000054\n",
      "[17/25][5120/9765] Loss_D: 0.0913 Loss_G: 0.0385 Convergence: 0.0937 k= 0.019491 lr = 0.0000054\n",
      "[17/25][5130/9765] Loss_D: 0.1017 Loss_G: 0.0402 Convergence: 0.1033 k= 0.019491 lr = 0.0000054\n",
      "[17/25][5140/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0965 k= 0.019468 lr = 0.0000054\n",
      "[17/25][5150/9765] Loss_D: 0.0911 Loss_G: 0.0399 Convergence: 0.0950 k= 0.019449 lr = 0.0000054\n",
      "[17/25][5160/9765] Loss_D: 0.0962 Loss_G: 0.0373 Convergence: 0.0984 k= 0.019464 lr = 0.0000054\n",
      "[17/25][5170/9765] Loss_D: 0.0921 Loss_G: 0.0382 Convergence: 0.0939 k= 0.019487 lr = 0.0000054\n",
      "[17/25][5180/9765] Loss_D: 0.0796 Loss_G: 0.0371 Convergence: 0.0853 k= 0.019488 lr = 0.0000054\n",
      "[17/25][5190/9765] Loss_D: 0.0931 Loss_G: 0.0373 Convergence: 0.0940 k= 0.019493 lr = 0.0000054\n",
      "[17/25][5200/9765] Loss_D: 0.0931 Loss_G: 0.0383 Convergence: 0.0947 k= 0.019502 lr = 0.0000054\n",
      "[17/25][5210/9765] Loss_D: 0.0959 Loss_G: 0.0396 Convergence: 0.0975 k= 0.019506 lr = 0.0000054\n",
      "[17/25][5220/9765] Loss_D: 0.0934 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019506 lr = 0.0000054\n",
      "[17/25][5230/9765] Loss_D: 0.0988 Loss_G: 0.0414 Convergence: 0.1012 k= 0.019495 lr = 0.0000054\n",
      "[17/25][5240/9765] Loss_D: 0.0954 Loss_G: 0.0378 Convergence: 0.0968 k= 0.019489 lr = 0.0000054\n",
      "[17/25][5250/9765] Loss_D: 0.1048 Loss_G: 0.0388 Convergence: 0.1090 k= 0.019501 lr = 0.0000054\n",
      "[17/25][5260/9765] Loss_D: 0.1034 Loss_G: 0.0409 Convergence: 0.1051 k= 0.019494 lr = 0.0000054\n",
      "[17/25][5270/9765] Loss_D: 0.0941 Loss_G: 0.0402 Convergence: 0.0972 k= 0.019483 lr = 0.0000054\n",
      "[17/25][5280/9765] Loss_D: 0.1033 Loss_G: 0.0402 Convergence: 0.1055 k= 0.019471 lr = 0.0000054\n",
      "[17/25][5290/9765] Loss_D: 0.0867 Loss_G: 0.0378 Convergence: 0.0902 k= 0.019460 lr = 0.0000054\n",
      "[17/25][5300/9765] Loss_D: 0.0962 Loss_G: 0.0384 Convergence: 0.0973 k= 0.019452 lr = 0.0000054\n",
      "[17/25][5310/9765] Loss_D: 0.0964 Loss_G: 0.0389 Convergence: 0.0972 k= 0.019456 lr = 0.0000054\n",
      "[17/25][5320/9765] Loss_D: 0.0978 Loss_G: 0.0373 Convergence: 0.1007 k= 0.019460 lr = 0.0000054\n",
      "[17/25][5330/9765] Loss_D: 0.0877 Loss_G: 0.0381 Convergence: 0.0912 k= 0.019461 lr = 0.0000054\n",
      "[17/25][5340/9765] Loss_D: 0.1039 Loss_G: 0.0381 Convergence: 0.1083 k= 0.019474 lr = 0.0000054\n",
      "[17/25][5350/9765] Loss_D: 0.0927 Loss_G: 0.0387 Convergence: 0.0948 k= 0.019482 lr = 0.0000054\n",
      "[17/25][5360/9765] Loss_D: 0.0952 Loss_G: 0.0360 Convergence: 0.0982 k= 0.019491 lr = 0.0000054\n",
      "[17/25][5370/9765] Loss_D: 0.0995 Loss_G: 0.0392 Convergence: 0.1011 k= 0.019498 lr = 0.0000054\n",
      "[17/25][5380/9765] Loss_D: 0.1013 Loss_G: 0.0392 Convergence: 0.1037 k= 0.019485 lr = 0.0000054\n",
      "[17/25][5390/9765] Loss_D: 0.0946 Loss_G: 0.0378 Convergence: 0.0957 k= 0.019477 lr = 0.0000054\n",
      "[17/25][5400/9765] Loss_D: 0.1071 Loss_G: 0.0402 Convergence: 0.1108 k= 0.019483 lr = 0.0000054\n",
      "[17/25][5410/9765] Loss_D: 0.0925 Loss_G: 0.0399 Convergence: 0.0958 k= 0.019465 lr = 0.0000054\n",
      "[17/25][5420/9765] Loss_D: 0.0884 Loss_G: 0.0390 Convergence: 0.0925 k= 0.019460 lr = 0.0000054\n",
      "[17/25][5430/9765] Loss_D: 0.1001 Loss_G: 0.0400 Convergence: 0.1012 k= 0.019459 lr = 0.0000054\n",
      "[17/25][5440/9765] Loss_D: 0.1059 Loss_G: 0.0407 Convergence: 0.1087 k= 0.019444 lr = 0.0000054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][5450/9765] Loss_D: 0.0996 Loss_G: 0.0414 Convergence: 0.1016 k= 0.019433 lr = 0.0000054\n",
      "[17/25][5460/9765] Loss_D: 0.1014 Loss_G: 0.0421 Convergence: 0.1034 k= 0.019418 lr = 0.0000054\n",
      "[17/25][5470/9765] Loss_D: 0.1044 Loss_G: 0.0410 Convergence: 0.1063 k= 0.019398 lr = 0.0000054\n",
      "[17/25][5480/9765] Loss_D: 0.1035 Loss_G: 0.0401 Convergence: 0.1059 k= 0.019386 lr = 0.0000054\n",
      "[17/25][5490/9765] Loss_D: 0.0941 Loss_G: 0.0395 Convergence: 0.0964 k= 0.019372 lr = 0.0000054\n",
      "[17/25][5500/9765] Loss_D: 0.0911 Loss_G: 0.0402 Convergence: 0.0953 k= 0.019360 lr = 0.0000054\n",
      "[17/25][5510/9765] Loss_D: 0.0934 Loss_G: 0.0384 Convergence: 0.0948 k= 0.019354 lr = 0.0000054\n",
      "[17/25][5520/9765] Loss_D: 0.0941 Loss_G: 0.0378 Convergence: 0.0949 k= 0.019368 lr = 0.0000054\n",
      "[17/25][5530/9765] Loss_D: 0.0940 Loss_G: 0.0393 Convergence: 0.0962 k= 0.019362 lr = 0.0000054\n",
      "[17/25][5540/9765] Loss_D: 0.1018 Loss_G: 0.0398 Convergence: 0.1038 k= 0.019361 lr = 0.0000054\n",
      "[17/25][5550/9765] Loss_D: 0.0927 Loss_G: 0.0408 Convergence: 0.0969 k= 0.019353 lr = 0.0000054\n",
      "[17/25][5560/9765] Loss_D: 0.1010 Loss_G: 0.0402 Convergence: 0.1023 k= 0.019331 lr = 0.0000054\n",
      "[17/25][5570/9765] Loss_D: 0.0993 Loss_G: 0.0389 Convergence: 0.1012 k= 0.019317 lr = 0.0000054\n",
      "[17/25][5580/9765] Loss_D: 0.0950 Loss_G: 0.0414 Convergence: 0.0988 k= 0.019321 lr = 0.0000054\n",
      "[17/25][5590/9765] Loss_D: 0.0885 Loss_G: 0.0407 Convergence: 0.0943 k= 0.019316 lr = 0.0000054\n",
      "[17/25][5600/9765] Loss_D: 0.0940 Loss_G: 0.0411 Convergence: 0.0980 k= 0.019289 lr = 0.0000054\n",
      "[17/25][5610/9765] Loss_D: 0.0901 Loss_G: 0.0377 Convergence: 0.0922 k= 0.019296 lr = 0.0000054\n",
      "[17/25][5620/9765] Loss_D: 0.1027 Loss_G: 0.0393 Convergence: 0.1056 k= 0.019308 lr = 0.0000054\n",
      "[17/25][5630/9765] Loss_D: 0.0939 Loss_G: 0.0366 Convergence: 0.0959 k= 0.019316 lr = 0.0000054\n",
      "[17/25][5640/9765] Loss_D: 0.0960 Loss_G: 0.0365 Convergence: 0.0988 k= 0.019337 lr = 0.0000054\n",
      "[17/25][5650/9765] Loss_D: 0.0980 Loss_G: 0.0369 Convergence: 0.1012 k= 0.019362 lr = 0.0000054\n",
      "[17/25][5660/9765] Loss_D: 0.0880 Loss_G: 0.0365 Convergence: 0.0898 k= 0.019378 lr = 0.0000054\n",
      "[17/25][5670/9765] Loss_D: 0.0947 Loss_G: 0.0387 Convergence: 0.0960 k= 0.019398 lr = 0.0000054\n",
      "[17/25][5680/9765] Loss_D: 0.0918 Loss_G: 0.0373 Convergence: 0.0927 k= 0.019409 lr = 0.0000054\n",
      "[17/25][5690/9765] Loss_D: 0.0907 Loss_G: 0.0392 Convergence: 0.0941 k= 0.019423 lr = 0.0000054\n",
      "[17/25][5700/9765] Loss_D: 0.0958 Loss_G: 0.0375 Convergence: 0.0976 k= 0.019437 lr = 0.0000054\n",
      "[17/25][5710/9765] Loss_D: 0.1018 Loss_G: 0.0365 Convergence: 0.1071 k= 0.019438 lr = 0.0000054\n",
      "[17/25][5720/9765] Loss_D: 0.0928 Loss_G: 0.0393 Convergence: 0.0955 k= 0.019433 lr = 0.0000054\n",
      "[17/25][5730/9765] Loss_D: 0.0958 Loss_G: 0.0385 Convergence: 0.0967 k= 0.019425 lr = 0.0000054\n",
      "[17/25][5740/9765] Loss_D: 0.1033 Loss_G: 0.0410 Convergence: 0.1048 k= 0.019415 lr = 0.0000054\n",
      "[17/25][5750/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.019414 lr = 0.0000054\n",
      "[17/25][5760/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0985 k= 0.019421 lr = 0.0000054\n",
      "[17/25][5770/9765] Loss_D: 0.0908 Loss_G: 0.0390 Convergence: 0.0939 k= 0.019422 lr = 0.0000054\n",
      "[17/25][5780/9765] Loss_D: 0.0912 Loss_G: 0.0370 Convergence: 0.0922 k= 0.019417 lr = 0.0000054\n",
      "[17/25][5790/9765] Loss_D: 0.0913 Loss_G: 0.0365 Convergence: 0.0923 k= 0.019422 lr = 0.0000054\n",
      "[17/25][5800/9765] Loss_D: 0.0976 Loss_G: 0.0409 Convergence: 0.0999 k= 0.019428 lr = 0.0000054\n",
      "[17/25][5810/9765] Loss_D: 0.0888 Loss_G: 0.0390 Convergence: 0.0928 k= 0.019418 lr = 0.0000054\n",
      "[17/25][5820/9765] Loss_D: 0.0939 Loss_G: 0.0384 Convergence: 0.0952 k= 0.019422 lr = 0.0000054\n",
      "[17/25][5830/9765] Loss_D: 0.0982 Loss_G: 0.0379 Convergence: 0.1006 k= 0.019424 lr = 0.0000054\n",
      "[17/25][5840/9765] Loss_D: 0.0939 Loss_G: 0.0375 Convergence: 0.0950 k= 0.019426 lr = 0.0000054\n",
      "[17/25][5850/9765] Loss_D: 0.0892 Loss_G: 0.0395 Convergence: 0.0935 k= 0.019430 lr = 0.0000054\n",
      "[17/25][5860/9765] Loss_D: 0.0966 Loss_G: 0.0387 Convergence: 0.0975 k= 0.019440 lr = 0.0000054\n",
      "[17/25][5870/9765] Loss_D: 0.0949 Loss_G: 0.0386 Convergence: 0.0960 k= 0.019443 lr = 0.0000054\n",
      "[17/25][5880/9765] Loss_D: 0.1076 Loss_G: 0.0378 Convergence: 0.1138 k= 0.019472 lr = 0.0000054\n",
      "[17/25][5890/9765] Loss_D: 0.0924 Loss_G: 0.0383 Convergence: 0.0942 k= 0.019480 lr = 0.0000054\n",
      "[17/25][5900/9765] Loss_D: 0.0927 Loss_G: 0.0376 Convergence: 0.0937 k= 0.019476 lr = 0.0000054\n",
      "[17/25][5910/9765] Loss_D: 0.0933 Loss_G: 0.0380 Convergence: 0.0944 k= 0.019468 lr = 0.0000054\n",
      "[17/25][5920/9765] Loss_D: 0.0950 Loss_G: 0.0383 Convergence: 0.0958 k= 0.019490 lr = 0.0000054\n",
      "[17/25][5930/9765] Loss_D: 0.0885 Loss_G: 0.0379 Convergence: 0.0914 k= 0.019489 lr = 0.0000054\n",
      "[17/25][5940/9765] Loss_D: 0.0954 Loss_G: 0.0382 Convergence: 0.0964 k= 0.019511 lr = 0.0000054\n",
      "[17/25][5950/9765] Loss_D: 0.1001 Loss_G: 0.0398 Convergence: 0.1013 k= 0.019510 lr = 0.0000054\n",
      "[17/25][5960/9765] Loss_D: 0.0929 Loss_G: 0.0378 Convergence: 0.0939 k= 0.019516 lr = 0.0000054\n",
      "[17/25][5970/9765] Loss_D: 0.0934 Loss_G: 0.0377 Convergence: 0.0942 k= 0.019517 lr = 0.0000054\n",
      "[17/25][5980/9765] Loss_D: 0.0985 Loss_G: 0.0380 Convergence: 0.1010 k= 0.019525 lr = 0.0000054\n",
      "[17/25][5990/9765] Loss_D: 0.0895 Loss_G: 0.0385 Convergence: 0.0927 k= 0.019532 lr = 0.0000054\n",
      "[17/25][6000/9765] Loss_D: 0.0988 Loss_G: 0.0399 Convergence: 0.0996 k= 0.019527 lr = 0.0000054\n",
      "[17/25][6010/9765] Loss_D: 0.0940 Loss_G: 0.0396 Convergence: 0.0965 k= 0.019523 lr = 0.0000054\n",
      "[17/25][6020/9765] Loss_D: 0.0923 Loss_G: 0.0387 Convergence: 0.0945 k= 0.019524 lr = 0.0000054\n",
      "[17/25][6030/9765] Loss_D: 0.0972 Loss_G: 0.0380 Convergence: 0.0992 k= 0.019524 lr = 0.0000054\n",
      "[17/25][6040/9765] Loss_D: 0.0910 Loss_G: 0.0388 Convergence: 0.0938 k= 0.019540 lr = 0.0000054\n",
      "[17/25][6050/9765] Loss_D: 0.0879 Loss_G: 0.0401 Convergence: 0.0933 k= 0.019537 lr = 0.0000054\n",
      "[17/25][6060/9765] Loss_D: 0.0970 Loss_G: 0.0389 Convergence: 0.0981 k= 0.019521 lr = 0.0000054\n",
      "[17/25][6070/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0985 k= 0.019528 lr = 0.0000054\n",
      "[17/25][6080/9765] Loss_D: 0.1012 Loss_G: 0.0406 Convergence: 0.1022 k= 0.019516 lr = 0.0000054\n",
      "[17/25][6090/9765] Loss_D: 0.0953 Loss_G: 0.0410 Convergence: 0.0987 k= 0.019491 lr = 0.0000054\n",
      "[17/25][6100/9765] Loss_D: 0.0987 Loss_G: 0.0393 Convergence: 0.0998 k= 0.019490 lr = 0.0000054\n",
      "[17/25][6110/9765] Loss_D: 0.0989 Loss_G: 0.0392 Convergence: 0.1003 k= 0.019492 lr = 0.0000054\n",
      "[17/25][6120/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0975 k= 0.019493 lr = 0.0000054\n",
      "[17/25][6130/9765] Loss_D: 0.0936 Loss_G: 0.0388 Convergence: 0.0954 k= 0.019490 lr = 0.0000054\n",
      "[17/25][6140/9765] Loss_D: 0.1012 Loss_G: 0.0385 Convergence: 0.1043 k= 0.019496 lr = 0.0000054\n",
      "[17/25][6150/9765] Loss_D: 0.1012 Loss_G: 0.0408 Convergence: 0.1020 k= 0.019499 lr = 0.0000054\n",
      "[17/25][6160/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.019495 lr = 0.0000054\n",
      "[17/25][6170/9765] Loss_D: 0.0902 Loss_G: 0.0411 Convergence: 0.0957 k= 0.019484 lr = 0.0000054\n",
      "[17/25][6180/9765] Loss_D: 0.0930 Loss_G: 0.0411 Convergence: 0.0974 k= 0.019470 lr = 0.0000054\n",
      "[17/25][6190/9765] Loss_D: 0.0995 Loss_G: 0.0388 Convergence: 0.1016 k= 0.019453 lr = 0.0000054\n",
      "[17/25][6200/9765] Loss_D: 0.0942 Loss_G: 0.0385 Convergence: 0.0954 k= 0.019455 lr = 0.0000054\n",
      "[17/25][6210/9765] Loss_D: 0.1016 Loss_G: 0.0386 Convergence: 0.1046 k= 0.019462 lr = 0.0000054\n",
      "[17/25][6220/9765] Loss_D: 0.1070 Loss_G: 0.0379 Convergence: 0.1130 k= 0.019463 lr = 0.0000054\n",
      "[17/25][6230/9765] Loss_D: 0.0972 Loss_G: 0.0377 Convergence: 0.0993 k= 0.019463 lr = 0.0000054\n",
      "[17/25][6240/9765] Loss_D: 0.1038 Loss_G: 0.0386 Convergence: 0.1078 k= 0.019485 lr = 0.0000054\n",
      "[17/25][6250/9765] Loss_D: 0.0899 Loss_G: 0.0383 Convergence: 0.0927 k= 0.019487 lr = 0.0000054\n",
      "[17/25][6260/9765] Loss_D: 0.0993 Loss_G: 0.0386 Convergence: 0.1014 k= 0.019482 lr = 0.0000054\n",
      "[17/25][6270/9765] Loss_D: 0.1047 Loss_G: 0.0410 Convergence: 0.1067 k= 0.019490 lr = 0.0000054\n",
      "[17/25][6280/9765] Loss_D: 0.0885 Loss_G: 0.0403 Convergence: 0.0938 k= 0.019474 lr = 0.0000054\n",
      "[17/25][6290/9765] Loss_D: 0.0965 Loss_G: 0.0409 Convergence: 0.0992 k= 0.019463 lr = 0.0000054\n",
      "[17/25][6300/9765] Loss_D: 0.0940 Loss_G: 0.0405 Convergence: 0.0973 k= 0.019451 lr = 0.0000054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][6310/9765] Loss_D: 0.0970 Loss_G: 0.0404 Convergence: 0.0990 k= 0.019441 lr = 0.0000054\n",
      "[17/25][6320/9765] Loss_D: 0.1021 Loss_G: 0.0409 Convergence: 0.1032 k= 0.019415 lr = 0.0000054\n",
      "[17/25][6330/9765] Loss_D: 0.0997 Loss_G: 0.0423 Convergence: 0.1027 k= 0.019395 lr = 0.0000054\n",
      "[17/25][6340/9765] Loss_D: 0.1000 Loss_G: 0.0413 Convergence: 0.1018 k= 0.019373 lr = 0.0000054\n",
      "[17/25][6350/9765] Loss_D: 0.1053 Loss_G: 0.0433 Convergence: 0.1070 k= 0.019358 lr = 0.0000054\n",
      "[17/25][6360/9765] Loss_D: 0.0988 Loss_G: 0.0408 Convergence: 0.1005 k= 0.019326 lr = 0.0000054\n",
      "[17/25][6370/9765] Loss_D: 0.0929 Loss_G: 0.0380 Convergence: 0.0942 k= 0.019331 lr = 0.0000054\n",
      "[17/25][6380/9765] Loss_D: 0.1022 Loss_G: 0.0397 Convergence: 0.1044 k= 0.019356 lr = 0.0000054\n",
      "[17/25][6390/9765] Loss_D: 0.0918 Loss_G: 0.0380 Convergence: 0.0935 k= 0.019357 lr = 0.0000054\n",
      "[17/25][6400/9765] Loss_D: 0.0949 Loss_G: 0.0403 Convergence: 0.0977 k= 0.019362 lr = 0.0000054\n",
      "[17/25][6410/9765] Loss_D: 0.1045 Loss_G: 0.0373 Convergence: 0.1101 k= 0.019373 lr = 0.0000054\n",
      "[17/25][6420/9765] Loss_D: 0.1010 Loss_G: 0.0402 Convergence: 0.1022 k= 0.019377 lr = 0.0000054\n",
      "[17/25][6430/9765] Loss_D: 0.0931 Loss_G: 0.0423 Convergence: 0.0987 k= 0.019343 lr = 0.0000054\n",
      "[17/25][6440/9765] Loss_D: 0.0926 Loss_G: 0.0405 Convergence: 0.0966 k= 0.019303 lr = 0.0000054\n",
      "[17/25][6450/9765] Loss_D: 0.0945 Loss_G: 0.0421 Convergence: 0.0992 k= 0.019273 lr = 0.0000054\n",
      "[17/25][6460/9765] Loss_D: 0.0916 Loss_G: 0.0418 Convergence: 0.0973 k= 0.019251 lr = 0.0000054\n",
      "[17/25][6470/9765] Loss_D: 0.0995 Loss_G: 0.0424 Convergence: 0.1026 k= 0.019206 lr = 0.0000054\n",
      "[17/25][6480/9765] Loss_D: 0.0896 Loss_G: 0.0414 Convergence: 0.0957 k= 0.019165 lr = 0.0000054\n",
      "[17/25][6490/9765] Loss_D: 0.0970 Loss_G: 0.0414 Convergence: 0.1001 k= 0.019155 lr = 0.0000054\n",
      "[17/25][6500/9765] Loss_D: 0.1018 Loss_G: 0.0378 Convergence: 0.1057 k= 0.019154 lr = 0.0000054\n",
      "[17/25][6510/9765] Loss_D: 0.1011 Loss_G: 0.0368 Convergence: 0.1058 k= 0.019157 lr = 0.0000054\n",
      "[17/25][6520/9765] Loss_D: 0.1046 Loss_G: 0.0379 Convergence: 0.1095 k= 0.019179 lr = 0.0000054\n",
      "[17/25][6530/9765] Loss_D: 0.1058 Loss_G: 0.0369 Convergence: 0.1123 k= 0.019207 lr = 0.0000054\n",
      "[17/25][6540/9765] Loss_D: 0.1049 Loss_G: 0.0386 Convergence: 0.1093 k= 0.019227 lr = 0.0000054\n",
      "[17/25][6550/9765] Loss_D: 0.0939 Loss_G: 0.0377 Convergence: 0.0947 k= 0.019225 lr = 0.0000054\n",
      "[17/25][6560/9765] Loss_D: 0.0895 Loss_G: 0.0381 Convergence: 0.0922 k= 0.019227 lr = 0.0000054\n",
      "[17/25][6570/9765] Loss_D: 0.0926 Loss_G: 0.0389 Convergence: 0.0949 k= 0.019229 lr = 0.0000054\n",
      "[17/25][6580/9765] Loss_D: 0.0892 Loss_G: 0.0411 Convergence: 0.0951 k= 0.019213 lr = 0.0000054\n",
      "[17/25][6590/9765] Loss_D: 0.0920 Loss_G: 0.0383 Convergence: 0.0939 k= 0.019200 lr = 0.0000054\n",
      "[17/25][6600/9765] Loss_D: 0.1070 Loss_G: 0.0402 Convergence: 0.1106 k= 0.019207 lr = 0.0000054\n",
      "[17/25][6610/9765] Loss_D: 0.0874 Loss_G: 0.0369 Convergence: 0.0898 k= 0.019200 lr = 0.0000054\n",
      "[17/25][6620/9765] Loss_D: 0.0941 Loss_G: 0.0378 Convergence: 0.0949 k= 0.019220 lr = 0.0000054\n",
      "[17/25][6630/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1001 k= 0.019233 lr = 0.0000054\n",
      "[17/25][6640/9765] Loss_D: 0.0967 Loss_G: 0.0388 Convergence: 0.0976 k= 0.019238 lr = 0.0000054\n",
      "[17/25][6650/9765] Loss_D: 0.0922 Loss_G: 0.0382 Convergence: 0.0940 k= 0.019245 lr = 0.0000054\n",
      "[17/25][6660/9765] Loss_D: 0.0910 Loss_G: 0.0384 Convergence: 0.0934 k= 0.019254 lr = 0.0000054\n",
      "[17/25][6670/9765] Loss_D: 0.1087 Loss_G: 0.0400 Convergence: 0.1131 k= 0.019256 lr = 0.0000054\n",
      "[17/25][6680/9765] Loss_D: 0.0997 Loss_G: 0.0391 Convergence: 0.1015 k= 0.019243 lr = 0.0000054\n",
      "[17/25][6690/9765] Loss_D: 0.0958 Loss_G: 0.0394 Convergence: 0.0973 k= 0.019237 lr = 0.0000054\n",
      "[17/25][6700/9765] Loss_D: 0.1013 Loss_G: 0.0385 Convergence: 0.1043 k= 0.019231 lr = 0.0000054\n",
      "[17/25][6710/9765] Loss_D: 0.0925 Loss_G: 0.0390 Convergence: 0.0950 k= 0.019231 lr = 0.0000054\n",
      "[17/25][6720/9765] Loss_D: 0.0931 Loss_G: 0.0392 Convergence: 0.0955 k= 0.019221 lr = 0.0000054\n",
      "[17/25][6730/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0988 k= 0.019216 lr = 0.0000054\n",
      "[17/25][6740/9765] Loss_D: 0.0934 Loss_G: 0.0389 Convergence: 0.0953 k= 0.019207 lr = 0.0000054\n",
      "[17/25][6750/9765] Loss_D: 0.0967 Loss_G: 0.0383 Convergence: 0.0982 k= 0.019203 lr = 0.0000054\n",
      "[17/25][6760/9765] Loss_D: 0.0961 Loss_G: 0.0387 Convergence: 0.0969 k= 0.019212 lr = 0.0000054\n",
      "[17/25][6770/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0973 k= 0.019221 lr = 0.0000054\n",
      "[17/25][6780/9765] Loss_D: 0.0991 Loss_G: 0.0400 Convergence: 0.0999 k= 0.019223 lr = 0.0000054\n",
      "[17/25][6790/9765] Loss_D: 0.1050 Loss_G: 0.0374 Convergence: 0.1105 k= 0.019224 lr = 0.0000054\n",
      "[17/25][6800/9765] Loss_D: 0.0992 Loss_G: 0.0380 Convergence: 0.1020 k= 0.019225 lr = 0.0000054\n",
      "[17/25][6810/9765] Loss_D: 0.1105 Loss_G: 0.0401 Convergence: 0.1157 k= 0.019224 lr = 0.0000054\n",
      "[17/25][6820/9765] Loss_D: 0.0954 Loss_G: 0.0368 Convergence: 0.0977 k= 0.019217 lr = 0.0000054\n",
      "[17/25][6830/9765] Loss_D: 0.0956 Loss_G: 0.0401 Convergence: 0.0979 k= 0.019219 lr = 0.0000054\n",
      "[17/25][6840/9765] Loss_D: 0.0977 Loss_G: 0.0394 Convergence: 0.0984 k= 0.019216 lr = 0.0000054\n",
      "[17/25][6850/9765] Loss_D: 0.0993 Loss_G: 0.0387 Convergence: 0.1013 k= 0.019207 lr = 0.0000054\n",
      "[17/25][6860/9765] Loss_D: 0.1021 Loss_G: 0.0371 Convergence: 0.1068 k= 0.019222 lr = 0.0000054\n",
      "[17/25][6870/9765] Loss_D: 0.0902 Loss_G: 0.0369 Convergence: 0.0914 k= 0.019236 lr = 0.0000054\n",
      "[17/25][6880/9765] Loss_D: 0.0962 Loss_G: 0.0390 Convergence: 0.0972 k= 0.019241 lr = 0.0000054\n",
      "[17/25][6890/9765] Loss_D: 0.0975 Loss_G: 0.0401 Convergence: 0.0991 k= 0.019240 lr = 0.0000054\n",
      "[17/25][6900/9765] Loss_D: 0.0930 Loss_G: 0.0401 Convergence: 0.0963 k= 0.019236 lr = 0.0000054\n",
      "[17/25][6910/9765] Loss_D: 0.1019 Loss_G: 0.0379 Convergence: 0.1058 k= 0.019235 lr = 0.0000054\n",
      "[17/25][6920/9765] Loss_D: 0.0976 Loss_G: 0.0390 Convergence: 0.0987 k= 0.019245 lr = 0.0000054\n",
      "[17/25][6930/9765] Loss_D: 0.1003 Loss_G: 0.0410 Convergence: 0.1017 k= 0.019252 lr = 0.0000054\n",
      "[17/25][6940/9765] Loss_D: 0.1057 Loss_G: 0.0405 Convergence: 0.1086 k= 0.019240 lr = 0.0000054\n",
      "[17/25][6950/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.0999 k= 0.019237 lr = 0.0000054\n",
      "[17/25][6960/9765] Loss_D: 0.0982 Loss_G: 0.0381 Convergence: 0.1004 k= 0.019248 lr = 0.0000054\n",
      "[17/25][6970/9765] Loss_D: 0.0943 Loss_G: 0.0408 Convergence: 0.0979 k= 0.019258 lr = 0.0000054\n",
      "[17/25][6980/9765] Loss_D: 0.1040 Loss_G: 0.0380 Convergence: 0.1086 k= 0.019261 lr = 0.0000054\n",
      "[17/25][6990/9765] Loss_D: 0.0897 Loss_G: 0.0379 Convergence: 0.0922 k= 0.019259 lr = 0.0000054\n",
      "[17/25][7000/9765] Loss_D: 0.0936 Loss_G: 0.0390 Convergence: 0.0956 k= 0.019253 lr = 0.0000054\n",
      "[17/25][7010/9765] Loss_D: 0.0882 Loss_G: 0.0382 Convergence: 0.0916 k= 0.019229 lr = 0.0000054\n",
      "[17/25][7020/9765] Loss_D: 0.1029 Loss_G: 0.0397 Convergence: 0.1055 k= 0.019226 lr = 0.0000054\n",
      "[17/25][7030/9765] Loss_D: 0.0935 Loss_G: 0.0397 Convergence: 0.0962 k= 0.019228 lr = 0.0000054\n",
      "[17/25][7040/9765] Loss_D: 0.0892 Loss_G: 0.0385 Convergence: 0.0925 k= 0.019226 lr = 0.0000054\n",
      "[17/25][7050/9765] Loss_D: 0.0977 Loss_G: 0.0371 Convergence: 0.1007 k= 0.019234 lr = 0.0000054\n",
      "[17/25][7060/9765] Loss_D: 0.1038 Loss_G: 0.0374 Convergence: 0.1089 k= 0.019235 lr = 0.0000054\n",
      "[17/25][7070/9765] Loss_D: 0.0859 Loss_G: 0.0350 Convergence: 0.0870 k= 0.019263 lr = 0.0000054\n",
      "[17/25][7080/9765] Loss_D: 0.1063 Loss_G: 0.0379 Convergence: 0.1119 k= 0.019296 lr = 0.0000054\n",
      "[17/25][7090/9765] Loss_D: 0.0810 Loss_G: 0.0375 Convergence: 0.0866 k= 0.019297 lr = 0.0000054\n",
      "[17/25][7100/9765] Loss_D: 0.1007 Loss_G: 0.0401 Convergence: 0.1019 k= 0.019297 lr = 0.0000054\n",
      "[17/25][7110/9765] Loss_D: 0.0951 Loss_G: 0.0398 Convergence: 0.0972 k= 0.019296 lr = 0.0000054\n",
      "[17/25][7120/9765] Loss_D: 0.0979 Loss_G: 0.0400 Convergence: 0.0992 k= 0.019298 lr = 0.0000054\n",
      "[17/25][7130/9765] Loss_D: 0.0887 Loss_G: 0.0379 Convergence: 0.0916 k= 0.019291 lr = 0.0000054\n",
      "[17/25][7140/9765] Loss_D: 0.0972 Loss_G: 0.0403 Convergence: 0.0991 k= 0.019282 lr = 0.0000054\n",
      "[17/25][7150/9765] Loss_D: 0.1001 Loss_G: 0.0388 Convergence: 0.1023 k= 0.019290 lr = 0.0000054\n",
      "[17/25][7160/9765] Loss_D: 0.0942 Loss_G: 0.0381 Convergence: 0.0950 k= 0.019295 lr = 0.0000054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][7170/9765] Loss_D: 0.1029 Loss_G: 0.0400 Convergence: 0.1052 k= 0.019305 lr = 0.0000054\n",
      "[17/25][7180/9765] Loss_D: 0.1039 Loss_G: 0.0382 Convergence: 0.1083 k= 0.019299 lr = 0.0000054\n",
      "[17/25][7190/9765] Loss_D: 0.0951 Loss_G: 0.0387 Convergence: 0.0962 k= 0.019312 lr = 0.0000054\n",
      "[17/25][7200/9765] Loss_D: 0.0993 Loss_G: 0.0408 Convergence: 0.1008 k= 0.019321 lr = 0.0000054\n",
      "[17/25][7210/9765] Loss_D: 0.0998 Loss_G: 0.0421 Convergence: 0.1025 k= 0.019310 lr = 0.0000054\n",
      "[17/25][7220/9765] Loss_D: 0.1027 Loss_G: 0.0408 Convergence: 0.1041 k= 0.019288 lr = 0.0000054\n",
      "[17/25][7230/9765] Loss_D: 0.1099 Loss_G: 0.0382 Convergence: 0.1167 k= 0.019284 lr = 0.0000054\n",
      "[17/25][7240/9765] Loss_D: 0.1035 Loss_G: 0.0387 Convergence: 0.1073 k= 0.019287 lr = 0.0000054\n",
      "[17/25][7250/9765] Loss_D: 0.0946 Loss_G: 0.0392 Convergence: 0.0963 k= 0.019284 lr = 0.0000054\n",
      "[17/25][7260/9765] Loss_D: 0.0932 Loss_G: 0.0382 Convergence: 0.0945 k= 0.019287 lr = 0.0000054\n",
      "[17/25][7270/9765] Loss_D: 0.0929 Loss_G: 0.0402 Convergence: 0.0963 k= 0.019284 lr = 0.0000054\n",
      "[17/25][7280/9765] Loss_D: 0.0839 Loss_G: 0.0370 Convergence: 0.0877 k= 0.019287 lr = 0.0000054\n",
      "[17/25][7290/9765] Loss_D: 0.0974 Loss_G: 0.0390 Convergence: 0.0984 k= 0.019293 lr = 0.0000054\n",
      "[17/25][7300/9765] Loss_D: 0.0899 Loss_G: 0.0389 Convergence: 0.0933 k= 0.019291 lr = 0.0000054\n",
      "[17/25][7310/9765] Loss_D: 0.0936 Loss_G: 0.0377 Convergence: 0.0944 k= 0.019287 lr = 0.0000054\n",
      "[17/25][7320/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0964 k= 0.019296 lr = 0.0000054\n",
      "[17/25][7330/9765] Loss_D: 0.1030 Loss_G: 0.0389 Convergence: 0.1063 k= 0.019301 lr = 0.0000054\n",
      "[17/25][7340/9765] Loss_D: 0.0996 Loss_G: 0.0391 Convergence: 0.1015 k= 0.019291 lr = 0.0000054\n",
      "[17/25][7350/9765] Loss_D: 0.0947 Loss_G: 0.0386 Convergence: 0.0959 k= 0.019288 lr = 0.0000054\n",
      "[17/25][7360/9765] Loss_D: 0.0881 Loss_G: 0.0378 Convergence: 0.0911 k= 0.019295 lr = 0.0000054\n",
      "[17/25][7370/9765] Loss_D: 0.0969 Loss_G: 0.0383 Convergence: 0.0984 k= 0.019310 lr = 0.0000054\n",
      "[17/25][7380/9765] Loss_D: 0.1051 Loss_G: 0.0368 Convergence: 0.1114 k= 0.019326 lr = 0.0000054\n",
      "[17/25][7390/9765] Loss_D: 0.0986 Loss_G: 0.0366 Convergence: 0.1024 k= 0.019346 lr = 0.0000054\n",
      "[17/25][7400/9765] Loss_D: 0.0912 Loss_G: 0.0376 Convergence: 0.0927 k= 0.019356 lr = 0.0000054\n",
      "[17/25][7410/9765] Loss_D: 0.0932 Loss_G: 0.0396 Convergence: 0.0960 k= 0.019363 lr = 0.0000054\n",
      "[17/25][7420/9765] Loss_D: 0.0912 Loss_G: 0.0399 Convergence: 0.0951 k= 0.019352 lr = 0.0000054\n",
      "[17/25][7430/9765] Loss_D: 0.1078 Loss_G: 0.0415 Convergence: 0.1106 k= 0.019328 lr = 0.0000054\n",
      "[17/25][7440/9765] Loss_D: 0.1051 Loss_G: 0.0432 Convergence: 0.1067 k= 0.019302 lr = 0.0000054\n",
      "[17/25][7450/9765] Loss_D: 0.0946 Loss_G: 0.0415 Convergence: 0.0988 k= 0.019290 lr = 0.0000054\n",
      "[17/25][7460/9765] Loss_D: 0.0910 Loss_G: 0.0392 Convergence: 0.0943 k= 0.019268 lr = 0.0000054\n",
      "[17/25][7470/9765] Loss_D: 0.0922 Loss_G: 0.0387 Convergence: 0.0945 k= 0.019265 lr = 0.0000054\n",
      "[17/25][7480/9765] Loss_D: 0.0911 Loss_G: 0.0398 Convergence: 0.0949 k= 0.019249 lr = 0.0000054\n",
      "[17/25][7490/9765] Loss_D: 0.0926 Loss_G: 0.0402 Convergence: 0.0962 k= 0.019251 lr = 0.0000054\n",
      "[17/25][7500/9765] Loss_D: 0.1084 Loss_G: 0.0385 Convergence: 0.1143 k= 0.019252 lr = 0.0000054\n",
      "[17/25][7510/9765] Loss_D: 0.1036 Loss_G: 0.0375 Convergence: 0.1086 k= 0.019271 lr = 0.0000054\n",
      "[17/25][7520/9765] Loss_D: 0.0977 Loss_G: 0.0380 Convergence: 0.0999 k= 0.019278 lr = 0.0000054\n",
      "[17/25][7530/9765] Loss_D: 0.0935 Loss_G: 0.0384 Convergence: 0.0949 k= 0.019288 lr = 0.0000054\n",
      "[17/25][7540/9765] Loss_D: 0.0995 Loss_G: 0.0381 Convergence: 0.1023 k= 0.019292 lr = 0.0000054\n",
      "[17/25][7550/9765] Loss_D: 0.1006 Loss_G: 0.0404 Convergence: 0.1015 k= 0.019286 lr = 0.0000054\n",
      "[17/25][7560/9765] Loss_D: 0.0931 Loss_G: 0.0381 Convergence: 0.0944 k= 0.019282 lr = 0.0000054\n",
      "[17/25][7570/9765] Loss_D: 0.0904 Loss_G: 0.0375 Convergence: 0.0921 k= 0.019289 lr = 0.0000054\n",
      "[17/25][7580/9765] Loss_D: 0.0965 Loss_G: 0.0383 Convergence: 0.0978 k= 0.019292 lr = 0.0000054\n",
      "[17/25][7590/9765] Loss_D: 0.1035 Loss_G: 0.0393 Convergence: 0.1066 k= 0.019302 lr = 0.0000054\n",
      "[17/25][7600/9765] Loss_D: 0.0988 Loss_G: 0.0386 Convergence: 0.1007 k= 0.019322 lr = 0.0000054\n",
      "[17/25][7610/9765] Loss_D: 0.0945 Loss_G: 0.0381 Convergence: 0.0952 k= 0.019333 lr = 0.0000054\n",
      "[17/25][7620/9765] Loss_D: 0.0948 Loss_G: 0.0377 Convergence: 0.0960 k= 0.019331 lr = 0.0000054\n",
      "[17/25][7630/9765] Loss_D: 0.0961 Loss_G: 0.0393 Convergence: 0.0974 k= 0.019332 lr = 0.0000054\n",
      "[17/25][7640/9765] Loss_D: 0.0913 Loss_G: 0.0387 Convergence: 0.0940 k= 0.019331 lr = 0.0000054\n",
      "[17/25][7650/9765] Loss_D: 0.0942 Loss_G: 0.0400 Convergence: 0.0969 k= 0.019338 lr = 0.0000054\n",
      "[17/25][7660/9765] Loss_D: 0.0951 Loss_G: 0.0406 Convergence: 0.0981 k= 0.019331 lr = 0.0000054\n",
      "[17/25][7670/9765] Loss_D: 0.0853 Loss_G: 0.0395 Convergence: 0.0912 k= 0.019304 lr = 0.0000054\n",
      "[17/25][7680/9765] Loss_D: 0.1023 Loss_G: 0.0398 Convergence: 0.1045 k= 0.019285 lr = 0.0000054\n",
      "[17/25][7690/9765] Loss_D: 0.0920 Loss_G: 0.0413 Convergence: 0.0970 k= 0.019283 lr = 0.0000054\n",
      "[17/25][7700/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.019289 lr = 0.0000054\n",
      "[17/25][7710/9765] Loss_D: 0.0943 Loss_G: 0.0395 Convergence: 0.0965 k= 0.019283 lr = 0.0000054\n",
      "[17/25][7720/9765] Loss_D: 0.0966 Loss_G: 0.0353 Convergence: 0.1009 k= 0.019294 lr = 0.0000054\n",
      "[17/25][7730/9765] Loss_D: 0.0923 Loss_G: 0.0365 Convergence: 0.0938 k= 0.019301 lr = 0.0000054\n",
      "[17/25][7740/9765] Loss_D: 0.0968 Loss_G: 0.0384 Convergence: 0.0981 k= 0.019319 lr = 0.0000054\n",
      "[17/25][7750/9765] Loss_D: 0.0957 Loss_G: 0.0380 Convergence: 0.0970 k= 0.019320 lr = 0.0000054\n",
      "[17/25][7760/9765] Loss_D: 0.0918 Loss_G: 0.0357 Convergence: 0.0938 k= 0.019336 lr = 0.0000054\n",
      "[17/25][7770/9765] Loss_D: 0.0914 Loss_G: 0.0367 Convergence: 0.0923 k= 0.019355 lr = 0.0000054\n",
      "[17/25][7780/9765] Loss_D: 0.0904 Loss_G: 0.0359 Convergence: 0.0917 k= 0.019394 lr = 0.0000054\n",
      "[17/25][7790/9765] Loss_D: 0.1128 Loss_G: 0.0387 Convergence: 0.1203 k= 0.019417 lr = 0.0000054\n",
      "[17/25][7800/9765] Loss_D: 0.0965 Loss_G: 0.0377 Convergence: 0.0984 k= 0.019418 lr = 0.0000054\n",
      "[17/25][7810/9765] Loss_D: 0.1028 Loss_G: 0.0421 Convergence: 0.1042 k= 0.019425 lr = 0.0000054\n",
      "[17/25][7820/9765] Loss_D: 0.0959 Loss_G: 0.0401 Convergence: 0.0981 k= 0.019416 lr = 0.0000054\n",
      "[17/25][7830/9765] Loss_D: 0.0958 Loss_G: 0.0409 Convergence: 0.0989 k= 0.019389 lr = 0.0000054\n",
      "[17/25][7840/9765] Loss_D: 0.1003 Loss_G: 0.0399 Convergence: 0.1017 k= 0.019366 lr = 0.0000054\n",
      "[17/25][7850/9765] Loss_D: 0.0953 Loss_G: 0.0383 Convergence: 0.0961 k= 0.019365 lr = 0.0000054\n",
      "[17/25][7860/9765] Loss_D: 0.0906 Loss_G: 0.0383 Convergence: 0.0930 k= 0.019355 lr = 0.0000054\n",
      "[17/25][7870/9765] Loss_D: 0.1006 Loss_G: 0.0378 Convergence: 0.1040 k= 0.019353 lr = 0.0000054\n",
      "[17/25][7880/9765] Loss_D: 0.0934 Loss_G: 0.0395 Convergence: 0.0960 k= 0.019350 lr = 0.0000054\n",
      "[17/25][7890/9765] Loss_D: 0.0995 Loss_G: 0.0389 Convergence: 0.1014 k= 0.019344 lr = 0.0000054\n",
      "[17/25][7900/9765] Loss_D: 0.0937 Loss_G: 0.0371 Convergence: 0.0952 k= 0.019354 lr = 0.0000054\n",
      "[17/25][7910/9765] Loss_D: 0.0927 Loss_G: 0.0395 Convergence: 0.0956 k= 0.019354 lr = 0.0000054\n",
      "[17/25][7920/9765] Loss_D: 0.1028 Loss_G: 0.0415 Convergence: 0.1036 k= 0.019350 lr = 0.0000054\n",
      "[17/25][7930/9765] Loss_D: 0.0991 Loss_G: 0.0393 Convergence: 0.1005 k= 0.019350 lr = 0.0000054\n",
      "[17/25][7940/9765] Loss_D: 0.0882 Loss_G: 0.0401 Convergence: 0.0935 k= 0.019328 lr = 0.0000054\n",
      "[17/25][7950/9765] Loss_D: 0.0917 Loss_G: 0.0409 Convergence: 0.0964 k= 0.019309 lr = 0.0000054\n",
      "[17/25][7960/9765] Loss_D: 0.0940 Loss_G: 0.0390 Convergence: 0.0958 k= 0.019294 lr = 0.0000054\n",
      "[17/25][7970/9765] Loss_D: 0.1088 Loss_G: 0.0396 Convergence: 0.1137 k= 0.019293 lr = 0.0000054\n",
      "[17/25][7980/9765] Loss_D: 0.1074 Loss_G: 0.0404 Convergence: 0.1110 k= 0.019282 lr = 0.0000054\n",
      "[17/25][7990/9765] Loss_D: 0.0998 Loss_G: 0.0385 Convergence: 0.1022 k= 0.019284 lr = 0.0000054\n",
      "[17/25][8000/9765] Loss_D: 0.0914 Loss_G: 0.0375 Convergence: 0.0928 k= 0.019299 lr = 0.0000051\n",
      "[17/25][8010/9765] Loss_D: 0.0915 Loss_G: 0.0378 Convergence: 0.0931 k= 0.019298 lr = 0.0000051\n",
      "[17/25][8020/9765] Loss_D: 0.0929 Loss_G: 0.0367 Convergence: 0.0943 k= 0.019328 lr = 0.0000051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][8030/9765] Loss_D: 0.0939 Loss_G: 0.0366 Convergence: 0.0959 k= 0.019351 lr = 0.0000051\n",
      "[17/25][8040/9765] Loss_D: 0.0958 Loss_G: 0.0367 Convergence: 0.0984 k= 0.019364 lr = 0.0000051\n",
      "[17/25][8050/9765] Loss_D: 0.0927 Loss_G: 0.0374 Convergence: 0.0934 k= 0.019381 lr = 0.0000051\n",
      "[17/25][8060/9765] Loss_D: 0.0932 Loss_G: 0.0391 Convergence: 0.0955 k= 0.019388 lr = 0.0000051\n",
      "[17/25][8070/9765] Loss_D: 0.0954 Loss_G: 0.0397 Convergence: 0.0974 k= 0.019394 lr = 0.0000051\n",
      "[17/25][8080/9765] Loss_D: 0.0939 Loss_G: 0.0386 Convergence: 0.0954 k= 0.019395 lr = 0.0000051\n",
      "[17/25][8090/9765] Loss_D: 0.0990 Loss_G: 0.0387 Convergence: 0.1009 k= 0.019396 lr = 0.0000051\n",
      "[17/25][8100/9765] Loss_D: 0.0935 Loss_G: 0.0391 Convergence: 0.0957 k= 0.019401 lr = 0.0000051\n",
      "[17/25][8110/9765] Loss_D: 0.1037 Loss_G: 0.0408 Convergence: 0.1053 k= 0.019398 lr = 0.0000051\n",
      "[17/25][8120/9765] Loss_D: 0.0897 Loss_G: 0.0372 Convergence: 0.0915 k= 0.019389 lr = 0.0000051\n",
      "[17/25][8130/9765] Loss_D: 0.0982 Loss_G: 0.0380 Convergence: 0.1006 k= 0.019403 lr = 0.0000051\n",
      "[17/25][8140/9765] Loss_D: 0.1053 Loss_G: 0.0396 Convergence: 0.1088 k= 0.019410 lr = 0.0000051\n",
      "[17/25][8150/9765] Loss_D: 0.0895 Loss_G: 0.0378 Convergence: 0.0919 k= 0.019403 lr = 0.0000051\n",
      "[17/25][8160/9765] Loss_D: 0.0967 Loss_G: 0.0377 Convergence: 0.0986 k= 0.019402 lr = 0.0000051\n",
      "[17/25][8170/9765] Loss_D: 0.0887 Loss_G: 0.0382 Convergence: 0.0919 k= 0.019409 lr = 0.0000051\n",
      "[17/25][8180/9765] Loss_D: 0.0983 Loss_G: 0.0389 Convergence: 0.0997 k= 0.019427 lr = 0.0000051\n",
      "[17/25][8190/9765] Loss_D: 0.0951 Loss_G: 0.0383 Convergence: 0.0958 k= 0.019437 lr = 0.0000051\n",
      "[17/25][8200/9765] Loss_D: 0.0906 Loss_G: 0.0381 Convergence: 0.0930 k= 0.019442 lr = 0.0000051\n",
      "[17/25][8210/9765] Loss_D: 0.0881 Loss_G: 0.0386 Convergence: 0.0919 k= 0.019440 lr = 0.0000051\n",
      "[17/25][8220/9765] Loss_D: 0.0866 Loss_G: 0.0390 Convergence: 0.0914 k= 0.019431 lr = 0.0000051\n",
      "[17/25][8230/9765] Loss_D: 0.0921 Loss_G: 0.0410 Convergence: 0.0968 k= 0.019401 lr = 0.0000051\n",
      "[17/25][8240/9765] Loss_D: 0.0952 Loss_G: 0.0398 Convergence: 0.0973 k= 0.019387 lr = 0.0000051\n",
      "[17/25][8250/9765] Loss_D: 0.1007 Loss_G: 0.0401 Convergence: 0.1020 k= 0.019381 lr = 0.0000051\n",
      "[17/25][8260/9765] Loss_D: 0.0972 Loss_G: 0.0415 Convergence: 0.1003 k= 0.019355 lr = 0.0000051\n",
      "[17/25][8270/9765] Loss_D: 0.1043 Loss_G: 0.0407 Convergence: 0.1065 k= 0.019344 lr = 0.0000051\n",
      "[17/25][8280/9765] Loss_D: 0.1080 Loss_G: 0.0392 Convergence: 0.1131 k= 0.019333 lr = 0.0000051\n",
      "[17/25][8290/9765] Loss_D: 0.0970 Loss_G: 0.0384 Convergence: 0.0985 k= 0.019336 lr = 0.0000051\n",
      "[17/25][8300/9765] Loss_D: 0.0956 Loss_G: 0.0377 Convergence: 0.0972 k= 0.019343 lr = 0.0000051\n",
      "[17/25][8310/9765] Loss_D: 0.1015 Loss_G: 0.0388 Convergence: 0.1044 k= 0.019354 lr = 0.0000051\n",
      "[17/25][8320/9765] Loss_D: 0.0929 Loss_G: 0.0392 Convergence: 0.0954 k= 0.019347 lr = 0.0000051\n",
      "[17/25][8330/9765] Loss_D: 0.0999 Loss_G: 0.0403 Convergence: 0.1007 k= 0.019349 lr = 0.0000051\n",
      "[17/25][8340/9765] Loss_D: 0.0949 Loss_G: 0.0390 Convergence: 0.0964 k= 0.019346 lr = 0.0000051\n",
      "[17/25][8350/9765] Loss_D: 0.0872 Loss_G: 0.0368 Convergence: 0.0896 k= 0.019343 lr = 0.0000051\n",
      "[17/25][8360/9765] Loss_D: 0.0921 Loss_G: 0.0385 Convergence: 0.0943 k= 0.019344 lr = 0.0000051\n",
      "[17/25][8370/9765] Loss_D: 0.0858 Loss_G: 0.0374 Convergence: 0.0893 k= 0.019353 lr = 0.0000051\n",
      "[17/25][8380/9765] Loss_D: 0.0922 Loss_G: 0.0369 Convergence: 0.0932 k= 0.019370 lr = 0.0000051\n",
      "[17/25][8390/9765] Loss_D: 0.0947 Loss_G: 0.0394 Convergence: 0.0967 k= 0.019378 lr = 0.0000051\n",
      "[17/25][8400/9765] Loss_D: 0.0951 Loss_G: 0.0381 Convergence: 0.0962 k= 0.019393 lr = 0.0000051\n",
      "[17/25][8410/9765] Loss_D: 0.0991 Loss_G: 0.0377 Convergence: 0.1020 k= 0.019405 lr = 0.0000051\n",
      "[17/25][8420/9765] Loss_D: 0.0975 Loss_G: 0.0377 Convergence: 0.0999 k= 0.019412 lr = 0.0000051\n",
      "[17/25][8430/9765] Loss_D: 0.1036 Loss_G: 0.0362 Convergence: 0.1098 k= 0.019416 lr = 0.0000051\n",
      "[17/25][8440/9765] Loss_D: 0.0986 Loss_G: 0.0369 Convergence: 0.1021 k= 0.019432 lr = 0.0000051\n",
      "[17/25][8450/9765] Loss_D: 0.1021 Loss_G: 0.0398 Convergence: 0.1042 k= 0.019449 lr = 0.0000051\n",
      "[17/25][8460/9765] Loss_D: 0.0904 Loss_G: 0.0395 Convergence: 0.0942 k= 0.019437 lr = 0.0000051\n",
      "[17/25][8470/9765] Loss_D: 0.0935 Loss_G: 0.0386 Convergence: 0.0951 k= 0.019436 lr = 0.0000051\n",
      "[17/25][8480/9765] Loss_D: 0.0973 Loss_G: 0.0386 Convergence: 0.0987 k= 0.019448 lr = 0.0000051\n",
      "[17/25][8490/9765] Loss_D: 0.1069 Loss_G: 0.0398 Convergence: 0.1109 k= 0.019455 lr = 0.0000051\n",
      "[17/25][8500/9765] Loss_D: 0.0980 Loss_G: 0.0377 Convergence: 0.1005 k= 0.019463 lr = 0.0000051\n",
      "[17/25][8510/9765] Loss_D: 0.0953 Loss_G: 0.0371 Convergence: 0.0974 k= 0.019462 lr = 0.0000051\n",
      "[17/25][8520/9765] Loss_D: 0.0986 Loss_G: 0.0398 Convergence: 0.0995 k= 0.019463 lr = 0.0000051\n",
      "[17/25][8530/9765] Loss_D: 0.0907 Loss_G: 0.0388 Convergence: 0.0937 k= 0.019449 lr = 0.0000051\n",
      "[17/25][8540/9765] Loss_D: 0.0936 Loss_G: 0.0402 Convergence: 0.0968 k= 0.019437 lr = 0.0000051\n",
      "[17/25][8550/9765] Loss_D: 0.0979 Loss_G: 0.0398 Convergence: 0.0990 k= 0.019433 lr = 0.0000051\n",
      "[17/25][8560/9765] Loss_D: 0.1034 Loss_G: 0.0386 Convergence: 0.1072 k= 0.019426 lr = 0.0000051\n",
      "[17/25][8570/9765] Loss_D: 0.0951 Loss_G: 0.0374 Convergence: 0.0967 k= 0.019442 lr = 0.0000051\n",
      "[17/25][8580/9765] Loss_D: 0.0855 Loss_G: 0.0372 Convergence: 0.0889 k= 0.019444 lr = 0.0000051\n",
      "[17/25][8590/9765] Loss_D: 0.0879 Loss_G: 0.0362 Convergence: 0.0894 k= 0.019471 lr = 0.0000051\n",
      "[17/25][8600/9765] Loss_D: 0.0867 Loss_G: 0.0380 Convergence: 0.0905 k= 0.019478 lr = 0.0000051\n",
      "[17/25][8610/9765] Loss_D: 0.0962 Loss_G: 0.0368 Convergence: 0.0990 k= 0.019492 lr = 0.0000051\n",
      "[17/25][8620/9765] Loss_D: 0.0953 Loss_G: 0.0389 Convergence: 0.0965 k= 0.019506 lr = 0.0000051\n",
      "[17/25][8630/9765] Loss_D: 0.0883 Loss_G: 0.0397 Convergence: 0.0931 k= 0.019496 lr = 0.0000051\n",
      "[17/25][8640/9765] Loss_D: 0.1000 Loss_G: 0.0398 Convergence: 0.1013 k= 0.019493 lr = 0.0000051\n",
      "[17/25][8650/9765] Loss_D: 0.0959 Loss_G: 0.0379 Convergence: 0.0974 k= 0.019501 lr = 0.0000051\n",
      "[17/25][8660/9765] Loss_D: 0.0986 Loss_G: 0.0380 Convergence: 0.1011 k= 0.019511 lr = 0.0000051\n",
      "[17/25][8670/9765] Loss_D: 0.1058 Loss_G: 0.0392 Convergence: 0.1100 k= 0.019523 lr = 0.0000051\n",
      "[17/25][8680/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.019520 lr = 0.0000051\n",
      "[17/25][8690/9765] Loss_D: 0.1028 Loss_G: 0.0381 Convergence: 0.1069 k= 0.019523 lr = 0.0000051\n",
      "[17/25][8700/9765] Loss_D: 0.1024 Loss_G: 0.0374 Convergence: 0.1069 k= 0.019541 lr = 0.0000051\n",
      "[17/25][8710/9765] Loss_D: 0.0934 Loss_G: 0.0372 Convergence: 0.0946 k= 0.019553 lr = 0.0000051\n",
      "[17/25][8720/9765] Loss_D: 0.0979 Loss_G: 0.0382 Convergence: 0.0999 k= 0.019567 lr = 0.0000051\n",
      "[17/25][8730/9765] Loss_D: 0.1025 Loss_G: 0.0390 Convergence: 0.1056 k= 0.019566 lr = 0.0000051\n",
      "[17/25][8740/9765] Loss_D: 0.0964 Loss_G: 0.0394 Convergence: 0.0977 k= 0.019558 lr = 0.0000051\n",
      "[17/25][8750/9765] Loss_D: 0.0999 Loss_G: 0.0415 Convergence: 0.1020 k= 0.019556 lr = 0.0000051\n",
      "[17/25][8760/9765] Loss_D: 0.0934 Loss_G: 0.0411 Convergence: 0.0976 k= 0.019534 lr = 0.0000051\n",
      "[17/25][8770/9765] Loss_D: 0.0971 Loss_G: 0.0407 Convergence: 0.0994 k= 0.019527 lr = 0.0000051\n",
      "[17/25][8780/9765] Loss_D: 0.0899 Loss_G: 0.0405 Convergence: 0.0950 k= 0.019506 lr = 0.0000051\n",
      "[17/25][8790/9765] Loss_D: 0.0959 Loss_G: 0.0383 Convergence: 0.0970 k= 0.019503 lr = 0.0000051\n",
      "[17/25][8800/9765] Loss_D: 0.0949 Loss_G: 0.0380 Convergence: 0.0959 k= 0.019489 lr = 0.0000051\n",
      "[17/25][8810/9765] Loss_D: 0.0997 Loss_G: 0.0371 Convergence: 0.1035 k= 0.019498 lr = 0.0000051\n",
      "[17/25][8820/9765] Loss_D: 0.0951 Loss_G: 0.0371 Convergence: 0.0971 k= 0.019513 lr = 0.0000051\n",
      "[17/25][8830/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0992 k= 0.019526 lr = 0.0000051\n",
      "[17/25][8840/9765] Loss_D: 0.1060 Loss_G: 0.0402 Convergence: 0.1094 k= 0.019520 lr = 0.0000051\n",
      "[17/25][8850/9765] Loss_D: 0.0985 Loss_G: 0.0404 Convergence: 0.1001 k= 0.019496 lr = 0.0000051\n",
      "[17/25][8860/9765] Loss_D: 0.0886 Loss_G: 0.0405 Convergence: 0.0942 k= 0.019482 lr = 0.0000051\n",
      "[17/25][8870/9765] Loss_D: 0.0906 Loss_G: 0.0416 Convergence: 0.0964 k= 0.019468 lr = 0.0000051\n",
      "[17/25][8880/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.019455 lr = 0.0000051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][8890/9765] Loss_D: 0.0906 Loss_G: 0.0376 Convergence: 0.0924 k= 0.019461 lr = 0.0000051\n",
      "[17/25][8900/9765] Loss_D: 0.0922 Loss_G: 0.0379 Convergence: 0.0937 k= 0.019455 lr = 0.0000051\n",
      "[17/25][8910/9765] Loss_D: 0.0886 Loss_G: 0.0376 Convergence: 0.0912 k= 0.019456 lr = 0.0000051\n",
      "[17/25][8920/9765] Loss_D: 0.1026 Loss_G: 0.0380 Convergence: 0.1066 k= 0.019467 lr = 0.0000051\n",
      "[17/25][8930/9765] Loss_D: 0.1101 Loss_G: 0.0395 Convergence: 0.1156 k= 0.019485 lr = 0.0000051\n",
      "[17/25][8940/9765] Loss_D: 0.0909 Loss_G: 0.0395 Convergence: 0.0945 k= 0.019484 lr = 0.0000051\n",
      "[17/25][8950/9765] Loss_D: 0.0850 Loss_G: 0.0385 Convergence: 0.0900 k= 0.019496 lr = 0.0000051\n",
      "[17/25][8960/9765] Loss_D: 0.0945 Loss_G: 0.0392 Convergence: 0.0963 k= 0.019493 lr = 0.0000051\n",
      "[17/25][8970/9765] Loss_D: 0.0980 Loss_G: 0.0366 Convergence: 0.1016 k= 0.019506 lr = 0.0000051\n",
      "[17/25][8980/9765] Loss_D: 0.0881 Loss_G: 0.0381 Convergence: 0.0914 k= 0.019521 lr = 0.0000051\n",
      "[17/25][8990/9765] Loss_D: 0.0974 Loss_G: 0.0391 Convergence: 0.0983 k= 0.019525 lr = 0.0000051\n",
      "[17/25][9000/9765] Loss_D: 0.0946 Loss_G: 0.0392 Convergence: 0.0964 k= 0.019523 lr = 0.0000051\n",
      "[17/25][9010/9765] Loss_D: 0.1005 Loss_G: 0.0382 Convergence: 0.1035 k= 0.019525 lr = 0.0000051\n",
      "[17/25][9020/9765] Loss_D: 0.0913 Loss_G: 0.0378 Convergence: 0.0930 k= 0.019524 lr = 0.0000051\n",
      "[17/25][9030/9765] Loss_D: 0.0939 Loss_G: 0.0395 Convergence: 0.0963 k= 0.019521 lr = 0.0000051\n",
      "[17/25][9040/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0992 k= 0.019527 lr = 0.0000051\n",
      "[17/25][9050/9765] Loss_D: 0.0922 Loss_G: 0.0386 Convergence: 0.0943 k= 0.019523 lr = 0.0000051\n",
      "[17/25][9060/9765] Loss_D: 0.0914 Loss_G: 0.0383 Convergence: 0.0936 k= 0.019513 lr = 0.0000051\n",
      "[17/25][9070/9765] Loss_D: 0.0813 Loss_G: 0.0392 Convergence: 0.0885 k= 0.019515 lr = 0.0000051\n",
      "[17/25][9080/9765] Loss_D: 0.1016 Loss_G: 0.0391 Convergence: 0.1042 k= 0.019523 lr = 0.0000051\n",
      "[17/25][9090/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.019526 lr = 0.0000051\n",
      "[17/25][9100/9765] Loss_D: 0.0878 Loss_G: 0.0386 Convergence: 0.0918 k= 0.019514 lr = 0.0000051\n",
      "[17/25][9110/9765] Loss_D: 0.0993 Loss_G: 0.0387 Convergence: 0.1013 k= 0.019522 lr = 0.0000051\n",
      "[17/25][9120/9765] Loss_D: 0.0993 Loss_G: 0.0408 Convergence: 0.1009 k= 0.019527 lr = 0.0000051\n",
      "[17/25][9130/9765] Loss_D: 0.0999 Loss_G: 0.0389 Convergence: 0.1020 k= 0.019526 lr = 0.0000051\n",
      "[17/25][9140/9765] Loss_D: 0.1019 Loss_G: 0.0374 Convergence: 0.1063 k= 0.019532 lr = 0.0000051\n",
      "[17/25][9150/9765] Loss_D: 0.0890 Loss_G: 0.0380 Convergence: 0.0918 k= 0.019535 lr = 0.0000051\n",
      "[17/25][9160/9765] Loss_D: 0.0969 Loss_G: 0.0381 Convergence: 0.0987 k= 0.019551 lr = 0.0000051\n",
      "[17/25][9170/9765] Loss_D: 0.0906 Loss_G: 0.0401 Convergence: 0.0950 k= 0.019550 lr = 0.0000051\n",
      "[17/25][9180/9765] Loss_D: 0.0931 Loss_G: 0.0377 Convergence: 0.0941 k= 0.019542 lr = 0.0000051\n",
      "[17/25][9190/9765] Loss_D: 0.0925 Loss_G: 0.0402 Convergence: 0.0962 k= 0.019548 lr = 0.0000051\n",
      "[17/25][9200/9765] Loss_D: 0.0930 Loss_G: 0.0379 Convergence: 0.0942 k= 0.019541 lr = 0.0000051\n",
      "[17/25][9210/9765] Loss_D: 0.0899 Loss_G: 0.0396 Convergence: 0.0940 k= 0.019537 lr = 0.0000051\n",
      "[17/25][9220/9765] Loss_D: 0.1002 Loss_G: 0.0398 Convergence: 0.1015 k= 0.019526 lr = 0.0000051\n",
      "[17/25][9230/9765] Loss_D: 0.0863 Loss_G: 0.0385 Convergence: 0.0908 k= 0.019501 lr = 0.0000051\n",
      "[17/25][9240/9765] Loss_D: 0.1003 Loss_G: 0.0390 Convergence: 0.1025 k= 0.019493 lr = 0.0000051\n",
      "[17/25][9250/9765] Loss_D: 0.1050 Loss_G: 0.0415 Convergence: 0.1066 k= 0.019488 lr = 0.0000051\n",
      "[17/25][9260/9765] Loss_D: 0.0922 Loss_G: 0.0394 Convergence: 0.0952 k= 0.019479 lr = 0.0000051\n",
      "[17/25][9270/9765] Loss_D: 0.0960 Loss_G: 0.0404 Convergence: 0.0984 k= 0.019473 lr = 0.0000051\n",
      "[17/25][9280/9765] Loss_D: 0.0911 Loss_G: 0.0392 Convergence: 0.0944 k= 0.019458 lr = 0.0000051\n",
      "[17/25][9290/9765] Loss_D: 0.0973 Loss_G: 0.0412 Convergence: 0.1000 k= 0.019448 lr = 0.0000051\n",
      "[17/25][9300/9765] Loss_D: 0.0986 Loss_G: 0.0374 Convergence: 0.1017 k= 0.019449 lr = 0.0000051\n",
      "[17/25][9310/9765] Loss_D: 0.0961 Loss_G: 0.0385 Convergence: 0.0971 k= 0.019450 lr = 0.0000051\n",
      "[17/25][9320/9765] Loss_D: 0.0971 Loss_G: 0.0384 Convergence: 0.0986 k= 0.019458 lr = 0.0000051\n",
      "[17/25][9330/9765] Loss_D: 0.0959 Loss_G: 0.0393 Convergence: 0.0973 k= 0.019455 lr = 0.0000051\n",
      "[17/25][9340/9765] Loss_D: 0.1014 Loss_G: 0.0396 Convergence: 0.1034 k= 0.019453 lr = 0.0000051\n",
      "[17/25][9350/9765] Loss_D: 0.1002 Loss_G: 0.0409 Convergence: 0.1015 k= 0.019458 lr = 0.0000051\n",
      "[17/25][9360/9765] Loss_D: 0.0986 Loss_G: 0.0400 Convergence: 0.0996 k= 0.019454 lr = 0.0000051\n",
      "[17/25][9370/9765] Loss_D: 0.1010 Loss_G: 0.0399 Convergence: 0.1026 k= 0.019441 lr = 0.0000051\n",
      "[17/25][9380/9765] Loss_D: 0.1060 Loss_G: 0.0396 Convergence: 0.1099 k= 0.019438 lr = 0.0000051\n",
      "[17/25][9390/9765] Loss_D: 0.0971 Loss_G: 0.0401 Convergence: 0.0988 k= 0.019439 lr = 0.0000051\n",
      "[17/25][9400/9765] Loss_D: 0.0889 Loss_G: 0.0389 Convergence: 0.0927 k= 0.019439 lr = 0.0000051\n",
      "[17/25][9410/9765] Loss_D: 0.0964 Loss_G: 0.0400 Convergence: 0.0983 k= 0.019430 lr = 0.0000051\n",
      "[17/25][9420/9765] Loss_D: 0.0996 Loss_G: 0.0385 Convergence: 0.1021 k= 0.019422 lr = 0.0000051\n",
      "[17/25][9430/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0961 k= 0.019425 lr = 0.0000051\n",
      "[17/25][9440/9765] Loss_D: 0.1021 Loss_G: 0.0386 Convergence: 0.1054 k= 0.019417 lr = 0.0000051\n",
      "[17/25][9450/9765] Loss_D: 0.1024 Loss_G: 0.0402 Convergence: 0.1042 k= 0.019431 lr = 0.0000051\n",
      "[17/25][9460/9765] Loss_D: 0.1071 Loss_G: 0.0397 Convergence: 0.1113 k= 0.019422 lr = 0.0000051\n",
      "[17/25][9470/9765] Loss_D: 0.1054 Loss_G: 0.0405 Convergence: 0.1081 k= 0.019424 lr = 0.0000051\n",
      "[17/25][9480/9765] Loss_D: 0.0850 Loss_G: 0.0388 Convergence: 0.0903 k= 0.019409 lr = 0.0000051\n",
      "[17/25][9490/9765] Loss_D: 0.1081 Loss_G: 0.0384 Convergence: 0.1140 k= 0.019434 lr = 0.0000051\n",
      "[17/25][9500/9765] Loss_D: 0.0948 Loss_G: 0.0413 Convergence: 0.0986 k= 0.019437 lr = 0.0000051\n",
      "[17/25][9510/9765] Loss_D: 0.0985 Loss_G: 0.0398 Convergence: 0.0994 k= 0.019441 lr = 0.0000051\n",
      "[17/25][9520/9765] Loss_D: 0.0977 Loss_G: 0.0391 Convergence: 0.0987 k= 0.019430 lr = 0.0000051\n",
      "[17/25][9530/9765] Loss_D: 0.0904 Loss_G: 0.0379 Convergence: 0.0926 k= 0.019439 lr = 0.0000051\n",
      "[17/25][9540/9765] Loss_D: 0.0995 Loss_G: 0.0378 Convergence: 0.1024 k= 0.019435 lr = 0.0000051\n",
      "[17/25][9550/9765] Loss_D: 0.0973 Loss_G: 0.0380 Convergence: 0.0993 k= 0.019450 lr = 0.0000051\n",
      "[17/25][9560/9765] Loss_D: 0.0987 Loss_G: 0.0392 Convergence: 0.1001 k= 0.019463 lr = 0.0000051\n",
      "[17/25][9570/9765] Loss_D: 0.0923 Loss_G: 0.0368 Convergence: 0.0935 k= 0.019471 lr = 0.0000051\n",
      "[17/25][9580/9765] Loss_D: 0.0950 Loss_G: 0.0375 Convergence: 0.0965 k= 0.019487 lr = 0.0000051\n",
      "[17/25][9590/9765] Loss_D: 0.0881 Loss_G: 0.0387 Convergence: 0.0921 k= 0.019486 lr = 0.0000051\n",
      "[17/25][9600/9765] Loss_D: 0.0909 Loss_G: 0.0406 Convergence: 0.0956 k= 0.019483 lr = 0.0000051\n",
      "[17/25][9610/9765] Loss_D: 0.0914 Loss_G: 0.0417 Convergence: 0.0971 k= 0.019465 lr = 0.0000051\n",
      "[17/25][9620/9765] Loss_D: 0.1010 Loss_G: 0.0429 Convergence: 0.1040 k= 0.019422 lr = 0.0000051\n",
      "[17/25][9630/9765] Loss_D: 0.0953 Loss_G: 0.0416 Convergence: 0.0993 k= 0.019390 lr = 0.0000051\n",
      "[17/25][9640/9765] Loss_D: 0.0887 Loss_G: 0.0416 Convergence: 0.0953 k= 0.019358 lr = 0.0000051\n",
      "[17/25][9650/9765] Loss_D: 0.0910 Loss_G: 0.0392 Convergence: 0.0942 k= 0.019350 lr = 0.0000051\n",
      "[17/25][9660/9765] Loss_D: 0.0964 Loss_G: 0.0391 Convergence: 0.0974 k= 0.019350 lr = 0.0000051\n",
      "[17/25][9670/9765] Loss_D: 0.0917 Loss_G: 0.0381 Convergence: 0.0935 k= 0.019362 lr = 0.0000051\n",
      "[17/25][9680/9765] Loss_D: 0.0965 Loss_G: 0.0386 Convergence: 0.0976 k= 0.019371 lr = 0.0000051\n",
      "[17/25][9690/9765] Loss_D: 0.0908 Loss_G: 0.0351 Convergence: 0.0929 k= 0.019418 lr = 0.0000051\n",
      "[17/25][9700/9765] Loss_D: 0.1001 Loss_G: 0.0376 Convergence: 0.1036 k= 0.019452 lr = 0.0000051\n",
      "[17/25][9710/9765] Loss_D: 0.0963 Loss_G: 0.0368 Convergence: 0.0989 k= 0.019473 lr = 0.0000051\n",
      "[17/25][9720/9765] Loss_D: 0.0916 Loss_G: 0.0392 Convergence: 0.0946 k= 0.019481 lr = 0.0000051\n",
      "[17/25][9730/9765] Loss_D: 0.0969 Loss_G: 0.0381 Convergence: 0.0986 k= 0.019481 lr = 0.0000051\n",
      "[17/25][9740/9765] Loss_D: 0.0962 Loss_G: 0.0404 Convergence: 0.0986 k= 0.019467 lr = 0.0000051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/25][9750/9765] Loss_D: 0.0981 Loss_G: 0.0427 Convergence: 0.1021 k= 0.019429 lr = 0.0000051\n",
      "[17/25][9760/9765] Loss_D: 0.0974 Loss_G: 0.0420 Convergence: 0.1009 k= 0.019389 lr = 0.0000051\n",
      "[18/25][0/9765] Loss_D: 0.0953 Loss_G: 0.0434 Convergence: 0.1011 k= 0.019373 lr = 0.0000051\n",
      "[18/25][10/9765] Loss_D: 0.0932 Loss_G: 0.0405 Convergence: 0.0969 k= 0.019342 lr = 0.0000051\n",
      "[18/25][20/9765] Loss_D: 0.0917 Loss_G: 0.0408 Convergence: 0.0962 k= 0.019311 lr = 0.0000051\n",
      "[18/25][30/9765] Loss_D: 0.1027 Loss_G: 0.0393 Convergence: 0.1055 k= 0.019319 lr = 0.0000051\n",
      "[18/25][40/9765] Loss_D: 0.1010 Loss_G: 0.0370 Convergence: 0.1053 k= 0.019327 lr = 0.0000051\n",
      "[18/25][50/9765] Loss_D: 0.0890 Loss_G: 0.0381 Convergence: 0.0919 k= 0.019338 lr = 0.0000051\n",
      "[18/25][60/9765] Loss_D: 0.0997 Loss_G: 0.0393 Convergence: 0.1014 k= 0.019351 lr = 0.0000051\n",
      "[18/25][70/9765] Loss_D: 0.0888 Loss_G: 0.0385 Convergence: 0.0923 k= 0.019352 lr = 0.0000051\n",
      "[18/25][80/9765] Loss_D: 0.0943 Loss_G: 0.0394 Convergence: 0.0965 k= 0.019347 lr = 0.0000051\n",
      "[18/25][90/9765] Loss_D: 0.0971 Loss_G: 0.0381 Convergence: 0.0989 k= 0.019344 lr = 0.0000051\n",
      "[18/25][100/9765] Loss_D: 0.0904 Loss_G: 0.0401 Convergence: 0.0948 k= 0.019342 lr = 0.0000051\n",
      "[18/25][110/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1025 k= 0.019332 lr = 0.0000051\n",
      "[18/25][120/9765] Loss_D: 0.0984 Loss_G: 0.0397 Convergence: 0.0992 k= 0.019329 lr = 0.0000051\n",
      "[18/25][130/9765] Loss_D: 0.0897 Loss_G: 0.0394 Convergence: 0.0937 k= 0.019321 lr = 0.0000051\n",
      "[18/25][140/9765] Loss_D: 0.0926 Loss_G: 0.0391 Convergence: 0.0951 k= 0.019312 lr = 0.0000051\n",
      "[18/25][150/9765] Loss_D: 0.0962 Loss_G: 0.0392 Convergence: 0.0973 k= 0.019309 lr = 0.0000051\n",
      "[18/25][160/9765] Loss_D: 0.0988 Loss_G: 0.0391 Convergence: 0.1002 k= 0.019323 lr = 0.0000051\n",
      "[18/25][170/9765] Loss_D: 0.0919 Loss_G: 0.0390 Convergence: 0.0946 k= 0.019323 lr = 0.0000051\n",
      "[18/25][180/9765] Loss_D: 0.1025 Loss_G: 0.0397 Convergence: 0.1048 k= 0.019326 lr = 0.0000051\n",
      "[18/25][190/9765] Loss_D: 0.0969 Loss_G: 0.0368 Convergence: 0.0998 k= 0.019341 lr = 0.0000051\n",
      "[18/25][200/9765] Loss_D: 0.0970 Loss_G: 0.0373 Convergence: 0.0995 k= 0.019344 lr = 0.0000051\n",
      "[18/25][210/9765] Loss_D: 0.0999 Loss_G: 0.0380 Convergence: 0.1028 k= 0.019352 lr = 0.0000051\n",
      "[18/25][220/9765] Loss_D: 0.1012 Loss_G: 0.0392 Convergence: 0.1036 k= 0.019360 lr = 0.0000051\n",
      "[18/25][230/9765] Loss_D: 0.0970 Loss_G: 0.0394 Convergence: 0.0981 k= 0.019370 lr = 0.0000051\n",
      "[18/25][240/9765] Loss_D: 0.0962 Loss_G: 0.0411 Convergence: 0.0993 k= 0.019357 lr = 0.0000051\n",
      "[18/25][250/9765] Loss_D: 0.0968 Loss_G: 0.0379 Convergence: 0.0986 k= 0.019357 lr = 0.0000051\n",
      "[18/25][260/9765] Loss_D: 0.0874 Loss_G: 0.0391 Convergence: 0.0919 k= 0.019346 lr = 0.0000051\n",
      "[18/25][270/9765] Loss_D: 0.0916 Loss_G: 0.0413 Convergence: 0.0967 k= 0.019333 lr = 0.0000051\n",
      "[18/25][280/9765] Loss_D: 0.1025 Loss_G: 0.0403 Convergence: 0.1044 k= 0.019327 lr = 0.0000051\n",
      "[18/25][290/9765] Loss_D: 0.0933 Loss_G: 0.0415 Convergence: 0.0979 k= 0.019319 lr = 0.0000051\n",
      "[18/25][300/9765] Loss_D: 0.0989 Loss_G: 0.0394 Convergence: 0.1001 k= 0.019311 lr = 0.0000051\n",
      "[18/25][310/9765] Loss_D: 0.0976 Loss_G: 0.0397 Convergence: 0.0988 k= 0.019302 lr = 0.0000051\n",
      "[18/25][320/9765] Loss_D: 0.0941 Loss_G: 0.0386 Convergence: 0.0954 k= 0.019301 lr = 0.0000051\n",
      "[18/25][330/9765] Loss_D: 0.0959 Loss_G: 0.0398 Convergence: 0.0977 k= 0.019291 lr = 0.0000051\n",
      "[18/25][340/9765] Loss_D: 0.0953 Loss_G: 0.0381 Convergence: 0.0964 k= 0.019294 lr = 0.0000051\n",
      "[18/25][350/9765] Loss_D: 0.1063 Loss_G: 0.0379 Convergence: 0.1120 k= 0.019305 lr = 0.0000051\n",
      "[18/25][360/9765] Loss_D: 0.1005 Loss_G: 0.0380 Convergence: 0.1037 k= 0.019308 lr = 0.0000051\n",
      "[18/25][370/9765] Loss_D: 0.0924 Loss_G: 0.0370 Convergence: 0.0934 k= 0.019315 lr = 0.0000051\n",
      "[18/25][380/9765] Loss_D: 0.0914 Loss_G: 0.0393 Convergence: 0.0946 k= 0.019310 lr = 0.0000051\n",
      "[18/25][390/9765] Loss_D: 0.0913 Loss_G: 0.0392 Convergence: 0.0945 k= 0.019302 lr = 0.0000051\n",
      "[18/25][400/9765] Loss_D: 0.0881 Loss_G: 0.0390 Convergence: 0.0923 k= 0.019310 lr = 0.0000051\n",
      "[18/25][410/9765] Loss_D: 0.1026 Loss_G: 0.0375 Convergence: 0.1072 k= 0.019321 lr = 0.0000051\n",
      "[18/25][420/9765] Loss_D: 0.0898 Loss_G: 0.0378 Convergence: 0.0922 k= 0.019323 lr = 0.0000051\n",
      "[18/25][430/9765] Loss_D: 0.0900 Loss_G: 0.0382 Convergence: 0.0927 k= 0.019329 lr = 0.0000051\n",
      "[18/25][440/9765] Loss_D: 0.1015 Loss_G: 0.0375 Convergence: 0.1056 k= 0.019343 lr = 0.0000051\n",
      "[18/25][450/9765] Loss_D: 0.1007 Loss_G: 0.0388 Convergence: 0.1032 k= 0.019351 lr = 0.0000051\n",
      "[18/25][460/9765] Loss_D: 0.1019 Loss_G: 0.0404 Convergence: 0.1033 k= 0.019348 lr = 0.0000051\n",
      "[18/25][470/9765] Loss_D: 0.1031 Loss_G: 0.0406 Convergence: 0.1049 k= 0.019344 lr = 0.0000051\n",
      "[18/25][480/9765] Loss_D: 0.0885 Loss_G: 0.0409 Convergence: 0.0945 k= 0.019325 lr = 0.0000051\n",
      "[18/25][490/9765] Loss_D: 0.0878 Loss_G: 0.0403 Convergence: 0.0935 k= 0.019303 lr = 0.0000051\n",
      "[18/25][500/9765] Loss_D: 0.0949 Loss_G: 0.0394 Convergence: 0.0968 k= 0.019296 lr = 0.0000051\n",
      "[18/25][510/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0987 k= 0.019300 lr = 0.0000051\n",
      "[18/25][520/9765] Loss_D: 0.0930 Loss_G: 0.0392 Convergence: 0.0955 k= 0.019305 lr = 0.0000051\n",
      "[18/25][530/9765] Loss_D: 0.0986 Loss_G: 0.0400 Convergence: 0.0996 k= 0.019298 lr = 0.0000051\n",
      "[18/25][540/9765] Loss_D: 0.0993 Loss_G: 0.0421 Convergence: 0.1021 k= 0.019277 lr = 0.0000051\n",
      "[18/25][550/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0992 k= 0.019265 lr = 0.0000051\n",
      "[18/25][560/9765] Loss_D: 0.0936 Loss_G: 0.0409 Convergence: 0.0975 k= 0.019258 lr = 0.0000051\n",
      "[18/25][570/9765] Loss_D: 0.0948 Loss_G: 0.0371 Convergence: 0.0966 k= 0.019258 lr = 0.0000051\n",
      "[18/25][580/9765] Loss_D: 0.0879 Loss_G: 0.0379 Convergence: 0.0910 k= 0.019257 lr = 0.0000051\n",
      "[18/25][590/9765] Loss_D: 0.0919 Loss_G: 0.0383 Convergence: 0.0939 k= 0.019270 lr = 0.0000051\n",
      "[18/25][600/9765] Loss_D: 0.1029 Loss_G: 0.0396 Convergence: 0.1055 k= 0.019274 lr = 0.0000051\n",
      "[18/25][610/9765] Loss_D: 0.0916 Loss_G: 0.0389 Convergence: 0.0944 k= 0.019279 lr = 0.0000051\n",
      "[18/25][620/9765] Loss_D: 0.0881 Loss_G: 0.0380 Convergence: 0.0913 k= 0.019280 lr = 0.0000051\n",
      "[18/25][630/9765] Loss_D: 0.0935 Loss_G: 0.0399 Convergence: 0.0965 k= 0.019283 lr = 0.0000051\n",
      "[18/25][640/9765] Loss_D: 0.0964 Loss_G: 0.0383 Convergence: 0.0977 k= 0.019287 lr = 0.0000051\n",
      "[18/25][650/9765] Loss_D: 0.1041 Loss_G: 0.0402 Convergence: 0.1067 k= 0.019293 lr = 0.0000051\n",
      "[18/25][660/9765] Loss_D: 0.1041 Loss_G: 0.0401 Convergence: 0.1067 k= 0.019275 lr = 0.0000051\n",
      "[18/25][670/9765] Loss_D: 0.1071 Loss_G: 0.0401 Convergence: 0.1109 k= 0.019275 lr = 0.0000051\n",
      "[18/25][680/9765] Loss_D: 0.0979 Loss_G: 0.0384 Convergence: 0.0997 k= 0.019277 lr = 0.0000051\n",
      "[18/25][690/9765] Loss_D: 0.1005 Loss_G: 0.0363 Convergence: 0.1053 k= 0.019281 lr = 0.0000051\n",
      "[18/25][700/9765] Loss_D: 0.1072 Loss_G: 0.0365 Convergence: 0.1146 k= 0.019290 lr = 0.0000051\n",
      "[18/25][710/9765] Loss_D: 0.0931 Loss_G: 0.0363 Convergence: 0.0950 k= 0.019291 lr = 0.0000051\n",
      "[18/25][720/9765] Loss_D: 0.1006 Loss_G: 0.0388 Convergence: 0.1031 k= 0.019308 lr = 0.0000051\n",
      "[18/25][730/9765] Loss_D: 0.0993 Loss_G: 0.0397 Convergence: 0.1004 k= 0.019319 lr = 0.0000051\n",
      "[18/25][740/9765] Loss_D: 0.1021 Loss_G: 0.0393 Convergence: 0.1047 k= 0.019314 lr = 0.0000051\n",
      "[18/25][750/9765] Loss_D: 0.0897 Loss_G: 0.0396 Convergence: 0.0938 k= 0.019307 lr = 0.0000051\n",
      "[18/25][760/9765] Loss_D: 0.0982 Loss_G: 0.0410 Convergence: 0.1004 k= 0.019296 lr = 0.0000051\n",
      "[18/25][770/9765] Loss_D: 0.0931 Loss_G: 0.0397 Convergence: 0.0960 k= 0.019282 lr = 0.0000051\n",
      "[18/25][780/9765] Loss_D: 0.1052 Loss_G: 0.0402 Convergence: 0.1082 k= 0.019269 lr = 0.0000051\n",
      "[18/25][790/9765] Loss_D: 0.1026 Loss_G: 0.0393 Convergence: 0.1053 k= 0.019261 lr = 0.0000051\n",
      "[18/25][800/9765] Loss_D: 0.1044 Loss_G: 0.0400 Convergence: 0.1073 k= 0.019256 lr = 0.0000051\n",
      "[18/25][810/9765] Loss_D: 0.0888 Loss_G: 0.0380 Convergence: 0.0918 k= 0.019240 lr = 0.0000051\n",
      "[18/25][820/9765] Loss_D: 0.0965 Loss_G: 0.0368 Convergence: 0.0993 k= 0.019246 lr = 0.0000051\n",
      "[18/25][830/9765] Loss_D: 0.1032 Loss_G: 0.0371 Convergence: 0.1083 k= 0.019259 lr = 0.0000051\n",
      "[18/25][840/9765] Loss_D: 0.0867 Loss_G: 0.0369 Convergence: 0.0893 k= 0.019265 lr = 0.0000051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][850/9765] Loss_D: 0.1000 Loss_G: 0.0363 Convergence: 0.1048 k= 0.019286 lr = 0.0000051\n",
      "[18/25][860/9765] Loss_D: 0.0955 Loss_G: 0.0379 Convergence: 0.0969 k= 0.019286 lr = 0.0000051\n",
      "[18/25][870/9765] Loss_D: 0.0918 Loss_G: 0.0384 Convergence: 0.0939 k= 0.019281 lr = 0.0000051\n",
      "[18/25][880/9765] Loss_D: 0.0851 Loss_G: 0.0417 Convergence: 0.0932 k= 0.019251 lr = 0.0000051\n",
      "[18/25][890/9765] Loss_D: 0.0955 Loss_G: 0.0420 Convergence: 0.0998 k= 0.019242 lr = 0.0000051\n",
      "[18/25][900/9765] Loss_D: 0.1056 Loss_G: 0.0407 Convergence: 0.1082 k= 0.019213 lr = 0.0000051\n",
      "[18/25][910/9765] Loss_D: 0.0942 Loss_G: 0.0409 Convergence: 0.0978 k= 0.019204 lr = 0.0000051\n",
      "[18/25][920/9765] Loss_D: 0.1034 Loss_G: 0.0373 Convergence: 0.1085 k= 0.019200 lr = 0.0000051\n",
      "[18/25][930/9765] Loss_D: 0.1012 Loss_G: 0.0396 Convergence: 0.1031 k= 0.019214 lr = 0.0000051\n",
      "[18/25][940/9765] Loss_D: 0.0886 Loss_G: 0.0365 Convergence: 0.0901 k= 0.019224 lr = 0.0000051\n",
      "[18/25][950/9765] Loss_D: 0.0967 Loss_G: 0.0365 Convergence: 0.0998 k= 0.019247 lr = 0.0000051\n",
      "[18/25][960/9765] Loss_D: 0.0937 Loss_G: 0.0404 Convergence: 0.0971 k= 0.019259 lr = 0.0000051\n",
      "[18/25][970/9765] Loss_D: 0.1056 Loss_G: 0.0394 Convergence: 0.1096 k= 0.019260 lr = 0.0000051\n",
      "[18/25][980/9765] Loss_D: 0.1031 Loss_G: 0.0384 Convergence: 0.1070 k= 0.019241 lr = 0.0000051\n",
      "[18/25][990/9765] Loss_D: 0.0981 Loss_G: 0.0398 Convergence: 0.0991 k= 0.019244 lr = 0.0000051\n",
      "[18/25][1000/9765] Loss_D: 0.0898 Loss_G: 0.0421 Convergence: 0.0965 k= 0.019236 lr = 0.0000051\n",
      "[18/25][1010/9765] Loss_D: 0.0945 Loss_G: 0.0418 Convergence: 0.0990 k= 0.019207 lr = 0.0000051\n",
      "[18/25][1020/9765] Loss_D: 0.0948 Loss_G: 0.0391 Convergence: 0.0964 k= 0.019195 lr = 0.0000051\n",
      "[18/25][1030/9765] Loss_D: 0.0866 Loss_G: 0.0367 Convergence: 0.0891 k= 0.019196 lr = 0.0000051\n",
      "[18/25][1040/9765] Loss_D: 0.0916 Loss_G: 0.0387 Convergence: 0.0941 k= 0.019202 lr = 0.0000051\n",
      "[18/25][1050/9765] Loss_D: 0.0879 Loss_G: 0.0395 Convergence: 0.0927 k= 0.019201 lr = 0.0000051\n",
      "[18/25][1060/9765] Loss_D: 0.0966 Loss_G: 0.0379 Convergence: 0.0984 k= 0.019205 lr = 0.0000051\n",
      "[18/25][1070/9765] Loss_D: 0.0921 Loss_G: 0.0374 Convergence: 0.0931 k= 0.019215 lr = 0.0000051\n",
      "[18/25][1080/9765] Loss_D: 0.1009 Loss_G: 0.0400 Convergence: 0.1023 k= 0.019217 lr = 0.0000051\n",
      "[18/25][1090/9765] Loss_D: 0.0977 Loss_G: 0.0399 Convergence: 0.0989 k= 0.019226 lr = 0.0000051\n",
      "[18/25][1100/9765] Loss_D: 0.0965 Loss_G: 0.0392 Convergence: 0.0975 k= 0.019234 lr = 0.0000051\n",
      "[18/25][1110/9765] Loss_D: 0.0876 Loss_G: 0.0412 Convergence: 0.0943 k= 0.019222 lr = 0.0000051\n",
      "[18/25][1120/9765] Loss_D: 0.0920 Loss_G: 0.0390 Convergence: 0.0947 k= 0.019221 lr = 0.0000051\n",
      "[18/25][1130/9765] Loss_D: 0.0992 Loss_G: 0.0365 Convergence: 0.1033 k= 0.019229 lr = 0.0000051\n",
      "[18/25][1140/9765] Loss_D: 0.0956 Loss_G: 0.0391 Convergence: 0.0969 k= 0.019237 lr = 0.0000051\n",
      "[18/25][1150/9765] Loss_D: 0.0876 Loss_G: 0.0380 Convergence: 0.0910 k= 0.019243 lr = 0.0000051\n",
      "[18/25][1160/9765] Loss_D: 0.0948 Loss_G: 0.0387 Convergence: 0.0961 k= 0.019241 lr = 0.0000051\n",
      "[18/25][1170/9765] Loss_D: 0.0895 Loss_G: 0.0395 Convergence: 0.0937 k= 0.019221 lr = 0.0000051\n",
      "[18/25][1180/9765] Loss_D: 0.0894 Loss_G: 0.0388 Convergence: 0.0929 k= 0.019213 lr = 0.0000051\n",
      "[18/25][1190/9765] Loss_D: 0.1028 Loss_G: 0.0400 Convergence: 0.1050 k= 0.019210 lr = 0.0000051\n",
      "[18/25][1200/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1024 k= 0.019207 lr = 0.0000051\n",
      "[18/25][1210/9765] Loss_D: 0.0904 Loss_G: 0.0395 Convergence: 0.0942 k= 0.019187 lr = 0.0000051\n",
      "[18/25][1220/9765] Loss_D: 0.0971 Loss_G: 0.0394 Convergence: 0.0982 k= 0.019177 lr = 0.0000051\n",
      "[18/25][1230/9765] Loss_D: 0.0900 Loss_G: 0.0374 Convergence: 0.0919 k= 0.019171 lr = 0.0000048\n",
      "[18/25][1240/9765] Loss_D: 0.0926 Loss_G: 0.0392 Convergence: 0.0953 k= 0.019161 lr = 0.0000048\n",
      "[18/25][1250/9765] Loss_D: 0.1037 Loss_G: 0.0392 Convergence: 0.1070 k= 0.019160 lr = 0.0000048\n",
      "[18/25][1260/9765] Loss_D: 0.0967 Loss_G: 0.0380 Convergence: 0.0983 k= 0.019161 lr = 0.0000048\n",
      "[18/25][1270/9765] Loss_D: 0.0883 Loss_G: 0.0398 Convergence: 0.0932 k= 0.019165 lr = 0.0000048\n",
      "[18/25][1280/9765] Loss_D: 0.0984 Loss_G: 0.0367 Convergence: 0.1021 k= 0.019173 lr = 0.0000048\n",
      "[18/25][1290/9765] Loss_D: 0.1034 Loss_G: 0.0371 Convergence: 0.1085 k= 0.019192 lr = 0.0000048\n",
      "[18/25][1300/9765] Loss_D: 0.0898 Loss_G: 0.0372 Convergence: 0.0914 k= 0.019217 lr = 0.0000048\n",
      "[18/25][1310/9765] Loss_D: 0.0989 Loss_G: 0.0385 Convergence: 0.1010 k= 0.019230 lr = 0.0000048\n",
      "[18/25][1320/9765] Loss_D: 0.0908 Loss_G: 0.0390 Convergence: 0.0940 k= 0.019233 lr = 0.0000048\n",
      "[18/25][1330/9765] Loss_D: 0.0911 Loss_G: 0.0373 Convergence: 0.0924 k= 0.019252 lr = 0.0000048\n",
      "[18/25][1340/9765] Loss_D: 0.0940 Loss_G: 0.0382 Convergence: 0.0950 k= 0.019258 lr = 0.0000048\n",
      "[18/25][1350/9765] Loss_D: 0.0932 Loss_G: 0.0392 Convergence: 0.0956 k= 0.019264 lr = 0.0000048\n",
      "[18/25][1360/9765] Loss_D: 0.0967 Loss_G: 0.0372 Convergence: 0.0992 k= 0.019269 lr = 0.0000048\n",
      "[18/25][1370/9765] Loss_D: 0.0858 Loss_G: 0.0385 Convergence: 0.0905 k= 0.019274 lr = 0.0000048\n",
      "[18/25][1380/9765] Loss_D: 0.0906 Loss_G: 0.0393 Convergence: 0.0941 k= 0.019263 lr = 0.0000048\n",
      "[18/25][1390/9765] Loss_D: 0.0988 Loss_G: 0.0409 Convergence: 0.1007 k= 0.019238 lr = 0.0000048\n",
      "[18/25][1400/9765] Loss_D: 0.0930 Loss_G: 0.0411 Convergence: 0.0974 k= 0.019227 lr = 0.0000048\n",
      "[18/25][1410/9765] Loss_D: 0.0821 Loss_G: 0.0380 Convergence: 0.0877 k= 0.019202 lr = 0.0000048\n",
      "[18/25][1420/9765] Loss_D: 0.0855 Loss_G: 0.0377 Convergence: 0.0894 k= 0.019203 lr = 0.0000048\n",
      "[18/25][1430/9765] Loss_D: 0.1045 Loss_G: 0.0383 Convergence: 0.1091 k= 0.019213 lr = 0.0000048\n",
      "[18/25][1440/9765] Loss_D: 0.0946 Loss_G: 0.0397 Convergence: 0.0969 k= 0.019228 lr = 0.0000048\n",
      "[18/25][1450/9765] Loss_D: 0.1094 Loss_G: 0.0383 Convergence: 0.1159 k= 0.019225 lr = 0.0000048\n",
      "[18/25][1460/9765] Loss_D: 0.1065 Loss_G: 0.0389 Convergence: 0.1112 k= 0.019240 lr = 0.0000048\n",
      "[18/25][1470/9765] Loss_D: 0.1006 Loss_G: 0.0393 Convergence: 0.1026 k= 0.019232 lr = 0.0000048\n",
      "[18/25][1480/9765] Loss_D: 0.1007 Loss_G: 0.0406 Convergence: 0.1015 k= 0.019229 lr = 0.0000048\n",
      "[18/25][1490/9765] Loss_D: 0.1007 Loss_G: 0.0393 Convergence: 0.1027 k= 0.019232 lr = 0.0000048\n",
      "[18/25][1500/9765] Loss_D: 0.1034 Loss_G: 0.0397 Convergence: 0.1062 k= 0.019238 lr = 0.0000048\n",
      "[18/25][1510/9765] Loss_D: 0.1013 Loss_G: 0.0411 Convergence: 0.1023 k= 0.019229 lr = 0.0000048\n",
      "[18/25][1520/9765] Loss_D: 0.0932 Loss_G: 0.0394 Convergence: 0.0958 k= 0.019214 lr = 0.0000048\n",
      "[18/25][1530/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.0999 k= 0.019210 lr = 0.0000048\n",
      "[18/25][1540/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0970 k= 0.019192 lr = 0.0000048\n",
      "[18/25][1550/9765] Loss_D: 0.0881 Loss_G: 0.0391 Convergence: 0.0924 k= 0.019189 lr = 0.0000048\n",
      "[18/25][1560/9765] Loss_D: 0.0987 Loss_G: 0.0372 Convergence: 0.1019 k= 0.019188 lr = 0.0000048\n",
      "[18/25][1570/9765] Loss_D: 0.1006 Loss_G: 0.0381 Convergence: 0.1038 k= 0.019194 lr = 0.0000048\n",
      "[18/25][1580/9765] Loss_D: 0.1012 Loss_G: 0.0389 Convergence: 0.1038 k= 0.019209 lr = 0.0000048\n",
      "[18/25][1590/9765] Loss_D: 0.0973 Loss_G: 0.0383 Convergence: 0.0990 k= 0.019207 lr = 0.0000048\n",
      "[18/25][1600/9765] Loss_D: 0.0952 Loss_G: 0.0384 Convergence: 0.0959 k= 0.019220 lr = 0.0000048\n",
      "[18/25][1610/9765] Loss_D: 0.0960 Loss_G: 0.0394 Convergence: 0.0974 k= 0.019220 lr = 0.0000048\n",
      "[18/25][1620/9765] Loss_D: 0.0958 Loss_G: 0.0371 Convergence: 0.0981 k= 0.019234 lr = 0.0000048\n",
      "[18/25][1630/9765] Loss_D: 0.0957 Loss_G: 0.0377 Convergence: 0.0973 k= 0.019234 lr = 0.0000048\n",
      "[18/25][1640/9765] Loss_D: 0.0926 Loss_G: 0.0390 Convergence: 0.0950 k= 0.019222 lr = 0.0000048\n",
      "[18/25][1650/9765] Loss_D: 0.0922 Loss_G: 0.0405 Convergence: 0.0963 k= 0.019235 lr = 0.0000048\n",
      "[18/25][1660/9765] Loss_D: 0.0971 Loss_G: 0.0390 Convergence: 0.0979 k= 0.019243 lr = 0.0000048\n",
      "[18/25][1670/9765] Loss_D: 0.0991 Loss_G: 0.0383 Convergence: 0.1014 k= 0.019246 lr = 0.0000048\n",
      "[18/25][1680/9765] Loss_D: 0.0953 Loss_G: 0.0393 Convergence: 0.0969 k= 0.019255 lr = 0.0000048\n",
      "[18/25][1690/9765] Loss_D: 0.0964 Loss_G: 0.0393 Convergence: 0.0976 k= 0.019239 lr = 0.0000048\n",
      "[18/25][1700/9765] Loss_D: 0.1004 Loss_G: 0.0393 Convergence: 0.1023 k= 0.019246 lr = 0.0000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][1710/9765] Loss_D: 0.0917 Loss_G: 0.0390 Convergence: 0.0945 k= 0.019243 lr = 0.0000048\n",
      "[18/25][1720/9765] Loss_D: 0.0965 Loss_G: 0.0425 Convergence: 0.1009 k= 0.019237 lr = 0.0000048\n",
      "[18/25][1730/9765] Loss_D: 0.0947 Loss_G: 0.0384 Convergence: 0.0957 k= 0.019225 lr = 0.0000048\n",
      "[18/25][1740/9765] Loss_D: 0.1066 Loss_G: 0.0385 Convergence: 0.1118 k= 0.019221 lr = 0.0000048\n",
      "[18/25][1750/9765] Loss_D: 0.0938 Loss_G: 0.0388 Convergence: 0.0955 k= 0.019216 lr = 0.0000048\n",
      "[18/25][1760/9765] Loss_D: 0.0869 Loss_G: 0.0369 Convergence: 0.0894 k= 0.019220 lr = 0.0000048\n",
      "[18/25][1770/9765] Loss_D: 0.1016 Loss_G: 0.0363 Convergence: 0.1070 k= 0.019239 lr = 0.0000048\n",
      "[18/25][1780/9765] Loss_D: 0.0969 Loss_G: 0.0373 Convergence: 0.0994 k= 0.019274 lr = 0.0000048\n",
      "[18/25][1790/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0960 k= 0.019276 lr = 0.0000048\n",
      "[18/25][1800/9765] Loss_D: 0.0854 Loss_G: 0.0377 Convergence: 0.0894 k= 0.019273 lr = 0.0000048\n",
      "[18/25][1810/9765] Loss_D: 0.0859 Loss_G: 0.0363 Convergence: 0.0882 k= 0.019285 lr = 0.0000048\n",
      "[18/25][1820/9765] Loss_D: 0.0867 Loss_G: 0.0372 Convergence: 0.0896 k= 0.019309 lr = 0.0000048\n",
      "[18/25][1830/9765] Loss_D: 0.0911 Loss_G: 0.0389 Convergence: 0.0940 k= 0.019319 lr = 0.0000048\n",
      "[18/25][1840/9765] Loss_D: 0.1066 Loss_G: 0.0413 Convergence: 0.1091 k= 0.019315 lr = 0.0000048\n",
      "[18/25][1850/9765] Loss_D: 0.1027 Loss_G: 0.0415 Convergence: 0.1036 k= 0.019298 lr = 0.0000048\n",
      "[18/25][1860/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0966 k= 0.019271 lr = 0.0000048\n",
      "[18/25][1870/9765] Loss_D: 0.0892 Loss_G: 0.0416 Convergence: 0.0957 k= 0.019247 lr = 0.0000048\n",
      "[18/25][1880/9765] Loss_D: 0.1084 Loss_G: 0.0420 Convergence: 0.1109 k= 0.019221 lr = 0.0000048\n",
      "[18/25][1890/9765] Loss_D: 0.0991 Loss_G: 0.0425 Convergence: 0.1024 k= 0.019191 lr = 0.0000048\n",
      "[18/25][1900/9765] Loss_D: 0.0936 Loss_G: 0.0383 Convergence: 0.0949 k= 0.019173 lr = 0.0000048\n",
      "[18/25][1910/9765] Loss_D: 0.0910 Loss_G: 0.0405 Convergence: 0.0956 k= 0.019176 lr = 0.0000048\n",
      "[18/25][1920/9765] Loss_D: 0.1058 Loss_G: 0.0367 Convergence: 0.1124 k= 0.019181 lr = 0.0000048\n",
      "[18/25][1930/9765] Loss_D: 0.1038 Loss_G: 0.0397 Convergence: 0.1067 k= 0.019192 lr = 0.0000048\n",
      "[18/25][1940/9765] Loss_D: 0.0973 Loss_G: 0.0373 Convergence: 0.1000 k= 0.019191 lr = 0.0000048\n",
      "[18/25][1950/9765] Loss_D: 0.0933 Loss_G: 0.0393 Convergence: 0.0957 k= 0.019201 lr = 0.0000048\n",
      "[18/25][1960/9765] Loss_D: 0.0953 Loss_G: 0.0374 Convergence: 0.0970 k= 0.019213 lr = 0.0000048\n",
      "[18/25][1970/9765] Loss_D: 0.0954 Loss_G: 0.0363 Convergence: 0.0983 k= 0.019219 lr = 0.0000048\n",
      "[18/25][1980/9765] Loss_D: 0.0900 Loss_G: 0.0388 Convergence: 0.0933 k= 0.019229 lr = 0.0000048\n",
      "[18/25][1990/9765] Loss_D: 0.0872 Loss_G: 0.0381 Convergence: 0.0909 k= 0.019216 lr = 0.0000048\n",
      "[18/25][2000/9765] Loss_D: 0.1000 Loss_G: 0.0383 Convergence: 0.1028 k= 0.019210 lr = 0.0000048\n",
      "[18/25][2010/9765] Loss_D: 0.0956 Loss_G: 0.0401 Convergence: 0.0979 k= 0.019203 lr = 0.0000048\n",
      "[18/25][2020/9765] Loss_D: 0.0885 Loss_G: 0.0389 Convergence: 0.0924 k= 0.019191 lr = 0.0000048\n",
      "[18/25][2030/9765] Loss_D: 0.0989 Loss_G: 0.0403 Convergence: 0.1001 k= 0.019193 lr = 0.0000048\n",
      "[18/25][2040/9765] Loss_D: 0.0943 Loss_G: 0.0401 Convergence: 0.0971 k= 0.019173 lr = 0.0000048\n",
      "[18/25][2050/9765] Loss_D: 0.1065 Loss_G: 0.0408 Convergence: 0.1094 k= 0.019179 lr = 0.0000048\n",
      "[18/25][2060/9765] Loss_D: 0.0886 Loss_G: 0.0376 Convergence: 0.0912 k= 0.019173 lr = 0.0000048\n",
      "[18/25][2070/9765] Loss_D: 0.1073 Loss_G: 0.0405 Convergence: 0.1107 k= 0.019171 lr = 0.0000048\n",
      "[18/25][2080/9765] Loss_D: 0.0968 Loss_G: 0.0396 Convergence: 0.0981 k= 0.019163 lr = 0.0000048\n",
      "[18/25][2090/9765] Loss_D: 0.0969 Loss_G: 0.0389 Convergence: 0.0978 k= 0.019170 lr = 0.0000048\n",
      "[18/25][2100/9765] Loss_D: 0.1069 Loss_G: 0.0386 Convergence: 0.1121 k= 0.019178 lr = 0.0000048\n",
      "[18/25][2110/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1018 k= 0.019168 lr = 0.0000048\n",
      "[18/25][2120/9765] Loss_D: 0.0947 Loss_G: 0.0390 Convergence: 0.0963 k= 0.019166 lr = 0.0000048\n",
      "[18/25][2130/9765] Loss_D: 0.1077 Loss_G: 0.0401 Convergence: 0.1118 k= 0.019165 lr = 0.0000048\n",
      "[18/25][2140/9765] Loss_D: 0.0902 Loss_G: 0.0385 Convergence: 0.0931 k= 0.019162 lr = 0.0000048\n",
      "[18/25][2150/9765] Loss_D: 0.1010 Loss_G: 0.0397 Convergence: 0.1027 k= 0.019156 lr = 0.0000048\n",
      "[18/25][2160/9765] Loss_D: 0.0945 Loss_G: 0.0398 Convergence: 0.0969 k= 0.019146 lr = 0.0000048\n",
      "[18/25][2170/9765] Loss_D: 0.1078 Loss_G: 0.0378 Convergence: 0.1141 k= 0.019144 lr = 0.0000048\n",
      "[18/25][2180/9765] Loss_D: 0.0904 Loss_G: 0.0374 Convergence: 0.0921 k= 0.019151 lr = 0.0000048\n",
      "[18/25][2190/9765] Loss_D: 0.0895 Loss_G: 0.0376 Convergence: 0.0917 k= 0.019165 lr = 0.0000048\n",
      "[18/25][2200/9765] Loss_D: 0.0917 Loss_G: 0.0394 Convergence: 0.0949 k= 0.019162 lr = 0.0000048\n",
      "[18/25][2210/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0973 k= 0.019162 lr = 0.0000048\n",
      "[18/25][2220/9765] Loss_D: 0.0969 Loss_G: 0.0369 Convergence: 0.0998 k= 0.019178 lr = 0.0000048\n",
      "[18/25][2230/9765] Loss_D: 0.0999 Loss_G: 0.0371 Convergence: 0.1038 k= 0.019192 lr = 0.0000048\n",
      "[18/25][2240/9765] Loss_D: 0.1024 Loss_G: 0.0374 Convergence: 0.1070 k= 0.019206 lr = 0.0000048\n",
      "[18/25][2250/9765] Loss_D: 0.1003 Loss_G: 0.0386 Convergence: 0.1030 k= 0.019225 lr = 0.0000048\n",
      "[18/25][2260/9765] Loss_D: 0.0974 Loss_G: 0.0382 Convergence: 0.0991 k= 0.019248 lr = 0.0000048\n",
      "[18/25][2270/9765] Loss_D: 0.0930 Loss_G: 0.0388 Convergence: 0.0951 k= 0.019255 lr = 0.0000048\n",
      "[18/25][2280/9765] Loss_D: 0.0955 Loss_G: 0.0382 Convergence: 0.0965 k= 0.019247 lr = 0.0000048\n",
      "[18/25][2290/9765] Loss_D: 0.0856 Loss_G: 0.0380 Convergence: 0.0899 k= 0.019237 lr = 0.0000048\n",
      "[18/25][2300/9765] Loss_D: 0.0854 Loss_G: 0.0393 Convergence: 0.0910 k= 0.019226 lr = 0.0000048\n",
      "[18/25][2310/9765] Loss_D: 0.0972 Loss_G: 0.0403 Convergence: 0.0990 k= 0.019221 lr = 0.0000048\n",
      "[18/25][2320/9765] Loss_D: 0.1004 Loss_G: 0.0404 Convergence: 0.1013 k= 0.019194 lr = 0.0000048\n",
      "[18/25][2330/9765] Loss_D: 0.0897 Loss_G: 0.0396 Convergence: 0.0939 k= 0.019172 lr = 0.0000048\n",
      "[18/25][2340/9765] Loss_D: 0.0916 Loss_G: 0.0373 Convergence: 0.0927 k= 0.019162 lr = 0.0000048\n",
      "[18/25][2350/9765] Loss_D: 0.1009 Loss_G: 0.0380 Convergence: 0.1043 k= 0.019173 lr = 0.0000048\n",
      "[18/25][2360/9765] Loss_D: 0.1054 Loss_G: 0.0399 Convergence: 0.1088 k= 0.019182 lr = 0.0000048\n",
      "[18/25][2370/9765] Loss_D: 0.0949 Loss_G: 0.0372 Convergence: 0.0966 k= 0.019195 lr = 0.0000048\n",
      "[18/25][2380/9765] Loss_D: 0.0923 Loss_G: 0.0365 Convergence: 0.0937 k= 0.019205 lr = 0.0000048\n",
      "[18/25][2390/9765] Loss_D: 0.0989 Loss_G: 0.0388 Convergence: 0.1007 k= 0.019218 lr = 0.0000048\n",
      "[18/25][2400/9765] Loss_D: 0.0922 Loss_G: 0.0406 Convergence: 0.0964 k= 0.019211 lr = 0.0000048\n",
      "[18/25][2410/9765] Loss_D: 0.0989 Loss_G: 0.0405 Convergence: 0.1003 k= 0.019206 lr = 0.0000048\n",
      "[18/25][2420/9765] Loss_D: 0.0935 Loss_G: 0.0408 Convergence: 0.0973 k= 0.019176 lr = 0.0000048\n",
      "[18/25][2430/9765] Loss_D: 0.0997 Loss_G: 0.0418 Convergence: 0.1021 k= 0.019166 lr = 0.0000048\n",
      "[18/25][2440/9765] Loss_D: 0.0905 Loss_G: 0.0429 Convergence: 0.0977 k= 0.019137 lr = 0.0000048\n",
      "[18/25][2450/9765] Loss_D: 0.0904 Loss_G: 0.0394 Convergence: 0.0941 k= 0.019117 lr = 0.0000048\n",
      "[18/25][2460/9765] Loss_D: 0.1048 Loss_G: 0.0395 Convergence: 0.1082 k= 0.019106 lr = 0.0000048\n",
      "[18/25][2470/9765] Loss_D: 0.0971 Loss_G: 0.0408 Convergence: 0.0995 k= 0.019106 lr = 0.0000048\n",
      "[18/25][2480/9765] Loss_D: 0.1036 Loss_G: 0.0375 Convergence: 0.1085 k= 0.019111 lr = 0.0000048\n",
      "[18/25][2490/9765] Loss_D: 0.0977 Loss_G: 0.0384 Convergence: 0.0994 k= 0.019122 lr = 0.0000048\n",
      "[18/25][2500/9765] Loss_D: 0.1012 Loss_G: 0.0388 Convergence: 0.1039 k= 0.019125 lr = 0.0000048\n",
      "[18/25][2510/9765] Loss_D: 0.0929 Loss_G: 0.0393 Convergence: 0.0955 k= 0.019115 lr = 0.0000048\n",
      "[18/25][2520/9765] Loss_D: 0.0924 Loss_G: 0.0394 Convergence: 0.0953 k= 0.019102 lr = 0.0000048\n",
      "[18/25][2530/9765] Loss_D: 0.1017 Loss_G: 0.0380 Convergence: 0.1055 k= 0.019108 lr = 0.0000048\n",
      "[18/25][2540/9765] Loss_D: 0.1054 Loss_G: 0.0383 Convergence: 0.1103 k= 0.019100 lr = 0.0000048\n",
      "[18/25][2550/9765] Loss_D: 0.0981 Loss_G: 0.0390 Convergence: 0.0994 k= 0.019109 lr = 0.0000048\n",
      "[18/25][2560/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0995 k= 0.019097 lr = 0.0000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][2570/9765] Loss_D: 0.0961 Loss_G: 0.0398 Convergence: 0.0979 k= 0.019094 lr = 0.0000048\n",
      "[18/25][2580/9765] Loss_D: 0.1026 Loss_G: 0.0400 Convergence: 0.1048 k= 0.019092 lr = 0.0000048\n",
      "[18/25][2590/9765] Loss_D: 0.0903 Loss_G: 0.0393 Convergence: 0.0939 k= 0.019090 lr = 0.0000048\n",
      "[18/25][2600/9765] Loss_D: 0.1005 Loss_G: 0.0384 Convergence: 0.1034 k= 0.019081 lr = 0.0000048\n",
      "[18/25][2610/9765] Loss_D: 0.0933 Loss_G: 0.0381 Convergence: 0.0945 k= 0.019081 lr = 0.0000048\n",
      "[18/25][2620/9765] Loss_D: 0.0954 Loss_G: 0.0381 Convergence: 0.0964 k= 0.019089 lr = 0.0000048\n",
      "[18/25][2630/9765] Loss_D: 0.0952 Loss_G: 0.0383 Convergence: 0.0961 k= 0.019096 lr = 0.0000048\n",
      "[18/25][2640/9765] Loss_D: 0.0901 Loss_G: 0.0364 Convergence: 0.0909 k= 0.019100 lr = 0.0000048\n",
      "[18/25][2650/9765] Loss_D: 0.0923 Loss_G: 0.0377 Convergence: 0.0935 k= 0.019133 lr = 0.0000048\n",
      "[18/25][2660/9765] Loss_D: 0.0911 Loss_G: 0.0392 Convergence: 0.0943 k= 0.019132 lr = 0.0000048\n",
      "[18/25][2670/9765] Loss_D: 0.0877 Loss_G: 0.0372 Convergence: 0.0902 k= 0.019127 lr = 0.0000048\n",
      "[18/25][2680/9765] Loss_D: 0.0982 Loss_G: 0.0404 Convergence: 0.0998 k= 0.019132 lr = 0.0000048\n",
      "[18/25][2690/9765] Loss_D: 0.1001 Loss_G: 0.0387 Convergence: 0.1024 k= 0.019127 lr = 0.0000048\n",
      "[18/25][2700/9765] Loss_D: 0.0989 Loss_G: 0.0386 Convergence: 0.1009 k= 0.019126 lr = 0.0000048\n",
      "[18/25][2710/9765] Loss_D: 0.0994 Loss_G: 0.0418 Convergence: 0.1019 k= 0.019129 lr = 0.0000048\n",
      "[18/25][2720/9765] Loss_D: 0.0904 Loss_G: 0.0411 Convergence: 0.0958 k= 0.019111 lr = 0.0000048\n",
      "[18/25][2730/9765] Loss_D: 0.0922 Loss_G: 0.0399 Convergence: 0.0957 k= 0.019102 lr = 0.0000048\n",
      "[18/25][2740/9765] Loss_D: 0.0941 Loss_G: 0.0375 Convergence: 0.0952 k= 0.019086 lr = 0.0000048\n",
      "[18/25][2750/9765] Loss_D: 0.0956 Loss_G: 0.0389 Convergence: 0.0967 k= 0.019086 lr = 0.0000048\n",
      "[18/25][2760/9765] Loss_D: 0.0907 Loss_G: 0.0376 Convergence: 0.0925 k= 0.019094 lr = 0.0000048\n",
      "[18/25][2770/9765] Loss_D: 0.0896 Loss_G: 0.0385 Convergence: 0.0927 k= 0.019077 lr = 0.0000048\n",
      "[18/25][2780/9765] Loss_D: 0.0924 Loss_G: 0.0390 Convergence: 0.0949 k= 0.019083 lr = 0.0000048\n",
      "[18/25][2790/9765] Loss_D: 0.1007 Loss_G: 0.0395 Convergence: 0.1025 k= 0.019082 lr = 0.0000048\n",
      "[18/25][2800/9765] Loss_D: 0.0921 Loss_G: 0.0381 Convergence: 0.0938 k= 0.019071 lr = 0.0000048\n",
      "[18/25][2810/9765] Loss_D: 0.0911 Loss_G: 0.0393 Convergence: 0.0944 k= 0.019072 lr = 0.0000048\n",
      "[18/25][2820/9765] Loss_D: 0.0896 Loss_G: 0.0381 Convergence: 0.0923 k= 0.019063 lr = 0.0000048\n",
      "[18/25][2830/9765] Loss_D: 0.0943 Loss_G: 0.0382 Convergence: 0.0952 k= 0.019074 lr = 0.0000048\n",
      "[18/25][2840/9765] Loss_D: 0.1001 Loss_G: 0.0378 Convergence: 0.1034 k= 0.019076 lr = 0.0000048\n",
      "[18/25][2850/9765] Loss_D: 0.0966 Loss_G: 0.0385 Convergence: 0.0977 k= 0.019088 lr = 0.0000048\n",
      "[18/25][2860/9765] Loss_D: 0.1009 Loss_G: 0.0381 Convergence: 0.1042 k= 0.019119 lr = 0.0000048\n",
      "[18/25][2870/9765] Loss_D: 0.1047 Loss_G: 0.0380 Convergence: 0.1096 k= 0.019132 lr = 0.0000048\n",
      "[18/25][2880/9765] Loss_D: 0.0957 Loss_G: 0.0401 Convergence: 0.0979 k= 0.019132 lr = 0.0000048\n",
      "[18/25][2890/9765] Loss_D: 0.0913 Loss_G: 0.0399 Convergence: 0.0951 k= 0.019125 lr = 0.0000048\n",
      "[18/25][2900/9765] Loss_D: 0.0890 Loss_G: 0.0392 Convergence: 0.0930 k= 0.019115 lr = 0.0000048\n",
      "[18/25][2910/9765] Loss_D: 0.0935 Loss_G: 0.0382 Convergence: 0.0947 k= 0.019114 lr = 0.0000048\n",
      "[18/25][2920/9765] Loss_D: 0.0882 Loss_G: 0.0389 Convergence: 0.0923 k= 0.019109 lr = 0.0000048\n",
      "[18/25][2930/9765] Loss_D: 0.0990 Loss_G: 0.0396 Convergence: 0.1001 k= 0.019115 lr = 0.0000048\n",
      "[18/25][2940/9765] Loss_D: 0.0964 Loss_G: 0.0398 Convergence: 0.0981 k= 0.019106 lr = 0.0000048\n",
      "[18/25][2950/9765] Loss_D: 0.0921 Loss_G: 0.0403 Convergence: 0.0960 k= 0.019092 lr = 0.0000048\n",
      "[18/25][2960/9765] Loss_D: 0.0991 Loss_G: 0.0408 Convergence: 0.1007 k= 0.019078 lr = 0.0000048\n",
      "[18/25][2970/9765] Loss_D: 0.1012 Loss_G: 0.0391 Convergence: 0.1035 k= 0.019063 lr = 0.0000048\n",
      "[18/25][2980/9765] Loss_D: 0.1005 Loss_G: 0.0395 Convergence: 0.1022 k= 0.019065 lr = 0.0000048\n",
      "[18/25][2990/9765] Loss_D: 0.0892 Loss_G: 0.0399 Convergence: 0.0939 k= 0.019058 lr = 0.0000048\n",
      "[18/25][3000/9765] Loss_D: 0.0861 Loss_G: 0.0396 Convergence: 0.0917 k= 0.019059 lr = 0.0000048\n",
      "[18/25][3010/9765] Loss_D: 0.1052 Loss_G: 0.0391 Convergence: 0.1092 k= 0.019053 lr = 0.0000048\n",
      "[18/25][3020/9765] Loss_D: 0.0905 Loss_G: 0.0362 Convergence: 0.0914 k= 0.019067 lr = 0.0000048\n",
      "[18/25][3030/9765] Loss_D: 0.1015 Loss_G: 0.0377 Convergence: 0.1054 k= 0.019089 lr = 0.0000048\n",
      "[18/25][3040/9765] Loss_D: 0.0964 Loss_G: 0.0385 Convergence: 0.0974 k= 0.019099 lr = 0.0000048\n",
      "[18/25][3050/9765] Loss_D: 0.0975 Loss_G: 0.0403 Convergence: 0.0993 k= 0.019102 lr = 0.0000048\n",
      "[18/25][3060/9765] Loss_D: 0.1000 Loss_G: 0.0395 Convergence: 0.1016 k= 0.019113 lr = 0.0000048\n",
      "[18/25][3070/9765] Loss_D: 0.0912 Loss_G: 0.0393 Convergence: 0.0945 k= 0.019088 lr = 0.0000048\n",
      "[18/25][3080/9765] Loss_D: 0.0968 Loss_G: 0.0413 Convergence: 0.0999 k= 0.019070 lr = 0.0000048\n",
      "[18/25][3090/9765] Loss_D: 0.0966 Loss_G: 0.0398 Convergence: 0.0982 k= 0.019059 lr = 0.0000048\n",
      "[18/25][3100/9765] Loss_D: 0.0941 Loss_G: 0.0393 Convergence: 0.0962 k= 0.019051 lr = 0.0000048\n",
      "[18/25][3110/9765] Loss_D: 0.0932 Loss_G: 0.0397 Convergence: 0.0961 k= 0.019046 lr = 0.0000048\n",
      "[18/25][3120/9765] Loss_D: 0.0992 Loss_G: 0.0396 Convergence: 0.1003 k= 0.019055 lr = 0.0000048\n",
      "[18/25][3130/9765] Loss_D: 0.1071 Loss_G: 0.0404 Convergence: 0.1107 k= 0.019062 lr = 0.0000048\n",
      "[18/25][3140/9765] Loss_D: 0.1005 Loss_G: 0.0372 Convergence: 0.1045 k= 0.019067 lr = 0.0000048\n",
      "[18/25][3150/9765] Loss_D: 0.0908 Loss_G: 0.0370 Convergence: 0.0919 k= 0.019070 lr = 0.0000048\n",
      "[18/25][3160/9765] Loss_D: 0.0935 Loss_G: 0.0384 Convergence: 0.0949 k= 0.019086 lr = 0.0000048\n",
      "[18/25][3170/9765] Loss_D: 0.0946 Loss_G: 0.0391 Convergence: 0.0963 k= 0.019083 lr = 0.0000048\n",
      "[18/25][3180/9765] Loss_D: 0.0976 Loss_G: 0.0394 Convergence: 0.0984 k= 0.019088 lr = 0.0000048\n",
      "[18/25][3190/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0972 k= 0.019098 lr = 0.0000048\n",
      "[18/25][3200/9765] Loss_D: 0.0883 Loss_G: 0.0392 Convergence: 0.0926 k= 0.019101 lr = 0.0000048\n",
      "[18/25][3210/9765] Loss_D: 0.0930 Loss_G: 0.0386 Convergence: 0.0949 k= 0.019096 lr = 0.0000048\n",
      "[18/25][3220/9765] Loss_D: 0.1003 Loss_G: 0.0377 Convergence: 0.1037 k= 0.019095 lr = 0.0000048\n",
      "[18/25][3230/9765] Loss_D: 0.0953 Loss_G: 0.0391 Convergence: 0.0967 k= 0.019118 lr = 0.0000048\n",
      "[18/25][3240/9765] Loss_D: 0.0980 Loss_G: 0.0411 Convergence: 0.1004 k= 0.019097 lr = 0.0000048\n",
      "[18/25][3250/9765] Loss_D: 0.1036 Loss_G: 0.0384 Convergence: 0.1077 k= 0.019092 lr = 0.0000048\n",
      "[18/25][3260/9765] Loss_D: 0.0948 Loss_G: 0.0384 Convergence: 0.0957 k= 0.019080 lr = 0.0000048\n",
      "[18/25][3270/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0992 k= 0.019097 lr = 0.0000048\n",
      "[18/25][3280/9765] Loss_D: 0.1018 Loss_G: 0.0389 Convergence: 0.1047 k= 0.019092 lr = 0.0000048\n",
      "[18/25][3290/9765] Loss_D: 0.0950 Loss_G: 0.0391 Convergence: 0.0965 k= 0.019081 lr = 0.0000048\n",
      "[18/25][3300/9765] Loss_D: 0.0984 Loss_G: 0.0374 Convergence: 0.1013 k= 0.019084 lr = 0.0000048\n",
      "[18/25][3310/9765] Loss_D: 0.0921 Loss_G: 0.0374 Convergence: 0.0931 k= 0.019092 lr = 0.0000048\n",
      "[18/25][3320/9765] Loss_D: 0.0985 Loss_G: 0.0398 Convergence: 0.0993 k= 0.019108 lr = 0.0000048\n",
      "[18/25][3330/9765] Loss_D: 0.1008 Loss_G: 0.0371 Convergence: 0.1050 k= 0.019120 lr = 0.0000048\n",
      "[18/25][3340/9765] Loss_D: 0.0971 Loss_G: 0.0388 Convergence: 0.0981 k= 0.019140 lr = 0.0000048\n",
      "[18/25][3350/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0969 k= 0.019147 lr = 0.0000048\n",
      "[18/25][3360/9765] Loss_D: 0.0978 Loss_G: 0.0391 Convergence: 0.0988 k= 0.019139 lr = 0.0000048\n",
      "[18/25][3370/9765] Loss_D: 0.1001 Loss_G: 0.0395 Convergence: 0.1017 k= 0.019125 lr = 0.0000048\n",
      "[18/25][3380/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1008 k= 0.019102 lr = 0.0000048\n",
      "[18/25][3390/9765] Loss_D: 0.0815 Loss_G: 0.0417 Convergence: 0.0910 k= 0.019079 lr = 0.0000048\n",
      "[18/25][3400/9765] Loss_D: 0.0996 Loss_G: 0.0411 Convergence: 0.1013 k= 0.019048 lr = 0.0000048\n",
      "[18/25][3410/9765] Loss_D: 0.0944 Loss_G: 0.0407 Convergence: 0.0978 k= 0.019028 lr = 0.0000048\n",
      "[18/25][3420/9765] Loss_D: 0.0922 Loss_G: 0.0380 Convergence: 0.0938 k= 0.019019 lr = 0.0000048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][3430/9765] Loss_D: 0.0965 Loss_G: 0.0394 Convergence: 0.0977 k= 0.019029 lr = 0.0000048\n",
      "[18/25][3440/9765] Loss_D: 0.0981 Loss_G: 0.0380 Convergence: 0.1004 k= 0.019031 lr = 0.0000048\n",
      "[18/25][3450/9765] Loss_D: 0.0920 Loss_G: 0.0373 Convergence: 0.0930 k= 0.019043 lr = 0.0000048\n",
      "[18/25][3460/9765] Loss_D: 0.0989 Loss_G: 0.0377 Convergence: 0.1017 k= 0.019055 lr = 0.0000048\n",
      "[18/25][3470/9765] Loss_D: 0.0905 Loss_G: 0.0372 Convergence: 0.0919 k= 0.019074 lr = 0.0000048\n",
      "[18/25][3480/9765] Loss_D: 0.0953 Loss_G: 0.0362 Convergence: 0.0983 k= 0.019082 lr = 0.0000048\n",
      "[18/25][3490/9765] Loss_D: 0.1006 Loss_G: 0.0390 Convergence: 0.1028 k= 0.019109 lr = 0.0000048\n",
      "[18/25][3500/9765] Loss_D: 0.0933 Loss_G: 0.0390 Convergence: 0.0954 k= 0.019104 lr = 0.0000048\n",
      "[18/25][3510/9765] Loss_D: 0.0951 Loss_G: 0.0391 Convergence: 0.0966 k= 0.019120 lr = 0.0000048\n",
      "[18/25][3520/9765] Loss_D: 0.1000 Loss_G: 0.0406 Convergence: 0.1010 k= 0.019108 lr = 0.0000048\n",
      "[18/25][3530/9765] Loss_D: 0.0960 Loss_G: 0.0370 Convergence: 0.0984 k= 0.019095 lr = 0.0000048\n",
      "[18/25][3540/9765] Loss_D: 0.1017 Loss_G: 0.0396 Convergence: 0.1039 k= 0.019112 lr = 0.0000048\n",
      "[18/25][3550/9765] Loss_D: 0.0926 Loss_G: 0.0384 Convergence: 0.0944 k= 0.019105 lr = 0.0000048\n",
      "[18/25][3560/9765] Loss_D: 0.0949 Loss_G: 0.0383 Convergence: 0.0957 k= 0.019110 lr = 0.0000048\n",
      "[18/25][3570/9765] Loss_D: 0.0942 Loss_G: 0.0382 Convergence: 0.0952 k= 0.019116 lr = 0.0000048\n",
      "[18/25][3580/9765] Loss_D: 0.0902 Loss_G: 0.0372 Convergence: 0.0917 k= 0.019108 lr = 0.0000048\n",
      "[18/25][3590/9765] Loss_D: 0.1041 Loss_G: 0.0384 Convergence: 0.1084 k= 0.019113 lr = 0.0000048\n",
      "[18/25][3600/9765] Loss_D: 0.0960 Loss_G: 0.0405 Convergence: 0.0985 k= 0.019099 lr = 0.0000048\n",
      "[18/25][3610/9765] Loss_D: 0.1078 Loss_G: 0.0393 Convergence: 0.1126 k= 0.019100 lr = 0.0000048\n",
      "[18/25][3620/9765] Loss_D: 0.1054 Loss_G: 0.0401 Convergence: 0.1086 k= 0.019096 lr = 0.0000048\n",
      "[18/25][3630/9765] Loss_D: 0.0937 Loss_G: 0.0379 Convergence: 0.0945 k= 0.019094 lr = 0.0000048\n",
      "[18/25][3640/9765] Loss_D: 0.0929 Loss_G: 0.0367 Convergence: 0.0943 k= 0.019106 lr = 0.0000048\n",
      "[18/25][3650/9765] Loss_D: 0.1007 Loss_G: 0.0390 Convergence: 0.1030 k= 0.019118 lr = 0.0000048\n",
      "[18/25][3660/9765] Loss_D: 0.0884 Loss_G: 0.0376 Convergence: 0.0911 k= 0.019127 lr = 0.0000048\n",
      "[18/25][3670/9765] Loss_D: 0.1040 Loss_G: 0.0385 Convergence: 0.1081 k= 0.019127 lr = 0.0000048\n",
      "[18/25][3680/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0960 k= 0.019129 lr = 0.0000048\n",
      "[18/25][3690/9765] Loss_D: 0.1016 Loss_G: 0.0384 Convergence: 0.1048 k= 0.019133 lr = 0.0000048\n",
      "[18/25][3700/9765] Loss_D: 0.0948 Loss_G: 0.0379 Convergence: 0.0959 k= 0.019129 lr = 0.0000048\n",
      "[18/25][3710/9765] Loss_D: 0.1010 Loss_G: 0.0409 Convergence: 0.1020 k= 0.019128 lr = 0.0000048\n",
      "[18/25][3720/9765] Loss_D: 0.0827 Loss_G: 0.0380 Convergence: 0.0881 k= 0.019112 lr = 0.0000048\n",
      "[18/25][3730/9765] Loss_D: 0.1024 Loss_G: 0.0366 Convergence: 0.1077 k= 0.019131 lr = 0.0000048\n",
      "[18/25][3740/9765] Loss_D: 0.1000 Loss_G: 0.0369 Convergence: 0.1041 k= 0.019148 lr = 0.0000048\n",
      "[18/25][3750/9765] Loss_D: 0.1014 Loss_G: 0.0380 Convergence: 0.1051 k= 0.019165 lr = 0.0000048\n",
      "[18/25][3760/9765] Loss_D: 0.0903 Loss_G: 0.0359 Convergence: 0.0915 k= 0.019190 lr = 0.0000048\n",
      "[18/25][3770/9765] Loss_D: 0.1002 Loss_G: 0.0365 Convergence: 0.1047 k= 0.019218 lr = 0.0000048\n",
      "[18/25][3780/9765] Loss_D: 0.0897 Loss_G: 0.0358 Convergence: 0.0908 k= 0.019221 lr = 0.0000048\n",
      "[18/25][3790/9765] Loss_D: 0.0969 Loss_G: 0.0379 Convergence: 0.0987 k= 0.019229 lr = 0.0000048\n",
      "[18/25][3800/9765] Loss_D: 0.1057 Loss_G: 0.0378 Convergence: 0.1112 k= 0.019230 lr = 0.0000048\n",
      "[18/25][3810/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0992 k= 0.019236 lr = 0.0000048\n",
      "[18/25][3820/9765] Loss_D: 0.0955 Loss_G: 0.0404 Convergence: 0.0982 k= 0.019230 lr = 0.0000048\n",
      "[18/25][3830/9765] Loss_D: 0.0849 Loss_G: 0.0384 Convergence: 0.0898 k= 0.019211 lr = 0.0000048\n",
      "[18/25][3840/9765] Loss_D: 0.1058 Loss_G: 0.0378 Convergence: 0.1113 k= 0.019215 lr = 0.0000048\n",
      "[18/25][3850/9765] Loss_D: 0.0891 Loss_G: 0.0369 Convergence: 0.0908 k= 0.019224 lr = 0.0000048\n",
      "[18/25][3860/9765] Loss_D: 0.0967 Loss_G: 0.0387 Convergence: 0.0977 k= 0.019232 lr = 0.0000048\n",
      "[18/25][3870/9765] Loss_D: 0.0939 Loss_G: 0.0385 Convergence: 0.0953 k= 0.019222 lr = 0.0000048\n",
      "[18/25][3880/9765] Loss_D: 0.0920 Loss_G: 0.0398 Convergence: 0.0955 k= 0.019202 lr = 0.0000048\n",
      "[18/25][3890/9765] Loss_D: 0.0932 Loss_G: 0.0390 Convergence: 0.0954 k= 0.019205 lr = 0.0000048\n",
      "[18/25][3900/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1056 k= 0.019213 lr = 0.0000048\n",
      "[18/25][3910/9765] Loss_D: 0.0948 Loss_G: 0.0391 Convergence: 0.0964 k= 0.019213 lr = 0.0000048\n",
      "[18/25][3920/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1011 k= 0.019207 lr = 0.0000048\n",
      "[18/25][3930/9765] Loss_D: 0.0922 Loss_G: 0.0382 Convergence: 0.0939 k= 0.019216 lr = 0.0000048\n",
      "[18/25][3940/9765] Loss_D: 0.0934 Loss_G: 0.0393 Convergence: 0.0959 k= 0.019201 lr = 0.0000048\n",
      "[18/25][3950/9765] Loss_D: 0.1061 Loss_G: 0.0384 Convergence: 0.1111 k= 0.019213 lr = 0.0000048\n",
      "[18/25][3960/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0942 k= 0.019229 lr = 0.0000048\n",
      "[18/25][3970/9765] Loss_D: 0.1019 Loss_G: 0.0393 Convergence: 0.1044 k= 0.019244 lr = 0.0000048\n",
      "[18/25][3980/9765] Loss_D: 0.0913 Loss_G: 0.0372 Convergence: 0.0924 k= 0.019239 lr = 0.0000048\n",
      "[18/25][3990/9765] Loss_D: 0.0928 Loss_G: 0.0375 Convergence: 0.0937 k= 0.019246 lr = 0.0000048\n",
      "[18/25][4000/9765] Loss_D: 0.0924 Loss_G: 0.0387 Convergence: 0.0946 k= 0.019251 lr = 0.0000048\n",
      "[18/25][4010/9765] Loss_D: 0.0909 Loss_G: 0.0377 Convergence: 0.0927 k= 0.019259 lr = 0.0000048\n",
      "[18/25][4020/9765] Loss_D: 0.0963 Loss_G: 0.0365 Convergence: 0.0993 k= 0.019266 lr = 0.0000048\n",
      "[18/25][4030/9765] Loss_D: 0.0923 Loss_G: 0.0371 Convergence: 0.0931 k= 0.019281 lr = 0.0000048\n",
      "[18/25][4040/9765] Loss_D: 0.1164 Loss_G: 0.0366 Convergence: 0.1273 k= 0.019303 lr = 0.0000048\n",
      "[18/25][4050/9765] Loss_D: 0.0952 Loss_G: 0.0385 Convergence: 0.0961 k= 0.019314 lr = 0.0000048\n",
      "[18/25][4060/9765] Loss_D: 0.1000 Loss_G: 0.0388 Convergence: 0.1022 k= 0.019316 lr = 0.0000048\n",
      "[18/25][4070/9765] Loss_D: 0.0915 Loss_G: 0.0373 Convergence: 0.0926 k= 0.019311 lr = 0.0000048\n",
      "[18/25][4080/9765] Loss_D: 0.1003 Loss_G: 0.0392 Convergence: 0.1022 k= 0.019322 lr = 0.0000048\n",
      "[18/25][4090/9765] Loss_D: 0.0930 Loss_G: 0.0395 Convergence: 0.0958 k= 0.019317 lr = 0.0000048\n",
      "[18/25][4100/9765] Loss_D: 0.0907 Loss_G: 0.0382 Convergence: 0.0931 k= 0.019314 lr = 0.0000048\n",
      "[18/25][4110/9765] Loss_D: 0.0901 Loss_G: 0.0379 Convergence: 0.0924 k= 0.019310 lr = 0.0000048\n",
      "[18/25][4120/9765] Loss_D: 0.0969 Loss_G: 0.0400 Convergence: 0.0986 k= 0.019311 lr = 0.0000048\n",
      "[18/25][4130/9765] Loss_D: 0.1001 Loss_G: 0.0386 Convergence: 0.1026 k= 0.019316 lr = 0.0000048\n",
      "[18/25][4140/9765] Loss_D: 0.0910 Loss_G: 0.0396 Convergence: 0.0946 k= 0.019309 lr = 0.0000048\n",
      "[18/25][4150/9765] Loss_D: 0.0911 Loss_G: 0.0388 Convergence: 0.0940 k= 0.019303 lr = 0.0000048\n",
      "[18/25][4160/9765] Loss_D: 0.1014 Loss_G: 0.0395 Convergence: 0.1034 k= 0.019310 lr = 0.0000048\n",
      "[18/25][4170/9765] Loss_D: 0.0966 Loss_G: 0.0382 Convergence: 0.0981 k= 0.019316 lr = 0.0000048\n",
      "[18/25][4180/9765] Loss_D: 0.0934 Loss_G: 0.0380 Convergence: 0.0945 k= 0.019323 lr = 0.0000048\n",
      "[18/25][4190/9765] Loss_D: 0.0935 Loss_G: 0.0373 Convergence: 0.0947 k= 0.019331 lr = 0.0000048\n",
      "[18/25][4200/9765] Loss_D: 0.0923 Loss_G: 0.0393 Convergence: 0.0952 k= 0.019342 lr = 0.0000048\n",
      "[18/25][4210/9765] Loss_D: 0.0987 Loss_G: 0.0385 Convergence: 0.1007 k= 0.019336 lr = 0.0000048\n",
      "[18/25][4220/9765] Loss_D: 0.0963 Loss_G: 0.0397 Convergence: 0.0980 k= 0.019321 lr = 0.0000048\n",
      "[18/25][4230/9765] Loss_D: 0.0969 Loss_G: 0.0423 Convergence: 0.1010 k= 0.019310 lr = 0.0000046\n",
      "[18/25][4240/9765] Loss_D: 0.1005 Loss_G: 0.0407 Convergence: 0.1014 k= 0.019286 lr = 0.0000046\n",
      "[18/25][4250/9765] Loss_D: 0.0873 Loss_G: 0.0389 Convergence: 0.0917 k= 0.019257 lr = 0.0000046\n",
      "[18/25][4260/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0968 k= 0.019255 lr = 0.0000046\n",
      "[18/25][4270/9765] Loss_D: 0.1022 Loss_G: 0.0388 Convergence: 0.1053 k= 0.019253 lr = 0.0000046\n",
      "[18/25][4280/9765] Loss_D: 0.0919 Loss_G: 0.0378 Convergence: 0.0934 k= 0.019254 lr = 0.0000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][4290/9765] Loss_D: 0.0934 Loss_G: 0.0393 Convergence: 0.0958 k= 0.019268 lr = 0.0000046\n",
      "[18/25][4300/9765] Loss_D: 0.0992 Loss_G: 0.0377 Convergence: 0.1022 k= 0.019284 lr = 0.0000046\n",
      "[18/25][4310/9765] Loss_D: 0.0943 Loss_G: 0.0381 Convergence: 0.0951 k= 0.019286 lr = 0.0000046\n",
      "[18/25][4320/9765] Loss_D: 0.0973 Loss_G: 0.0372 Convergence: 0.1000 k= 0.019308 lr = 0.0000046\n",
      "[18/25][4330/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0980 k= 0.019319 lr = 0.0000046\n",
      "[18/25][4340/9765] Loss_D: 0.0906 Loss_G: 0.0372 Convergence: 0.0920 k= 0.019328 lr = 0.0000046\n",
      "[18/25][4350/9765] Loss_D: 0.1024 Loss_G: 0.0386 Convergence: 0.1058 k= 0.019333 lr = 0.0000046\n",
      "[18/25][4360/9765] Loss_D: 0.0979 Loss_G: 0.0380 Convergence: 0.1000 k= 0.019338 lr = 0.0000046\n",
      "[18/25][4370/9765] Loss_D: 0.1054 Loss_G: 0.0406 Convergence: 0.1080 k= 0.019337 lr = 0.0000046\n",
      "[18/25][4380/9765] Loss_D: 0.0883 Loss_G: 0.0397 Convergence: 0.0931 k= 0.019316 lr = 0.0000046\n",
      "[18/25][4390/9765] Loss_D: 0.1015 Loss_G: 0.0392 Convergence: 0.1039 k= 0.019313 lr = 0.0000046\n",
      "[18/25][4400/9765] Loss_D: 0.0861 Loss_G: 0.0395 Convergence: 0.0917 k= 0.019297 lr = 0.0000046\n",
      "[18/25][4410/9765] Loss_D: 0.0896 Loss_G: 0.0397 Convergence: 0.0940 k= 0.019294 lr = 0.0000046\n",
      "[18/25][4420/9765] Loss_D: 0.1048 Loss_G: 0.0405 Convergence: 0.1072 k= 0.019292 lr = 0.0000046\n",
      "[18/25][4430/9765] Loss_D: 0.0936 Loss_G: 0.0416 Convergence: 0.0982 k= 0.019281 lr = 0.0000046\n",
      "[18/25][4440/9765] Loss_D: 0.1009 Loss_G: 0.0412 Convergence: 0.1022 k= 0.019258 lr = 0.0000046\n",
      "[18/25][4450/9765] Loss_D: 0.0954 Loss_G: 0.0404 Convergence: 0.0981 k= 0.019244 lr = 0.0000046\n",
      "[18/25][4460/9765] Loss_D: 0.1015 Loss_G: 0.0404 Convergence: 0.1027 k= 0.019232 lr = 0.0000046\n",
      "[18/25][4470/9765] Loss_D: 0.0948 Loss_G: 0.0389 Convergence: 0.0963 k= 0.019230 lr = 0.0000046\n",
      "[18/25][4480/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1025 k= 0.019231 lr = 0.0000046\n",
      "[18/25][4490/9765] Loss_D: 0.1017 Loss_G: 0.0401 Convergence: 0.1034 k= 0.019227 lr = 0.0000046\n",
      "[18/25][4500/9765] Loss_D: 0.0989 Loss_G: 0.0421 Convergence: 0.1019 k= 0.019213 lr = 0.0000046\n",
      "[18/25][4510/9765] Loss_D: 0.0923 Loss_G: 0.0401 Convergence: 0.0959 k= 0.019197 lr = 0.0000046\n",
      "[18/25][4520/9765] Loss_D: 0.0960 Loss_G: 0.0405 Convergence: 0.0985 k= 0.019196 lr = 0.0000046\n",
      "[18/25][4530/9765] Loss_D: 0.0981 Loss_G: 0.0393 Convergence: 0.0991 k= 0.019190 lr = 0.0000046\n",
      "[18/25][4540/9765] Loss_D: 0.1040 Loss_G: 0.0395 Convergence: 0.1072 k= 0.019180 lr = 0.0000046\n",
      "[18/25][4550/9765] Loss_D: 0.0980 Loss_G: 0.0387 Convergence: 0.0995 k= 0.019186 lr = 0.0000046\n",
      "[18/25][4560/9765] Loss_D: 0.0898 Loss_G: 0.0403 Convergence: 0.0946 k= 0.019182 lr = 0.0000046\n",
      "[18/25][4570/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0966 k= 0.019178 lr = 0.0000046\n",
      "[18/25][4580/9765] Loss_D: 0.1022 Loss_G: 0.0385 Convergence: 0.1055 k= 0.019196 lr = 0.0000046\n",
      "[18/25][4590/9765] Loss_D: 0.0946 Loss_G: 0.0388 Convergence: 0.0960 k= 0.019198 lr = 0.0000046\n",
      "[18/25][4600/9765] Loss_D: 0.0895 Loss_G: 0.0391 Convergence: 0.0932 k= 0.019197 lr = 0.0000046\n",
      "[18/25][4610/9765] Loss_D: 0.0959 Loss_G: 0.0392 Convergence: 0.0972 k= 0.019200 lr = 0.0000046\n",
      "[18/25][4620/9765] Loss_D: 0.0969 Loss_G: 0.0401 Convergence: 0.0987 k= 0.019215 lr = 0.0000046\n",
      "[18/25][4630/9765] Loss_D: 0.0973 Loss_G: 0.0390 Convergence: 0.0983 k= 0.019213 lr = 0.0000046\n",
      "[18/25][4640/9765] Loss_D: 0.0939 Loss_G: 0.0368 Convergence: 0.0956 k= 0.019219 lr = 0.0000046\n",
      "[18/25][4650/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0964 k= 0.019223 lr = 0.0000046\n",
      "[18/25][4660/9765] Loss_D: 0.1053 Loss_G: 0.0385 Convergence: 0.1099 k= 0.019227 lr = 0.0000046\n",
      "[18/25][4670/9765] Loss_D: 0.0834 Loss_G: 0.0378 Convergence: 0.0883 k= 0.019209 lr = 0.0000046\n",
      "[18/25][4680/9765] Loss_D: 0.0954 Loss_G: 0.0370 Convergence: 0.0976 k= 0.019226 lr = 0.0000046\n",
      "[18/25][4690/9765] Loss_D: 0.0947 Loss_G: 0.0381 Convergence: 0.0955 k= 0.019241 lr = 0.0000046\n",
      "[18/25][4700/9765] Loss_D: 0.0930 Loss_G: 0.0394 Convergence: 0.0956 k= 0.019249 lr = 0.0000046\n",
      "[18/25][4710/9765] Loss_D: 0.1029 Loss_G: 0.0381 Convergence: 0.1070 k= 0.019247 lr = 0.0000046\n",
      "[18/25][4720/9765] Loss_D: 0.1019 Loss_G: 0.0388 Convergence: 0.1049 k= 0.019253 lr = 0.0000046\n",
      "[18/25][4730/9765] Loss_D: 0.0965 Loss_G: 0.0394 Convergence: 0.0978 k= 0.019261 lr = 0.0000046\n",
      "[18/25][4740/9765] Loss_D: 0.1012 Loss_G: 0.0391 Convergence: 0.1037 k= 0.019257 lr = 0.0000046\n",
      "[18/25][4750/9765] Loss_D: 0.0895 Loss_G: 0.0383 Convergence: 0.0925 k= 0.019256 lr = 0.0000046\n",
      "[18/25][4760/9765] Loss_D: 0.0942 Loss_G: 0.0381 Convergence: 0.0950 k= 0.019263 lr = 0.0000046\n",
      "[18/25][4770/9765] Loss_D: 0.0992 Loss_G: 0.0388 Convergence: 0.1011 k= 0.019260 lr = 0.0000046\n",
      "[18/25][4780/9765] Loss_D: 0.0973 Loss_G: 0.0368 Convergence: 0.1004 k= 0.019278 lr = 0.0000046\n",
      "[18/25][4790/9765] Loss_D: 0.0977 Loss_G: 0.0376 Convergence: 0.1002 k= 0.019301 lr = 0.0000046\n",
      "[18/25][4800/9765] Loss_D: 0.0995 Loss_G: 0.0385 Convergence: 0.1018 k= 0.019316 lr = 0.0000046\n",
      "[18/25][4810/9765] Loss_D: 0.0968 Loss_G: 0.0386 Convergence: 0.0979 k= 0.019323 lr = 0.0000046\n",
      "[18/25][4820/9765] Loss_D: 0.1078 Loss_G: 0.0393 Convergence: 0.1127 k= 0.019334 lr = 0.0000046\n",
      "[18/25][4830/9765] Loss_D: 0.0998 Loss_G: 0.0399 Convergence: 0.1009 k= 0.019337 lr = 0.0000046\n",
      "[18/25][4840/9765] Loss_D: 0.1014 Loss_G: 0.0403 Convergence: 0.1027 k= 0.019333 lr = 0.0000046\n",
      "[18/25][4850/9765] Loss_D: 0.0935 Loss_G: 0.0422 Convergence: 0.0988 k= 0.019308 lr = 0.0000046\n",
      "[18/25][4860/9765] Loss_D: 0.1021 Loss_G: 0.0414 Convergence: 0.1032 k= 0.019292 lr = 0.0000046\n",
      "[18/25][4870/9765] Loss_D: 0.0879 Loss_G: 0.0430 Convergence: 0.0962 k= 0.019260 lr = 0.0000046\n",
      "[18/25][4880/9765] Loss_D: 0.0928 Loss_G: 0.0414 Convergence: 0.0975 k= 0.019219 lr = 0.0000046\n",
      "[18/25][4890/9765] Loss_D: 0.0902 Loss_G: 0.0422 Convergence: 0.0968 k= 0.019188 lr = 0.0000046\n",
      "[18/25][4900/9765] Loss_D: 0.0938 Loss_G: 0.0401 Convergence: 0.0969 k= 0.019148 lr = 0.0000046\n",
      "[18/25][4910/9765] Loss_D: 0.1053 Loss_G: 0.0391 Convergence: 0.1093 k= 0.019136 lr = 0.0000046\n",
      "[18/25][4920/9765] Loss_D: 0.0970 Loss_G: 0.0396 Convergence: 0.0983 k= 0.019143 lr = 0.0000046\n",
      "[18/25][4930/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0964 k= 0.019154 lr = 0.0000046\n",
      "[18/25][4940/9765] Loss_D: 0.1023 Loss_G: 0.0380 Convergence: 0.1062 k= 0.019165 lr = 0.0000046\n",
      "[18/25][4950/9765] Loss_D: 0.0943 Loss_G: 0.0348 Convergence: 0.0981 k= 0.019188 lr = 0.0000046\n",
      "[18/25][4960/9765] Loss_D: 0.0900 Loss_G: 0.0369 Convergence: 0.0913 k= 0.019211 lr = 0.0000046\n",
      "[18/25][4970/9765] Loss_D: 0.1019 Loss_G: 0.0365 Convergence: 0.1072 k= 0.019243 lr = 0.0000046\n",
      "[18/25][4980/9765] Loss_D: 0.1004 Loss_G: 0.0362 Convergence: 0.1054 k= 0.019271 lr = 0.0000046\n",
      "[18/25][4990/9765] Loss_D: 0.0951 Loss_G: 0.0362 Convergence: 0.0979 k= 0.019289 lr = 0.0000046\n",
      "[18/25][5000/9765] Loss_D: 0.0977 Loss_G: 0.0368 Convergence: 0.1009 k= 0.019311 lr = 0.0000046\n",
      "[18/25][5010/9765] Loss_D: 0.0968 Loss_G: 0.0386 Convergence: 0.0979 k= 0.019326 lr = 0.0000046\n",
      "[18/25][5020/9765] Loss_D: 0.0925 Loss_G: 0.0409 Convergence: 0.0968 k= 0.019315 lr = 0.0000046\n",
      "[18/25][5030/9765] Loss_D: 0.0925 Loss_G: 0.0414 Convergence: 0.0974 k= 0.019300 lr = 0.0000046\n",
      "[18/25][5040/9765] Loss_D: 0.0928 Loss_G: 0.0428 Convergence: 0.0990 k= 0.019266 lr = 0.0000046\n",
      "[18/25][5050/9765] Loss_D: 0.1056 Loss_G: 0.0409 Convergence: 0.1081 k= 0.019238 lr = 0.0000046\n",
      "[18/25][5060/9765] Loss_D: 0.0984 Loss_G: 0.0393 Convergence: 0.0995 k= 0.019235 lr = 0.0000046\n",
      "[18/25][5070/9765] Loss_D: 0.0874 Loss_G: 0.0390 Convergence: 0.0918 k= 0.019211 lr = 0.0000046\n",
      "[18/25][5080/9765] Loss_D: 0.0875 Loss_G: 0.0389 Convergence: 0.0918 k= 0.019203 lr = 0.0000046\n",
      "[18/25][5090/9765] Loss_D: 0.0970 Loss_G: 0.0364 Convergence: 0.1004 k= 0.019207 lr = 0.0000046\n",
      "[18/25][5100/9765] Loss_D: 0.0914 Loss_G: 0.0381 Convergence: 0.0934 k= 0.019239 lr = 0.0000046\n",
      "[18/25][5110/9765] Loss_D: 0.1005 Loss_G: 0.0375 Convergence: 0.1042 k= 0.019252 lr = 0.0000046\n",
      "[18/25][5120/9765] Loss_D: 0.0926 Loss_G: 0.0385 Convergence: 0.0945 k= 0.019249 lr = 0.0000046\n",
      "[18/25][5130/9765] Loss_D: 0.0962 Loss_G: 0.0383 Convergence: 0.0974 k= 0.019256 lr = 0.0000046\n",
      "[18/25][5140/9765] Loss_D: 0.0924 Loss_G: 0.0381 Convergence: 0.0940 k= 0.019266 lr = 0.0000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][5150/9765] Loss_D: 0.0991 Loss_G: 0.0390 Convergence: 0.1007 k= 0.019283 lr = 0.0000046\n",
      "[18/25][5160/9765] Loss_D: 0.0968 Loss_G: 0.0376 Convergence: 0.0990 k= 0.019296 lr = 0.0000046\n",
      "[18/25][5170/9765] Loss_D: 0.0939 Loss_G: 0.0382 Convergence: 0.0950 k= 0.019305 lr = 0.0000046\n",
      "[18/25][5180/9765] Loss_D: 0.1006 Loss_G: 0.0379 Convergence: 0.1039 k= 0.019304 lr = 0.0000046\n",
      "[18/25][5190/9765] Loss_D: 0.1070 Loss_G: 0.0399 Convergence: 0.1109 k= 0.019313 lr = 0.0000046\n",
      "[18/25][5200/9765] Loss_D: 0.1028 Loss_G: 0.0402 Convergence: 0.1048 k= 0.019309 lr = 0.0000046\n",
      "[18/25][5210/9765] Loss_D: 0.1003 Loss_G: 0.0407 Convergence: 0.1013 k= 0.019302 lr = 0.0000046\n",
      "[18/25][5220/9765] Loss_D: 0.0930 Loss_G: 0.0407 Convergence: 0.0970 k= 0.019272 lr = 0.0000046\n",
      "[18/25][5230/9765] Loss_D: 0.0926 Loss_G: 0.0412 Convergence: 0.0973 k= 0.019244 lr = 0.0000046\n",
      "[18/25][5240/9765] Loss_D: 0.0963 Loss_G: 0.0399 Convergence: 0.0981 k= 0.019242 lr = 0.0000046\n",
      "[18/25][5250/9765] Loss_D: 0.0961 Loss_G: 0.0376 Convergence: 0.0980 k= 0.019232 lr = 0.0000046\n",
      "[18/25][5260/9765] Loss_D: 0.0938 Loss_G: 0.0390 Convergence: 0.0957 k= 0.019241 lr = 0.0000046\n",
      "[18/25][5270/9765] Loss_D: 0.1081 Loss_G: 0.0393 Convergence: 0.1131 k= 0.019244 lr = 0.0000046\n",
      "[18/25][5280/9765] Loss_D: 0.1029 Loss_G: 0.0391 Convergence: 0.1060 k= 0.019245 lr = 0.0000046\n",
      "[18/25][5290/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0973 k= 0.019254 lr = 0.0000046\n",
      "[18/25][5300/9765] Loss_D: 0.0912 Loss_G: 0.0372 Convergence: 0.0923 k= 0.019258 lr = 0.0000046\n",
      "[18/25][5310/9765] Loss_D: 0.0953 Loss_G: 0.0375 Convergence: 0.0969 k= 0.019286 lr = 0.0000046\n",
      "[18/25][5320/9765] Loss_D: 0.0968 Loss_G: 0.0385 Convergence: 0.0980 k= 0.019283 lr = 0.0000046\n",
      "[18/25][5330/9765] Loss_D: 0.0931 Loss_G: 0.0378 Convergence: 0.0941 k= 0.019278 lr = 0.0000046\n",
      "[18/25][5340/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1035 k= 0.019296 lr = 0.0000046\n",
      "[18/25][5350/9765] Loss_D: 0.1002 Loss_G: 0.0391 Convergence: 0.1022 k= 0.019300 lr = 0.0000046\n",
      "[18/25][5360/9765] Loss_D: 0.0999 Loss_G: 0.0404 Convergence: 0.1008 k= 0.019297 lr = 0.0000046\n",
      "[18/25][5370/9765] Loss_D: 0.0955 Loss_G: 0.0389 Convergence: 0.0967 k= 0.019300 lr = 0.0000046\n",
      "[18/25][5380/9765] Loss_D: 0.0969 Loss_G: 0.0373 Convergence: 0.0994 k= 0.019324 lr = 0.0000046\n",
      "[18/25][5390/9765] Loss_D: 0.0920 Loss_G: 0.0365 Convergence: 0.0933 k= 0.019329 lr = 0.0000046\n",
      "[18/25][5400/9765] Loss_D: 0.0957 Loss_G: 0.0378 Convergence: 0.0972 k= 0.019332 lr = 0.0000046\n",
      "[18/25][5410/9765] Loss_D: 0.0900 Loss_G: 0.0391 Convergence: 0.0935 k= 0.019336 lr = 0.0000046\n",
      "[18/25][5420/9765] Loss_D: 0.0962 Loss_G: 0.0403 Convergence: 0.0985 k= 0.019332 lr = 0.0000046\n",
      "[18/25][5430/9765] Loss_D: 0.0914 Loss_G: 0.0353 Convergence: 0.0937 k= 0.019346 lr = 0.0000046\n",
      "[18/25][5440/9765] Loss_D: 0.0944 Loss_G: 0.0353 Convergence: 0.0979 k= 0.019372 lr = 0.0000046\n",
      "[18/25][5450/9765] Loss_D: 0.1032 Loss_G: 0.0370 Convergence: 0.1085 k= 0.019397 lr = 0.0000046\n",
      "[18/25][5460/9765] Loss_D: 0.1010 Loss_G: 0.0390 Convergence: 0.1034 k= 0.019406 lr = 0.0000046\n",
      "[18/25][5470/9765] Loss_D: 0.0993 Loss_G: 0.0406 Convergence: 0.1007 k= 0.019403 lr = 0.0000046\n",
      "[18/25][5480/9765] Loss_D: 0.0870 Loss_G: 0.0388 Convergence: 0.0915 k= 0.019406 lr = 0.0000046\n",
      "[18/25][5490/9765] Loss_D: 0.0988 Loss_G: 0.0389 Convergence: 0.1004 k= 0.019402 lr = 0.0000046\n",
      "[18/25][5500/9765] Loss_D: 0.0950 Loss_G: 0.0406 Convergence: 0.0980 k= 0.019393 lr = 0.0000046\n",
      "[18/25][5510/9765] Loss_D: 0.0921 Loss_G: 0.0396 Convergence: 0.0954 k= 0.019388 lr = 0.0000046\n",
      "[18/25][5520/9765] Loss_D: 0.0945 Loss_G: 0.0380 Convergence: 0.0953 k= 0.019382 lr = 0.0000046\n",
      "[18/25][5530/9765] Loss_D: 0.0912 Loss_G: 0.0372 Convergence: 0.0924 k= 0.019374 lr = 0.0000046\n",
      "[18/25][5540/9765] Loss_D: 0.0962 Loss_G: 0.0385 Convergence: 0.0972 k= 0.019388 lr = 0.0000046\n",
      "[18/25][5550/9765] Loss_D: 0.0906 Loss_G: 0.0389 Convergence: 0.0937 k= 0.019380 lr = 0.0000046\n",
      "[18/25][5560/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0981 k= 0.019385 lr = 0.0000046\n",
      "[18/25][5570/9765] Loss_D: 0.1060 Loss_G: 0.0384 Convergence: 0.1111 k= 0.019389 lr = 0.0000046\n",
      "[18/25][5580/9765] Loss_D: 0.1025 Loss_G: 0.0364 Convergence: 0.1081 k= 0.019400 lr = 0.0000046\n",
      "[18/25][5590/9765] Loss_D: 0.1074 Loss_G: 0.0369 Convergence: 0.1145 k= 0.019429 lr = 0.0000046\n",
      "[18/25][5600/9765] Loss_D: 0.0978 Loss_G: 0.0372 Convergence: 0.1008 k= 0.019453 lr = 0.0000046\n",
      "[18/25][5610/9765] Loss_D: 0.0954 Loss_G: 0.0376 Convergence: 0.0970 k= 0.019451 lr = 0.0000046\n",
      "[18/25][5620/9765] Loss_D: 0.0959 Loss_G: 0.0390 Convergence: 0.0970 k= 0.019463 lr = 0.0000046\n",
      "[18/25][5630/9765] Loss_D: 0.0991 Loss_G: 0.0389 Convergence: 0.1009 k= 0.019475 lr = 0.0000046\n",
      "[18/25][5640/9765] Loss_D: 0.0951 Loss_G: 0.0386 Convergence: 0.0961 k= 0.019477 lr = 0.0000046\n",
      "[18/25][5650/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0964 k= 0.019468 lr = 0.0000046\n",
      "[18/25][5660/9765] Loss_D: 0.1056 Loss_G: 0.0397 Convergence: 0.1093 k= 0.019461 lr = 0.0000046\n",
      "[18/25][5670/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.0999 k= 0.019467 lr = 0.0000046\n",
      "[18/25][5680/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0994 k= 0.019459 lr = 0.0000046\n",
      "[18/25][5690/9765] Loss_D: 0.0934 Loss_G: 0.0408 Convergence: 0.0973 k= 0.019440 lr = 0.0000046\n",
      "[18/25][5700/9765] Loss_D: 0.0943 Loss_G: 0.0396 Convergence: 0.0966 k= 0.019419 lr = 0.0000046\n",
      "[18/25][5710/9765] Loss_D: 0.0927 Loss_G: 0.0389 Convergence: 0.0949 k= 0.019422 lr = 0.0000046\n",
      "[18/25][5720/9765] Loss_D: 0.0965 Loss_G: 0.0391 Convergence: 0.0975 k= 0.019431 lr = 0.0000046\n",
      "[18/25][5730/9765] Loss_D: 0.0945 Loss_G: 0.0369 Convergence: 0.0964 k= 0.019438 lr = 0.0000046\n",
      "[18/25][5740/9765] Loss_D: 0.0962 Loss_G: 0.0385 Convergence: 0.0973 k= 0.019436 lr = 0.0000046\n",
      "[18/25][5750/9765] Loss_D: 0.1009 Loss_G: 0.0394 Convergence: 0.1029 k= 0.019441 lr = 0.0000046\n",
      "[18/25][5760/9765] Loss_D: 0.0943 Loss_G: 0.0387 Convergence: 0.0958 k= 0.019435 lr = 0.0000046\n",
      "[18/25][5770/9765] Loss_D: 0.0887 Loss_G: 0.0383 Convergence: 0.0920 k= 0.019428 lr = 0.0000046\n",
      "[18/25][5780/9765] Loss_D: 0.0917 Loss_G: 0.0392 Convergence: 0.0947 k= 0.019436 lr = 0.0000046\n",
      "[18/25][5790/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0945 k= 0.019434 lr = 0.0000046\n",
      "[18/25][5800/9765] Loss_D: 0.1015 Loss_G: 0.0393 Convergence: 0.1039 k= 0.019438 lr = 0.0000046\n",
      "[18/25][5810/9765] Loss_D: 0.1061 Loss_G: 0.0385 Convergence: 0.1111 k= 0.019435 lr = 0.0000046\n",
      "[18/25][5820/9765] Loss_D: 0.1050 Loss_G: 0.0413 Convergence: 0.1068 k= 0.019432 lr = 0.0000046\n",
      "[18/25][5830/9765] Loss_D: 0.0966 Loss_G: 0.0394 Convergence: 0.0978 k= 0.019421 lr = 0.0000046\n",
      "[18/25][5840/9765] Loss_D: 0.0976 Loss_G: 0.0391 Convergence: 0.0987 k= 0.019407 lr = 0.0000046\n",
      "[18/25][5850/9765] Loss_D: 0.1030 Loss_G: 0.0409 Convergence: 0.1044 k= 0.019398 lr = 0.0000046\n",
      "[18/25][5860/9765] Loss_D: 0.0985 Loss_G: 0.0421 Convergence: 0.1017 k= 0.019368 lr = 0.0000046\n",
      "[18/25][5870/9765] Loss_D: 0.0884 Loss_G: 0.0396 Convergence: 0.0931 k= 0.019354 lr = 0.0000046\n",
      "[18/25][5880/9765] Loss_D: 0.0899 Loss_G: 0.0388 Convergence: 0.0932 k= 0.019351 lr = 0.0000046\n",
      "[18/25][5890/9765] Loss_D: 0.0980 Loss_G: 0.0386 Convergence: 0.0996 k= 0.019344 lr = 0.0000046\n",
      "[18/25][5900/9765] Loss_D: 0.0919 Loss_G: 0.0365 Convergence: 0.0931 k= 0.019358 lr = 0.0000046\n",
      "[18/25][5910/9765] Loss_D: 0.1017 Loss_G: 0.0383 Convergence: 0.1051 k= 0.019372 lr = 0.0000046\n",
      "[18/25][5920/9765] Loss_D: 0.1013 Loss_G: 0.0381 Convergence: 0.1048 k= 0.019376 lr = 0.0000046\n",
      "[18/25][5930/9765] Loss_D: 0.0961 Loss_G: 0.0356 Convergence: 0.0999 k= 0.019375 lr = 0.0000046\n",
      "[18/25][5940/9765] Loss_D: 0.0911 Loss_G: 0.0369 Convergence: 0.0920 k= 0.019400 lr = 0.0000046\n",
      "[18/25][5950/9765] Loss_D: 0.0992 Loss_G: 0.0380 Convergence: 0.1020 k= 0.019414 lr = 0.0000046\n",
      "[18/25][5960/9765] Loss_D: 0.1016 Loss_G: 0.0407 Convergence: 0.1026 k= 0.019419 lr = 0.0000046\n",
      "[18/25][5970/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.0997 k= 0.019394 lr = 0.0000046\n",
      "[18/25][5980/9765] Loss_D: 0.1050 Loss_G: 0.0430 Convergence: 0.1065 k= 0.019385 lr = 0.0000046\n",
      "[18/25][5990/9765] Loss_D: 0.0898 Loss_G: 0.0414 Convergence: 0.0958 k= 0.019341 lr = 0.0000046\n",
      "[18/25][6000/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1001 k= 0.019322 lr = 0.0000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][6010/9765] Loss_D: 0.0951 Loss_G: 0.0390 Convergence: 0.0965 k= 0.019314 lr = 0.0000046\n",
      "[18/25][6020/9765] Loss_D: 0.0902 Loss_G: 0.0395 Convergence: 0.0941 k= 0.019292 lr = 0.0000046\n",
      "[18/25][6030/9765] Loss_D: 0.1070 Loss_G: 0.0376 Convergence: 0.1133 k= 0.019302 lr = 0.0000046\n",
      "[18/25][6040/9765] Loss_D: 0.0925 Loss_G: 0.0393 Convergence: 0.0953 k= 0.019297 lr = 0.0000046\n",
      "[18/25][6050/9765] Loss_D: 0.0860 Loss_G: 0.0397 Convergence: 0.0918 k= 0.019310 lr = 0.0000046\n",
      "[18/25][6060/9765] Loss_D: 0.1013 Loss_G: 0.0413 Convergence: 0.1026 k= 0.019289 lr = 0.0000046\n",
      "[18/25][6070/9765] Loss_D: 0.0979 Loss_G: 0.0403 Convergence: 0.0995 k= 0.019267 lr = 0.0000046\n",
      "[18/25][6080/9765] Loss_D: 0.0960 Loss_G: 0.0383 Convergence: 0.0971 k= 0.019267 lr = 0.0000046\n",
      "[18/25][6090/9765] Loss_D: 0.0990 Loss_G: 0.0390 Convergence: 0.1007 k= 0.019264 lr = 0.0000046\n",
      "[18/25][6100/9765] Loss_D: 0.1044 Loss_G: 0.0395 Convergence: 0.1078 k= 0.019267 lr = 0.0000046\n",
      "[18/25][6110/9765] Loss_D: 0.1029 Loss_G: 0.0398 Convergence: 0.1053 k= 0.019271 lr = 0.0000046\n",
      "[18/25][6120/9765] Loss_D: 0.1076 Loss_G: 0.0397 Convergence: 0.1121 k= 0.019274 lr = 0.0000046\n",
      "[18/25][6130/9765] Loss_D: 0.1032 Loss_G: 0.0398 Convergence: 0.1058 k= 0.019279 lr = 0.0000046\n",
      "[18/25][6140/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1042 k= 0.019265 lr = 0.0000046\n",
      "[18/25][6150/9765] Loss_D: 0.0936 Loss_G: 0.0387 Convergence: 0.0953 k= 0.019254 lr = 0.0000046\n",
      "[18/25][6160/9765] Loss_D: 0.0916 Loss_G: 0.0404 Convergence: 0.0958 k= 0.019245 lr = 0.0000046\n",
      "[18/25][6170/9765] Loss_D: 0.0913 Loss_G: 0.0386 Convergence: 0.0938 k= 0.019238 lr = 0.0000046\n",
      "[18/25][6180/9765] Loss_D: 0.1005 Loss_G: 0.0383 Convergence: 0.1035 k= 0.019240 lr = 0.0000046\n",
      "[18/25][6190/9765] Loss_D: 0.1011 Loss_G: 0.0384 Convergence: 0.1042 k= 0.019243 lr = 0.0000046\n",
      "[18/25][6200/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0934 k= 0.019238 lr = 0.0000046\n",
      "[18/25][6210/9765] Loss_D: 0.1016 Loss_G: 0.0386 Convergence: 0.1048 k= 0.019232 lr = 0.0000046\n",
      "[18/25][6220/9765] Loss_D: 0.0972 Loss_G: 0.0365 Convergence: 0.1005 k= 0.019245 lr = 0.0000046\n",
      "[18/25][6230/9765] Loss_D: 0.0923 Loss_G: 0.0372 Convergence: 0.0930 k= 0.019265 lr = 0.0000046\n",
      "[18/25][6240/9765] Loss_D: 0.0930 Loss_G: 0.0380 Convergence: 0.0942 k= 0.019276 lr = 0.0000046\n",
      "[18/25][6250/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1055 k= 0.019275 lr = 0.0000046\n",
      "[18/25][6260/9765] Loss_D: 0.0952 Loss_G: 0.0377 Convergence: 0.0966 k= 0.019286 lr = 0.0000046\n",
      "[18/25][6270/9765] Loss_D: 0.0943 Loss_G: 0.0398 Convergence: 0.0968 k= 0.019289 lr = 0.0000046\n",
      "[18/25][6280/9765] Loss_D: 0.0958 Loss_G: 0.0392 Convergence: 0.0971 k= 0.019294 lr = 0.0000046\n",
      "[18/25][6290/9765] Loss_D: 0.0896 Loss_G: 0.0386 Convergence: 0.0928 k= 0.019309 lr = 0.0000046\n",
      "[18/25][6300/9765] Loss_D: 0.0944 Loss_G: 0.0394 Convergence: 0.0966 k= 0.019297 lr = 0.0000046\n",
      "[18/25][6310/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0960 k= 0.019281 lr = 0.0000046\n",
      "[18/25][6320/9765] Loss_D: 0.0942 Loss_G: 0.0382 Convergence: 0.0951 k= 0.019282 lr = 0.0000046\n",
      "[18/25][6330/9765] Loss_D: 0.1018 Loss_G: 0.0379 Convergence: 0.1057 k= 0.019297 lr = 0.0000046\n",
      "[18/25][6340/9765] Loss_D: 0.0903 Loss_G: 0.0379 Convergence: 0.0925 k= 0.019299 lr = 0.0000046\n",
      "[18/25][6350/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.019309 lr = 0.0000046\n",
      "[18/25][6360/9765] Loss_D: 0.1010 Loss_G: 0.0382 Convergence: 0.1042 k= 0.019316 lr = 0.0000046\n",
      "[18/25][6370/9765] Loss_D: 0.1044 Loss_G: 0.0388 Convergence: 0.1084 k= 0.019311 lr = 0.0000046\n",
      "[18/25][6380/9765] Loss_D: 0.0950 Loss_G: 0.0399 Convergence: 0.0974 k= 0.019308 lr = 0.0000046\n",
      "[18/25][6390/9765] Loss_D: 0.1068 Loss_G: 0.0396 Convergence: 0.1109 k= 0.019310 lr = 0.0000046\n",
      "[18/25][6400/9765] Loss_D: 0.0968 Loss_G: 0.0390 Convergence: 0.0976 k= 0.019313 lr = 0.0000046\n",
      "[18/25][6410/9765] Loss_D: 0.0969 Loss_G: 0.0385 Convergence: 0.0982 k= 0.019310 lr = 0.0000046\n",
      "[18/25][6420/9765] Loss_D: 0.0971 Loss_G: 0.0392 Convergence: 0.0980 k= 0.019314 lr = 0.0000046\n",
      "[18/25][6430/9765] Loss_D: 0.0943 Loss_G: 0.0386 Convergence: 0.0956 k= 0.019309 lr = 0.0000046\n",
      "[18/25][6440/9765] Loss_D: 0.1029 Loss_G: 0.0392 Convergence: 0.1059 k= 0.019298 lr = 0.0000046\n",
      "[18/25][6450/9765] Loss_D: 0.0928 Loss_G: 0.0391 Convergence: 0.0952 k= 0.019286 lr = 0.0000046\n",
      "[18/25][6460/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0983 k= 0.019278 lr = 0.0000046\n",
      "[18/25][6470/9765] Loss_D: 0.0981 Loss_G: 0.0392 Convergence: 0.0993 k= 0.019282 lr = 0.0000046\n",
      "[18/25][6480/9765] Loss_D: 0.0950 Loss_G: 0.0379 Convergence: 0.0961 k= 0.019283 lr = 0.0000046\n",
      "[18/25][6490/9765] Loss_D: 0.1026 Loss_G: 0.0376 Convergence: 0.1070 k= 0.019296 lr = 0.0000046\n",
      "[18/25][6500/9765] Loss_D: 0.0931 Loss_G: 0.0403 Convergence: 0.0966 k= 0.019296 lr = 0.0000046\n",
      "[18/25][6510/9765] Loss_D: 0.0925 Loss_G: 0.0395 Convergence: 0.0955 k= 0.019291 lr = 0.0000046\n",
      "[18/25][6520/9765] Loss_D: 0.0887 Loss_G: 0.0397 Convergence: 0.0934 k= 0.019283 lr = 0.0000046\n",
      "[18/25][6530/9765] Loss_D: 0.0984 Loss_G: 0.0399 Convergence: 0.0994 k= 0.019269 lr = 0.0000046\n",
      "[18/25][6540/9765] Loss_D: 0.0904 Loss_G: 0.0379 Convergence: 0.0926 k= 0.019258 lr = 0.0000046\n",
      "[18/25][6550/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0958 k= 0.019268 lr = 0.0000046\n",
      "[18/25][6560/9765] Loss_D: 0.1006 Loss_G: 0.0419 Convergence: 0.1027 k= 0.019267 lr = 0.0000046\n",
      "[18/25][6570/9765] Loss_D: 0.0987 Loss_G: 0.0398 Convergence: 0.0995 k= 0.019268 lr = 0.0000046\n",
      "[18/25][6580/9765] Loss_D: 0.0819 Loss_G: 0.0396 Convergence: 0.0892 k= 0.019249 lr = 0.0000046\n",
      "[18/25][6590/9765] Loss_D: 0.1026 Loss_G: 0.0377 Convergence: 0.1070 k= 0.019243 lr = 0.0000046\n",
      "[18/25][6600/9765] Loss_D: 0.0922 Loss_G: 0.0390 Convergence: 0.0948 k= 0.019247 lr = 0.0000046\n",
      "[18/25][6610/9765] Loss_D: 0.0874 Loss_G: 0.0402 Convergence: 0.0931 k= 0.019228 lr = 0.0000046\n",
      "[18/25][6620/9765] Loss_D: 0.1019 Loss_G: 0.0398 Convergence: 0.1039 k= 0.019217 lr = 0.0000046\n",
      "[18/25][6630/9765] Loss_D: 0.0875 Loss_G: 0.0406 Convergence: 0.0935 k= 0.019204 lr = 0.0000046\n",
      "[18/25][6640/9765] Loss_D: 0.0957 Loss_G: 0.0377 Convergence: 0.0973 k= 0.019213 lr = 0.0000046\n",
      "[18/25][6650/9765] Loss_D: 0.0990 Loss_G: 0.0372 Convergence: 0.1024 k= 0.019224 lr = 0.0000046\n",
      "[18/25][6660/9765] Loss_D: 0.1065 Loss_G: 0.0383 Convergence: 0.1118 k= 0.019226 lr = 0.0000046\n",
      "[18/25][6670/9765] Loss_D: 0.0973 Loss_G: 0.0368 Convergence: 0.1004 k= 0.019231 lr = 0.0000046\n",
      "[18/25][6680/9765] Loss_D: 0.0991 Loss_G: 0.0398 Convergence: 0.0999 k= 0.019235 lr = 0.0000046\n",
      "[18/25][6690/9765] Loss_D: 0.0912 Loss_G: 0.0400 Convergence: 0.0952 k= 0.019232 lr = 0.0000046\n",
      "[18/25][6700/9765] Loss_D: 0.0992 Loss_G: 0.0417 Convergence: 0.1017 k= 0.019217 lr = 0.0000046\n",
      "[18/25][6710/9765] Loss_D: 0.0959 Loss_G: 0.0411 Convergence: 0.0991 k= 0.019191 lr = 0.0000046\n",
      "[18/25][6720/9765] Loss_D: 0.0927 Loss_G: 0.0386 Convergence: 0.0946 k= 0.019180 lr = 0.0000046\n",
      "[18/25][6730/9765] Loss_D: 0.0880 Loss_G: 0.0386 Convergence: 0.0919 k= 0.019179 lr = 0.0000046\n",
      "[18/25][6740/9765] Loss_D: 0.0977 Loss_G: 0.0382 Convergence: 0.0996 k= 0.019174 lr = 0.0000046\n",
      "[18/25][6750/9765] Loss_D: 0.1108 Loss_G: 0.0388 Convergence: 0.1174 k= 0.019182 lr = 0.0000046\n",
      "[18/25][6760/9765] Loss_D: 0.0912 Loss_G: 0.0384 Convergence: 0.0935 k= 0.019191 lr = 0.0000046\n",
      "[18/25][6770/9765] Loss_D: 0.1014 Loss_G: 0.0381 Convergence: 0.1048 k= 0.019184 lr = 0.0000046\n",
      "[18/25][6780/9765] Loss_D: 0.0926 Loss_G: 0.0395 Convergence: 0.0955 k= 0.019185 lr = 0.0000046\n",
      "[18/25][6790/9765] Loss_D: 0.0987 Loss_G: 0.0390 Convergence: 0.1003 k= 0.019189 lr = 0.0000046\n",
      "[18/25][6800/9765] Loss_D: 0.0955 Loss_G: 0.0389 Convergence: 0.0967 k= 0.019193 lr = 0.0000046\n",
      "[18/25][6810/9765] Loss_D: 0.0998 Loss_G: 0.0371 Convergence: 0.1035 k= 0.019208 lr = 0.0000046\n",
      "[18/25][6820/9765] Loss_D: 0.0966 Loss_G: 0.0379 Convergence: 0.0984 k= 0.019208 lr = 0.0000046\n",
      "[18/25][6830/9765] Loss_D: 0.0907 Loss_G: 0.0370 Convergence: 0.0919 k= 0.019212 lr = 0.0000046\n",
      "[18/25][6840/9765] Loss_D: 0.0918 Loss_G: 0.0380 Convergence: 0.0935 k= 0.019210 lr = 0.0000046\n",
      "[18/25][6850/9765] Loss_D: 0.0965 Loss_G: 0.0380 Convergence: 0.0981 k= 0.019222 lr = 0.0000046\n",
      "[18/25][6860/9765] Loss_D: 0.0952 Loss_G: 0.0381 Convergence: 0.0962 k= 0.019240 lr = 0.0000046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][6870/9765] Loss_D: 0.0993 Loss_G: 0.0364 Convergence: 0.1036 k= 0.019257 lr = 0.0000046\n",
      "[18/25][6880/9765] Loss_D: 0.0962 Loss_G: 0.0381 Convergence: 0.0976 k= 0.019268 lr = 0.0000046\n",
      "[18/25][6890/9765] Loss_D: 0.1050 Loss_G: 0.0370 Convergence: 0.1110 k= 0.019282 lr = 0.0000046\n",
      "[18/25][6900/9765] Loss_D: 0.0939 Loss_G: 0.0378 Convergence: 0.0947 k= 0.019294 lr = 0.0000046\n",
      "[18/25][6910/9765] Loss_D: 0.0912 Loss_G: 0.0382 Convergence: 0.0933 k= 0.019299 lr = 0.0000046\n",
      "[18/25][6920/9765] Loss_D: 0.1041 Loss_G: 0.0388 Convergence: 0.1079 k= 0.019312 lr = 0.0000046\n",
      "[18/25][6930/9765] Loss_D: 0.0969 Loss_G: 0.0378 Convergence: 0.0988 k= 0.019320 lr = 0.0000046\n",
      "[18/25][6940/9765] Loss_D: 0.0984 Loss_G: 0.0375 Convergence: 0.1011 k= 0.019341 lr = 0.0000046\n",
      "[18/25][6950/9765] Loss_D: 0.0972 Loss_G: 0.0385 Convergence: 0.0987 k= 0.019356 lr = 0.0000046\n",
      "[18/25][6960/9765] Loss_D: 0.0924 Loss_G: 0.0372 Convergence: 0.0931 k= 0.019363 lr = 0.0000046\n",
      "[18/25][6970/9765] Loss_D: 0.1040 Loss_G: 0.0401 Convergence: 0.1066 k= 0.019367 lr = 0.0000046\n",
      "[18/25][6980/9765] Loss_D: 0.1023 Loss_G: 0.0410 Convergence: 0.1033 k= 0.019360 lr = 0.0000046\n",
      "[18/25][6990/9765] Loss_D: 0.1011 Loss_G: 0.0402 Convergence: 0.1024 k= 0.019342 lr = 0.0000046\n",
      "[18/25][7000/9765] Loss_D: 0.1040 Loss_G: 0.0382 Convergence: 0.1084 k= 0.019354 lr = 0.0000046\n",
      "[18/25][7010/9765] Loss_D: 0.0974 Loss_G: 0.0384 Convergence: 0.0990 k= 0.019358 lr = 0.0000046\n",
      "[18/25][7020/9765] Loss_D: 0.0914 Loss_G: 0.0401 Convergence: 0.0954 k= 0.019345 lr = 0.0000046\n",
      "[18/25][7030/9765] Loss_D: 0.0995 Loss_G: 0.0396 Convergence: 0.1007 k= 0.019327 lr = 0.0000046\n",
      "[18/25][7040/9765] Loss_D: 0.0894 Loss_G: 0.0392 Convergence: 0.0933 k= 0.019324 lr = 0.0000046\n",
      "[18/25][7050/9765] Loss_D: 0.0999 Loss_G: 0.0384 Convergence: 0.1025 k= 0.019337 lr = 0.0000046\n",
      "[18/25][7060/9765] Loss_D: 0.0855 Loss_G: 0.0380 Convergence: 0.0897 k= 0.019345 lr = 0.0000046\n",
      "[18/25][7070/9765] Loss_D: 0.1002 Loss_G: 0.0369 Convergence: 0.1044 k= 0.019347 lr = 0.0000046\n",
      "[18/25][7080/9765] Loss_D: 0.0984 Loss_G: 0.0392 Convergence: 0.0997 k= 0.019353 lr = 0.0000046\n",
      "[18/25][7090/9765] Loss_D: 0.0981 Loss_G: 0.0388 Convergence: 0.0997 k= 0.019360 lr = 0.0000046\n",
      "[18/25][7100/9765] Loss_D: 0.0953 Loss_G: 0.0413 Convergence: 0.0990 k= 0.019346 lr = 0.0000046\n",
      "[18/25][7110/9765] Loss_D: 0.0974 Loss_G: 0.0400 Convergence: 0.0989 k= 0.019345 lr = 0.0000046\n",
      "[18/25][7120/9765] Loss_D: 0.0946 Loss_G: 0.0413 Convergence: 0.0986 k= 0.019336 lr = 0.0000046\n",
      "[18/25][7130/9765] Loss_D: 0.1021 Loss_G: 0.0398 Convergence: 0.1043 k= 0.019322 lr = 0.0000046\n",
      "[18/25][7140/9765] Loss_D: 0.0989 Loss_G: 0.0419 Convergence: 0.1017 k= 0.019300 lr = 0.0000046\n",
      "[18/25][7150/9765] Loss_D: 0.0980 Loss_G: 0.0393 Convergence: 0.0990 k= 0.019282 lr = 0.0000046\n",
      "[18/25][7160/9765] Loss_D: 0.1032 Loss_G: 0.0385 Convergence: 0.1070 k= 0.019271 lr = 0.0000046\n",
      "[18/25][7170/9765] Loss_D: 0.0858 Loss_G: 0.0388 Convergence: 0.0907 k= 0.019273 lr = 0.0000046\n",
      "[18/25][7180/9765] Loss_D: 0.0963 Loss_G: 0.0394 Convergence: 0.0976 k= 0.019280 lr = 0.0000046\n",
      "[18/25][7190/9765] Loss_D: 0.0934 Loss_G: 0.0383 Convergence: 0.0948 k= 0.019292 lr = 0.0000046\n",
      "[18/25][7200/9765] Loss_D: 0.0875 Loss_G: 0.0357 Convergence: 0.0887 k= 0.019307 lr = 0.0000046\n",
      "[18/25][7210/9765] Loss_D: 0.0908 Loss_G: 0.0373 Convergence: 0.0923 k= 0.019325 lr = 0.0000046\n",
      "[18/25][7220/9765] Loss_D: 0.0970 Loss_G: 0.0377 Convergence: 0.0991 k= 0.019352 lr = 0.0000046\n",
      "[18/25][7230/9765] Loss_D: 0.0933 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019352 lr = 0.0000044\n",
      "[18/25][7240/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0934 k= 0.019342 lr = 0.0000044\n",
      "[18/25][7250/9765] Loss_D: 0.0916 Loss_G: 0.0404 Convergence: 0.0958 k= 0.019341 lr = 0.0000044\n",
      "[18/25][7260/9765] Loss_D: 0.1036 Loss_G: 0.0407 Convergence: 0.1055 k= 0.019319 lr = 0.0000044\n",
      "[18/25][7270/9765] Loss_D: 0.0841 Loss_G: 0.0403 Convergence: 0.0912 k= 0.019284 lr = 0.0000044\n",
      "[18/25][7280/9765] Loss_D: 0.0898 Loss_G: 0.0374 Convergence: 0.0917 k= 0.019279 lr = 0.0000044\n",
      "[18/25][7290/9765] Loss_D: 0.0935 Loss_G: 0.0397 Convergence: 0.0962 k= 0.019274 lr = 0.0000044\n",
      "[18/25][7300/9765] Loss_D: 0.0892 Loss_G: 0.0396 Convergence: 0.0936 k= 0.019262 lr = 0.0000044\n",
      "[18/25][7310/9765] Loss_D: 0.0894 Loss_G: 0.0368 Convergence: 0.0909 k= 0.019270 lr = 0.0000044\n",
      "[18/25][7320/9765] Loss_D: 0.0987 Loss_G: 0.0382 Convergence: 0.1010 k= 0.019286 lr = 0.0000044\n",
      "[18/25][7330/9765] Loss_D: 0.0922 Loss_G: 0.0373 Convergence: 0.0930 k= 0.019296 lr = 0.0000044\n",
      "[18/25][7340/9765] Loss_D: 0.1054 Loss_G: 0.0381 Convergence: 0.1105 k= 0.019304 lr = 0.0000044\n",
      "[18/25][7350/9765] Loss_D: 0.0938 Loss_G: 0.0377 Convergence: 0.0946 k= 0.019324 lr = 0.0000044\n",
      "[18/25][7360/9765] Loss_D: 0.0915 Loss_G: 0.0407 Convergence: 0.0960 k= 0.019331 lr = 0.0000044\n",
      "[18/25][7370/9765] Loss_D: 0.1056 Loss_G: 0.0389 Convergence: 0.1100 k= 0.019332 lr = 0.0000044\n",
      "[18/25][7380/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0995 k= 0.019333 lr = 0.0000044\n",
      "[18/25][7390/9765] Loss_D: 0.1118 Loss_G: 0.0392 Convergence: 0.1184 k= 0.019343 lr = 0.0000044\n",
      "[18/25][7400/9765] Loss_D: 0.0980 Loss_G: 0.0378 Convergence: 0.1004 k= 0.019340 lr = 0.0000044\n",
      "[18/25][7410/9765] Loss_D: 0.0955 Loss_G: 0.0381 Convergence: 0.0966 k= 0.019336 lr = 0.0000044\n",
      "[18/25][7420/9765] Loss_D: 0.0942 Loss_G: 0.0395 Convergence: 0.0964 k= 0.019330 lr = 0.0000044\n",
      "[18/25][7430/9765] Loss_D: 0.0976 Loss_G: 0.0401 Convergence: 0.0991 k= 0.019307 lr = 0.0000044\n",
      "[18/25][7440/9765] Loss_D: 0.0942 Loss_G: 0.0405 Convergence: 0.0975 k= 0.019279 lr = 0.0000044\n",
      "[18/25][7450/9765] Loss_D: 0.0919 Loss_G: 0.0403 Convergence: 0.0959 k= 0.019258 lr = 0.0000044\n",
      "[18/25][7460/9765] Loss_D: 0.0857 Loss_G: 0.0400 Convergence: 0.0919 k= 0.019236 lr = 0.0000044\n",
      "[18/25][7470/9765] Loss_D: 0.0951 Loss_G: 0.0416 Convergence: 0.0992 k= 0.019223 lr = 0.0000044\n",
      "[18/25][7480/9765] Loss_D: 0.1000 Loss_G: 0.0389 Convergence: 0.1022 k= 0.019215 lr = 0.0000044\n",
      "[18/25][7490/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0959 k= 0.019212 lr = 0.0000044\n",
      "[18/25][7500/9765] Loss_D: 0.0931 Loss_G: 0.0367 Convergence: 0.0946 k= 0.019234 lr = 0.0000044\n",
      "[18/25][7510/9765] Loss_D: 0.0993 Loss_G: 0.0376 Convergence: 0.1025 k= 0.019247 lr = 0.0000044\n",
      "[18/25][7520/9765] Loss_D: 0.0986 Loss_G: 0.0361 Convergence: 0.1029 k= 0.019258 lr = 0.0000044\n",
      "[18/25][7530/9765] Loss_D: 0.1051 Loss_G: 0.0367 Convergence: 0.1114 k= 0.019283 lr = 0.0000044\n",
      "[18/25][7540/9765] Loss_D: 0.0901 Loss_G: 0.0367 Convergence: 0.0912 k= 0.019293 lr = 0.0000044\n",
      "[18/25][7550/9765] Loss_D: 0.1002 Loss_G: 0.0372 Convergence: 0.1041 k= 0.019311 lr = 0.0000044\n",
      "[18/25][7560/9765] Loss_D: 0.1032 Loss_G: 0.0374 Convergence: 0.1081 k= 0.019322 lr = 0.0000044\n",
      "[18/25][7570/9765] Loss_D: 0.0971 Loss_G: 0.0385 Convergence: 0.0986 k= 0.019330 lr = 0.0000044\n",
      "[18/25][7580/9765] Loss_D: 0.0956 Loss_G: 0.0375 Convergence: 0.0974 k= 0.019337 lr = 0.0000044\n",
      "[18/25][7590/9765] Loss_D: 0.0957 Loss_G: 0.0380 Convergence: 0.0970 k= 0.019347 lr = 0.0000044\n",
      "[18/25][7600/9765] Loss_D: 0.1077 Loss_G: 0.0394 Convergence: 0.1124 k= 0.019343 lr = 0.0000044\n",
      "[18/25][7610/9765] Loss_D: 0.1037 Loss_G: 0.0420 Convergence: 0.1047 k= 0.019329 lr = 0.0000044\n",
      "[18/25][7620/9765] Loss_D: 0.0900 Loss_G: 0.0387 Convergence: 0.0931 k= 0.019310 lr = 0.0000044\n",
      "[18/25][7630/9765] Loss_D: 0.0971 Loss_G: 0.0390 Convergence: 0.0980 k= 0.019300 lr = 0.0000044\n",
      "[18/25][7640/9765] Loss_D: 0.1027 Loss_G: 0.0387 Convergence: 0.1062 k= 0.019301 lr = 0.0000044\n",
      "[18/25][7650/9765] Loss_D: 0.0904 Loss_G: 0.0378 Convergence: 0.0925 k= 0.019301 lr = 0.0000044\n",
      "[18/25][7660/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0948 k= 0.019307 lr = 0.0000044\n",
      "[18/25][7670/9765] Loss_D: 0.1024 Loss_G: 0.0392 Convergence: 0.1053 k= 0.019306 lr = 0.0000044\n",
      "[18/25][7680/9765] Loss_D: 0.0979 Loss_G: 0.0387 Convergence: 0.0995 k= 0.019311 lr = 0.0000044\n",
      "[18/25][7690/9765] Loss_D: 0.0936 Loss_G: 0.0381 Convergence: 0.0947 k= 0.019318 lr = 0.0000044\n",
      "[18/25][7700/9765] Loss_D: 0.0966 Loss_G: 0.0392 Convergence: 0.0976 k= 0.019330 lr = 0.0000044\n",
      "[18/25][7710/9765] Loss_D: 0.0895 Loss_G: 0.0375 Convergence: 0.0917 k= 0.019336 lr = 0.0000044\n",
      "[18/25][7720/9765] Loss_D: 0.0965 Loss_G: 0.0377 Convergence: 0.0984 k= 0.019344 lr = 0.0000044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][7730/9765] Loss_D: 0.0952 Loss_G: 0.0384 Convergence: 0.0960 k= 0.019367 lr = 0.0000044\n",
      "[18/25][7740/9765] Loss_D: 0.0824 Loss_G: 0.0387 Convergence: 0.0886 k= 0.019370 lr = 0.0000044\n",
      "[18/25][7750/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0970 k= 0.019361 lr = 0.0000044\n",
      "[18/25][7760/9765] Loss_D: 0.0991 Loss_G: 0.0408 Convergence: 0.1007 k= 0.019359 lr = 0.0000044\n",
      "[18/25][7770/9765] Loss_D: 0.1028 Loss_G: 0.0400 Convergence: 0.1051 k= 0.019353 lr = 0.0000044\n",
      "[18/25][7780/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1022 k= 0.019342 lr = 0.0000044\n",
      "[18/25][7790/9765] Loss_D: 0.0932 Loss_G: 0.0388 Convergence: 0.0952 k= 0.019339 lr = 0.0000044\n",
      "[18/25][7800/9765] Loss_D: 0.0965 Loss_G: 0.0393 Convergence: 0.0976 k= 0.019333 lr = 0.0000044\n",
      "[18/25][7810/9765] Loss_D: 0.0929 Loss_G: 0.0399 Convergence: 0.0961 k= 0.019331 lr = 0.0000044\n",
      "[18/25][7820/9765] Loss_D: 0.0954 Loss_G: 0.0372 Convergence: 0.0973 k= 0.019352 lr = 0.0000044\n",
      "[18/25][7830/9765] Loss_D: 0.0967 Loss_G: 0.0385 Convergence: 0.0979 k= 0.019363 lr = 0.0000044\n",
      "[18/25][7840/9765] Loss_D: 0.0870 Loss_G: 0.0379 Convergence: 0.0905 k= 0.019361 lr = 0.0000044\n",
      "[18/25][7850/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0949 k= 0.019365 lr = 0.0000044\n",
      "[18/25][7860/9765] Loss_D: 0.0914 Loss_G: 0.0380 Convergence: 0.0933 k= 0.019369 lr = 0.0000044\n",
      "[18/25][7870/9765] Loss_D: 0.1011 Loss_G: 0.0396 Convergence: 0.1031 k= 0.019378 lr = 0.0000044\n",
      "[18/25][7880/9765] Loss_D: 0.1023 Loss_G: 0.0406 Convergence: 0.1037 k= 0.019372 lr = 0.0000044\n",
      "[18/25][7890/9765] Loss_D: 0.0916 Loss_G: 0.0390 Convergence: 0.0944 k= 0.019361 lr = 0.0000044\n",
      "[18/25][7900/9765] Loss_D: 0.0968 Loss_G: 0.0370 Convergence: 0.0996 k= 0.019366 lr = 0.0000044\n",
      "[18/25][7910/9765] Loss_D: 0.0970 Loss_G: 0.0389 Convergence: 0.0980 k= 0.019373 lr = 0.0000044\n",
      "[18/25][7920/9765] Loss_D: 0.0976 Loss_G: 0.0406 Convergence: 0.0997 k= 0.019368 lr = 0.0000044\n",
      "[18/25][7930/9765] Loss_D: 0.0961 Loss_G: 0.0398 Convergence: 0.0980 k= 0.019349 lr = 0.0000044\n",
      "[18/25][7940/9765] Loss_D: 0.0958 Loss_G: 0.0381 Convergence: 0.0972 k= 0.019341 lr = 0.0000044\n",
      "[18/25][7950/9765] Loss_D: 0.1028 Loss_G: 0.0393 Convergence: 0.1057 k= 0.019345 lr = 0.0000044\n",
      "[18/25][7960/9765] Loss_D: 0.0959 Loss_G: 0.0401 Convergence: 0.0981 k= 0.019344 lr = 0.0000044\n",
      "[18/25][7970/9765] Loss_D: 0.1009 Loss_G: 0.0393 Convergence: 0.1031 k= 0.019345 lr = 0.0000044\n",
      "[18/25][7980/9765] Loss_D: 0.0863 Loss_G: 0.0388 Convergence: 0.0910 k= 0.019341 lr = 0.0000044\n",
      "[18/25][7990/9765] Loss_D: 0.1013 Loss_G: 0.0407 Convergence: 0.1023 k= 0.019331 lr = 0.0000044\n",
      "[18/25][8000/9765] Loss_D: 0.0872 Loss_G: 0.0389 Convergence: 0.0917 k= 0.019317 lr = 0.0000044\n",
      "[18/25][8010/9765] Loss_D: 0.0954 Loss_G: 0.0397 Convergence: 0.0974 k= 0.019309 lr = 0.0000044\n",
      "[18/25][8020/9765] Loss_D: 0.0950 Loss_G: 0.0389 Convergence: 0.0963 k= 0.019293 lr = 0.0000044\n",
      "[18/25][8030/9765] Loss_D: 0.0949 Loss_G: 0.0399 Convergence: 0.0973 k= 0.019288 lr = 0.0000044\n",
      "[18/25][8040/9765] Loss_D: 0.0997 Loss_G: 0.0386 Convergence: 0.1020 k= 0.019282 lr = 0.0000044\n",
      "[18/25][8050/9765] Loss_D: 0.0899 Loss_G: 0.0396 Convergence: 0.0940 k= 0.019262 lr = 0.0000044\n",
      "[18/25][8060/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0994 k= 0.019258 lr = 0.0000044\n",
      "[18/25][8070/9765] Loss_D: 0.0971 Loss_G: 0.0400 Convergence: 0.0987 k= 0.019264 lr = 0.0000044\n",
      "[18/25][8080/9765] Loss_D: 0.0953 Loss_G: 0.0392 Convergence: 0.0969 k= 0.019245 lr = 0.0000044\n",
      "[18/25][8090/9765] Loss_D: 0.0976 Loss_G: 0.0393 Convergence: 0.0983 k= 0.019236 lr = 0.0000044\n",
      "[18/25][8100/9765] Loss_D: 0.1019 Loss_G: 0.0397 Convergence: 0.1040 k= 0.019238 lr = 0.0000044\n",
      "[18/25][8110/9765] Loss_D: 0.1051 Loss_G: 0.0402 Convergence: 0.1080 k= 0.019235 lr = 0.0000044\n",
      "[18/25][8120/9765] Loss_D: 0.0965 Loss_G: 0.0406 Convergence: 0.0989 k= 0.019230 lr = 0.0000044\n",
      "[18/25][8130/9765] Loss_D: 0.0892 Loss_G: 0.0385 Convergence: 0.0924 k= 0.019210 lr = 0.0000044\n",
      "[18/25][8140/9765] Loss_D: 0.1007 Loss_G: 0.0379 Convergence: 0.1042 k= 0.019214 lr = 0.0000044\n",
      "[18/25][8150/9765] Loss_D: 0.0910 Loss_G: 0.0386 Convergence: 0.0937 k= 0.019208 lr = 0.0000044\n",
      "[18/25][8160/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0942 k= 0.019220 lr = 0.0000044\n",
      "[18/25][8170/9765] Loss_D: 0.0922 Loss_G: 0.0380 Convergence: 0.0938 k= 0.019227 lr = 0.0000044\n",
      "[18/25][8180/9765] Loss_D: 0.1000 Loss_G: 0.0380 Convergence: 0.1031 k= 0.019233 lr = 0.0000044\n",
      "[18/25][8190/9765] Loss_D: 0.0947 Loss_G: 0.0388 Convergence: 0.0960 k= 0.019234 lr = 0.0000044\n",
      "[18/25][8200/9765] Loss_D: 0.1016 Loss_G: 0.0374 Convergence: 0.1058 k= 0.019242 lr = 0.0000044\n",
      "[18/25][8210/9765] Loss_D: 0.0926 Loss_G: 0.0385 Convergence: 0.0945 k= 0.019247 lr = 0.0000044\n",
      "[18/25][8220/9765] Loss_D: 0.0984 Loss_G: 0.0398 Convergence: 0.0993 k= 0.019250 lr = 0.0000044\n",
      "[18/25][8230/9765] Loss_D: 0.0965 Loss_G: 0.0406 Convergence: 0.0990 k= 0.019238 lr = 0.0000044\n",
      "[18/25][8240/9765] Loss_D: 0.1063 Loss_G: 0.0384 Convergence: 0.1115 k= 0.019246 lr = 0.0000044\n",
      "[18/25][8250/9765] Loss_D: 0.1011 Loss_G: 0.0392 Convergence: 0.1034 k= 0.019251 lr = 0.0000044\n",
      "[18/25][8260/9765] Loss_D: 0.1005 Loss_G: 0.0384 Convergence: 0.1033 k= 0.019247 lr = 0.0000044\n",
      "[18/25][8270/9765] Loss_D: 0.0930 Loss_G: 0.0377 Convergence: 0.0940 k= 0.019253 lr = 0.0000044\n",
      "[18/25][8280/9765] Loss_D: 0.1009 Loss_G: 0.0388 Convergence: 0.1035 k= 0.019264 lr = 0.0000044\n",
      "[18/25][8290/9765] Loss_D: 0.0907 Loss_G: 0.0390 Convergence: 0.0939 k= 0.019273 lr = 0.0000044\n",
      "[18/25][8300/9765] Loss_D: 0.0875 Loss_G: 0.0368 Convergence: 0.0897 k= 0.019285 lr = 0.0000044\n",
      "[18/25][8310/9765] Loss_D: 0.0994 Loss_G: 0.0400 Convergence: 0.1002 k= 0.019303 lr = 0.0000044\n",
      "[18/25][8320/9765] Loss_D: 0.0969 Loss_G: 0.0398 Convergence: 0.0983 k= 0.019308 lr = 0.0000044\n",
      "[18/25][8330/9765] Loss_D: 0.1019 Loss_G: 0.0371 Convergence: 0.1066 k= 0.019308 lr = 0.0000044\n",
      "[18/25][8340/9765] Loss_D: 0.1004 Loss_G: 0.0406 Convergence: 0.1013 k= 0.019308 lr = 0.0000044\n",
      "[18/25][8350/9765] Loss_D: 0.1037 Loss_G: 0.0396 Convergence: 0.1067 k= 0.019303 lr = 0.0000044\n",
      "[18/25][8360/9765] Loss_D: 0.0935 Loss_G: 0.0387 Convergence: 0.0953 k= 0.019303 lr = 0.0000044\n",
      "[18/25][8370/9765] Loss_D: 0.0897 Loss_G: 0.0391 Convergence: 0.0934 k= 0.019293 lr = 0.0000044\n",
      "[18/25][8380/9765] Loss_D: 0.0885 Loss_G: 0.0380 Convergence: 0.0915 k= 0.019283 lr = 0.0000044\n",
      "[18/25][8390/9765] Loss_D: 0.1097 Loss_G: 0.0372 Convergence: 0.1174 k= 0.019286 lr = 0.0000044\n",
      "[18/25][8400/9765] Loss_D: 0.0966 Loss_G: 0.0363 Convergence: 0.0999 k= 0.019307 lr = 0.0000044\n",
      "[18/25][8410/9765] Loss_D: 0.0974 Loss_G: 0.0376 Convergence: 0.0998 k= 0.019320 lr = 0.0000044\n",
      "[18/25][8420/9765] Loss_D: 0.0948 Loss_G: 0.0410 Convergence: 0.0984 k= 0.019317 lr = 0.0000044\n",
      "[18/25][8430/9765] Loss_D: 0.0978 Loss_G: 0.0396 Convergence: 0.0987 k= 0.019306 lr = 0.0000044\n",
      "[18/25][8440/9765] Loss_D: 0.0990 Loss_G: 0.0382 Convergence: 0.1015 k= 0.019304 lr = 0.0000044\n",
      "[18/25][8450/9765] Loss_D: 0.0967 Loss_G: 0.0418 Convergence: 0.1003 k= 0.019282 lr = 0.0000044\n",
      "[18/25][8460/9765] Loss_D: 0.0980 Loss_G: 0.0408 Convergence: 0.1001 k= 0.019282 lr = 0.0000044\n",
      "[18/25][8470/9765] Loss_D: 0.0949 Loss_G: 0.0398 Convergence: 0.0972 k= 0.019268 lr = 0.0000044\n",
      "[18/25][8480/9765] Loss_D: 0.0927 Loss_G: 0.0379 Convergence: 0.0939 k= 0.019273 lr = 0.0000044\n",
      "[18/25][8490/9765] Loss_D: 0.0930 Loss_G: 0.0391 Convergence: 0.0953 k= 0.019274 lr = 0.0000044\n",
      "[18/25][8500/9765] Loss_D: 0.1000 Loss_G: 0.0384 Convergence: 0.1026 k= 0.019273 lr = 0.0000044\n",
      "[18/25][8510/9765] Loss_D: 0.0926 Loss_G: 0.0379 Convergence: 0.0939 k= 0.019263 lr = 0.0000044\n",
      "[18/25][8520/9765] Loss_D: 0.0960 Loss_G: 0.0379 Convergence: 0.0975 k= 0.019275 lr = 0.0000044\n",
      "[18/25][8530/9765] Loss_D: 0.0885 Loss_G: 0.0367 Convergence: 0.0903 k= 0.019282 lr = 0.0000044\n",
      "[18/25][8540/9765] Loss_D: 0.0944 Loss_G: 0.0373 Convergence: 0.0959 k= 0.019294 lr = 0.0000044\n",
      "[18/25][8550/9765] Loss_D: 0.0911 Loss_G: 0.0371 Convergence: 0.0921 k= 0.019319 lr = 0.0000044\n",
      "[18/25][8560/9765] Loss_D: 0.0959 Loss_G: 0.0371 Convergence: 0.0982 k= 0.019338 lr = 0.0000044\n",
      "[18/25][8570/9765] Loss_D: 0.1016 Loss_G: 0.0364 Convergence: 0.1069 k= 0.019366 lr = 0.0000044\n",
      "[18/25][8580/9765] Loss_D: 0.0966 Loss_G: 0.0371 Convergence: 0.0992 k= 0.019390 lr = 0.0000044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][8590/9765] Loss_D: 0.0937 Loss_G: 0.0393 Convergence: 0.0960 k= 0.019401 lr = 0.0000044\n",
      "[18/25][8600/9765] Loss_D: 0.1021 Loss_G: 0.0404 Convergence: 0.1036 k= 0.019387 lr = 0.0000044\n",
      "[18/25][8610/9765] Loss_D: 0.0921 Loss_G: 0.0410 Convergence: 0.0967 k= 0.019365 lr = 0.0000044\n",
      "[18/25][8620/9765] Loss_D: 0.0982 Loss_G: 0.0418 Convergence: 0.1012 k= 0.019339 lr = 0.0000044\n",
      "[18/25][8630/9765] Loss_D: 0.0988 Loss_G: 0.0428 Convergence: 0.1026 k= 0.019310 lr = 0.0000044\n",
      "[18/25][8640/9765] Loss_D: 0.0991 Loss_G: 0.0411 Convergence: 0.1010 k= 0.019294 lr = 0.0000044\n",
      "[18/25][8650/9765] Loss_D: 0.1000 Loss_G: 0.0392 Convergence: 0.1019 k= 0.019286 lr = 0.0000044\n",
      "[18/25][8660/9765] Loss_D: 0.1020 Loss_G: 0.0371 Convergence: 0.1067 k= 0.019302 lr = 0.0000044\n",
      "[18/25][8670/9765] Loss_D: 0.0937 Loss_G: 0.0388 Convergence: 0.0954 k= 0.019307 lr = 0.0000044\n",
      "[18/25][8680/9765] Loss_D: 0.0923 Loss_G: 0.0385 Convergence: 0.0944 k= 0.019303 lr = 0.0000044\n",
      "[18/25][8690/9765] Loss_D: 0.0881 Loss_G: 0.0375 Convergence: 0.0908 k= 0.019323 lr = 0.0000044\n",
      "[18/25][8700/9765] Loss_D: 0.0855 Loss_G: 0.0391 Convergence: 0.0908 k= 0.019311 lr = 0.0000044\n",
      "[18/25][8710/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1000 k= 0.019310 lr = 0.0000044\n",
      "[18/25][8720/9765] Loss_D: 0.0908 Loss_G: 0.0389 Convergence: 0.0938 k= 0.019302 lr = 0.0000044\n",
      "[18/25][8730/9765] Loss_D: 0.1021 Loss_G: 0.0407 Convergence: 0.1034 k= 0.019303 lr = 0.0000044\n",
      "[18/25][8740/9765] Loss_D: 0.0986 Loss_G: 0.0404 Convergence: 0.1000 k= 0.019306 lr = 0.0000044\n",
      "[18/25][8750/9765] Loss_D: 0.0980 Loss_G: 0.0405 Convergence: 0.0997 k= 0.019290 lr = 0.0000044\n",
      "[18/25][8760/9765] Loss_D: 0.0861 Loss_G: 0.0405 Convergence: 0.0926 k= 0.019275 lr = 0.0000044\n",
      "[18/25][8770/9765] Loss_D: 0.0901 Loss_G: 0.0395 Convergence: 0.0940 k= 0.019260 lr = 0.0000044\n",
      "[18/25][8780/9765] Loss_D: 0.0973 Loss_G: 0.0389 Convergence: 0.0984 k= 0.019248 lr = 0.0000044\n",
      "[18/25][8790/9765] Loss_D: 0.0905 Loss_G: 0.0393 Convergence: 0.0941 k= 0.019234 lr = 0.0000044\n",
      "[18/25][8800/9765] Loss_D: 0.0954 Loss_G: 0.0393 Convergence: 0.0970 k= 0.019242 lr = 0.0000044\n",
      "[18/25][8810/9765] Loss_D: 0.0942 Loss_G: 0.0390 Convergence: 0.0959 k= 0.019247 lr = 0.0000044\n",
      "[18/25][8820/9765] Loss_D: 0.0864 Loss_G: 0.0357 Convergence: 0.0879 k= 0.019262 lr = 0.0000044\n",
      "[18/25][8830/9765] Loss_D: 0.0976 Loss_G: 0.0382 Convergence: 0.0994 k= 0.019273 lr = 0.0000044\n",
      "[18/25][8840/9765] Loss_D: 0.0961 Loss_G: 0.0391 Convergence: 0.0972 k= 0.019286 lr = 0.0000044\n",
      "[18/25][8850/9765] Loss_D: 0.0972 Loss_G: 0.0380 Convergence: 0.0991 k= 0.019283 lr = 0.0000044\n",
      "[18/25][8860/9765] Loss_D: 0.1014 Loss_G: 0.0392 Convergence: 0.1039 k= 0.019295 lr = 0.0000044\n",
      "[18/25][8870/9765] Loss_D: 0.1047 Loss_G: 0.0387 Convergence: 0.1090 k= 0.019297 lr = 0.0000044\n",
      "[18/25][8880/9765] Loss_D: 0.0979 Loss_G: 0.0412 Convergence: 0.1004 k= 0.019292 lr = 0.0000044\n",
      "[18/25][8890/9765] Loss_D: 0.1020 Loss_G: 0.0368 Convergence: 0.1071 k= 0.019292 lr = 0.0000044\n",
      "[18/25][8900/9765] Loss_D: 0.0954 Loss_G: 0.0383 Convergence: 0.0963 k= 0.019299 lr = 0.0000044\n",
      "[18/25][8910/9765] Loss_D: 0.0980 Loss_G: 0.0384 Convergence: 0.0999 k= 0.019301 lr = 0.0000044\n",
      "[18/25][8920/9765] Loss_D: 0.0866 Loss_G: 0.0382 Convergence: 0.0906 k= 0.019312 lr = 0.0000044\n",
      "[18/25][8930/9765] Loss_D: 0.0950 Loss_G: 0.0400 Convergence: 0.0974 k= 0.019304 lr = 0.0000044\n",
      "[18/25][8940/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1001 k= 0.019306 lr = 0.0000044\n",
      "[18/25][8950/9765] Loss_D: 0.1010 Loss_G: 0.0404 Convergence: 0.1020 k= 0.019296 lr = 0.0000044\n",
      "[18/25][8960/9765] Loss_D: 0.0963 Loss_G: 0.0402 Convergence: 0.0984 k= 0.019277 lr = 0.0000044\n",
      "[18/25][8970/9765] Loss_D: 0.1034 Loss_G: 0.0401 Convergence: 0.1057 k= 0.019258 lr = 0.0000044\n",
      "[18/25][8980/9765] Loss_D: 0.1007 Loss_G: 0.0397 Convergence: 0.1024 k= 0.019255 lr = 0.0000044\n",
      "[18/25][8990/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.019245 lr = 0.0000044\n",
      "[18/25][9000/9765] Loss_D: 0.0963 Loss_G: 0.0394 Convergence: 0.0976 k= 0.019249 lr = 0.0000044\n",
      "[18/25][9010/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.0998 k= 0.019244 lr = 0.0000044\n",
      "[18/25][9020/9765] Loss_D: 0.0967 Loss_G: 0.0406 Convergence: 0.0991 k= 0.019239 lr = 0.0000044\n",
      "[18/25][9030/9765] Loss_D: 0.0939 Loss_G: 0.0398 Convergence: 0.0966 k= 0.019233 lr = 0.0000044\n",
      "[18/25][9040/9765] Loss_D: 0.0948 Loss_G: 0.0367 Convergence: 0.0970 k= 0.019226 lr = 0.0000044\n",
      "[18/25][9050/9765] Loss_D: 0.0911 Loss_G: 0.0388 Convergence: 0.0940 k= 0.019231 lr = 0.0000044\n",
      "[18/25][9060/9765] Loss_D: 0.0853 Loss_G: 0.0375 Convergence: 0.0891 k= 0.019237 lr = 0.0000044\n",
      "[18/25][9070/9765] Loss_D: 0.1010 Loss_G: 0.0373 Convergence: 0.1051 k= 0.019245 lr = 0.0000044\n",
      "[18/25][9080/9765] Loss_D: 0.1048 Loss_G: 0.0384 Convergence: 0.1093 k= 0.019262 lr = 0.0000044\n",
      "[18/25][9090/9765] Loss_D: 0.1064 Loss_G: 0.0399 Convergence: 0.1102 k= 0.019263 lr = 0.0000044\n",
      "[18/25][9100/9765] Loss_D: 0.1023 Loss_G: 0.0386 Convergence: 0.1056 k= 0.019273 lr = 0.0000044\n",
      "[18/25][9110/9765] Loss_D: 0.0944 Loss_G: 0.0375 Convergence: 0.0957 k= 0.019279 lr = 0.0000044\n",
      "[18/25][9120/9765] Loss_D: 0.0932 Loss_G: 0.0384 Convergence: 0.0948 k= 0.019279 lr = 0.0000044\n",
      "[18/25][9130/9765] Loss_D: 0.1039 Loss_G: 0.0373 Convergence: 0.1092 k= 0.019279 lr = 0.0000044\n",
      "[18/25][9140/9765] Loss_D: 0.0936 Loss_G: 0.0380 Convergence: 0.0946 k= 0.019293 lr = 0.0000044\n",
      "[18/25][9150/9765] Loss_D: 0.0974 Loss_G: 0.0385 Convergence: 0.0989 k= 0.019296 lr = 0.0000044\n",
      "[18/25][9160/9765] Loss_D: 0.0956 Loss_G: 0.0413 Convergence: 0.0991 k= 0.019290 lr = 0.0000044\n",
      "[18/25][9170/9765] Loss_D: 0.1003 Loss_G: 0.0386 Convergence: 0.1029 k= 0.019283 lr = 0.0000044\n",
      "[18/25][9180/9765] Loss_D: 0.0974 Loss_G: 0.0396 Convergence: 0.0985 k= 0.019287 lr = 0.0000044\n",
      "[18/25][9190/9765] Loss_D: 0.1043 Loss_G: 0.0399 Convergence: 0.1072 k= 0.019281 lr = 0.0000044\n",
      "[18/25][9200/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1005 k= 0.019275 lr = 0.0000044\n",
      "[18/25][9210/9765] Loss_D: 0.0983 Loss_G: 0.0385 Convergence: 0.1001 k= 0.019276 lr = 0.0000044\n",
      "[18/25][9220/9765] Loss_D: 0.0944 Loss_G: 0.0365 Convergence: 0.0967 k= 0.019287 lr = 0.0000044\n",
      "[18/25][9230/9765] Loss_D: 0.1061 Loss_G: 0.0373 Convergence: 0.1122 k= 0.019307 lr = 0.0000044\n",
      "[18/25][9240/9765] Loss_D: 0.0981 Loss_G: 0.0385 Convergence: 0.0998 k= 0.019310 lr = 0.0000044\n",
      "[18/25][9250/9765] Loss_D: 0.1003 Loss_G: 0.0372 Convergence: 0.1042 k= 0.019320 lr = 0.0000044\n",
      "[18/25][9260/9765] Loss_D: 0.0943 Loss_G: 0.0381 Convergence: 0.0951 k= 0.019330 lr = 0.0000044\n",
      "[18/25][9270/9765] Loss_D: 0.0975 Loss_G: 0.0391 Convergence: 0.0984 k= 0.019337 lr = 0.0000044\n",
      "[18/25][9280/9765] Loss_D: 0.0925 Loss_G: 0.0382 Convergence: 0.0941 k= 0.019337 lr = 0.0000044\n",
      "[18/25][9290/9765] Loss_D: 0.1037 Loss_G: 0.0374 Convergence: 0.1087 k= 0.019353 lr = 0.0000044\n",
      "[18/25][9300/9765] Loss_D: 0.0978 Loss_G: 0.0378 Convergence: 0.1002 k= 0.019357 lr = 0.0000044\n",
      "[18/25][9310/9765] Loss_D: 0.0909 Loss_G: 0.0389 Convergence: 0.0939 k= 0.019368 lr = 0.0000044\n",
      "[18/25][9320/9765] Loss_D: 0.0963 Loss_G: 0.0409 Convergence: 0.0991 k= 0.019367 lr = 0.0000044\n",
      "[18/25][9330/9765] Loss_D: 0.0928 Loss_G: 0.0423 Convergence: 0.0985 k= 0.019351 lr = 0.0000044\n",
      "[18/25][9340/9765] Loss_D: 0.0888 Loss_G: 0.0412 Convergence: 0.0950 k= 0.019337 lr = 0.0000044\n",
      "[18/25][9350/9765] Loss_D: 0.0946 Loss_G: 0.0368 Convergence: 0.0967 k= 0.019323 lr = 0.0000044\n",
      "[18/25][9360/9765] Loss_D: 0.0909 Loss_G: 0.0383 Convergence: 0.0933 k= 0.019336 lr = 0.0000044\n",
      "[18/25][9370/9765] Loss_D: 0.0896 Loss_G: 0.0391 Convergence: 0.0933 k= 0.019334 lr = 0.0000044\n",
      "[18/25][9380/9765] Loss_D: 0.0867 Loss_G: 0.0392 Convergence: 0.0917 k= 0.019327 lr = 0.0000044\n",
      "[18/25][9390/9765] Loss_D: 0.0934 Loss_G: 0.0394 Convergence: 0.0959 k= 0.019325 lr = 0.0000044\n",
      "[18/25][9400/9765] Loss_D: 0.0865 Loss_G: 0.0385 Convergence: 0.0909 k= 0.019330 lr = 0.0000044\n",
      "[18/25][9410/9765] Loss_D: 0.0966 Loss_G: 0.0378 Convergence: 0.0986 k= 0.019339 lr = 0.0000044\n",
      "[18/25][9420/9765] Loss_D: 0.0884 Loss_G: 0.0383 Convergence: 0.0917 k= 0.019331 lr = 0.0000044\n",
      "[18/25][9430/9765] Loss_D: 0.0938 Loss_G: 0.0372 Convergence: 0.0951 k= 0.019354 lr = 0.0000044\n",
      "[18/25][9440/9765] Loss_D: 0.0977 Loss_G: 0.0368 Convergence: 0.1011 k= 0.019362 lr = 0.0000044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/25][9450/9765] Loss_D: 0.0942 Loss_G: 0.0373 Convergence: 0.0956 k= 0.019374 lr = 0.0000044\n",
      "[18/25][9460/9765] Loss_D: 0.0992 Loss_G: 0.0395 Convergence: 0.1004 k= 0.019384 lr = 0.0000044\n",
      "[18/25][9470/9765] Loss_D: 0.0989 Loss_G: 0.0375 Convergence: 0.1019 k= 0.019405 lr = 0.0000044\n",
      "[18/25][9480/9765] Loss_D: 0.0912 Loss_G: 0.0391 Convergence: 0.0942 k= 0.019413 lr = 0.0000044\n",
      "[18/25][9490/9765] Loss_D: 0.1073 Loss_G: 0.0409 Convergence: 0.1104 k= 0.019421 lr = 0.0000044\n",
      "[18/25][9500/9765] Loss_D: 0.1031 Loss_G: 0.0421 Convergence: 0.1044 k= 0.019406 lr = 0.0000044\n",
      "[18/25][9510/9765] Loss_D: 0.0949 Loss_G: 0.0410 Convergence: 0.0984 k= 0.019391 lr = 0.0000044\n",
      "[18/25][9520/9765] Loss_D: 0.0988 Loss_G: 0.0418 Convergence: 0.1015 k= 0.019365 lr = 0.0000044\n",
      "[18/25][9530/9765] Loss_D: 0.0905 Loss_G: 0.0401 Convergence: 0.0948 k= 0.019343 lr = 0.0000044\n",
      "[18/25][9540/9765] Loss_D: 0.1068 Loss_G: 0.0409 Convergence: 0.1097 k= 0.019323 lr = 0.0000044\n",
      "[18/25][9550/9765] Loss_D: 0.0899 Loss_G: 0.0388 Convergence: 0.0932 k= 0.019307 lr = 0.0000044\n",
      "[18/25][9560/9765] Loss_D: 0.0857 Loss_G: 0.0380 Convergence: 0.0899 k= 0.019300 lr = 0.0000044\n",
      "[18/25][9570/9765] Loss_D: 0.0959 Loss_G: 0.0393 Convergence: 0.0973 k= 0.019305 lr = 0.0000044\n",
      "[18/25][9580/9765] Loss_D: 0.1050 Loss_G: 0.0383 Convergence: 0.1097 k= 0.019310 lr = 0.0000044\n",
      "[18/25][9590/9765] Loss_D: 0.0975 Loss_G: 0.0378 Convergence: 0.0997 k= 0.019322 lr = 0.0000044\n",
      "[18/25][9600/9765] Loss_D: 0.1052 Loss_G: 0.0371 Convergence: 0.1111 k= 0.019336 lr = 0.0000044\n",
      "[18/25][9610/9765] Loss_D: 0.0992 Loss_G: 0.0382 Convergence: 0.1018 k= 0.019350 lr = 0.0000044\n",
      "[18/25][9620/9765] Loss_D: 0.0896 Loss_G: 0.0385 Convergence: 0.0927 k= 0.019355 lr = 0.0000044\n",
      "[18/25][9630/9765] Loss_D: 0.0955 Loss_G: 0.0386 Convergence: 0.0964 k= 0.019369 lr = 0.0000044\n",
      "[18/25][9640/9765] Loss_D: 0.1029 Loss_G: 0.0400 Convergence: 0.1051 k= 0.019360 lr = 0.0000044\n",
      "[18/25][9650/9765] Loss_D: 0.0905 Loss_G: 0.0437 Convergence: 0.0985 k= 0.019332 lr = 0.0000044\n",
      "[18/25][9660/9765] Loss_D: 0.1025 Loss_G: 0.0468 Convergence: 0.1088 k= 0.019292 lr = 0.0000044\n",
      "[18/25][9670/9765] Loss_D: 0.0887 Loss_G: 0.0480 Convergence: 0.1017 k= 0.019206 lr = 0.0000044\n",
      "[18/25][9680/9765] Loss_D: 0.0975 Loss_G: 0.0465 Convergence: 0.1056 k= 0.019131 lr = 0.0000044\n",
      "[18/25][9690/9765] Loss_D: 0.0898 Loss_G: 0.0442 Convergence: 0.0986 k= 0.019071 lr = 0.0000044\n",
      "[18/25][9700/9765] Loss_D: 0.0932 Loss_G: 0.0418 Convergence: 0.0981 k= 0.019017 lr = 0.0000044\n",
      "[18/25][9710/9765] Loss_D: 0.0896 Loss_G: 0.0398 Convergence: 0.0940 k= 0.018984 lr = 0.0000044\n",
      "[18/25][9720/9765] Loss_D: 0.0992 Loss_G: 0.0386 Convergence: 0.1013 k= 0.018984 lr = 0.0000044\n",
      "[18/25][9730/9765] Loss_D: 0.1045 Loss_G: 0.0395 Convergence: 0.1079 k= 0.018975 lr = 0.0000044\n",
      "[18/25][9740/9765] Loss_D: 0.1058 Loss_G: 0.0368 Convergence: 0.1123 k= 0.018996 lr = 0.0000044\n",
      "[18/25][9750/9765] Loss_D: 0.1033 Loss_G: 0.0370 Convergence: 0.1087 k= 0.019021 lr = 0.0000044\n",
      "[18/25][9760/9765] Loss_D: 0.0909 Loss_G: 0.0368 Convergence: 0.0918 k= 0.019030 lr = 0.0000044\n",
      "[19/25][0/9765] Loss_D: 0.0988 Loss_G: 0.0359 Convergence: 0.1034 k= 0.019042 lr = 0.0000044\n",
      "[19/25][10/9765] Loss_D: 0.1016 Loss_G: 0.0378 Convergence: 0.1054 k= 0.019065 lr = 0.0000044\n",
      "[19/25][20/9765] Loss_D: 0.0974 Loss_G: 0.0373 Convergence: 0.1001 k= 0.019076 lr = 0.0000044\n",
      "[19/25][30/9765] Loss_D: 0.0973 Loss_G: 0.0396 Convergence: 0.0984 k= 0.019078 lr = 0.0000044\n",
      "[19/25][40/9765] Loss_D: 0.0996 Loss_G: 0.0372 Convergence: 0.1033 k= 0.019075 lr = 0.0000044\n",
      "[19/25][50/9765] Loss_D: 0.0903 Loss_G: 0.0393 Convergence: 0.0939 k= 0.019075 lr = 0.0000044\n",
      "[19/25][60/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0998 k= 0.019072 lr = 0.0000044\n",
      "[19/25][70/9765] Loss_D: 0.0927 Loss_G: 0.0385 Convergence: 0.0945 k= 0.019059 lr = 0.0000044\n",
      "[19/25][80/9765] Loss_D: 0.1091 Loss_G: 0.0396 Convergence: 0.1142 k= 0.019076 lr = 0.0000044\n",
      "[19/25][90/9765] Loss_D: 0.0913 Loss_G: 0.0401 Convergence: 0.0953 k= 0.019062 lr = 0.0000044\n",
      "[19/25][100/9765] Loss_D: 0.0871 Loss_G: 0.0397 Convergence: 0.0924 k= 0.019054 lr = 0.0000044\n",
      "[19/25][110/9765] Loss_D: 0.0940 Loss_G: 0.0390 Convergence: 0.0958 k= 0.019046 lr = 0.0000044\n",
      "[19/25][120/9765] Loss_D: 0.1036 Loss_G: 0.0400 Convergence: 0.1061 k= 0.019044 lr = 0.0000044\n",
      "[19/25][130/9765] Loss_D: 0.1001 Loss_G: 0.0392 Convergence: 0.1020 k= 0.019045 lr = 0.0000044\n",
      "[19/25][140/9765] Loss_D: 0.1010 Loss_G: 0.0384 Convergence: 0.1040 k= 0.019042 lr = 0.0000044\n",
      "[19/25][150/9765] Loss_D: 0.0884 Loss_G: 0.0389 Convergence: 0.0923 k= 0.019037 lr = 0.0000044\n",
      "[19/25][160/9765] Loss_D: 0.0953 Loss_G: 0.0388 Convergence: 0.0964 k= 0.019041 lr = 0.0000044\n",
      "[19/25][170/9765] Loss_D: 0.1031 Loss_G: 0.0387 Convergence: 0.1066 k= 0.019037 lr = 0.0000044\n",
      "[19/25][180/9765] Loss_D: 0.0940 Loss_G: 0.0392 Convergence: 0.0961 k= 0.019034 lr = 0.0000044\n",
      "[19/25][190/9765] Loss_D: 0.0967 Loss_G: 0.0380 Convergence: 0.0984 k= 0.019031 lr = 0.0000044\n",
      "[19/25][200/9765] Loss_D: 0.1041 Loss_G: 0.0397 Convergence: 0.1072 k= 0.019029 lr = 0.0000044\n",
      "[19/25][210/9765] Loss_D: 0.0999 Loss_G: 0.0373 Convergence: 0.1035 k= 0.019033 lr = 0.0000044\n",
      "[19/25][220/9765] Loss_D: 0.0927 Loss_G: 0.0393 Convergence: 0.0954 k= 0.019035 lr = 0.0000044\n",
      "[19/25][230/9765] Loss_D: 0.0937 Loss_G: 0.0389 Convergence: 0.0956 k= 0.019034 lr = 0.0000044\n",
      "[19/25][240/9765] Loss_D: 0.1027 Loss_G: 0.0406 Convergence: 0.1043 k= 0.019047 lr = 0.0000044\n",
      "[19/25][250/9765] Loss_D: 0.0999 Loss_G: 0.0402 Convergence: 0.1007 k= 0.019028 lr = 0.0000044\n",
      "[19/25][260/9765] Loss_D: 0.1000 Loss_G: 0.0379 Convergence: 0.1032 k= 0.019028 lr = 0.0000044\n",
      "[19/25][270/9765] Loss_D: 0.1049 Loss_G: 0.0393 Convergence: 0.1087 k= 0.019048 lr = 0.0000044\n",
      "[19/25][280/9765] Loss_D: 0.0883 Loss_G: 0.0390 Convergence: 0.0925 k= 0.019033 lr = 0.0000044\n",
      "[19/25][290/9765] Loss_D: 0.0950 Loss_G: 0.0375 Convergence: 0.0964 k= 0.019035 lr = 0.0000044\n",
      "[19/25][300/9765] Loss_D: 0.1013 Loss_G: 0.0402 Convergence: 0.1027 k= 0.019038 lr = 0.0000044\n",
      "[19/25][310/9765] Loss_D: 0.0972 Loss_G: 0.0388 Convergence: 0.0983 k= 0.019041 lr = 0.0000044\n",
      "[19/25][320/9765] Loss_D: 0.1012 Loss_G: 0.0383 Convergence: 0.1044 k= 0.019042 lr = 0.0000044\n",
      "[19/25][330/9765] Loss_D: 0.0897 Loss_G: 0.0381 Convergence: 0.0924 k= 0.019031 lr = 0.0000044\n",
      "[19/25][340/9765] Loss_D: 0.0873 Loss_G: 0.0375 Convergence: 0.0904 k= 0.019030 lr = 0.0000044\n",
      "[19/25][350/9765] Loss_D: 0.1000 Loss_G: 0.0374 Convergence: 0.1036 k= 0.019023 lr = 0.0000044\n",
      "[19/25][360/9765] Loss_D: 0.1064 Loss_G: 0.0389 Convergence: 0.1111 k= 0.019025 lr = 0.0000044\n",
      "[19/25][370/9765] Loss_D: 0.0925 Loss_G: 0.0368 Convergence: 0.0937 k= 0.019025 lr = 0.0000044\n",
      "[19/25][380/9765] Loss_D: 0.0989 Loss_G: 0.0395 Convergence: 0.0999 k= 0.019022 lr = 0.0000044\n",
      "[19/25][390/9765] Loss_D: 0.0926 Loss_G: 0.0382 Convergence: 0.0941 k= 0.019029 lr = 0.0000044\n",
      "[19/25][400/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0941 k= 0.019026 lr = 0.0000044\n",
      "[19/25][410/9765] Loss_D: 0.0975 Loss_G: 0.0389 Convergence: 0.0986 k= 0.019037 lr = 0.0000044\n",
      "[19/25][420/9765] Loss_D: 0.0907 Loss_G: 0.0400 Convergence: 0.0949 k= 0.019027 lr = 0.0000044\n",
      "[19/25][430/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0988 k= 0.019038 lr = 0.0000044\n",
      "[19/25][440/9765] Loss_D: 0.0923 Loss_G: 0.0379 Convergence: 0.0937 k= 0.019052 lr = 0.0000044\n",
      "[19/25][450/9765] Loss_D: 0.0959 Loss_G: 0.0393 Convergence: 0.0973 k= 0.019052 lr = 0.0000044\n",
      "[19/25][460/9765] Loss_D: 0.0935 Loss_G: 0.0393 Convergence: 0.0958 k= 0.019040 lr = 0.0000044\n",
      "[19/25][470/9765] Loss_D: 0.0890 Loss_G: 0.0380 Convergence: 0.0918 k= 0.019044 lr = 0.0000042\n",
      "[19/25][480/9765] Loss_D: 0.0989 Loss_G: 0.0387 Convergence: 0.1007 k= 0.019046 lr = 0.0000042\n",
      "[19/25][490/9765] Loss_D: 0.0839 Loss_G: 0.0380 Convergence: 0.0888 k= 0.019036 lr = 0.0000042\n",
      "[19/25][500/9765] Loss_D: 0.1039 Loss_G: 0.0395 Convergence: 0.1070 k= 0.019031 lr = 0.0000042\n",
      "[19/25][510/9765] Loss_D: 0.0928 Loss_G: 0.0380 Convergence: 0.0940 k= 0.019043 lr = 0.0000042\n",
      "[19/25][520/9765] Loss_D: 0.1033 Loss_G: 0.0385 Convergence: 0.1071 k= 0.019046 lr = 0.0000042\n",
      "[19/25][530/9765] Loss_D: 0.1019 Loss_G: 0.0379 Convergence: 0.1058 k= 0.019064 lr = 0.0000042\n",
      "[19/25][540/9765] Loss_D: 0.0919 Loss_G: 0.0377 Convergence: 0.0933 k= 0.019079 lr = 0.0000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][550/9765] Loss_D: 0.0914 Loss_G: 0.0390 Convergence: 0.0943 k= 0.019082 lr = 0.0000042\n",
      "[19/25][560/9765] Loss_D: 0.0969 Loss_G: 0.0397 Convergence: 0.0983 k= 0.019083 lr = 0.0000042\n",
      "[19/25][570/9765] Loss_D: 0.0976 Loss_G: 0.0386 Convergence: 0.0991 k= 0.019086 lr = 0.0000042\n",
      "[19/25][580/9765] Loss_D: 0.0850 Loss_G: 0.0382 Convergence: 0.0896 k= 0.019085 lr = 0.0000042\n",
      "[19/25][590/9765] Loss_D: 0.1013 Loss_G: 0.0407 Convergence: 0.1023 k= 0.019086 lr = 0.0000042\n",
      "[19/25][600/9765] Loss_D: 0.1053 Loss_G: 0.0391 Convergence: 0.1094 k= 0.019088 lr = 0.0000042\n",
      "[19/25][610/9765] Loss_D: 0.0997 Loss_G: 0.0393 Convergence: 0.1013 k= 0.019087 lr = 0.0000042\n",
      "[19/25][620/9765] Loss_D: 0.0867 Loss_G: 0.0382 Convergence: 0.0907 k= 0.019087 lr = 0.0000042\n",
      "[19/25][630/9765] Loss_D: 0.0969 Loss_G: 0.0371 Convergence: 0.0995 k= 0.019094 lr = 0.0000042\n",
      "[19/25][640/9765] Loss_D: 0.0949 Loss_G: 0.0396 Convergence: 0.0969 k= 0.019102 lr = 0.0000042\n",
      "[19/25][650/9765] Loss_D: 0.0923 Loss_G: 0.0377 Convergence: 0.0936 k= 0.019110 lr = 0.0000042\n",
      "[19/25][660/9765] Loss_D: 0.0965 Loss_G: 0.0380 Convergence: 0.0981 k= 0.019122 lr = 0.0000042\n",
      "[19/25][670/9765] Loss_D: 0.1001 Loss_G: 0.0380 Convergence: 0.1031 k= 0.019134 lr = 0.0000042\n",
      "[19/25][680/9765] Loss_D: 0.0944 Loss_G: 0.0382 Convergence: 0.0953 k= 0.019140 lr = 0.0000042\n",
      "[19/25][690/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.019146 lr = 0.0000042\n",
      "[19/25][700/9765] Loss_D: 0.0969 Loss_G: 0.0394 Convergence: 0.0980 k= 0.019139 lr = 0.0000042\n",
      "[19/25][710/9765] Loss_D: 0.1012 Loss_G: 0.0413 Convergence: 0.1025 k= 0.019130 lr = 0.0000042\n",
      "[19/25][720/9765] Loss_D: 0.0958 Loss_G: 0.0406 Convergence: 0.0985 k= 0.019132 lr = 0.0000042\n",
      "[19/25][730/9765] Loss_D: 0.0916 Loss_G: 0.0395 Convergence: 0.0949 k= 0.019131 lr = 0.0000042\n",
      "[19/25][740/9765] Loss_D: 0.0894 Loss_G: 0.0365 Convergence: 0.0906 k= 0.019134 lr = 0.0000042\n",
      "[19/25][750/9765] Loss_D: 0.1046 Loss_G: 0.0383 Convergence: 0.1091 k= 0.019135 lr = 0.0000042\n",
      "[19/25][760/9765] Loss_D: 0.1093 Loss_G: 0.0381 Convergence: 0.1160 k= 0.019152 lr = 0.0000042\n",
      "[19/25][770/9765] Loss_D: 0.0899 Loss_G: 0.0391 Convergence: 0.0935 k= 0.019151 lr = 0.0000042\n",
      "[19/25][780/9765] Loss_D: 0.0925 Loss_G: 0.0376 Convergence: 0.0935 k= 0.019157 lr = 0.0000042\n",
      "[19/25][790/9765] Loss_D: 0.1017 Loss_G: 0.0371 Convergence: 0.1063 k= 0.019161 lr = 0.0000042\n",
      "[19/25][800/9765] Loss_D: 0.0985 Loss_G: 0.0368 Convergence: 0.1021 k= 0.019177 lr = 0.0000042\n",
      "[19/25][810/9765] Loss_D: 0.0923 Loss_G: 0.0385 Convergence: 0.0943 k= 0.019191 lr = 0.0000042\n",
      "[19/25][820/9765] Loss_D: 0.1004 Loss_G: 0.0379 Convergence: 0.1037 k= 0.019204 lr = 0.0000042\n",
      "[19/25][830/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0953 k= 0.019214 lr = 0.0000042\n",
      "[19/25][840/9765] Loss_D: 0.1040 Loss_G: 0.0397 Convergence: 0.1069 k= 0.019221 lr = 0.0000042\n",
      "[19/25][850/9765] Loss_D: 0.0900 Loss_G: 0.0389 Convergence: 0.0934 k= 0.019208 lr = 0.0000042\n",
      "[19/25][860/9765] Loss_D: 0.0998 Loss_G: 0.0380 Convergence: 0.1027 k= 0.019199 lr = 0.0000042\n",
      "[19/25][870/9765] Loss_D: 0.0912 Loss_G: 0.0372 Convergence: 0.0923 k= 0.019197 lr = 0.0000042\n",
      "[19/25][880/9765] Loss_D: 0.0917 Loss_G: 0.0375 Convergence: 0.0930 k= 0.019210 lr = 0.0000042\n",
      "[19/25][890/9765] Loss_D: 0.0971 Loss_G: 0.0381 Convergence: 0.0988 k= 0.019216 lr = 0.0000042\n",
      "[19/25][900/9765] Loss_D: 0.1076 Loss_G: 0.0383 Convergence: 0.1134 k= 0.019231 lr = 0.0000042\n",
      "[19/25][910/9765] Loss_D: 0.0961 Loss_G: 0.0369 Convergence: 0.0986 k= 0.019241 lr = 0.0000042\n",
      "[19/25][920/9765] Loss_D: 0.1041 Loss_G: 0.0361 Convergence: 0.1107 k= 0.019259 lr = 0.0000042\n",
      "[19/25][930/9765] Loss_D: 0.0941 Loss_G: 0.0379 Convergence: 0.0949 k= 0.019276 lr = 0.0000042\n",
      "[19/25][940/9765] Loss_D: 0.1016 Loss_G: 0.0382 Convergence: 0.1051 k= 0.019288 lr = 0.0000042\n",
      "[19/25][950/9765] Loss_D: 0.0964 Loss_G: 0.0384 Convergence: 0.0976 k= 0.019288 lr = 0.0000042\n",
      "[19/25][960/9765] Loss_D: 0.1009 Loss_G: 0.0380 Convergence: 0.1043 k= 0.019293 lr = 0.0000042\n",
      "[19/25][970/9765] Loss_D: 0.1024 Loss_G: 0.0389 Convergence: 0.1054 k= 0.019294 lr = 0.0000042\n",
      "[19/25][980/9765] Loss_D: 0.0949 Loss_G: 0.0392 Convergence: 0.0966 k= 0.019289 lr = 0.0000042\n",
      "[19/25][990/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0990 k= 0.019285 lr = 0.0000042\n",
      "[19/25][1000/9765] Loss_D: 0.0849 Loss_G: 0.0376 Convergence: 0.0890 k= 0.019275 lr = 0.0000042\n",
      "[19/25][1010/9765] Loss_D: 0.0922 Loss_G: 0.0384 Convergence: 0.0942 k= 0.019272 lr = 0.0000042\n",
      "[19/25][1020/9765] Loss_D: 0.0931 Loss_G: 0.0402 Convergence: 0.0965 k= 0.019273 lr = 0.0000042\n",
      "[19/25][1030/9765] Loss_D: 0.0956 Loss_G: 0.0390 Convergence: 0.0968 k= 0.019275 lr = 0.0000042\n",
      "[19/25][1040/9765] Loss_D: 0.0894 Loss_G: 0.0387 Convergence: 0.0929 k= 0.019278 lr = 0.0000042\n",
      "[19/25][1050/9765] Loss_D: 0.0939 Loss_G: 0.0381 Convergence: 0.0949 k= 0.019271 lr = 0.0000042\n",
      "[19/25][1060/9765] Loss_D: 0.1061 Loss_G: 0.0367 Convergence: 0.1128 k= 0.019288 lr = 0.0000042\n",
      "[19/25][1070/9765] Loss_D: 0.0970 Loss_G: 0.0378 Convergence: 0.0990 k= 0.019309 lr = 0.0000042\n",
      "[19/25][1080/9765] Loss_D: 0.0925 Loss_G: 0.0395 Convergence: 0.0955 k= 0.019313 lr = 0.0000042\n",
      "[19/25][1090/9765] Loss_D: 0.0864 Loss_G: 0.0390 Convergence: 0.0913 k= 0.019299 lr = 0.0000042\n",
      "[19/25][1100/9765] Loss_D: 0.0990 Loss_G: 0.0399 Convergence: 0.0998 k= 0.019293 lr = 0.0000042\n",
      "[19/25][1110/9765] Loss_D: 0.1020 Loss_G: 0.0410 Convergence: 0.1029 k= 0.019302 lr = 0.0000042\n",
      "[19/25][1120/9765] Loss_D: 0.0937 Loss_G: 0.0402 Convergence: 0.0969 k= 0.019275 lr = 0.0000042\n",
      "[19/25][1130/9765] Loss_D: 0.0907 Loss_G: 0.0386 Convergence: 0.0934 k= 0.019265 lr = 0.0000042\n",
      "[19/25][1140/9765] Loss_D: 0.1007 Loss_G: 0.0413 Convergence: 0.1022 k= 0.019251 lr = 0.0000042\n",
      "[19/25][1150/9765] Loss_D: 0.1029 Loss_G: 0.0398 Convergence: 0.1054 k= 0.019239 lr = 0.0000042\n",
      "[19/25][1160/9765] Loss_D: 0.0997 Loss_G: 0.0387 Convergence: 0.1018 k= 0.019239 lr = 0.0000042\n",
      "[19/25][1170/9765] Loss_D: 0.0974 Loss_G: 0.0381 Convergence: 0.0993 k= 0.019232 lr = 0.0000042\n",
      "[19/25][1180/9765] Loss_D: 0.0902 Loss_G: 0.0386 Convergence: 0.0932 k= 0.019234 lr = 0.0000042\n",
      "[19/25][1190/9765] Loss_D: 0.0930 Loss_G: 0.0387 Convergence: 0.0949 k= 0.019242 lr = 0.0000042\n",
      "[19/25][1200/9765] Loss_D: 0.0939 Loss_G: 0.0380 Convergence: 0.0947 k= 0.019260 lr = 0.0000042\n",
      "[19/25][1210/9765] Loss_D: 0.0899 Loss_G: 0.0371 Convergence: 0.0915 k= 0.019265 lr = 0.0000042\n",
      "[19/25][1220/9765] Loss_D: 0.0940 Loss_G: 0.0373 Convergence: 0.0953 k= 0.019277 lr = 0.0000042\n",
      "[19/25][1230/9765] Loss_D: 0.1000 Loss_G: 0.0368 Convergence: 0.1042 k= 0.019301 lr = 0.0000042\n",
      "[19/25][1240/9765] Loss_D: 0.1005 Loss_G: 0.0354 Convergence: 0.1063 k= 0.019326 lr = 0.0000042\n",
      "[19/25][1250/9765] Loss_D: 0.0969 Loss_G: 0.0364 Convergence: 0.1002 k= 0.019356 lr = 0.0000042\n",
      "[19/25][1260/9765] Loss_D: 0.0937 Loss_G: 0.0380 Convergence: 0.0947 k= 0.019372 lr = 0.0000042\n",
      "[19/25][1270/9765] Loss_D: 0.0981 Loss_G: 0.0384 Convergence: 0.0999 k= 0.019382 lr = 0.0000042\n",
      "[19/25][1280/9765] Loss_D: 0.0923 Loss_G: 0.0398 Convergence: 0.0956 k= 0.019384 lr = 0.0000042\n",
      "[19/25][1290/9765] Loss_D: 0.0994 Loss_G: 0.0396 Convergence: 0.1007 k= 0.019382 lr = 0.0000042\n",
      "[19/25][1300/9765] Loss_D: 0.1034 Loss_G: 0.0420 Convergence: 0.1045 k= 0.019373 lr = 0.0000042\n",
      "[19/25][1310/9765] Loss_D: 0.0956 Loss_G: 0.0407 Convergence: 0.0985 k= 0.019357 lr = 0.0000042\n",
      "[19/25][1320/9765] Loss_D: 0.0926 Loss_G: 0.0419 Convergence: 0.0980 k= 0.019330 lr = 0.0000042\n",
      "[19/25][1330/9765] Loss_D: 0.0955 Loss_G: 0.0391 Convergence: 0.0969 k= 0.019308 lr = 0.0000042\n",
      "[19/25][1340/9765] Loss_D: 0.0922 Loss_G: 0.0407 Convergence: 0.0965 k= 0.019294 lr = 0.0000042\n",
      "[19/25][1350/9765] Loss_D: 0.0935 Loss_G: 0.0411 Convergence: 0.0977 k= 0.019272 lr = 0.0000042\n",
      "[19/25][1360/9765] Loss_D: 0.0901 Loss_G: 0.0389 Convergence: 0.0933 k= 0.019268 lr = 0.0000042\n",
      "[19/25][1370/9765] Loss_D: 0.0965 Loss_G: 0.0392 Convergence: 0.0976 k= 0.019263 lr = 0.0000042\n",
      "[19/25][1380/9765] Loss_D: 0.0941 Loss_G: 0.0392 Convergence: 0.0961 k= 0.019255 lr = 0.0000042\n",
      "[19/25][1390/9765] Loss_D: 0.0909 Loss_G: 0.0365 Convergence: 0.0918 k= 0.019262 lr = 0.0000042\n",
      "[19/25][1400/9765] Loss_D: 0.0998 Loss_G: 0.0383 Convergence: 0.1024 k= 0.019280 lr = 0.0000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][1410/9765] Loss_D: 0.0945 Loss_G: 0.0370 Convergence: 0.0963 k= 0.019294 lr = 0.0000042\n",
      "[19/25][1420/9765] Loss_D: 0.1126 Loss_G: 0.0390 Convergence: 0.1197 k= 0.019309 lr = 0.0000042\n",
      "[19/25][1430/9765] Loss_D: 0.1024 Loss_G: 0.0401 Convergence: 0.1044 k= 0.019324 lr = 0.0000042\n",
      "[19/25][1440/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0947 k= 0.019311 lr = 0.0000042\n",
      "[19/25][1450/9765] Loss_D: 0.1000 Loss_G: 0.0416 Convergence: 0.1021 k= 0.019304 lr = 0.0000042\n",
      "[19/25][1460/9765] Loss_D: 0.0955 Loss_G: 0.0391 Convergence: 0.0969 k= 0.019295 lr = 0.0000042\n",
      "[19/25][1470/9765] Loss_D: 0.1028 Loss_G: 0.0382 Convergence: 0.1066 k= 0.019300 lr = 0.0000042\n",
      "[19/25][1480/9765] Loss_D: 0.0899 Loss_G: 0.0384 Convergence: 0.0927 k= 0.019297 lr = 0.0000042\n",
      "[19/25][1490/9765] Loss_D: 0.0937 Loss_G: 0.0403 Convergence: 0.0970 k= 0.019299 lr = 0.0000042\n",
      "[19/25][1500/9765] Loss_D: 0.0980 Loss_G: 0.0404 Convergence: 0.0997 k= 0.019292 lr = 0.0000042\n",
      "[19/25][1510/9765] Loss_D: 0.0972 Loss_G: 0.0385 Convergence: 0.0986 k= 0.019283 lr = 0.0000042\n",
      "[19/25][1520/9765] Loss_D: 0.0929 Loss_G: 0.0377 Convergence: 0.0939 k= 0.019282 lr = 0.0000042\n",
      "[19/25][1530/9765] Loss_D: 0.1013 Loss_G: 0.0391 Convergence: 0.1037 k= 0.019293 lr = 0.0000042\n",
      "[19/25][1540/9765] Loss_D: 0.0940 Loss_G: 0.0382 Convergence: 0.0951 k= 0.019290 lr = 0.0000042\n",
      "[19/25][1550/9765] Loss_D: 0.0987 Loss_G: 0.0383 Convergence: 0.1008 k= 0.019294 lr = 0.0000042\n",
      "[19/25][1560/9765] Loss_D: 0.0947 Loss_G: 0.0358 Convergence: 0.0978 k= 0.019313 lr = 0.0000042\n",
      "[19/25][1570/9765] Loss_D: 0.0878 Loss_G: 0.0357 Convergence: 0.0887 k= 0.019335 lr = 0.0000042\n",
      "[19/25][1580/9765] Loss_D: 0.0904 Loss_G: 0.0367 Convergence: 0.0914 k= 0.019339 lr = 0.0000042\n",
      "[19/25][1590/9765] Loss_D: 0.0879 Loss_G: 0.0387 Convergence: 0.0918 k= 0.019337 lr = 0.0000042\n",
      "[19/25][1600/9765] Loss_D: 0.0956 Loss_G: 0.0378 Convergence: 0.0970 k= 0.019347 lr = 0.0000042\n",
      "[19/25][1610/9765] Loss_D: 0.1016 Loss_G: 0.0393 Convergence: 0.1039 k= 0.019352 lr = 0.0000042\n",
      "[19/25][1620/9765] Loss_D: 0.0977 Loss_G: 0.0392 Convergence: 0.0987 k= 0.019364 lr = 0.0000042\n",
      "[19/25][1630/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0940 k= 0.019367 lr = 0.0000042\n",
      "[19/25][1640/9765] Loss_D: 0.0977 Loss_G: 0.0391 Convergence: 0.0987 k= 0.019364 lr = 0.0000042\n",
      "[19/25][1650/9765] Loss_D: 0.0915 Loss_G: 0.0386 Convergence: 0.0939 k= 0.019358 lr = 0.0000042\n",
      "[19/25][1660/9765] Loss_D: 0.0961 Loss_G: 0.0380 Convergence: 0.0975 k= 0.019361 lr = 0.0000042\n",
      "[19/25][1670/9765] Loss_D: 0.0965 Loss_G: 0.0382 Convergence: 0.0979 k= 0.019371 lr = 0.0000042\n",
      "[19/25][1680/9765] Loss_D: 0.0931 Loss_G: 0.0383 Convergence: 0.0947 k= 0.019377 lr = 0.0000042\n",
      "[19/25][1690/9765] Loss_D: 0.1080 Loss_G: 0.0390 Convergence: 0.1133 k= 0.019388 lr = 0.0000042\n",
      "[19/25][1700/9765] Loss_D: 0.0961 Loss_G: 0.0372 Convergence: 0.0983 k= 0.019397 lr = 0.0000042\n",
      "[19/25][1710/9765] Loss_D: 0.0977 Loss_G: 0.0377 Convergence: 0.1001 k= 0.019412 lr = 0.0000042\n",
      "[19/25][1720/9765] Loss_D: 0.0985 Loss_G: 0.0391 Convergence: 0.0998 k= 0.019410 lr = 0.0000042\n",
      "[19/25][1730/9765] Loss_D: 0.0989 Loss_G: 0.0382 Convergence: 0.1013 k= 0.019409 lr = 0.0000042\n",
      "[19/25][1740/9765] Loss_D: 0.0900 Loss_G: 0.0382 Convergence: 0.0927 k= 0.019404 lr = 0.0000042\n",
      "[19/25][1750/9765] Loss_D: 0.1030 Loss_G: 0.0397 Convergence: 0.1055 k= 0.019408 lr = 0.0000042\n",
      "[19/25][1760/9765] Loss_D: 0.0919 Loss_G: 0.0367 Convergence: 0.0929 k= 0.019406 lr = 0.0000042\n",
      "[19/25][1770/9765] Loss_D: 0.0991 Loss_G: 0.0392 Convergence: 0.1006 k= 0.019418 lr = 0.0000042\n",
      "[19/25][1780/9765] Loss_D: 0.0905 Loss_G: 0.0366 Convergence: 0.0913 k= 0.019424 lr = 0.0000042\n",
      "[19/25][1790/9765] Loss_D: 0.1028 Loss_G: 0.0371 Convergence: 0.1078 k= 0.019434 lr = 0.0000042\n",
      "[19/25][1800/9765] Loss_D: 0.1058 Loss_G: 0.0377 Convergence: 0.1114 k= 0.019451 lr = 0.0000042\n",
      "[19/25][1810/9765] Loss_D: 0.1038 Loss_G: 0.0381 Convergence: 0.1083 k= 0.019462 lr = 0.0000042\n",
      "[19/25][1820/9765] Loss_D: 0.0930 Loss_G: 0.0394 Convergence: 0.0956 k= 0.019459 lr = 0.0000042\n",
      "[19/25][1830/9765] Loss_D: 0.0890 Loss_G: 0.0387 Convergence: 0.0925 k= 0.019454 lr = 0.0000042\n",
      "[19/25][1840/9765] Loss_D: 0.0998 Loss_G: 0.0392 Convergence: 0.1016 k= 0.019457 lr = 0.0000042\n",
      "[19/25][1850/9765] Loss_D: 0.0940 Loss_G: 0.0393 Convergence: 0.0961 k= 0.019449 lr = 0.0000042\n",
      "[19/25][1860/9765] Loss_D: 0.0874 Loss_G: 0.0392 Convergence: 0.0921 k= 0.019442 lr = 0.0000042\n",
      "[19/25][1870/9765] Loss_D: 0.0959 Loss_G: 0.0394 Convergence: 0.0974 k= 0.019434 lr = 0.0000042\n",
      "[19/25][1880/9765] Loss_D: 0.1012 Loss_G: 0.0373 Convergence: 0.1053 k= 0.019434 lr = 0.0000042\n",
      "[19/25][1890/9765] Loss_D: 0.1008 Loss_G: 0.0378 Convergence: 0.1044 k= 0.019437 lr = 0.0000042\n",
      "[19/25][1900/9765] Loss_D: 0.0998 Loss_G: 0.0402 Convergence: 0.1006 k= 0.019440 lr = 0.0000042\n",
      "[19/25][1910/9765] Loss_D: 0.0945 Loss_G: 0.0412 Convergence: 0.0984 k= 0.019435 lr = 0.0000042\n",
      "[19/25][1920/9765] Loss_D: 0.0952 Loss_G: 0.0403 Convergence: 0.0978 k= 0.019416 lr = 0.0000042\n",
      "[19/25][1930/9765] Loss_D: 0.1013 Loss_G: 0.0402 Convergence: 0.1027 k= 0.019402 lr = 0.0000042\n",
      "[19/25][1940/9765] Loss_D: 0.0916 Loss_G: 0.0407 Convergence: 0.0961 k= 0.019393 lr = 0.0000042\n",
      "[19/25][1950/9765] Loss_D: 0.0969 Loss_G: 0.0396 Convergence: 0.0982 k= 0.019367 lr = 0.0000042\n",
      "[19/25][1960/9765] Loss_D: 0.0912 Loss_G: 0.0407 Convergence: 0.0959 k= 0.019353 lr = 0.0000042\n",
      "[19/25][1970/9765] Loss_D: 0.0940 Loss_G: 0.0390 Convergence: 0.0958 k= 0.019337 lr = 0.0000042\n",
      "[19/25][1980/9765] Loss_D: 0.0988 Loss_G: 0.0403 Convergence: 0.1001 k= 0.019320 lr = 0.0000042\n",
      "[19/25][1990/9765] Loss_D: 0.0960 Loss_G: 0.0407 Convergence: 0.0988 k= 0.019302 lr = 0.0000042\n",
      "[19/25][2000/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.0999 k= 0.019281 lr = 0.0000042\n",
      "[19/25][2010/9765] Loss_D: 0.0998 Loss_G: 0.0391 Convergence: 0.1016 k= 0.019271 lr = 0.0000042\n",
      "[19/25][2020/9765] Loss_D: 0.1054 Loss_G: 0.0393 Convergence: 0.1094 k= 0.019276 lr = 0.0000042\n",
      "[19/25][2030/9765] Loss_D: 0.0991 Loss_G: 0.0388 Convergence: 0.1010 k= 0.019282 lr = 0.0000042\n",
      "[19/25][2040/9765] Loss_D: 0.0919 Loss_G: 0.0377 Convergence: 0.0933 k= 0.019288 lr = 0.0000042\n",
      "[19/25][2050/9765] Loss_D: 0.0942 Loss_G: 0.0389 Convergence: 0.0959 k= 0.019293 lr = 0.0000042\n",
      "[19/25][2060/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.019293 lr = 0.0000042\n",
      "[19/25][2070/9765] Loss_D: 0.0925 Loss_G: 0.0400 Convergence: 0.0959 k= 0.019302 lr = 0.0000042\n",
      "[19/25][2080/9765] Loss_D: 0.0974 Loss_G: 0.0409 Convergence: 0.0998 k= 0.019283 lr = 0.0000042\n",
      "[19/25][2090/9765] Loss_D: 0.0886 Loss_G: 0.0401 Convergence: 0.0938 k= 0.019265 lr = 0.0000042\n",
      "[19/25][2100/9765] Loss_D: 0.0975 Loss_G: 0.0396 Convergence: 0.0985 k= 0.019264 lr = 0.0000042\n",
      "[19/25][2110/9765] Loss_D: 0.1019 Loss_G: 0.0397 Convergence: 0.1040 k= 0.019253 lr = 0.0000042\n",
      "[19/25][2120/9765] Loss_D: 0.0940 Loss_G: 0.0374 Convergence: 0.0951 k= 0.019257 lr = 0.0000042\n",
      "[19/25][2130/9765] Loss_D: 0.1030 Loss_G: 0.0383 Convergence: 0.1069 k= 0.019272 lr = 0.0000042\n",
      "[19/25][2140/9765] Loss_D: 0.0979 Loss_G: 0.0398 Convergence: 0.0989 k= 0.019266 lr = 0.0000042\n",
      "[19/25][2150/9765] Loss_D: 0.1060 Loss_G: 0.0389 Convergence: 0.1106 k= 0.019261 lr = 0.0000042\n",
      "[19/25][2160/9765] Loss_D: 0.0981 Loss_G: 0.0392 Convergence: 0.0992 k= 0.019256 lr = 0.0000042\n",
      "[19/25][2170/9765] Loss_D: 0.0911 Loss_G: 0.0366 Convergence: 0.0920 k= 0.019262 lr = 0.0000042\n",
      "[19/25][2180/9765] Loss_D: 0.0931 Loss_G: 0.0382 Convergence: 0.0945 k= 0.019270 lr = 0.0000042\n",
      "[19/25][2190/9765] Loss_D: 0.0883 Loss_G: 0.0387 Convergence: 0.0921 k= 0.019272 lr = 0.0000042\n",
      "[19/25][2200/9765] Loss_D: 0.0952 Loss_G: 0.0387 Convergence: 0.0963 k= 0.019269 lr = 0.0000042\n",
      "[19/25][2210/9765] Loss_D: 0.1002 Loss_G: 0.0388 Convergence: 0.1025 k= 0.019267 lr = 0.0000042\n",
      "[19/25][2220/9765] Loss_D: 0.0929 Loss_G: 0.0379 Convergence: 0.0941 k= 0.019271 lr = 0.0000042\n",
      "[19/25][2230/9765] Loss_D: 0.0926 Loss_G: 0.0379 Convergence: 0.0939 k= 0.019283 lr = 0.0000042\n",
      "[19/25][2240/9765] Loss_D: 0.1008 Loss_G: 0.0386 Convergence: 0.1035 k= 0.019292 lr = 0.0000042\n",
      "[19/25][2250/9765] Loss_D: 0.0940 Loss_G: 0.0383 Convergence: 0.0951 k= 0.019296 lr = 0.0000042\n",
      "[19/25][2260/9765] Loss_D: 0.1022 Loss_G: 0.0385 Convergence: 0.1056 k= 0.019298 lr = 0.0000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][2270/9765] Loss_D: 0.0942 Loss_G: 0.0384 Convergence: 0.0954 k= 0.019297 lr = 0.0000042\n",
      "[19/25][2280/9765] Loss_D: 0.0946 Loss_G: 0.0396 Convergence: 0.0968 k= 0.019302 lr = 0.0000042\n",
      "[19/25][2290/9765] Loss_D: 0.0927 Loss_G: 0.0402 Convergence: 0.0963 k= 0.019289 lr = 0.0000042\n",
      "[19/25][2300/9765] Loss_D: 0.0928 Loss_G: 0.0400 Convergence: 0.0961 k= 0.019278 lr = 0.0000042\n",
      "[19/25][2310/9765] Loss_D: 0.0991 Loss_G: 0.0392 Convergence: 0.1006 k= 0.019280 lr = 0.0000042\n",
      "[19/25][2320/9765] Loss_D: 0.0919 Loss_G: 0.0386 Convergence: 0.0942 k= 0.019274 lr = 0.0000042\n",
      "[19/25][2330/9765] Loss_D: 0.0900 Loss_G: 0.0390 Convergence: 0.0934 k= 0.019274 lr = 0.0000042\n",
      "[19/25][2340/9765] Loss_D: 0.0968 Loss_G: 0.0382 Convergence: 0.0983 k= 0.019285 lr = 0.0000042\n",
      "[19/25][2350/9765] Loss_D: 0.0925 Loss_G: 0.0376 Convergence: 0.0935 k= 0.019289 lr = 0.0000042\n",
      "[19/25][2360/9765] Loss_D: 0.0837 Loss_G: 0.0379 Convergence: 0.0885 k= 0.019290 lr = 0.0000042\n",
      "[19/25][2370/9765] Loss_D: 0.0849 Loss_G: 0.0370 Convergence: 0.0884 k= 0.019296 lr = 0.0000042\n",
      "[19/25][2380/9765] Loss_D: 0.1010 Loss_G: 0.0364 Convergence: 0.1059 k= 0.019313 lr = 0.0000042\n",
      "[19/25][2390/9765] Loss_D: 0.0985 Loss_G: 0.0378 Convergence: 0.1010 k= 0.019331 lr = 0.0000042\n",
      "[19/25][2400/9765] Loss_D: 0.0946 Loss_G: 0.0394 Convergence: 0.0966 k= 0.019333 lr = 0.0000042\n",
      "[19/25][2410/9765] Loss_D: 0.0974 Loss_G: 0.0392 Convergence: 0.0982 k= 0.019332 lr = 0.0000042\n",
      "[19/25][2420/9765] Loss_D: 0.0967 Loss_G: 0.0412 Convergence: 0.0997 k= 0.019316 lr = 0.0000042\n",
      "[19/25][2430/9765] Loss_D: 0.1190 Loss_G: 0.0412 Convergence: 0.1265 k= 0.019309 lr = 0.0000042\n",
      "[19/25][2440/9765] Loss_D: 0.0981 Loss_G: 0.0421 Convergence: 0.1014 k= 0.019271 lr = 0.0000042\n",
      "[19/25][2450/9765] Loss_D: 0.0960 Loss_G: 0.0416 Convergence: 0.0997 k= 0.019251 lr = 0.0000042\n",
      "[19/25][2460/9765] Loss_D: 0.0897 Loss_G: 0.0410 Convergence: 0.0953 k= 0.019221 lr = 0.0000042\n",
      "[19/25][2470/9765] Loss_D: 0.0928 Loss_G: 0.0400 Convergence: 0.0961 k= 0.019204 lr = 0.0000042\n",
      "[19/25][2480/9765] Loss_D: 0.0977 Loss_G: 0.0399 Convergence: 0.0990 k= 0.019196 lr = 0.0000042\n",
      "[19/25][2490/9765] Loss_D: 0.0817 Loss_G: 0.0393 Convergence: 0.0888 k= 0.019178 lr = 0.0000042\n",
      "[19/25][2500/9765] Loss_D: 0.0987 Loss_G: 0.0376 Convergence: 0.1016 k= 0.019185 lr = 0.0000042\n",
      "[19/25][2510/9765] Loss_D: 0.0962 Loss_G: 0.0375 Convergence: 0.0982 k= 0.019191 lr = 0.0000042\n",
      "[19/25][2520/9765] Loss_D: 0.0874 Loss_G: 0.0381 Convergence: 0.0909 k= 0.019194 lr = 0.0000042\n",
      "[19/25][2530/9765] Loss_D: 0.0925 Loss_G: 0.0366 Convergence: 0.0938 k= 0.019199 lr = 0.0000042\n",
      "[19/25][2540/9765] Loss_D: 0.0890 Loss_G: 0.0363 Convergence: 0.0902 k= 0.019198 lr = 0.0000042\n",
      "[19/25][2550/9765] Loss_D: 0.1053 Loss_G: 0.0376 Convergence: 0.1108 k= 0.019209 lr = 0.0000042\n",
      "[19/25][2560/9765] Loss_D: 0.0950 Loss_G: 0.0381 Convergence: 0.0959 k= 0.019211 lr = 0.0000042\n",
      "[19/25][2570/9765] Loss_D: 0.0995 Loss_G: 0.0400 Convergence: 0.1003 k= 0.019221 lr = 0.0000042\n",
      "[19/25][2580/9765] Loss_D: 0.0952 Loss_G: 0.0404 Convergence: 0.0980 k= 0.019210 lr = 0.0000042\n",
      "[19/25][2590/9765] Loss_D: 0.1055 Loss_G: 0.0395 Convergence: 0.1093 k= 0.019194 lr = 0.0000042\n",
      "[19/25][2600/9765] Loss_D: 0.0858 Loss_G: 0.0398 Convergence: 0.0917 k= 0.019170 lr = 0.0000042\n",
      "[19/25][2610/9765] Loss_D: 0.0908 Loss_G: 0.0421 Convergence: 0.0971 k= 0.019139 lr = 0.0000042\n",
      "[19/25][2620/9765] Loss_D: 0.0979 Loss_G: 0.0387 Convergence: 0.0995 k= 0.019129 lr = 0.0000042\n",
      "[19/25][2630/9765] Loss_D: 0.0939 Loss_G: 0.0412 Convergence: 0.0980 k= 0.019118 lr = 0.0000042\n",
      "[19/25][2640/9765] Loss_D: 0.0967 Loss_G: 0.0395 Convergence: 0.0980 k= 0.019104 lr = 0.0000042\n",
      "[19/25][2650/9765] Loss_D: 0.0886 Loss_G: 0.0387 Convergence: 0.0923 k= 0.019093 lr = 0.0000042\n",
      "[19/25][2660/9765] Loss_D: 0.1017 Loss_G: 0.0389 Convergence: 0.1045 k= 0.019095 lr = 0.0000042\n",
      "[19/25][2670/9765] Loss_D: 0.1005 Loss_G: 0.0376 Convergence: 0.1041 k= 0.019107 lr = 0.0000042\n",
      "[19/25][2680/9765] Loss_D: 0.0903 Loss_G: 0.0371 Convergence: 0.0917 k= 0.019127 lr = 0.0000042\n",
      "[19/25][2690/9765] Loss_D: 0.0960 Loss_G: 0.0370 Convergence: 0.0984 k= 0.019150 lr = 0.0000042\n",
      "[19/25][2700/9765] Loss_D: 0.0924 Loss_G: 0.0381 Convergence: 0.0939 k= 0.019177 lr = 0.0000042\n",
      "[19/25][2710/9765] Loss_D: 0.0968 Loss_G: 0.0394 Convergence: 0.0980 k= 0.019181 lr = 0.0000042\n",
      "[19/25][2720/9765] Loss_D: 0.0940 Loss_G: 0.0384 Convergence: 0.0952 k= 0.019178 lr = 0.0000042\n",
      "[19/25][2730/9765] Loss_D: 0.0979 Loss_G: 0.0392 Convergence: 0.0989 k= 0.019182 lr = 0.0000042\n",
      "[19/25][2740/9765] Loss_D: 0.1010 Loss_G: 0.0384 Convergence: 0.1039 k= 0.019187 lr = 0.0000042\n",
      "[19/25][2750/9765] Loss_D: 0.0926 Loss_G: 0.0396 Convergence: 0.0956 k= 0.019180 lr = 0.0000042\n",
      "[19/25][2760/9765] Loss_D: 0.0827 Loss_G: 0.0385 Convergence: 0.0886 k= 0.019173 lr = 0.0000042\n",
      "[19/25][2770/9765] Loss_D: 0.0899 Loss_G: 0.0383 Convergence: 0.0926 k= 0.019170 lr = 0.0000042\n",
      "[19/25][2780/9765] Loss_D: 0.0978 Loss_G: 0.0398 Convergence: 0.0990 k= 0.019173 lr = 0.0000042\n",
      "[19/25][2790/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0985 k= 0.019172 lr = 0.0000042\n",
      "[19/25][2800/9765] Loss_D: 0.0952 Loss_G: 0.0397 Convergence: 0.0973 k= 0.019163 lr = 0.0000042\n",
      "[19/25][2810/9765] Loss_D: 0.0887 Loss_G: 0.0391 Convergence: 0.0928 k= 0.019154 lr = 0.0000042\n",
      "[19/25][2820/9765] Loss_D: 0.0984 Loss_G: 0.0396 Convergence: 0.0992 k= 0.019152 lr = 0.0000042\n",
      "[19/25][2830/9765] Loss_D: 0.0981 Loss_G: 0.0393 Convergence: 0.0991 k= 0.019144 lr = 0.0000042\n",
      "[19/25][2840/9765] Loss_D: 0.0974 Loss_G: 0.0390 Convergence: 0.0984 k= 0.019143 lr = 0.0000042\n",
      "[19/25][2850/9765] Loss_D: 0.0931 Loss_G: 0.0387 Convergence: 0.0950 k= 0.019143 lr = 0.0000042\n",
      "[19/25][2860/9765] Loss_D: 0.0980 Loss_G: 0.0378 Convergence: 0.1004 k= 0.019154 lr = 0.0000042\n",
      "[19/25][2870/9765] Loss_D: 0.1095 Loss_G: 0.0368 Convergence: 0.1175 k= 0.019172 lr = 0.0000042\n",
      "[19/25][2880/9765] Loss_D: 0.0854 Loss_G: 0.0391 Convergence: 0.0908 k= 0.019182 lr = 0.0000042\n",
      "[19/25][2890/9765] Loss_D: 0.1111 Loss_G: 0.0386 Convergence: 0.1180 k= 0.019200 lr = 0.0000042\n",
      "[19/25][2900/9765] Loss_D: 0.0929 Loss_G: 0.0389 Convergence: 0.0951 k= 0.019199 lr = 0.0000042\n",
      "[19/25][2910/9765] Loss_D: 0.1001 Loss_G: 0.0398 Convergence: 0.1015 k= 0.019193 lr = 0.0000042\n",
      "[19/25][2920/9765] Loss_D: 0.0949 Loss_G: 0.0381 Convergence: 0.0958 k= 0.019187 lr = 0.0000042\n",
      "[19/25][2930/9765] Loss_D: 0.0952 Loss_G: 0.0403 Convergence: 0.0979 k= 0.019186 lr = 0.0000042\n",
      "[19/25][2940/9765] Loss_D: 0.0940 Loss_G: 0.0397 Convergence: 0.0966 k= 0.019177 lr = 0.0000042\n",
      "[19/25][2950/9765] Loss_D: 0.0972 Loss_G: 0.0400 Convergence: 0.0987 k= 0.019178 lr = 0.0000042\n",
      "[19/25][2960/9765] Loss_D: 0.0882 Loss_G: 0.0387 Convergence: 0.0921 k= 0.019173 lr = 0.0000042\n",
      "[19/25][2970/9765] Loss_D: 0.1013 Loss_G: 0.0373 Convergence: 0.1055 k= 0.019184 lr = 0.0000042\n",
      "[19/25][2980/9765] Loss_D: 0.0874 Loss_G: 0.0394 Convergence: 0.0922 k= 0.019181 lr = 0.0000042\n",
      "[19/25][2990/9765] Loss_D: 0.1032 Loss_G: 0.0383 Convergence: 0.1072 k= 0.019186 lr = 0.0000042\n",
      "[19/25][3000/9765] Loss_D: 0.0905 Loss_G: 0.0369 Convergence: 0.0916 k= 0.019194 lr = 0.0000042\n",
      "[19/25][3010/9765] Loss_D: 0.0935 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019201 lr = 0.0000042\n",
      "[19/25][3020/9765] Loss_D: 0.0899 Loss_G: 0.0391 Convergence: 0.0935 k= 0.019197 lr = 0.0000042\n",
      "[19/25][3030/9765] Loss_D: 0.1015 Loss_G: 0.0393 Convergence: 0.1038 k= 0.019203 lr = 0.0000042\n",
      "[19/25][3040/9765] Loss_D: 0.0846 Loss_G: 0.0367 Convergence: 0.0879 k= 0.019186 lr = 0.0000042\n",
      "[19/25][3050/9765] Loss_D: 0.0883 Loss_G: 0.0395 Convergence: 0.0929 k= 0.019181 lr = 0.0000042\n",
      "[19/25][3060/9765] Loss_D: 0.0958 Loss_G: 0.0392 Convergence: 0.0972 k= 0.019195 lr = 0.0000042\n",
      "[19/25][3070/9765] Loss_D: 0.1002 Loss_G: 0.0384 Convergence: 0.1029 k= 0.019180 lr = 0.0000042\n",
      "[19/25][3080/9765] Loss_D: 0.1053 Loss_G: 0.0386 Convergence: 0.1099 k= 0.019182 lr = 0.0000042\n",
      "[19/25][3090/9765] Loss_D: 0.0999 Loss_G: 0.0394 Convergence: 0.1016 k= 0.019177 lr = 0.0000042\n",
      "[19/25][3100/9765] Loss_D: 0.0904 Loss_G: 0.0376 Convergence: 0.0923 k= 0.019180 lr = 0.0000042\n",
      "[19/25][3110/9765] Loss_D: 0.0965 Loss_G: 0.0382 Convergence: 0.0979 k= 0.019179 lr = 0.0000042\n",
      "[19/25][3120/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.1000 k= 0.019199 lr = 0.0000042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][3130/9765] Loss_D: 0.1005 Loss_G: 0.0378 Convergence: 0.1040 k= 0.019200 lr = 0.0000042\n",
      "[19/25][3140/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0970 k= 0.019209 lr = 0.0000042\n",
      "[19/25][3150/9765] Loss_D: 0.0921 Loss_G: 0.0389 Convergence: 0.0946 k= 0.019216 lr = 0.0000042\n",
      "[19/25][3160/9765] Loss_D: 0.1001 Loss_G: 0.0413 Convergence: 0.1018 k= 0.019212 lr = 0.0000042\n",
      "[19/25][3170/9765] Loss_D: 0.0929 Loss_G: 0.0411 Convergence: 0.0973 k= 0.019192 lr = 0.0000042\n",
      "[19/25][3180/9765] Loss_D: 0.0973 Loss_G: 0.0385 Convergence: 0.0987 k= 0.019183 lr = 0.0000042\n",
      "[19/25][3190/9765] Loss_D: 0.0982 Loss_G: 0.0406 Convergence: 0.1000 k= 0.019177 lr = 0.0000042\n",
      "[19/25][3200/9765] Loss_D: 0.1025 Loss_G: 0.0397 Convergence: 0.1049 k= 0.019160 lr = 0.0000042\n",
      "[19/25][3210/9765] Loss_D: 0.0992 Loss_G: 0.0387 Convergence: 0.1012 k= 0.019163 lr = 0.0000042\n",
      "[19/25][3220/9765] Loss_D: 0.0980 Loss_G: 0.0384 Convergence: 0.0998 k= 0.019182 lr = 0.0000042\n",
      "[19/25][3230/9765] Loss_D: 0.0971 Loss_G: 0.0389 Convergence: 0.0980 k= 0.019196 lr = 0.0000042\n",
      "[19/25][3240/9765] Loss_D: 0.1009 Loss_G: 0.0379 Convergence: 0.1044 k= 0.019204 lr = 0.0000042\n",
      "[19/25][3250/9765] Loss_D: 0.1050 Loss_G: 0.0394 Convergence: 0.1086 k= 0.019206 lr = 0.0000042\n",
      "[19/25][3260/9765] Loss_D: 0.1114 Loss_G: 0.0401 Convergence: 0.1169 k= 0.019209 lr = 0.0000042\n",
      "[19/25][3270/9765] Loss_D: 0.1064 Loss_G: 0.0388 Convergence: 0.1111 k= 0.019212 lr = 0.0000042\n",
      "[19/25][3280/9765] Loss_D: 0.1011 Loss_G: 0.0393 Convergence: 0.1033 k= 0.019205 lr = 0.0000042\n",
      "[19/25][3290/9765] Loss_D: 0.0903 Loss_G: 0.0389 Convergence: 0.0935 k= 0.019199 lr = 0.0000042\n",
      "[19/25][3300/9765] Loss_D: 0.0899 Loss_G: 0.0377 Convergence: 0.0920 k= 0.019196 lr = 0.0000042\n",
      "[19/25][3310/9765] Loss_D: 0.1046 Loss_G: 0.0387 Convergence: 0.1088 k= 0.019203 lr = 0.0000042\n",
      "[19/25][3320/9765] Loss_D: 0.0987 Loss_G: 0.0386 Convergence: 0.1006 k= 0.019202 lr = 0.0000042\n",
      "[19/25][3330/9765] Loss_D: 0.0824 Loss_G: 0.0374 Convergence: 0.0873 k= 0.019185 lr = 0.0000042\n",
      "[19/25][3340/9765] Loss_D: 0.0880 Loss_G: 0.0381 Convergence: 0.0914 k= 0.019181 lr = 0.0000042\n",
      "[19/25][3350/9765] Loss_D: 0.1024 Loss_G: 0.0368 Convergence: 0.1075 k= 0.019183 lr = 0.0000042\n",
      "[19/25][3360/9765] Loss_D: 0.0952 Loss_G: 0.0362 Convergence: 0.0980 k= 0.019189 lr = 0.0000042\n",
      "[19/25][3370/9765] Loss_D: 0.0922 Loss_G: 0.0363 Convergence: 0.0938 k= 0.019225 lr = 0.0000042\n",
      "[19/25][3380/9765] Loss_D: 0.0962 Loss_G: 0.0374 Convergence: 0.0984 k= 0.019261 lr = 0.0000042\n",
      "[19/25][3390/9765] Loss_D: 0.0883 Loss_G: 0.0370 Convergence: 0.0904 k= 0.019264 lr = 0.0000042\n",
      "[19/25][3400/9765] Loss_D: 0.0918 Loss_G: 0.0376 Convergence: 0.0932 k= 0.019278 lr = 0.0000042\n",
      "[19/25][3410/9765] Loss_D: 0.0952 Loss_G: 0.0387 Convergence: 0.0963 k= 0.019292 lr = 0.0000042\n",
      "[19/25][3420/9765] Loss_D: 0.0891 Loss_G: 0.0401 Convergence: 0.0941 k= 0.019287 lr = 0.0000042\n",
      "[19/25][3430/9765] Loss_D: 0.0873 Loss_G: 0.0388 Convergence: 0.0916 k= 0.019268 lr = 0.0000042\n",
      "[19/25][3440/9765] Loss_D: 0.0929 Loss_G: 0.0405 Convergence: 0.0967 k= 0.019250 lr = 0.0000042\n",
      "[19/25][3450/9765] Loss_D: 0.0927 Loss_G: 0.0398 Convergence: 0.0959 k= 0.019235 lr = 0.0000042\n",
      "[19/25][3460/9765] Loss_D: 0.0974 Loss_G: 0.0393 Convergence: 0.0982 k= 0.019230 lr = 0.0000042\n",
      "[19/25][3470/9765] Loss_D: 0.0969 Loss_G: 0.0402 Convergence: 0.0988 k= 0.019230 lr = 0.0000039\n",
      "[19/25][3480/9765] Loss_D: 0.1009 Loss_G: 0.0402 Convergence: 0.1022 k= 0.019222 lr = 0.0000039\n",
      "[19/25][3490/9765] Loss_D: 0.0985 Loss_G: 0.0401 Convergence: 0.0997 k= 0.019204 lr = 0.0000039\n",
      "[19/25][3500/9765] Loss_D: 0.0983 Loss_G: 0.0402 Convergence: 0.0997 k= 0.019207 lr = 0.0000039\n",
      "[19/25][3510/9765] Loss_D: 0.0893 Loss_G: 0.0417 Convergence: 0.0958 k= 0.019191 lr = 0.0000039\n",
      "[19/25][3520/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0974 k= 0.019177 lr = 0.0000039\n",
      "[19/25][3530/9765] Loss_D: 0.0957 Loss_G: 0.0390 Convergence: 0.0968 k= 0.019169 lr = 0.0000039\n",
      "[19/25][3540/9765] Loss_D: 0.0872 Loss_G: 0.0358 Convergence: 0.0885 k= 0.019174 lr = 0.0000039\n",
      "[19/25][3550/9765] Loss_D: 0.1039 Loss_G: 0.0376 Convergence: 0.1089 k= 0.019198 lr = 0.0000039\n",
      "[19/25][3560/9765] Loss_D: 0.1046 Loss_G: 0.0384 Convergence: 0.1090 k= 0.019212 lr = 0.0000039\n",
      "[19/25][3570/9765] Loss_D: 0.1085 Loss_G: 0.0389 Convergence: 0.1141 k= 0.019215 lr = 0.0000039\n",
      "[19/25][3580/9765] Loss_D: 0.0934 Loss_G: 0.0385 Convergence: 0.0950 k= 0.019221 lr = 0.0000039\n",
      "[19/25][3590/9765] Loss_D: 0.0975 Loss_G: 0.0358 Convergence: 0.1017 k= 0.019241 lr = 0.0000039\n",
      "[19/25][3600/9765] Loss_D: 0.0975 Loss_G: 0.0364 Convergence: 0.1011 k= 0.019268 lr = 0.0000039\n",
      "[19/25][3610/9765] Loss_D: 0.0935 Loss_G: 0.0376 Convergence: 0.0943 k= 0.019285 lr = 0.0000039\n",
      "[19/25][3620/9765] Loss_D: 0.1020 Loss_G: 0.0380 Convergence: 0.1058 k= 0.019288 lr = 0.0000039\n",
      "[19/25][3630/9765] Loss_D: 0.0956 Loss_G: 0.0392 Convergence: 0.0970 k= 0.019280 lr = 0.0000039\n",
      "[19/25][3640/9765] Loss_D: 0.0924 Loss_G: 0.0382 Convergence: 0.0941 k= 0.019269 lr = 0.0000039\n",
      "[19/25][3650/9765] Loss_D: 0.0863 Loss_G: 0.0392 Convergence: 0.0914 k= 0.019268 lr = 0.0000039\n",
      "[19/25][3660/9765] Loss_D: 0.0884 Loss_G: 0.0419 Convergence: 0.0954 k= 0.019250 lr = 0.0000039\n",
      "[19/25][3670/9765] Loss_D: 0.0961 Loss_G: 0.0408 Convergence: 0.0990 k= 0.019242 lr = 0.0000039\n",
      "[19/25][3680/9765] Loss_D: 0.0923 Loss_G: 0.0408 Convergence: 0.0967 k= 0.019224 lr = 0.0000039\n",
      "[19/25][3690/9765] Loss_D: 0.0940 Loss_G: 0.0404 Convergence: 0.0973 k= 0.019215 lr = 0.0000039\n",
      "[19/25][3700/9765] Loss_D: 0.0932 Loss_G: 0.0424 Convergence: 0.0988 k= 0.019186 lr = 0.0000039\n",
      "[19/25][3710/9765] Loss_D: 0.0964 Loss_G: 0.0418 Convergence: 0.1001 k= 0.019147 lr = 0.0000039\n",
      "[19/25][3720/9765] Loss_D: 0.0942 Loss_G: 0.0400 Convergence: 0.0970 k= 0.019130 lr = 0.0000039\n",
      "[19/25][3730/9765] Loss_D: 0.1022 Loss_G: 0.0403 Convergence: 0.1039 k= 0.019131 lr = 0.0000039\n",
      "[19/25][3740/9765] Loss_D: 0.0882 Loss_G: 0.0395 Convergence: 0.0929 k= 0.019122 lr = 0.0000039\n",
      "[19/25][3750/9765] Loss_D: 0.1025 Loss_G: 0.0401 Convergence: 0.1044 k= 0.019124 lr = 0.0000039\n",
      "[19/25][3760/9765] Loss_D: 0.0989 Loss_G: 0.0396 Convergence: 0.0999 k= 0.019130 lr = 0.0000039\n",
      "[19/25][3770/9765] Loss_D: 0.0881 Loss_G: 0.0368 Convergence: 0.0901 k= 0.019122 lr = 0.0000039\n",
      "[19/25][3780/9765] Loss_D: 0.0969 Loss_G: 0.0378 Convergence: 0.0988 k= 0.019146 lr = 0.0000039\n",
      "[19/25][3790/9765] Loss_D: 0.0882 Loss_G: 0.0353 Convergence: 0.0891 k= 0.019156 lr = 0.0000039\n",
      "[19/25][3800/9765] Loss_D: 0.0946 Loss_G: 0.0363 Convergence: 0.0972 k= 0.019183 lr = 0.0000039\n",
      "[19/25][3810/9765] Loss_D: 0.0917 Loss_G: 0.0367 Convergence: 0.0926 k= 0.019209 lr = 0.0000039\n",
      "[19/25][3820/9765] Loss_D: 0.0874 Loss_G: 0.0378 Convergence: 0.0907 k= 0.019212 lr = 0.0000039\n",
      "[19/25][3830/9765] Loss_D: 0.1008 Loss_G: 0.0383 Convergence: 0.1038 k= 0.019220 lr = 0.0000039\n",
      "[19/25][3840/9765] Loss_D: 0.0915 Loss_G: 0.0399 Convergence: 0.0953 k= 0.019225 lr = 0.0000039\n",
      "[19/25][3850/9765] Loss_D: 0.0977 Loss_G: 0.0411 Convergence: 0.1002 k= 0.019219 lr = 0.0000039\n",
      "[19/25][3860/9765] Loss_D: 0.1004 Loss_G: 0.0395 Convergence: 0.1020 k= 0.019194 lr = 0.0000039\n",
      "[19/25][3870/9765] Loss_D: 0.1065 Loss_G: 0.0399 Convergence: 0.1102 k= 0.019198 lr = 0.0000039\n",
      "[19/25][3880/9765] Loss_D: 0.0920 Loss_G: 0.0406 Convergence: 0.0963 k= 0.019181 lr = 0.0000039\n",
      "[19/25][3890/9765] Loss_D: 0.0975 Loss_G: 0.0397 Convergence: 0.0986 k= 0.019161 lr = 0.0000039\n",
      "[19/25][3900/9765] Loss_D: 0.1020 Loss_G: 0.0399 Convergence: 0.1039 k= 0.019159 lr = 0.0000039\n",
      "[19/25][3910/9765] Loss_D: 0.0916 Loss_G: 0.0399 Convergence: 0.0953 k= 0.019150 lr = 0.0000039\n",
      "[19/25][3920/9765] Loss_D: 0.0964 Loss_G: 0.0384 Convergence: 0.0976 k= 0.019139 lr = 0.0000039\n",
      "[19/25][3930/9765] Loss_D: 0.0901 Loss_G: 0.0417 Convergence: 0.0962 k= 0.019123 lr = 0.0000039\n",
      "[19/25][3940/9765] Loss_D: 0.0977 Loss_G: 0.0410 Convergence: 0.1002 k= 0.019105 lr = 0.0000039\n",
      "[19/25][3950/9765] Loss_D: 0.0955 Loss_G: 0.0396 Convergence: 0.0973 k= 0.019106 lr = 0.0000039\n",
      "[19/25][3960/9765] Loss_D: 0.0855 Loss_G: 0.0396 Convergence: 0.0914 k= 0.019099 lr = 0.0000039\n",
      "[19/25][3970/9765] Loss_D: 0.0864 Loss_G: 0.0371 Convergence: 0.0893 k= 0.019103 lr = 0.0000039\n",
      "[19/25][3980/9765] Loss_D: 0.1011 Loss_G: 0.0383 Convergence: 0.1042 k= 0.019112 lr = 0.0000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][3990/9765] Loss_D: 0.0951 Loss_G: 0.0381 Convergence: 0.0961 k= 0.019130 lr = 0.0000039\n",
      "[19/25][4000/9765] Loss_D: 0.1023 Loss_G: 0.0390 Convergence: 0.1052 k= 0.019146 lr = 0.0000039\n",
      "[19/25][4010/9765] Loss_D: 0.0963 Loss_G: 0.0379 Convergence: 0.0980 k= 0.019156 lr = 0.0000039\n",
      "[19/25][4020/9765] Loss_D: 0.1015 Loss_G: 0.0391 Convergence: 0.1040 k= 0.019161 lr = 0.0000039\n",
      "[19/25][4030/9765] Loss_D: 0.0937 Loss_G: 0.0395 Convergence: 0.0961 k= 0.019161 lr = 0.0000039\n",
      "[19/25][4040/9765] Loss_D: 0.0963 Loss_G: 0.0386 Convergence: 0.0973 k= 0.019139 lr = 0.0000039\n",
      "[19/25][4050/9765] Loss_D: 0.0998 Loss_G: 0.0398 Convergence: 0.1010 k= 0.019133 lr = 0.0000039\n",
      "[19/25][4060/9765] Loss_D: 0.0853 Loss_G: 0.0418 Convergence: 0.0934 k= 0.019109 lr = 0.0000039\n",
      "[19/25][4070/9765] Loss_D: 0.0990 Loss_G: 0.0402 Convergence: 0.1001 k= 0.019093 lr = 0.0000039\n",
      "[19/25][4080/9765] Loss_D: 0.0959 Loss_G: 0.0394 Convergence: 0.0974 k= 0.019086 lr = 0.0000039\n",
      "[19/25][4090/9765] Loss_D: 0.1023 Loss_G: 0.0383 Convergence: 0.1059 k= 0.019083 lr = 0.0000039\n",
      "[19/25][4100/9765] Loss_D: 0.0946 Loss_G: 0.0402 Convergence: 0.0974 k= 0.019060 lr = 0.0000039\n",
      "[19/25][4110/9765] Loss_D: 0.0952 Loss_G: 0.0386 Convergence: 0.0961 k= 0.019058 lr = 0.0000039\n",
      "[19/25][4120/9765] Loss_D: 0.0915 Loss_G: 0.0365 Convergence: 0.0926 k= 0.019073 lr = 0.0000039\n",
      "[19/25][4130/9765] Loss_D: 0.0979 Loss_G: 0.0385 Convergence: 0.0996 k= 0.019081 lr = 0.0000039\n",
      "[19/25][4140/9765] Loss_D: 0.1009 Loss_G: 0.0382 Convergence: 0.1041 k= 0.019074 lr = 0.0000039\n",
      "[19/25][4150/9765] Loss_D: 0.0948 Loss_G: 0.0377 Convergence: 0.0960 k= 0.019083 lr = 0.0000039\n",
      "[19/25][4160/9765] Loss_D: 0.0955 Loss_G: 0.0379 Convergence: 0.0969 k= 0.019080 lr = 0.0000039\n",
      "[19/25][4170/9765] Loss_D: 0.0991 Loss_G: 0.0373 Convergence: 0.1023 k= 0.019075 lr = 0.0000039\n",
      "[19/25][4180/9765] Loss_D: 0.0971 Loss_G: 0.0386 Convergence: 0.0983 k= 0.019103 lr = 0.0000039\n",
      "[19/25][4190/9765] Loss_D: 0.0998 Loss_G: 0.0387 Convergence: 0.1020 k= 0.019099 lr = 0.0000039\n",
      "[19/25][4200/9765] Loss_D: 0.0948 Loss_G: 0.0392 Convergence: 0.0966 k= 0.019100 lr = 0.0000039\n",
      "[19/25][4210/9765] Loss_D: 0.0982 Loss_G: 0.0384 Convergence: 0.1001 k= 0.019106 lr = 0.0000039\n",
      "[19/25][4220/9765] Loss_D: 0.0953 Loss_G: 0.0391 Convergence: 0.0967 k= 0.019116 lr = 0.0000039\n",
      "[19/25][4230/9765] Loss_D: 0.1009 Loss_G: 0.0379 Convergence: 0.1044 k= 0.019111 lr = 0.0000039\n",
      "[19/25][4240/9765] Loss_D: 0.0964 Loss_G: 0.0384 Convergence: 0.0975 k= 0.019117 lr = 0.0000039\n",
      "[19/25][4250/9765] Loss_D: 0.0958 Loss_G: 0.0379 Convergence: 0.0972 k= 0.019138 lr = 0.0000039\n",
      "[19/25][4260/9765] Loss_D: 0.1017 Loss_G: 0.0374 Convergence: 0.1061 k= 0.019142 lr = 0.0000039\n",
      "[19/25][4270/9765] Loss_D: 0.1002 Loss_G: 0.0395 Convergence: 0.1018 k= 0.019151 lr = 0.0000039\n",
      "[19/25][4280/9765] Loss_D: 0.0940 Loss_G: 0.0384 Convergence: 0.0953 k= 0.019156 lr = 0.0000039\n",
      "[19/25][4290/9765] Loss_D: 0.1031 Loss_G: 0.0394 Convergence: 0.1059 k= 0.019167 lr = 0.0000039\n",
      "[19/25][4300/9765] Loss_D: 0.1038 Loss_G: 0.0381 Convergence: 0.1083 k= 0.019177 lr = 0.0000039\n",
      "[19/25][4310/9765] Loss_D: 0.0966 Loss_G: 0.0400 Convergence: 0.0984 k= 0.019165 lr = 0.0000039\n",
      "[19/25][4320/9765] Loss_D: 0.0975 Loss_G: 0.0408 Convergence: 0.0998 k= 0.019157 lr = 0.0000039\n",
      "[19/25][4330/9765] Loss_D: 0.0899 Loss_G: 0.0388 Convergence: 0.0931 k= 0.019146 lr = 0.0000039\n",
      "[19/25][4340/9765] Loss_D: 0.0959 Loss_G: 0.0388 Convergence: 0.0968 k= 0.019151 lr = 0.0000039\n",
      "[19/25][4350/9765] Loss_D: 0.0935 Loss_G: 0.0391 Convergence: 0.0957 k= 0.019147 lr = 0.0000039\n",
      "[19/25][4360/9765] Loss_D: 0.0884 Loss_G: 0.0395 Convergence: 0.0930 k= 0.019134 lr = 0.0000039\n",
      "[19/25][4370/9765] Loss_D: 0.0988 Loss_G: 0.0383 Convergence: 0.1010 k= 0.019122 lr = 0.0000039\n",
      "[19/25][4380/9765] Loss_D: 0.0919 Loss_G: 0.0380 Convergence: 0.0935 k= 0.019125 lr = 0.0000039\n",
      "[19/25][4390/9765] Loss_D: 0.0891 Loss_G: 0.0378 Convergence: 0.0917 k= 0.019121 lr = 0.0000039\n",
      "[19/25][4400/9765] Loss_D: 0.0945 Loss_G: 0.0356 Convergence: 0.0977 k= 0.019133 lr = 0.0000039\n",
      "[19/25][4410/9765] Loss_D: 0.0907 Loss_G: 0.0359 Convergence: 0.0921 k= 0.019154 lr = 0.0000039\n",
      "[19/25][4420/9765] Loss_D: 0.0968 Loss_G: 0.0370 Convergence: 0.0995 k= 0.019169 lr = 0.0000039\n",
      "[19/25][4430/9765] Loss_D: 0.0963 Loss_G: 0.0382 Convergence: 0.0977 k= 0.019189 lr = 0.0000039\n",
      "[19/25][4440/9765] Loss_D: 0.1090 Loss_G: 0.0400 Convergence: 0.1137 k= 0.019193 lr = 0.0000039\n",
      "[19/25][4450/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0964 k= 0.019193 lr = 0.0000039\n",
      "[19/25][4460/9765] Loss_D: 0.0976 Loss_G: 0.0408 Convergence: 0.0999 k= 0.019172 lr = 0.0000039\n",
      "[19/25][4470/9765] Loss_D: 0.0966 Loss_G: 0.0392 Convergence: 0.0976 k= 0.019169 lr = 0.0000039\n",
      "[19/25][4480/9765] Loss_D: 0.0861 Loss_G: 0.0396 Convergence: 0.0917 k= 0.019151 lr = 0.0000039\n",
      "[19/25][4490/9765] Loss_D: 0.1010 Loss_G: 0.0407 Convergence: 0.1019 k= 0.019132 lr = 0.0000039\n",
      "[19/25][4500/9765] Loss_D: 0.0958 Loss_G: 0.0428 Convergence: 0.1007 k= 0.019111 lr = 0.0000039\n",
      "[19/25][4510/9765] Loss_D: 0.0897 Loss_G: 0.0408 Convergence: 0.0950 k= 0.019085 lr = 0.0000039\n",
      "[19/25][4520/9765] Loss_D: 0.1050 Loss_G: 0.0393 Convergence: 0.1087 k= 0.019081 lr = 0.0000039\n",
      "[19/25][4530/9765] Loss_D: 0.1000 Loss_G: 0.0389 Convergence: 0.1020 k= 0.019074 lr = 0.0000039\n",
      "[19/25][4540/9765] Loss_D: 0.0943 Loss_G: 0.0386 Convergence: 0.0956 k= 0.019065 lr = 0.0000039\n",
      "[19/25][4550/9765] Loss_D: 0.0945 Loss_G: 0.0378 Convergence: 0.0956 k= 0.019064 lr = 0.0000039\n",
      "[19/25][4560/9765] Loss_D: 0.0916 Loss_G: 0.0353 Convergence: 0.0939 k= 0.019081 lr = 0.0000039\n",
      "[19/25][4570/9765] Loss_D: 0.1028 Loss_G: 0.0365 Convergence: 0.1084 k= 0.019110 lr = 0.0000039\n",
      "[19/25][4580/9765] Loss_D: 0.1003 Loss_G: 0.0367 Convergence: 0.1047 k= 0.019139 lr = 0.0000039\n",
      "[19/25][4590/9765] Loss_D: 0.1074 Loss_G: 0.0383 Convergence: 0.1131 k= 0.019158 lr = 0.0000039\n",
      "[19/25][4600/9765] Loss_D: 0.0894 Loss_G: 0.0381 Convergence: 0.0922 k= 0.019162 lr = 0.0000039\n",
      "[19/25][4610/9765] Loss_D: 0.0938 Loss_G: 0.0396 Convergence: 0.0963 k= 0.019162 lr = 0.0000039\n",
      "[19/25][4620/9765] Loss_D: 0.0921 Loss_G: 0.0403 Convergence: 0.0960 k= 0.019161 lr = 0.0000039\n",
      "[19/25][4630/9765] Loss_D: 0.1033 Loss_G: 0.0413 Convergence: 0.1044 k= 0.019156 lr = 0.0000039\n",
      "[19/25][4640/9765] Loss_D: 0.1024 Loss_G: 0.0418 Convergence: 0.1037 k= 0.019124 lr = 0.0000039\n",
      "[19/25][4650/9765] Loss_D: 0.0852 Loss_G: 0.0413 Convergence: 0.0929 k= 0.019090 lr = 0.0000039\n",
      "[19/25][4660/9765] Loss_D: 0.0922 Loss_G: 0.0407 Convergence: 0.0965 k= 0.019065 lr = 0.0000039\n",
      "[19/25][4670/9765] Loss_D: 0.0959 Loss_G: 0.0413 Convergence: 0.0993 k= 0.019051 lr = 0.0000039\n",
      "[19/25][4680/9765] Loss_D: 0.1042 Loss_G: 0.0413 Convergence: 0.1057 k= 0.019037 lr = 0.0000039\n",
      "[19/25][4690/9765] Loss_D: 0.0876 Loss_G: 0.0390 Convergence: 0.0920 k= 0.019019 lr = 0.0000039\n",
      "[19/25][4700/9765] Loss_D: 0.0994 Loss_G: 0.0387 Convergence: 0.1015 k= 0.019022 lr = 0.0000039\n",
      "[19/25][4710/9765] Loss_D: 0.1033 Loss_G: 0.0369 Convergence: 0.1086 k= 0.019021 lr = 0.0000039\n",
      "[19/25][4720/9765] Loss_D: 0.0960 Loss_G: 0.0377 Convergence: 0.0977 k= 0.019027 lr = 0.0000039\n",
      "[19/25][4730/9765] Loss_D: 0.0969 Loss_G: 0.0379 Convergence: 0.0988 k= 0.019038 lr = 0.0000039\n",
      "[19/25][4740/9765] Loss_D: 0.0986 Loss_G: 0.0382 Convergence: 0.1009 k= 0.019048 lr = 0.0000039\n",
      "[19/25][4750/9765] Loss_D: 0.0850 Loss_G: 0.0365 Convergence: 0.0879 k= 0.019050 lr = 0.0000039\n",
      "[19/25][4760/9765] Loss_D: 0.0899 Loss_G: 0.0365 Convergence: 0.0908 k= 0.019056 lr = 0.0000039\n",
      "[19/25][4770/9765] Loss_D: 0.0907 Loss_G: 0.0378 Convergence: 0.0926 k= 0.019065 lr = 0.0000039\n",
      "[19/25][4780/9765] Loss_D: 0.1051 Loss_G: 0.0399 Convergence: 0.1083 k= 0.019067 lr = 0.0000039\n",
      "[19/25][4790/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0957 k= 0.019070 lr = 0.0000039\n",
      "[19/25][4800/9765] Loss_D: 0.1140 Loss_G: 0.0384 Convergence: 0.1222 k= 0.019084 lr = 0.0000039\n",
      "[19/25][4810/9765] Loss_D: 0.1065 Loss_G: 0.0384 Convergence: 0.1118 k= 0.019101 lr = 0.0000039\n",
      "[19/25][4820/9765] Loss_D: 0.1015 Loss_G: 0.0395 Convergence: 0.1037 k= 0.019098 lr = 0.0000039\n",
      "[19/25][4830/9765] Loss_D: 0.0880 Loss_G: 0.0392 Convergence: 0.0925 k= 0.019088 lr = 0.0000039\n",
      "[19/25][4840/9765] Loss_D: 0.1030 Loss_G: 0.0402 Convergence: 0.1051 k= 0.019080 lr = 0.0000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][4850/9765] Loss_D: 0.1002 Loss_G: 0.0394 Convergence: 0.1020 k= 0.019076 lr = 0.0000039\n",
      "[19/25][4860/9765] Loss_D: 0.0987 Loss_G: 0.0394 Convergence: 0.0998 k= 0.019075 lr = 0.0000039\n",
      "[19/25][4870/9765] Loss_D: 0.0960 Loss_G: 0.0386 Convergence: 0.0967 k= 0.019075 lr = 0.0000039\n",
      "[19/25][4880/9765] Loss_D: 0.1035 Loss_G: 0.0396 Convergence: 0.1064 k= 0.019084 lr = 0.0000039\n",
      "[19/25][4890/9765] Loss_D: 0.0978 Loss_G: 0.0382 Convergence: 0.0998 k= 0.019086 lr = 0.0000039\n",
      "[19/25][4900/9765] Loss_D: 0.0976 Loss_G: 0.0392 Convergence: 0.0985 k= 0.019095 lr = 0.0000039\n",
      "[19/25][4910/9765] Loss_D: 0.0995 Loss_G: 0.0380 Convergence: 0.1023 k= 0.019107 lr = 0.0000039\n",
      "[19/25][4920/9765] Loss_D: 0.0900 Loss_G: 0.0384 Convergence: 0.0929 k= 0.019102 lr = 0.0000039\n",
      "[19/25][4930/9765] Loss_D: 0.0952 Loss_G: 0.0387 Convergence: 0.0962 k= 0.019104 lr = 0.0000039\n",
      "[19/25][4940/9765] Loss_D: 0.0961 Loss_G: 0.0370 Convergence: 0.0986 k= 0.019123 lr = 0.0000039\n",
      "[19/25][4950/9765] Loss_D: 0.0983 Loss_G: 0.0384 Convergence: 0.1002 k= 0.019133 lr = 0.0000039\n",
      "[19/25][4960/9765] Loss_D: 0.1021 Loss_G: 0.0372 Convergence: 0.1068 k= 0.019141 lr = 0.0000039\n",
      "[19/25][4970/9765] Loss_D: 0.1066 Loss_G: 0.0381 Convergence: 0.1121 k= 0.019161 lr = 0.0000039\n",
      "[19/25][4980/9765] Loss_D: 0.0855 Loss_G: 0.0374 Convergence: 0.0891 k= 0.019180 lr = 0.0000039\n",
      "[19/25][4990/9765] Loss_D: 0.0943 Loss_G: 0.0375 Convergence: 0.0956 k= 0.019192 lr = 0.0000039\n",
      "[19/25][5000/9765] Loss_D: 0.0937 Loss_G: 0.0377 Convergence: 0.0944 k= 0.019207 lr = 0.0000039\n",
      "[19/25][5010/9765] Loss_D: 0.0942 Loss_G: 0.0384 Convergence: 0.0954 k= 0.019210 lr = 0.0000039\n",
      "[19/25][5020/9765] Loss_D: 0.0979 Loss_G: 0.0393 Convergence: 0.0989 k= 0.019212 lr = 0.0000039\n",
      "[19/25][5030/9765] Loss_D: 0.0922 Loss_G: 0.0375 Convergence: 0.0932 k= 0.019223 lr = 0.0000039\n",
      "[19/25][5040/9765] Loss_D: 0.0931 Loss_G: 0.0390 Convergence: 0.0954 k= 0.019229 lr = 0.0000039\n",
      "[19/25][5050/9765] Loss_D: 0.0974 Loss_G: 0.0372 Convergence: 0.1002 k= 0.019220 lr = 0.0000039\n",
      "[19/25][5060/9765] Loss_D: 0.1035 Loss_G: 0.0384 Convergence: 0.1075 k= 0.019223 lr = 0.0000039\n",
      "[19/25][5070/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0961 k= 0.019224 lr = 0.0000039\n",
      "[19/25][5080/9765] Loss_D: 0.0941 Loss_G: 0.0390 Convergence: 0.0959 k= 0.019222 lr = 0.0000039\n",
      "[19/25][5090/9765] Loss_D: 0.0956 Loss_G: 0.0386 Convergence: 0.0964 k= 0.019211 lr = 0.0000039\n",
      "[19/25][5100/9765] Loss_D: 0.0943 Loss_G: 0.0386 Convergence: 0.0956 k= 0.019210 lr = 0.0000039\n",
      "[19/25][5110/9765] Loss_D: 0.1025 Loss_G: 0.0389 Convergence: 0.1056 k= 0.019212 lr = 0.0000039\n",
      "[19/25][5120/9765] Loss_D: 0.0849 Loss_G: 0.0390 Convergence: 0.0904 k= 0.019217 lr = 0.0000039\n",
      "[19/25][5130/9765] Loss_D: 0.0930 Loss_G: 0.0390 Convergence: 0.0953 k= 0.019209 lr = 0.0000039\n",
      "[19/25][5140/9765] Loss_D: 0.0911 Loss_G: 0.0385 Convergence: 0.0936 k= 0.019203 lr = 0.0000039\n",
      "[19/25][5150/9765] Loss_D: 0.1087 Loss_G: 0.0382 Convergence: 0.1150 k= 0.019201 lr = 0.0000039\n",
      "[19/25][5160/9765] Loss_D: 0.0958 Loss_G: 0.0391 Convergence: 0.0970 k= 0.019212 lr = 0.0000039\n",
      "[19/25][5170/9765] Loss_D: 0.0889 Loss_G: 0.0388 Convergence: 0.0926 k= 0.019220 lr = 0.0000039\n",
      "[19/25][5180/9765] Loss_D: 0.0989 Loss_G: 0.0379 Convergence: 0.1017 k= 0.019209 lr = 0.0000039\n",
      "[19/25][5190/9765] Loss_D: 0.1043 Loss_G: 0.0403 Convergence: 0.1068 k= 0.019206 lr = 0.0000039\n",
      "[19/25][5200/9765] Loss_D: 0.0965 Loss_G: 0.0390 Convergence: 0.0974 k= 0.019208 lr = 0.0000039\n",
      "[19/25][5210/9765] Loss_D: 0.1001 Loss_G: 0.0375 Convergence: 0.1036 k= 0.019216 lr = 0.0000039\n",
      "[19/25][5220/9765] Loss_D: 0.0947 Loss_G: 0.0395 Convergence: 0.0968 k= 0.019229 lr = 0.0000039\n",
      "[19/25][5230/9765] Loss_D: 0.0957 Loss_G: 0.0413 Convergence: 0.0993 k= 0.019213 lr = 0.0000039\n",
      "[19/25][5240/9765] Loss_D: 0.0909 Loss_G: 0.0389 Convergence: 0.0939 k= 0.019199 lr = 0.0000039\n",
      "[19/25][5250/9765] Loss_D: 0.1039 Loss_G: 0.0407 Convergence: 0.1058 k= 0.019194 lr = 0.0000039\n",
      "[19/25][5260/9765] Loss_D: 0.0941 Loss_G: 0.0395 Convergence: 0.0964 k= 0.019200 lr = 0.0000039\n",
      "[19/25][5270/9765] Loss_D: 0.0926 Loss_G: 0.0388 Convergence: 0.0948 k= 0.019196 lr = 0.0000039\n",
      "[19/25][5280/9765] Loss_D: 0.0953 Loss_G: 0.0399 Convergence: 0.0975 k= 0.019193 lr = 0.0000039\n",
      "[19/25][5290/9765] Loss_D: 0.0966 Loss_G: 0.0394 Convergence: 0.0978 k= 0.019191 lr = 0.0000039\n",
      "[19/25][5300/9765] Loss_D: 0.0968 Loss_G: 0.0398 Convergence: 0.0983 k= 0.019207 lr = 0.0000039\n",
      "[19/25][5310/9765] Loss_D: 0.0980 Loss_G: 0.0384 Convergence: 0.0998 k= 0.019205 lr = 0.0000039\n",
      "[19/25][5320/9765] Loss_D: 0.0956 Loss_G: 0.0385 Convergence: 0.0963 k= 0.019205 lr = 0.0000039\n",
      "[19/25][5330/9765] Loss_D: 0.1072 Loss_G: 0.0394 Convergence: 0.1117 k= 0.019206 lr = 0.0000039\n",
      "[19/25][5340/9765] Loss_D: 0.0945 Loss_G: 0.0382 Convergence: 0.0954 k= 0.019193 lr = 0.0000039\n",
      "[19/25][5350/9765] Loss_D: 0.0942 Loss_G: 0.0397 Convergence: 0.0967 k= 0.019188 lr = 0.0000039\n",
      "[19/25][5360/9765] Loss_D: 0.1013 Loss_G: 0.0407 Convergence: 0.1022 k= 0.019181 lr = 0.0000039\n",
      "[19/25][5370/9765] Loss_D: 0.1006 Loss_G: 0.0402 Convergence: 0.1018 k= 0.019162 lr = 0.0000039\n",
      "[19/25][5380/9765] Loss_D: 0.1026 Loss_G: 0.0383 Convergence: 0.1064 k= 0.019160 lr = 0.0000039\n",
      "[19/25][5390/9765] Loss_D: 0.1010 Loss_G: 0.0388 Convergence: 0.1036 k= 0.019153 lr = 0.0000039\n",
      "[19/25][5400/9765] Loss_D: 0.0970 Loss_G: 0.0387 Convergence: 0.0981 k= 0.019158 lr = 0.0000039\n",
      "[19/25][5410/9765] Loss_D: 0.0956 Loss_G: 0.0381 Convergence: 0.0967 k= 0.019172 lr = 0.0000039\n",
      "[19/25][5420/9765] Loss_D: 0.0896 Loss_G: 0.0385 Convergence: 0.0927 k= 0.019170 lr = 0.0000039\n",
      "[19/25][5430/9765] Loss_D: 0.0908 Loss_G: 0.0370 Convergence: 0.0919 k= 0.019169 lr = 0.0000039\n",
      "[19/25][5440/9765] Loss_D: 0.1025 Loss_G: 0.0372 Convergence: 0.1074 k= 0.019187 lr = 0.0000039\n",
      "[19/25][5450/9765] Loss_D: 0.0988 Loss_G: 0.0368 Convergence: 0.1025 k= 0.019197 lr = 0.0000039\n",
      "[19/25][5460/9765] Loss_D: 0.0973 Loss_G: 0.0407 Convergence: 0.0995 k= 0.019198 lr = 0.0000039\n",
      "[19/25][5470/9765] Loss_D: 0.0913 Loss_G: 0.0379 Convergence: 0.0931 k= 0.019196 lr = 0.0000039\n",
      "[19/25][5480/9765] Loss_D: 0.0969 Loss_G: 0.0391 Convergence: 0.0977 k= 0.019201 lr = 0.0000039\n",
      "[19/25][5490/9765] Loss_D: 0.1033 Loss_G: 0.0382 Convergence: 0.1074 k= 0.019195 lr = 0.0000039\n",
      "[19/25][5500/9765] Loss_D: 0.1037 Loss_G: 0.0410 Convergence: 0.1052 k= 0.019210 lr = 0.0000039\n",
      "[19/25][5510/9765] Loss_D: 0.0900 Loss_G: 0.0412 Convergence: 0.0957 k= 0.019194 lr = 0.0000039\n",
      "[19/25][5520/9765] Loss_D: 0.0929 Loss_G: 0.0388 Convergence: 0.0951 k= 0.019186 lr = 0.0000039\n",
      "[19/25][5530/9765] Loss_D: 0.0965 Loss_G: 0.0398 Convergence: 0.0982 k= 0.019174 lr = 0.0000039\n",
      "[19/25][5540/9765] Loss_D: 0.1052 Loss_G: 0.0418 Convergence: 0.1065 k= 0.019151 lr = 0.0000039\n",
      "[19/25][5550/9765] Loss_D: 0.0970 Loss_G: 0.0405 Convergence: 0.0992 k= 0.019140 lr = 0.0000039\n",
      "[19/25][5560/9765] Loss_D: 0.1016 Loss_G: 0.0406 Convergence: 0.1027 k= 0.019126 lr = 0.0000039\n",
      "[19/25][5570/9765] Loss_D: 0.0985 Loss_G: 0.0406 Convergence: 0.1002 k= 0.019107 lr = 0.0000039\n",
      "[19/25][5580/9765] Loss_D: 0.0923 Loss_G: 0.0396 Convergence: 0.0955 k= 0.019097 lr = 0.0000039\n",
      "[19/25][5590/9765] Loss_D: 0.0985 Loss_G: 0.0403 Convergence: 0.0998 k= 0.019092 lr = 0.0000039\n",
      "[19/25][5600/9765] Loss_D: 0.0976 Loss_G: 0.0405 Convergence: 0.0996 k= 0.019084 lr = 0.0000039\n",
      "[19/25][5610/9765] Loss_D: 0.0923 Loss_G: 0.0397 Convergence: 0.0955 k= 0.019073 lr = 0.0000039\n",
      "[19/25][5620/9765] Loss_D: 0.0926 Loss_G: 0.0380 Convergence: 0.0941 k= 0.019066 lr = 0.0000039\n",
      "[19/25][5630/9765] Loss_D: 0.0978 Loss_G: 0.0370 Convergence: 0.1008 k= 0.019083 lr = 0.0000039\n",
      "[19/25][5640/9765] Loss_D: 0.0973 Loss_G: 0.0366 Convergence: 0.1006 k= 0.019102 lr = 0.0000039\n",
      "[19/25][5650/9765] Loss_D: 0.0894 Loss_G: 0.0360 Convergence: 0.0901 k= 0.019125 lr = 0.0000039\n",
      "[19/25][5660/9765] Loss_D: 0.0930 Loss_G: 0.0375 Convergence: 0.0937 k= 0.019149 lr = 0.0000039\n",
      "[19/25][5670/9765] Loss_D: 0.0928 Loss_G: 0.0379 Convergence: 0.0940 k= 0.019152 lr = 0.0000039\n",
      "[19/25][5680/9765] Loss_D: 0.0919 Loss_G: 0.0395 Convergence: 0.0950 k= 0.019147 lr = 0.0000039\n",
      "[19/25][5690/9765] Loss_D: 0.0922 Loss_G: 0.0400 Convergence: 0.0957 k= 0.019135 lr = 0.0000039\n",
      "[19/25][5700/9765] Loss_D: 0.1011 Loss_G: 0.0405 Convergence: 0.1022 k= 0.019120 lr = 0.0000039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][5710/9765] Loss_D: 0.0928 Loss_G: 0.0408 Convergence: 0.0969 k= 0.019092 lr = 0.0000039\n",
      "[19/25][5720/9765] Loss_D: 0.1038 Loss_G: 0.0422 Convergence: 0.1049 k= 0.019060 lr = 0.0000039\n",
      "[19/25][5730/9765] Loss_D: 0.0952 Loss_G: 0.0399 Convergence: 0.0975 k= 0.019035 lr = 0.0000039\n",
      "[19/25][5740/9765] Loss_D: 0.0957 Loss_G: 0.0393 Convergence: 0.0972 k= 0.019030 lr = 0.0000039\n",
      "[19/25][5750/9765] Loss_D: 0.0988 Loss_G: 0.0396 Convergence: 0.0998 k= 0.019023 lr = 0.0000039\n",
      "[19/25][5760/9765] Loss_D: 0.0882 Loss_G: 0.0393 Convergence: 0.0926 k= 0.019014 lr = 0.0000039\n",
      "[19/25][5770/9765] Loss_D: 0.0988 Loss_G: 0.0377 Convergence: 0.1016 k= 0.019014 lr = 0.0000039\n",
      "[19/25][5780/9765] Loss_D: 0.0991 Loss_G: 0.0368 Convergence: 0.1029 k= 0.019023 lr = 0.0000039\n",
      "[19/25][5790/9765] Loss_D: 0.1011 Loss_G: 0.0354 Convergence: 0.1071 k= 0.019042 lr = 0.0000039\n",
      "[19/25][5800/9765] Loss_D: 0.0938 Loss_G: 0.0370 Convergence: 0.0954 k= 0.019060 lr = 0.0000039\n",
      "[19/25][5810/9765] Loss_D: 0.0980 Loss_G: 0.0349 Convergence: 0.1032 k= 0.019063 lr = 0.0000039\n",
      "[19/25][5820/9765] Loss_D: 0.1007 Loss_G: 0.0366 Convergence: 0.1054 k= 0.019091 lr = 0.0000039\n",
      "[19/25][5830/9765] Loss_D: 0.0989 Loss_G: 0.0376 Convergence: 0.1018 k= 0.019113 lr = 0.0000039\n",
      "[19/25][5840/9765] Loss_D: 0.0927 Loss_G: 0.0378 Convergence: 0.0939 k= 0.019125 lr = 0.0000039\n",
      "[19/25][5850/9765] Loss_D: 0.0895 Loss_G: 0.0384 Convergence: 0.0925 k= 0.019129 lr = 0.0000039\n",
      "[19/25][5860/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0966 k= 0.019142 lr = 0.0000039\n",
      "[19/25][5870/9765] Loss_D: 0.0946 Loss_G: 0.0386 Convergence: 0.0958 k= 0.019128 lr = 0.0000039\n",
      "[19/25][5880/9765] Loss_D: 0.0924 Loss_G: 0.0408 Convergence: 0.0967 k= 0.019125 lr = 0.0000039\n",
      "[19/25][5890/9765] Loss_D: 0.0972 Loss_G: 0.0378 Convergence: 0.0993 k= 0.019102 lr = 0.0000039\n",
      "[19/25][5900/9765] Loss_D: 0.0892 Loss_G: 0.0394 Convergence: 0.0934 k= 0.019098 lr = 0.0000039\n",
      "[19/25][5910/9765] Loss_D: 0.0912 Loss_G: 0.0397 Convergence: 0.0949 k= 0.019084 lr = 0.0000039\n",
      "[19/25][5920/9765] Loss_D: 0.1024 Loss_G: 0.0389 Convergence: 0.1055 k= 0.019083 lr = 0.0000039\n",
      "[19/25][5930/9765] Loss_D: 0.0887 Loss_G: 0.0395 Convergence: 0.0931 k= 0.019066 lr = 0.0000039\n",
      "[19/25][5940/9765] Loss_D: 0.1017 Loss_G: 0.0396 Convergence: 0.1038 k= 0.019064 lr = 0.0000039\n",
      "[19/25][5950/9765] Loss_D: 0.0965 Loss_G: 0.0393 Convergence: 0.0977 k= 0.019065 lr = 0.0000039\n",
      "[19/25][5960/9765] Loss_D: 0.0998 Loss_G: 0.0394 Convergence: 0.1013 k= 0.019069 lr = 0.0000039\n",
      "[19/25][5970/9765] Loss_D: 0.0891 Loss_G: 0.0385 Convergence: 0.0924 k= 0.019065 lr = 0.0000039\n",
      "[19/25][5980/9765] Loss_D: 0.0928 Loss_G: 0.0386 Convergence: 0.0947 k= 0.019074 lr = 0.0000039\n",
      "[19/25][5990/9765] Loss_D: 0.0972 Loss_G: 0.0393 Convergence: 0.0981 k= 0.019090 lr = 0.0000039\n",
      "[19/25][6000/9765] Loss_D: 0.0950 Loss_G: 0.0383 Convergence: 0.0958 k= 0.019085 lr = 0.0000039\n",
      "[19/25][6010/9765] Loss_D: 0.1030 Loss_G: 0.0384 Convergence: 0.1068 k= 0.019084 lr = 0.0000039\n",
      "[19/25][6020/9765] Loss_D: 0.0906 Loss_G: 0.0381 Convergence: 0.0929 k= 0.019084 lr = 0.0000039\n",
      "[19/25][6030/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0975 k= 0.019084 lr = 0.0000039\n",
      "[19/25][6040/9765] Loss_D: 0.0924 Loss_G: 0.0387 Convergence: 0.0946 k= 0.019095 lr = 0.0000039\n",
      "[19/25][6050/9765] Loss_D: 0.1025 Loss_G: 0.0389 Convergence: 0.1057 k= 0.019115 lr = 0.0000039\n",
      "[19/25][6060/9765] Loss_D: 0.0970 Loss_G: 0.0379 Convergence: 0.0990 k= 0.019121 lr = 0.0000039\n",
      "[19/25][6070/9765] Loss_D: 0.0969 Loss_G: 0.0389 Convergence: 0.0977 k= 0.019131 lr = 0.0000039\n",
      "[19/25][6080/9765] Loss_D: 0.1002 Loss_G: 0.0386 Convergence: 0.1026 k= 0.019138 lr = 0.0000039\n",
      "[19/25][6090/9765] Loss_D: 0.1013 Loss_G: 0.0393 Convergence: 0.1035 k= 0.019132 lr = 0.0000039\n",
      "[19/25][6100/9765] Loss_D: 0.1061 Loss_G: 0.0396 Convergence: 0.1100 k= 0.019135 lr = 0.0000039\n",
      "[19/25][6110/9765] Loss_D: 0.0914 Loss_G: 0.0400 Convergence: 0.0953 k= 0.019116 lr = 0.0000039\n",
      "[19/25][6120/9765] Loss_D: 0.0907 Loss_G: 0.0395 Convergence: 0.0944 k= 0.019101 lr = 0.0000039\n",
      "[19/25][6130/9765] Loss_D: 0.0968 Loss_G: 0.0374 Convergence: 0.0991 k= 0.019108 lr = 0.0000039\n",
      "[19/25][6140/9765] Loss_D: 0.0955 Loss_G: 0.0383 Convergence: 0.0964 k= 0.019111 lr = 0.0000039\n",
      "[19/25][6150/9765] Loss_D: 0.0930 Loss_G: 0.0397 Convergence: 0.0959 k= 0.019102 lr = 0.0000039\n",
      "[19/25][6160/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.0999 k= 0.019103 lr = 0.0000039\n",
      "[19/25][6170/9765] Loss_D: 0.0966 Loss_G: 0.0401 Convergence: 0.0985 k= 0.019115 lr = 0.0000039\n",
      "[19/25][6180/9765] Loss_D: 0.0941 Loss_G: 0.0399 Convergence: 0.0968 k= 0.019104 lr = 0.0000039\n",
      "[19/25][6190/9765] Loss_D: 0.0908 Loss_G: 0.0394 Convergence: 0.0944 k= 0.019109 lr = 0.0000039\n",
      "[19/25][6200/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0964 k= 0.019114 lr = 0.0000039\n",
      "[19/25][6210/9765] Loss_D: 0.0906 Loss_G: 0.0388 Convergence: 0.0937 k= 0.019131 lr = 0.0000039\n",
      "[19/25][6220/9765] Loss_D: 0.0890 Loss_G: 0.0384 Convergence: 0.0923 k= 0.019136 lr = 0.0000039\n",
      "[19/25][6230/9765] Loss_D: 0.0902 Loss_G: 0.0388 Convergence: 0.0934 k= 0.019132 lr = 0.0000039\n",
      "[19/25][6240/9765] Loss_D: 0.1071 Loss_G: 0.0390 Convergence: 0.1119 k= 0.019133 lr = 0.0000039\n",
      "[19/25][6250/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0995 k= 0.019137 lr = 0.0000039\n",
      "[19/25][6260/9765] Loss_D: 0.1002 Loss_G: 0.0392 Convergence: 0.1022 k= 0.019141 lr = 0.0000039\n",
      "[19/25][6270/9765] Loss_D: 0.0940 Loss_G: 0.0383 Convergence: 0.0951 k= 0.019145 lr = 0.0000039\n",
      "[19/25][6280/9765] Loss_D: 0.0914 Loss_G: 0.0391 Convergence: 0.0945 k= 0.019137 lr = 0.0000039\n",
      "[19/25][6290/9765] Loss_D: 0.0942 Loss_G: 0.0383 Convergence: 0.0953 k= 0.019138 lr = 0.0000039\n",
      "[19/25][6300/9765] Loss_D: 0.0938 Loss_G: 0.0389 Convergence: 0.0957 k= 0.019155 lr = 0.0000039\n",
      "[19/25][6310/9765] Loss_D: 0.0919 Loss_G: 0.0389 Convergence: 0.0945 k= 0.019151 lr = 0.0000039\n",
      "[19/25][6320/9765] Loss_D: 0.0922 Loss_G: 0.0380 Convergence: 0.0938 k= 0.019145 lr = 0.0000039\n",
      "[19/25][6330/9765] Loss_D: 0.0972 Loss_G: 0.0387 Convergence: 0.0984 k= 0.019155 lr = 0.0000039\n",
      "[19/25][6340/9765] Loss_D: 0.0989 Loss_G: 0.0386 Convergence: 0.1009 k= 0.019158 lr = 0.0000039\n",
      "[19/25][6350/9765] Loss_D: 0.0946 Loss_G: 0.0388 Convergence: 0.0960 k= 0.019149 lr = 0.0000039\n",
      "[19/25][6360/9765] Loss_D: 0.1036 Loss_G: 0.0373 Convergence: 0.1087 k= 0.019139 lr = 0.0000039\n",
      "[19/25][6370/9765] Loss_D: 0.0957 Loss_G: 0.0399 Convergence: 0.0978 k= 0.019136 lr = 0.0000039\n",
      "[19/25][6380/9765] Loss_D: 0.0999 Loss_G: 0.0389 Convergence: 0.1020 k= 0.019143 lr = 0.0000039\n",
      "[19/25][6390/9765] Loss_D: 0.0942 Loss_G: 0.0397 Convergence: 0.0967 k= 0.019145 lr = 0.0000039\n",
      "[19/25][6400/9765] Loss_D: 0.0937 Loss_G: 0.0408 Convergence: 0.0975 k= 0.019144 lr = 0.0000039\n",
      "[19/25][6410/9765] Loss_D: 0.0936 Loss_G: 0.0388 Convergence: 0.0954 k= 0.019150 lr = 0.0000039\n",
      "[19/25][6420/9765] Loss_D: 0.1023 Loss_G: 0.0379 Convergence: 0.1063 k= 0.019159 lr = 0.0000039\n",
      "[19/25][6430/9765] Loss_D: 0.0898 Loss_G: 0.0386 Convergence: 0.0929 k= 0.019153 lr = 0.0000039\n",
      "[19/25][6440/9765] Loss_D: 0.0935 Loss_G: 0.0389 Convergence: 0.0954 k= 0.019160 lr = 0.0000039\n",
      "[19/25][6450/9765] Loss_D: 0.0946 Loss_G: 0.0392 Convergence: 0.0964 k= 0.019151 lr = 0.0000039\n",
      "[19/25][6460/9765] Loss_D: 0.0970 Loss_G: 0.0386 Convergence: 0.0983 k= 0.019144 lr = 0.0000039\n",
      "[19/25][6470/9765] Loss_D: 0.0959 Loss_G: 0.0403 Convergence: 0.0982 k= 0.019130 lr = 0.0000038\n",
      "[19/25][6480/9765] Loss_D: 0.0922 Loss_G: 0.0404 Convergence: 0.0961 k= 0.019123 lr = 0.0000038\n",
      "[19/25][6490/9765] Loss_D: 0.0867 Loss_G: 0.0400 Convergence: 0.0925 k= 0.019104 lr = 0.0000038\n",
      "[19/25][6500/9765] Loss_D: 0.0969 Loss_G: 0.0405 Convergence: 0.0991 k= 0.019100 lr = 0.0000038\n",
      "[19/25][6510/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0994 k= 0.019099 lr = 0.0000038\n",
      "[19/25][6520/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0955 k= 0.019098 lr = 0.0000038\n",
      "[19/25][6530/9765] Loss_D: 0.0998 Loss_G: 0.0393 Convergence: 0.1015 k= 0.019106 lr = 0.0000038\n",
      "[19/25][6540/9765] Loss_D: 0.1017 Loss_G: 0.0393 Convergence: 0.1041 k= 0.019100 lr = 0.0000038\n",
      "[19/25][6550/9765] Loss_D: 0.1008 Loss_G: 0.0377 Convergence: 0.1045 k= 0.019103 lr = 0.0000038\n",
      "[19/25][6560/9765] Loss_D: 0.0931 Loss_G: 0.0388 Convergence: 0.0951 k= 0.019108 lr = 0.0000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][6570/9765] Loss_D: 0.1020 Loss_G: 0.0377 Convergence: 0.1061 k= 0.019114 lr = 0.0000038\n",
      "[19/25][6580/9765] Loss_D: 0.0952 Loss_G: 0.0382 Convergence: 0.0962 k= 0.019118 lr = 0.0000038\n",
      "[19/25][6590/9765] Loss_D: 0.1010 Loss_G: 0.0399 Convergence: 0.1025 k= 0.019118 lr = 0.0000038\n",
      "[19/25][6600/9765] Loss_D: 0.1005 Loss_G: 0.0385 Convergence: 0.1032 k= 0.019124 lr = 0.0000038\n",
      "[19/25][6610/9765] Loss_D: 0.1113 Loss_G: 0.0405 Convergence: 0.1164 k= 0.019119 lr = 0.0000038\n",
      "[19/25][6620/9765] Loss_D: 0.1038 Loss_G: 0.0392 Convergence: 0.1072 k= 0.019124 lr = 0.0000038\n",
      "[19/25][6630/9765] Loss_D: 0.0972 Loss_G: 0.0388 Convergence: 0.0984 k= 0.019123 lr = 0.0000038\n",
      "[19/25][6640/9765] Loss_D: 0.0925 Loss_G: 0.0382 Convergence: 0.0941 k= 0.019126 lr = 0.0000038\n",
      "[19/25][6650/9765] Loss_D: 0.0987 Loss_G: 0.0400 Convergence: 0.0997 k= 0.019115 lr = 0.0000038\n",
      "[19/25][6660/9765] Loss_D: 0.0986 Loss_G: 0.0375 Convergence: 0.1016 k= 0.019112 lr = 0.0000038\n",
      "[19/25][6670/9765] Loss_D: 0.0981 Loss_G: 0.0416 Convergence: 0.1010 k= 0.019105 lr = 0.0000038\n",
      "[19/25][6680/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1000 k= 0.019088 lr = 0.0000038\n",
      "[19/25][6690/9765] Loss_D: 0.0914 Loss_G: 0.0413 Convergence: 0.0967 k= 0.019069 lr = 0.0000038\n",
      "[19/25][6700/9765] Loss_D: 0.0917 Loss_G: 0.0380 Convergence: 0.0935 k= 0.019058 lr = 0.0000038\n",
      "[19/25][6710/9765] Loss_D: 0.0979 Loss_G: 0.0387 Convergence: 0.0994 k= 0.019050 lr = 0.0000038\n",
      "[19/25][6720/9765] Loss_D: 0.0943 Loss_G: 0.0385 Convergence: 0.0956 k= 0.019056 lr = 0.0000038\n",
      "[19/25][6730/9765] Loss_D: 0.0939 Loss_G: 0.0395 Convergence: 0.0963 k= 0.019067 lr = 0.0000038\n",
      "[19/25][6740/9765] Loss_D: 0.1019 Loss_G: 0.0377 Convergence: 0.1059 k= 0.019060 lr = 0.0000038\n",
      "[19/25][6750/9765] Loss_D: 0.1054 Loss_G: 0.0379 Convergence: 0.1106 k= 0.019086 lr = 0.0000038\n",
      "[19/25][6760/9765] Loss_D: 0.0907 Loss_G: 0.0373 Convergence: 0.0922 k= 0.019099 lr = 0.0000038\n",
      "[19/25][6770/9765] Loss_D: 0.1012 Loss_G: 0.0397 Convergence: 0.1031 k= 0.019103 lr = 0.0000038\n",
      "[19/25][6780/9765] Loss_D: 0.1042 Loss_G: 0.0387 Convergence: 0.1083 k= 0.019101 lr = 0.0000038\n",
      "[19/25][6790/9765] Loss_D: 0.1003 Loss_G: 0.0389 Convergence: 0.1026 k= 0.019102 lr = 0.0000038\n",
      "[19/25][6800/9765] Loss_D: 0.0883 Loss_G: 0.0396 Convergence: 0.0930 k= 0.019089 lr = 0.0000038\n",
      "[19/25][6810/9765] Loss_D: 0.0914 Loss_G: 0.0384 Convergence: 0.0937 k= 0.019081 lr = 0.0000038\n",
      "[19/25][6820/9765] Loss_D: 0.0856 Loss_G: 0.0387 Convergence: 0.0905 k= 0.019082 lr = 0.0000038\n",
      "[19/25][6830/9765] Loss_D: 0.0979 Loss_G: 0.0391 Convergence: 0.0990 k= 0.019077 lr = 0.0000038\n",
      "[19/25][6840/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1010 k= 0.019080 lr = 0.0000038\n",
      "[19/25][6850/9765] Loss_D: 0.1095 Loss_G: 0.0391 Convergence: 0.1152 k= 0.019084 lr = 0.0000038\n",
      "[19/25][6860/9765] Loss_D: 0.0844 Loss_G: 0.0372 Convergence: 0.0883 k= 0.019074 lr = 0.0000038\n",
      "[19/25][6870/9765] Loss_D: 0.1064 Loss_G: 0.0374 Convergence: 0.1125 k= 0.019095 lr = 0.0000038\n",
      "[19/25][6880/9765] Loss_D: 0.0904 Loss_G: 0.0387 Convergence: 0.0933 k= 0.019089 lr = 0.0000038\n",
      "[19/25][6890/9765] Loss_D: 0.0914 Loss_G: 0.0387 Convergence: 0.0940 k= 0.019098 lr = 0.0000038\n",
      "[19/25][6900/9765] Loss_D: 0.0964 Loss_G: 0.0388 Convergence: 0.0972 k= 0.019107 lr = 0.0000038\n",
      "[19/25][6910/9765] Loss_D: 0.0932 Loss_G: 0.0373 Convergence: 0.0942 k= 0.019121 lr = 0.0000038\n",
      "[19/25][6920/9765] Loss_D: 0.0933 Loss_G: 0.0381 Convergence: 0.0945 k= 0.019139 lr = 0.0000038\n",
      "[19/25][6930/9765] Loss_D: 0.0897 Loss_G: 0.0383 Convergence: 0.0925 k= 0.019140 lr = 0.0000038\n",
      "[19/25][6940/9765] Loss_D: 0.1006 Loss_G: 0.0375 Convergence: 0.1044 k= 0.019144 lr = 0.0000038\n",
      "[19/25][6950/9765] Loss_D: 0.0876 Loss_G: 0.0389 Convergence: 0.0919 k= 0.019149 lr = 0.0000038\n",
      "[19/25][6960/9765] Loss_D: 0.1002 Loss_G: 0.0407 Convergence: 0.1013 k= 0.019129 lr = 0.0000038\n",
      "[19/25][6970/9765] Loss_D: 0.0919 Loss_G: 0.0380 Convergence: 0.0936 k= 0.019117 lr = 0.0000038\n",
      "[19/25][6980/9765] Loss_D: 0.0882 Loss_G: 0.0384 Convergence: 0.0918 k= 0.019116 lr = 0.0000038\n",
      "[19/25][6990/9765] Loss_D: 0.0964 Loss_G: 0.0394 Convergence: 0.0977 k= 0.019110 lr = 0.0000038\n",
      "[19/25][7000/9765] Loss_D: 0.0958 Loss_G: 0.0412 Convergence: 0.0992 k= 0.019105 lr = 0.0000038\n",
      "[19/25][7010/9765] Loss_D: 0.0935 Loss_G: 0.0407 Convergence: 0.0972 k= 0.019094 lr = 0.0000038\n",
      "[19/25][7020/9765] Loss_D: 0.0946 Loss_G: 0.0400 Convergence: 0.0972 k= 0.019081 lr = 0.0000038\n",
      "[19/25][7030/9765] Loss_D: 0.0999 Loss_G: 0.0398 Convergence: 0.1011 k= 0.019067 lr = 0.0000038\n",
      "[19/25][7040/9765] Loss_D: 0.0963 Loss_G: 0.0403 Convergence: 0.0985 k= 0.019056 lr = 0.0000038\n",
      "[19/25][7050/9765] Loss_D: 0.0899 Loss_G: 0.0400 Convergence: 0.0943 k= 0.019043 lr = 0.0000038\n",
      "[19/25][7060/9765] Loss_D: 0.1040 Loss_G: 0.0396 Convergence: 0.1070 k= 0.019041 lr = 0.0000038\n",
      "[19/25][7070/9765] Loss_D: 0.0958 Loss_G: 0.0378 Convergence: 0.0973 k= 0.019039 lr = 0.0000038\n",
      "[19/25][7080/9765] Loss_D: 0.1029 Loss_G: 0.0376 Convergence: 0.1075 k= 0.019045 lr = 0.0000038\n",
      "[19/25][7090/9765] Loss_D: 0.1024 Loss_G: 0.0371 Convergence: 0.1072 k= 0.019061 lr = 0.0000038\n",
      "[19/25][7100/9765] Loss_D: 0.1042 Loss_G: 0.0370 Convergence: 0.1099 k= 0.019077 lr = 0.0000038\n",
      "[19/25][7110/9765] Loss_D: 0.0928 Loss_G: 0.0376 Convergence: 0.0937 k= 0.019096 lr = 0.0000038\n",
      "[19/25][7120/9765] Loss_D: 0.1016 Loss_G: 0.0383 Convergence: 0.1050 k= 0.019107 lr = 0.0000038\n",
      "[19/25][7130/9765] Loss_D: 0.1115 Loss_G: 0.0376 Convergence: 0.1195 k= 0.019128 lr = 0.0000038\n",
      "[19/25][7140/9765] Loss_D: 0.0926 Loss_G: 0.0350 Convergence: 0.0955 k= 0.019150 lr = 0.0000038\n",
      "[19/25][7150/9765] Loss_D: 0.0879 Loss_G: 0.0381 Convergence: 0.0913 k= 0.019153 lr = 0.0000038\n",
      "[19/25][7160/9765] Loss_D: 0.0975 Loss_G: 0.0382 Convergence: 0.0993 k= 0.019160 lr = 0.0000038\n",
      "[19/25][7170/9765] Loss_D: 0.0981 Loss_G: 0.0381 Convergence: 0.1002 k= 0.019155 lr = 0.0000038\n",
      "[19/25][7180/9765] Loss_D: 0.0933 Loss_G: 0.0411 Convergence: 0.0975 k= 0.019146 lr = 0.0000038\n",
      "[19/25][7190/9765] Loss_D: 0.1017 Loss_G: 0.0385 Convergence: 0.1049 k= 0.019138 lr = 0.0000038\n",
      "[19/25][7200/9765] Loss_D: 0.0939 Loss_G: 0.0399 Convergence: 0.0968 k= 0.019131 lr = 0.0000038\n",
      "[19/25][7210/9765] Loss_D: 0.0975 Loss_G: 0.0402 Convergence: 0.0991 k= 0.019113 lr = 0.0000038\n",
      "[19/25][7220/9765] Loss_D: 0.0986 Loss_G: 0.0400 Convergence: 0.0996 k= 0.019104 lr = 0.0000038\n",
      "[19/25][7230/9765] Loss_D: 0.0961 Loss_G: 0.0388 Convergence: 0.0969 k= 0.019099 lr = 0.0000038\n",
      "[19/25][7240/9765] Loss_D: 0.0956 Loss_G: 0.0387 Convergence: 0.0965 k= 0.019102 lr = 0.0000038\n",
      "[19/25][7250/9765] Loss_D: 0.0945 Loss_G: 0.0383 Convergence: 0.0954 k= 0.019105 lr = 0.0000038\n",
      "[19/25][7260/9765] Loss_D: 0.0983 Loss_G: 0.0368 Convergence: 0.1018 k= 0.019114 lr = 0.0000038\n",
      "[19/25][7270/9765] Loss_D: 0.1002 Loss_G: 0.0383 Convergence: 0.1031 k= 0.019131 lr = 0.0000038\n",
      "[19/25][7280/9765] Loss_D: 0.0998 Loss_G: 0.0382 Convergence: 0.1026 k= 0.019136 lr = 0.0000038\n",
      "[19/25][7290/9765] Loss_D: 0.0992 Loss_G: 0.0395 Convergence: 0.1004 k= 0.019153 lr = 0.0000038\n",
      "[19/25][7300/9765] Loss_D: 0.0944 Loss_G: 0.0386 Convergence: 0.0957 k= 0.019138 lr = 0.0000038\n",
      "[19/25][7310/9765] Loss_D: 0.1016 Loss_G: 0.0367 Convergence: 0.1066 k= 0.019145 lr = 0.0000038\n",
      "[19/25][7320/9765] Loss_D: 0.0948 Loss_G: 0.0371 Convergence: 0.0966 k= 0.019177 lr = 0.0000038\n",
      "[19/25][7330/9765] Loss_D: 0.0956 Loss_G: 0.0369 Convergence: 0.0979 k= 0.019194 lr = 0.0000038\n",
      "[19/25][7340/9765] Loss_D: 0.1008 Loss_G: 0.0382 Convergence: 0.1038 k= 0.019202 lr = 0.0000038\n",
      "[19/25][7350/9765] Loss_D: 0.0850 Loss_G: 0.0383 Convergence: 0.0898 k= 0.019199 lr = 0.0000038\n",
      "[19/25][7360/9765] Loss_D: 0.0899 Loss_G: 0.0390 Convergence: 0.0934 k= 0.019198 lr = 0.0000038\n",
      "[19/25][7370/9765] Loss_D: 0.0923 Loss_G: 0.0398 Convergence: 0.0957 k= 0.019190 lr = 0.0000038\n",
      "[19/25][7380/9765] Loss_D: 0.0938 Loss_G: 0.0396 Convergence: 0.0963 k= 0.019177 lr = 0.0000038\n",
      "[19/25][7390/9765] Loss_D: 0.0912 Loss_G: 0.0393 Convergence: 0.0945 k= 0.019175 lr = 0.0000038\n",
      "[19/25][7400/9765] Loss_D: 0.0881 Loss_G: 0.0404 Convergence: 0.0938 k= 0.019161 lr = 0.0000038\n",
      "[19/25][7410/9765] Loss_D: 0.0978 Loss_G: 0.0405 Convergence: 0.0997 k= 0.019139 lr = 0.0000038\n",
      "[19/25][7420/9765] Loss_D: 0.0918 Loss_G: 0.0383 Convergence: 0.0938 k= 0.019126 lr = 0.0000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][7430/9765] Loss_D: 0.0960 Loss_G: 0.0398 Convergence: 0.0979 k= 0.019120 lr = 0.0000038\n",
      "[19/25][7440/9765] Loss_D: 0.0928 Loss_G: 0.0392 Convergence: 0.0953 k= 0.019097 lr = 0.0000038\n",
      "[19/25][7450/9765] Loss_D: 0.0999 Loss_G: 0.0385 Convergence: 0.1025 k= 0.019094 lr = 0.0000038\n",
      "[19/25][7460/9765] Loss_D: 0.0941 Loss_G: 0.0375 Convergence: 0.0952 k= 0.019100 lr = 0.0000038\n",
      "[19/25][7470/9765] Loss_D: 0.0958 Loss_G: 0.0380 Convergence: 0.0971 k= 0.019107 lr = 0.0000038\n",
      "[19/25][7480/9765] Loss_D: 0.0987 Loss_G: 0.0370 Convergence: 0.1022 k= 0.019120 lr = 0.0000038\n",
      "[19/25][7490/9765] Loss_D: 0.1060 Loss_G: 0.0385 Convergence: 0.1109 k= 0.019134 lr = 0.0000038\n",
      "[19/25][7500/9765] Loss_D: 0.1014 Loss_G: 0.0393 Convergence: 0.1038 k= 0.019138 lr = 0.0000038\n",
      "[19/25][7510/9765] Loss_D: 0.1008 Loss_G: 0.0385 Convergence: 0.1037 k= 0.019146 lr = 0.0000038\n",
      "[19/25][7520/9765] Loss_D: 0.1040 Loss_G: 0.0396 Convergence: 0.1070 k= 0.019153 lr = 0.0000038\n",
      "[19/25][7530/9765] Loss_D: 0.1112 Loss_G: 0.0408 Convergence: 0.1160 k= 0.019147 lr = 0.0000038\n",
      "[19/25][7540/9765] Loss_D: 0.1023 Loss_G: 0.0404 Convergence: 0.1039 k= 0.019140 lr = 0.0000038\n",
      "[19/25][7550/9765] Loss_D: 0.0891 Loss_G: 0.0398 Convergence: 0.0937 k= 0.019127 lr = 0.0000038\n",
      "[19/25][7560/9765] Loss_D: 0.0970 Loss_G: 0.0401 Convergence: 0.0987 k= 0.019111 lr = 0.0000038\n",
      "[19/25][7570/9765] Loss_D: 0.0999 Loss_G: 0.0395 Convergence: 0.1014 k= 0.019101 lr = 0.0000038\n",
      "[19/25][7580/9765] Loss_D: 0.0947 Loss_G: 0.0390 Convergence: 0.0962 k= 0.019093 lr = 0.0000038\n",
      "[19/25][7590/9765] Loss_D: 0.1027 Loss_G: 0.0391 Convergence: 0.1057 k= 0.019083 lr = 0.0000038\n",
      "[19/25][7600/9765] Loss_D: 0.0992 Loss_G: 0.0398 Convergence: 0.1001 k= 0.019077 lr = 0.0000038\n",
      "[19/25][7610/9765] Loss_D: 0.0997 Loss_G: 0.0389 Convergence: 0.1017 k= 0.019085 lr = 0.0000038\n",
      "[19/25][7620/9765] Loss_D: 0.0963 Loss_G: 0.0371 Convergence: 0.0987 k= 0.019096 lr = 0.0000038\n",
      "[19/25][7630/9765] Loss_D: 0.0998 Loss_G: 0.0369 Convergence: 0.1038 k= 0.019110 lr = 0.0000038\n",
      "[19/25][7640/9765] Loss_D: 0.0886 Loss_G: 0.0359 Convergence: 0.0895 k= 0.019129 lr = 0.0000038\n",
      "[19/25][7650/9765] Loss_D: 0.0926 Loss_G: 0.0364 Convergence: 0.0942 k= 0.019157 lr = 0.0000038\n",
      "[19/25][7660/9765] Loss_D: 0.1010 Loss_G: 0.0387 Convergence: 0.1038 k= 0.019170 lr = 0.0000038\n",
      "[19/25][7670/9765] Loss_D: 0.0983 Loss_G: 0.0374 Convergence: 0.1012 k= 0.019166 lr = 0.0000038\n",
      "[19/25][7680/9765] Loss_D: 0.0929 Loss_G: 0.0386 Convergence: 0.0948 k= 0.019175 lr = 0.0000038\n",
      "[19/25][7690/9765] Loss_D: 0.1029 Loss_G: 0.0395 Convergence: 0.1056 k= 0.019174 lr = 0.0000038\n",
      "[19/25][7700/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1032 k= 0.019172 lr = 0.0000038\n",
      "[19/25][7710/9765] Loss_D: 0.0983 Loss_G: 0.0401 Convergence: 0.0995 k= 0.019166 lr = 0.0000038\n",
      "[19/25][7720/9765] Loss_D: 0.1022 Loss_G: 0.0395 Convergence: 0.1047 k= 0.019160 lr = 0.0000038\n",
      "[19/25][7730/9765] Loss_D: 0.0967 Loss_G: 0.0402 Convergence: 0.0986 k= 0.019151 lr = 0.0000038\n",
      "[19/25][7740/9765] Loss_D: 0.0922 Loss_G: 0.0386 Convergence: 0.0944 k= 0.019132 lr = 0.0000038\n",
      "[19/25][7750/9765] Loss_D: 0.0923 Loss_G: 0.0375 Convergence: 0.0933 k= 0.019131 lr = 0.0000038\n",
      "[19/25][7760/9765] Loss_D: 0.0891 Loss_G: 0.0388 Convergence: 0.0927 k= 0.019125 lr = 0.0000038\n",
      "[19/25][7770/9765] Loss_D: 0.1007 Loss_G: 0.0394 Convergence: 0.1026 k= 0.019129 lr = 0.0000038\n",
      "[19/25][7780/9765] Loss_D: 0.0916 Loss_G: 0.0402 Convergence: 0.0956 k= 0.019124 lr = 0.0000038\n",
      "[19/25][7790/9765] Loss_D: 0.0916 Loss_G: 0.0379 Convergence: 0.0933 k= 0.019130 lr = 0.0000038\n",
      "[19/25][7800/9765] Loss_D: 0.1000 Loss_G: 0.0398 Convergence: 0.1012 k= 0.019141 lr = 0.0000038\n",
      "[19/25][7810/9765] Loss_D: 0.1011 Loss_G: 0.0381 Convergence: 0.1045 k= 0.019145 lr = 0.0000038\n",
      "[19/25][7820/9765] Loss_D: 0.0976 Loss_G: 0.0387 Convergence: 0.0989 k= 0.019158 lr = 0.0000038\n",
      "[19/25][7830/9765] Loss_D: 0.0929 Loss_G: 0.0364 Convergence: 0.0946 k= 0.019174 lr = 0.0000038\n",
      "[19/25][7840/9765] Loss_D: 0.0966 Loss_G: 0.0378 Convergence: 0.0984 k= 0.019181 lr = 0.0000038\n",
      "[19/25][7850/9765] Loss_D: 0.0991 Loss_G: 0.0369 Convergence: 0.1029 k= 0.019186 lr = 0.0000038\n",
      "[19/25][7860/9765] Loss_D: 0.0963 Loss_G: 0.0380 Convergence: 0.0978 k= 0.019202 lr = 0.0000038\n",
      "[19/25][7870/9765] Loss_D: 0.0886 Loss_G: 0.0393 Convergence: 0.0929 k= 0.019205 lr = 0.0000038\n",
      "[19/25][7880/9765] Loss_D: 0.0914 Loss_G: 0.0403 Convergence: 0.0956 k= 0.019198 lr = 0.0000038\n",
      "[19/25][7890/9765] Loss_D: 0.0957 Loss_G: 0.0376 Convergence: 0.0974 k= 0.019195 lr = 0.0000038\n",
      "[19/25][7900/9765] Loss_D: 0.0932 Loss_G: 0.0381 Convergence: 0.0945 k= 0.019206 lr = 0.0000038\n",
      "[19/25][7910/9765] Loss_D: 0.0894 Loss_G: 0.0399 Convergence: 0.0939 k= 0.019203 lr = 0.0000038\n",
      "[19/25][7920/9765] Loss_D: 0.1039 Loss_G: 0.0381 Convergence: 0.1084 k= 0.019204 lr = 0.0000038\n",
      "[19/25][7930/9765] Loss_D: 0.0896 Loss_G: 0.0389 Convergence: 0.0931 k= 0.019191 lr = 0.0000038\n",
      "[19/25][7940/9765] Loss_D: 0.0923 Loss_G: 0.0397 Convergence: 0.0955 k= 0.019181 lr = 0.0000038\n",
      "[19/25][7950/9765] Loss_D: 0.0977 Loss_G: 0.0397 Convergence: 0.0988 k= 0.019173 lr = 0.0000038\n",
      "[19/25][7960/9765] Loss_D: 0.0900 Loss_G: 0.0370 Convergence: 0.0914 k= 0.019174 lr = 0.0000038\n",
      "[19/25][7970/9765] Loss_D: 0.0941 Loss_G: 0.0408 Convergence: 0.0977 k= 0.019177 lr = 0.0000038\n",
      "[19/25][7980/9765] Loss_D: 0.0886 Loss_G: 0.0379 Convergence: 0.0914 k= 0.019177 lr = 0.0000038\n",
      "[19/25][7990/9765] Loss_D: 0.0975 Loss_G: 0.0393 Convergence: 0.0983 k= 0.019178 lr = 0.0000038\n",
      "[19/25][8000/9765] Loss_D: 0.0925 Loss_G: 0.0377 Convergence: 0.0937 k= 0.019166 lr = 0.0000038\n",
      "[19/25][8010/9765] Loss_D: 0.0975 Loss_G: 0.0368 Convergence: 0.1008 k= 0.019184 lr = 0.0000038\n",
      "[19/25][8020/9765] Loss_D: 0.0939 Loss_G: 0.0382 Convergence: 0.0949 k= 0.019203 lr = 0.0000038\n",
      "[19/25][8030/9765] Loss_D: 0.0953 Loss_G: 0.0386 Convergence: 0.0962 k= 0.019205 lr = 0.0000038\n",
      "[19/25][8040/9765] Loss_D: 0.1005 Loss_G: 0.0404 Convergence: 0.1014 k= 0.019195 lr = 0.0000038\n",
      "[19/25][8050/9765] Loss_D: 0.0978 Loss_G: 0.0390 Convergence: 0.0989 k= 0.019190 lr = 0.0000038\n",
      "[19/25][8060/9765] Loss_D: 0.0869 Loss_G: 0.0379 Convergence: 0.0905 k= 0.019198 lr = 0.0000038\n",
      "[19/25][8070/9765] Loss_D: 0.1069 Loss_G: 0.0392 Convergence: 0.1115 k= 0.019215 lr = 0.0000038\n",
      "[19/25][8080/9765] Loss_D: 0.0942 Loss_G: 0.0400 Convergence: 0.0970 k= 0.019216 lr = 0.0000038\n",
      "[19/25][8090/9765] Loss_D: 0.1028 Loss_G: 0.0420 Convergence: 0.1042 k= 0.019207 lr = 0.0000038\n",
      "[19/25][8100/9765] Loss_D: 0.1025 Loss_G: 0.0396 Convergence: 0.1049 k= 0.019197 lr = 0.0000038\n",
      "[19/25][8110/9765] Loss_D: 0.0969 Loss_G: 0.0400 Convergence: 0.0986 k= 0.019174 lr = 0.0000038\n",
      "[19/25][8120/9765] Loss_D: 0.0937 Loss_G: 0.0388 Convergence: 0.0955 k= 0.019161 lr = 0.0000038\n",
      "[19/25][8130/9765] Loss_D: 0.1028 Loss_G: 0.0381 Convergence: 0.1068 k= 0.019156 lr = 0.0000038\n",
      "[19/25][8140/9765] Loss_D: 0.0961 Loss_G: 0.0378 Convergence: 0.0977 k= 0.019166 lr = 0.0000038\n",
      "[19/25][8150/9765] Loss_D: 0.0964 Loss_G: 0.0380 Convergence: 0.0981 k= 0.019166 lr = 0.0000038\n",
      "[19/25][8160/9765] Loss_D: 0.1098 Loss_G: 0.0398 Convergence: 0.1149 k= 0.019178 lr = 0.0000038\n",
      "[19/25][8170/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0974 k= 0.019171 lr = 0.0000038\n",
      "[19/25][8180/9765] Loss_D: 0.0945 Loss_G: 0.0383 Convergence: 0.0955 k= 0.019169 lr = 0.0000038\n",
      "[19/25][8190/9765] Loss_D: 0.0999 Loss_G: 0.0383 Convergence: 0.1026 k= 0.019179 lr = 0.0000038\n",
      "[19/25][8200/9765] Loss_D: 0.0944 Loss_G: 0.0402 Convergence: 0.0973 k= 0.019177 lr = 0.0000038\n",
      "[19/25][8210/9765] Loss_D: 0.1009 Loss_G: 0.0395 Convergence: 0.1029 k= 0.019177 lr = 0.0000038\n",
      "[19/25][8220/9765] Loss_D: 0.0992 Loss_G: 0.0385 Convergence: 0.1014 k= 0.019186 lr = 0.0000038\n",
      "[19/25][8230/9765] Loss_D: 0.0936 Loss_G: 0.0374 Convergence: 0.0947 k= 0.019178 lr = 0.0000038\n",
      "[19/25][8240/9765] Loss_D: 0.0949 Loss_G: 0.0381 Convergence: 0.0958 k= 0.019178 lr = 0.0000038\n",
      "[19/25][8250/9765] Loss_D: 0.1005 Loss_G: 0.0380 Convergence: 0.1037 k= 0.019187 lr = 0.0000038\n",
      "[19/25][8260/9765] Loss_D: 0.1027 Loss_G: 0.0383 Convergence: 0.1064 k= 0.019198 lr = 0.0000038\n",
      "[19/25][8270/9765] Loss_D: 0.1032 Loss_G: 0.0402 Convergence: 0.1054 k= 0.019191 lr = 0.0000038\n",
      "[19/25][8280/9765] Loss_D: 0.0949 Loss_G: 0.0391 Convergence: 0.0965 k= 0.019171 lr = 0.0000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][8290/9765] Loss_D: 0.0945 Loss_G: 0.0399 Convergence: 0.0970 k= 0.019146 lr = 0.0000038\n",
      "[19/25][8300/9765] Loss_D: 0.0991 Loss_G: 0.0397 Convergence: 0.1001 k= 0.019142 lr = 0.0000038\n",
      "[19/25][8310/9765] Loss_D: 0.0934 Loss_G: 0.0407 Convergence: 0.0972 k= 0.019133 lr = 0.0000038\n",
      "[19/25][8320/9765] Loss_D: 0.1019 Loss_G: 0.0393 Convergence: 0.1044 k= 0.019135 lr = 0.0000038\n",
      "[19/25][8330/9765] Loss_D: 0.0936 Loss_G: 0.0383 Convergence: 0.0949 k= 0.019144 lr = 0.0000038\n",
      "[19/25][8340/9765] Loss_D: 0.0937 Loss_G: 0.0372 Convergence: 0.0951 k= 0.019143 lr = 0.0000038\n",
      "[19/25][8350/9765] Loss_D: 0.0961 Loss_G: 0.0379 Convergence: 0.0978 k= 0.019158 lr = 0.0000038\n",
      "[19/25][8360/9765] Loss_D: 0.0970 Loss_G: 0.0369 Convergence: 0.0999 k= 0.019168 lr = 0.0000038\n",
      "[19/25][8370/9765] Loss_D: 0.1014 Loss_G: 0.0385 Convergence: 0.1045 k= 0.019179 lr = 0.0000038\n",
      "[19/25][8380/9765] Loss_D: 0.1063 Loss_G: 0.0400 Convergence: 0.1100 k= 0.019187 lr = 0.0000038\n",
      "[19/25][8390/9765] Loss_D: 0.0945 Loss_G: 0.0372 Convergence: 0.0961 k= 0.019194 lr = 0.0000038\n",
      "[19/25][8400/9765] Loss_D: 0.0945 Loss_G: 0.0381 Convergence: 0.0953 k= 0.019200 lr = 0.0000038\n",
      "[19/25][8410/9765] Loss_D: 0.0910 Loss_G: 0.0371 Convergence: 0.0922 k= 0.019205 lr = 0.0000038\n",
      "[19/25][8420/9765] Loss_D: 0.0912 Loss_G: 0.0389 Convergence: 0.0941 k= 0.019202 lr = 0.0000038\n",
      "[19/25][8430/9765] Loss_D: 0.1034 Loss_G: 0.0396 Convergence: 0.1063 k= 0.019206 lr = 0.0000038\n",
      "[19/25][8440/9765] Loss_D: 0.0948 Loss_G: 0.0415 Convergence: 0.0989 k= 0.019195 lr = 0.0000038\n",
      "[19/25][8450/9765] Loss_D: 0.1040 Loss_G: 0.0415 Convergence: 0.1052 k= 0.019178 lr = 0.0000038\n",
      "[19/25][8460/9765] Loss_D: 0.0902 Loss_G: 0.0408 Convergence: 0.0955 k= 0.019164 lr = 0.0000038\n",
      "[19/25][8470/9765] Loss_D: 0.0979 Loss_G: 0.0401 Convergence: 0.0993 k= 0.019151 lr = 0.0000038\n",
      "[19/25][8480/9765] Loss_D: 0.0933 Loss_G: 0.0418 Convergence: 0.0983 k= 0.019128 lr = 0.0000038\n",
      "[19/25][8490/9765] Loss_D: 0.0986 Loss_G: 0.0402 Convergence: 0.0998 k= 0.019107 lr = 0.0000038\n",
      "[19/25][8500/9765] Loss_D: 0.0951 Loss_G: 0.0400 Convergence: 0.0975 k= 0.019093 lr = 0.0000038\n",
      "[19/25][8510/9765] Loss_D: 0.0946 Loss_G: 0.0384 Convergence: 0.0956 k= 0.019083 lr = 0.0000038\n",
      "[19/25][8520/9765] Loss_D: 0.1034 Loss_G: 0.0370 Convergence: 0.1088 k= 0.019103 lr = 0.0000038\n",
      "[19/25][8530/9765] Loss_D: 0.1045 Loss_G: 0.0379 Convergence: 0.1095 k= 0.019099 lr = 0.0000038\n",
      "[19/25][8540/9765] Loss_D: 0.1007 Loss_G: 0.0393 Convergence: 0.1028 k= 0.019096 lr = 0.0000038\n",
      "[19/25][8550/9765] Loss_D: 0.0940 Loss_G: 0.0378 Convergence: 0.0948 k= 0.019106 lr = 0.0000038\n",
      "[19/25][8560/9765] Loss_D: 0.0943 Loss_G: 0.0371 Convergence: 0.0959 k= 0.019122 lr = 0.0000038\n",
      "[19/25][8570/9765] Loss_D: 0.0911 Loss_G: 0.0376 Convergence: 0.0927 k= 0.019141 lr = 0.0000038\n",
      "[19/25][8580/9765] Loss_D: 0.1030 Loss_G: 0.0363 Convergence: 0.1089 k= 0.019156 lr = 0.0000038\n",
      "[19/25][8590/9765] Loss_D: 0.1007 Loss_G: 0.0384 Convergence: 0.1036 k= 0.019175 lr = 0.0000038\n",
      "[19/25][8600/9765] Loss_D: 0.0961 Loss_G: 0.0393 Convergence: 0.0974 k= 0.019172 lr = 0.0000038\n",
      "[19/25][8610/9765] Loss_D: 0.0999 Loss_G: 0.0400 Convergence: 0.1009 k= 0.019169 lr = 0.0000038\n",
      "[19/25][8620/9765] Loss_D: 0.1076 Loss_G: 0.0407 Convergence: 0.1110 k= 0.019163 lr = 0.0000038\n",
      "[19/25][8630/9765] Loss_D: 0.0916 Loss_G: 0.0409 Convergence: 0.0964 k= 0.019150 lr = 0.0000038\n",
      "[19/25][8640/9765] Loss_D: 0.0914 Loss_G: 0.0398 Convergence: 0.0952 k= 0.019128 lr = 0.0000038\n",
      "[19/25][8650/9765] Loss_D: 0.1083 Loss_G: 0.0415 Convergence: 0.1111 k= 0.019109 lr = 0.0000038\n",
      "[19/25][8660/9765] Loss_D: 0.0938 Loss_G: 0.0427 Convergence: 0.0995 k= 0.019076 lr = 0.0000038\n",
      "[19/25][8670/9765] Loss_D: 0.0990 Loss_G: 0.0406 Convergence: 0.1005 k= 0.019051 lr = 0.0000038\n",
      "[19/25][8680/9765] Loss_D: 0.0955 Loss_G: 0.0410 Convergence: 0.0987 k= 0.019033 lr = 0.0000038\n",
      "[19/25][8690/9765] Loss_D: 0.0880 Loss_G: 0.0399 Convergence: 0.0931 k= 0.019010 lr = 0.0000038\n",
      "[19/25][8700/9765] Loss_D: 0.1025 Loss_G: 0.0400 Convergence: 0.1045 k= 0.019006 lr = 0.0000038\n",
      "[19/25][8710/9765] Loss_D: 0.1029 Loss_G: 0.0397 Convergence: 0.1054 k= 0.019006 lr = 0.0000038\n",
      "[19/25][8720/9765] Loss_D: 0.0909 Loss_G: 0.0392 Convergence: 0.0942 k= 0.019011 lr = 0.0000038\n",
      "[19/25][8730/9765] Loss_D: 0.0925 Loss_G: 0.0388 Convergence: 0.0947 k= 0.019002 lr = 0.0000038\n",
      "[19/25][8740/9765] Loss_D: 0.1022 Loss_G: 0.0389 Convergence: 0.1052 k= 0.018994 lr = 0.0000038\n",
      "[19/25][8750/9765] Loss_D: 0.0925 Loss_G: 0.0381 Convergence: 0.0940 k= 0.018997 lr = 0.0000038\n",
      "[19/25][8760/9765] Loss_D: 0.0937 Loss_G: 0.0385 Convergence: 0.0952 k= 0.019026 lr = 0.0000038\n",
      "[19/25][8770/9765] Loss_D: 0.0996 Loss_G: 0.0373 Convergence: 0.1031 k= 0.019044 lr = 0.0000038\n",
      "[19/25][8780/9765] Loss_D: 0.1021 Loss_G: 0.0385 Convergence: 0.1054 k= 0.019056 lr = 0.0000038\n",
      "[19/25][8790/9765] Loss_D: 0.0897 Loss_G: 0.0379 Convergence: 0.0922 k= 0.019053 lr = 0.0000038\n",
      "[19/25][8800/9765] Loss_D: 0.0936 Loss_G: 0.0389 Convergence: 0.0955 k= 0.019053 lr = 0.0000038\n",
      "[19/25][8810/9765] Loss_D: 0.0982 Loss_G: 0.0408 Convergence: 0.1002 k= 0.019042 lr = 0.0000038\n",
      "[19/25][8820/9765] Loss_D: 0.0908 Loss_G: 0.0400 Convergence: 0.0950 k= 0.019030 lr = 0.0000038\n",
      "[19/25][8830/9765] Loss_D: 0.0905 Loss_G: 0.0399 Convergence: 0.0946 k= 0.019015 lr = 0.0000038\n",
      "[19/25][8840/9765] Loss_D: 0.0911 Loss_G: 0.0413 Convergence: 0.0964 k= 0.019012 lr = 0.0000038\n",
      "[19/25][8850/9765] Loss_D: 0.0932 Loss_G: 0.0395 Convergence: 0.0959 k= 0.018996 lr = 0.0000038\n",
      "[19/25][8860/9765] Loss_D: 0.1113 Loss_G: 0.0386 Convergence: 0.1183 k= 0.018998 lr = 0.0000038\n",
      "[19/25][8870/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.018998 lr = 0.0000038\n",
      "[19/25][8880/9765] Loss_D: 0.0965 Loss_G: 0.0376 Convergence: 0.0984 k= 0.019012 lr = 0.0000038\n",
      "[19/25][8890/9765] Loss_D: 0.0971 Loss_G: 0.0381 Convergence: 0.0989 k= 0.019027 lr = 0.0000038\n",
      "[19/25][8900/9765] Loss_D: 0.0894 Loss_G: 0.0353 Convergence: 0.0908 k= 0.019033 lr = 0.0000038\n",
      "[19/25][8910/9765] Loss_D: 0.0940 Loss_G: 0.0366 Convergence: 0.0960 k= 0.019048 lr = 0.0000038\n",
      "[19/25][8920/9765] Loss_D: 0.0967 Loss_G: 0.0365 Convergence: 0.0998 k= 0.019063 lr = 0.0000038\n",
      "[19/25][8930/9765] Loss_D: 0.0997 Loss_G: 0.0371 Convergence: 0.1034 k= 0.019079 lr = 0.0000038\n",
      "[19/25][8940/9765] Loss_D: 0.0991 Loss_G: 0.0371 Convergence: 0.1025 k= 0.019091 lr = 0.0000038\n",
      "[19/25][8950/9765] Loss_D: 0.1082 Loss_G: 0.0393 Convergence: 0.1132 k= 0.019091 lr = 0.0000038\n",
      "[19/25][8960/9765] Loss_D: 0.0890 Loss_G: 0.0382 Convergence: 0.0921 k= 0.019097 lr = 0.0000038\n",
      "[19/25][8970/9765] Loss_D: 0.0918 Loss_G: 0.0382 Convergence: 0.0937 k= 0.019097 lr = 0.0000038\n",
      "[19/25][8980/9765] Loss_D: 0.0967 Loss_G: 0.0396 Convergence: 0.0981 k= 0.019082 lr = 0.0000038\n",
      "[19/25][8990/9765] Loss_D: 0.0945 Loss_G: 0.0392 Convergence: 0.0963 k= 0.019079 lr = 0.0000038\n",
      "[19/25][9000/9765] Loss_D: 0.0998 Loss_G: 0.0405 Convergence: 0.1008 k= 0.019073 lr = 0.0000038\n",
      "[19/25][9010/9765] Loss_D: 0.1050 Loss_G: 0.0390 Convergence: 0.1091 k= 0.019069 lr = 0.0000038\n",
      "[19/25][9020/9765] Loss_D: 0.0945 Loss_G: 0.0409 Convergence: 0.0981 k= 0.019063 lr = 0.0000038\n",
      "[19/25][9030/9765] Loss_D: 0.0953 Loss_G: 0.0404 Convergence: 0.0981 k= 0.019052 lr = 0.0000038\n",
      "[19/25][9040/9765] Loss_D: 0.0939 Loss_G: 0.0408 Convergence: 0.0976 k= 0.019050 lr = 0.0000038\n",
      "[19/25][9050/9765] Loss_D: 0.0895 Loss_G: 0.0391 Convergence: 0.0932 k= 0.019050 lr = 0.0000038\n",
      "[19/25][9060/9765] Loss_D: 0.0873 Loss_G: 0.0376 Convergence: 0.0905 k= 0.019036 lr = 0.0000038\n",
      "[19/25][9070/9765] Loss_D: 0.1039 Loss_G: 0.0393 Convergence: 0.1073 k= 0.019049 lr = 0.0000038\n",
      "[19/25][9080/9765] Loss_D: 0.0968 Loss_G: 0.0360 Convergence: 0.1005 k= 0.019061 lr = 0.0000038\n",
      "[19/25][9090/9765] Loss_D: 0.0886 Loss_G: 0.0364 Convergence: 0.0900 k= 0.019081 lr = 0.0000038\n",
      "[19/25][9100/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0948 k= 0.019102 lr = 0.0000038\n",
      "[19/25][9110/9765] Loss_D: 0.0975 Loss_G: 0.0363 Convergence: 0.1012 k= 0.019130 lr = 0.0000038\n",
      "[19/25][9120/9765] Loss_D: 0.1006 Loss_G: 0.0365 Convergence: 0.1053 k= 0.019142 lr = 0.0000038\n",
      "[19/25][9130/9765] Loss_D: 0.0965 Loss_G: 0.0378 Convergence: 0.0983 k= 0.019152 lr = 0.0000038\n",
      "[19/25][9140/9765] Loss_D: 0.0950 Loss_G: 0.0393 Convergence: 0.0968 k= 0.019153 lr = 0.0000038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/25][9150/9765] Loss_D: 0.1018 Loss_G: 0.0392 Convergence: 0.1044 k= 0.019149 lr = 0.0000038\n",
      "[19/25][9160/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1008 k= 0.019133 lr = 0.0000038\n",
      "[19/25][9170/9765] Loss_D: 0.1036 Loss_G: 0.0394 Convergence: 0.1068 k= 0.019110 lr = 0.0000038\n",
      "[19/25][9180/9765] Loss_D: 0.1023 Loss_G: 0.0396 Convergence: 0.1046 k= 0.019103 lr = 0.0000038\n",
      "[19/25][9190/9765] Loss_D: 0.1044 Loss_G: 0.0406 Convergence: 0.1066 k= 0.019097 lr = 0.0000038\n",
      "[19/25][9200/9765] Loss_D: 0.0988 Loss_G: 0.0394 Convergence: 0.1000 k= 0.019103 lr = 0.0000038\n",
      "[19/25][9210/9765] Loss_D: 0.0889 Loss_G: 0.0389 Convergence: 0.0928 k= 0.019097 lr = 0.0000038\n",
      "[19/25][9220/9765] Loss_D: 0.0909 Loss_G: 0.0380 Convergence: 0.0930 k= 0.019101 lr = 0.0000038\n",
      "[19/25][9230/9765] Loss_D: 0.0941 Loss_G: 0.0384 Convergence: 0.0953 k= 0.019107 lr = 0.0000038\n",
      "[19/25][9240/9765] Loss_D: 0.1027 Loss_G: 0.0393 Convergence: 0.1056 k= 0.019117 lr = 0.0000038\n",
      "[19/25][9250/9765] Loss_D: 0.0872 Loss_G: 0.0395 Convergence: 0.0923 k= 0.019121 lr = 0.0000038\n",
      "[19/25][9260/9765] Loss_D: 0.0916 Loss_G: 0.0387 Convergence: 0.0941 k= 0.019117 lr = 0.0000038\n",
      "[19/25][9270/9765] Loss_D: 0.0968 Loss_G: 0.0398 Convergence: 0.0983 k= 0.019120 lr = 0.0000038\n",
      "[19/25][9280/9765] Loss_D: 0.0868 Loss_G: 0.0388 Convergence: 0.0914 k= 0.019111 lr = 0.0000038\n",
      "[19/25][9290/9765] Loss_D: 0.1000 Loss_G: 0.0386 Convergence: 0.1025 k= 0.019110 lr = 0.0000038\n",
      "[19/25][9300/9765] Loss_D: 0.0991 Loss_G: 0.0398 Convergence: 0.1000 k= 0.019117 lr = 0.0000038\n",
      "[19/25][9310/9765] Loss_D: 0.0999 Loss_G: 0.0392 Convergence: 0.1017 k= 0.019115 lr = 0.0000038\n",
      "[19/25][9320/9765] Loss_D: 0.0953 Loss_G: 0.0388 Convergence: 0.0965 k= 0.019103 lr = 0.0000038\n",
      "[19/25][9330/9765] Loss_D: 0.0993 Loss_G: 0.0391 Convergence: 0.1009 k= 0.019086 lr = 0.0000038\n",
      "[19/25][9340/9765] Loss_D: 0.1032 Loss_G: 0.0404 Convergence: 0.1052 k= 0.019076 lr = 0.0000038\n",
      "[19/25][9350/9765] Loss_D: 0.0989 Loss_G: 0.0393 Convergence: 0.1002 k= 0.019065 lr = 0.0000038\n",
      "[19/25][9360/9765] Loss_D: 0.1029 Loss_G: 0.0389 Convergence: 0.1062 k= 0.019062 lr = 0.0000038\n",
      "[19/25][9370/9765] Loss_D: 0.0913 Loss_G: 0.0386 Convergence: 0.0938 k= 0.019058 lr = 0.0000038\n",
      "[19/25][9380/9765] Loss_D: 0.0899 Loss_G: 0.0377 Convergence: 0.0921 k= 0.019065 lr = 0.0000038\n",
      "[19/25][9390/9765] Loss_D: 0.1067 Loss_G: 0.0379 Convergence: 0.1125 k= 0.019069 lr = 0.0000038\n",
      "[19/25][9400/9765] Loss_D: 0.0981 Loss_G: 0.0381 Convergence: 0.1003 k= 0.019071 lr = 0.0000038\n",
      "[19/25][9410/9765] Loss_D: 0.0960 Loss_G: 0.0394 Convergence: 0.0975 k= 0.019064 lr = 0.0000038\n",
      "[19/25][9420/9765] Loss_D: 0.1028 Loss_G: 0.0385 Convergence: 0.1065 k= 0.019078 lr = 0.0000038\n",
      "[19/25][9430/9765] Loss_D: 0.1042 Loss_G: 0.0399 Convergence: 0.1070 k= 0.019067 lr = 0.0000038\n",
      "[19/25][9440/9765] Loss_D: 0.0978 Loss_G: 0.0396 Convergence: 0.0987 k= 0.019053 lr = 0.0000038\n",
      "[19/25][9450/9765] Loss_D: 0.1002 Loss_G: 0.0405 Convergence: 0.1011 k= 0.019048 lr = 0.0000038\n",
      "[19/25][9460/9765] Loss_D: 0.0884 Loss_G: 0.0413 Convergence: 0.0948 k= 0.019036 lr = 0.0000038\n",
      "[19/25][9470/9765] Loss_D: 0.0975 Loss_G: 0.0416 Convergence: 0.1006 k= 0.019017 lr = 0.0000036\n",
      "[19/25][9480/9765] Loss_D: 0.1016 Loss_G: 0.0395 Convergence: 0.1038 k= 0.019004 lr = 0.0000036\n",
      "[19/25][9490/9765] Loss_D: 0.0950 Loss_G: 0.0397 Convergence: 0.0972 k= 0.019007 lr = 0.0000036\n",
      "[19/25][9500/9765] Loss_D: 0.0931 Loss_G: 0.0399 Convergence: 0.0962 k= 0.018999 lr = 0.0000036\n",
      "[19/25][9510/9765] Loss_D: 0.0877 Loss_G: 0.0383 Convergence: 0.0913 k= 0.018987 lr = 0.0000036\n",
      "[19/25][9520/9765] Loss_D: 0.0931 Loss_G: 0.0373 Convergence: 0.0941 k= 0.018985 lr = 0.0000036\n",
      "[19/25][9530/9765] Loss_D: 0.0958 Loss_G: 0.0378 Convergence: 0.0973 k= 0.019000 lr = 0.0000036\n",
      "[19/25][9540/9765] Loss_D: 0.0958 Loss_G: 0.0390 Convergence: 0.0969 k= 0.019000 lr = 0.0000036\n",
      "[19/25][9550/9765] Loss_D: 0.1033 Loss_G: 0.0396 Convergence: 0.1061 k= 0.019001 lr = 0.0000036\n",
      "[19/25][9560/9765] Loss_D: 0.0958 Loss_G: 0.0402 Convergence: 0.0981 k= 0.018991 lr = 0.0000036\n",
      "[19/25][9570/9765] Loss_D: 0.1006 Loss_G: 0.0388 Convergence: 0.1031 k= 0.018988 lr = 0.0000036\n",
      "[19/25][9580/9765] Loss_D: 0.0939 Loss_G: 0.0414 Convergence: 0.0982 k= 0.018979 lr = 0.0000036\n",
      "[19/25][9590/9765] Loss_D: 0.1034 Loss_G: 0.0405 Convergence: 0.1052 k= 0.018972 lr = 0.0000036\n",
      "[19/25][9600/9765] Loss_D: 0.0950 Loss_G: 0.0389 Convergence: 0.0963 k= 0.018958 lr = 0.0000036\n",
      "[19/25][9610/9765] Loss_D: 0.0979 Loss_G: 0.0389 Convergence: 0.0992 k= 0.018957 lr = 0.0000036\n",
      "[19/25][9620/9765] Loss_D: 0.0944 Loss_G: 0.0387 Convergence: 0.0958 k= 0.018955 lr = 0.0000036\n",
      "[19/25][9630/9765] Loss_D: 0.1080 Loss_G: 0.0373 Convergence: 0.1150 k= 0.018964 lr = 0.0000036\n",
      "[19/25][9640/9765] Loss_D: 0.0996 Loss_G: 0.0377 Convergence: 0.1028 k= 0.018972 lr = 0.0000036\n",
      "[19/25][9650/9765] Loss_D: 0.0914 Loss_G: 0.0381 Convergence: 0.0933 k= 0.018962 lr = 0.0000036\n",
      "[19/25][9660/9765] Loss_D: 0.0930 Loss_G: 0.0380 Convergence: 0.0942 k= 0.018964 lr = 0.0000036\n",
      "[19/25][9670/9765] Loss_D: 0.1007 Loss_G: 0.0405 Convergence: 0.1016 k= 0.018979 lr = 0.0000036\n",
      "[19/25][9680/9765] Loss_D: 0.1064 Loss_G: 0.0378 Convergence: 0.1122 k= 0.018984 lr = 0.0000036\n",
      "[19/25][9690/9765] Loss_D: 0.0953 Loss_G: 0.0390 Convergence: 0.0966 k= 0.018977 lr = 0.0000036\n",
      "[19/25][9700/9765] Loss_D: 0.0949 Loss_G: 0.0370 Convergence: 0.0969 k= 0.019006 lr = 0.0000036\n",
      "[19/25][9710/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0985 k= 0.018999 lr = 0.0000036\n",
      "[19/25][9720/9765] Loss_D: 0.0955 Loss_G: 0.0393 Convergence: 0.0971 k= 0.019002 lr = 0.0000036\n",
      "[19/25][9730/9765] Loss_D: 0.0958 Loss_G: 0.0391 Convergence: 0.0970 k= 0.018995 lr = 0.0000036\n",
      "[19/25][9740/9765] Loss_D: 0.1051 Loss_G: 0.0398 Convergence: 0.1084 k= 0.018982 lr = 0.0000036\n",
      "[19/25][9750/9765] Loss_D: 0.0965 Loss_G: 0.0425 Convergence: 0.1009 k= 0.018961 lr = 0.0000036\n",
      "[19/25][9760/9765] Loss_D: 0.0964 Loss_G: 0.0419 Convergence: 0.1001 k= 0.018925 lr = 0.0000036\n",
      "[20/25][0/9765] Loss_D: 0.0925 Loss_G: 0.0419 Convergence: 0.0979 k= 0.018910 lr = 0.0000036\n",
      "[20/25][10/9765] Loss_D: 0.0958 Loss_G: 0.0403 Convergence: 0.0982 k= 0.018885 lr = 0.0000036\n",
      "[20/25][20/9765] Loss_D: 0.1000 Loss_G: 0.0412 Convergence: 0.1016 k= 0.018875 lr = 0.0000036\n",
      "[20/25][30/9765] Loss_D: 0.0942 Loss_G: 0.0415 Convergence: 0.0985 k= 0.018855 lr = 0.0000036\n",
      "[20/25][40/9765] Loss_D: 0.0975 Loss_G: 0.0384 Convergence: 0.0992 k= 0.018850 lr = 0.0000036\n",
      "[20/25][50/9765] Loss_D: 0.0914 Loss_G: 0.0394 Convergence: 0.0947 k= 0.018856 lr = 0.0000036\n",
      "[20/25][60/9765] Loss_D: 0.1050 Loss_G: 0.0378 Convergence: 0.1103 k= 0.018861 lr = 0.0000036\n",
      "[20/25][70/9765] Loss_D: 0.0938 Loss_G: 0.0394 Convergence: 0.0961 k= 0.018874 lr = 0.0000036\n",
      "[20/25][80/9765] Loss_D: 0.0894 Loss_G: 0.0397 Convergence: 0.0938 k= 0.018875 lr = 0.0000036\n",
      "[20/25][90/9765] Loss_D: 0.0979 Loss_G: 0.0388 Convergence: 0.0994 k= 0.018883 lr = 0.0000036\n",
      "[20/25][100/9765] Loss_D: 0.1079 Loss_G: 0.0391 Convergence: 0.1130 k= 0.018879 lr = 0.0000036\n",
      "[20/25][110/9765] Loss_D: 0.0962 Loss_G: 0.0389 Convergence: 0.0971 k= 0.018872 lr = 0.0000036\n",
      "[20/25][120/9765] Loss_D: 0.0948 Loss_G: 0.0380 Convergence: 0.0958 k= 0.018877 lr = 0.0000036\n",
      "[20/25][130/9765] Loss_D: 0.1016 Loss_G: 0.0394 Convergence: 0.1039 k= 0.018880 lr = 0.0000036\n",
      "[20/25][140/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0968 k= 0.018890 lr = 0.0000036\n",
      "[20/25][150/9765] Loss_D: 0.0940 Loss_G: 0.0392 Convergence: 0.0960 k= 0.018885 lr = 0.0000036\n",
      "[20/25][160/9765] Loss_D: 0.0968 Loss_G: 0.0389 Convergence: 0.0977 k= 0.018896 lr = 0.0000036\n",
      "[20/25][170/9765] Loss_D: 0.0938 Loss_G: 0.0397 Convergence: 0.0965 k= 0.018890 lr = 0.0000036\n",
      "[20/25][180/9765] Loss_D: 0.0947 Loss_G: 0.0391 Convergence: 0.0963 k= 0.018884 lr = 0.0000036\n",
      "[20/25][190/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0950 k= 0.018882 lr = 0.0000036\n",
      "[20/25][200/9765] Loss_D: 0.0988 Loss_G: 0.0385 Convergence: 0.1008 k= 0.018883 lr = 0.0000036\n",
      "[20/25][210/9765] Loss_D: 0.0970 Loss_G: 0.0385 Convergence: 0.0983 k= 0.018899 lr = 0.0000036\n",
      "[20/25][220/9765] Loss_D: 0.0987 Loss_G: 0.0388 Convergence: 0.1004 k= 0.018905 lr = 0.0000036\n",
      "[20/25][230/9765] Loss_D: 0.0947 Loss_G: 0.0383 Convergence: 0.0955 k= 0.018904 lr = 0.0000036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][240/9765] Loss_D: 0.0953 Loss_G: 0.0369 Convergence: 0.0975 k= 0.018916 lr = 0.0000036\n",
      "[20/25][250/9765] Loss_D: 0.1019 Loss_G: 0.0391 Convergence: 0.1046 k= 0.018924 lr = 0.0000036\n",
      "[20/25][260/9765] Loss_D: 0.0861 Loss_G: 0.0387 Convergence: 0.0908 k= 0.018930 lr = 0.0000036\n",
      "[20/25][270/9765] Loss_D: 0.0945 Loss_G: 0.0382 Convergence: 0.0953 k= 0.018929 lr = 0.0000036\n",
      "[20/25][280/9765] Loss_D: 0.0882 Loss_G: 0.0384 Convergence: 0.0918 k= 0.018915 lr = 0.0000036\n",
      "[20/25][290/9765] Loss_D: 0.0969 Loss_G: 0.0412 Convergence: 0.0998 k= 0.018903 lr = 0.0000036\n",
      "[20/25][300/9765] Loss_D: 0.0920 Loss_G: 0.0406 Convergence: 0.0963 k= 0.018880 lr = 0.0000036\n",
      "[20/25][310/9765] Loss_D: 0.0975 Loss_G: 0.0397 Convergence: 0.0987 k= 0.018867 lr = 0.0000036\n",
      "[20/25][320/9765] Loss_D: 0.0998 Loss_G: 0.0410 Convergence: 0.1013 k= 0.018858 lr = 0.0000036\n",
      "[20/25][330/9765] Loss_D: 0.0938 Loss_G: 0.0425 Convergence: 0.0992 k= 0.018832 lr = 0.0000036\n",
      "[20/25][340/9765] Loss_D: 0.1064 Loss_G: 0.0404 Convergence: 0.1096 k= 0.018813 lr = 0.0000036\n",
      "[20/25][350/9765] Loss_D: 0.0915 Loss_G: 0.0406 Convergence: 0.0959 k= 0.018805 lr = 0.0000036\n",
      "[20/25][360/9765] Loss_D: 0.1001 Loss_G: 0.0406 Convergence: 0.1012 k= 0.018791 lr = 0.0000036\n",
      "[20/25][370/9765] Loss_D: 0.1059 Loss_G: 0.0406 Convergence: 0.1087 k= 0.018796 lr = 0.0000036\n",
      "[20/25][380/9765] Loss_D: 0.0974 Loss_G: 0.0395 Convergence: 0.0984 k= 0.018778 lr = 0.0000036\n",
      "[20/25][390/9765] Loss_D: 0.0928 Loss_G: 0.0391 Convergence: 0.0952 k= 0.018771 lr = 0.0000036\n",
      "[20/25][400/9765] Loss_D: 0.1012 Loss_G: 0.0374 Convergence: 0.1052 k= 0.018773 lr = 0.0000036\n",
      "[20/25][410/9765] Loss_D: 0.0932 Loss_G: 0.0373 Convergence: 0.0942 k= 0.018788 lr = 0.0000036\n",
      "[20/25][420/9765] Loss_D: 0.0923 Loss_G: 0.0363 Convergence: 0.0938 k= 0.018800 lr = 0.0000036\n",
      "[20/25][430/9765] Loss_D: 0.0968 Loss_G: 0.0355 Convergence: 0.1009 k= 0.018825 lr = 0.0000036\n",
      "[20/25][440/9765] Loss_D: 0.0966 Loss_G: 0.0346 Convergence: 0.1016 k= 0.018853 lr = 0.0000036\n",
      "[20/25][450/9765] Loss_D: 0.0923 Loss_G: 0.0346 Convergence: 0.0955 k= 0.018885 lr = 0.0000036\n",
      "[20/25][460/9765] Loss_D: 0.0960 Loss_G: 0.0357 Convergence: 0.0997 k= 0.018925 lr = 0.0000036\n",
      "[20/25][470/9765] Loss_D: 0.1006 Loss_G: 0.0369 Convergence: 0.1048 k= 0.018947 lr = 0.0000036\n",
      "[20/25][480/9765] Loss_D: 0.1063 Loss_G: 0.0387 Convergence: 0.1112 k= 0.018967 lr = 0.0000036\n",
      "[20/25][490/9765] Loss_D: 0.0977 Loss_G: 0.0389 Convergence: 0.0990 k= 0.018971 lr = 0.0000036\n",
      "[20/25][500/9765] Loss_D: 0.0978 Loss_G: 0.0397 Convergence: 0.0988 k= 0.018966 lr = 0.0000036\n",
      "[20/25][510/9765] Loss_D: 0.1024 Loss_G: 0.0401 Convergence: 0.1043 k= 0.018944 lr = 0.0000036\n",
      "[20/25][520/9765] Loss_D: 0.1108 Loss_G: 0.0414 Convergence: 0.1147 k= 0.018928 lr = 0.0000036\n",
      "[20/25][530/9765] Loss_D: 0.0920 Loss_G: 0.0415 Convergence: 0.0972 k= 0.018901 lr = 0.0000036\n",
      "[20/25][540/9765] Loss_D: 0.0915 Loss_G: 0.0401 Convergence: 0.0954 k= 0.018873 lr = 0.0000036\n",
      "[20/25][550/9765] Loss_D: 0.0948 Loss_G: 0.0399 Convergence: 0.0972 k= 0.018864 lr = 0.0000036\n",
      "[20/25][560/9765] Loss_D: 0.0933 Loss_G: 0.0395 Convergence: 0.0960 k= 0.018843 lr = 0.0000036\n",
      "[20/25][570/9765] Loss_D: 0.0900 Loss_G: 0.0413 Convergence: 0.0958 k= 0.018831 lr = 0.0000036\n",
      "[20/25][580/9765] Loss_D: 0.0913 Loss_G: 0.0416 Convergence: 0.0969 k= 0.018806 lr = 0.0000036\n",
      "[20/25][590/9765] Loss_D: 0.1018 Loss_G: 0.0396 Convergence: 0.1040 k= 0.018796 lr = 0.0000036\n",
      "[20/25][600/9765] Loss_D: 0.0936 Loss_G: 0.0393 Convergence: 0.0959 k= 0.018798 lr = 0.0000036\n",
      "[20/25][610/9765] Loss_D: 0.0999 Loss_G: 0.0382 Convergence: 0.1026 k= 0.018799 lr = 0.0000036\n",
      "[20/25][620/9765] Loss_D: 0.0952 Loss_G: 0.0379 Convergence: 0.0964 k= 0.018796 lr = 0.0000036\n",
      "[20/25][630/9765] Loss_D: 0.0974 Loss_G: 0.0395 Convergence: 0.0984 k= 0.018794 lr = 0.0000036\n",
      "[20/25][640/9765] Loss_D: 0.0984 Loss_G: 0.0400 Convergence: 0.0995 k= 0.018790 lr = 0.0000036\n",
      "[20/25][650/9765] Loss_D: 0.0987 Loss_G: 0.0408 Convergence: 0.1005 k= 0.018770 lr = 0.0000036\n",
      "[20/25][660/9765] Loss_D: 0.0941 Loss_G: 0.0386 Convergence: 0.0955 k= 0.018772 lr = 0.0000036\n",
      "[20/25][670/9765] Loss_D: 0.0955 Loss_G: 0.0382 Convergence: 0.0964 k= 0.018777 lr = 0.0000036\n",
      "[20/25][680/9765] Loss_D: 0.1003 Loss_G: 0.0388 Convergence: 0.1026 k= 0.018791 lr = 0.0000036\n",
      "[20/25][690/9765] Loss_D: 0.0884 Loss_G: 0.0371 Convergence: 0.0906 k= 0.018796 lr = 0.0000036\n",
      "[20/25][700/9765] Loss_D: 0.0817 Loss_G: 0.0380 Convergence: 0.0874 k= 0.018805 lr = 0.0000036\n",
      "[20/25][710/9765] Loss_D: 0.0973 Loss_G: 0.0375 Convergence: 0.0997 k= 0.018815 lr = 0.0000036\n",
      "[20/25][720/9765] Loss_D: 0.1107 Loss_G: 0.0374 Convergence: 0.1186 k= 0.018816 lr = 0.0000036\n",
      "[20/25][730/9765] Loss_D: 0.0999 Loss_G: 0.0390 Convergence: 0.1019 k= 0.018816 lr = 0.0000036\n",
      "[20/25][740/9765] Loss_D: 0.0841 Loss_G: 0.0391 Convergence: 0.0900 k= 0.018813 lr = 0.0000036\n",
      "[20/25][750/9765] Loss_D: 0.0898 Loss_G: 0.0396 Convergence: 0.0939 k= 0.018804 lr = 0.0000036\n",
      "[20/25][760/9765] Loss_D: 0.1049 Loss_G: 0.0393 Convergence: 0.1086 k= 0.018806 lr = 0.0000036\n",
      "[20/25][770/9765] Loss_D: 0.1018 Loss_G: 0.0387 Convergence: 0.1049 k= 0.018801 lr = 0.0000036\n",
      "[20/25][780/9765] Loss_D: 0.0918 Loss_G: 0.0376 Convergence: 0.0931 k= 0.018799 lr = 0.0000036\n",
      "[20/25][790/9765] Loss_D: 0.0931 Loss_G: 0.0385 Convergence: 0.0948 k= 0.018786 lr = 0.0000036\n",
      "[20/25][800/9765] Loss_D: 0.0968 Loss_G: 0.0383 Convergence: 0.0983 k= 0.018786 lr = 0.0000036\n",
      "[20/25][810/9765] Loss_D: 0.0929 Loss_G: 0.0374 Convergence: 0.0937 k= 0.018792 lr = 0.0000036\n",
      "[20/25][820/9765] Loss_D: 0.1119 Loss_G: 0.0388 Convergence: 0.1188 k= 0.018795 lr = 0.0000036\n",
      "[20/25][830/9765] Loss_D: 0.1001 Loss_G: 0.0364 Convergence: 0.1047 k= 0.018808 lr = 0.0000036\n",
      "[20/25][840/9765] Loss_D: 0.0940 Loss_G: 0.0376 Convergence: 0.0951 k= 0.018825 lr = 0.0000036\n",
      "[20/25][850/9765] Loss_D: 0.0957 Loss_G: 0.0368 Convergence: 0.0982 k= 0.018838 lr = 0.0000036\n",
      "[20/25][860/9765] Loss_D: 0.0868 Loss_G: 0.0384 Convergence: 0.0910 k= 0.018831 lr = 0.0000036\n",
      "[20/25][870/9765] Loss_D: 0.1031 Loss_G: 0.0382 Convergence: 0.1072 k= 0.018837 lr = 0.0000036\n",
      "[20/25][880/9765] Loss_D: 0.0984 Loss_G: 0.0380 Convergence: 0.1008 k= 0.018856 lr = 0.0000036\n",
      "[20/25][890/9765] Loss_D: 0.0990 Loss_G: 0.0394 Convergence: 0.1003 k= 0.018862 lr = 0.0000036\n",
      "[20/25][900/9765] Loss_D: 0.1083 Loss_G: 0.0391 Convergence: 0.1136 k= 0.018880 lr = 0.0000036\n",
      "[20/25][910/9765] Loss_D: 0.0980 Loss_G: 0.0408 Convergence: 0.1001 k= 0.018861 lr = 0.0000036\n",
      "[20/25][920/9765] Loss_D: 0.0952 Loss_G: 0.0399 Convergence: 0.0975 k= 0.018847 lr = 0.0000036\n",
      "[20/25][930/9765] Loss_D: 0.0988 Loss_G: 0.0388 Convergence: 0.1005 k= 0.018840 lr = 0.0000036\n",
      "[20/25][940/9765] Loss_D: 0.0901 Loss_G: 0.0389 Convergence: 0.0934 k= 0.018842 lr = 0.0000036\n",
      "[20/25][950/9765] Loss_D: 0.1030 Loss_G: 0.0407 Convergence: 0.1045 k= 0.018831 lr = 0.0000036\n",
      "[20/25][960/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0967 k= 0.018830 lr = 0.0000036\n",
      "[20/25][970/9765] Loss_D: 0.0979 Loss_G: 0.0386 Convergence: 0.0995 k= 0.018817 lr = 0.0000036\n",
      "[20/25][980/9765] Loss_D: 0.1027 Loss_G: 0.0389 Convergence: 0.1059 k= 0.018818 lr = 0.0000036\n",
      "[20/25][990/9765] Loss_D: 0.0992 Loss_G: 0.0378 Convergence: 0.1020 k= 0.018830 lr = 0.0000036\n",
      "[20/25][1000/9765] Loss_D: 0.1016 Loss_G: 0.0379 Convergence: 0.1053 k= 0.018847 lr = 0.0000036\n",
      "[20/25][1010/9765] Loss_D: 0.0927 Loss_G: 0.0368 Convergence: 0.0939 k= 0.018859 lr = 0.0000036\n",
      "[20/25][1020/9765] Loss_D: 0.0964 Loss_G: 0.0378 Convergence: 0.0981 k= 0.018881 lr = 0.0000036\n",
      "[20/25][1030/9765] Loss_D: 0.0872 Loss_G: 0.0367 Convergence: 0.0894 k= 0.018896 lr = 0.0000036\n",
      "[20/25][1040/9765] Loss_D: 0.0984 Loss_G: 0.0400 Convergence: 0.0995 k= 0.018911 lr = 0.0000036\n",
      "[20/25][1050/9765] Loss_D: 0.0952 Loss_G: 0.0390 Convergence: 0.0965 k= 0.018912 lr = 0.0000036\n",
      "[20/25][1060/9765] Loss_D: 0.0963 Loss_G: 0.0384 Convergence: 0.0974 k= 0.018913 lr = 0.0000036\n",
      "[20/25][1070/9765] Loss_D: 0.0909 Loss_G: 0.0385 Convergence: 0.0935 k= 0.018914 lr = 0.0000036\n",
      "[20/25][1080/9765] Loss_D: 0.0977 Loss_G: 0.0391 Convergence: 0.0987 k= 0.018908 lr = 0.0000036\n",
      "[20/25][1090/9765] Loss_D: 0.1007 Loss_G: 0.0381 Convergence: 0.1039 k= 0.018921 lr = 0.0000036\n",
      "[20/25][1100/9765] Loss_D: 0.0901 Loss_G: 0.0376 Convergence: 0.0921 k= 0.018912 lr = 0.0000036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][1110/9765] Loss_D: 0.0915 Loss_G: 0.0385 Convergence: 0.0938 k= 0.018916 lr = 0.0000036\n",
      "[20/25][1120/9765] Loss_D: 0.0939 Loss_G: 0.0404 Convergence: 0.0972 k= 0.018916 lr = 0.0000036\n",
      "[20/25][1130/9765] Loss_D: 0.0995 Loss_G: 0.0398 Convergence: 0.1006 k= 0.018910 lr = 0.0000036\n",
      "[20/25][1140/9765] Loss_D: 0.0997 Loss_G: 0.0387 Convergence: 0.1019 k= 0.018911 lr = 0.0000036\n",
      "[20/25][1150/9765] Loss_D: 0.0951 Loss_G: 0.0376 Convergence: 0.0965 k= 0.018911 lr = 0.0000036\n",
      "[20/25][1160/9765] Loss_D: 0.0954 Loss_G: 0.0384 Convergence: 0.0962 k= 0.018910 lr = 0.0000036\n",
      "[20/25][1170/9765] Loss_D: 0.0945 Loss_G: 0.0398 Convergence: 0.0969 k= 0.018906 lr = 0.0000036\n",
      "[20/25][1180/9765] Loss_D: 0.0950 Loss_G: 0.0388 Convergence: 0.0963 k= 0.018891 lr = 0.0000036\n",
      "[20/25][1190/9765] Loss_D: 0.0956 Loss_G: 0.0389 Convergence: 0.0967 k= 0.018889 lr = 0.0000036\n",
      "[20/25][1200/9765] Loss_D: 0.0964 Loss_G: 0.0377 Convergence: 0.0982 k= 0.018891 lr = 0.0000036\n",
      "[20/25][1210/9765] Loss_D: 0.0924 Loss_G: 0.0383 Convergence: 0.0941 k= 0.018890 lr = 0.0000036\n",
      "[20/25][1220/9765] Loss_D: 0.0981 Loss_G: 0.0377 Convergence: 0.1007 k= 0.018890 lr = 0.0000036\n",
      "[20/25][1230/9765] Loss_D: 0.0973 Loss_G: 0.0380 Convergence: 0.0992 k= 0.018897 lr = 0.0000036\n",
      "[20/25][1240/9765] Loss_D: 0.1113 Loss_G: 0.0386 Convergence: 0.1182 k= 0.018910 lr = 0.0000036\n",
      "[20/25][1250/9765] Loss_D: 0.0901 Loss_G: 0.0387 Convergence: 0.0932 k= 0.018905 lr = 0.0000036\n",
      "[20/25][1260/9765] Loss_D: 0.1015 Loss_G: 0.0377 Convergence: 0.1054 k= 0.018907 lr = 0.0000036\n",
      "[20/25][1270/9765] Loss_D: 0.0884 Loss_G: 0.0382 Convergence: 0.0917 k= 0.018913 lr = 0.0000036\n",
      "[20/25][1280/9765] Loss_D: 0.0854 Loss_G: 0.0360 Convergence: 0.0876 k= 0.018916 lr = 0.0000036\n",
      "[20/25][1290/9765] Loss_D: 0.0939 Loss_G: 0.0376 Convergence: 0.0948 k= 0.018933 lr = 0.0000036\n",
      "[20/25][1300/9765] Loss_D: 0.1003 Loss_G: 0.0378 Convergence: 0.1037 k= 0.018935 lr = 0.0000036\n",
      "[20/25][1310/9765] Loss_D: 0.1024 Loss_G: 0.0383 Convergence: 0.1060 k= 0.018950 lr = 0.0000036\n",
      "[20/25][1320/9765] Loss_D: 0.0929 Loss_G: 0.0372 Convergence: 0.0939 k= 0.018965 lr = 0.0000036\n",
      "[20/25][1330/9765] Loss_D: 0.0996 Loss_G: 0.0364 Convergence: 0.1040 k= 0.018976 lr = 0.0000036\n",
      "[20/25][1340/9765] Loss_D: 0.0958 Loss_G: 0.0374 Convergence: 0.0978 k= 0.018980 lr = 0.0000036\n",
      "[20/25][1350/9765] Loss_D: 0.1006 Loss_G: 0.0398 Convergence: 0.1021 k= 0.018989 lr = 0.0000036\n",
      "[20/25][1360/9765] Loss_D: 0.1013 Loss_G: 0.0403 Convergence: 0.1025 k= 0.018988 lr = 0.0000036\n",
      "[20/25][1370/9765] Loss_D: 0.0985 Loss_G: 0.0404 Convergence: 0.1000 k= 0.018968 lr = 0.0000036\n",
      "[20/25][1380/9765] Loss_D: 0.0969 Loss_G: 0.0402 Convergence: 0.0988 k= 0.018943 lr = 0.0000036\n",
      "[20/25][1390/9765] Loss_D: 0.0953 Loss_G: 0.0418 Convergence: 0.0995 k= 0.018906 lr = 0.0000036\n",
      "[20/25][1400/9765] Loss_D: 0.1013 Loss_G: 0.0421 Convergence: 0.1034 k= 0.018886 lr = 0.0000036\n",
      "[20/25][1410/9765] Loss_D: 0.1002 Loss_G: 0.0397 Convergence: 0.1016 k= 0.018875 lr = 0.0000036\n",
      "[20/25][1420/9765] Loss_D: 0.0922 Loss_G: 0.0399 Convergence: 0.0957 k= 0.018862 lr = 0.0000036\n",
      "[20/25][1430/9765] Loss_D: 0.0928 Loss_G: 0.0387 Convergence: 0.0948 k= 0.018861 lr = 0.0000036\n",
      "[20/25][1440/9765] Loss_D: 0.0959 Loss_G: 0.0383 Convergence: 0.0971 k= 0.018878 lr = 0.0000036\n",
      "[20/25][1450/9765] Loss_D: 0.0934 Loss_G: 0.0378 Convergence: 0.0943 k= 0.018886 lr = 0.0000036\n",
      "[20/25][1460/9765] Loss_D: 0.1042 Loss_G: 0.0379 Convergence: 0.1090 k= 0.018905 lr = 0.0000036\n",
      "[20/25][1470/9765] Loss_D: 0.0902 Loss_G: 0.0376 Convergence: 0.0922 k= 0.018897 lr = 0.0000036\n",
      "[20/25][1480/9765] Loss_D: 0.0976 Loss_G: 0.0383 Convergence: 0.0993 k= 0.018910 lr = 0.0000036\n",
      "[20/25][1490/9765] Loss_D: 0.0908 Loss_G: 0.0400 Convergence: 0.0950 k= 0.018901 lr = 0.0000036\n",
      "[20/25][1500/9765] Loss_D: 0.0937 Loss_G: 0.0400 Convergence: 0.0967 k= 0.018893 lr = 0.0000036\n",
      "[20/25][1510/9765] Loss_D: 0.1019 Loss_G: 0.0423 Convergence: 0.1039 k= 0.018874 lr = 0.0000036\n",
      "[20/25][1520/9765] Loss_D: 0.0923 Loss_G: 0.0393 Convergence: 0.0951 k= 0.018851 lr = 0.0000036\n",
      "[20/25][1530/9765] Loss_D: 0.0928 Loss_G: 0.0401 Convergence: 0.0962 k= 0.018831 lr = 0.0000036\n",
      "[20/25][1540/9765] Loss_D: 0.0969 Loss_G: 0.0395 Convergence: 0.0981 k= 0.018820 lr = 0.0000036\n",
      "[20/25][1550/9765] Loss_D: 0.0877 Loss_G: 0.0378 Convergence: 0.0908 k= 0.018815 lr = 0.0000036\n",
      "[20/25][1560/9765] Loss_D: 0.1046 Loss_G: 0.0398 Convergence: 0.1077 k= 0.018799 lr = 0.0000036\n",
      "[20/25][1570/9765] Loss_D: 0.0923 Loss_G: 0.0396 Convergence: 0.0954 k= 0.018788 lr = 0.0000036\n",
      "[20/25][1580/9765] Loss_D: 0.0920 Loss_G: 0.0388 Convergence: 0.0944 k= 0.018787 lr = 0.0000036\n",
      "[20/25][1590/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0994 k= 0.018785 lr = 0.0000036\n",
      "[20/25][1600/9765] Loss_D: 0.1029 Loss_G: 0.0385 Convergence: 0.1066 k= 0.018793 lr = 0.0000036\n",
      "[20/25][1610/9765] Loss_D: 0.0983 Loss_G: 0.0375 Convergence: 0.1011 k= 0.018794 lr = 0.0000036\n",
      "[20/25][1620/9765] Loss_D: 0.0990 Loss_G: 0.0379 Convergence: 0.1017 k= 0.018817 lr = 0.0000036\n",
      "[20/25][1630/9765] Loss_D: 0.0950 Loss_G: 0.0377 Convergence: 0.0963 k= 0.018828 lr = 0.0000036\n",
      "[20/25][1640/9765] Loss_D: 0.0887 Loss_G: 0.0378 Convergence: 0.0915 k= 0.018832 lr = 0.0000036\n",
      "[20/25][1650/9765] Loss_D: 0.1075 Loss_G: 0.0359 Convergence: 0.1156 k= 0.018845 lr = 0.0000036\n",
      "[20/25][1660/9765] Loss_D: 0.0986 Loss_G: 0.0375 Convergence: 0.1015 k= 0.018855 lr = 0.0000036\n",
      "[20/25][1670/9765] Loss_D: 0.0946 Loss_G: 0.0387 Convergence: 0.0959 k= 0.018853 lr = 0.0000036\n",
      "[20/25][1680/9765] Loss_D: 0.0942 Loss_G: 0.0409 Convergence: 0.0979 k= 0.018845 lr = 0.0000036\n",
      "[20/25][1690/9765] Loss_D: 0.1040 Loss_G: 0.0397 Convergence: 0.1070 k= 0.018838 lr = 0.0000036\n",
      "[20/25][1700/9765] Loss_D: 0.0921 Loss_G: 0.0410 Convergence: 0.0967 k= 0.018817 lr = 0.0000036\n",
      "[20/25][1710/9765] Loss_D: 0.0989 Loss_G: 0.0426 Convergence: 0.1024 k= 0.018805 lr = 0.0000036\n",
      "[20/25][1720/9765] Loss_D: 0.1038 Loss_G: 0.0427 Convergence: 0.1054 k= 0.018779 lr = 0.0000036\n",
      "[20/25][1730/9765] Loss_D: 0.0999 Loss_G: 0.0423 Convergence: 0.1028 k= 0.018753 lr = 0.0000036\n",
      "[20/25][1740/9765] Loss_D: 0.0878 Loss_G: 0.0397 Convergence: 0.0929 k= 0.018732 lr = 0.0000036\n",
      "[20/25][1750/9765] Loss_D: 0.0961 Loss_G: 0.0401 Convergence: 0.0982 k= 0.018732 lr = 0.0000036\n",
      "[20/25][1760/9765] Loss_D: 0.0920 Loss_G: 0.0382 Convergence: 0.0938 k= 0.018724 lr = 0.0000036\n",
      "[20/25][1770/9765] Loss_D: 0.0925 Loss_G: 0.0387 Convergence: 0.0946 k= 0.018721 lr = 0.0000036\n",
      "[20/25][1780/9765] Loss_D: 0.0960 Loss_G: 0.0385 Convergence: 0.0968 k= 0.018733 lr = 0.0000036\n",
      "[20/25][1790/9765] Loss_D: 0.1126 Loss_G: 0.0371 Convergence: 0.1216 k= 0.018740 lr = 0.0000036\n",
      "[20/25][1800/9765] Loss_D: 0.0957 Loss_G: 0.0382 Convergence: 0.0967 k= 0.018757 lr = 0.0000036\n",
      "[20/25][1810/9765] Loss_D: 0.0870 Loss_G: 0.0380 Convergence: 0.0906 k= 0.018760 lr = 0.0000036\n",
      "[20/25][1820/9765] Loss_D: 0.0897 Loss_G: 0.0389 Convergence: 0.0932 k= 0.018752 lr = 0.0000036\n",
      "[20/25][1830/9765] Loss_D: 0.0939 Loss_G: 0.0413 Convergence: 0.0982 k= 0.018721 lr = 0.0000036\n",
      "[20/25][1840/9765] Loss_D: 0.1000 Loss_G: 0.0424 Convergence: 0.1029 k= 0.018706 lr = 0.0000036\n",
      "[20/25][1850/9765] Loss_D: 0.0925 Loss_G: 0.0397 Convergence: 0.0957 k= 0.018673 lr = 0.0000036\n",
      "[20/25][1860/9765] Loss_D: 0.0924 Loss_G: 0.0418 Convergence: 0.0977 k= 0.018648 lr = 0.0000036\n",
      "[20/25][1870/9765] Loss_D: 0.0987 Loss_G: 0.0409 Convergence: 0.1006 k= 0.018605 lr = 0.0000036\n",
      "[20/25][1880/9765] Loss_D: 0.1014 Loss_G: 0.0415 Convergence: 0.1028 k= 0.018579 lr = 0.0000036\n",
      "[20/25][1890/9765] Loss_D: 0.0950 Loss_G: 0.0396 Convergence: 0.0970 k= 0.018577 lr = 0.0000036\n",
      "[20/25][1900/9765] Loss_D: 0.0900 Loss_G: 0.0374 Convergence: 0.0919 k= 0.018584 lr = 0.0000036\n",
      "[20/25][1910/9765] Loss_D: 0.1069 Loss_G: 0.0370 Convergence: 0.1136 k= 0.018608 lr = 0.0000036\n",
      "[20/25][1920/9765] Loss_D: 0.1014 Loss_G: 0.0352 Convergence: 0.1077 k= 0.018632 lr = 0.0000036\n",
      "[20/25][1930/9765] Loss_D: 0.0993 Loss_G: 0.0381 Convergence: 0.1020 k= 0.018661 lr = 0.0000036\n",
      "[20/25][1940/9765] Loss_D: 0.0977 Loss_G: 0.0372 Convergence: 0.1005 k= 0.018676 lr = 0.0000036\n",
      "[20/25][1950/9765] Loss_D: 0.1002 Loss_G: 0.0380 Convergence: 0.1033 k= 0.018703 lr = 0.0000036\n",
      "[20/25][1960/9765] Loss_D: 0.0909 Loss_G: 0.0367 Convergence: 0.0916 k= 0.018724 lr = 0.0000036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][1970/9765] Loss_D: 0.0974 Loss_G: 0.0363 Convergence: 0.1009 k= 0.018726 lr = 0.0000036\n",
      "[20/25][1980/9765] Loss_D: 0.0900 Loss_G: 0.0370 Convergence: 0.0914 k= 0.018747 lr = 0.0000036\n",
      "[20/25][1990/9765] Loss_D: 0.1040 Loss_G: 0.0380 Convergence: 0.1086 k= 0.018752 lr = 0.0000036\n",
      "[20/25][2000/9765] Loss_D: 0.1007 Loss_G: 0.0396 Convergence: 0.1023 k= 0.018750 lr = 0.0000036\n",
      "[20/25][2010/9765] Loss_D: 0.0997 Loss_G: 0.0400 Convergence: 0.1006 k= 0.018736 lr = 0.0000036\n",
      "[20/25][2020/9765] Loss_D: 0.0969 Loss_G: 0.0404 Convergence: 0.0990 k= 0.018717 lr = 0.0000036\n",
      "[20/25][2030/9765] Loss_D: 0.0992 Loss_G: 0.0392 Convergence: 0.1007 k= 0.018700 lr = 0.0000036\n",
      "[20/25][2040/9765] Loss_D: 0.1011 Loss_G: 0.0395 Convergence: 0.1031 k= 0.018690 lr = 0.0000036\n",
      "[20/25][2050/9765] Loss_D: 0.0964 Loss_G: 0.0389 Convergence: 0.0972 k= 0.018682 lr = 0.0000036\n",
      "[20/25][2060/9765] Loss_D: 0.0934 Loss_G: 0.0403 Convergence: 0.0968 k= 0.018674 lr = 0.0000036\n",
      "[20/25][2070/9765] Loss_D: 0.0952 Loss_G: 0.0383 Convergence: 0.0961 k= 0.018657 lr = 0.0000036\n",
      "[20/25][2080/9765] Loss_D: 0.0901 Loss_G: 0.0382 Convergence: 0.0926 k= 0.018660 lr = 0.0000036\n",
      "[20/25][2090/9765] Loss_D: 0.0878 Loss_G: 0.0380 Convergence: 0.0911 k= 0.018664 lr = 0.0000036\n",
      "[20/25][2100/9765] Loss_D: 0.0942 Loss_G: 0.0367 Convergence: 0.0962 k= 0.018672 lr = 0.0000036\n",
      "[20/25][2110/9765] Loss_D: 0.1013 Loss_G: 0.0375 Convergence: 0.1053 k= 0.018685 lr = 0.0000036\n",
      "[20/25][2120/9765] Loss_D: 0.0969 Loss_G: 0.0368 Convergence: 0.0998 k= 0.018697 lr = 0.0000036\n",
      "[20/25][2130/9765] Loss_D: 0.0962 Loss_G: 0.0366 Convergence: 0.0991 k= 0.018717 lr = 0.0000036\n",
      "[20/25][2140/9765] Loss_D: 0.1004 Loss_G: 0.0379 Convergence: 0.1037 k= 0.018737 lr = 0.0000036\n",
      "[20/25][2150/9765] Loss_D: 0.0967 Loss_G: 0.0386 Convergence: 0.0978 k= 0.018755 lr = 0.0000036\n",
      "[20/25][2160/9765] Loss_D: 0.0936 Loss_G: 0.0386 Convergence: 0.0952 k= 0.018769 lr = 0.0000036\n",
      "[20/25][2170/9765] Loss_D: 0.0987 Loss_G: 0.0379 Convergence: 0.1013 k= 0.018769 lr = 0.0000036\n",
      "[20/25][2180/9765] Loss_D: 0.0935 Loss_G: 0.0381 Convergence: 0.0946 k= 0.018758 lr = 0.0000036\n",
      "[20/25][2190/9765] Loss_D: 0.0983 Loss_G: 0.0395 Convergence: 0.0992 k= 0.018765 lr = 0.0000036\n",
      "[20/25][2200/9765] Loss_D: 0.1009 Loss_G: 0.0393 Convergence: 0.1030 k= 0.018768 lr = 0.0000036\n",
      "[20/25][2210/9765] Loss_D: 0.0888 Loss_G: 0.0384 Convergence: 0.0921 k= 0.018761 lr = 0.0000036\n",
      "[20/25][2220/9765] Loss_D: 0.0946 Loss_G: 0.0378 Convergence: 0.0957 k= 0.018764 lr = 0.0000036\n",
      "[20/25][2230/9765] Loss_D: 0.1026 Loss_G: 0.0386 Convergence: 0.1061 k= 0.018764 lr = 0.0000036\n",
      "[20/25][2240/9765] Loss_D: 0.0983 Loss_G: 0.0392 Convergence: 0.0994 k= 0.018751 lr = 0.0000036\n",
      "[20/25][2250/9765] Loss_D: 0.0913 Loss_G: 0.0382 Convergence: 0.0934 k= 0.018747 lr = 0.0000036\n",
      "[20/25][2260/9765] Loss_D: 0.0904 Loss_G: 0.0381 Convergence: 0.0928 k= 0.018754 lr = 0.0000036\n",
      "[20/25][2270/9765] Loss_D: 0.0925 Loss_G: 0.0385 Convergence: 0.0944 k= 0.018763 lr = 0.0000036\n",
      "[20/25][2280/9765] Loss_D: 0.1012 Loss_G: 0.0405 Convergence: 0.1022 k= 0.018759 lr = 0.0000036\n",
      "[20/25][2290/9765] Loss_D: 0.0924 Loss_G: 0.0382 Convergence: 0.0941 k= 0.018745 lr = 0.0000036\n",
      "[20/25][2300/9765] Loss_D: 0.0926 Loss_G: 0.0392 Convergence: 0.0952 k= 0.018735 lr = 0.0000036\n",
      "[20/25][2310/9765] Loss_D: 0.0853 Loss_G: 0.0373 Convergence: 0.0889 k= 0.018737 lr = 0.0000036\n",
      "[20/25][2320/9765] Loss_D: 0.0899 Loss_G: 0.0381 Convergence: 0.0925 k= 0.018748 lr = 0.0000036\n",
      "[20/25][2330/9765] Loss_D: 0.0996 Loss_G: 0.0384 Convergence: 0.1020 k= 0.018755 lr = 0.0000036\n",
      "[20/25][2340/9765] Loss_D: 0.0922 Loss_G: 0.0364 Convergence: 0.0936 k= 0.018773 lr = 0.0000036\n",
      "[20/25][2350/9765] Loss_D: 0.1058 Loss_G: 0.0376 Convergence: 0.1115 k= 0.018781 lr = 0.0000036\n",
      "[20/25][2360/9765] Loss_D: 0.0899 Loss_G: 0.0392 Convergence: 0.0935 k= 0.018785 lr = 0.0000036\n",
      "[20/25][2370/9765] Loss_D: 0.0955 Loss_G: 0.0382 Convergence: 0.0965 k= 0.018805 lr = 0.0000036\n",
      "[20/25][2380/9765] Loss_D: 0.0956 Loss_G: 0.0375 Convergence: 0.0973 k= 0.018820 lr = 0.0000036\n",
      "[20/25][2390/9765] Loss_D: 0.0989 Loss_G: 0.0398 Convergence: 0.0998 k= 0.018814 lr = 0.0000036\n",
      "[20/25][2400/9765] Loss_D: 0.0996 Loss_G: 0.0394 Convergence: 0.1011 k= 0.018809 lr = 0.0000036\n",
      "[20/25][2410/9765] Loss_D: 0.0995 Loss_G: 0.0393 Convergence: 0.1011 k= 0.018808 lr = 0.0000036\n",
      "[20/25][2420/9765] Loss_D: 0.0948 Loss_G: 0.0387 Convergence: 0.0960 k= 0.018801 lr = 0.0000036\n",
      "[20/25][2430/9765] Loss_D: 0.0988 Loss_G: 0.0393 Convergence: 0.1001 k= 0.018806 lr = 0.0000036\n",
      "[20/25][2440/9765] Loss_D: 0.1001 Loss_G: 0.0378 Convergence: 0.1033 k= 0.018811 lr = 0.0000036\n",
      "[20/25][2450/9765] Loss_D: 0.0963 Loss_G: 0.0394 Convergence: 0.0976 k= 0.018812 lr = 0.0000036\n",
      "[20/25][2460/9765] Loss_D: 0.1009 Loss_G: 0.0395 Convergence: 0.1028 k= 0.018799 lr = 0.0000036\n",
      "[20/25][2470/9765] Loss_D: 0.0880 Loss_G: 0.0393 Convergence: 0.0925 k= 0.018786 lr = 0.0000036\n",
      "[20/25][2480/9765] Loss_D: 0.0920 Loss_G: 0.0391 Convergence: 0.0948 k= 0.018778 lr = 0.0000036\n",
      "[20/25][2490/9765] Loss_D: 0.0953 Loss_G: 0.0367 Convergence: 0.0977 k= 0.018777 lr = 0.0000036\n",
      "[20/25][2500/9765] Loss_D: 0.0920 Loss_G: 0.0389 Convergence: 0.0946 k= 0.018779 lr = 0.0000036\n",
      "[20/25][2510/9765] Loss_D: 0.0898 Loss_G: 0.0393 Convergence: 0.0936 k= 0.018768 lr = 0.0000036\n",
      "[20/25][2520/9765] Loss_D: 0.0942 Loss_G: 0.0375 Convergence: 0.0954 k= 0.018761 lr = 0.0000036\n",
      "[20/25][2530/9765] Loss_D: 0.1032 Loss_G: 0.0391 Convergence: 0.1064 k= 0.018769 lr = 0.0000036\n",
      "[20/25][2540/9765] Loss_D: 0.0923 Loss_G: 0.0389 Convergence: 0.0947 k= 0.018761 lr = 0.0000036\n",
      "[20/25][2550/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0996 k= 0.018761 lr = 0.0000036\n",
      "[20/25][2560/9765] Loss_D: 0.1086 Loss_G: 0.0388 Convergence: 0.1143 k= 0.018751 lr = 0.0000036\n",
      "[20/25][2570/9765] Loss_D: 0.0935 Loss_G: 0.0376 Convergence: 0.0943 k= 0.018748 lr = 0.0000036\n",
      "[20/25][2580/9765] Loss_D: 0.1048 Loss_G: 0.0390 Convergence: 0.1087 k= 0.018765 lr = 0.0000036\n",
      "[20/25][2590/9765] Loss_D: 0.0962 Loss_G: 0.0403 Convergence: 0.0984 k= 0.018762 lr = 0.0000036\n",
      "[20/25][2600/9765] Loss_D: 0.0968 Loss_G: 0.0388 Convergence: 0.0977 k= 0.018740 lr = 0.0000036\n",
      "[20/25][2610/9765] Loss_D: 0.1013 Loss_G: 0.0412 Convergence: 0.1025 k= 0.018741 lr = 0.0000036\n",
      "[20/25][2620/9765] Loss_D: 0.0925 Loss_G: 0.0404 Convergence: 0.0964 k= 0.018732 lr = 0.0000036\n",
      "[20/25][2630/9765] Loss_D: 0.1023 Loss_G: 0.0400 Convergence: 0.1044 k= 0.018721 lr = 0.0000036\n",
      "[20/25][2640/9765] Loss_D: 0.0922 Loss_G: 0.0377 Convergence: 0.0935 k= 0.018725 lr = 0.0000036\n",
      "[20/25][2650/9765] Loss_D: 0.1064 Loss_G: 0.0403 Convergence: 0.1097 k= 0.018714 lr = 0.0000036\n",
      "[20/25][2660/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0974 k= 0.018714 lr = 0.0000036\n",
      "[20/25][2670/9765] Loss_D: 0.1059 Loss_G: 0.0381 Convergence: 0.1111 k= 0.018717 lr = 0.0000036\n",
      "[20/25][2680/9765] Loss_D: 0.1096 Loss_G: 0.0372 Convergence: 0.1172 k= 0.018734 lr = 0.0000036\n",
      "[20/25][2690/9765] Loss_D: 0.0969 Loss_G: 0.0383 Convergence: 0.0983 k= 0.018737 lr = 0.0000036\n",
      "[20/25][2700/9765] Loss_D: 0.1003 Loss_G: 0.0395 Convergence: 0.1020 k= 0.018740 lr = 0.0000034\n",
      "[20/25][2710/9765] Loss_D: 0.0962 Loss_G: 0.0383 Convergence: 0.0974 k= 0.018738 lr = 0.0000034\n",
      "[20/25][2720/9765] Loss_D: 0.0959 Loss_G: 0.0392 Convergence: 0.0972 k= 0.018735 lr = 0.0000034\n",
      "[20/25][2730/9765] Loss_D: 0.0956 Loss_G: 0.0380 Convergence: 0.0968 k= 0.018733 lr = 0.0000034\n",
      "[20/25][2740/9765] Loss_D: 0.0927 Loss_G: 0.0378 Convergence: 0.0938 k= 0.018743 lr = 0.0000034\n",
      "[20/25][2750/9765] Loss_D: 0.0936 Loss_G: 0.0378 Convergence: 0.0944 k= 0.018756 lr = 0.0000034\n",
      "[20/25][2760/9765] Loss_D: 0.0952 Loss_G: 0.0387 Convergence: 0.0962 k= 0.018768 lr = 0.0000034\n",
      "[20/25][2770/9765] Loss_D: 0.0939 Loss_G: 0.0380 Convergence: 0.0948 k= 0.018770 lr = 0.0000034\n",
      "[20/25][2780/9765] Loss_D: 0.0917 Loss_G: 0.0370 Convergence: 0.0925 k= 0.018786 lr = 0.0000034\n",
      "[20/25][2790/9765] Loss_D: 0.0993 Loss_G: 0.0378 Convergence: 0.1022 k= 0.018796 lr = 0.0000034\n",
      "[20/25][2800/9765] Loss_D: 0.0996 Loss_G: 0.0379 Convergence: 0.1026 k= 0.018801 lr = 0.0000034\n",
      "[20/25][2810/9765] Loss_D: 0.0880 Loss_G: 0.0384 Convergence: 0.0917 k= 0.018815 lr = 0.0000034\n",
      "[20/25][2820/9765] Loss_D: 0.0982 Loss_G: 0.0383 Convergence: 0.1002 k= 0.018839 lr = 0.0000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][2830/9765] Loss_D: 0.0969 Loss_G: 0.0384 Convergence: 0.0983 k= 0.018834 lr = 0.0000034\n",
      "[20/25][2840/9765] Loss_D: 0.0956 Loss_G: 0.0378 Convergence: 0.0970 k= 0.018839 lr = 0.0000034\n",
      "[20/25][2850/9765] Loss_D: 0.1072 Loss_G: 0.0396 Convergence: 0.1116 k= 0.018839 lr = 0.0000034\n",
      "[20/25][2860/9765] Loss_D: 0.0947 Loss_G: 0.0379 Convergence: 0.0958 k= 0.018842 lr = 0.0000034\n",
      "[20/25][2870/9765] Loss_D: 0.0905 Loss_G: 0.0375 Convergence: 0.0922 k= 0.018847 lr = 0.0000034\n",
      "[20/25][2880/9765] Loss_D: 0.0946 Loss_G: 0.0377 Convergence: 0.0957 k= 0.018847 lr = 0.0000034\n",
      "[20/25][2890/9765] Loss_D: 0.0872 Loss_G: 0.0391 Convergence: 0.0919 k= 0.018853 lr = 0.0000034\n",
      "[20/25][2900/9765] Loss_D: 0.1002 Loss_G: 0.0378 Convergence: 0.1034 k= 0.018850 lr = 0.0000034\n",
      "[20/25][2910/9765] Loss_D: 0.0916 Loss_G: 0.0386 Convergence: 0.0940 k= 0.018857 lr = 0.0000034\n",
      "[20/25][2920/9765] Loss_D: 0.0986 Loss_G: 0.0385 Convergence: 0.1005 k= 0.018870 lr = 0.0000034\n",
      "[20/25][2930/9765] Loss_D: 0.1032 Loss_G: 0.0382 Convergence: 0.1073 k= 0.018875 lr = 0.0000034\n",
      "[20/25][2940/9765] Loss_D: 0.0963 Loss_G: 0.0381 Convergence: 0.0977 k= 0.018881 lr = 0.0000034\n",
      "[20/25][2950/9765] Loss_D: 0.0943 Loss_G: 0.0379 Convergence: 0.0952 k= 0.018873 lr = 0.0000034\n",
      "[20/25][2960/9765] Loss_D: 0.1044 Loss_G: 0.0405 Convergence: 0.1067 k= 0.018874 lr = 0.0000034\n",
      "[20/25][2970/9765] Loss_D: 0.0924 Loss_G: 0.0380 Convergence: 0.0939 k= 0.018868 lr = 0.0000034\n",
      "[20/25][2980/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1005 k= 0.018874 lr = 0.0000034\n",
      "[20/25][2990/9765] Loss_D: 0.0966 Loss_G: 0.0396 Convergence: 0.0980 k= 0.018867 lr = 0.0000034\n",
      "[20/25][3000/9765] Loss_D: 0.0915 Loss_G: 0.0409 Convergence: 0.0962 k= 0.018860 lr = 0.0000034\n",
      "[20/25][3010/9765] Loss_D: 0.0859 Loss_G: 0.0405 Convergence: 0.0925 k= 0.018847 lr = 0.0000034\n",
      "[20/25][3020/9765] Loss_D: 0.1001 Loss_G: 0.0402 Convergence: 0.1010 k= 0.018833 lr = 0.0000034\n",
      "[20/25][3030/9765] Loss_D: 0.1050 Loss_G: 0.0397 Convergence: 0.1084 k= 0.018827 lr = 0.0000034\n",
      "[20/25][3040/9765] Loss_D: 0.0864 Loss_G: 0.0407 Convergence: 0.0931 k= 0.018806 lr = 0.0000034\n",
      "[20/25][3050/9765] Loss_D: 0.0959 Loss_G: 0.0396 Convergence: 0.0976 k= 0.018795 lr = 0.0000034\n",
      "[20/25][3060/9765] Loss_D: 0.0980 Loss_G: 0.0385 Convergence: 0.0997 k= 0.018788 lr = 0.0000034\n",
      "[20/25][3070/9765] Loss_D: 0.0887 Loss_G: 0.0393 Convergence: 0.0929 k= 0.018785 lr = 0.0000034\n",
      "[20/25][3080/9765] Loss_D: 0.0920 Loss_G: 0.0375 Convergence: 0.0931 k= 0.018797 lr = 0.0000034\n",
      "[20/25][3090/9765] Loss_D: 0.1039 Loss_G: 0.0364 Convergence: 0.1100 k= 0.018810 lr = 0.0000034\n",
      "[20/25][3100/9765] Loss_D: 0.0995 Loss_G: 0.0373 Convergence: 0.1030 k= 0.018838 lr = 0.0000034\n",
      "[20/25][3110/9765] Loss_D: 0.0881 Loss_G: 0.0373 Convergence: 0.0905 k= 0.018860 lr = 0.0000034\n",
      "[20/25][3120/9765] Loss_D: 0.0933 Loss_G: 0.0371 Convergence: 0.0945 k= 0.018874 lr = 0.0000034\n",
      "[20/25][3130/9765] Loss_D: 0.1015 Loss_G: 0.0393 Convergence: 0.1039 k= 0.018901 lr = 0.0000034\n",
      "[20/25][3140/9765] Loss_D: 0.0930 Loss_G: 0.0370 Convergence: 0.0943 k= 0.018893 lr = 0.0000034\n",
      "[20/25][3150/9765] Loss_D: 0.0912 Loss_G: 0.0388 Convergence: 0.0939 k= 0.018891 lr = 0.0000034\n",
      "[20/25][3160/9765] Loss_D: 0.1015 Loss_G: 0.0383 Convergence: 0.1047 k= 0.018896 lr = 0.0000034\n",
      "[20/25][3170/9765] Loss_D: 0.0943 Loss_G: 0.0399 Convergence: 0.0969 k= 0.018897 lr = 0.0000034\n",
      "[20/25][3180/9765] Loss_D: 0.0905 Loss_G: 0.0408 Convergence: 0.0955 k= 0.018883 lr = 0.0000034\n",
      "[20/25][3190/9765] Loss_D: 0.0876 Loss_G: 0.0412 Convergence: 0.0942 k= 0.018861 lr = 0.0000034\n",
      "[20/25][3200/9765] Loss_D: 0.0939 Loss_G: 0.0385 Convergence: 0.0953 k= 0.018848 lr = 0.0000034\n",
      "[20/25][3210/9765] Loss_D: 0.0952 Loss_G: 0.0398 Convergence: 0.0974 k= 0.018820 lr = 0.0000034\n",
      "[20/25][3220/9765] Loss_D: 0.0972 Loss_G: 0.0434 Convergence: 0.1023 k= 0.018796 lr = 0.0000034\n",
      "[20/25][3230/9765] Loss_D: 0.0974 Loss_G: 0.0394 Convergence: 0.0983 k= 0.018789 lr = 0.0000034\n",
      "[20/25][3240/9765] Loss_D: 0.0920 Loss_G: 0.0398 Convergence: 0.0954 k= 0.018769 lr = 0.0000034\n",
      "[20/25][3250/9765] Loss_D: 0.1035 Loss_G: 0.0389 Convergence: 0.1071 k= 0.018765 lr = 0.0000034\n",
      "[20/25][3260/9765] Loss_D: 0.0919 Loss_G: 0.0379 Convergence: 0.0935 k= 0.018758 lr = 0.0000034\n",
      "[20/25][3270/9765] Loss_D: 0.0881 Loss_G: 0.0383 Convergence: 0.0916 k= 0.018762 lr = 0.0000034\n",
      "[20/25][3280/9765] Loss_D: 0.0965 Loss_G: 0.0383 Convergence: 0.0978 k= 0.018770 lr = 0.0000034\n",
      "[20/25][3290/9765] Loss_D: 0.0968 Loss_G: 0.0357 Convergence: 0.1008 k= 0.018783 lr = 0.0000034\n",
      "[20/25][3300/9765] Loss_D: 0.0840 Loss_G: 0.0367 Convergence: 0.0875 k= 0.018806 lr = 0.0000034\n",
      "[20/25][3310/9765] Loss_D: 0.0927 Loss_G: 0.0382 Convergence: 0.0942 k= 0.018814 lr = 0.0000034\n",
      "[20/25][3320/9765] Loss_D: 0.0982 Loss_G: 0.0383 Convergence: 0.1002 k= 0.018812 lr = 0.0000034\n",
      "[20/25][3330/9765] Loss_D: 0.0941 Loss_G: 0.0361 Convergence: 0.0966 k= 0.018838 lr = 0.0000034\n",
      "[20/25][3340/9765] Loss_D: 0.0891 Loss_G: 0.0374 Convergence: 0.0913 k= 0.018857 lr = 0.0000034\n",
      "[20/25][3350/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0989 k= 0.018864 lr = 0.0000034\n",
      "[20/25][3360/9765] Loss_D: 0.0951 Loss_G: 0.0380 Convergence: 0.0962 k= 0.018866 lr = 0.0000034\n",
      "[20/25][3370/9765] Loss_D: 0.0997 Loss_G: 0.0407 Convergence: 0.1010 k= 0.018856 lr = 0.0000034\n",
      "[20/25][3380/9765] Loss_D: 0.0950 Loss_G: 0.0414 Convergence: 0.0988 k= 0.018834 lr = 0.0000034\n",
      "[20/25][3390/9765] Loss_D: 0.0898 Loss_G: 0.0371 Convergence: 0.0914 k= 0.018815 lr = 0.0000034\n",
      "[20/25][3400/9765] Loss_D: 0.0865 Loss_G: 0.0390 Convergence: 0.0913 k= 0.018809 lr = 0.0000034\n",
      "[20/25][3410/9765] Loss_D: 0.0987 Loss_G: 0.0396 Convergence: 0.0997 k= 0.018801 lr = 0.0000034\n",
      "[20/25][3420/9765] Loss_D: 0.0981 Loss_G: 0.0404 Convergence: 0.0997 k= 0.018786 lr = 0.0000034\n",
      "[20/25][3430/9765] Loss_D: 0.0933 Loss_G: 0.0413 Convergence: 0.0978 k= 0.018766 lr = 0.0000034\n",
      "[20/25][3440/9765] Loss_D: 0.0929 Loss_G: 0.0418 Convergence: 0.0980 k= 0.018751 lr = 0.0000034\n",
      "[20/25][3450/9765] Loss_D: 0.1055 Loss_G: 0.0399 Convergence: 0.1089 k= 0.018752 lr = 0.0000034\n",
      "[20/25][3460/9765] Loss_D: 0.1020 Loss_G: 0.0405 Convergence: 0.1034 k= 0.018737 lr = 0.0000034\n",
      "[20/25][3470/9765] Loss_D: 0.0902 Loss_G: 0.0383 Convergence: 0.0929 k= 0.018724 lr = 0.0000034\n",
      "[20/25][3480/9765] Loss_D: 0.0988 Loss_G: 0.0372 Convergence: 0.1022 k= 0.018732 lr = 0.0000034\n",
      "[20/25][3490/9765] Loss_D: 0.1008 Loss_G: 0.0363 Convergence: 0.1058 k= 0.018754 lr = 0.0000034\n",
      "[20/25][3500/9765] Loss_D: 0.1036 Loss_G: 0.0378 Convergence: 0.1083 k= 0.018779 lr = 0.0000034\n",
      "[20/25][3510/9765] Loss_D: 0.0968 Loss_G: 0.0382 Convergence: 0.0983 k= 0.018798 lr = 0.0000034\n",
      "[20/25][3520/9765] Loss_D: 0.0893 Loss_G: 0.0386 Convergence: 0.0926 k= 0.018813 lr = 0.0000034\n",
      "[20/25][3530/9765] Loss_D: 0.0994 Loss_G: 0.0381 Convergence: 0.1020 k= 0.018815 lr = 0.0000034\n",
      "[20/25][3540/9765] Loss_D: 0.0973 Loss_G: 0.0384 Convergence: 0.0988 k= 0.018825 lr = 0.0000034\n",
      "[20/25][3550/9765] Loss_D: 0.1022 Loss_G: 0.0378 Convergence: 0.1063 k= 0.018831 lr = 0.0000034\n",
      "[20/25][3560/9765] Loss_D: 0.0929 Loss_G: 0.0391 Convergence: 0.0952 k= 0.018834 lr = 0.0000034\n",
      "[20/25][3570/9765] Loss_D: 0.1000 Loss_G: 0.0399 Convergence: 0.1011 k= 0.018829 lr = 0.0000034\n",
      "[20/25][3580/9765] Loss_D: 0.0958 Loss_G: 0.0402 Convergence: 0.0981 k= 0.018826 lr = 0.0000034\n",
      "[20/25][3590/9765] Loss_D: 0.0983 Loss_G: 0.0391 Convergence: 0.0995 k= 0.018837 lr = 0.0000034\n",
      "[20/25][3600/9765] Loss_D: 0.1002 Loss_G: 0.0377 Convergence: 0.1036 k= 0.018836 lr = 0.0000034\n",
      "[20/25][3610/9765] Loss_D: 0.0930 Loss_G: 0.0393 Convergence: 0.0955 k= 0.018842 lr = 0.0000034\n",
      "[20/25][3620/9765] Loss_D: 0.0971 Loss_G: 0.0370 Convergence: 0.1000 k= 0.018842 lr = 0.0000034\n",
      "[20/25][3630/9765] Loss_D: 0.0933 Loss_G: 0.0373 Convergence: 0.0943 k= 0.018849 lr = 0.0000034\n",
      "[20/25][3640/9765] Loss_D: 0.0919 Loss_G: 0.0378 Convergence: 0.0933 k= 0.018857 lr = 0.0000034\n",
      "[20/25][3650/9765] Loss_D: 0.0892 Loss_G: 0.0372 Convergence: 0.0912 k= 0.018865 lr = 0.0000034\n",
      "[20/25][3660/9765] Loss_D: 0.0994 Loss_G: 0.0392 Convergence: 0.1010 k= 0.018877 lr = 0.0000034\n",
      "[20/25][3670/9765] Loss_D: 0.1063 Loss_G: 0.0390 Convergence: 0.1109 k= 0.018880 lr = 0.0000034\n",
      "[20/25][3680/9765] Loss_D: 0.1053 Loss_G: 0.0396 Convergence: 0.1089 k= 0.018891 lr = 0.0000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][3690/9765] Loss_D: 0.0943 Loss_G: 0.0394 Convergence: 0.0964 k= 0.018877 lr = 0.0000034\n",
      "[20/25][3700/9765] Loss_D: 0.0987 Loss_G: 0.0399 Convergence: 0.0995 k= 0.018876 lr = 0.0000034\n",
      "[20/25][3710/9765] Loss_D: 0.0912 Loss_G: 0.0406 Convergence: 0.0958 k= 0.018877 lr = 0.0000034\n",
      "[20/25][3720/9765] Loss_D: 0.0931 Loss_G: 0.0409 Convergence: 0.0972 k= 0.018863 lr = 0.0000034\n",
      "[20/25][3730/9765] Loss_D: 0.0924 Loss_G: 0.0400 Convergence: 0.0959 k= 0.018842 lr = 0.0000034\n",
      "[20/25][3740/9765] Loss_D: 0.0957 Loss_G: 0.0391 Convergence: 0.0970 k= 0.018823 lr = 0.0000034\n",
      "[20/25][3750/9765] Loss_D: 0.0923 Loss_G: 0.0388 Convergence: 0.0946 k= 0.018816 lr = 0.0000034\n",
      "[20/25][3760/9765] Loss_D: 0.0946 Loss_G: 0.0379 Convergence: 0.0955 k= 0.018820 lr = 0.0000034\n",
      "[20/25][3770/9765] Loss_D: 0.0857 Loss_G: 0.0394 Convergence: 0.0913 k= 0.018815 lr = 0.0000034\n",
      "[20/25][3780/9765] Loss_D: 0.0881 Loss_G: 0.0381 Convergence: 0.0914 k= 0.018820 lr = 0.0000034\n",
      "[20/25][3790/9765] Loss_D: 0.0979 Loss_G: 0.0381 Convergence: 0.1000 k= 0.018830 lr = 0.0000034\n",
      "[20/25][3800/9765] Loss_D: 0.0947 Loss_G: 0.0375 Convergence: 0.0960 k= 0.018827 lr = 0.0000034\n",
      "[20/25][3810/9765] Loss_D: 0.0914 Loss_G: 0.0390 Convergence: 0.0943 k= 0.018828 lr = 0.0000034\n",
      "[20/25][3820/9765] Loss_D: 0.0987 Loss_G: 0.0413 Convergence: 0.1010 k= 0.018817 lr = 0.0000034\n",
      "[20/25][3830/9765] Loss_D: 0.0943 Loss_G: 0.0383 Convergence: 0.0953 k= 0.018823 lr = 0.0000034\n",
      "[20/25][3840/9765] Loss_D: 0.0944 Loss_G: 0.0384 Convergence: 0.0955 k= 0.018827 lr = 0.0000034\n",
      "[20/25][3850/9765] Loss_D: 0.0977 Loss_G: 0.0392 Convergence: 0.0987 k= 0.018836 lr = 0.0000034\n",
      "[20/25][3860/9765] Loss_D: 0.0871 Loss_G: 0.0376 Convergence: 0.0903 k= 0.018833 lr = 0.0000034\n",
      "[20/25][3870/9765] Loss_D: 0.0999 Loss_G: 0.0386 Convergence: 0.1024 k= 0.018849 lr = 0.0000034\n",
      "[20/25][3880/9765] Loss_D: 0.0964 Loss_G: 0.0399 Convergence: 0.0982 k= 0.018847 lr = 0.0000034\n",
      "[20/25][3890/9765] Loss_D: 0.0958 Loss_G: 0.0402 Convergence: 0.0982 k= 0.018840 lr = 0.0000034\n",
      "[20/25][3900/9765] Loss_D: 0.0942 Loss_G: 0.0383 Convergence: 0.0952 k= 0.018844 lr = 0.0000034\n",
      "[20/25][3910/9765] Loss_D: 0.0845 Loss_G: 0.0384 Convergence: 0.0895 k= 0.018844 lr = 0.0000034\n",
      "[20/25][3920/9765] Loss_D: 0.0872 Loss_G: 0.0384 Convergence: 0.0912 k= 0.018853 lr = 0.0000034\n",
      "[20/25][3930/9765] Loss_D: 0.1007 Loss_G: 0.0388 Convergence: 0.1032 k= 0.018862 lr = 0.0000034\n",
      "[20/25][3940/9765] Loss_D: 0.0894 Loss_G: 0.0384 Convergence: 0.0925 k= 0.018858 lr = 0.0000034\n",
      "[20/25][3950/9765] Loss_D: 0.0973 Loss_G: 0.0384 Convergence: 0.0988 k= 0.018855 lr = 0.0000034\n",
      "[20/25][3960/9765] Loss_D: 0.0954 Loss_G: 0.0382 Convergence: 0.0964 k= 0.018850 lr = 0.0000034\n",
      "[20/25][3970/9765] Loss_D: 0.0919 Loss_G: 0.0395 Convergence: 0.0951 k= 0.018849 lr = 0.0000034\n",
      "[20/25][3980/9765] Loss_D: 0.1021 Loss_G: 0.0392 Convergence: 0.1048 k= 0.018859 lr = 0.0000034\n",
      "[20/25][3990/9765] Loss_D: 0.0926 Loss_G: 0.0379 Convergence: 0.0938 k= 0.018849 lr = 0.0000034\n",
      "[20/25][4000/9765] Loss_D: 0.0949 Loss_G: 0.0392 Convergence: 0.0966 k= 0.018849 lr = 0.0000034\n",
      "[20/25][4010/9765] Loss_D: 0.0962 Loss_G: 0.0395 Convergence: 0.0977 k= 0.018837 lr = 0.0000034\n",
      "[20/25][4020/9765] Loss_D: 0.0982 Loss_G: 0.0368 Convergence: 0.1017 k= 0.018837 lr = 0.0000034\n",
      "[20/25][4030/9765] Loss_D: 0.0948 Loss_G: 0.0379 Convergence: 0.0958 k= 0.018854 lr = 0.0000034\n",
      "[20/25][4040/9765] Loss_D: 0.0991 Loss_G: 0.0379 Convergence: 0.1018 k= 0.018857 lr = 0.0000034\n",
      "[20/25][4050/9765] Loss_D: 0.0913 Loss_G: 0.0386 Convergence: 0.0939 k= 0.018854 lr = 0.0000034\n",
      "[20/25][4060/9765] Loss_D: 0.1033 Loss_G: 0.0397 Convergence: 0.1060 k= 0.018850 lr = 0.0000034\n",
      "[20/25][4070/9765] Loss_D: 0.0964 Loss_G: 0.0394 Convergence: 0.0977 k= 0.018843 lr = 0.0000034\n",
      "[20/25][4080/9765] Loss_D: 0.0935 Loss_G: 0.0378 Convergence: 0.0943 k= 0.018849 lr = 0.0000034\n",
      "[20/25][4090/9765] Loss_D: 0.0872 Loss_G: 0.0371 Convergence: 0.0898 k= 0.018865 lr = 0.0000034\n",
      "[20/25][4100/9765] Loss_D: 0.0960 Loss_G: 0.0395 Convergence: 0.0975 k= 0.018867 lr = 0.0000034\n",
      "[20/25][4110/9765] Loss_D: 0.0941 Loss_G: 0.0374 Convergence: 0.0953 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4120/9765] Loss_D: 0.0941 Loss_G: 0.0386 Convergence: 0.0955 k= 0.018872 lr = 0.0000034\n",
      "[20/25][4130/9765] Loss_D: 0.0904 Loss_G: 0.0381 Convergence: 0.0927 k= 0.018866 lr = 0.0000034\n",
      "[20/25][4140/9765] Loss_D: 0.0973 Loss_G: 0.0368 Convergence: 0.1004 k= 0.018872 lr = 0.0000034\n",
      "[20/25][4150/9765] Loss_D: 0.0935 Loss_G: 0.0377 Convergence: 0.0943 k= 0.018869 lr = 0.0000034\n",
      "[20/25][4160/9765] Loss_D: 0.0910 Loss_G: 0.0371 Convergence: 0.0922 k= 0.018872 lr = 0.0000034\n",
      "[20/25][4170/9765] Loss_D: 0.0910 Loss_G: 0.0385 Convergence: 0.0936 k= 0.018879 lr = 0.0000034\n",
      "[20/25][4180/9765] Loss_D: 0.0969 Loss_G: 0.0380 Convergence: 0.0986 k= 0.018882 lr = 0.0000034\n",
      "[20/25][4190/9765] Loss_D: 0.1032 Loss_G: 0.0392 Convergence: 0.1063 k= 0.018899 lr = 0.0000034\n",
      "[20/25][4200/9765] Loss_D: 0.0986 Loss_G: 0.0389 Convergence: 0.1002 k= 0.018900 lr = 0.0000034\n",
      "[20/25][4210/9765] Loss_D: 0.0971 Loss_G: 0.0389 Convergence: 0.0980 k= 0.018893 lr = 0.0000034\n",
      "[20/25][4220/9765] Loss_D: 0.1025 Loss_G: 0.0411 Convergence: 0.1035 k= 0.018884 lr = 0.0000034\n",
      "[20/25][4230/9765] Loss_D: 0.1002 Loss_G: 0.0393 Convergence: 0.1020 k= 0.018886 lr = 0.0000034\n",
      "[20/25][4240/9765] Loss_D: 0.0922 Loss_G: 0.0389 Convergence: 0.0947 k= 0.018886 lr = 0.0000034\n",
      "[20/25][4250/9765] Loss_D: 0.1046 Loss_G: 0.0407 Convergence: 0.1068 k= 0.018873 lr = 0.0000034\n",
      "[20/25][4260/9765] Loss_D: 0.0893 Loss_G: 0.0393 Convergence: 0.0933 k= 0.018858 lr = 0.0000034\n",
      "[20/25][4270/9765] Loss_D: 0.1061 Loss_G: 0.0380 Convergence: 0.1115 k= 0.018858 lr = 0.0000034\n",
      "[20/25][4280/9765] Loss_D: 0.0987 Loss_G: 0.0383 Convergence: 0.1009 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4290/9765] Loss_D: 0.0990 Loss_G: 0.0379 Convergence: 0.1018 k= 0.018869 lr = 0.0000034\n",
      "[20/25][4300/9765] Loss_D: 0.0970 Loss_G: 0.0394 Convergence: 0.0981 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4310/9765] Loss_D: 0.0980 Loss_G: 0.0381 Convergence: 0.1001 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4320/9765] Loss_D: 0.1009 Loss_G: 0.0371 Convergence: 0.1050 k= 0.018878 lr = 0.0000034\n",
      "[20/25][4330/9765] Loss_D: 0.1015 Loss_G: 0.0384 Convergence: 0.1047 k= 0.018900 lr = 0.0000034\n",
      "[20/25][4340/9765] Loss_D: 0.0932 Loss_G: 0.0380 Convergence: 0.0944 k= 0.018882 lr = 0.0000034\n",
      "[20/25][4350/9765] Loss_D: 0.0979 Loss_G: 0.0390 Convergence: 0.0991 k= 0.018888 lr = 0.0000034\n",
      "[20/25][4360/9765] Loss_D: 0.1002 Loss_G: 0.0390 Convergence: 0.1023 k= 0.018880 lr = 0.0000034\n",
      "[20/25][4370/9765] Loss_D: 0.1030 Loss_G: 0.0377 Convergence: 0.1075 k= 0.018888 lr = 0.0000034\n",
      "[20/25][4380/9765] Loss_D: 0.0954 Loss_G: 0.0394 Convergence: 0.0971 k= 0.018889 lr = 0.0000034\n",
      "[20/25][4390/9765] Loss_D: 0.1054 Loss_G: 0.0388 Convergence: 0.1097 k= 0.018896 lr = 0.0000034\n",
      "[20/25][4400/9765] Loss_D: 0.1029 Loss_G: 0.0384 Convergence: 0.1067 k= 0.018888 lr = 0.0000034\n",
      "[20/25][4410/9765] Loss_D: 0.1049 Loss_G: 0.0383 Convergence: 0.1095 k= 0.018901 lr = 0.0000034\n",
      "[20/25][4420/9765] Loss_D: 0.0889 Loss_G: 0.0372 Convergence: 0.0910 k= 0.018901 lr = 0.0000034\n",
      "[20/25][4430/9765] Loss_D: 0.0942 Loss_G: 0.0391 Convergence: 0.0961 k= 0.018905 lr = 0.0000034\n",
      "[20/25][4440/9765] Loss_D: 0.1015 Loss_G: 0.0377 Convergence: 0.1054 k= 0.018908 lr = 0.0000034\n",
      "[20/25][4450/9765] Loss_D: 0.1089 Loss_G: 0.0368 Convergence: 0.1166 k= 0.018920 lr = 0.0000034\n",
      "[20/25][4460/9765] Loss_D: 0.0981 Loss_G: 0.0377 Convergence: 0.1006 k= 0.018941 lr = 0.0000034\n",
      "[20/25][4470/9765] Loss_D: 0.0913 Loss_G: 0.0376 Convergence: 0.0929 k= 0.018960 lr = 0.0000034\n",
      "[20/25][4480/9765] Loss_D: 0.0952 Loss_G: 0.0384 Convergence: 0.0960 k= 0.018964 lr = 0.0000034\n",
      "[20/25][4490/9765] Loss_D: 0.0932 Loss_G: 0.0399 Convergence: 0.0963 k= 0.018957 lr = 0.0000034\n",
      "[20/25][4500/9765] Loss_D: 0.0916 Loss_G: 0.0386 Convergence: 0.0939 k= 0.018947 lr = 0.0000034\n",
      "[20/25][4510/9765] Loss_D: 0.0865 Loss_G: 0.0406 Convergence: 0.0929 k= 0.018939 lr = 0.0000034\n",
      "[20/25][4520/9765] Loss_D: 0.0981 Loss_G: 0.0409 Convergence: 0.1002 k= 0.018933 lr = 0.0000034\n",
      "[20/25][4530/9765] Loss_D: 0.0932 Loss_G: 0.0413 Convergence: 0.0977 k= 0.018918 lr = 0.0000034\n",
      "[20/25][4540/9765] Loss_D: 0.1010 Loss_G: 0.0397 Convergence: 0.1027 k= 0.018906 lr = 0.0000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][4550/9765] Loss_D: 0.0997 Loss_G: 0.0402 Convergence: 0.1005 k= 0.018896 lr = 0.0000034\n",
      "[20/25][4560/9765] Loss_D: 0.0935 Loss_G: 0.0409 Convergence: 0.0975 k= 0.018891 lr = 0.0000034\n",
      "[20/25][4570/9765] Loss_D: 0.0947 Loss_G: 0.0386 Convergence: 0.0958 k= 0.018899 lr = 0.0000034\n",
      "[20/25][4580/9765] Loss_D: 0.0903 Loss_G: 0.0385 Convergence: 0.0931 k= 0.018894 lr = 0.0000034\n",
      "[20/25][4590/9765] Loss_D: 0.0969 Loss_G: 0.0381 Convergence: 0.0986 k= 0.018905 lr = 0.0000034\n",
      "[20/25][4600/9765] Loss_D: 0.0954 Loss_G: 0.0376 Convergence: 0.0970 k= 0.018904 lr = 0.0000034\n",
      "[20/25][4610/9765] Loss_D: 0.0829 Loss_G: 0.0361 Convergence: 0.0862 k= 0.018908 lr = 0.0000034\n",
      "[20/25][4620/9765] Loss_D: 0.0901 Loss_G: 0.0388 Convergence: 0.0933 k= 0.018933 lr = 0.0000034\n",
      "[20/25][4630/9765] Loss_D: 0.0963 Loss_G: 0.0387 Convergence: 0.0971 k= 0.018941 lr = 0.0000034\n",
      "[20/25][4640/9765] Loss_D: 0.0879 Loss_G: 0.0385 Convergence: 0.0917 k= 0.018952 lr = 0.0000034\n",
      "[20/25][4650/9765] Loss_D: 0.0996 Loss_G: 0.0379 Convergence: 0.1025 k= 0.018961 lr = 0.0000034\n",
      "[20/25][4660/9765] Loss_D: 0.1085 Loss_G: 0.0384 Convergence: 0.1146 k= 0.018965 lr = 0.0000034\n",
      "[20/25][4670/9765] Loss_D: 0.0939 Loss_G: 0.0385 Convergence: 0.0954 k= 0.018952 lr = 0.0000034\n",
      "[20/25][4680/9765] Loss_D: 0.0987 Loss_G: 0.0402 Convergence: 0.0998 k= 0.018952 lr = 0.0000034\n",
      "[20/25][4690/9765] Loss_D: 0.0979 Loss_G: 0.0397 Convergence: 0.0989 k= 0.018951 lr = 0.0000034\n",
      "[20/25][4700/9765] Loss_D: 0.0928 Loss_G: 0.0402 Convergence: 0.0964 k= 0.018935 lr = 0.0000034\n",
      "[20/25][4710/9765] Loss_D: 0.0971 Loss_G: 0.0391 Convergence: 0.0979 k= 0.018932 lr = 0.0000034\n",
      "[20/25][4720/9765] Loss_D: 0.0973 Loss_G: 0.0398 Convergence: 0.0986 k= 0.018918 lr = 0.0000034\n",
      "[20/25][4730/9765] Loss_D: 0.1000 Loss_G: 0.0397 Convergence: 0.1014 k= 0.018919 lr = 0.0000034\n",
      "[20/25][4740/9765] Loss_D: 0.0955 Loss_G: 0.0403 Convergence: 0.0980 k= 0.018914 lr = 0.0000034\n",
      "[20/25][4750/9765] Loss_D: 0.0929 Loss_G: 0.0405 Convergence: 0.0967 k= 0.018891 lr = 0.0000034\n",
      "[20/25][4760/9765] Loss_D: 0.1014 Loss_G: 0.0373 Convergence: 0.1056 k= 0.018876 lr = 0.0000034\n",
      "[20/25][4770/9765] Loss_D: 0.0883 Loss_G: 0.0389 Convergence: 0.0923 k= 0.018874 lr = 0.0000034\n",
      "[20/25][4780/9765] Loss_D: 0.0951 Loss_G: 0.0366 Convergence: 0.0975 k= 0.018884 lr = 0.0000034\n",
      "[20/25][4790/9765] Loss_D: 0.0924 Loss_G: 0.0378 Convergence: 0.0937 k= 0.018882 lr = 0.0000034\n",
      "[20/25][4800/9765] Loss_D: 0.1006 Loss_G: 0.0397 Convergence: 0.1022 k= 0.018885 lr = 0.0000034\n",
      "[20/25][4810/9765] Loss_D: 0.0966 Loss_G: 0.0399 Convergence: 0.0983 k= 0.018879 lr = 0.0000034\n",
      "[20/25][4820/9765] Loss_D: 0.0938 Loss_G: 0.0384 Convergence: 0.0951 k= 0.018875 lr = 0.0000034\n",
      "[20/25][4830/9765] Loss_D: 0.0971 Loss_G: 0.0387 Convergence: 0.0983 k= 0.018870 lr = 0.0000034\n",
      "[20/25][4840/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0966 k= 0.018862 lr = 0.0000034\n",
      "[20/25][4850/9765] Loss_D: 0.0917 Loss_G: 0.0392 Convergence: 0.0947 k= 0.018870 lr = 0.0000034\n",
      "[20/25][4860/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1005 k= 0.018878 lr = 0.0000034\n",
      "[20/25][4870/9765] Loss_D: 0.0887 Loss_G: 0.0390 Convergence: 0.0927 k= 0.018878 lr = 0.0000034\n",
      "[20/25][4880/9765] Loss_D: 0.0862 Loss_G: 0.0375 Convergence: 0.0897 k= 0.018870 lr = 0.0000034\n",
      "[20/25][4890/9765] Loss_D: 0.0984 Loss_G: 0.0381 Convergence: 0.1007 k= 0.018872 lr = 0.0000034\n",
      "[20/25][4900/9765] Loss_D: 0.0899 Loss_G: 0.0380 Convergence: 0.0924 k= 0.018866 lr = 0.0000034\n",
      "[20/25][4910/9765] Loss_D: 0.0923 Loss_G: 0.0385 Convergence: 0.0943 k= 0.018867 lr = 0.0000034\n",
      "[20/25][4920/9765] Loss_D: 0.0995 Loss_G: 0.0382 Convergence: 0.1021 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4930/9765] Loss_D: 0.1049 Loss_G: 0.0388 Convergence: 0.1091 k= 0.018870 lr = 0.0000034\n",
      "[20/25][4940/9765] Loss_D: 0.0914 Loss_G: 0.0389 Convergence: 0.0942 k= 0.018871 lr = 0.0000034\n",
      "[20/25][4950/9765] Loss_D: 0.0892 Loss_G: 0.0371 Convergence: 0.0911 k= 0.018881 lr = 0.0000034\n",
      "[20/25][4960/9765] Loss_D: 0.0941 Loss_G: 0.0386 Convergence: 0.0955 k= 0.018887 lr = 0.0000034\n",
      "[20/25][4970/9765] Loss_D: 0.0854 Loss_G: 0.0387 Convergence: 0.0903 k= 0.018868 lr = 0.0000034\n",
      "[20/25][4980/9765] Loss_D: 0.0958 Loss_G: 0.0392 Convergence: 0.0972 k= 0.018867 lr = 0.0000034\n",
      "[20/25][4990/9765] Loss_D: 0.0962 Loss_G: 0.0377 Convergence: 0.0979 k= 0.018852 lr = 0.0000034\n",
      "[20/25][5000/9765] Loss_D: 0.1015 Loss_G: 0.0383 Convergence: 0.1048 k= 0.018860 lr = 0.0000034\n",
      "[20/25][5010/9765] Loss_D: 0.0948 Loss_G: 0.0375 Convergence: 0.0962 k= 0.018867 lr = 0.0000034\n",
      "[20/25][5020/9765] Loss_D: 0.0947 Loss_G: 0.0385 Convergence: 0.0958 k= 0.018883 lr = 0.0000034\n",
      "[20/25][5030/9765] Loss_D: 0.1083 Loss_G: 0.0379 Convergence: 0.1147 k= 0.018906 lr = 0.0000034\n",
      "[20/25][5040/9765] Loss_D: 0.0984 Loss_G: 0.0379 Convergence: 0.1009 k= 0.018912 lr = 0.0000034\n",
      "[20/25][5050/9765] Loss_D: 0.0979 Loss_G: 0.0373 Convergence: 0.1007 k= 0.018920 lr = 0.0000034\n",
      "[20/25][5060/9765] Loss_D: 0.0941 Loss_G: 0.0397 Convergence: 0.0966 k= 0.018933 lr = 0.0000034\n",
      "[20/25][5070/9765] Loss_D: 0.0892 Loss_G: 0.0370 Convergence: 0.0909 k= 0.018931 lr = 0.0000034\n",
      "[20/25][5080/9765] Loss_D: 0.1029 Loss_G: 0.0378 Convergence: 0.1073 k= 0.018945 lr = 0.0000034\n",
      "[20/25][5090/9765] Loss_D: 0.0919 Loss_G: 0.0379 Convergence: 0.0934 k= 0.018961 lr = 0.0000034\n",
      "[20/25][5100/9765] Loss_D: 0.0984 Loss_G: 0.0373 Convergence: 0.1015 k= 0.018973 lr = 0.0000034\n",
      "[20/25][5110/9765] Loss_D: 0.0935 Loss_G: 0.0375 Convergence: 0.0944 k= 0.018976 lr = 0.0000034\n",
      "[20/25][5120/9765] Loss_D: 0.0984 Loss_G: 0.0390 Convergence: 0.0998 k= 0.018969 lr = 0.0000034\n",
      "[20/25][5130/9765] Loss_D: 0.0936 Loss_G: 0.0392 Convergence: 0.0958 k= 0.018970 lr = 0.0000034\n",
      "[20/25][5140/9765] Loss_D: 0.1012 Loss_G: 0.0395 Convergence: 0.1033 k= 0.018975 lr = 0.0000034\n",
      "[20/25][5150/9765] Loss_D: 0.0844 Loss_G: 0.0395 Convergence: 0.0906 k= 0.018966 lr = 0.0000034\n",
      "[20/25][5160/9765] Loss_D: 0.1002 Loss_G: 0.0386 Convergence: 0.1027 k= 0.018960 lr = 0.0000034\n",
      "[20/25][5170/9765] Loss_D: 0.0933 Loss_G: 0.0379 Convergence: 0.0943 k= 0.018962 lr = 0.0000034\n",
      "[20/25][5180/9765] Loss_D: 0.0946 Loss_G: 0.0393 Convergence: 0.0965 k= 0.018957 lr = 0.0000034\n",
      "[20/25][5190/9765] Loss_D: 0.1100 Loss_G: 0.0391 Convergence: 0.1159 k= 0.018963 lr = 0.0000034\n",
      "[20/25][5200/9765] Loss_D: 0.1042 Loss_G: 0.0384 Convergence: 0.1086 k= 0.018965 lr = 0.0000034\n",
      "[20/25][5210/9765] Loss_D: 0.0924 Loss_G: 0.0382 Convergence: 0.0941 k= 0.018982 lr = 0.0000034\n",
      "[20/25][5220/9765] Loss_D: 0.1049 Loss_G: 0.0390 Convergence: 0.1090 k= 0.019000 lr = 0.0000034\n",
      "[20/25][5230/9765] Loss_D: 0.0945 Loss_G: 0.0375 Convergence: 0.0957 k= 0.019011 lr = 0.0000034\n",
      "[20/25][5240/9765] Loss_D: 0.0909 Loss_G: 0.0366 Convergence: 0.0916 k= 0.019024 lr = 0.0000034\n",
      "[20/25][5250/9765] Loss_D: 0.0858 Loss_G: 0.0383 Convergence: 0.0902 k= 0.019028 lr = 0.0000034\n",
      "[20/25][5260/9765] Loss_D: 0.0896 Loss_G: 0.0374 Convergence: 0.0916 k= 0.019046 lr = 0.0000034\n",
      "[20/25][5270/9765] Loss_D: 0.0857 Loss_G: 0.0366 Convergence: 0.0885 k= 0.019059 lr = 0.0000034\n",
      "[20/25][5280/9765] Loss_D: 0.0935 Loss_G: 0.0385 Convergence: 0.0950 k= 0.019066 lr = 0.0000034\n",
      "[20/25][5290/9765] Loss_D: 0.0850 Loss_G: 0.0396 Convergence: 0.0910 k= 0.019057 lr = 0.0000034\n",
      "[20/25][5300/9765] Loss_D: 0.0867 Loss_G: 0.0393 Convergence: 0.0917 k= 0.019038 lr = 0.0000034\n",
      "[20/25][5310/9765] Loss_D: 0.0937 Loss_G: 0.0398 Convergence: 0.0965 k= 0.019024 lr = 0.0000034\n",
      "[20/25][5320/9765] Loss_D: 0.0982 Loss_G: 0.0400 Convergence: 0.0994 k= 0.019015 lr = 0.0000034\n",
      "[20/25][5330/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0965 k= 0.019002 lr = 0.0000034\n",
      "[20/25][5340/9765] Loss_D: 0.1002 Loss_G: 0.0389 Convergence: 0.1024 k= 0.019005 lr = 0.0000034\n",
      "[20/25][5350/9765] Loss_D: 0.0954 Loss_G: 0.0380 Convergence: 0.0966 k= 0.019010 lr = 0.0000034\n",
      "[20/25][5360/9765] Loss_D: 0.1034 Loss_G: 0.0386 Convergence: 0.1071 k= 0.019017 lr = 0.0000034\n",
      "[20/25][5370/9765] Loss_D: 0.0916 Loss_G: 0.0377 Convergence: 0.0931 k= 0.019012 lr = 0.0000034\n",
      "[20/25][5380/9765] Loss_D: 0.1070 Loss_G: 0.0381 Convergence: 0.1127 k= 0.019022 lr = 0.0000034\n",
      "[20/25][5390/9765] Loss_D: 0.0980 Loss_G: 0.0379 Convergence: 0.1003 k= 0.019024 lr = 0.0000034\n",
      "[20/25][5400/9765] Loss_D: 0.0938 Loss_G: 0.0373 Convergence: 0.0950 k= 0.019027 lr = 0.0000034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][5410/9765] Loss_D: 0.1065 Loss_G: 0.0377 Convergence: 0.1123 k= 0.019034 lr = 0.0000034\n",
      "[20/25][5420/9765] Loss_D: 0.0963 Loss_G: 0.0380 Convergence: 0.0979 k= 0.019040 lr = 0.0000034\n",
      "[20/25][5430/9765] Loss_D: 0.0940 Loss_G: 0.0386 Convergence: 0.0954 k= 0.019040 lr = 0.0000034\n",
      "[20/25][5440/9765] Loss_D: 0.0845 Loss_G: 0.0375 Convergence: 0.0886 k= 0.019051 lr = 0.0000034\n",
      "[20/25][5450/9765] Loss_D: 0.0958 Loss_G: 0.0377 Convergence: 0.0974 k= 0.019062 lr = 0.0000034\n",
      "[20/25][5460/9765] Loss_D: 0.0933 Loss_G: 0.0378 Convergence: 0.0942 k= 0.019055 lr = 0.0000034\n",
      "[20/25][5470/9765] Loss_D: 0.1057 Loss_G: 0.0375 Convergence: 0.1115 k= 0.019068 lr = 0.0000034\n",
      "[20/25][5480/9765] Loss_D: 0.1046 Loss_G: 0.0381 Convergence: 0.1094 k= 0.019090 lr = 0.0000034\n",
      "[20/25][5490/9765] Loss_D: 0.0961 Loss_G: 0.0379 Convergence: 0.0977 k= 0.019087 lr = 0.0000034\n",
      "[20/25][5500/9765] Loss_D: 0.0944 Loss_G: 0.0396 Convergence: 0.0967 k= 0.019083 lr = 0.0000034\n",
      "[20/25][5510/9765] Loss_D: 0.0997 Loss_G: 0.0382 Convergence: 0.1024 k= 0.019075 lr = 0.0000034\n",
      "[20/25][5520/9765] Loss_D: 0.0972 Loss_G: 0.0386 Convergence: 0.0986 k= 0.019067 lr = 0.0000034\n",
      "[20/25][5530/9765] Loss_D: 0.0987 Loss_G: 0.0392 Convergence: 0.1000 k= 0.019076 lr = 0.0000034\n",
      "[20/25][5540/9765] Loss_D: 0.0948 Loss_G: 0.0383 Convergence: 0.0956 k= 0.019071 lr = 0.0000034\n",
      "[20/25][5550/9765] Loss_D: 0.0997 Loss_G: 0.0390 Convergence: 0.1016 k= 0.019078 lr = 0.0000034\n",
      "[20/25][5560/9765] Loss_D: 0.0964 Loss_G: 0.0386 Convergence: 0.0973 k= 0.019074 lr = 0.0000034\n",
      "[20/25][5570/9765] Loss_D: 0.0885 Loss_G: 0.0381 Convergence: 0.0916 k= 0.019065 lr = 0.0000034\n",
      "[20/25][5580/9765] Loss_D: 0.0872 Loss_G: 0.0385 Convergence: 0.0912 k= 0.019057 lr = 0.0000034\n",
      "[20/25][5590/9765] Loss_D: 0.0916 Loss_G: 0.0381 Convergence: 0.0935 k= 0.019052 lr = 0.0000034\n",
      "[20/25][5600/9765] Loss_D: 0.0914 Loss_G: 0.0396 Convergence: 0.0949 k= 0.019056 lr = 0.0000034\n",
      "[20/25][5610/9765] Loss_D: 0.0928 Loss_G: 0.0391 Convergence: 0.0952 k= 0.019063 lr = 0.0000034\n",
      "[20/25][5620/9765] Loss_D: 0.0990 Loss_G: 0.0368 Convergence: 0.1028 k= 0.019066 lr = 0.0000034\n",
      "[20/25][5630/9765] Loss_D: 0.0883 Loss_G: 0.0372 Convergence: 0.0906 k= 0.019084 lr = 0.0000034\n",
      "[20/25][5640/9765] Loss_D: 0.0892 Loss_G: 0.0374 Convergence: 0.0914 k= 0.019087 lr = 0.0000034\n",
      "[20/25][5650/9765] Loss_D: 0.1105 Loss_G: 0.0374 Convergence: 0.1183 k= 0.019112 lr = 0.0000034\n",
      "[20/25][5660/9765] Loss_D: 0.1059 Loss_G: 0.0375 Convergence: 0.1117 k= 0.019131 lr = 0.0000034\n",
      "[20/25][5670/9765] Loss_D: 0.0932 Loss_G: 0.0382 Convergence: 0.0946 k= 0.019137 lr = 0.0000034\n",
      "[20/25][5680/9765] Loss_D: 0.0950 Loss_G: 0.0408 Convergence: 0.0983 k= 0.019136 lr = 0.0000034\n",
      "[20/25][5690/9765] Loss_D: 0.1048 Loss_G: 0.0384 Convergence: 0.1093 k= 0.019149 lr = 0.0000034\n",
      "[20/25][5700/9765] Loss_D: 0.0968 Loss_G: 0.0393 Convergence: 0.0978 k= 0.019145 lr = 0.0000032\n",
      "[20/25][5710/9765] Loss_D: 0.0954 Loss_G: 0.0376 Convergence: 0.0969 k= 0.019161 lr = 0.0000032\n",
      "[20/25][5720/9765] Loss_D: 0.0912 Loss_G: 0.0383 Convergence: 0.0935 k= 0.019163 lr = 0.0000032\n",
      "[20/25][5730/9765] Loss_D: 0.0955 Loss_G: 0.0373 Convergence: 0.0974 k= 0.019162 lr = 0.0000032\n",
      "[20/25][5740/9765] Loss_D: 0.0964 Loss_G: 0.0375 Convergence: 0.0986 k= 0.019172 lr = 0.0000032\n",
      "[20/25][5750/9765] Loss_D: 0.0971 Loss_G: 0.0387 Convergence: 0.0983 k= 0.019179 lr = 0.0000032\n",
      "[20/25][5760/9765] Loss_D: 0.0878 Loss_G: 0.0385 Convergence: 0.0916 k= 0.019164 lr = 0.0000032\n",
      "[20/25][5770/9765] Loss_D: 0.0954 Loss_G: 0.0401 Convergence: 0.0978 k= 0.019165 lr = 0.0000032\n",
      "[20/25][5780/9765] Loss_D: 0.0908 Loss_G: 0.0387 Convergence: 0.0936 k= 0.019162 lr = 0.0000032\n",
      "[20/25][5790/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0993 k= 0.019165 lr = 0.0000032\n",
      "[20/25][5800/9765] Loss_D: 0.0892 Loss_G: 0.0371 Convergence: 0.0910 k= 0.019173 lr = 0.0000032\n",
      "[20/25][5810/9765] Loss_D: 0.1091 Loss_G: 0.0389 Convergence: 0.1149 k= 0.019194 lr = 0.0000032\n",
      "[20/25][5820/9765] Loss_D: 0.0878 Loss_G: 0.0387 Convergence: 0.0918 k= 0.019195 lr = 0.0000032\n",
      "[20/25][5830/9765] Loss_D: 0.0934 Loss_G: 0.0375 Convergence: 0.0943 k= 0.019198 lr = 0.0000032\n",
      "[20/25][5840/9765] Loss_D: 0.0953 Loss_G: 0.0375 Convergence: 0.0970 k= 0.019201 lr = 0.0000032\n",
      "[20/25][5850/9765] Loss_D: 0.0884 Loss_G: 0.0373 Convergence: 0.0907 k= 0.019218 lr = 0.0000032\n",
      "[20/25][5860/9765] Loss_D: 0.0932 Loss_G: 0.0383 Convergence: 0.0946 k= 0.019222 lr = 0.0000032\n",
      "[20/25][5870/9765] Loss_D: 0.0967 Loss_G: 0.0367 Convergence: 0.0997 k= 0.019225 lr = 0.0000032\n",
      "[20/25][5880/9765] Loss_D: 0.0922 Loss_G: 0.0374 Convergence: 0.0932 k= 0.019237 lr = 0.0000032\n",
      "[20/25][5890/9765] Loss_D: 0.0998 Loss_G: 0.0368 Convergence: 0.1040 k= 0.019258 lr = 0.0000032\n",
      "[20/25][5900/9765] Loss_D: 0.1048 Loss_G: 0.0382 Convergence: 0.1095 k= 0.019269 lr = 0.0000032\n",
      "[20/25][5910/9765] Loss_D: 0.0938 Loss_G: 0.0402 Convergence: 0.0970 k= 0.019268 lr = 0.0000032\n",
      "[20/25][5920/9765] Loss_D: 0.0941 Loss_G: 0.0397 Convergence: 0.0966 k= 0.019263 lr = 0.0000032\n",
      "[20/25][5930/9765] Loss_D: 0.0946 Loss_G: 0.0408 Convergence: 0.0981 k= 0.019251 lr = 0.0000032\n",
      "[20/25][5940/9765] Loss_D: 0.1061 Loss_G: 0.0412 Convergence: 0.1085 k= 0.019245 lr = 0.0000032\n",
      "[20/25][5950/9765] Loss_D: 0.0935 Loss_G: 0.0401 Convergence: 0.0966 k= 0.019241 lr = 0.0000032\n",
      "[20/25][5960/9765] Loss_D: 0.1001 Loss_G: 0.0398 Convergence: 0.1014 k= 0.019232 lr = 0.0000032\n",
      "[20/25][5970/9765] Loss_D: 0.0950 Loss_G: 0.0409 Convergence: 0.0983 k= 0.019211 lr = 0.0000032\n",
      "[20/25][5980/9765] Loss_D: 0.0970 Loss_G: 0.0406 Convergence: 0.0993 k= 0.019194 lr = 0.0000032\n",
      "[20/25][5990/9765] Loss_D: 0.0902 Loss_G: 0.0419 Convergence: 0.0965 k= 0.019175 lr = 0.0000032\n",
      "[20/25][6000/9765] Loss_D: 0.0978 Loss_G: 0.0407 Convergence: 0.0998 k= 0.019151 lr = 0.0000032\n",
      "[20/25][6010/9765] Loss_D: 0.0910 Loss_G: 0.0403 Convergence: 0.0954 k= 0.019141 lr = 0.0000032\n",
      "[20/25][6020/9765] Loss_D: 0.0918 Loss_G: 0.0396 Convergence: 0.0952 k= 0.019126 lr = 0.0000032\n",
      "[20/25][6030/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.019122 lr = 0.0000032\n",
      "[20/25][6040/9765] Loss_D: 0.0980 Loss_G: 0.0402 Convergence: 0.0995 k= 0.019127 lr = 0.0000032\n",
      "[20/25][6050/9765] Loss_D: 0.0899 Loss_G: 0.0386 Convergence: 0.0930 k= 0.019116 lr = 0.0000032\n",
      "[20/25][6060/9765] Loss_D: 0.0944 Loss_G: 0.0377 Convergence: 0.0955 k= 0.019123 lr = 0.0000032\n",
      "[20/25][6070/9765] Loss_D: 0.1010 Loss_G: 0.0386 Convergence: 0.1037 k= 0.019136 lr = 0.0000032\n",
      "[20/25][6080/9765] Loss_D: 0.0833 Loss_G: 0.0383 Convergence: 0.0887 k= 0.019133 lr = 0.0000032\n",
      "[20/25][6090/9765] Loss_D: 0.0996 Loss_G: 0.0372 Convergence: 0.1031 k= 0.019140 lr = 0.0000032\n",
      "[20/25][6100/9765] Loss_D: 0.1077 Loss_G: 0.0382 Convergence: 0.1136 k= 0.019144 lr = 0.0000032\n",
      "[20/25][6110/9765] Loss_D: 0.1023 Loss_G: 0.0395 Convergence: 0.1048 k= 0.019141 lr = 0.0000032\n",
      "[20/25][6120/9765] Loss_D: 0.0898 Loss_G: 0.0387 Convergence: 0.0931 k= 0.019135 lr = 0.0000032\n",
      "[20/25][6130/9765] Loss_D: 0.0958 Loss_G: 0.0379 Convergence: 0.0972 k= 0.019127 lr = 0.0000032\n",
      "[20/25][6140/9765] Loss_D: 0.1009 Loss_G: 0.0392 Convergence: 0.1031 k= 0.019113 lr = 0.0000032\n",
      "[20/25][6150/9765] Loss_D: 0.1027 Loss_G: 0.0387 Convergence: 0.1061 k= 0.019127 lr = 0.0000032\n",
      "[20/25][6160/9765] Loss_D: 0.0897 Loss_G: 0.0405 Convergence: 0.0948 k= 0.019125 lr = 0.0000032\n",
      "[20/25][6170/9765] Loss_D: 0.0900 Loss_G: 0.0392 Convergence: 0.0936 k= 0.019133 lr = 0.0000032\n",
      "[20/25][6180/9765] Loss_D: 0.0902 Loss_G: 0.0387 Convergence: 0.0932 k= 0.019134 lr = 0.0000032\n",
      "[20/25][6190/9765] Loss_D: 0.0934 Loss_G: 0.0384 Convergence: 0.0949 k= 0.019136 lr = 0.0000032\n",
      "[20/25][6200/9765] Loss_D: 0.0948 Loss_G: 0.0390 Convergence: 0.0963 k= 0.019126 lr = 0.0000032\n",
      "[20/25][6210/9765] Loss_D: 0.1033 Loss_G: 0.0398 Convergence: 0.1059 k= 0.019117 lr = 0.0000032\n",
      "[20/25][6220/9765] Loss_D: 0.0949 Loss_G: 0.0397 Convergence: 0.0971 k= 0.019108 lr = 0.0000032\n",
      "[20/25][6230/9765] Loss_D: 0.0992 Loss_G: 0.0404 Convergence: 0.1003 k= 0.019093 lr = 0.0000032\n",
      "[20/25][6240/9765] Loss_D: 0.0995 Loss_G: 0.0393 Convergence: 0.1010 k= 0.019092 lr = 0.0000032\n",
      "[20/25][6250/9765] Loss_D: 0.0936 Loss_G: 0.0388 Convergence: 0.0954 k= 0.019093 lr = 0.0000032\n",
      "[20/25][6260/9765] Loss_D: 0.0933 Loss_G: 0.0391 Convergence: 0.0955 k= 0.019098 lr = 0.0000032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][6270/9765] Loss_D: 0.0969 Loss_G: 0.0392 Convergence: 0.0978 k= 0.019097 lr = 0.0000032\n",
      "[20/25][6280/9765] Loss_D: 0.0996 Loss_G: 0.0371 Convergence: 0.1034 k= 0.019106 lr = 0.0000032\n",
      "[20/25][6290/9765] Loss_D: 0.0954 Loss_G: 0.0380 Convergence: 0.0966 k= 0.019113 lr = 0.0000032\n",
      "[20/25][6300/9765] Loss_D: 0.0795 Loss_G: 0.0373 Convergence: 0.0855 k= 0.019120 lr = 0.0000032\n",
      "[20/25][6310/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0949 k= 0.019121 lr = 0.0000032\n",
      "[20/25][6320/9765] Loss_D: 0.0993 Loss_G: 0.0383 Convergence: 0.1017 k= 0.019117 lr = 0.0000032\n",
      "[20/25][6330/9765] Loss_D: 0.1002 Loss_G: 0.0393 Convergence: 0.1021 k= 0.019119 lr = 0.0000032\n",
      "[20/25][6340/9765] Loss_D: 0.1000 Loss_G: 0.0389 Convergence: 0.1021 k= 0.019110 lr = 0.0000032\n",
      "[20/25][6350/9765] Loss_D: 0.1039 Loss_G: 0.0397 Convergence: 0.1067 k= 0.019102 lr = 0.0000032\n",
      "[20/25][6360/9765] Loss_D: 0.0910 Loss_G: 0.0414 Convergence: 0.0965 k= 0.019076 lr = 0.0000032\n",
      "[20/25][6370/9765] Loss_D: 0.0915 Loss_G: 0.0398 Convergence: 0.0952 k= 0.019062 lr = 0.0000032\n",
      "[20/25][6380/9765] Loss_D: 0.0947 Loss_G: 0.0396 Convergence: 0.0968 k= 0.019047 lr = 0.0000032\n",
      "[20/25][6390/9765] Loss_D: 0.0981 Loss_G: 0.0390 Convergence: 0.0994 k= 0.019033 lr = 0.0000032\n",
      "[20/25][6400/9765] Loss_D: 0.0966 Loss_G: 0.0375 Convergence: 0.0988 k= 0.019022 lr = 0.0000032\n",
      "[20/25][6410/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1016 k= 0.019026 lr = 0.0000032\n",
      "[20/25][6420/9765] Loss_D: 0.1024 Loss_G: 0.0380 Convergence: 0.1063 k= 0.019034 lr = 0.0000032\n",
      "[20/25][6430/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0992 k= 0.019033 lr = 0.0000032\n",
      "[20/25][6440/9765] Loss_D: 0.0913 Loss_G: 0.0392 Convergence: 0.0944 k= 0.019039 lr = 0.0000032\n",
      "[20/25][6450/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0972 k= 0.019049 lr = 0.0000032\n",
      "[20/25][6460/9765] Loss_D: 0.0987 Loss_G: 0.0382 Convergence: 0.1010 k= 0.019054 lr = 0.0000032\n",
      "[20/25][6470/9765] Loss_D: 0.1064 Loss_G: 0.0377 Convergence: 0.1123 k= 0.019070 lr = 0.0000032\n",
      "[20/25][6480/9765] Loss_D: 0.1024 Loss_G: 0.0380 Convergence: 0.1065 k= 0.019082 lr = 0.0000032\n",
      "[20/25][6490/9765] Loss_D: 0.0921 Loss_G: 0.0370 Convergence: 0.0929 k= 0.019095 lr = 0.0000032\n",
      "[20/25][6500/9765] Loss_D: 0.0939 Loss_G: 0.0383 Convergence: 0.0951 k= 0.019101 lr = 0.0000032\n",
      "[20/25][6510/9765] Loss_D: 0.0996 Loss_G: 0.0390 Convergence: 0.1015 k= 0.019114 lr = 0.0000032\n",
      "[20/25][6520/9765] Loss_D: 0.0927 Loss_G: 0.0385 Convergence: 0.0946 k= 0.019108 lr = 0.0000032\n",
      "[20/25][6530/9765] Loss_D: 0.0970 Loss_G: 0.0409 Convergence: 0.0996 k= 0.019094 lr = 0.0000032\n",
      "[20/25][6540/9765] Loss_D: 0.0919 Loss_G: 0.0409 Convergence: 0.0965 k= 0.019078 lr = 0.0000032\n",
      "[20/25][6550/9765] Loss_D: 0.0976 Loss_G: 0.0422 Convergence: 0.1012 k= 0.019059 lr = 0.0000032\n",
      "[20/25][6560/9765] Loss_D: 0.0951 Loss_G: 0.0416 Convergence: 0.0991 k= 0.019027 lr = 0.0000032\n",
      "[20/25][6570/9765] Loss_D: 0.1054 Loss_G: 0.0400 Convergence: 0.1085 k= 0.019006 lr = 0.0000032\n",
      "[20/25][6580/9765] Loss_D: 0.0949 Loss_G: 0.0398 Convergence: 0.0972 k= 0.018982 lr = 0.0000032\n",
      "[20/25][6590/9765] Loss_D: 0.0991 Loss_G: 0.0399 Convergence: 0.1000 k= 0.018978 lr = 0.0000032\n",
      "[20/25][6600/9765] Loss_D: 0.0933 Loss_G: 0.0392 Convergence: 0.0956 k= 0.018974 lr = 0.0000032\n",
      "[20/25][6610/9765] Loss_D: 0.0872 Loss_G: 0.0383 Convergence: 0.0911 k= 0.018972 lr = 0.0000032\n",
      "[20/25][6620/9765] Loss_D: 0.0938 Loss_G: 0.0372 Convergence: 0.0951 k= 0.018977 lr = 0.0000032\n",
      "[20/25][6630/9765] Loss_D: 0.0942 Loss_G: 0.0354 Convergence: 0.0975 k= 0.018983 lr = 0.0000032\n",
      "[20/25][6640/9765] Loss_D: 0.0928 Loss_G: 0.0370 Convergence: 0.0939 k= 0.019008 lr = 0.0000032\n",
      "[20/25][6650/9765] Loss_D: 0.0964 Loss_G: 0.0373 Convergence: 0.0985 k= 0.019026 lr = 0.0000032\n",
      "[20/25][6660/9765] Loss_D: 0.1003 Loss_G: 0.0377 Convergence: 0.1037 k= 0.019050 lr = 0.0000032\n",
      "[20/25][6670/9765] Loss_D: 0.0878 Loss_G: 0.0373 Convergence: 0.0903 k= 0.019051 lr = 0.0000032\n",
      "[20/25][6680/9765] Loss_D: 0.0953 Loss_G: 0.0369 Convergence: 0.0975 k= 0.019055 lr = 0.0000032\n",
      "[20/25][6690/9765] Loss_D: 0.0925 Loss_G: 0.0400 Convergence: 0.0959 k= 0.019068 lr = 0.0000032\n",
      "[20/25][6700/9765] Loss_D: 0.0990 Loss_G: 0.0392 Convergence: 0.1005 k= 0.019060 lr = 0.0000032\n",
      "[20/25][6710/9765] Loss_D: 0.0985 Loss_G: 0.0402 Convergence: 0.0997 k= 0.019066 lr = 0.0000032\n",
      "[20/25][6720/9765] Loss_D: 0.1010 Loss_G: 0.0402 Convergence: 0.1022 k= 0.019054 lr = 0.0000032\n",
      "[20/25][6730/9765] Loss_D: 0.0923 Loss_G: 0.0405 Convergence: 0.0963 k= 0.019040 lr = 0.0000032\n",
      "[20/25][6740/9765] Loss_D: 0.0958 Loss_G: 0.0405 Convergence: 0.0984 k= 0.019022 lr = 0.0000032\n",
      "[20/25][6750/9765] Loss_D: 0.0949 Loss_G: 0.0414 Convergence: 0.0988 k= 0.019022 lr = 0.0000032\n",
      "[20/25][6760/9765] Loss_D: 0.0896 Loss_G: 0.0401 Convergence: 0.0943 k= 0.019010 lr = 0.0000032\n",
      "[20/25][6770/9765] Loss_D: 0.1008 Loss_G: 0.0390 Convergence: 0.1032 k= 0.018988 lr = 0.0000032\n",
      "[20/25][6780/9765] Loss_D: 0.0879 Loss_G: 0.0392 Convergence: 0.0924 k= 0.018980 lr = 0.0000032\n",
      "[20/25][6790/9765] Loss_D: 0.0931 Loss_G: 0.0381 Convergence: 0.0943 k= 0.018978 lr = 0.0000032\n",
      "[20/25][6800/9765] Loss_D: 0.0925 Loss_G: 0.0391 Convergence: 0.0951 k= 0.018983 lr = 0.0000032\n",
      "[20/25][6810/9765] Loss_D: 0.0958 Loss_G: 0.0370 Convergence: 0.0982 k= 0.018992 lr = 0.0000032\n",
      "[20/25][6820/9765] Loss_D: 0.1013 Loss_G: 0.0381 Convergence: 0.1047 k= 0.018987 lr = 0.0000032\n",
      "[20/25][6830/9765] Loss_D: 0.1066 Loss_G: 0.0392 Convergence: 0.1111 k= 0.018977 lr = 0.0000032\n",
      "[20/25][6840/9765] Loss_D: 0.1033 Loss_G: 0.0388 Convergence: 0.1068 k= 0.018984 lr = 0.0000032\n",
      "[20/25][6850/9765] Loss_D: 0.1079 Loss_G: 0.0389 Convergence: 0.1131 k= 0.018994 lr = 0.0000032\n",
      "[20/25][6860/9765] Loss_D: 0.0910 Loss_G: 0.0396 Convergence: 0.0947 k= 0.018989 lr = 0.0000032\n",
      "[20/25][6870/9765] Loss_D: 0.1094 Loss_G: 0.0391 Convergence: 0.1152 k= 0.018998 lr = 0.0000032\n",
      "[20/25][6880/9765] Loss_D: 0.1071 Loss_G: 0.0405 Convergence: 0.1105 k= 0.019010 lr = 0.0000032\n",
      "[20/25][6890/9765] Loss_D: 0.0955 Loss_G: 0.0395 Convergence: 0.0972 k= 0.018998 lr = 0.0000032\n",
      "[20/25][6900/9765] Loss_D: 0.0999 Loss_G: 0.0395 Convergence: 0.1014 k= 0.018985 lr = 0.0000032\n",
      "[20/25][6910/9765] Loss_D: 0.0886 Loss_G: 0.0394 Convergence: 0.0930 k= 0.018969 lr = 0.0000032\n",
      "[20/25][6920/9765] Loss_D: 0.0908 Loss_G: 0.0406 Convergence: 0.0955 k= 0.018954 lr = 0.0000032\n",
      "[20/25][6930/9765] Loss_D: 0.0980 Loss_G: 0.0411 Convergence: 0.1003 k= 0.018940 lr = 0.0000032\n",
      "[20/25][6940/9765] Loss_D: 0.0897 Loss_G: 0.0406 Convergence: 0.0949 k= 0.018924 lr = 0.0000032\n",
      "[20/25][6950/9765] Loss_D: 0.0930 Loss_G: 0.0389 Convergence: 0.0952 k= 0.018906 lr = 0.0000032\n",
      "[20/25][6960/9765] Loss_D: 0.1001 Loss_G: 0.0393 Convergence: 0.1019 k= 0.018887 lr = 0.0000032\n",
      "[20/25][6970/9765] Loss_D: 0.0895 Loss_G: 0.0384 Convergence: 0.0925 k= 0.018875 lr = 0.0000032\n",
      "[20/25][6980/9765] Loss_D: 0.0940 Loss_G: 0.0393 Convergence: 0.0961 k= 0.018884 lr = 0.0000032\n",
      "[20/25][6990/9765] Loss_D: 0.0963 Loss_G: 0.0404 Convergence: 0.0986 k= 0.018880 lr = 0.0000032\n",
      "[20/25][7000/9765] Loss_D: 0.0938 Loss_G: 0.0388 Convergence: 0.0955 k= 0.018869 lr = 0.0000032\n",
      "[20/25][7010/9765] Loss_D: 0.0970 Loss_G: 0.0392 Convergence: 0.0978 k= 0.018875 lr = 0.0000032\n",
      "[20/25][7020/9765] Loss_D: 0.0973 Loss_G: 0.0399 Convergence: 0.0987 k= 0.018880 lr = 0.0000032\n",
      "[20/25][7030/9765] Loss_D: 0.0931 Loss_G: 0.0385 Convergence: 0.0948 k= 0.018878 lr = 0.0000032\n",
      "[20/25][7040/9765] Loss_D: 0.0977 Loss_G: 0.0410 Convergence: 0.1001 k= 0.018876 lr = 0.0000032\n",
      "[20/25][7050/9765] Loss_D: 0.0950 Loss_G: 0.0390 Convergence: 0.0964 k= 0.018865 lr = 0.0000032\n",
      "[20/25][7060/9765] Loss_D: 0.1061 Loss_G: 0.0384 Convergence: 0.1112 k= 0.018858 lr = 0.0000032\n",
      "[20/25][7070/9765] Loss_D: 0.0925 Loss_G: 0.0382 Convergence: 0.0941 k= 0.018867 lr = 0.0000032\n",
      "[20/25][7080/9765] Loss_D: 0.0957 Loss_G: 0.0378 Convergence: 0.0972 k= 0.018875 lr = 0.0000032\n",
      "[20/25][7090/9765] Loss_D: 0.0922 Loss_G: 0.0378 Convergence: 0.0936 k= 0.018881 lr = 0.0000032\n",
      "[20/25][7100/9765] Loss_D: 0.0908 Loss_G: 0.0381 Convergence: 0.0930 k= 0.018891 lr = 0.0000032\n",
      "[20/25][7110/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.0998 k= 0.018906 lr = 0.0000032\n",
      "[20/25][7120/9765] Loss_D: 0.1006 Loss_G: 0.0366 Convergence: 0.1053 k= 0.018916 lr = 0.0000032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][7130/9765] Loss_D: 0.0950 Loss_G: 0.0379 Convergence: 0.0962 k= 0.018932 lr = 0.0000032\n",
      "[20/25][7140/9765] Loss_D: 0.0938 Loss_G: 0.0392 Convergence: 0.0959 k= 0.018943 lr = 0.0000032\n",
      "[20/25][7150/9765] Loss_D: 0.0917 Loss_G: 0.0384 Convergence: 0.0939 k= 0.018944 lr = 0.0000032\n",
      "[20/25][7160/9765] Loss_D: 0.1045 Loss_G: 0.0395 Convergence: 0.1078 k= 0.018947 lr = 0.0000032\n",
      "[20/25][7170/9765] Loss_D: 0.0981 Loss_G: 0.0386 Convergence: 0.0997 k= 0.018947 lr = 0.0000032\n",
      "[20/25][7180/9765] Loss_D: 0.0952 Loss_G: 0.0403 Convergence: 0.0979 k= 0.018939 lr = 0.0000032\n",
      "[20/25][7190/9765] Loss_D: 0.0826 Loss_G: 0.0397 Convergence: 0.0897 k= 0.018924 lr = 0.0000032\n",
      "[20/25][7200/9765] Loss_D: 0.0978 Loss_G: 0.0388 Convergence: 0.0992 k= 0.018908 lr = 0.0000032\n",
      "[20/25][7210/9765] Loss_D: 0.1023 Loss_G: 0.0387 Convergence: 0.1056 k= 0.018911 lr = 0.0000032\n",
      "[20/25][7220/9765] Loss_D: 0.0943 Loss_G: 0.0388 Convergence: 0.0959 k= 0.018903 lr = 0.0000032\n",
      "[20/25][7230/9765] Loss_D: 0.0935 Loss_G: 0.0383 Convergence: 0.0948 k= 0.018908 lr = 0.0000032\n",
      "[20/25][7240/9765] Loss_D: 0.0945 Loss_G: 0.0400 Convergence: 0.0971 k= 0.018899 lr = 0.0000032\n",
      "[20/25][7250/9765] Loss_D: 0.0998 Loss_G: 0.0408 Convergence: 0.1012 k= 0.018902 lr = 0.0000032\n",
      "[20/25][7260/9765] Loss_D: 0.0932 Loss_G: 0.0396 Convergence: 0.0959 k= 0.018895 lr = 0.0000032\n",
      "[20/25][7270/9765] Loss_D: 0.0934 Loss_G: 0.0379 Convergence: 0.0944 k= 0.018891 lr = 0.0000032\n",
      "[20/25][7280/9765] Loss_D: 0.0962 Loss_G: 0.0382 Convergence: 0.0974 k= 0.018888 lr = 0.0000032\n",
      "[20/25][7290/9765] Loss_D: 0.0946 Loss_G: 0.0402 Convergence: 0.0974 k= 0.018883 lr = 0.0000032\n",
      "[20/25][7300/9765] Loss_D: 0.0965 Loss_G: 0.0401 Convergence: 0.0984 k= 0.018878 lr = 0.0000032\n",
      "[20/25][7310/9765] Loss_D: 0.0878 Loss_G: 0.0398 Convergence: 0.0930 k= 0.018872 lr = 0.0000032\n",
      "[20/25][7320/9765] Loss_D: 0.1012 Loss_G: 0.0394 Convergence: 0.1034 k= 0.018875 lr = 0.0000032\n",
      "[20/25][7330/9765] Loss_D: 0.0924 Loss_G: 0.0392 Convergence: 0.0951 k= 0.018870 lr = 0.0000032\n",
      "[20/25][7340/9765] Loss_D: 0.0983 Loss_G: 0.0405 Convergence: 0.0999 k= 0.018866 lr = 0.0000032\n",
      "[20/25][7350/9765] Loss_D: 0.0892 Loss_G: 0.0401 Convergence: 0.0941 k= 0.018862 lr = 0.0000032\n",
      "[20/25][7360/9765] Loss_D: 0.0912 Loss_G: 0.0395 Convergence: 0.0946 k= 0.018857 lr = 0.0000032\n",
      "[20/25][7370/9765] Loss_D: 0.0872 Loss_G: 0.0377 Convergence: 0.0905 k= 0.018841 lr = 0.0000032\n",
      "[20/25][7380/9765] Loss_D: 0.0931 Loss_G: 0.0386 Convergence: 0.0949 k= 0.018860 lr = 0.0000032\n",
      "[20/25][7390/9765] Loss_D: 0.0853 Loss_G: 0.0384 Convergence: 0.0900 k= 0.018860 lr = 0.0000032\n",
      "[20/25][7400/9765] Loss_D: 0.0960 Loss_G: 0.0389 Convergence: 0.0969 k= 0.018869 lr = 0.0000032\n",
      "[20/25][7410/9765] Loss_D: 0.0958 Loss_G: 0.0399 Convergence: 0.0978 k= 0.018867 lr = 0.0000032\n",
      "[20/25][7420/9765] Loss_D: 0.0983 Loss_G: 0.0399 Convergence: 0.0993 k= 0.018869 lr = 0.0000032\n",
      "[20/25][7430/9765] Loss_D: 0.0896 Loss_G: 0.0409 Convergence: 0.0951 k= 0.018836 lr = 0.0000032\n",
      "[20/25][7440/9765] Loss_D: 0.0881 Loss_G: 0.0453 Convergence: 0.0987 k= 0.018789 lr = 0.0000032\n",
      "[20/25][7450/9765] Loss_D: 0.1016 Loss_G: 0.0424 Convergence: 0.1038 k= 0.018731 lr = 0.0000032\n",
      "[20/25][7460/9765] Loss_D: 0.0954 Loss_G: 0.0427 Convergence: 0.1004 k= 0.018689 lr = 0.0000032\n",
      "[20/25][7470/9765] Loss_D: 0.1128 Loss_G: 0.0444 Convergence: 0.1146 k= 0.018658 lr = 0.0000032\n",
      "[20/25][7480/9765] Loss_D: 0.0934 Loss_G: 0.0430 Convergence: 0.0996 k= 0.018623 lr = 0.0000032\n",
      "[20/25][7490/9765] Loss_D: 0.1063 Loss_G: 0.0431 Convergence: 0.1073 k= 0.018583 lr = 0.0000032\n",
      "[20/25][7500/9765] Loss_D: 0.0936 Loss_G: 0.0410 Convergence: 0.0976 k= 0.018575 lr = 0.0000032\n",
      "[20/25][7510/9765] Loss_D: 0.1039 Loss_G: 0.0393 Convergence: 0.1072 k= 0.018568 lr = 0.0000032\n",
      "[20/25][7520/9765] Loss_D: 0.1016 Loss_G: 0.0374 Convergence: 0.1058 k= 0.018582 lr = 0.0000032\n",
      "[20/25][7530/9765] Loss_D: 0.0922 Loss_G: 0.0365 Convergence: 0.0935 k= 0.018593 lr = 0.0000032\n",
      "[20/25][7540/9765] Loss_D: 0.0967 Loss_G: 0.0364 Convergence: 0.0999 k= 0.018626 lr = 0.0000032\n",
      "[20/25][7550/9765] Loss_D: 0.0998 Loss_G: 0.0362 Convergence: 0.1045 k= 0.018662 lr = 0.0000032\n",
      "[20/25][7560/9765] Loss_D: 0.0936 Loss_G: 0.0363 Convergence: 0.0956 k= 0.018693 lr = 0.0000032\n",
      "[20/25][7570/9765] Loss_D: 0.1007 Loss_G: 0.0366 Convergence: 0.1054 k= 0.018729 lr = 0.0000032\n",
      "[20/25][7580/9765] Loss_D: 0.0889 Loss_G: 0.0369 Convergence: 0.0907 k= 0.018742 lr = 0.0000032\n",
      "[20/25][7590/9765] Loss_D: 0.0949 Loss_G: 0.0375 Convergence: 0.0962 k= 0.018756 lr = 0.0000032\n",
      "[20/25][7600/9765] Loss_D: 0.0992 Loss_G: 0.0368 Convergence: 0.1031 k= 0.018766 lr = 0.0000032\n",
      "[20/25][7610/9765] Loss_D: 0.0863 Loss_G: 0.0371 Convergence: 0.0893 k= 0.018784 lr = 0.0000032\n",
      "[20/25][7620/9765] Loss_D: 0.0988 Loss_G: 0.0362 Convergence: 0.1031 k= 0.018802 lr = 0.0000032\n",
      "[20/25][7630/9765] Loss_D: 0.1008 Loss_G: 0.0375 Convergence: 0.1046 k= 0.018809 lr = 0.0000032\n",
      "[20/25][7640/9765] Loss_D: 0.0931 Loss_G: 0.0395 Convergence: 0.0959 k= 0.018804 lr = 0.0000032\n",
      "[20/25][7650/9765] Loss_D: 0.0902 Loss_G: 0.0382 Convergence: 0.0927 k= 0.018792 lr = 0.0000032\n",
      "[20/25][7660/9765] Loss_D: 0.0905 Loss_G: 0.0397 Convergence: 0.0944 k= 0.018794 lr = 0.0000032\n",
      "[20/25][7670/9765] Loss_D: 0.0926 Loss_G: 0.0393 Convergence: 0.0953 k= 0.018783 lr = 0.0000032\n",
      "[20/25][7680/9765] Loss_D: 0.0910 Loss_G: 0.0387 Convergence: 0.0938 k= 0.018761 lr = 0.0000032\n",
      "[20/25][7690/9765] Loss_D: 0.0897 Loss_G: 0.0382 Convergence: 0.0925 k= 0.018778 lr = 0.0000032\n",
      "[20/25][7700/9765] Loss_D: 0.0990 Loss_G: 0.0403 Convergence: 0.1002 k= 0.018769 lr = 0.0000032\n",
      "[20/25][7710/9765] Loss_D: 0.0997 Loss_G: 0.0408 Convergence: 0.1011 k= 0.018760 lr = 0.0000032\n",
      "[20/25][7720/9765] Loss_D: 0.0961 Loss_G: 0.0385 Convergence: 0.0970 k= 0.018759 lr = 0.0000032\n",
      "[20/25][7730/9765] Loss_D: 0.0872 Loss_G: 0.0394 Convergence: 0.0922 k= 0.018763 lr = 0.0000032\n",
      "[20/25][7740/9765] Loss_D: 0.0977 Loss_G: 0.0389 Convergence: 0.0989 k= 0.018772 lr = 0.0000032\n",
      "[20/25][7750/9765] Loss_D: 0.1087 Loss_G: 0.0401 Convergence: 0.1131 k= 0.018769 lr = 0.0000032\n",
      "[20/25][7760/9765] Loss_D: 0.1020 Loss_G: 0.0405 Convergence: 0.1033 k= 0.018759 lr = 0.0000032\n",
      "[20/25][7770/9765] Loss_D: 0.1021 Loss_G: 0.0386 Convergence: 0.1054 k= 0.018755 lr = 0.0000032\n",
      "[20/25][7780/9765] Loss_D: 0.0990 Loss_G: 0.0398 Convergence: 0.0998 k= 0.018757 lr = 0.0000032\n",
      "[20/25][7790/9765] Loss_D: 0.1040 Loss_G: 0.0390 Convergence: 0.1075 k= 0.018753 lr = 0.0000032\n",
      "[20/25][7800/9765] Loss_D: 0.0987 Loss_G: 0.0386 Convergence: 0.1006 k= 0.018769 lr = 0.0000032\n",
      "[20/25][7810/9765] Loss_D: 0.1028 Loss_G: 0.0394 Convergence: 0.1055 k= 0.018781 lr = 0.0000032\n",
      "[20/25][7820/9765] Loss_D: 0.1032 Loss_G: 0.0396 Convergence: 0.1059 k= 0.018775 lr = 0.0000032\n",
      "[20/25][7830/9765] Loss_D: 0.0972 Loss_G: 0.0394 Convergence: 0.0982 k= 0.018760 lr = 0.0000032\n",
      "[20/25][7840/9765] Loss_D: 0.0999 Loss_G: 0.0384 Convergence: 0.1025 k= 0.018753 lr = 0.0000032\n",
      "[20/25][7850/9765] Loss_D: 0.0819 Loss_G: 0.0390 Convergence: 0.0885 k= 0.018741 lr = 0.0000032\n",
      "[20/25][7860/9765] Loss_D: 0.0874 Loss_G: 0.0397 Convergence: 0.0926 k= 0.018740 lr = 0.0000032\n",
      "[20/25][7870/9765] Loss_D: 0.0860 Loss_G: 0.0384 Convergence: 0.0904 k= 0.018721 lr = 0.0000032\n",
      "[20/25][7880/9765] Loss_D: 0.0910 Loss_G: 0.0379 Convergence: 0.0929 k= 0.018713 lr = 0.0000032\n",
      "[20/25][7890/9765] Loss_D: 0.0934 Loss_G: 0.0391 Convergence: 0.0956 k= 0.018710 lr = 0.0000032\n",
      "[20/25][7900/9765] Loss_D: 0.0999 Loss_G: 0.0379 Convergence: 0.1029 k= 0.018711 lr = 0.0000032\n",
      "[20/25][7910/9765] Loss_D: 0.1004 Loss_G: 0.0383 Convergence: 0.1032 k= 0.018718 lr = 0.0000032\n",
      "[20/25][7920/9765] Loss_D: 0.0933 Loss_G: 0.0377 Convergence: 0.0941 k= 0.018723 lr = 0.0000032\n",
      "[20/25][7930/9765] Loss_D: 0.0987 Loss_G: 0.0391 Convergence: 0.1001 k= 0.018712 lr = 0.0000032\n",
      "[20/25][7940/9765] Loss_D: 0.0917 Loss_G: 0.0400 Convergence: 0.0954 k= 0.018704 lr = 0.0000032\n",
      "[20/25][7950/9765] Loss_D: 0.0849 Loss_G: 0.0377 Convergence: 0.0891 k= 0.018694 lr = 0.0000032\n",
      "[20/25][7960/9765] Loss_D: 0.0960 Loss_G: 0.0391 Convergence: 0.0971 k= 0.018698 lr = 0.0000032\n",
      "[20/25][7970/9765] Loss_D: 0.0919 Loss_G: 0.0391 Convergence: 0.0947 k= 0.018699 lr = 0.0000032\n",
      "[20/25][7980/9765] Loss_D: 0.0990 Loss_G: 0.0391 Convergence: 0.1006 k= 0.018692 lr = 0.0000032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][7990/9765] Loss_D: 0.0977 Loss_G: 0.0388 Convergence: 0.0990 k= 0.018696 lr = 0.0000032\n",
      "[20/25][8000/9765] Loss_D: 0.0924 Loss_G: 0.0403 Convergence: 0.0962 k= 0.018687 lr = 0.0000032\n",
      "[20/25][8010/9765] Loss_D: 0.1070 Loss_G: 0.0391 Convergence: 0.1116 k= 0.018683 lr = 0.0000032\n",
      "[20/25][8020/9765] Loss_D: 0.0991 Loss_G: 0.0385 Convergence: 0.1013 k= 0.018680 lr = 0.0000032\n",
      "[20/25][8030/9765] Loss_D: 0.0961 Loss_G: 0.0379 Convergence: 0.0976 k= 0.018694 lr = 0.0000032\n",
      "[20/25][8040/9765] Loss_D: 0.0935 Loss_G: 0.0386 Convergence: 0.0951 k= 0.018695 lr = 0.0000032\n",
      "[20/25][8050/9765] Loss_D: 0.0896 Loss_G: 0.0384 Convergence: 0.0926 k= 0.018688 lr = 0.0000032\n",
      "[20/25][8060/9765] Loss_D: 0.0995 Loss_G: 0.0377 Convergence: 0.1026 k= 0.018708 lr = 0.0000032\n",
      "[20/25][8070/9765] Loss_D: 0.0871 Loss_G: 0.0374 Convergence: 0.0901 k= 0.018713 lr = 0.0000032\n",
      "[20/25][8080/9765] Loss_D: 0.0940 Loss_G: 0.0377 Convergence: 0.0949 k= 0.018717 lr = 0.0000032\n",
      "[20/25][8090/9765] Loss_D: 0.0922 Loss_G: 0.0397 Convergence: 0.0954 k= 0.018711 lr = 0.0000032\n",
      "[20/25][8100/9765] Loss_D: 0.0953 Loss_G: 0.0389 Convergence: 0.0966 k= 0.018716 lr = 0.0000032\n",
      "[20/25][8110/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0972 k= 0.018716 lr = 0.0000032\n",
      "[20/25][8120/9765] Loss_D: 0.1011 Loss_G: 0.0398 Convergence: 0.1028 k= 0.018712 lr = 0.0000032\n",
      "[20/25][8130/9765] Loss_D: 0.1058 Loss_G: 0.0410 Convergence: 0.1083 k= 0.018709 lr = 0.0000032\n",
      "[20/25][8140/9765] Loss_D: 0.0923 Loss_G: 0.0369 Convergence: 0.0932 k= 0.018698 lr = 0.0000032\n",
      "[20/25][8150/9765] Loss_D: 0.0978 Loss_G: 0.0372 Convergence: 0.1007 k= 0.018703 lr = 0.0000032\n",
      "[20/25][8160/9765] Loss_D: 0.1037 Loss_G: 0.0392 Convergence: 0.1071 k= 0.018713 lr = 0.0000032\n",
      "[20/25][8170/9765] Loss_D: 0.1054 Loss_G: 0.0391 Convergence: 0.1095 k= 0.018716 lr = 0.0000032\n",
      "[20/25][8180/9765] Loss_D: 0.0868 Loss_G: 0.0408 Convergence: 0.0934 k= 0.018719 lr = 0.0000032\n",
      "[20/25][8190/9765] Loss_D: 0.0883 Loss_G: 0.0401 Convergence: 0.0935 k= 0.018707 lr = 0.0000032\n",
      "[20/25][8200/9765] Loss_D: 0.0869 Loss_G: 0.0393 Convergence: 0.0919 k= 0.018701 lr = 0.0000032\n",
      "[20/25][8210/9765] Loss_D: 0.1015 Loss_G: 0.0385 Convergence: 0.1046 k= 0.018709 lr = 0.0000032\n",
      "[20/25][8220/9765] Loss_D: 0.0990 Loss_G: 0.0377 Convergence: 0.1018 k= 0.018707 lr = 0.0000032\n",
      "[20/25][8230/9765] Loss_D: 0.0901 Loss_G: 0.0397 Convergence: 0.0942 k= 0.018695 lr = 0.0000032\n",
      "[20/25][8240/9765] Loss_D: 0.0941 Loss_G: 0.0388 Convergence: 0.0957 k= 0.018697 lr = 0.0000032\n",
      "[20/25][8250/9765] Loss_D: 0.0920 Loss_G: 0.0387 Convergence: 0.0943 k= 0.018691 lr = 0.0000032\n",
      "[20/25][8260/9765] Loss_D: 0.0980 Loss_G: 0.0398 Convergence: 0.0990 k= 0.018700 lr = 0.0000032\n",
      "[20/25][8270/9765] Loss_D: 0.0934 Loss_G: 0.0397 Convergence: 0.0962 k= 0.018695 lr = 0.0000032\n",
      "[20/25][8280/9765] Loss_D: 0.1053 Loss_G: 0.0388 Convergence: 0.1096 k= 0.018690 lr = 0.0000032\n",
      "[20/25][8290/9765] Loss_D: 0.0941 Loss_G: 0.0383 Convergence: 0.0952 k= 0.018688 lr = 0.0000032\n",
      "[20/25][8300/9765] Loss_D: 0.1084 Loss_G: 0.0400 Convergence: 0.1129 k= 0.018689 lr = 0.0000032\n",
      "[20/25][8310/9765] Loss_D: 0.0980 Loss_G: 0.0367 Convergence: 0.1015 k= 0.018695 lr = 0.0000032\n",
      "[20/25][8320/9765] Loss_D: 0.1020 Loss_G: 0.0359 Convergence: 0.1079 k= 0.018707 lr = 0.0000032\n",
      "[20/25][8330/9765] Loss_D: 0.0997 Loss_G: 0.0377 Convergence: 0.1029 k= 0.018730 lr = 0.0000032\n",
      "[20/25][8340/9765] Loss_D: 0.0928 Loss_G: 0.0380 Convergence: 0.0941 k= 0.018748 lr = 0.0000032\n",
      "[20/25][8350/9765] Loss_D: 0.0959 Loss_G: 0.0390 Convergence: 0.0970 k= 0.018756 lr = 0.0000032\n",
      "[20/25][8360/9765] Loss_D: 0.0954 Loss_G: 0.0378 Convergence: 0.0967 k= 0.018767 lr = 0.0000032\n",
      "[20/25][8370/9765] Loss_D: 0.0999 Loss_G: 0.0378 Convergence: 0.1031 k= 0.018781 lr = 0.0000032\n",
      "[20/25][8380/9765] Loss_D: 0.0956 Loss_G: 0.0375 Convergence: 0.0974 k= 0.018785 lr = 0.0000032\n",
      "[20/25][8390/9765] Loss_D: 0.0882 Loss_G: 0.0386 Convergence: 0.0919 k= 0.018788 lr = 0.0000032\n",
      "[20/25][8400/9765] Loss_D: 0.0979 Loss_G: 0.0377 Convergence: 0.1004 k= 0.018799 lr = 0.0000032\n",
      "[20/25][8410/9765] Loss_D: 0.0922 Loss_G: 0.0388 Convergence: 0.0946 k= 0.018808 lr = 0.0000032\n",
      "[20/25][8420/9765] Loss_D: 0.0928 Loss_G: 0.0383 Convergence: 0.0944 k= 0.018804 lr = 0.0000032\n",
      "[20/25][8430/9765] Loss_D: 0.1050 Loss_G: 0.0399 Convergence: 0.1081 k= 0.018803 lr = 0.0000032\n",
      "[20/25][8440/9765] Loss_D: 0.1014 Loss_G: 0.0391 Convergence: 0.1038 k= 0.018798 lr = 0.0000032\n",
      "[20/25][8450/9765] Loss_D: 0.0940 Loss_G: 0.0379 Convergence: 0.0947 k= 0.018803 lr = 0.0000032\n",
      "[20/25][8460/9765] Loss_D: 0.0997 Loss_G: 0.0390 Convergence: 0.1015 k= 0.018817 lr = 0.0000032\n",
      "[20/25][8470/9765] Loss_D: 0.1000 Loss_G: 0.0408 Convergence: 0.1013 k= 0.018805 lr = 0.0000032\n",
      "[20/25][8480/9765] Loss_D: 0.1040 Loss_G: 0.0402 Convergence: 0.1065 k= 0.018793 lr = 0.0000032\n",
      "[20/25][8490/9765] Loss_D: 0.0986 Loss_G: 0.0393 Convergence: 0.0998 k= 0.018778 lr = 0.0000032\n",
      "[20/25][8500/9765] Loss_D: 0.0917 Loss_G: 0.0395 Convergence: 0.0949 k= 0.018772 lr = 0.0000032\n",
      "[20/25][8510/9765] Loss_D: 0.0914 Loss_G: 0.0375 Convergence: 0.0928 k= 0.018763 lr = 0.0000032\n",
      "[20/25][8520/9765] Loss_D: 0.0937 Loss_G: 0.0370 Convergence: 0.0952 k= 0.018774 lr = 0.0000032\n",
      "[20/25][8530/9765] Loss_D: 0.0923 Loss_G: 0.0367 Convergence: 0.0935 k= 0.018788 lr = 0.0000032\n",
      "[20/25][8540/9765] Loss_D: 0.0963 Loss_G: 0.0381 Convergence: 0.0977 k= 0.018804 lr = 0.0000032\n",
      "[20/25][8550/9765] Loss_D: 0.0934 Loss_G: 0.0375 Convergence: 0.0943 k= 0.018825 lr = 0.0000032\n",
      "[20/25][8560/9765] Loss_D: 0.0986 Loss_G: 0.0383 Convergence: 0.1008 k= 0.018836 lr = 0.0000032\n",
      "[20/25][8570/9765] Loss_D: 0.0969 Loss_G: 0.0379 Convergence: 0.0989 k= 0.018842 lr = 0.0000032\n",
      "[20/25][8580/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.018845 lr = 0.0000032\n",
      "[20/25][8590/9765] Loss_D: 0.0981 Loss_G: 0.0377 Convergence: 0.1007 k= 0.018842 lr = 0.0000032\n",
      "[20/25][8600/9765] Loss_D: 0.0823 Loss_G: 0.0371 Convergence: 0.0869 k= 0.018836 lr = 0.0000032\n",
      "[20/25][8610/9765] Loss_D: 0.0930 Loss_G: 0.0380 Convergence: 0.0943 k= 0.018846 lr = 0.0000032\n",
      "[20/25][8620/9765] Loss_D: 0.0885 Loss_G: 0.0377 Convergence: 0.0913 k= 0.018846 lr = 0.0000032\n",
      "[20/25][8630/9765] Loss_D: 0.0962 Loss_G: 0.0380 Convergence: 0.0977 k= 0.018850 lr = 0.0000032\n",
      "[20/25][8640/9765] Loss_D: 0.0975 Loss_G: 0.0387 Convergence: 0.0989 k= 0.018848 lr = 0.0000032\n",
      "[20/25][8650/9765] Loss_D: 0.0959 Loss_G: 0.0380 Convergence: 0.0972 k= 0.018855 lr = 0.0000032\n",
      "[20/25][8660/9765] Loss_D: 0.0976 Loss_G: 0.0371 Convergence: 0.1005 k= 0.018859 lr = 0.0000032\n",
      "[20/25][8670/9765] Loss_D: 0.1040 Loss_G: 0.0392 Convergence: 0.1074 k= 0.018861 lr = 0.0000032\n",
      "[20/25][8680/9765] Loss_D: 0.1051 Loss_G: 0.0385 Convergence: 0.1096 k= 0.018867 lr = 0.0000032\n",
      "[20/25][8690/9765] Loss_D: 0.0943 Loss_G: 0.0401 Convergence: 0.0972 k= 0.018869 lr = 0.0000032\n",
      "[20/25][8700/9765] Loss_D: 0.1086 Loss_G: 0.0401 Convergence: 0.1130 k= 0.018877 lr = 0.0000031\n",
      "[20/25][8710/9765] Loss_D: 0.0986 Loss_G: 0.0394 Convergence: 0.0997 k= 0.018866 lr = 0.0000031\n",
      "[20/25][8720/9765] Loss_D: 0.0980 Loss_G: 0.0398 Convergence: 0.0991 k= 0.018850 lr = 0.0000031\n",
      "[20/25][8730/9765] Loss_D: 0.1033 Loss_G: 0.0406 Convergence: 0.1050 k= 0.018848 lr = 0.0000031\n",
      "[20/25][8740/9765] Loss_D: 0.0964 Loss_G: 0.0393 Convergence: 0.0976 k= 0.018833 lr = 0.0000031\n",
      "[20/25][8750/9765] Loss_D: 0.1015 Loss_G: 0.0378 Convergence: 0.1053 k= 0.018847 lr = 0.0000031\n",
      "[20/25][8760/9765] Loss_D: 0.1008 Loss_G: 0.0394 Convergence: 0.1027 k= 0.018858 lr = 0.0000031\n",
      "[20/25][8770/9765] Loss_D: 0.0955 Loss_G: 0.0382 Convergence: 0.0965 k= 0.018862 lr = 0.0000031\n",
      "[20/25][8780/9765] Loss_D: 0.0941 Loss_G: 0.0392 Convergence: 0.0961 k= 0.018873 lr = 0.0000031\n",
      "[20/25][8790/9765] Loss_D: 0.0976 Loss_G: 0.0386 Convergence: 0.0991 k= 0.018876 lr = 0.0000031\n",
      "[20/25][8800/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0960 k= 0.018871 lr = 0.0000031\n",
      "[20/25][8810/9765] Loss_D: 0.0908 Loss_G: 0.0398 Convergence: 0.0947 k= 0.018866 lr = 0.0000031\n",
      "[20/25][8820/9765] Loss_D: 0.0921 Loss_G: 0.0372 Convergence: 0.0929 k= 0.018849 lr = 0.0000031\n",
      "[20/25][8830/9765] Loss_D: 0.0894 Loss_G: 0.0386 Convergence: 0.0926 k= 0.018846 lr = 0.0000031\n",
      "[20/25][8840/9765] Loss_D: 0.0916 Loss_G: 0.0386 Convergence: 0.0940 k= 0.018834 lr = 0.0000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][8850/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1007 k= 0.018832 lr = 0.0000031\n",
      "[20/25][8860/9765] Loss_D: 0.0889 Loss_G: 0.0393 Convergence: 0.0931 k= 0.018823 lr = 0.0000031\n",
      "[20/25][8870/9765] Loss_D: 0.0911 Loss_G: 0.0384 Convergence: 0.0935 k= 0.018827 lr = 0.0000031\n",
      "[20/25][8880/9765] Loss_D: 0.0957 Loss_G: 0.0374 Convergence: 0.0975 k= 0.018821 lr = 0.0000031\n",
      "[20/25][8890/9765] Loss_D: 0.0959 Loss_G: 0.0388 Convergence: 0.0968 k= 0.018826 lr = 0.0000031\n",
      "[20/25][8900/9765] Loss_D: 0.0984 Loss_G: 0.0390 Convergence: 0.0998 k= 0.018824 lr = 0.0000031\n",
      "[20/25][8910/9765] Loss_D: 0.0949 Loss_G: 0.0407 Convergence: 0.0981 k= 0.018816 lr = 0.0000031\n",
      "[20/25][8920/9765] Loss_D: 0.1059 Loss_G: 0.0390 Convergence: 0.1102 k= 0.018808 lr = 0.0000031\n",
      "[20/25][8930/9765] Loss_D: 0.0960 Loss_G: 0.0381 Convergence: 0.0972 k= 0.018815 lr = 0.0000031\n",
      "[20/25][8940/9765] Loss_D: 0.0909 Loss_G: 0.0382 Convergence: 0.0932 k= 0.018817 lr = 0.0000031\n",
      "[20/25][8950/9765] Loss_D: 0.0985 Loss_G: 0.0394 Convergence: 0.0995 k= 0.018817 lr = 0.0000031\n",
      "[20/25][8960/9765] Loss_D: 0.0930 Loss_G: 0.0386 Convergence: 0.0948 k= 0.018815 lr = 0.0000031\n",
      "[20/25][8970/9765] Loss_D: 0.0968 Loss_G: 0.0391 Convergence: 0.0976 k= 0.018821 lr = 0.0000031\n",
      "[20/25][8980/9765] Loss_D: 0.0948 Loss_G: 0.0397 Convergence: 0.0970 k= 0.018813 lr = 0.0000031\n",
      "[20/25][8990/9765] Loss_D: 0.0988 Loss_G: 0.0379 Convergence: 0.1014 k= 0.018814 lr = 0.0000031\n",
      "[20/25][9000/9765] Loss_D: 0.0961 Loss_G: 0.0368 Convergence: 0.0988 k= 0.018828 lr = 0.0000031\n",
      "[20/25][9010/9765] Loss_D: 0.0926 Loss_G: 0.0374 Convergence: 0.0934 k= 0.018838 lr = 0.0000031\n",
      "[20/25][9020/9765] Loss_D: 0.1041 Loss_G: 0.0394 Convergence: 0.1074 k= 0.018855 lr = 0.0000031\n",
      "[20/25][9030/9765] Loss_D: 0.1145 Loss_G: 0.0384 Convergence: 0.1228 k= 0.018847 lr = 0.0000031\n",
      "[20/25][9040/9765] Loss_D: 0.1069 Loss_G: 0.0406 Convergence: 0.1101 k= 0.018847 lr = 0.0000031\n",
      "[20/25][9050/9765] Loss_D: 0.0966 Loss_G: 0.0398 Convergence: 0.0982 k= 0.018830 lr = 0.0000031\n",
      "[20/25][9060/9765] Loss_D: 0.1087 Loss_G: 0.0404 Convergence: 0.1129 k= 0.018828 lr = 0.0000031\n",
      "[20/25][9070/9765] Loss_D: 0.1000 Loss_G: 0.0416 Convergence: 0.1020 k= 0.018811 lr = 0.0000031\n",
      "[20/25][9080/9765] Loss_D: 0.0999 Loss_G: 0.0408 Convergence: 0.1012 k= 0.018783 lr = 0.0000031\n",
      "[20/25][9090/9765] Loss_D: 0.1037 Loss_G: 0.0392 Convergence: 0.1069 k= 0.018761 lr = 0.0000031\n",
      "[20/25][9100/9765] Loss_D: 0.0961 Loss_G: 0.0408 Convergence: 0.0989 k= 0.018743 lr = 0.0000031\n",
      "[20/25][9110/9765] Loss_D: 0.0927 Loss_G: 0.0416 Convergence: 0.0976 k= 0.018724 lr = 0.0000031\n",
      "[20/25][9120/9765] Loss_D: 0.1004 Loss_G: 0.0411 Convergence: 0.1019 k= 0.018697 lr = 0.0000031\n",
      "[20/25][9130/9765] Loss_D: 0.1043 Loss_G: 0.0389 Convergence: 0.1081 k= 0.018677 lr = 0.0000031\n",
      "[20/25][9140/9765] Loss_D: 0.0959 Loss_G: 0.0414 Convergence: 0.0994 k= 0.018659 lr = 0.0000031\n",
      "[20/25][9150/9765] Loss_D: 0.0925 Loss_G: 0.0420 Convergence: 0.0980 k= 0.018628 lr = 0.0000031\n",
      "[20/25][9160/9765] Loss_D: 0.0927 Loss_G: 0.0408 Convergence: 0.0969 k= 0.018610 lr = 0.0000031\n",
      "[20/25][9170/9765] Loss_D: 0.0938 Loss_G: 0.0398 Convergence: 0.0965 k= 0.018610 lr = 0.0000031\n",
      "[20/25][9180/9765] Loss_D: 0.0946 Loss_G: 0.0389 Convergence: 0.0961 k= 0.018603 lr = 0.0000031\n",
      "[20/25][9190/9765] Loss_D: 0.0978 Loss_G: 0.0374 Convergence: 0.1006 k= 0.018615 lr = 0.0000031\n",
      "[20/25][9200/9765] Loss_D: 0.0979 Loss_G: 0.0371 Convergence: 0.1010 k= 0.018620 lr = 0.0000031\n",
      "[20/25][9210/9765] Loss_D: 0.1041 Loss_G: 0.0364 Convergence: 0.1104 k= 0.018646 lr = 0.0000031\n",
      "[20/25][9220/9765] Loss_D: 0.0958 Loss_G: 0.0368 Convergence: 0.0983 k= 0.018666 lr = 0.0000031\n",
      "[20/25][9230/9765] Loss_D: 0.0979 Loss_G: 0.0354 Convergence: 0.1025 k= 0.018684 lr = 0.0000031\n",
      "[20/25][9240/9765] Loss_D: 0.0987 Loss_G: 0.0360 Convergence: 0.1030 k= 0.018720 lr = 0.0000031\n",
      "[20/25][9250/9765] Loss_D: 0.0939 Loss_G: 0.0368 Convergence: 0.0956 k= 0.018757 lr = 0.0000031\n",
      "[20/25][9260/9765] Loss_D: 0.0915 Loss_G: 0.0355 Convergence: 0.0935 k= 0.018786 lr = 0.0000031\n",
      "[20/25][9270/9765] Loss_D: 0.0924 Loss_G: 0.0366 Convergence: 0.0937 k= 0.018815 lr = 0.0000031\n",
      "[20/25][9280/9765] Loss_D: 0.0879 Loss_G: 0.0375 Convergence: 0.0907 k= 0.018836 lr = 0.0000031\n",
      "[20/25][9290/9765] Loss_D: 0.0890 Loss_G: 0.0378 Convergence: 0.0916 k= 0.018838 lr = 0.0000031\n",
      "[20/25][9300/9765] Loss_D: 0.1047 Loss_G: 0.0387 Convergence: 0.1089 k= 0.018843 lr = 0.0000031\n",
      "[20/25][9310/9765] Loss_D: 0.1021 Loss_G: 0.0385 Convergence: 0.1055 k= 0.018847 lr = 0.0000031\n",
      "[20/25][9320/9765] Loss_D: 0.0941 Loss_G: 0.0395 Convergence: 0.0964 k= 0.018840 lr = 0.0000031\n",
      "[20/25][9330/9765] Loss_D: 0.0976 Loss_G: 0.0399 Convergence: 0.0989 k= 0.018826 lr = 0.0000031\n",
      "[20/25][9340/9765] Loss_D: 0.0926 Loss_G: 0.0409 Convergence: 0.0969 k= 0.018819 lr = 0.0000031\n",
      "[20/25][9350/9765] Loss_D: 0.1004 Loss_G: 0.0395 Convergence: 0.1022 k= 0.018802 lr = 0.0000031\n",
      "[20/25][9360/9765] Loss_D: 0.0929 Loss_G: 0.0397 Convergence: 0.0959 k= 0.018778 lr = 0.0000031\n",
      "[20/25][9370/9765] Loss_D: 0.0974 Loss_G: 0.0418 Convergence: 0.1007 k= 0.018768 lr = 0.0000031\n",
      "[20/25][9380/9765] Loss_D: 0.1052 Loss_G: 0.0396 Convergence: 0.1088 k= 0.018762 lr = 0.0000031\n",
      "[20/25][9390/9765] Loss_D: 0.0929 Loss_G: 0.0397 Convergence: 0.0959 k= 0.018752 lr = 0.0000031\n",
      "[20/25][9400/9765] Loss_D: 0.0940 Loss_G: 0.0406 Convergence: 0.0974 k= 0.018735 lr = 0.0000031\n",
      "[20/25][9410/9765] Loss_D: 0.0894 Loss_G: 0.0403 Convergence: 0.0945 k= 0.018713 lr = 0.0000031\n",
      "[20/25][9420/9765] Loss_D: 0.0856 Loss_G: 0.0385 Convergence: 0.0903 k= 0.018707 lr = 0.0000031\n",
      "[20/25][9430/9765] Loss_D: 0.1008 Loss_G: 0.0409 Convergence: 0.1018 k= 0.018704 lr = 0.0000031\n",
      "[20/25][9440/9765] Loss_D: 0.0946 Loss_G: 0.0393 Convergence: 0.0965 k= 0.018679 lr = 0.0000031\n",
      "[20/25][9450/9765] Loss_D: 0.0954 Loss_G: 0.0392 Convergence: 0.0969 k= 0.018676 lr = 0.0000031\n",
      "[20/25][9460/9765] Loss_D: 0.1016 Loss_G: 0.0385 Convergence: 0.1047 k= 0.018680 lr = 0.0000031\n",
      "[20/25][9470/9765] Loss_D: 0.0954 Loss_G: 0.0384 Convergence: 0.0962 k= 0.018684 lr = 0.0000031\n",
      "[20/25][9480/9765] Loss_D: 0.0929 Loss_G: 0.0380 Convergence: 0.0941 k= 0.018679 lr = 0.0000031\n",
      "[20/25][9490/9765] Loss_D: 0.0866 Loss_G: 0.0390 Convergence: 0.0914 k= 0.018694 lr = 0.0000031\n",
      "[20/25][9500/9765] Loss_D: 0.1016 Loss_G: 0.0392 Convergence: 0.1041 k= 0.018688 lr = 0.0000031\n",
      "[20/25][9510/9765] Loss_D: 0.0937 Loss_G: 0.0383 Convergence: 0.0949 k= 0.018693 lr = 0.0000031\n",
      "[20/25][9520/9765] Loss_D: 0.0991 Loss_G: 0.0390 Convergence: 0.1008 k= 0.018691 lr = 0.0000031\n",
      "[20/25][9530/9765] Loss_D: 0.0974 Loss_G: 0.0401 Convergence: 0.0990 k= 0.018689 lr = 0.0000031\n",
      "[20/25][9540/9765] Loss_D: 0.1068 Loss_G: 0.0402 Convergence: 0.1103 k= 0.018691 lr = 0.0000031\n",
      "[20/25][9550/9765] Loss_D: 0.0829 Loss_G: 0.0382 Convergence: 0.0884 k= 0.018679 lr = 0.0000031\n",
      "[20/25][9560/9765] Loss_D: 0.0912 Loss_G: 0.0389 Convergence: 0.0941 k= 0.018674 lr = 0.0000031\n",
      "[20/25][9570/9765] Loss_D: 0.1004 Loss_G: 0.0397 Convergence: 0.1018 k= 0.018673 lr = 0.0000031\n",
      "[20/25][9580/9765] Loss_D: 0.0979 Loss_G: 0.0404 Convergence: 0.0996 k= 0.018678 lr = 0.0000031\n",
      "[20/25][9590/9765] Loss_D: 0.0941 Loss_G: 0.0392 Convergence: 0.0961 k= 0.018668 lr = 0.0000031\n",
      "[20/25][9600/9765] Loss_D: 0.0953 Loss_G: 0.0388 Convergence: 0.0964 k= 0.018676 lr = 0.0000031\n",
      "[20/25][9610/9765] Loss_D: 0.1049 Loss_G: 0.0396 Convergence: 0.1083 k= 0.018690 lr = 0.0000031\n",
      "[20/25][9620/9765] Loss_D: 0.1029 Loss_G: 0.0383 Convergence: 0.1067 k= 0.018686 lr = 0.0000031\n",
      "[20/25][9630/9765] Loss_D: 0.0897 Loss_G: 0.0387 Convergence: 0.0929 k= 0.018680 lr = 0.0000031\n",
      "[20/25][9640/9765] Loss_D: 0.1060 Loss_G: 0.0378 Convergence: 0.1116 k= 0.018697 lr = 0.0000031\n",
      "[20/25][9650/9765] Loss_D: 0.0952 Loss_G: 0.0384 Convergence: 0.0960 k= 0.018711 lr = 0.0000031\n",
      "[20/25][9660/9765] Loss_D: 0.0919 Loss_G: 0.0375 Convergence: 0.0931 k= 0.018721 lr = 0.0000031\n",
      "[20/25][9670/9765] Loss_D: 0.1010 Loss_G: 0.0383 Convergence: 0.1041 k= 0.018735 lr = 0.0000031\n",
      "[20/25][9680/9765] Loss_D: 0.0976 Loss_G: 0.0378 Convergence: 0.0998 k= 0.018758 lr = 0.0000031\n",
      "[20/25][9690/9765] Loss_D: 0.1010 Loss_G: 0.0383 Convergence: 0.1042 k= 0.018769 lr = 0.0000031\n",
      "[20/25][9700/9765] Loss_D: 0.0914 Loss_G: 0.0395 Convergence: 0.0948 k= 0.018763 lr = 0.0000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/25][9710/9765] Loss_D: 0.0990 Loss_G: 0.0380 Convergence: 0.1017 k= 0.018763 lr = 0.0000031\n",
      "[20/25][9720/9765] Loss_D: 0.0955 Loss_G: 0.0382 Convergence: 0.0966 k= 0.018773 lr = 0.0000031\n",
      "[20/25][9730/9765] Loss_D: 0.0922 Loss_G: 0.0375 Convergence: 0.0932 k= 0.018778 lr = 0.0000031\n",
      "[20/25][9740/9765] Loss_D: 0.0906 Loss_G: 0.0377 Convergence: 0.0925 k= 0.018776 lr = 0.0000031\n",
      "[20/25][9750/9765] Loss_D: 0.0933 Loss_G: 0.0392 Convergence: 0.0957 k= 0.018790 lr = 0.0000031\n",
      "[20/25][9760/9765] Loss_D: 0.1089 Loss_G: 0.0392 Convergence: 0.1143 k= 0.018801 lr = 0.0000031\n",
      "[21/25][0/9765] Loss_D: 0.0909 Loss_G: 0.0380 Convergence: 0.0930 k= 0.018792 lr = 0.0000031\n",
      "[21/25][10/9765] Loss_D: 0.0935 Loss_G: 0.0409 Convergence: 0.0974 k= 0.018793 lr = 0.0000031\n",
      "[21/25][20/9765] Loss_D: 0.0926 Loss_G: 0.0405 Convergence: 0.0965 k= 0.018786 lr = 0.0000031\n",
      "[21/25][30/9765] Loss_D: 0.1032 Loss_G: 0.0385 Convergence: 0.1070 k= 0.018777 lr = 0.0000031\n",
      "[21/25][40/9765] Loss_D: 0.0994 Loss_G: 0.0384 Convergence: 0.1017 k= 0.018775 lr = 0.0000031\n",
      "[21/25][50/9765] Loss_D: 0.1020 Loss_G: 0.0391 Convergence: 0.1047 k= 0.018792 lr = 0.0000031\n",
      "[21/25][60/9765] Loss_D: 0.0982 Loss_G: 0.0383 Convergence: 0.1001 k= 0.018792 lr = 0.0000031\n",
      "[21/25][70/9765] Loss_D: 0.0956 Loss_G: 0.0390 Convergence: 0.0968 k= 0.018787 lr = 0.0000031\n",
      "[21/25][80/9765] Loss_D: 0.1055 Loss_G: 0.0383 Convergence: 0.1103 k= 0.018787 lr = 0.0000031\n",
      "[21/25][90/9765] Loss_D: 0.0934 Loss_G: 0.0387 Convergence: 0.0952 k= 0.018788 lr = 0.0000031\n",
      "[21/25][100/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0985 k= 0.018797 lr = 0.0000031\n",
      "[21/25][110/9765] Loss_D: 0.0936 Loss_G: 0.0396 Convergence: 0.0962 k= 0.018799 lr = 0.0000031\n",
      "[21/25][120/9765] Loss_D: 0.0932 Loss_G: 0.0392 Convergence: 0.0955 k= 0.018797 lr = 0.0000031\n",
      "[21/25][130/9765] Loss_D: 0.0973 Loss_G: 0.0401 Convergence: 0.0989 k= 0.018800 lr = 0.0000031\n",
      "[21/25][140/9765] Loss_D: 0.1077 Loss_G: 0.0386 Convergence: 0.1132 k= 0.018806 lr = 0.0000031\n",
      "[21/25][150/9765] Loss_D: 0.1065 Loss_G: 0.0392 Convergence: 0.1109 k= 0.018820 lr = 0.0000031\n",
      "[21/25][160/9765] Loss_D: 0.0982 Loss_G: 0.0382 Convergence: 0.1003 k= 0.018831 lr = 0.0000031\n",
      "[21/25][170/9765] Loss_D: 0.0950 Loss_G: 0.0374 Convergence: 0.0966 k= 0.018824 lr = 0.0000031\n",
      "[21/25][180/9765] Loss_D: 0.0894 Loss_G: 0.0378 Convergence: 0.0919 k= 0.018829 lr = 0.0000031\n",
      "[21/25][190/9765] Loss_D: 0.1011 Loss_G: 0.0377 Convergence: 0.1048 k= 0.018839 lr = 0.0000031\n",
      "[21/25][200/9765] Loss_D: 0.1030 Loss_G: 0.0396 Convergence: 0.1056 k= 0.018854 lr = 0.0000031\n",
      "[21/25][210/9765] Loss_D: 0.0942 Loss_G: 0.0409 Convergence: 0.0979 k= 0.018843 lr = 0.0000031\n",
      "[21/25][220/9765] Loss_D: 0.1011 Loss_G: 0.0419 Convergence: 0.1030 k= 0.018825 lr = 0.0000031\n",
      "[21/25][230/9765] Loss_D: 0.1008 Loss_G: 0.0394 Convergence: 0.1027 k= 0.018809 lr = 0.0000031\n",
      "[21/25][240/9765] Loss_D: 0.0959 Loss_G: 0.0401 Convergence: 0.0981 k= 0.018796 lr = 0.0000031\n",
      "[21/25][250/9765] Loss_D: 0.1046 Loss_G: 0.0386 Convergence: 0.1089 k= 0.018802 lr = 0.0000031\n",
      "[21/25][260/9765] Loss_D: 0.0915 Loss_G: 0.0385 Convergence: 0.0938 k= 0.018794 lr = 0.0000031\n",
      "[21/25][270/9765] Loss_D: 0.0849 Loss_G: 0.0392 Convergence: 0.0906 k= 0.018804 lr = 0.0000031\n",
      "[21/25][280/9765] Loss_D: 0.1002 Loss_G: 0.0399 Convergence: 0.1014 k= 0.018792 lr = 0.0000031\n",
      "[21/25][290/9765] Loss_D: 0.0982 Loss_G: 0.0388 Convergence: 0.0996 k= 0.018787 lr = 0.0000031\n",
      "[21/25][300/9765] Loss_D: 0.0968 Loss_G: 0.0381 Convergence: 0.0983 k= 0.018803 lr = 0.0000031\n",
      "[21/25][310/9765] Loss_D: 0.0845 Loss_G: 0.0372 Convergence: 0.0883 k= 0.018811 lr = 0.0000031\n",
      "[21/25][320/9765] Loss_D: 0.1052 Loss_G: 0.0380 Convergence: 0.1102 k= 0.018832 lr = 0.0000031\n",
      "[21/25][330/9765] Loss_D: 0.0978 Loss_G: 0.0384 Convergence: 0.0995 k= 0.018831 lr = 0.0000031\n",
      "[21/25][340/9765] Loss_D: 0.0979 Loss_G: 0.0377 Convergence: 0.1003 k= 0.018829 lr = 0.0000031\n",
      "[21/25][350/9765] Loss_D: 0.0979 Loss_G: 0.0377 Convergence: 0.1004 k= 0.018831 lr = 0.0000031\n",
      "[21/25][360/9765] Loss_D: 0.0973 Loss_G: 0.0383 Convergence: 0.0989 k= 0.018831 lr = 0.0000031\n",
      "[21/25][370/9765] Loss_D: 0.1012 Loss_G: 0.0388 Convergence: 0.1039 k= 0.018834 lr = 0.0000031\n",
      "[21/25][380/9765] Loss_D: 0.0923 Loss_G: 0.0388 Convergence: 0.0946 k= 0.018838 lr = 0.0000031\n",
      "[21/25][390/9765] Loss_D: 0.0952 Loss_G: 0.0394 Convergence: 0.0969 k= 0.018828 lr = 0.0000031\n",
      "[21/25][400/9765] Loss_D: 0.0960 Loss_G: 0.0395 Convergence: 0.0975 k= 0.018830 lr = 0.0000031\n",
      "[21/25][410/9765] Loss_D: 0.0939 Loss_G: 0.0392 Convergence: 0.0960 k= 0.018819 lr = 0.0000031\n",
      "[21/25][420/9765] Loss_D: 0.1103 Loss_G: 0.0390 Convergence: 0.1164 k= 0.018826 lr = 0.0000031\n",
      "[21/25][430/9765] Loss_D: 0.0938 Loss_G: 0.0380 Convergence: 0.0947 k= 0.018821 lr = 0.0000031\n",
      "[21/25][440/9765] Loss_D: 0.0847 Loss_G: 0.0398 Convergence: 0.0911 k= 0.018811 lr = 0.0000031\n",
      "[21/25][450/9765] Loss_D: 0.0981 Loss_G: 0.0374 Convergence: 0.1010 k= 0.018807 lr = 0.0000031\n",
      "[21/25][460/9765] Loss_D: 0.1005 Loss_G: 0.0377 Convergence: 0.1040 k= 0.018831 lr = 0.0000031\n",
      "[21/25][470/9765] Loss_D: 0.0989 Loss_G: 0.0384 Convergence: 0.1011 k= 0.018853 lr = 0.0000031\n",
      "[21/25][480/9765] Loss_D: 0.0948 Loss_G: 0.0387 Convergence: 0.0960 k= 0.018858 lr = 0.0000031\n",
      "[21/25][490/9765] Loss_D: 0.1002 Loss_G: 0.0398 Convergence: 0.1015 k= 0.018857 lr = 0.0000031\n",
      "[21/25][500/9765] Loss_D: 0.0917 Loss_G: 0.0384 Convergence: 0.0939 k= 0.018851 lr = 0.0000031\n",
      "[21/25][510/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0992 k= 0.018846 lr = 0.0000031\n",
      "[21/25][520/9765] Loss_D: 0.0912 Loss_G: 0.0395 Convergence: 0.0947 k= 0.018846 lr = 0.0000031\n",
      "[21/25][530/9765] Loss_D: 0.1073 Loss_G: 0.0390 Convergence: 0.1123 k= 0.018859 lr = 0.0000031\n",
      "[21/25][540/9765] Loss_D: 0.0980 Loss_G: 0.0377 Convergence: 0.1005 k= 0.018860 lr = 0.0000031\n",
      "[21/25][550/9765] Loss_D: 0.0954 Loss_G: 0.0383 Convergence: 0.0963 k= 0.018866 lr = 0.0000031\n",
      "[21/25][560/9765] Loss_D: 0.1007 Loss_G: 0.0392 Convergence: 0.1029 k= 0.018854 lr = 0.0000031\n",
      "[21/25][570/9765] Loss_D: 0.1002 Loss_G: 0.0399 Convergence: 0.1015 k= 0.018854 lr = 0.0000031\n",
      "[21/25][580/9765] Loss_D: 0.0877 Loss_G: 0.0403 Convergence: 0.0934 k= 0.018832 lr = 0.0000031\n",
      "[21/25][590/9765] Loss_D: 0.1055 Loss_G: 0.0394 Convergence: 0.1093 k= 0.018833 lr = 0.0000031\n",
      "[21/25][600/9765] Loss_D: 0.1036 Loss_G: 0.0390 Convergence: 0.1070 k= 0.018821 lr = 0.0000031\n",
      "[21/25][610/9765] Loss_D: 0.0920 Loss_G: 0.0395 Convergence: 0.0952 k= 0.018814 lr = 0.0000031\n",
      "[21/25][620/9765] Loss_D: 0.0946 Loss_G: 0.0375 Convergence: 0.0959 k= 0.018810 lr = 0.0000031\n",
      "[21/25][630/9765] Loss_D: 0.0870 Loss_G: 0.0382 Convergence: 0.0908 k= 0.018815 lr = 0.0000031\n",
      "[21/25][640/9765] Loss_D: 0.0932 Loss_G: 0.0392 Convergence: 0.0956 k= 0.018811 lr = 0.0000031\n",
      "[21/25][650/9765] Loss_D: 0.0960 Loss_G: 0.0392 Convergence: 0.0972 k= 0.018816 lr = 0.0000031\n",
      "[21/25][660/9765] Loss_D: 0.0930 Loss_G: 0.0378 Convergence: 0.0940 k= 0.018822 lr = 0.0000031\n",
      "[21/25][670/9765] Loss_D: 0.0995 Loss_G: 0.0394 Convergence: 0.1010 k= 0.018817 lr = 0.0000031\n",
      "[21/25][680/9765] Loss_D: 0.1031 Loss_G: 0.0396 Convergence: 0.1058 k= 0.018809 lr = 0.0000031\n",
      "[21/25][690/9765] Loss_D: 0.0960 Loss_G: 0.0380 Convergence: 0.0974 k= 0.018814 lr = 0.0000031\n",
      "[21/25][700/9765] Loss_D: 0.0927 Loss_G: 0.0376 Convergence: 0.0936 k= 0.018819 lr = 0.0000031\n",
      "[21/25][710/9765] Loss_D: 0.0937 Loss_G: 0.0394 Convergence: 0.0961 k= 0.018827 lr = 0.0000031\n",
      "[21/25][720/9765] Loss_D: 0.1029 Loss_G: 0.0382 Convergence: 0.1069 k= 0.018838 lr = 0.0000031\n",
      "[21/25][730/9765] Loss_D: 0.1004 Loss_G: 0.0400 Convergence: 0.1017 k= 0.018832 lr = 0.0000031\n",
      "[21/25][740/9765] Loss_D: 0.0908 Loss_G: 0.0387 Convergence: 0.0936 k= 0.018821 lr = 0.0000031\n",
      "[21/25][750/9765] Loss_D: 0.0885 Loss_G: 0.0406 Convergence: 0.0941 k= 0.018816 lr = 0.0000031\n",
      "[21/25][760/9765] Loss_D: 0.0994 Loss_G: 0.0397 Convergence: 0.1005 k= 0.018803 lr = 0.0000031\n",
      "[21/25][770/9765] Loss_D: 0.0897 Loss_G: 0.0398 Convergence: 0.0941 k= 0.018787 lr = 0.0000031\n",
      "[21/25][780/9765] Loss_D: 0.0953 Loss_G: 0.0398 Convergence: 0.0974 k= 0.018773 lr = 0.0000031\n",
      "[21/25][790/9765] Loss_D: 0.0955 Loss_G: 0.0379 Convergence: 0.0967 k= 0.018780 lr = 0.0000031\n",
      "[21/25][800/9765] Loss_D: 0.0911 Loss_G: 0.0394 Convergence: 0.0945 k= 0.018772 lr = 0.0000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][810/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0968 k= 0.018762 lr = 0.0000031\n",
      "[21/25][820/9765] Loss_D: 0.0882 Loss_G: 0.0388 Convergence: 0.0922 k= 0.018764 lr = 0.0000031\n",
      "[21/25][830/9765] Loss_D: 0.0985 Loss_G: 0.0381 Convergence: 0.1007 k= 0.018776 lr = 0.0000031\n",
      "[21/25][840/9765] Loss_D: 0.0896 Loss_G: 0.0378 Convergence: 0.0920 k= 0.018782 lr = 0.0000031\n",
      "[21/25][850/9765] Loss_D: 0.1005 Loss_G: 0.0377 Convergence: 0.1041 k= 0.018796 lr = 0.0000031\n",
      "[21/25][860/9765] Loss_D: 0.0997 Loss_G: 0.0380 Convergence: 0.1026 k= 0.018809 lr = 0.0000031\n",
      "[21/25][870/9765] Loss_D: 0.0953 Loss_G: 0.0367 Convergence: 0.0977 k= 0.018819 lr = 0.0000031\n",
      "[21/25][880/9765] Loss_D: 0.0996 Loss_G: 0.0381 Convergence: 0.1024 k= 0.018848 lr = 0.0000031\n",
      "[21/25][890/9765] Loss_D: 0.1000 Loss_G: 0.0370 Convergence: 0.1040 k= 0.018855 lr = 0.0000031\n",
      "[21/25][900/9765] Loss_D: 0.1068 Loss_G: 0.0387 Convergence: 0.1119 k= 0.018885 lr = 0.0000031\n",
      "[21/25][910/9765] Loss_D: 0.0948 Loss_G: 0.0372 Convergence: 0.0964 k= 0.018904 lr = 0.0000031\n",
      "[21/25][920/9765] Loss_D: 0.0940 Loss_G: 0.0388 Convergence: 0.0957 k= 0.018917 lr = 0.0000031\n",
      "[21/25][930/9765] Loss_D: 0.0883 Loss_G: 0.0389 Convergence: 0.0924 k= 0.018936 lr = 0.0000031\n",
      "[21/25][940/9765] Loss_D: 0.0963 Loss_G: 0.0412 Convergence: 0.0994 k= 0.018933 lr = 0.0000031\n",
      "[21/25][950/9765] Loss_D: 0.0955 Loss_G: 0.0400 Convergence: 0.0977 k= 0.018918 lr = 0.0000031\n",
      "[21/25][960/9765] Loss_D: 0.0966 Loss_G: 0.0397 Convergence: 0.0981 k= 0.018900 lr = 0.0000031\n",
      "[21/25][970/9765] Loss_D: 0.0934 Loss_G: 0.0412 Convergence: 0.0977 k= 0.018867 lr = 0.0000031\n",
      "[21/25][980/9765] Loss_D: 0.0828 Loss_G: 0.0405 Convergence: 0.0907 k= 0.018844 lr = 0.0000031\n",
      "[21/25][990/9765] Loss_D: 0.0915 Loss_G: 0.0400 Convergence: 0.0954 k= 0.018823 lr = 0.0000031\n",
      "[21/25][1000/9765] Loss_D: 0.1053 Loss_G: 0.0398 Convergence: 0.1087 k= 0.018818 lr = 0.0000031\n",
      "[21/25][1010/9765] Loss_D: 0.0979 Loss_G: 0.0388 Convergence: 0.0992 k= 0.018826 lr = 0.0000031\n",
      "[21/25][1020/9765] Loss_D: 0.0925 Loss_G: 0.0395 Convergence: 0.0955 k= 0.018832 lr = 0.0000031\n",
      "[21/25][1030/9765] Loss_D: 0.0917 Loss_G: 0.0387 Convergence: 0.0942 k= 0.018830 lr = 0.0000031\n",
      "[21/25][1040/9765] Loss_D: 0.0949 Loss_G: 0.0389 Convergence: 0.0963 k= 0.018831 lr = 0.0000031\n",
      "[21/25][1050/9765] Loss_D: 0.1054 Loss_G: 0.0382 Convergence: 0.1103 k= 0.018847 lr = 0.0000031\n",
      "[21/25][1060/9765] Loss_D: 0.1009 Loss_G: 0.0387 Convergence: 0.1036 k= 0.018856 lr = 0.0000031\n",
      "[21/25][1070/9765] Loss_D: 0.0890 Loss_G: 0.0377 Convergence: 0.0915 k= 0.018859 lr = 0.0000031\n",
      "[21/25][1080/9765] Loss_D: 0.0977 Loss_G: 0.0383 Convergence: 0.0995 k= 0.018870 lr = 0.0000031\n",
      "[21/25][1090/9765] Loss_D: 0.0886 Loss_G: 0.0381 Convergence: 0.0916 k= 0.018874 lr = 0.0000031\n",
      "[21/25][1100/9765] Loss_D: 0.1049 Loss_G: 0.0381 Convergence: 0.1098 k= 0.018884 lr = 0.0000031\n",
      "[21/25][1110/9765] Loss_D: 0.0934 Loss_G: 0.0393 Convergence: 0.0958 k= 0.018881 lr = 0.0000031\n",
      "[21/25][1120/9765] Loss_D: 0.1006 Loss_G: 0.0399 Convergence: 0.1020 k= 0.018862 lr = 0.0000031\n",
      "[21/25][1130/9765] Loss_D: 0.0942 Loss_G: 0.0396 Convergence: 0.0966 k= 0.018859 lr = 0.0000031\n",
      "[21/25][1140/9765] Loss_D: 0.0818 Loss_G: 0.0387 Convergence: 0.0882 k= 0.018857 lr = 0.0000031\n",
      "[21/25][1150/9765] Loss_D: 0.0927 Loss_G: 0.0394 Convergence: 0.0955 k= 0.018852 lr = 0.0000031\n",
      "[21/25][1160/9765] Loss_D: 0.0933 Loss_G: 0.0403 Convergence: 0.0968 k= 0.018850 lr = 0.0000031\n",
      "[21/25][1170/9765] Loss_D: 0.0952 Loss_G: 0.0409 Convergence: 0.0985 k= 0.018833 lr = 0.0000031\n",
      "[21/25][1180/9765] Loss_D: 0.0969 Loss_G: 0.0419 Convergence: 0.1005 k= 0.018815 lr = 0.0000031\n",
      "[21/25][1190/9765] Loss_D: 0.1008 Loss_G: 0.0398 Convergence: 0.1024 k= 0.018802 lr = 0.0000031\n",
      "[21/25][1200/9765] Loss_D: 0.0929 Loss_G: 0.0391 Convergence: 0.0952 k= 0.018788 lr = 0.0000031\n",
      "[21/25][1210/9765] Loss_D: 0.0952 Loss_G: 0.0380 Convergence: 0.0962 k= 0.018771 lr = 0.0000031\n",
      "[21/25][1220/9765] Loss_D: 0.1061 Loss_G: 0.0390 Convergence: 0.1106 k= 0.018780 lr = 0.0000031\n",
      "[21/25][1230/9765] Loss_D: 0.0947 Loss_G: 0.0393 Convergence: 0.0965 k= 0.018774 lr = 0.0000031\n",
      "[21/25][1240/9765] Loss_D: 0.0948 Loss_G: 0.0396 Convergence: 0.0969 k= 0.018772 lr = 0.0000031\n",
      "[21/25][1250/9765] Loss_D: 0.0888 Loss_G: 0.0390 Convergence: 0.0927 k= 0.018783 lr = 0.0000031\n",
      "[21/25][1260/9765] Loss_D: 0.0966 Loss_G: 0.0366 Convergence: 0.0996 k= 0.018798 lr = 0.0000031\n",
      "[21/25][1270/9765] Loss_D: 0.0941 Loss_G: 0.0372 Convergence: 0.0956 k= 0.018809 lr = 0.0000031\n",
      "[21/25][1280/9765] Loss_D: 0.0926 Loss_G: 0.0368 Convergence: 0.0938 k= 0.018820 lr = 0.0000031\n",
      "[21/25][1290/9765] Loss_D: 0.0926 Loss_G: 0.0372 Convergence: 0.0934 k= 0.018847 lr = 0.0000031\n",
      "[21/25][1300/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0986 k= 0.018850 lr = 0.0000031\n",
      "[21/25][1310/9765] Loss_D: 0.0975 Loss_G: 0.0387 Convergence: 0.0989 k= 0.018857 lr = 0.0000031\n",
      "[21/25][1320/9765] Loss_D: 0.0985 Loss_G: 0.0400 Convergence: 0.0996 k= 0.018848 lr = 0.0000031\n",
      "[21/25][1330/9765] Loss_D: 0.0922 Loss_G: 0.0395 Convergence: 0.0952 k= 0.018838 lr = 0.0000031\n",
      "[21/25][1340/9765] Loss_D: 0.0924 Loss_G: 0.0388 Convergence: 0.0946 k= 0.018839 lr = 0.0000031\n",
      "[21/25][1350/9765] Loss_D: 0.0896 Loss_G: 0.0382 Convergence: 0.0924 k= 0.018830 lr = 0.0000031\n",
      "[21/25][1360/9765] Loss_D: 0.0867 Loss_G: 0.0387 Convergence: 0.0911 k= 0.018835 lr = 0.0000031\n",
      "[21/25][1370/9765] Loss_D: 0.1017 Loss_G: 0.0389 Convergence: 0.1046 k= 0.018833 lr = 0.0000031\n",
      "[21/25][1380/9765] Loss_D: 0.0942 Loss_G: 0.0396 Convergence: 0.0965 k= 0.018822 lr = 0.0000031\n",
      "[21/25][1390/9765] Loss_D: 0.0970 Loss_G: 0.0373 Convergence: 0.0994 k= 0.018822 lr = 0.0000031\n",
      "[21/25][1400/9765] Loss_D: 0.1013 Loss_G: 0.0370 Convergence: 0.1058 k= 0.018841 lr = 0.0000031\n",
      "[21/25][1410/9765] Loss_D: 0.0939 Loss_G: 0.0365 Convergence: 0.0960 k= 0.018838 lr = 0.0000031\n",
      "[21/25][1420/9765] Loss_D: 0.0956 Loss_G: 0.0376 Convergence: 0.0972 k= 0.018851 lr = 0.0000031\n",
      "[21/25][1430/9765] Loss_D: 0.0942 Loss_G: 0.0384 Convergence: 0.0954 k= 0.018849 lr = 0.0000031\n",
      "[21/25][1440/9765] Loss_D: 0.1114 Loss_G: 0.0399 Convergence: 0.1171 k= 0.018856 lr = 0.0000031\n",
      "[21/25][1450/9765] Loss_D: 0.0914 Loss_G: 0.0381 Convergence: 0.0933 k= 0.018852 lr = 0.0000031\n",
      "[21/25][1460/9765] Loss_D: 0.1034 Loss_G: 0.0388 Convergence: 0.1070 k= 0.018861 lr = 0.0000031\n",
      "[21/25][1470/9765] Loss_D: 0.0986 Loss_G: 0.0391 Convergence: 0.1000 k= 0.018855 lr = 0.0000031\n",
      "[21/25][1480/9765] Loss_D: 0.0922 Loss_G: 0.0393 Convergence: 0.0950 k= 0.018853 lr = 0.0000031\n",
      "[21/25][1490/9765] Loss_D: 0.0920 Loss_G: 0.0393 Convergence: 0.0949 k= 0.018840 lr = 0.0000031\n",
      "[21/25][1500/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0985 k= 0.018828 lr = 0.0000031\n",
      "[21/25][1510/9765] Loss_D: 0.0980 Loss_G: 0.0397 Convergence: 0.0989 k= 0.018818 lr = 0.0000031\n",
      "[21/25][1520/9765] Loss_D: 0.0960 Loss_G: 0.0395 Convergence: 0.0975 k= 0.018797 lr = 0.0000031\n",
      "[21/25][1530/9765] Loss_D: 0.0969 Loss_G: 0.0411 Convergence: 0.0997 k= 0.018785 lr = 0.0000031\n",
      "[21/25][1540/9765] Loss_D: 0.0952 Loss_G: 0.0395 Convergence: 0.0971 k= 0.018768 lr = 0.0000031\n",
      "[21/25][1550/9765] Loss_D: 0.0922 Loss_G: 0.0384 Convergence: 0.0941 k= 0.018758 lr = 0.0000031\n",
      "[21/25][1560/9765] Loss_D: 0.0975 Loss_G: 0.0398 Convergence: 0.0987 k= 0.018759 lr = 0.0000031\n",
      "[21/25][1570/9765] Loss_D: 0.1040 Loss_G: 0.0384 Convergence: 0.1083 k= 0.018766 lr = 0.0000031\n",
      "[21/25][1580/9765] Loss_D: 0.1038 Loss_G: 0.0375 Convergence: 0.1089 k= 0.018778 lr = 0.0000031\n",
      "[21/25][1590/9765] Loss_D: 0.1029 Loss_G: 0.0374 Convergence: 0.1076 k= 0.018788 lr = 0.0000031\n",
      "[21/25][1600/9765] Loss_D: 0.1061 Loss_G: 0.0379 Convergence: 0.1116 k= 0.018803 lr = 0.0000031\n",
      "[21/25][1610/9765] Loss_D: 0.0956 Loss_G: 0.0370 Convergence: 0.0978 k= 0.018813 lr = 0.0000031\n",
      "[21/25][1620/9765] Loss_D: 0.0914 Loss_G: 0.0371 Convergence: 0.0924 k= 0.018820 lr = 0.0000031\n",
      "[21/25][1630/9765] Loss_D: 0.0962 Loss_G: 0.0372 Convergence: 0.0985 k= 0.018837 lr = 0.0000031\n",
      "[21/25][1640/9765] Loss_D: 0.0970 Loss_G: 0.0374 Convergence: 0.0994 k= 0.018833 lr = 0.0000031\n",
      "[21/25][1650/9765] Loss_D: 0.0948 Loss_G: 0.0388 Convergence: 0.0961 k= 0.018836 lr = 0.0000031\n",
      "[21/25][1660/9765] Loss_D: 0.0940 Loss_G: 0.0402 Convergence: 0.0971 k= 0.018834 lr = 0.0000031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][1670/9765] Loss_D: 0.1000 Loss_G: 0.0409 Convergence: 0.1014 k= 0.018821 lr = 0.0000031\n",
      "[21/25][1680/9765] Loss_D: 0.0916 Loss_G: 0.0426 Convergence: 0.0980 k= 0.018801 lr = 0.0000031\n",
      "[21/25][1690/9765] Loss_D: 0.0937 Loss_G: 0.0427 Convergence: 0.0994 k= 0.018766 lr = 0.0000031\n",
      "[21/25][1700/9765] Loss_D: 0.0996 Loss_G: 0.0415 Convergence: 0.1017 k= 0.018729 lr = 0.0000031\n",
      "[21/25][1710/9765] Loss_D: 0.0875 Loss_G: 0.0414 Convergence: 0.0943 k= 0.018685 lr = 0.0000031\n",
      "[21/25][1720/9765] Loss_D: 0.0934 Loss_G: 0.0415 Convergence: 0.0980 k= 0.018651 lr = 0.0000031\n",
      "[21/25][1730/9765] Loss_D: 0.0870 Loss_G: 0.0422 Convergence: 0.0948 k= 0.018602 lr = 0.0000031\n",
      "[21/25][1740/9765] Loss_D: 0.0854 Loss_G: 0.0397 Convergence: 0.0914 k= 0.018569 lr = 0.0000031\n",
      "[21/25][1750/9765] Loss_D: 0.0942 Loss_G: 0.0389 Convergence: 0.0959 k= 0.018565 lr = 0.0000031\n",
      "[21/25][1760/9765] Loss_D: 0.0961 Loss_G: 0.0378 Convergence: 0.0977 k= 0.018558 lr = 0.0000031\n",
      "[21/25][1770/9765] Loss_D: 0.1017 Loss_G: 0.0403 Convergence: 0.1032 k= 0.018550 lr = 0.0000031\n",
      "[21/25][1780/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0954 k= 0.018546 lr = 0.0000031\n",
      "[21/25][1790/9765] Loss_D: 0.0984 Loss_G: 0.0376 Convergence: 0.1012 k= 0.018556 lr = 0.0000031\n",
      "[21/25][1800/9765] Loss_D: 0.0897 Loss_G: 0.0353 Convergence: 0.0913 k= 0.018574 lr = 0.0000031\n",
      "[21/25][1810/9765] Loss_D: 0.0986 Loss_G: 0.0346 Convergence: 0.1043 k= 0.018602 lr = 0.0000031\n",
      "[21/25][1820/9765] Loss_D: 0.0993 Loss_G: 0.0358 Convergence: 0.1042 k= 0.018633 lr = 0.0000031\n",
      "[21/25][1830/9765] Loss_D: 0.0972 Loss_G: 0.0356 Convergence: 0.1014 k= 0.018660 lr = 0.0000031\n",
      "[21/25][1840/9765] Loss_D: 0.0902 Loss_G: 0.0382 Convergence: 0.0927 k= 0.018684 lr = 0.0000031\n",
      "[21/25][1850/9765] Loss_D: 0.0925 Loss_G: 0.0357 Convergence: 0.0947 k= 0.018700 lr = 0.0000031\n",
      "[21/25][1860/9765] Loss_D: 0.0873 Loss_G: 0.0371 Convergence: 0.0900 k= 0.018708 lr = 0.0000031\n",
      "[21/25][1870/9765] Loss_D: 0.0907 Loss_G: 0.0381 Convergence: 0.0929 k= 0.018719 lr = 0.0000031\n",
      "[21/25][1880/9765] Loss_D: 0.0980 Loss_G: 0.0385 Convergence: 0.0997 k= 0.018728 lr = 0.0000031\n",
      "[21/25][1890/9765] Loss_D: 0.0962 Loss_G: 0.0385 Convergence: 0.0972 k= 0.018732 lr = 0.0000031\n",
      "[21/25][1900/9765] Loss_D: 0.1005 Loss_G: 0.0388 Convergence: 0.1029 k= 0.018741 lr = 0.0000031\n",
      "[21/25][1910/9765] Loss_D: 0.0944 Loss_G: 0.0390 Convergence: 0.0961 k= 0.018736 lr = 0.0000031\n",
      "[21/25][1920/9765] Loss_D: 0.0886 Loss_G: 0.0387 Convergence: 0.0923 k= 0.018727 lr = 0.0000031\n",
      "[21/25][1930/9765] Loss_D: 0.0975 Loss_G: 0.0407 Convergence: 0.0996 k= 0.018721 lr = 0.0000031\n",
      "[21/25][1940/9765] Loss_D: 0.0998 Loss_G: 0.0401 Convergence: 0.1006 k= 0.018717 lr = 0.0000029\n",
      "[21/25][1950/9765] Loss_D: 0.0929 Loss_G: 0.0377 Convergence: 0.0938 k= 0.018715 lr = 0.0000029\n",
      "[21/25][1960/9765] Loss_D: 0.1017 Loss_G: 0.0401 Convergence: 0.1033 k= 0.018713 lr = 0.0000029\n",
      "[21/25][1970/9765] Loss_D: 0.0961 Loss_G: 0.0385 Convergence: 0.0970 k= 0.018701 lr = 0.0000029\n",
      "[21/25][1980/9765] Loss_D: 0.0952 Loss_G: 0.0386 Convergence: 0.0962 k= 0.018700 lr = 0.0000029\n",
      "[21/25][1990/9765] Loss_D: 0.1001 Loss_G: 0.0389 Convergence: 0.1023 k= 0.018707 lr = 0.0000029\n",
      "[21/25][2000/9765] Loss_D: 0.0934 Loss_G: 0.0392 Convergence: 0.0957 k= 0.018718 lr = 0.0000029\n",
      "[21/25][2010/9765] Loss_D: 0.0950 Loss_G: 0.0377 Convergence: 0.0962 k= 0.018715 lr = 0.0000029\n",
      "[21/25][2020/9765] Loss_D: 0.0934 Loss_G: 0.0390 Convergence: 0.0954 k= 0.018726 lr = 0.0000029\n",
      "[21/25][2030/9765] Loss_D: 0.0980 Loss_G: 0.0386 Convergence: 0.0996 k= 0.018732 lr = 0.0000029\n",
      "[21/25][2040/9765] Loss_D: 0.0949 Loss_G: 0.0376 Convergence: 0.0963 k= 0.018745 lr = 0.0000029\n",
      "[21/25][2050/9765] Loss_D: 0.1000 Loss_G: 0.0391 Convergence: 0.1020 k= 0.018758 lr = 0.0000029\n",
      "[21/25][2060/9765] Loss_D: 0.1029 Loss_G: 0.0371 Convergence: 0.1079 k= 0.018753 lr = 0.0000029\n",
      "[21/25][2070/9765] Loss_D: 0.0964 Loss_G: 0.0376 Convergence: 0.0983 k= 0.018765 lr = 0.0000029\n",
      "[21/25][2080/9765] Loss_D: 0.0917 Loss_G: 0.0384 Convergence: 0.0938 k= 0.018770 lr = 0.0000029\n",
      "[21/25][2090/9765] Loss_D: 0.0913 Loss_G: 0.0386 Convergence: 0.0939 k= 0.018761 lr = 0.0000029\n",
      "[21/25][2100/9765] Loss_D: 0.0864 Loss_G: 0.0380 Convergence: 0.0903 k= 0.018752 lr = 0.0000029\n",
      "[21/25][2110/9765] Loss_D: 0.0920 Loss_G: 0.0391 Convergence: 0.0947 k= 0.018757 lr = 0.0000029\n",
      "[21/25][2120/9765] Loss_D: 0.0937 Loss_G: 0.0397 Convergence: 0.0964 k= 0.018756 lr = 0.0000029\n",
      "[21/25][2130/9765] Loss_D: 0.0889 Loss_G: 0.0372 Convergence: 0.0910 k= 0.018752 lr = 0.0000029\n",
      "[21/25][2140/9765] Loss_D: 0.1009 Loss_G: 0.0381 Convergence: 0.1042 k= 0.018762 lr = 0.0000029\n",
      "[21/25][2150/9765] Loss_D: 0.0909 Loss_G: 0.0388 Convergence: 0.0938 k= 0.018769 lr = 0.0000029\n",
      "[21/25][2160/9765] Loss_D: 0.1037 Loss_G: 0.0380 Convergence: 0.1082 k= 0.018784 lr = 0.0000029\n",
      "[21/25][2170/9765] Loss_D: 0.0998 Loss_G: 0.0386 Convergence: 0.1021 k= 0.018804 lr = 0.0000029\n",
      "[21/25][2180/9765] Loss_D: 0.1027 Loss_G: 0.0392 Convergence: 0.1057 k= 0.018809 lr = 0.0000029\n",
      "[21/25][2190/9765] Loss_D: 0.0978 Loss_G: 0.0390 Convergence: 0.0990 k= 0.018812 lr = 0.0000029\n",
      "[21/25][2200/9765] Loss_D: 0.0943 Loss_G: 0.0377 Convergence: 0.0952 k= 0.018803 lr = 0.0000029\n",
      "[21/25][2210/9765] Loss_D: 0.1035 Loss_G: 0.0376 Convergence: 0.1083 k= 0.018810 lr = 0.0000029\n",
      "[21/25][2220/9765] Loss_D: 0.1006 Loss_G: 0.0394 Convergence: 0.1025 k= 0.018826 lr = 0.0000029\n",
      "[21/25][2230/9765] Loss_D: 0.1036 Loss_G: 0.0385 Convergence: 0.1076 k= 0.018823 lr = 0.0000029\n",
      "[21/25][2240/9765] Loss_D: 0.0902 Loss_G: 0.0390 Convergence: 0.0935 k= 0.018823 lr = 0.0000029\n",
      "[21/25][2250/9765] Loss_D: 0.1070 Loss_G: 0.0382 Convergence: 0.1127 k= 0.018844 lr = 0.0000029\n",
      "[21/25][2260/9765] Loss_D: 0.0935 Loss_G: 0.0362 Convergence: 0.0957 k= 0.018858 lr = 0.0000029\n",
      "[21/25][2270/9765] Loss_D: 0.0959 Loss_G: 0.0359 Convergence: 0.0993 k= 0.018884 lr = 0.0000029\n",
      "[21/25][2280/9765] Loss_D: 0.0820 Loss_G: 0.0371 Convergence: 0.0867 k= 0.018891 lr = 0.0000029\n",
      "[21/25][2290/9765] Loss_D: 0.0921 Loss_G: 0.0380 Convergence: 0.0937 k= 0.018903 lr = 0.0000029\n",
      "[21/25][2300/9765] Loss_D: 0.0887 Loss_G: 0.0360 Convergence: 0.0897 k= 0.018918 lr = 0.0000029\n",
      "[21/25][2310/9765] Loss_D: 0.1072 Loss_G: 0.0389 Convergence: 0.1122 k= 0.018934 lr = 0.0000029\n",
      "[21/25][2320/9765] Loss_D: 0.0924 Loss_G: 0.0381 Convergence: 0.0940 k= 0.018936 lr = 0.0000029\n",
      "[21/25][2330/9765] Loss_D: 0.1044 Loss_G: 0.0372 Convergence: 0.1099 k= 0.018933 lr = 0.0000029\n",
      "[21/25][2340/9765] Loss_D: 0.0995 Loss_G: 0.0393 Convergence: 0.1011 k= 0.018941 lr = 0.0000029\n",
      "[21/25][2350/9765] Loss_D: 0.0934 Loss_G: 0.0379 Convergence: 0.0943 k= 0.018937 lr = 0.0000029\n",
      "[21/25][2360/9765] Loss_D: 0.0925 Loss_G: 0.0386 Convergence: 0.0945 k= 0.018927 lr = 0.0000029\n",
      "[21/25][2370/9765] Loss_D: 0.1010 Loss_G: 0.0398 Convergence: 0.1027 k= 0.018915 lr = 0.0000029\n",
      "[21/25][2380/9765] Loss_D: 0.1039 Loss_G: 0.0375 Convergence: 0.1089 k= 0.018926 lr = 0.0000029\n",
      "[21/25][2390/9765] Loss_D: 0.0995 Loss_G: 0.0378 Convergence: 0.1025 k= 0.018938 lr = 0.0000029\n",
      "[21/25][2400/9765] Loss_D: 0.0966 Loss_G: 0.0384 Convergence: 0.0979 k= 0.018938 lr = 0.0000029\n",
      "[21/25][2410/9765] Loss_D: 0.0944 Loss_G: 0.0398 Convergence: 0.0969 k= 0.018933 lr = 0.0000029\n",
      "[21/25][2420/9765] Loss_D: 0.0907 Loss_G: 0.0376 Convergence: 0.0924 k= 0.018935 lr = 0.0000029\n",
      "[21/25][2430/9765] Loss_D: 0.0905 Loss_G: 0.0368 Convergence: 0.0915 k= 0.018934 lr = 0.0000029\n",
      "[21/25][2440/9765] Loss_D: 0.1073 Loss_G: 0.0381 Convergence: 0.1131 k= 0.018951 lr = 0.0000029\n",
      "[21/25][2450/9765] Loss_D: 0.0958 Loss_G: 0.0388 Convergence: 0.0967 k= 0.018968 lr = 0.0000029\n",
      "[21/25][2460/9765] Loss_D: 0.0927 Loss_G: 0.0397 Convergence: 0.0958 k= 0.018960 lr = 0.0000029\n",
      "[21/25][2470/9765] Loss_D: 0.1024 Loss_G: 0.0390 Convergence: 0.1053 k= 0.018958 lr = 0.0000029\n",
      "[21/25][2480/9765] Loss_D: 0.0909 Loss_G: 0.0375 Convergence: 0.0925 k= 0.018957 lr = 0.0000029\n",
      "[21/25][2490/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1005 k= 0.018962 lr = 0.0000029\n",
      "[21/25][2500/9765] Loss_D: 0.0942 Loss_G: 0.0399 Convergence: 0.0969 k= 0.018958 lr = 0.0000029\n",
      "[21/25][2510/9765] Loss_D: 0.0969 Loss_G: 0.0400 Convergence: 0.0986 k= 0.018957 lr = 0.0000029\n",
      "[21/25][2520/9765] Loss_D: 0.1003 Loss_G: 0.0378 Convergence: 0.1036 k= 0.018956 lr = 0.0000029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][2530/9765] Loss_D: 0.1054 Loss_G: 0.0393 Convergence: 0.1094 k= 0.018970 lr = 0.0000029\n",
      "[21/25][2540/9765] Loss_D: 0.0995 Loss_G: 0.0390 Convergence: 0.1014 k= 0.018967 lr = 0.0000029\n",
      "[21/25][2550/9765] Loss_D: 0.0951 Loss_G: 0.0379 Convergence: 0.0963 k= 0.018981 lr = 0.0000029\n",
      "[21/25][2560/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0974 k= 0.018987 lr = 0.0000029\n",
      "[21/25][2570/9765] Loss_D: 0.0971 Loss_G: 0.0386 Convergence: 0.0984 k= 0.018998 lr = 0.0000029\n",
      "[21/25][2580/9765] Loss_D: 0.0969 Loss_G: 0.0386 Convergence: 0.0981 k= 0.018995 lr = 0.0000029\n",
      "[21/25][2590/9765] Loss_D: 0.0995 Loss_G: 0.0386 Convergence: 0.1017 k= 0.018994 lr = 0.0000029\n",
      "[21/25][2600/9765] Loss_D: 0.1038 Loss_G: 0.0390 Convergence: 0.1074 k= 0.018989 lr = 0.0000029\n",
      "[21/25][2610/9765] Loss_D: 0.0969 Loss_G: 0.0384 Convergence: 0.0983 k= 0.018987 lr = 0.0000029\n",
      "[21/25][2620/9765] Loss_D: 0.1009 Loss_G: 0.0385 Convergence: 0.1038 k= 0.019004 lr = 0.0000029\n",
      "[21/25][2630/9765] Loss_D: 0.0933 Loss_G: 0.0403 Convergence: 0.0968 k= 0.019011 lr = 0.0000029\n",
      "[21/25][2640/9765] Loss_D: 0.0999 Loss_G: 0.0370 Convergence: 0.1038 k= 0.019017 lr = 0.0000029\n",
      "[21/25][2650/9765] Loss_D: 0.1089 Loss_G: 0.0385 Convergence: 0.1149 k= 0.019044 lr = 0.0000029\n",
      "[21/25][2660/9765] Loss_D: 0.1018 Loss_G: 0.0393 Convergence: 0.1043 k= 0.019040 lr = 0.0000029\n",
      "[21/25][2670/9765] Loss_D: 0.0939 Loss_G: 0.0396 Convergence: 0.0964 k= 0.019035 lr = 0.0000029\n",
      "[21/25][2680/9765] Loss_D: 0.0913 Loss_G: 0.0389 Convergence: 0.0941 k= 0.019028 lr = 0.0000029\n",
      "[21/25][2690/9765] Loss_D: 0.1102 Loss_G: 0.0379 Convergence: 0.1173 k= 0.019034 lr = 0.0000029\n",
      "[21/25][2700/9765] Loss_D: 0.0944 Loss_G: 0.0381 Convergence: 0.0952 k= 0.019030 lr = 0.0000029\n",
      "[21/25][2710/9765] Loss_D: 0.0962 Loss_G: 0.0380 Convergence: 0.0978 k= 0.019032 lr = 0.0000029\n",
      "[21/25][2720/9765] Loss_D: 0.1093 Loss_G: 0.0401 Convergence: 0.1140 k= 0.019043 lr = 0.0000029\n",
      "[21/25][2730/9765] Loss_D: 0.1032 Loss_G: 0.0389 Convergence: 0.1065 k= 0.019053 lr = 0.0000029\n",
      "[21/25][2740/9765] Loss_D: 0.0978 Loss_G: 0.0385 Convergence: 0.0995 k= 0.019051 lr = 0.0000029\n",
      "[21/25][2750/9765] Loss_D: 0.0956 Loss_G: 0.0403 Convergence: 0.0982 k= 0.019040 lr = 0.0000029\n",
      "[21/25][2760/9765] Loss_D: 0.0927 Loss_G: 0.0402 Convergence: 0.0963 k= 0.019029 lr = 0.0000029\n",
      "[21/25][2770/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1005 k= 0.019036 lr = 0.0000029\n",
      "[21/25][2780/9765] Loss_D: 0.1016 Loss_G: 0.0383 Convergence: 0.1049 k= 0.019035 lr = 0.0000029\n",
      "[21/25][2790/9765] Loss_D: 0.1043 Loss_G: 0.0392 Convergence: 0.1079 k= 0.019026 lr = 0.0000029\n",
      "[21/25][2800/9765] Loss_D: 0.0967 Loss_G: 0.0388 Convergence: 0.0976 k= 0.019029 lr = 0.0000029\n",
      "[21/25][2810/9765] Loss_D: 0.0917 Loss_G: 0.0395 Convergence: 0.0949 k= 0.019027 lr = 0.0000029\n",
      "[21/25][2820/9765] Loss_D: 0.1018 Loss_G: 0.0378 Convergence: 0.1057 k= 0.019022 lr = 0.0000029\n",
      "[21/25][2830/9765] Loss_D: 0.0932 Loss_G: 0.0391 Convergence: 0.0955 k= 0.019021 lr = 0.0000029\n",
      "[21/25][2840/9765] Loss_D: 0.0919 Loss_G: 0.0392 Convergence: 0.0948 k= 0.019019 lr = 0.0000029\n",
      "[21/25][2850/9765] Loss_D: 0.0944 Loss_G: 0.0392 Convergence: 0.0963 k= 0.019017 lr = 0.0000029\n",
      "[21/25][2860/9765] Loss_D: 0.0952 Loss_G: 0.0385 Convergence: 0.0960 k= 0.019010 lr = 0.0000029\n",
      "[21/25][2870/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0964 k= 0.019011 lr = 0.0000029\n",
      "[21/25][2880/9765] Loss_D: 0.0971 Loss_G: 0.0394 Convergence: 0.0981 k= 0.019006 lr = 0.0000029\n",
      "[21/25][2890/9765] Loss_D: 0.0961 Loss_G: 0.0382 Convergence: 0.0973 k= 0.019013 lr = 0.0000029\n",
      "[21/25][2900/9765] Loss_D: 0.1056 Loss_G: 0.0393 Convergence: 0.1097 k= 0.019026 lr = 0.0000029\n",
      "[21/25][2910/9765] Loss_D: 0.0906 Loss_G: 0.0377 Convergence: 0.0925 k= 0.019031 lr = 0.0000029\n",
      "[21/25][2920/9765] Loss_D: 0.0911 Loss_G: 0.0382 Convergence: 0.0933 k= 0.019031 lr = 0.0000029\n",
      "[21/25][2930/9765] Loss_D: 0.0914 Loss_G: 0.0376 Convergence: 0.0928 k= 0.019034 lr = 0.0000029\n",
      "[21/25][2940/9765] Loss_D: 0.1000 Loss_G: 0.0388 Convergence: 0.1022 k= 0.019036 lr = 0.0000029\n",
      "[21/25][2950/9765] Loss_D: 0.0994 Loss_G: 0.0382 Convergence: 0.1019 k= 0.019037 lr = 0.0000029\n",
      "[21/25][2960/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0992 k= 0.019051 lr = 0.0000029\n",
      "[21/25][2970/9765] Loss_D: 0.1002 Loss_G: 0.0392 Convergence: 0.1022 k= 0.019044 lr = 0.0000029\n",
      "[21/25][2980/9765] Loss_D: 0.0951 Loss_G: 0.0391 Convergence: 0.0966 k= 0.019031 lr = 0.0000029\n",
      "[21/25][2990/9765] Loss_D: 0.0957 Loss_G: 0.0401 Convergence: 0.0980 k= 0.019025 lr = 0.0000029\n",
      "[21/25][3000/9765] Loss_D: 0.1010 Loss_G: 0.0400 Convergence: 0.1025 k= 0.019015 lr = 0.0000029\n",
      "[21/25][3010/9765] Loss_D: 0.0998 Loss_G: 0.0413 Convergence: 0.1017 k= 0.019008 lr = 0.0000029\n",
      "[21/25][3020/9765] Loss_D: 0.0874 Loss_G: 0.0402 Convergence: 0.0931 k= 0.018987 lr = 0.0000029\n",
      "[21/25][3030/9765] Loss_D: 0.0919 Loss_G: 0.0387 Convergence: 0.0942 k= 0.018971 lr = 0.0000029\n",
      "[21/25][3040/9765] Loss_D: 0.1016 Loss_G: 0.0381 Convergence: 0.1052 k= 0.018969 lr = 0.0000029\n",
      "[21/25][3050/9765] Loss_D: 0.0939 Loss_G: 0.0387 Convergence: 0.0955 k= 0.018974 lr = 0.0000029\n",
      "[21/25][3060/9765] Loss_D: 0.0926 Loss_G: 0.0402 Convergence: 0.0962 k= 0.018976 lr = 0.0000029\n",
      "[21/25][3070/9765] Loss_D: 0.0979 Loss_G: 0.0387 Convergence: 0.0994 k= 0.018966 lr = 0.0000029\n",
      "[21/25][3080/9765] Loss_D: 0.0943 Loss_G: 0.0381 Convergence: 0.0951 k= 0.018973 lr = 0.0000029\n",
      "[21/25][3090/9765] Loss_D: 0.1002 Loss_G: 0.0384 Convergence: 0.1030 k= 0.018975 lr = 0.0000029\n",
      "[21/25][3100/9765] Loss_D: 0.0998 Loss_G: 0.0389 Convergence: 0.1019 k= 0.018986 lr = 0.0000029\n",
      "[21/25][3110/9765] Loss_D: 0.0959 Loss_G: 0.0386 Convergence: 0.0966 k= 0.019001 lr = 0.0000029\n",
      "[21/25][3120/9765] Loss_D: 0.0956 Loss_G: 0.0373 Convergence: 0.0976 k= 0.019005 lr = 0.0000029\n",
      "[21/25][3130/9765] Loss_D: 0.0960 Loss_G: 0.0373 Convergence: 0.0981 k= 0.019021 lr = 0.0000029\n",
      "[21/25][3140/9765] Loss_D: 0.0999 Loss_G: 0.0385 Convergence: 0.1024 k= 0.019029 lr = 0.0000029\n",
      "[21/25][3150/9765] Loss_D: 0.1106 Loss_G: 0.0401 Convergence: 0.1157 k= 0.019030 lr = 0.0000029\n",
      "[21/25][3160/9765] Loss_D: 0.0892 Loss_G: 0.0412 Convergence: 0.0952 k= 0.019006 lr = 0.0000029\n",
      "[21/25][3170/9765] Loss_D: 0.0996 Loss_G: 0.0400 Convergence: 0.1005 k= 0.018992 lr = 0.0000029\n",
      "[21/25][3180/9765] Loss_D: 0.0933 Loss_G: 0.0418 Convergence: 0.0983 k= 0.018966 lr = 0.0000029\n",
      "[21/25][3190/9765] Loss_D: 0.0929 Loss_G: 0.0406 Convergence: 0.0968 k= 0.018939 lr = 0.0000029\n",
      "[21/25][3200/9765] Loss_D: 0.0895 Loss_G: 0.0412 Convergence: 0.0954 k= 0.018916 lr = 0.0000029\n",
      "[21/25][3210/9765] Loss_D: 0.0842 Loss_G: 0.0393 Convergence: 0.0903 k= 0.018892 lr = 0.0000029\n",
      "[21/25][3220/9765] Loss_D: 0.0959 Loss_G: 0.0416 Convergence: 0.0996 k= 0.018862 lr = 0.0000029\n",
      "[21/25][3230/9765] Loss_D: 0.1049 Loss_G: 0.0365 Convergence: 0.1114 k= 0.018856 lr = 0.0000029\n",
      "[21/25][3240/9765] Loss_D: 0.0993 Loss_G: 0.0375 Convergence: 0.1025 k= 0.018853 lr = 0.0000029\n",
      "[21/25][3250/9765] Loss_D: 0.0992 Loss_G: 0.0368 Convergence: 0.1031 k= 0.018869 lr = 0.0000029\n",
      "[21/25][3260/9765] Loss_D: 0.0894 Loss_G: 0.0369 Convergence: 0.0909 k= 0.018881 lr = 0.0000029\n",
      "[21/25][3270/9765] Loss_D: 0.0926 Loss_G: 0.0373 Convergence: 0.0933 k= 0.018899 lr = 0.0000029\n",
      "[21/25][3280/9765] Loss_D: 0.1027 Loss_G: 0.0380 Convergence: 0.1068 k= 0.018913 lr = 0.0000029\n",
      "[21/25][3290/9765] Loss_D: 0.1020 Loss_G: 0.0378 Convergence: 0.1059 k= 0.018932 lr = 0.0000029\n",
      "[21/25][3300/9765] Loss_D: 0.0992 Loss_G: 0.0374 Convergence: 0.1025 k= 0.018947 lr = 0.0000029\n",
      "[21/25][3310/9765] Loss_D: 0.0951 Loss_G: 0.0368 Convergence: 0.0973 k= 0.018966 lr = 0.0000029\n",
      "[21/25][3320/9765] Loss_D: 0.0959 Loss_G: 0.0383 Convergence: 0.0970 k= 0.018981 lr = 0.0000029\n",
      "[21/25][3330/9765] Loss_D: 0.0920 Loss_G: 0.0397 Convergence: 0.0953 k= 0.018983 lr = 0.0000029\n",
      "[21/25][3340/9765] Loss_D: 0.0972 Loss_G: 0.0396 Convergence: 0.0983 k= 0.018978 lr = 0.0000029\n",
      "[21/25][3350/9765] Loss_D: 0.0983 Loss_G: 0.0393 Convergence: 0.0994 k= 0.018974 lr = 0.0000029\n",
      "[21/25][3360/9765] Loss_D: 0.0893 Loss_G: 0.0399 Convergence: 0.0939 k= 0.018967 lr = 0.0000029\n",
      "[21/25][3370/9765] Loss_D: 0.0887 Loss_G: 0.0377 Convergence: 0.0914 k= 0.018955 lr = 0.0000029\n",
      "[21/25][3380/9765] Loss_D: 0.0995 Loss_G: 0.0386 Convergence: 0.1016 k= 0.018964 lr = 0.0000029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][3390/9765] Loss_D: 0.0906 Loss_G: 0.0391 Convergence: 0.0939 k= 0.018959 lr = 0.0000029\n",
      "[21/25][3400/9765] Loss_D: 0.0960 Loss_G: 0.0397 Convergence: 0.0977 k= 0.018951 lr = 0.0000029\n",
      "[21/25][3410/9765] Loss_D: 0.1019 Loss_G: 0.0396 Convergence: 0.1041 k= 0.018940 lr = 0.0000029\n",
      "[21/25][3420/9765] Loss_D: 0.0920 Loss_G: 0.0400 Convergence: 0.0957 k= 0.018935 lr = 0.0000029\n",
      "[21/25][3430/9765] Loss_D: 0.0961 Loss_G: 0.0395 Convergence: 0.0976 k= 0.018933 lr = 0.0000029\n",
      "[21/25][3440/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1011 k= 0.018935 lr = 0.0000029\n",
      "[21/25][3450/9765] Loss_D: 0.0983 Loss_G: 0.0391 Convergence: 0.0995 k= 0.018935 lr = 0.0000029\n",
      "[21/25][3460/9765] Loss_D: 0.0954 Loss_G: 0.0401 Convergence: 0.0978 k= 0.018922 lr = 0.0000029\n",
      "[21/25][3470/9765] Loss_D: 0.0906 Loss_G: 0.0391 Convergence: 0.0939 k= 0.018929 lr = 0.0000029\n",
      "[21/25][3480/9765] Loss_D: 0.0997 Loss_G: 0.0383 Convergence: 0.1023 k= 0.018938 lr = 0.0000029\n",
      "[21/25][3490/9765] Loss_D: 0.1002 Loss_G: 0.0391 Convergence: 0.1023 k= 0.018935 lr = 0.0000029\n",
      "[21/25][3500/9765] Loss_D: 0.0948 Loss_G: 0.0389 Convergence: 0.0962 k= 0.018929 lr = 0.0000029\n",
      "[21/25][3510/9765] Loss_D: 0.0977 Loss_G: 0.0379 Convergence: 0.0999 k= 0.018932 lr = 0.0000029\n",
      "[21/25][3520/9765] Loss_D: 0.0970 Loss_G: 0.0404 Convergence: 0.0991 k= 0.018939 lr = 0.0000029\n",
      "[21/25][3530/9765] Loss_D: 0.1103 Loss_G: 0.0375 Convergence: 0.1178 k= 0.018941 lr = 0.0000029\n",
      "[21/25][3540/9765] Loss_D: 0.0910 Loss_G: 0.0358 Convergence: 0.0926 k= 0.018948 lr = 0.0000029\n",
      "[21/25][3550/9765] Loss_D: 0.0931 Loss_G: 0.0373 Convergence: 0.0941 k= 0.018967 lr = 0.0000029\n",
      "[21/25][3560/9765] Loss_D: 0.0891 Loss_G: 0.0370 Convergence: 0.0908 k= 0.018967 lr = 0.0000029\n",
      "[21/25][3570/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0957 k= 0.018976 lr = 0.0000029\n",
      "[21/25][3580/9765] Loss_D: 0.1021 Loss_G: 0.0393 Convergence: 0.1047 k= 0.018987 lr = 0.0000029\n",
      "[21/25][3590/9765] Loss_D: 0.0895 Loss_G: 0.0372 Convergence: 0.0913 k= 0.018978 lr = 0.0000029\n",
      "[21/25][3600/9765] Loss_D: 0.0825 Loss_G: 0.0364 Convergence: 0.0863 k= 0.018987 lr = 0.0000029\n",
      "[21/25][3610/9765] Loss_D: 0.0980 Loss_G: 0.0395 Convergence: 0.0988 k= 0.018995 lr = 0.0000029\n",
      "[21/25][3620/9765] Loss_D: 0.0918 Loss_G: 0.0403 Convergence: 0.0958 k= 0.018988 lr = 0.0000029\n",
      "[21/25][3630/9765] Loss_D: 0.0863 Loss_G: 0.0387 Convergence: 0.0909 k= 0.018977 lr = 0.0000029\n",
      "[21/25][3640/9765] Loss_D: 0.0970 Loss_G: 0.0409 Convergence: 0.0996 k= 0.018968 lr = 0.0000029\n",
      "[21/25][3650/9765] Loss_D: 0.0938 Loss_G: 0.0407 Convergence: 0.0974 k= 0.018954 lr = 0.0000029\n",
      "[21/25][3660/9765] Loss_D: 0.0903 Loss_G: 0.0388 Convergence: 0.0934 k= 0.018941 lr = 0.0000029\n",
      "[21/25][3670/9765] Loss_D: 0.1034 Loss_G: 0.0390 Convergence: 0.1068 k= 0.018946 lr = 0.0000029\n",
      "[21/25][3680/9765] Loss_D: 0.1000 Loss_G: 0.0401 Convergence: 0.1010 k= 0.018949 lr = 0.0000029\n",
      "[21/25][3690/9765] Loss_D: 0.0891 Loss_G: 0.0394 Convergence: 0.0932 k= 0.018945 lr = 0.0000029\n",
      "[21/25][3700/9765] Loss_D: 0.1006 Loss_G: 0.0377 Convergence: 0.1042 k= 0.018948 lr = 0.0000029\n",
      "[21/25][3710/9765] Loss_D: 0.0983 Loss_G: 0.0371 Convergence: 0.1016 k= 0.018962 lr = 0.0000029\n",
      "[21/25][3720/9765] Loss_D: 0.1000 Loss_G: 0.0377 Convergence: 0.1032 k= 0.018987 lr = 0.0000029\n",
      "[21/25][3730/9765] Loss_D: 0.0942 Loss_G: 0.0364 Convergence: 0.0965 k= 0.018998 lr = 0.0000029\n",
      "[21/25][3740/9765] Loss_D: 0.0856 Loss_G: 0.0365 Convergence: 0.0883 k= 0.019016 lr = 0.0000029\n",
      "[21/25][3750/9765] Loss_D: 0.0934 Loss_G: 0.0366 Convergence: 0.0951 k= 0.019038 lr = 0.0000029\n",
      "[21/25][3760/9765] Loss_D: 0.0900 Loss_G: 0.0379 Convergence: 0.0924 k= 0.019049 lr = 0.0000029\n",
      "[21/25][3770/9765] Loss_D: 0.0934 Loss_G: 0.0392 Convergence: 0.0956 k= 0.019049 lr = 0.0000029\n",
      "[21/25][3780/9765] Loss_D: 0.0882 Loss_G: 0.0397 Convergence: 0.0931 k= 0.019038 lr = 0.0000029\n",
      "[21/25][3790/9765] Loss_D: 0.0999 Loss_G: 0.0422 Convergence: 0.1026 k= 0.019029 lr = 0.0000029\n",
      "[21/25][3800/9765] Loss_D: 0.0947 Loss_G: 0.0412 Convergence: 0.0985 k= 0.019012 lr = 0.0000029\n",
      "[21/25][3810/9765] Loss_D: 0.0960 Loss_G: 0.0419 Convergence: 0.1000 k= 0.018984 lr = 0.0000029\n",
      "[21/25][3820/9765] Loss_D: 0.1127 Loss_G: 0.0403 Convergence: 0.1185 k= 0.018974 lr = 0.0000029\n",
      "[21/25][3830/9765] Loss_D: 0.0936 Loss_G: 0.0404 Convergence: 0.0970 k= 0.018943 lr = 0.0000029\n",
      "[21/25][3840/9765] Loss_D: 0.0907 Loss_G: 0.0425 Convergence: 0.0974 k= 0.018924 lr = 0.0000029\n",
      "[21/25][3850/9765] Loss_D: 0.0893 Loss_G: 0.0399 Convergence: 0.0939 k= 0.018906 lr = 0.0000029\n",
      "[21/25][3860/9765] Loss_D: 0.0929 Loss_G: 0.0405 Convergence: 0.0967 k= 0.018906 lr = 0.0000029\n",
      "[21/25][3870/9765] Loss_D: 0.0931 Loss_G: 0.0391 Convergence: 0.0954 k= 0.018886 lr = 0.0000029\n",
      "[21/25][3880/9765] Loss_D: 0.0956 Loss_G: 0.0391 Convergence: 0.0970 k= 0.018891 lr = 0.0000029\n",
      "[21/25][3890/9765] Loss_D: 0.0810 Loss_G: 0.0350 Convergence: 0.0840 k= 0.018905 lr = 0.0000029\n",
      "[21/25][3900/9765] Loss_D: 0.0935 Loss_G: 0.0356 Convergence: 0.0962 k= 0.018930 lr = 0.0000029\n",
      "[21/25][3910/9765] Loss_D: 0.1004 Loss_G: 0.0367 Convergence: 0.1049 k= 0.018950 lr = 0.0000029\n",
      "[21/25][3920/9765] Loss_D: 0.0996 Loss_G: 0.0357 Convergence: 0.1047 k= 0.018980 lr = 0.0000029\n",
      "[21/25][3930/9765] Loss_D: 0.0957 Loss_G: 0.0360 Convergence: 0.0989 k= 0.019007 lr = 0.0000029\n",
      "[21/25][3940/9765] Loss_D: 0.0955 Loss_G: 0.0380 Convergence: 0.0967 k= 0.019017 lr = 0.0000029\n",
      "[21/25][3950/9765] Loss_D: 0.0978 Loss_G: 0.0386 Convergence: 0.0993 k= 0.019024 lr = 0.0000029\n",
      "[21/25][3960/9765] Loss_D: 0.0938 Loss_G: 0.0368 Convergence: 0.0955 k= 0.019024 lr = 0.0000029\n",
      "[21/25][3970/9765] Loss_D: 0.0883 Loss_G: 0.0383 Convergence: 0.0917 k= 0.019029 lr = 0.0000029\n",
      "[21/25][3980/9765] Loss_D: 0.0944 Loss_G: 0.0395 Convergence: 0.0966 k= 0.019025 lr = 0.0000029\n",
      "[21/25][3990/9765] Loss_D: 0.0920 Loss_G: 0.0400 Convergence: 0.0956 k= 0.019015 lr = 0.0000029\n",
      "[21/25][4000/9765] Loss_D: 0.0983 Loss_G: 0.0409 Convergence: 0.1004 k= 0.018999 lr = 0.0000029\n",
      "[21/25][4010/9765] Loss_D: 0.0940 Loss_G: 0.0400 Convergence: 0.0969 k= 0.018975 lr = 0.0000029\n",
      "[21/25][4020/9765] Loss_D: 0.0960 Loss_G: 0.0402 Convergence: 0.0983 k= 0.018957 lr = 0.0000029\n",
      "[21/25][4030/9765] Loss_D: 0.0951 Loss_G: 0.0384 Convergence: 0.0959 k= 0.018944 lr = 0.0000029\n",
      "[21/25][4040/9765] Loss_D: 0.0947 Loss_G: 0.0395 Convergence: 0.0967 k= 0.018937 lr = 0.0000029\n",
      "[21/25][4050/9765] Loss_D: 0.0997 Loss_G: 0.0394 Convergence: 0.1012 k= 0.018919 lr = 0.0000029\n",
      "[21/25][4060/9765] Loss_D: 0.0978 Loss_G: 0.0379 Convergence: 0.1000 k= 0.018914 lr = 0.0000029\n",
      "[21/25][4070/9765] Loss_D: 0.1060 Loss_G: 0.0398 Convergence: 0.1097 k= 0.018927 lr = 0.0000029\n",
      "[21/25][4080/9765] Loss_D: 0.1010 Loss_G: 0.0389 Convergence: 0.1035 k= 0.018930 lr = 0.0000029\n",
      "[21/25][4090/9765] Loss_D: 0.0950 Loss_G: 0.0385 Convergence: 0.0960 k= 0.018924 lr = 0.0000029\n",
      "[21/25][4100/9765] Loss_D: 0.0979 Loss_G: 0.0384 Convergence: 0.0997 k= 0.018924 lr = 0.0000029\n",
      "[21/25][4110/9765] Loss_D: 0.1012 Loss_G: 0.0388 Convergence: 0.1039 k= 0.018920 lr = 0.0000029\n",
      "[21/25][4120/9765] Loss_D: 0.0980 Loss_G: 0.0388 Convergence: 0.0994 k= 0.018921 lr = 0.0000029\n",
      "[21/25][4130/9765] Loss_D: 0.0963 Loss_G: 0.0394 Convergence: 0.0976 k= 0.018925 lr = 0.0000029\n",
      "[21/25][4140/9765] Loss_D: 0.1014 Loss_G: 0.0382 Convergence: 0.1048 k= 0.018924 lr = 0.0000029\n",
      "[21/25][4150/9765] Loss_D: 0.0891 Loss_G: 0.0412 Convergence: 0.0951 k= 0.018929 lr = 0.0000029\n",
      "[21/25][4160/9765] Loss_D: 0.0867 Loss_G: 0.0391 Convergence: 0.0916 k= 0.018913 lr = 0.0000029\n",
      "[21/25][4170/9765] Loss_D: 0.0919 Loss_G: 0.0381 Convergence: 0.0937 k= 0.018912 lr = 0.0000029\n",
      "[21/25][4180/9765] Loss_D: 0.1082 Loss_G: 0.0397 Convergence: 0.1128 k= 0.018916 lr = 0.0000029\n",
      "[21/25][4190/9765] Loss_D: 0.1081 Loss_G: 0.0401 Convergence: 0.1123 k= 0.018915 lr = 0.0000029\n",
      "[21/25][4200/9765] Loss_D: 0.0978 Loss_G: 0.0400 Convergence: 0.0991 k= 0.018913 lr = 0.0000029\n",
      "[21/25][4210/9765] Loss_D: 0.1007 Loss_G: 0.0416 Convergence: 0.1025 k= 0.018903 lr = 0.0000029\n",
      "[21/25][4220/9765] Loss_D: 0.0930 Loss_G: 0.0383 Convergence: 0.0945 k= 0.018889 lr = 0.0000029\n",
      "[21/25][4230/9765] Loss_D: 0.0966 Loss_G: 0.0385 Convergence: 0.0978 k= 0.018882 lr = 0.0000029\n",
      "[21/25][4240/9765] Loss_D: 0.1063 Loss_G: 0.0393 Convergence: 0.1106 k= 0.018894 lr = 0.0000029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][4250/9765] Loss_D: 0.0891 Loss_G: 0.0392 Convergence: 0.0931 k= 0.018895 lr = 0.0000029\n",
      "[21/25][4260/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0961 k= 0.018904 lr = 0.0000029\n",
      "[21/25][4270/9765] Loss_D: 0.1020 Loss_G: 0.0393 Convergence: 0.1045 k= 0.018901 lr = 0.0000029\n",
      "[21/25][4280/9765] Loss_D: 0.0913 Loss_G: 0.0379 Convergence: 0.0931 k= 0.018906 lr = 0.0000029\n",
      "[21/25][4290/9765] Loss_D: 0.0938 Loss_G: 0.0395 Convergence: 0.0962 k= 0.018897 lr = 0.0000029\n",
      "[21/25][4300/9765] Loss_D: 0.0958 Loss_G: 0.0377 Convergence: 0.0974 k= 0.018897 lr = 0.0000029\n",
      "[21/25][4310/9765] Loss_D: 0.0955 Loss_G: 0.0398 Convergence: 0.0975 k= 0.018898 lr = 0.0000029\n",
      "[21/25][4320/9765] Loss_D: 0.0941 Loss_G: 0.0367 Convergence: 0.0960 k= 0.018906 lr = 0.0000029\n",
      "[21/25][4330/9765] Loss_D: 0.0978 Loss_G: 0.0366 Convergence: 0.1013 k= 0.018912 lr = 0.0000029\n",
      "[21/25][4340/9765] Loss_D: 0.0935 Loss_G: 0.0393 Convergence: 0.0959 k= 0.018911 lr = 0.0000029\n",
      "[21/25][4350/9765] Loss_D: 0.1040 Loss_G: 0.0386 Convergence: 0.1080 k= 0.018903 lr = 0.0000029\n",
      "[21/25][4360/9765] Loss_D: 0.0984 Loss_G: 0.0402 Convergence: 0.0996 k= 0.018895 lr = 0.0000029\n",
      "[21/25][4370/9765] Loss_D: 0.0933 Loss_G: 0.0387 Convergence: 0.0952 k= 0.018887 lr = 0.0000029\n",
      "[21/25][4380/9765] Loss_D: 0.1052 Loss_G: 0.0393 Convergence: 0.1090 k= 0.018880 lr = 0.0000029\n",
      "[21/25][4390/9765] Loss_D: 0.0816 Loss_G: 0.0372 Convergence: 0.0866 k= 0.018864 lr = 0.0000029\n",
      "[21/25][4400/9765] Loss_D: 0.0893 Loss_G: 0.0381 Convergence: 0.0922 k= 0.018863 lr = 0.0000029\n",
      "[21/25][4410/9765] Loss_D: 0.1010 Loss_G: 0.0383 Convergence: 0.1040 k= 0.018861 lr = 0.0000029\n",
      "[21/25][4420/9765] Loss_D: 0.0925 Loss_G: 0.0377 Convergence: 0.0937 k= 0.018851 lr = 0.0000029\n",
      "[21/25][4430/9765] Loss_D: 0.0944 Loss_G: 0.0387 Convergence: 0.0958 k= 0.018855 lr = 0.0000029\n",
      "[21/25][4440/9765] Loss_D: 0.1057 Loss_G: 0.0384 Convergence: 0.1106 k= 0.018848 lr = 0.0000029\n",
      "[21/25][4450/9765] Loss_D: 0.0998 Loss_G: 0.0375 Convergence: 0.1031 k= 0.018851 lr = 0.0000029\n",
      "[21/25][4460/9765] Loss_D: 0.0981 Loss_G: 0.0380 Convergence: 0.1003 k= 0.018868 lr = 0.0000029\n",
      "[21/25][4470/9765] Loss_D: 0.1022 Loss_G: 0.0383 Convergence: 0.1058 k= 0.018877 lr = 0.0000029\n",
      "[21/25][4480/9765] Loss_D: 0.1015 Loss_G: 0.0389 Convergence: 0.1042 k= 0.018885 lr = 0.0000029\n",
      "[21/25][4490/9765] Loss_D: 0.0946 Loss_G: 0.0390 Convergence: 0.0962 k= 0.018892 lr = 0.0000029\n",
      "[21/25][4500/9765] Loss_D: 0.0935 Loss_G: 0.0389 Convergence: 0.0954 k= 0.018905 lr = 0.0000029\n",
      "[21/25][4510/9765] Loss_D: 0.0887 Loss_G: 0.0401 Convergence: 0.0938 k= 0.018906 lr = 0.0000029\n",
      "[21/25][4520/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0942 k= 0.018906 lr = 0.0000029\n",
      "[21/25][4530/9765] Loss_D: 0.0985 Loss_G: 0.0389 Convergence: 0.1001 k= 0.018916 lr = 0.0000029\n",
      "[21/25][4540/9765] Loss_D: 0.0950 Loss_G: 0.0392 Convergence: 0.0966 k= 0.018921 lr = 0.0000029\n",
      "[21/25][4550/9765] Loss_D: 0.0990 Loss_G: 0.0400 Convergence: 0.0998 k= 0.018925 lr = 0.0000029\n",
      "[21/25][4560/9765] Loss_D: 0.0868 Loss_G: 0.0393 Convergence: 0.0919 k= 0.018904 lr = 0.0000029\n",
      "[21/25][4570/9765] Loss_D: 0.1053 Loss_G: 0.0405 Convergence: 0.1080 k= 0.018905 lr = 0.0000029\n",
      "[21/25][4580/9765] Loss_D: 0.0902 Loss_G: 0.0389 Convergence: 0.0935 k= 0.018882 lr = 0.0000029\n",
      "[21/25][4590/9765] Loss_D: 0.0908 Loss_G: 0.0398 Convergence: 0.0947 k= 0.018873 lr = 0.0000029\n",
      "[21/25][4600/9765] Loss_D: 0.0984 Loss_G: 0.0386 Convergence: 0.1002 k= 0.018864 lr = 0.0000029\n",
      "[21/25][4610/9765] Loss_D: 0.0866 Loss_G: 0.0391 Convergence: 0.0915 k= 0.018859 lr = 0.0000029\n",
      "[21/25][4620/9765] Loss_D: 0.1045 Loss_G: 0.0385 Convergence: 0.1088 k= 0.018859 lr = 0.0000029\n",
      "[21/25][4630/9765] Loss_D: 0.0991 Loss_G: 0.0377 Convergence: 0.1021 k= 0.018866 lr = 0.0000029\n",
      "[21/25][4640/9765] Loss_D: 0.1064 Loss_G: 0.0378 Convergence: 0.1122 k= 0.018875 lr = 0.0000029\n",
      "[21/25][4650/9765] Loss_D: 0.0961 Loss_G: 0.0387 Convergence: 0.0969 k= 0.018876 lr = 0.0000029\n",
      "[21/25][4660/9765] Loss_D: 0.0965 Loss_G: 0.0372 Convergence: 0.0988 k= 0.018887 lr = 0.0000029\n",
      "[21/25][4670/9765] Loss_D: 0.0989 Loss_G: 0.0380 Convergence: 0.1014 k= 0.018903 lr = 0.0000029\n",
      "[21/25][4680/9765] Loss_D: 0.0820 Loss_G: 0.0377 Convergence: 0.0873 k= 0.018916 lr = 0.0000029\n",
      "[21/25][4690/9765] Loss_D: 0.0949 Loss_G: 0.0393 Convergence: 0.0967 k= 0.018919 lr = 0.0000029\n",
      "[21/25][4700/9765] Loss_D: 0.0841 Loss_G: 0.0381 Convergence: 0.0890 k= 0.018920 lr = 0.0000029\n",
      "[21/25][4710/9765] Loss_D: 0.0852 Loss_G: 0.0379 Convergence: 0.0894 k= 0.018919 lr = 0.0000029\n",
      "[21/25][4720/9765] Loss_D: 0.0961 Loss_G: 0.0371 Convergence: 0.0984 k= 0.018930 lr = 0.0000029\n",
      "[21/25][4730/9765] Loss_D: 0.0910 Loss_G: 0.0379 Convergence: 0.0930 k= 0.018949 lr = 0.0000029\n",
      "[21/25][4740/9765] Loss_D: 0.0923 Loss_G: 0.0377 Convergence: 0.0935 k= 0.018956 lr = 0.0000029\n",
      "[21/25][4750/9765] Loss_D: 0.0995 Loss_G: 0.0407 Convergence: 0.1008 k= 0.018956 lr = 0.0000029\n",
      "[21/25][4760/9765] Loss_D: 0.0991 Loss_G: 0.0403 Convergence: 0.1002 k= 0.018935 lr = 0.0000029\n",
      "[21/25][4770/9765] Loss_D: 0.0987 Loss_G: 0.0413 Convergence: 0.1010 k= 0.018918 lr = 0.0000029\n",
      "[21/25][4780/9765] Loss_D: 0.0996 Loss_G: 0.0395 Convergence: 0.1009 k= 0.018898 lr = 0.0000029\n",
      "[21/25][4790/9765] Loss_D: 0.0939 Loss_G: 0.0385 Convergence: 0.0953 k= 0.018900 lr = 0.0000029\n",
      "[21/25][4800/9765] Loss_D: 0.0892 Loss_G: 0.0395 Convergence: 0.0935 k= 0.018902 lr = 0.0000029\n",
      "[21/25][4810/9765] Loss_D: 0.1002 Loss_G: 0.0397 Convergence: 0.1016 k= 0.018894 lr = 0.0000029\n",
      "[21/25][4820/9765] Loss_D: 0.1008 Loss_G: 0.0395 Convergence: 0.1027 k= 0.018882 lr = 0.0000029\n",
      "[21/25][4830/9765] Loss_D: 0.0856 Loss_G: 0.0381 Convergence: 0.0899 k= 0.018881 lr = 0.0000029\n",
      "[21/25][4840/9765] Loss_D: 0.1011 Loss_G: 0.0391 Convergence: 0.1034 k= 0.018894 lr = 0.0000029\n",
      "[21/25][4850/9765] Loss_D: 0.0987 Loss_G: 0.0388 Convergence: 0.1004 k= 0.018887 lr = 0.0000029\n",
      "[21/25][4860/9765] Loss_D: 0.0897 Loss_G: 0.0399 Convergence: 0.0941 k= 0.018887 lr = 0.0000029\n",
      "[21/25][4870/9765] Loss_D: 0.0916 Loss_G: 0.0400 Convergence: 0.0954 k= 0.018877 lr = 0.0000029\n",
      "[21/25][4880/9765] Loss_D: 0.0870 Loss_G: 0.0386 Convergence: 0.0913 k= 0.018867 lr = 0.0000029\n",
      "[21/25][4890/9765] Loss_D: 0.1057 Loss_G: 0.0395 Convergence: 0.1095 k= 0.018870 lr = 0.0000029\n",
      "[21/25][4900/9765] Loss_D: 0.0934 Loss_G: 0.0405 Convergence: 0.0970 k= 0.018865 lr = 0.0000029\n",
      "[21/25][4910/9765] Loss_D: 0.0944 Loss_G: 0.0392 Convergence: 0.0963 k= 0.018853 lr = 0.0000029\n",
      "[21/25][4920/9765] Loss_D: 0.0866 Loss_G: 0.0403 Convergence: 0.0927 k= 0.018856 lr = 0.0000029\n",
      "[21/25][4930/9765] Loss_D: 0.0955 Loss_G: 0.0403 Convergence: 0.0981 k= 0.018840 lr = 0.0000029\n",
      "[21/25][4940/9765] Loss_D: 0.1115 Loss_G: 0.0387 Convergence: 0.1185 k= 0.018833 lr = 0.0000028\n",
      "[21/25][4950/9765] Loss_D: 0.1047 Loss_G: 0.0407 Convergence: 0.1069 k= 0.018838 lr = 0.0000028\n",
      "[21/25][4960/9765] Loss_D: 0.0908 Loss_G: 0.0382 Convergence: 0.0932 k= 0.018826 lr = 0.0000028\n",
      "[21/25][4970/9765] Loss_D: 0.0876 Loss_G: 0.0405 Convergence: 0.0935 k= 0.018813 lr = 0.0000028\n",
      "[21/25][4980/9765] Loss_D: 0.1052 Loss_G: 0.0394 Convergence: 0.1089 k= 0.018817 lr = 0.0000028\n",
      "[21/25][4990/9765] Loss_D: 0.0929 Loss_G: 0.0383 Convergence: 0.0945 k= 0.018823 lr = 0.0000028\n",
      "[21/25][5000/9765] Loss_D: 0.0970 Loss_G: 0.0393 Convergence: 0.0980 k= 0.018807 lr = 0.0000028\n",
      "[21/25][5010/9765] Loss_D: 0.0957 Loss_G: 0.0385 Convergence: 0.0965 k= 0.018808 lr = 0.0000028\n",
      "[21/25][5020/9765] Loss_D: 0.1038 Loss_G: 0.0396 Convergence: 0.1067 k= 0.018803 lr = 0.0000028\n",
      "[21/25][5030/9765] Loss_D: 0.0965 Loss_G: 0.0385 Convergence: 0.0977 k= 0.018795 lr = 0.0000028\n",
      "[21/25][5040/9765] Loss_D: 0.1017 Loss_G: 0.0395 Convergence: 0.1040 k= 0.018780 lr = 0.0000028\n",
      "[21/25][5050/9765] Loss_D: 0.0975 Loss_G: 0.0389 Convergence: 0.0985 k= 0.018780 lr = 0.0000028\n",
      "[21/25][5060/9765] Loss_D: 0.0962 Loss_G: 0.0392 Convergence: 0.0974 k= 0.018774 lr = 0.0000028\n",
      "[21/25][5070/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0992 k= 0.018784 lr = 0.0000028\n",
      "[21/25][5080/9765] Loss_D: 0.0938 Loss_G: 0.0375 Convergence: 0.0949 k= 0.018787 lr = 0.0000028\n",
      "[21/25][5090/9765] Loss_D: 0.1007 Loss_G: 0.0379 Convergence: 0.1040 k= 0.018789 lr = 0.0000028\n",
      "[21/25][5100/9765] Loss_D: 0.0971 Loss_G: 0.0385 Convergence: 0.0985 k= 0.018794 lr = 0.0000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][5110/9765] Loss_D: 0.0961 Loss_G: 0.0388 Convergence: 0.0969 k= 0.018793 lr = 0.0000028\n",
      "[21/25][5120/9765] Loss_D: 0.0917 Loss_G: 0.0386 Convergence: 0.0940 k= 0.018800 lr = 0.0000028\n",
      "[21/25][5130/9765] Loss_D: 0.1018 Loss_G: 0.0397 Convergence: 0.1038 k= 0.018792 lr = 0.0000028\n",
      "[21/25][5140/9765] Loss_D: 0.0887 Loss_G: 0.0376 Convergence: 0.0913 k= 0.018786 lr = 0.0000028\n",
      "[21/25][5150/9765] Loss_D: 0.0960 Loss_G: 0.0396 Convergence: 0.0976 k= 0.018793 lr = 0.0000028\n",
      "[21/25][5160/9765] Loss_D: 0.0998 Loss_G: 0.0391 Convergence: 0.1017 k= 0.018789 lr = 0.0000028\n",
      "[21/25][5170/9765] Loss_D: 0.1008 Loss_G: 0.0394 Convergence: 0.1027 k= 0.018780 lr = 0.0000028\n",
      "[21/25][5180/9765] Loss_D: 0.0951 Loss_G: 0.0394 Convergence: 0.0969 k= 0.018776 lr = 0.0000028\n",
      "[21/25][5190/9765] Loss_D: 0.0983 Loss_G: 0.0400 Convergence: 0.0994 k= 0.018776 lr = 0.0000028\n",
      "[21/25][5200/9765] Loss_D: 0.0919 Loss_G: 0.0398 Convergence: 0.0954 k= 0.018769 lr = 0.0000028\n",
      "[21/25][5210/9765] Loss_D: 0.0901 Loss_G: 0.0397 Convergence: 0.0942 k= 0.018762 lr = 0.0000028\n",
      "[21/25][5220/9765] Loss_D: 0.0964 Loss_G: 0.0395 Convergence: 0.0978 k= 0.018763 lr = 0.0000028\n",
      "[21/25][5230/9765] Loss_D: 0.0918 Loss_G: 0.0396 Convergence: 0.0952 k= 0.018756 lr = 0.0000028\n",
      "[21/25][5240/9765] Loss_D: 0.0956 Loss_G: 0.0403 Convergence: 0.0982 k= 0.018752 lr = 0.0000028\n",
      "[21/25][5250/9765] Loss_D: 0.0959 Loss_G: 0.0380 Convergence: 0.0973 k= 0.018745 lr = 0.0000028\n",
      "[21/25][5260/9765] Loss_D: 0.0965 Loss_G: 0.0384 Convergence: 0.0978 k= 0.018746 lr = 0.0000028\n",
      "[21/25][5270/9765] Loss_D: 0.0917 Loss_G: 0.0381 Convergence: 0.0936 k= 0.018755 lr = 0.0000028\n",
      "[21/25][5280/9765] Loss_D: 0.0914 Loss_G: 0.0383 Convergence: 0.0936 k= 0.018738 lr = 0.0000028\n",
      "[21/25][5290/9765] Loss_D: 0.1040 Loss_G: 0.0382 Convergence: 0.1084 k= 0.018736 lr = 0.0000028\n",
      "[21/25][5300/9765] Loss_D: 0.1024 Loss_G: 0.0393 Convergence: 0.1052 k= 0.018743 lr = 0.0000028\n",
      "[21/25][5310/9765] Loss_D: 0.0908 Loss_G: 0.0391 Convergence: 0.0941 k= 0.018744 lr = 0.0000028\n",
      "[21/25][5320/9765] Loss_D: 0.1035 Loss_G: 0.0398 Convergence: 0.1062 k= 0.018749 lr = 0.0000028\n",
      "[21/25][5330/9765] Loss_D: 0.0918 Loss_G: 0.0400 Convergence: 0.0955 k= 0.018734 lr = 0.0000028\n",
      "[21/25][5340/9765] Loss_D: 0.0910 Loss_G: 0.0399 Convergence: 0.0950 k= 0.018724 lr = 0.0000028\n",
      "[21/25][5350/9765] Loss_D: 0.0929 Loss_G: 0.0390 Convergence: 0.0952 k= 0.018710 lr = 0.0000028\n",
      "[21/25][5360/9765] Loss_D: 0.0950 Loss_G: 0.0396 Convergence: 0.0970 k= 0.018697 lr = 0.0000028\n",
      "[21/25][5370/9765] Loss_D: 0.1033 Loss_G: 0.0401 Convergence: 0.1057 k= 0.018675 lr = 0.0000028\n",
      "[21/25][5380/9765] Loss_D: 0.0983 Loss_G: 0.0410 Convergence: 0.1005 k= 0.018660 lr = 0.0000028\n",
      "[21/25][5390/9765] Loss_D: 0.0868 Loss_G: 0.0408 Convergence: 0.0933 k= 0.018651 lr = 0.0000028\n",
      "[21/25][5400/9765] Loss_D: 0.0872 Loss_G: 0.0407 Convergence: 0.0935 k= 0.018631 lr = 0.0000028\n",
      "[21/25][5410/9765] Loss_D: 0.0938 Loss_G: 0.0384 Convergence: 0.0951 k= 0.018624 lr = 0.0000028\n",
      "[21/25][5420/9765] Loss_D: 0.1032 Loss_G: 0.0399 Convergence: 0.1057 k= 0.018634 lr = 0.0000028\n",
      "[21/25][5430/9765] Loss_D: 0.0937 Loss_G: 0.0397 Convergence: 0.0964 k= 0.018630 lr = 0.0000028\n",
      "[21/25][5440/9765] Loss_D: 0.1010 Loss_G: 0.0397 Convergence: 0.1027 k= 0.018625 lr = 0.0000028\n",
      "[21/25][5450/9765] Loss_D: 0.0901 Loss_G: 0.0381 Convergence: 0.0925 k= 0.018617 lr = 0.0000028\n",
      "[21/25][5460/9765] Loss_D: 0.0906 Loss_G: 0.0383 Convergence: 0.0931 k= 0.018616 lr = 0.0000028\n",
      "[21/25][5470/9765] Loss_D: 0.0990 Loss_G: 0.0373 Convergence: 0.1023 k= 0.018612 lr = 0.0000028\n",
      "[21/25][5480/9765] Loss_D: 0.0896 Loss_G: 0.0369 Convergence: 0.0910 k= 0.018625 lr = 0.0000028\n",
      "[21/25][5490/9765] Loss_D: 0.0925 Loss_G: 0.0375 Convergence: 0.0934 k= 0.018623 lr = 0.0000028\n",
      "[21/25][5500/9765] Loss_D: 0.1005 Loss_G: 0.0381 Convergence: 0.1036 k= 0.018629 lr = 0.0000028\n",
      "[21/25][5510/9765] Loss_D: 0.1026 Loss_G: 0.0376 Convergence: 0.1070 k= 0.018632 lr = 0.0000028\n",
      "[21/25][5520/9765] Loss_D: 0.0948 Loss_G: 0.0371 Convergence: 0.0966 k= 0.018651 lr = 0.0000028\n",
      "[21/25][5530/9765] Loss_D: 0.0985 Loss_G: 0.0358 Convergence: 0.1030 k= 0.018663 lr = 0.0000028\n",
      "[21/25][5540/9765] Loss_D: 0.1040 Loss_G: 0.0376 Convergence: 0.1089 k= 0.018680 lr = 0.0000028\n",
      "[21/25][5550/9765] Loss_D: 0.0938 Loss_G: 0.0373 Convergence: 0.0950 k= 0.018690 lr = 0.0000028\n",
      "[21/25][5560/9765] Loss_D: 0.1013 Loss_G: 0.0382 Convergence: 0.1046 k= 0.018690 lr = 0.0000028\n",
      "[21/25][5570/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0969 k= 0.018685 lr = 0.0000028\n",
      "[21/25][5580/9765] Loss_D: 0.0902 Loss_G: 0.0380 Convergence: 0.0925 k= 0.018672 lr = 0.0000028\n",
      "[21/25][5590/9765] Loss_D: 0.0829 Loss_G: 0.0380 Convergence: 0.0882 k= 0.018679 lr = 0.0000028\n",
      "[21/25][5600/9765] Loss_D: 0.0894 Loss_G: 0.0389 Convergence: 0.0930 k= 0.018691 lr = 0.0000028\n",
      "[21/25][5610/9765] Loss_D: 0.0920 Loss_G: 0.0389 Convergence: 0.0945 k= 0.018692 lr = 0.0000028\n",
      "[21/25][5620/9765] Loss_D: 0.1013 Loss_G: 0.0384 Convergence: 0.1044 k= 0.018699 lr = 0.0000028\n",
      "[21/25][5630/9765] Loss_D: 0.0914 Loss_G: 0.0397 Convergence: 0.0950 k= 0.018696 lr = 0.0000028\n",
      "[21/25][5640/9765] Loss_D: 0.0896 Loss_G: 0.0378 Convergence: 0.0920 k= 0.018691 lr = 0.0000028\n",
      "[21/25][5650/9765] Loss_D: 0.0923 Loss_G: 0.0385 Convergence: 0.0943 k= 0.018676 lr = 0.0000028\n",
      "[21/25][5660/9765] Loss_D: 0.0945 Loss_G: 0.0386 Convergence: 0.0957 k= 0.018691 lr = 0.0000028\n",
      "[21/25][5670/9765] Loss_D: 0.0935 Loss_G: 0.0411 Convergence: 0.0976 k= 0.018679 lr = 0.0000028\n",
      "[21/25][5680/9765] Loss_D: 0.1005 Loss_G: 0.0400 Convergence: 0.1017 k= 0.018676 lr = 0.0000028\n",
      "[21/25][5690/9765] Loss_D: 0.0964 Loss_G: 0.0394 Convergence: 0.0977 k= 0.018662 lr = 0.0000028\n",
      "[21/25][5700/9765] Loss_D: 0.0961 Loss_G: 0.0403 Convergence: 0.0984 k= 0.018651 lr = 0.0000028\n",
      "[21/25][5710/9765] Loss_D: 0.0900 Loss_G: 0.0402 Convergence: 0.0947 k= 0.018628 lr = 0.0000028\n",
      "[21/25][5720/9765] Loss_D: 0.0998 Loss_G: 0.0396 Convergence: 0.1011 k= 0.018633 lr = 0.0000028\n",
      "[21/25][5730/9765] Loss_D: 0.0943 Loss_G: 0.0394 Convergence: 0.0965 k= 0.018621 lr = 0.0000028\n",
      "[21/25][5740/9765] Loss_D: 0.0909 Loss_G: 0.0389 Convergence: 0.0939 k= 0.018616 lr = 0.0000028\n",
      "[21/25][5750/9765] Loss_D: 0.1017 Loss_G: 0.0393 Convergence: 0.1040 k= 0.018616 lr = 0.0000028\n",
      "[21/25][5760/9765] Loss_D: 0.0946 Loss_G: 0.0380 Convergence: 0.0954 k= 0.018614 lr = 0.0000028\n",
      "[21/25][5770/9765] Loss_D: 0.0962 Loss_G: 0.0379 Convergence: 0.0978 k= 0.018617 lr = 0.0000028\n",
      "[21/25][5780/9765] Loss_D: 0.1023 Loss_G: 0.0374 Convergence: 0.1067 k= 0.018621 lr = 0.0000028\n",
      "[21/25][5790/9765] Loss_D: 0.1002 Loss_G: 0.0381 Convergence: 0.1032 k= 0.018647 lr = 0.0000028\n",
      "[21/25][5800/9765] Loss_D: 0.1001 Loss_G: 0.0403 Convergence: 0.1008 k= 0.018658 lr = 0.0000028\n",
      "[21/25][5810/9765] Loss_D: 0.0955 Loss_G: 0.0394 Convergence: 0.0972 k= 0.018650 lr = 0.0000028\n",
      "[21/25][5820/9765] Loss_D: 0.0967 Loss_G: 0.0381 Convergence: 0.0982 k= 0.018644 lr = 0.0000028\n",
      "[21/25][5830/9765] Loss_D: 0.0961 Loss_G: 0.0400 Convergence: 0.0981 k= 0.018638 lr = 0.0000028\n",
      "[21/25][5840/9765] Loss_D: 0.0949 Loss_G: 0.0387 Convergence: 0.0961 k= 0.018625 lr = 0.0000028\n",
      "[21/25][5850/9765] Loss_D: 0.0864 Loss_G: 0.0406 Convergence: 0.0928 k= 0.018612 lr = 0.0000028\n",
      "[21/25][5860/9765] Loss_D: 0.0917 Loss_G: 0.0408 Convergence: 0.0962 k= 0.018590 lr = 0.0000028\n",
      "[21/25][5870/9765] Loss_D: 0.0860 Loss_G: 0.0405 Convergence: 0.0926 k= 0.018567 lr = 0.0000028\n",
      "[21/25][5880/9765] Loss_D: 0.0975 Loss_G: 0.0383 Convergence: 0.0993 k= 0.018551 lr = 0.0000028\n",
      "[21/25][5890/9765] Loss_D: 0.0927 Loss_G: 0.0396 Convergence: 0.0957 k= 0.018557 lr = 0.0000028\n",
      "[21/25][5900/9765] Loss_D: 0.1019 Loss_G: 0.0393 Convergence: 0.1044 k= 0.018550 lr = 0.0000028\n",
      "[21/25][5910/9765] Loss_D: 0.1101 Loss_G: 0.0376 Convergence: 0.1176 k= 0.018554 lr = 0.0000028\n",
      "[21/25][5920/9765] Loss_D: 0.0934 Loss_G: 0.0388 Convergence: 0.0953 k= 0.018550 lr = 0.0000028\n",
      "[21/25][5930/9765] Loss_D: 0.0943 Loss_G: 0.0389 Convergence: 0.0959 k= 0.018550 lr = 0.0000028\n",
      "[21/25][5940/9765] Loss_D: 0.1072 Loss_G: 0.0399 Convergence: 0.1112 k= 0.018563 lr = 0.0000028\n",
      "[21/25][5950/9765] Loss_D: 0.1013 Loss_G: 0.0377 Convergence: 0.1052 k= 0.018572 lr = 0.0000028\n",
      "[21/25][5960/9765] Loss_D: 0.1024 Loss_G: 0.0370 Convergence: 0.1074 k= 0.018581 lr = 0.0000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][5970/9765] Loss_D: 0.1029 Loss_G: 0.0378 Convergence: 0.1073 k= 0.018588 lr = 0.0000028\n",
      "[21/25][5980/9765] Loss_D: 0.0928 Loss_G: 0.0377 Convergence: 0.0938 k= 0.018593 lr = 0.0000028\n",
      "[21/25][5990/9765] Loss_D: 0.0969 Loss_G: 0.0383 Convergence: 0.0984 k= 0.018609 lr = 0.0000028\n",
      "[21/25][6000/9765] Loss_D: 0.1009 Loss_G: 0.0385 Convergence: 0.1037 k= 0.018618 lr = 0.0000028\n",
      "[21/25][6010/9765] Loss_D: 0.0858 Loss_G: 0.0380 Convergence: 0.0900 k= 0.018606 lr = 0.0000028\n",
      "[21/25][6020/9765] Loss_D: 0.0921 Loss_G: 0.0383 Convergence: 0.0940 k= 0.018622 lr = 0.0000028\n",
      "[21/25][6030/9765] Loss_D: 0.0935 Loss_G: 0.0384 Convergence: 0.0949 k= 0.018615 lr = 0.0000028\n",
      "[21/25][6040/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0958 k= 0.018615 lr = 0.0000028\n",
      "[21/25][6050/9765] Loss_D: 0.0896 Loss_G: 0.0393 Convergence: 0.0935 k= 0.018604 lr = 0.0000028\n",
      "[21/25][6060/9765] Loss_D: 0.1066 Loss_G: 0.0380 Convergence: 0.1122 k= 0.018604 lr = 0.0000028\n",
      "[21/25][6070/9765] Loss_D: 0.0944 Loss_G: 0.0395 Convergence: 0.0965 k= 0.018601 lr = 0.0000028\n",
      "[21/25][6080/9765] Loss_D: 0.0949 Loss_G: 0.0388 Convergence: 0.0962 k= 0.018590 lr = 0.0000028\n",
      "[21/25][6090/9765] Loss_D: 0.0906 Loss_G: 0.0392 Convergence: 0.0940 k= 0.018590 lr = 0.0000028\n",
      "[21/25][6100/9765] Loss_D: 0.0963 Loss_G: 0.0379 Convergence: 0.0980 k= 0.018593 lr = 0.0000028\n",
      "[21/25][6110/9765] Loss_D: 0.0988 Loss_G: 0.0390 Convergence: 0.1002 k= 0.018605 lr = 0.0000028\n",
      "[21/25][6120/9765] Loss_D: 0.0991 Loss_G: 0.0402 Convergence: 0.1002 k= 0.018597 lr = 0.0000028\n",
      "[21/25][6130/9765] Loss_D: 0.0971 Loss_G: 0.0401 Convergence: 0.0988 k= 0.018600 lr = 0.0000028\n",
      "[21/25][6140/9765] Loss_D: 0.0926 Loss_G: 0.0395 Convergence: 0.0955 k= 0.018594 lr = 0.0000028\n",
      "[21/25][6150/9765] Loss_D: 0.0959 Loss_G: 0.0390 Convergence: 0.0970 k= 0.018593 lr = 0.0000028\n",
      "[21/25][6160/9765] Loss_D: 0.0924 Loss_G: 0.0386 Convergence: 0.0945 k= 0.018583 lr = 0.0000028\n",
      "[21/25][6170/9765] Loss_D: 0.0987 Loss_G: 0.0376 Convergence: 0.1015 k= 0.018589 lr = 0.0000028\n",
      "[21/25][6180/9765] Loss_D: 0.1001 Loss_G: 0.0378 Convergence: 0.1032 k= 0.018596 lr = 0.0000028\n",
      "[21/25][6190/9765] Loss_D: 0.0897 Loss_G: 0.0374 Convergence: 0.0917 k= 0.018609 lr = 0.0000028\n",
      "[21/25][6200/9765] Loss_D: 0.0954 Loss_G: 0.0381 Convergence: 0.0964 k= 0.018622 lr = 0.0000028\n",
      "[21/25][6210/9765] Loss_D: 0.1004 Loss_G: 0.0383 Convergence: 0.1033 k= 0.018626 lr = 0.0000028\n",
      "[21/25][6220/9765] Loss_D: 0.0874 Loss_G: 0.0384 Convergence: 0.0912 k= 0.018634 lr = 0.0000028\n",
      "[21/25][6230/9765] Loss_D: 0.0910 Loss_G: 0.0368 Convergence: 0.0919 k= 0.018646 lr = 0.0000028\n",
      "[21/25][6240/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0967 k= 0.018649 lr = 0.0000028\n",
      "[21/25][6250/9765] Loss_D: 0.0872 Loss_G: 0.0388 Convergence: 0.0916 k= 0.018645 lr = 0.0000028\n",
      "[21/25][6260/9765] Loss_D: 0.1117 Loss_G: 0.0384 Convergence: 0.1189 k= 0.018659 lr = 0.0000028\n",
      "[21/25][6270/9765] Loss_D: 0.1026 Loss_G: 0.0391 Convergence: 0.1056 k= 0.018662 lr = 0.0000028\n",
      "[21/25][6280/9765] Loss_D: 0.1009 Loss_G: 0.0390 Convergence: 0.1032 k= 0.018683 lr = 0.0000028\n",
      "[21/25][6290/9765] Loss_D: 0.0999 Loss_G: 0.0395 Convergence: 0.1014 k= 0.018687 lr = 0.0000028\n",
      "[21/25][6300/9765] Loss_D: 0.1014 Loss_G: 0.0389 Convergence: 0.1041 k= 0.018697 lr = 0.0000028\n",
      "[21/25][6310/9765] Loss_D: 0.0981 Loss_G: 0.0388 Convergence: 0.0995 k= 0.018701 lr = 0.0000028\n",
      "[21/25][6320/9765] Loss_D: 0.0966 Loss_G: 0.0390 Convergence: 0.0974 k= 0.018695 lr = 0.0000028\n",
      "[21/25][6330/9765] Loss_D: 0.0906 Loss_G: 0.0382 Convergence: 0.0930 k= 0.018693 lr = 0.0000028\n",
      "[21/25][6340/9765] Loss_D: 0.0988 Loss_G: 0.0403 Convergence: 0.1000 k= 0.018683 lr = 0.0000028\n",
      "[21/25][6350/9765] Loss_D: 0.0904 Loss_G: 0.0398 Convergence: 0.0945 k= 0.018681 lr = 0.0000028\n",
      "[21/25][6360/9765] Loss_D: 0.0940 Loss_G: 0.0382 Convergence: 0.0950 k= 0.018680 lr = 0.0000028\n",
      "[21/25][6370/9765] Loss_D: 0.0912 Loss_G: 0.0381 Convergence: 0.0932 k= 0.018667 lr = 0.0000028\n",
      "[21/25][6380/9765] Loss_D: 0.0922 Loss_G: 0.0376 Convergence: 0.0934 k= 0.018671 lr = 0.0000028\n",
      "[21/25][6390/9765] Loss_D: 0.0918 Loss_G: 0.0379 Convergence: 0.0934 k= 0.018673 lr = 0.0000028\n",
      "[21/25][6400/9765] Loss_D: 0.0976 Loss_G: 0.0394 Convergence: 0.0984 k= 0.018672 lr = 0.0000028\n",
      "[21/25][6410/9765] Loss_D: 0.0974 Loss_G: 0.0383 Convergence: 0.0990 k= 0.018666 lr = 0.0000028\n",
      "[21/25][6420/9765] Loss_D: 0.1014 Loss_G: 0.0389 Convergence: 0.1041 k= 0.018662 lr = 0.0000028\n",
      "[21/25][6430/9765] Loss_D: 0.1028 Loss_G: 0.0387 Convergence: 0.1063 k= 0.018667 lr = 0.0000028\n",
      "[21/25][6440/9765] Loss_D: 0.1005 Loss_G: 0.0390 Convergence: 0.1027 k= 0.018671 lr = 0.0000028\n",
      "[21/25][6450/9765] Loss_D: 0.0990 Loss_G: 0.0381 Convergence: 0.1015 k= 0.018667 lr = 0.0000028\n",
      "[21/25][6460/9765] Loss_D: 0.0981 Loss_G: 0.0382 Convergence: 0.1001 k= 0.018683 lr = 0.0000028\n",
      "[21/25][6470/9765] Loss_D: 0.0909 Loss_G: 0.0390 Convergence: 0.0940 k= 0.018678 lr = 0.0000028\n",
      "[21/25][6480/9765] Loss_D: 0.0919 Loss_G: 0.0386 Convergence: 0.0942 k= 0.018669 lr = 0.0000028\n",
      "[21/25][6490/9765] Loss_D: 0.0981 Loss_G: 0.0390 Convergence: 0.0994 k= 0.018669 lr = 0.0000028\n",
      "[21/25][6500/9765] Loss_D: 0.1059 Loss_G: 0.0374 Convergence: 0.1118 k= 0.018670 lr = 0.0000028\n",
      "[21/25][6510/9765] Loss_D: 0.1069 Loss_G: 0.0385 Convergence: 0.1121 k= 0.018686 lr = 0.0000028\n",
      "[21/25][6520/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0966 k= 0.018698 lr = 0.0000028\n",
      "[21/25][6530/9765] Loss_D: 0.0935 Loss_G: 0.0391 Convergence: 0.0956 k= 0.018699 lr = 0.0000028\n",
      "[21/25][6540/9765] Loss_D: 0.0913 Loss_G: 0.0393 Convergence: 0.0946 k= 0.018707 lr = 0.0000028\n",
      "[21/25][6550/9765] Loss_D: 0.1066 Loss_G: 0.0396 Convergence: 0.1107 k= 0.018704 lr = 0.0000028\n",
      "[21/25][6560/9765] Loss_D: 0.0897 Loss_G: 0.0388 Convergence: 0.0931 k= 0.018704 lr = 0.0000028\n",
      "[21/25][6570/9765] Loss_D: 0.1051 Loss_G: 0.0390 Convergence: 0.1091 k= 0.018708 lr = 0.0000028\n",
      "[21/25][6580/9765] Loss_D: 0.0962 Loss_G: 0.0399 Convergence: 0.0981 k= 0.018708 lr = 0.0000028\n",
      "[21/25][6590/9765] Loss_D: 0.0871 Loss_G: 0.0392 Convergence: 0.0919 k= 0.018709 lr = 0.0000028\n",
      "[21/25][6600/9765] Loss_D: 0.0976 Loss_G: 0.0402 Convergence: 0.0992 k= 0.018699 lr = 0.0000028\n",
      "[21/25][6610/9765] Loss_D: 0.0957 Loss_G: 0.0397 Convergence: 0.0975 k= 0.018704 lr = 0.0000028\n",
      "[21/25][6620/9765] Loss_D: 0.0951 Loss_G: 0.0382 Convergence: 0.0960 k= 0.018704 lr = 0.0000028\n",
      "[21/25][6630/9765] Loss_D: 0.0941 Loss_G: 0.0385 Convergence: 0.0954 k= 0.018696 lr = 0.0000028\n",
      "[21/25][6640/9765] Loss_D: 0.0835 Loss_G: 0.0380 Convergence: 0.0885 k= 0.018692 lr = 0.0000028\n",
      "[21/25][6650/9765] Loss_D: 0.0972 Loss_G: 0.0366 Convergence: 0.1005 k= 0.018702 lr = 0.0000028\n",
      "[21/25][6660/9765] Loss_D: 0.0882 Loss_G: 0.0379 Convergence: 0.0912 k= 0.018714 lr = 0.0000028\n",
      "[21/25][6670/9765] Loss_D: 0.0970 Loss_G: 0.0396 Convergence: 0.0982 k= 0.018721 lr = 0.0000028\n",
      "[21/25][6680/9765] Loss_D: 0.1045 Loss_G: 0.0396 Convergence: 0.1078 k= 0.018722 lr = 0.0000028\n",
      "[21/25][6690/9765] Loss_D: 0.0995 Loss_G: 0.0371 Convergence: 0.1032 k= 0.018734 lr = 0.0000028\n",
      "[21/25][6700/9765] Loss_D: 0.1081 Loss_G: 0.0380 Convergence: 0.1144 k= 0.018764 lr = 0.0000028\n",
      "[21/25][6710/9765] Loss_D: 0.1019 Loss_G: 0.0379 Convergence: 0.1058 k= 0.018773 lr = 0.0000028\n",
      "[21/25][6720/9765] Loss_D: 0.0993 Loss_G: 0.0368 Convergence: 0.1032 k= 0.018784 lr = 0.0000028\n",
      "[21/25][6730/9765] Loss_D: 0.0961 Loss_G: 0.0391 Convergence: 0.0972 k= 0.018800 lr = 0.0000028\n",
      "[21/25][6740/9765] Loss_D: 0.0981 Loss_G: 0.0381 Convergence: 0.1002 k= 0.018806 lr = 0.0000028\n",
      "[21/25][6750/9765] Loss_D: 0.0970 Loss_G: 0.0388 Convergence: 0.0980 k= 0.018802 lr = 0.0000028\n",
      "[21/25][6760/9765] Loss_D: 0.1048 Loss_G: 0.0381 Convergence: 0.1097 k= 0.018826 lr = 0.0000028\n",
      "[21/25][6770/9765] Loss_D: 0.0922 Loss_G: 0.0383 Convergence: 0.0941 k= 0.018842 lr = 0.0000028\n",
      "[21/25][6780/9765] Loss_D: 0.1017 Loss_G: 0.0383 Convergence: 0.1051 k= 0.018842 lr = 0.0000028\n",
      "[21/25][6790/9765] Loss_D: 0.0998 Loss_G: 0.0407 Convergence: 0.1011 k= 0.018842 lr = 0.0000028\n",
      "[21/25][6800/9765] Loss_D: 0.0870 Loss_G: 0.0393 Convergence: 0.0919 k= 0.018850 lr = 0.0000028\n",
      "[21/25][6810/9765] Loss_D: 0.0980 Loss_G: 0.0396 Convergence: 0.0988 k= 0.018850 lr = 0.0000028\n",
      "[21/25][6820/9765] Loss_D: 0.0892 Loss_G: 0.0393 Convergence: 0.0933 k= 0.018841 lr = 0.0000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][6830/9765] Loss_D: 0.1020 Loss_G: 0.0375 Convergence: 0.1062 k= 0.018843 lr = 0.0000028\n",
      "[21/25][6840/9765] Loss_D: 0.0980 Loss_G: 0.0402 Convergence: 0.0994 k= 0.018838 lr = 0.0000028\n",
      "[21/25][6850/9765] Loss_D: 0.1011 Loss_G: 0.0403 Convergence: 0.1022 k= 0.018826 lr = 0.0000028\n",
      "[21/25][6860/9765] Loss_D: 0.1081 Loss_G: 0.0402 Convergence: 0.1122 k= 0.018819 lr = 0.0000028\n",
      "[21/25][6870/9765] Loss_D: 0.0977 Loss_G: 0.0400 Convergence: 0.0991 k= 0.018806 lr = 0.0000028\n",
      "[21/25][6880/9765] Loss_D: 0.1004 Loss_G: 0.0399 Convergence: 0.1017 k= 0.018791 lr = 0.0000028\n",
      "[21/25][6890/9765] Loss_D: 0.1002 Loss_G: 0.0396 Convergence: 0.1017 k= 0.018785 lr = 0.0000028\n",
      "[21/25][6900/9765] Loss_D: 0.1037 Loss_G: 0.0372 Convergence: 0.1089 k= 0.018795 lr = 0.0000028\n",
      "[21/25][6910/9765] Loss_D: 0.0895 Loss_G: 0.0370 Convergence: 0.0911 k= 0.018804 lr = 0.0000028\n",
      "[21/25][6920/9765] Loss_D: 0.0928 Loss_G: 0.0381 Convergence: 0.0942 k= 0.018814 lr = 0.0000028\n",
      "[21/25][6930/9765] Loss_D: 0.0979 Loss_G: 0.0397 Convergence: 0.0988 k= 0.018818 lr = 0.0000028\n",
      "[21/25][6940/9765] Loss_D: 0.0936 Loss_G: 0.0397 Convergence: 0.0963 k= 0.018807 lr = 0.0000028\n",
      "[21/25][6950/9765] Loss_D: 0.0879 Loss_G: 0.0383 Convergence: 0.0914 k= 0.018793 lr = 0.0000028\n",
      "[21/25][6960/9765] Loss_D: 0.1002 Loss_G: 0.0388 Convergence: 0.1024 k= 0.018792 lr = 0.0000028\n",
      "[21/25][6970/9765] Loss_D: 0.0988 Loss_G: 0.0388 Convergence: 0.1004 k= 0.018784 lr = 0.0000028\n",
      "[21/25][6980/9765] Loss_D: 0.1022 Loss_G: 0.0392 Convergence: 0.1049 k= 0.018777 lr = 0.0000028\n",
      "[21/25][6990/9765] Loss_D: 0.0969 Loss_G: 0.0391 Convergence: 0.0977 k= 0.018777 lr = 0.0000028\n",
      "[21/25][7000/9765] Loss_D: 0.0963 Loss_G: 0.0393 Convergence: 0.0975 k= 0.018765 lr = 0.0000028\n",
      "[21/25][7010/9765] Loss_D: 0.1025 Loss_G: 0.0394 Convergence: 0.1051 k= 0.018750 lr = 0.0000028\n",
      "[21/25][7020/9765] Loss_D: 0.1008 Loss_G: 0.0388 Convergence: 0.1033 k= 0.018746 lr = 0.0000028\n",
      "[21/25][7030/9765] Loss_D: 0.0956 Loss_G: 0.0389 Convergence: 0.0967 k= 0.018751 lr = 0.0000028\n",
      "[21/25][7040/9765] Loss_D: 0.0886 Loss_G: 0.0378 Convergence: 0.0914 k= 0.018752 lr = 0.0000028\n",
      "[21/25][7050/9765] Loss_D: 0.0980 Loss_G: 0.0390 Convergence: 0.0992 k= 0.018753 lr = 0.0000028\n",
      "[21/25][7060/9765] Loss_D: 0.0971 Loss_G: 0.0375 Convergence: 0.0994 k= 0.018754 lr = 0.0000028\n",
      "[21/25][7070/9765] Loss_D: 0.0957 Loss_G: 0.0388 Convergence: 0.0966 k= 0.018764 lr = 0.0000028\n",
      "[21/25][7080/9765] Loss_D: 0.0899 Loss_G: 0.0374 Convergence: 0.0917 k= 0.018770 lr = 0.0000028\n",
      "[21/25][7090/9765] Loss_D: 0.0856 Loss_G: 0.0368 Convergence: 0.0885 k= 0.018777 lr = 0.0000028\n",
      "[21/25][7100/9765] Loss_D: 0.0973 Loss_G: 0.0372 Convergence: 0.1001 k= 0.018789 lr = 0.0000028\n",
      "[21/25][7110/9765] Loss_D: 0.0960 Loss_G: 0.0380 Convergence: 0.0974 k= 0.018801 lr = 0.0000028\n",
      "[21/25][7120/9765] Loss_D: 0.0967 Loss_G: 0.0394 Convergence: 0.0979 k= 0.018818 lr = 0.0000028\n",
      "[21/25][7130/9765] Loss_D: 0.0930 Loss_G: 0.0388 Convergence: 0.0951 k= 0.018811 lr = 0.0000028\n",
      "[21/25][7140/9765] Loss_D: 0.0939 Loss_G: 0.0395 Convergence: 0.0963 k= 0.018797 lr = 0.0000028\n",
      "[21/25][7150/9765] Loss_D: 0.0998 Loss_G: 0.0399 Convergence: 0.1009 k= 0.018801 lr = 0.0000028\n",
      "[21/25][7160/9765] Loss_D: 0.0922 Loss_G: 0.0402 Convergence: 0.0960 k= 0.018786 lr = 0.0000028\n",
      "[21/25][7170/9765] Loss_D: 0.0945 Loss_G: 0.0381 Convergence: 0.0952 k= 0.018780 lr = 0.0000028\n",
      "[21/25][7180/9765] Loss_D: 0.0914 Loss_G: 0.0391 Convergence: 0.0944 k= 0.018786 lr = 0.0000028\n",
      "[21/25][7190/9765] Loss_D: 0.0931 Loss_G: 0.0397 Convergence: 0.0960 k= 0.018785 lr = 0.0000028\n",
      "[21/25][7200/9765] Loss_D: 0.0996 Loss_G: 0.0400 Convergence: 0.1005 k= 0.018767 lr = 0.0000028\n",
      "[21/25][7210/9765] Loss_D: 0.0944 Loss_G: 0.0399 Convergence: 0.0970 k= 0.018747 lr = 0.0000028\n",
      "[21/25][7220/9765] Loss_D: 0.1003 Loss_G: 0.0442 Convergence: 0.1049 k= 0.018718 lr = 0.0000028\n",
      "[21/25][7230/9765] Loss_D: 0.1008 Loss_G: 0.0409 Convergence: 0.1018 k= 0.018691 lr = 0.0000028\n",
      "[21/25][7240/9765] Loss_D: 0.0981 Loss_G: 0.0406 Convergence: 0.0999 k= 0.018671 lr = 0.0000028\n",
      "[21/25][7250/9765] Loss_D: 0.0964 Loss_G: 0.0412 Convergence: 0.0995 k= 0.018656 lr = 0.0000028\n",
      "[21/25][7260/9765] Loss_D: 0.0976 Loss_G: 0.0413 Convergence: 0.1003 k= 0.018639 lr = 0.0000028\n",
      "[21/25][7270/9765] Loss_D: 0.1009 Loss_G: 0.0395 Convergence: 0.1028 k= 0.018626 lr = 0.0000028\n",
      "[21/25][7280/9765] Loss_D: 0.0882 Loss_G: 0.0396 Convergence: 0.0929 k= 0.018611 lr = 0.0000028\n",
      "[21/25][7290/9765] Loss_D: 0.1007 Loss_G: 0.0389 Convergence: 0.1031 k= 0.018608 lr = 0.0000028\n",
      "[21/25][7300/9765] Loss_D: 0.0934 Loss_G: 0.0390 Convergence: 0.0955 k= 0.018600 lr = 0.0000028\n",
      "[21/25][7310/9765] Loss_D: 0.0935 Loss_G: 0.0389 Convergence: 0.0954 k= 0.018600 lr = 0.0000028\n",
      "[21/25][7320/9765] Loss_D: 0.0874 Loss_G: 0.0379 Convergence: 0.0908 k= 0.018596 lr = 0.0000028\n",
      "[21/25][7330/9765] Loss_D: 0.1047 Loss_G: 0.0375 Convergence: 0.1100 k= 0.018596 lr = 0.0000028\n",
      "[21/25][7340/9765] Loss_D: 0.0960 Loss_G: 0.0366 Convergence: 0.0988 k= 0.018598 lr = 0.0000028\n",
      "[21/25][7350/9765] Loss_D: 0.0861 Loss_G: 0.0369 Convergence: 0.0890 k= 0.018613 lr = 0.0000028\n",
      "[21/25][7360/9765] Loss_D: 0.0931 Loss_G: 0.0370 Convergence: 0.0943 k= 0.018614 lr = 0.0000028\n",
      "[21/25][7370/9765] Loss_D: 0.0970 Loss_G: 0.0364 Convergence: 0.1003 k= 0.018632 lr = 0.0000028\n",
      "[21/25][7380/9765] Loss_D: 0.0974 Loss_G: 0.0364 Convergence: 0.1010 k= 0.018655 lr = 0.0000028\n",
      "[21/25][7390/9765] Loss_D: 0.0918 Loss_G: 0.0369 Convergence: 0.0926 k= 0.018657 lr = 0.0000028\n",
      "[21/25][7400/9765] Loss_D: 0.0918 Loss_G: 0.0371 Convergence: 0.0927 k= 0.018664 lr = 0.0000028\n",
      "[21/25][7410/9765] Loss_D: 0.1017 Loss_G: 0.0388 Convergence: 0.1045 k= 0.018684 lr = 0.0000028\n",
      "[21/25][7420/9765] Loss_D: 0.0955 Loss_G: 0.0386 Convergence: 0.0963 k= 0.018689 lr = 0.0000028\n",
      "[21/25][7430/9765] Loss_D: 0.0998 Loss_G: 0.0394 Convergence: 0.1013 k= 0.018699 lr = 0.0000028\n",
      "[21/25][7440/9765] Loss_D: 0.1011 Loss_G: 0.0387 Convergence: 0.1039 k= 0.018692 lr = 0.0000028\n",
      "[21/25][7450/9765] Loss_D: 0.0996 Loss_G: 0.0403 Convergence: 0.1005 k= 0.018684 lr = 0.0000028\n",
      "[21/25][7460/9765] Loss_D: 0.0945 Loss_G: 0.0385 Convergence: 0.0956 k= 0.018668 lr = 0.0000028\n",
      "[21/25][7470/9765] Loss_D: 0.0930 Loss_G: 0.0382 Convergence: 0.0944 k= 0.018658 lr = 0.0000028\n",
      "[21/25][7480/9765] Loss_D: 0.0959 Loss_G: 0.0394 Convergence: 0.0974 k= 0.018653 lr = 0.0000028\n",
      "[21/25][7490/9765] Loss_D: 0.1057 Loss_G: 0.0389 Convergence: 0.1102 k= 0.018635 lr = 0.0000028\n",
      "[21/25][7500/9765] Loss_D: 0.0899 Loss_G: 0.0401 Convergence: 0.0945 k= 0.018623 lr = 0.0000028\n",
      "[21/25][7510/9765] Loss_D: 0.0882 Loss_G: 0.0386 Convergence: 0.0919 k= 0.018617 lr = 0.0000028\n",
      "[21/25][7520/9765] Loss_D: 0.1099 Loss_G: 0.0393 Convergence: 0.1157 k= 0.018625 lr = 0.0000028\n",
      "[21/25][7530/9765] Loss_D: 0.0985 Loss_G: 0.0396 Convergence: 0.0993 k= 0.018626 lr = 0.0000028\n",
      "[21/25][7540/9765] Loss_D: 0.0967 Loss_G: 0.0382 Convergence: 0.0982 k= 0.018627 lr = 0.0000028\n",
      "[21/25][7550/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0950 k= 0.018634 lr = 0.0000028\n",
      "[21/25][7560/9765] Loss_D: 0.0901 Loss_G: 0.0403 Convergence: 0.0949 k= 0.018633 lr = 0.0000028\n",
      "[21/25][7570/9765] Loss_D: 0.0919 Loss_G: 0.0390 Convergence: 0.0946 k= 0.018621 lr = 0.0000028\n",
      "[21/25][7580/9765] Loss_D: 0.0900 Loss_G: 0.0377 Convergence: 0.0921 k= 0.018614 lr = 0.0000028\n",
      "[21/25][7590/9765] Loss_D: 0.0863 Loss_G: 0.0394 Convergence: 0.0916 k= 0.018608 lr = 0.0000028\n",
      "[21/25][7600/9765] Loss_D: 0.0969 Loss_G: 0.0363 Convergence: 0.1004 k= 0.018611 lr = 0.0000028\n",
      "[21/25][7610/9765] Loss_D: 0.0996 Loss_G: 0.0367 Convergence: 0.1037 k= 0.018619 lr = 0.0000028\n",
      "[21/25][7620/9765] Loss_D: 0.0987 Loss_G: 0.0392 Convergence: 0.1001 k= 0.018639 lr = 0.0000028\n",
      "[21/25][7630/9765] Loss_D: 0.1004 Loss_G: 0.0381 Convergence: 0.1035 k= 0.018654 lr = 0.0000028\n",
      "[21/25][7640/9765] Loss_D: 0.0918 Loss_G: 0.0378 Convergence: 0.0933 k= 0.018656 lr = 0.0000028\n",
      "[21/25][7650/9765] Loss_D: 0.0898 Loss_G: 0.0372 Convergence: 0.0915 k= 0.018657 lr = 0.0000028\n",
      "[21/25][7660/9765] Loss_D: 0.0925 Loss_G: 0.0373 Convergence: 0.0932 k= 0.018671 lr = 0.0000028\n",
      "[21/25][7670/9765] Loss_D: 0.0913 Loss_G: 0.0382 Convergence: 0.0934 k= 0.018678 lr = 0.0000028\n",
      "[21/25][7680/9765] Loss_D: 0.0984 Loss_G: 0.0384 Convergence: 0.1003 k= 0.018687 lr = 0.0000028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][7690/9765] Loss_D: 0.0883 Loss_G: 0.0392 Convergence: 0.0926 k= 0.018684 lr = 0.0000028\n",
      "[21/25][7700/9765] Loss_D: 0.0992 Loss_G: 0.0394 Convergence: 0.1005 k= 0.018669 lr = 0.0000028\n",
      "[21/25][7710/9765] Loss_D: 0.0880 Loss_G: 0.0413 Convergence: 0.0946 k= 0.018657 lr = 0.0000028\n",
      "[21/25][7720/9765] Loss_D: 0.0941 Loss_G: 0.0409 Convergence: 0.0978 k= 0.018641 lr = 0.0000028\n",
      "[21/25][7730/9765] Loss_D: 0.0924 Loss_G: 0.0404 Convergence: 0.0963 k= 0.018630 lr = 0.0000028\n",
      "[21/25][7740/9765] Loss_D: 0.0902 Loss_G: 0.0382 Convergence: 0.0928 k= 0.018615 lr = 0.0000028\n",
      "[21/25][7750/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0988 k= 0.018622 lr = 0.0000028\n",
      "[21/25][7760/9765] Loss_D: 0.0965 Loss_G: 0.0380 Convergence: 0.0981 k= 0.018614 lr = 0.0000028\n",
      "[21/25][7770/9765] Loss_D: 0.0997 Loss_G: 0.0391 Convergence: 0.1015 k= 0.018622 lr = 0.0000028\n",
      "[21/25][7780/9765] Loss_D: 0.0926 Loss_G: 0.0389 Convergence: 0.0948 k= 0.018618 lr = 0.0000028\n",
      "[21/25][7790/9765] Loss_D: 0.0882 Loss_G: 0.0387 Convergence: 0.0921 k= 0.018608 lr = 0.0000028\n",
      "[21/25][7800/9765] Loss_D: 0.0971 Loss_G: 0.0389 Convergence: 0.0980 k= 0.018612 lr = 0.0000028\n",
      "[21/25][7810/9765] Loss_D: 0.1019 Loss_G: 0.0385 Convergence: 0.1052 k= 0.018619 lr = 0.0000028\n",
      "[21/25][7820/9765] Loss_D: 0.1081 Loss_G: 0.0387 Convergence: 0.1136 k= 0.018621 lr = 0.0000028\n",
      "[21/25][7830/9765] Loss_D: 0.0997 Loss_G: 0.0381 Convergence: 0.1024 k= 0.018618 lr = 0.0000028\n",
      "[21/25][7840/9765] Loss_D: 0.1024 Loss_G: 0.0380 Convergence: 0.1064 k= 0.018625 lr = 0.0000028\n",
      "[21/25][7850/9765] Loss_D: 0.1022 Loss_G: 0.0370 Convergence: 0.1070 k= 0.018648 lr = 0.0000028\n",
      "[21/25][7860/9765] Loss_D: 0.0962 Loss_G: 0.0364 Convergence: 0.0993 k= 0.018671 lr = 0.0000028\n",
      "[21/25][7870/9765] Loss_D: 0.0919 Loss_G: 0.0373 Convergence: 0.0928 k= 0.018694 lr = 0.0000028\n",
      "[21/25][7880/9765] Loss_D: 0.0966 Loss_G: 0.0388 Convergence: 0.0975 k= 0.018699 lr = 0.0000028\n",
      "[21/25][7890/9765] Loss_D: 0.0969 Loss_G: 0.0380 Convergence: 0.0987 k= 0.018709 lr = 0.0000028\n",
      "[21/25][7900/9765] Loss_D: 0.1063 Loss_G: 0.0394 Convergence: 0.1104 k= 0.018714 lr = 0.0000028\n",
      "[21/25][7910/9765] Loss_D: 0.0951 Loss_G: 0.0373 Convergence: 0.0968 k= 0.018718 lr = 0.0000028\n",
      "[21/25][7920/9765] Loss_D: 0.0910 Loss_G: 0.0383 Convergence: 0.0933 k= 0.018715 lr = 0.0000028\n",
      "[21/25][7930/9765] Loss_D: 0.0911 Loss_G: 0.0375 Convergence: 0.0926 k= 0.018718 lr = 0.0000028\n",
      "[21/25][7940/9765] Loss_D: 0.1003 Loss_G: 0.0388 Convergence: 0.1026 k= 0.018720 lr = 0.0000026\n",
      "[21/25][7950/9765] Loss_D: 0.0940 Loss_G: 0.0391 Convergence: 0.0959 k= 0.018725 lr = 0.0000026\n",
      "[21/25][7960/9765] Loss_D: 0.1005 Loss_G: 0.0396 Convergence: 0.1022 k= 0.018726 lr = 0.0000026\n",
      "[21/25][7970/9765] Loss_D: 0.0945 Loss_G: 0.0405 Convergence: 0.0976 k= 0.018712 lr = 0.0000026\n",
      "[21/25][7980/9765] Loss_D: 0.0922 Loss_G: 0.0408 Convergence: 0.0966 k= 0.018695 lr = 0.0000026\n",
      "[21/25][7990/9765] Loss_D: 0.1033 Loss_G: 0.0396 Convergence: 0.1060 k= 0.018688 lr = 0.0000026\n",
      "[21/25][8000/9765] Loss_D: 0.0983 Loss_G: 0.0384 Convergence: 0.1002 k= 0.018680 lr = 0.0000026\n",
      "[21/25][8010/9765] Loss_D: 0.0945 Loss_G: 0.0394 Convergence: 0.0965 k= 0.018676 lr = 0.0000026\n",
      "[21/25][8020/9765] Loss_D: 0.0952 Loss_G: 0.0394 Convergence: 0.0969 k= 0.018671 lr = 0.0000026\n",
      "[21/25][8030/9765] Loss_D: 0.0972 Loss_G: 0.0381 Convergence: 0.0989 k= 0.018674 lr = 0.0000026\n",
      "[21/25][8040/9765] Loss_D: 0.0919 Loss_G: 0.0384 Convergence: 0.0940 k= 0.018682 lr = 0.0000026\n",
      "[21/25][8050/9765] Loss_D: 0.0876 Loss_G: 0.0380 Convergence: 0.0910 k= 0.018687 lr = 0.0000026\n",
      "[21/25][8060/9765] Loss_D: 0.1144 Loss_G: 0.0388 Convergence: 0.1223 k= 0.018695 lr = 0.0000026\n",
      "[21/25][8070/9765] Loss_D: 0.1019 Loss_G: 0.0368 Convergence: 0.1068 k= 0.018697 lr = 0.0000026\n",
      "[21/25][8080/9765] Loss_D: 0.0983 Loss_G: 0.0389 Convergence: 0.0997 k= 0.018701 lr = 0.0000026\n",
      "[21/25][8090/9765] Loss_D: 0.0925 Loss_G: 0.0385 Convergence: 0.0944 k= 0.018696 lr = 0.0000026\n",
      "[21/25][8100/9765] Loss_D: 0.0948 Loss_G: 0.0374 Convergence: 0.0963 k= 0.018685 lr = 0.0000026\n",
      "[21/25][8110/9765] Loss_D: 0.0959 Loss_G: 0.0377 Convergence: 0.0976 k= 0.018698 lr = 0.0000026\n",
      "[21/25][8120/9765] Loss_D: 0.0935 Loss_G: 0.0375 Convergence: 0.0943 k= 0.018715 lr = 0.0000026\n",
      "[21/25][8130/9765] Loss_D: 0.0892 Loss_G: 0.0391 Convergence: 0.0931 k= 0.018714 lr = 0.0000026\n",
      "[21/25][8140/9765] Loss_D: 0.0990 Loss_G: 0.0391 Convergence: 0.1006 k= 0.018707 lr = 0.0000026\n",
      "[21/25][8150/9765] Loss_D: 0.0984 Loss_G: 0.0382 Convergence: 0.1006 k= 0.018711 lr = 0.0000026\n",
      "[21/25][8160/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0993 k= 0.018720 lr = 0.0000026\n",
      "[21/25][8170/9765] Loss_D: 0.0859 Loss_G: 0.0387 Convergence: 0.0907 k= 0.018712 lr = 0.0000026\n",
      "[21/25][8180/9765] Loss_D: 0.0991 Loss_G: 0.0390 Convergence: 0.1007 k= 0.018718 lr = 0.0000026\n",
      "[21/25][8190/9765] Loss_D: 0.0915 Loss_G: 0.0377 Convergence: 0.0930 k= 0.018704 lr = 0.0000026\n",
      "[21/25][8200/9765] Loss_D: 0.0969 Loss_G: 0.0398 Convergence: 0.0984 k= 0.018696 lr = 0.0000026\n",
      "[21/25][8210/9765] Loss_D: 0.1019 Loss_G: 0.0377 Convergence: 0.1060 k= 0.018690 lr = 0.0000026\n",
      "[21/25][8220/9765] Loss_D: 0.0918 Loss_G: 0.0388 Convergence: 0.0944 k= 0.018694 lr = 0.0000026\n",
      "[21/25][8230/9765] Loss_D: 0.0952 Loss_G: 0.0395 Convergence: 0.0970 k= 0.018700 lr = 0.0000026\n",
      "[21/25][8240/9765] Loss_D: 0.0940 Loss_G: 0.0389 Convergence: 0.0957 k= 0.018696 lr = 0.0000026\n",
      "[21/25][8250/9765] Loss_D: 0.0998 Loss_G: 0.0389 Convergence: 0.1019 k= 0.018698 lr = 0.0000026\n",
      "[21/25][8260/9765] Loss_D: 0.0885 Loss_G: 0.0392 Convergence: 0.0928 k= 0.018695 lr = 0.0000026\n",
      "[21/25][8270/9765] Loss_D: 0.0880 Loss_G: 0.0382 Convergence: 0.0915 k= 0.018690 lr = 0.0000026\n",
      "[21/25][8280/9765] Loss_D: 0.1036 Loss_G: 0.0381 Convergence: 0.1079 k= 0.018701 lr = 0.0000026\n",
      "[21/25][8290/9765] Loss_D: 0.0968 Loss_G: 0.0373 Convergence: 0.0993 k= 0.018695 lr = 0.0000026\n",
      "[21/25][8300/9765] Loss_D: 0.0848 Loss_G: 0.0386 Convergence: 0.0899 k= 0.018696 lr = 0.0000026\n",
      "[21/25][8310/9765] Loss_D: 0.0998 Loss_G: 0.0378 Convergence: 0.1029 k= 0.018717 lr = 0.0000026\n",
      "[21/25][8320/9765] Loss_D: 0.0944 Loss_G: 0.0372 Convergence: 0.0959 k= 0.018727 lr = 0.0000026\n",
      "[21/25][8330/9765] Loss_D: 0.0990 Loss_G: 0.0369 Convergence: 0.1027 k= 0.018745 lr = 0.0000026\n",
      "[21/25][8340/9765] Loss_D: 0.0853 Loss_G: 0.0390 Convergence: 0.0906 k= 0.018749 lr = 0.0000026\n",
      "[21/25][8350/9765] Loss_D: 0.1007 Loss_G: 0.0378 Convergence: 0.1042 k= 0.018761 lr = 0.0000026\n",
      "[21/25][8360/9765] Loss_D: 0.0968 Loss_G: 0.0383 Convergence: 0.0982 k= 0.018772 lr = 0.0000026\n",
      "[21/25][8370/9765] Loss_D: 0.1012 Loss_G: 0.0376 Convergence: 0.1050 k= 0.018779 lr = 0.0000026\n",
      "[21/25][8380/9765] Loss_D: 0.0917 Loss_G: 0.0399 Convergence: 0.0954 k= 0.018777 lr = 0.0000026\n",
      "[21/25][8390/9765] Loss_D: 0.0947 Loss_G: 0.0392 Convergence: 0.0965 k= 0.018775 lr = 0.0000026\n",
      "[21/25][8400/9765] Loss_D: 0.1020 Loss_G: 0.0405 Convergence: 0.1033 k= 0.018769 lr = 0.0000026\n",
      "[21/25][8410/9765] Loss_D: 0.1073 Loss_G: 0.0401 Convergence: 0.1112 k= 0.018759 lr = 0.0000026\n",
      "[21/25][8420/9765] Loss_D: 0.0890 Loss_G: 0.0397 Convergence: 0.0936 k= 0.018740 lr = 0.0000026\n",
      "[21/25][8430/9765] Loss_D: 0.1002 Loss_G: 0.0392 Convergence: 0.1021 k= 0.018736 lr = 0.0000026\n",
      "[21/25][8440/9765] Loss_D: 0.0897 Loss_G: 0.0393 Convergence: 0.0935 k= 0.018735 lr = 0.0000026\n",
      "[21/25][8450/9765] Loss_D: 0.0946 Loss_G: 0.0386 Convergence: 0.0958 k= 0.018736 lr = 0.0000026\n",
      "[21/25][8460/9765] Loss_D: 0.1049 Loss_G: 0.0410 Convergence: 0.1069 k= 0.018732 lr = 0.0000026\n",
      "[21/25][8470/9765] Loss_D: 0.0949 Loss_G: 0.0402 Convergence: 0.0976 k= 0.018709 lr = 0.0000026\n",
      "[21/25][8480/9765] Loss_D: 0.0990 Loss_G: 0.0396 Convergence: 0.1001 k= 0.018690 lr = 0.0000026\n",
      "[21/25][8490/9765] Loss_D: 0.0959 Loss_G: 0.0396 Convergence: 0.0976 k= 0.018685 lr = 0.0000026\n",
      "[21/25][8500/9765] Loss_D: 0.0938 Loss_G: 0.0378 Convergence: 0.0946 k= 0.018673 lr = 0.0000026\n",
      "[21/25][8510/9765] Loss_D: 0.0937 Loss_G: 0.0361 Convergence: 0.0960 k= 0.018673 lr = 0.0000026\n",
      "[21/25][8520/9765] Loss_D: 0.0972 Loss_G: 0.0391 Convergence: 0.0980 k= 0.018686 lr = 0.0000026\n",
      "[21/25][8530/9765] Loss_D: 0.1004 Loss_G: 0.0390 Convergence: 0.1027 k= 0.018694 lr = 0.0000026\n",
      "[21/25][8540/9765] Loss_D: 0.0948 Loss_G: 0.0391 Convergence: 0.0964 k= 0.018694 lr = 0.0000026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][8550/9765] Loss_D: 0.0943 Loss_G: 0.0389 Convergence: 0.0959 k= 0.018701 lr = 0.0000026\n",
      "[21/25][8560/9765] Loss_D: 0.0953 Loss_G: 0.0405 Convergence: 0.0981 k= 0.018703 lr = 0.0000026\n",
      "[21/25][8570/9765] Loss_D: 0.0934 Loss_G: 0.0406 Convergence: 0.0971 k= 0.018691 lr = 0.0000026\n",
      "[21/25][8580/9765] Loss_D: 0.0876 Loss_G: 0.0388 Convergence: 0.0918 k= 0.018686 lr = 0.0000026\n",
      "[21/25][8590/9765] Loss_D: 0.0843 Loss_G: 0.0380 Convergence: 0.0890 k= 0.018700 lr = 0.0000026\n",
      "[21/25][8600/9765] Loss_D: 0.0956 Loss_G: 0.0377 Convergence: 0.0971 k= 0.018713 lr = 0.0000026\n",
      "[21/25][8610/9765] Loss_D: 0.0916 Loss_G: 0.0388 Convergence: 0.0942 k= 0.018723 lr = 0.0000026\n",
      "[21/25][8620/9765] Loss_D: 0.0921 Loss_G: 0.0379 Convergence: 0.0935 k= 0.018728 lr = 0.0000026\n",
      "[21/25][8630/9765] Loss_D: 0.0961 Loss_G: 0.0382 Convergence: 0.0974 k= 0.018731 lr = 0.0000026\n",
      "[21/25][8640/9765] Loss_D: 0.0975 Loss_G: 0.0387 Convergence: 0.0988 k= 0.018743 lr = 0.0000026\n",
      "[21/25][8650/9765] Loss_D: 0.0928 Loss_G: 0.0393 Convergence: 0.0954 k= 0.018736 lr = 0.0000026\n",
      "[21/25][8660/9765] Loss_D: 0.1072 Loss_G: 0.0404 Convergence: 0.1106 k= 0.018727 lr = 0.0000026\n",
      "[21/25][8670/9765] Loss_D: 0.0966 Loss_G: 0.0389 Convergence: 0.0973 k= 0.018733 lr = 0.0000026\n",
      "[21/25][8680/9765] Loss_D: 0.0976 Loss_G: 0.0405 Convergence: 0.0996 k= 0.018731 lr = 0.0000026\n",
      "[21/25][8690/9765] Loss_D: 0.0943 Loss_G: 0.0402 Convergence: 0.0972 k= 0.018720 lr = 0.0000026\n",
      "[21/25][8700/9765] Loss_D: 0.0976 Loss_G: 0.0390 Convergence: 0.0987 k= 0.018704 lr = 0.0000026\n",
      "[21/25][8710/9765] Loss_D: 0.1014 Loss_G: 0.0377 Convergence: 0.1051 k= 0.018698 lr = 0.0000026\n",
      "[21/25][8720/9765] Loss_D: 0.1030 Loss_G: 0.0374 Convergence: 0.1077 k= 0.018694 lr = 0.0000026\n",
      "[21/25][8730/9765] Loss_D: 0.0926 Loss_G: 0.0380 Convergence: 0.0940 k= 0.018718 lr = 0.0000026\n",
      "[21/25][8740/9765] Loss_D: 0.0981 Loss_G: 0.0376 Convergence: 0.1007 k= 0.018724 lr = 0.0000026\n",
      "[21/25][8750/9765] Loss_D: 0.0938 Loss_G: 0.0383 Convergence: 0.0950 k= 0.018747 lr = 0.0000026\n",
      "[21/25][8760/9765] Loss_D: 0.0984 Loss_G: 0.0384 Convergence: 0.1003 k= 0.018749 lr = 0.0000026\n",
      "[21/25][8770/9765] Loss_D: 0.0992 Loss_G: 0.0403 Convergence: 0.1003 k= 0.018753 lr = 0.0000026\n",
      "[21/25][8780/9765] Loss_D: 0.0954 Loss_G: 0.0393 Convergence: 0.0970 k= 0.018747 lr = 0.0000026\n",
      "[21/25][8790/9765] Loss_D: 0.0880 Loss_G: 0.0380 Convergence: 0.0912 k= 0.018752 lr = 0.0000026\n",
      "[21/25][8800/9765] Loss_D: 0.1077 Loss_G: 0.0385 Convergence: 0.1133 k= 0.018751 lr = 0.0000026\n",
      "[21/25][8810/9765] Loss_D: 0.0939 Loss_G: 0.0376 Convergence: 0.0949 k= 0.018752 lr = 0.0000026\n",
      "[21/25][8820/9765] Loss_D: 0.0970 Loss_G: 0.0388 Convergence: 0.0981 k= 0.018748 lr = 0.0000026\n",
      "[21/25][8830/9765] Loss_D: 0.0903 Loss_G: 0.0387 Convergence: 0.0933 k= 0.018743 lr = 0.0000026\n",
      "[21/25][8840/9765] Loss_D: 0.0896 Loss_G: 0.0378 Convergence: 0.0919 k= 0.018751 lr = 0.0000026\n",
      "[21/25][8850/9765] Loss_D: 0.0815 Loss_G: 0.0385 Convergence: 0.0879 k= 0.018747 lr = 0.0000026\n",
      "[21/25][8860/9765] Loss_D: 0.0946 Loss_G: 0.0387 Convergence: 0.0959 k= 0.018761 lr = 0.0000026\n",
      "[21/25][8870/9765] Loss_D: 0.0995 Loss_G: 0.0377 Convergence: 0.1026 k= 0.018756 lr = 0.0000026\n",
      "[21/25][8880/9765] Loss_D: 0.0959 Loss_G: 0.0395 Convergence: 0.0975 k= 0.018762 lr = 0.0000026\n",
      "[21/25][8890/9765] Loss_D: 0.1018 Loss_G: 0.0381 Convergence: 0.1054 k= 0.018769 lr = 0.0000026\n",
      "[21/25][8900/9765] Loss_D: 0.0978 Loss_G: 0.0395 Convergence: 0.0986 k= 0.018767 lr = 0.0000026\n",
      "[21/25][8910/9765] Loss_D: 0.1037 Loss_G: 0.0377 Convergence: 0.1085 k= 0.018773 lr = 0.0000026\n",
      "[21/25][8920/9765] Loss_D: 0.1002 Loss_G: 0.0391 Convergence: 0.1022 k= 0.018790 lr = 0.0000026\n",
      "[21/25][8930/9765] Loss_D: 0.1027 Loss_G: 0.0394 Convergence: 0.1054 k= 0.018783 lr = 0.0000026\n",
      "[21/25][8940/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1001 k= 0.018772 lr = 0.0000026\n",
      "[21/25][8950/9765] Loss_D: 0.1026 Loss_G: 0.0386 Convergence: 0.1061 k= 0.018775 lr = 0.0000026\n",
      "[21/25][8960/9765] Loss_D: 0.1007 Loss_G: 0.0407 Convergence: 0.1016 k= 0.018772 lr = 0.0000026\n",
      "[21/25][8970/9765] Loss_D: 0.0960 Loss_G: 0.0394 Convergence: 0.0974 k= 0.018761 lr = 0.0000026\n",
      "[21/25][8980/9765] Loss_D: 0.1059 Loss_G: 0.0397 Convergence: 0.1096 k= 0.018753 lr = 0.0000026\n",
      "[21/25][8990/9765] Loss_D: 0.0951 Loss_G: 0.0388 Convergence: 0.0963 k= 0.018735 lr = 0.0000026\n",
      "[21/25][9000/9765] Loss_D: 0.0971 Loss_G: 0.0392 Convergence: 0.0979 k= 0.018726 lr = 0.0000026\n",
      "[21/25][9010/9765] Loss_D: 0.0937 Loss_G: 0.0387 Convergence: 0.0953 k= 0.018725 lr = 0.0000026\n",
      "[21/25][9020/9765] Loss_D: 0.0928 Loss_G: 0.0395 Convergence: 0.0956 k= 0.018718 lr = 0.0000026\n",
      "[21/25][9030/9765] Loss_D: 0.0934 Loss_G: 0.0396 Convergence: 0.0961 k= 0.018717 lr = 0.0000026\n",
      "[21/25][9040/9765] Loss_D: 0.0928 Loss_G: 0.0410 Convergence: 0.0972 k= 0.018703 lr = 0.0000026\n",
      "[21/25][9050/9765] Loss_D: 0.0914 Loss_G: 0.0400 Convergence: 0.0953 k= 0.018687 lr = 0.0000026\n",
      "[21/25][9060/9765] Loss_D: 0.0858 Loss_G: 0.0398 Convergence: 0.0918 k= 0.018685 lr = 0.0000026\n",
      "[21/25][9070/9765] Loss_D: 0.0917 Loss_G: 0.0414 Convergence: 0.0969 k= 0.018675 lr = 0.0000026\n",
      "[21/25][9080/9765] Loss_D: 0.0988 Loss_G: 0.0393 Convergence: 0.0999 k= 0.018672 lr = 0.0000026\n",
      "[21/25][9090/9765] Loss_D: 0.0872 Loss_G: 0.0396 Convergence: 0.0923 k= 0.018653 lr = 0.0000026\n",
      "[21/25][9100/9765] Loss_D: 0.1021 Loss_G: 0.0386 Convergence: 0.1053 k= 0.018655 lr = 0.0000026\n",
      "[21/25][9110/9765] Loss_D: 0.0908 Loss_G: 0.0391 Convergence: 0.0940 k= 0.018649 lr = 0.0000026\n",
      "[21/25][9120/9765] Loss_D: 0.0901 Loss_G: 0.0385 Convergence: 0.0930 k= 0.018639 lr = 0.0000026\n",
      "[21/25][9130/9765] Loss_D: 0.1017 Loss_G: 0.0383 Convergence: 0.1050 k= 0.018647 lr = 0.0000026\n",
      "[21/25][9140/9765] Loss_D: 0.1050 Loss_G: 0.0388 Convergence: 0.1092 k= 0.018664 lr = 0.0000026\n",
      "[21/25][9150/9765] Loss_D: 0.0990 Loss_G: 0.0381 Convergence: 0.1015 k= 0.018660 lr = 0.0000026\n",
      "[21/25][9160/9765] Loss_D: 0.1003 Loss_G: 0.0387 Convergence: 0.1028 k= 0.018676 lr = 0.0000026\n",
      "[21/25][9170/9765] Loss_D: 0.1057 Loss_G: 0.0366 Convergence: 0.1123 k= 0.018693 lr = 0.0000026\n",
      "[21/25][9180/9765] Loss_D: 0.0882 Loss_G: 0.0373 Convergence: 0.0906 k= 0.018705 lr = 0.0000026\n",
      "[21/25][9190/9765] Loss_D: 0.0936 Loss_G: 0.0381 Convergence: 0.0947 k= 0.018720 lr = 0.0000026\n",
      "[21/25][9200/9765] Loss_D: 0.1098 Loss_G: 0.0382 Convergence: 0.1166 k= 0.018736 lr = 0.0000026\n",
      "[21/25][9210/9765] Loss_D: 0.0952 Loss_G: 0.0381 Convergence: 0.0961 k= 0.018738 lr = 0.0000026\n",
      "[21/25][9220/9765] Loss_D: 0.0901 Loss_G: 0.0387 Convergence: 0.0932 k= 0.018724 lr = 0.0000026\n",
      "[21/25][9230/9765] Loss_D: 0.0970 Loss_G: 0.0405 Convergence: 0.0991 k= 0.018720 lr = 0.0000026\n",
      "[21/25][9240/9765] Loss_D: 0.0876 Loss_G: 0.0427 Convergence: 0.0957 k= 0.018695 lr = 0.0000026\n",
      "[21/25][9250/9765] Loss_D: 0.0948 Loss_G: 0.0411 Convergence: 0.0985 k= 0.018659 lr = 0.0000026\n",
      "[21/25][9260/9765] Loss_D: 0.0913 Loss_G: 0.0437 Convergence: 0.0990 k= 0.018621 lr = 0.0000026\n",
      "[21/25][9270/9765] Loss_D: 0.0955 Loss_G: 0.0446 Convergence: 0.1024 k= 0.018585 lr = 0.0000026\n",
      "[21/25][9280/9765] Loss_D: 0.1006 Loss_G: 0.0426 Convergence: 0.1034 k= 0.018537 lr = 0.0000026\n",
      "[21/25][9290/9765] Loss_D: 0.0950 Loss_G: 0.0428 Convergence: 0.1003 k= 0.018495 lr = 0.0000026\n",
      "[21/25][9300/9765] Loss_D: 0.0952 Loss_G: 0.0427 Convergence: 0.1003 k= 0.018457 lr = 0.0000026\n",
      "[21/25][9310/9765] Loss_D: 0.1022 Loss_G: 0.0407 Convergence: 0.1035 k= 0.018421 lr = 0.0000026\n",
      "[21/25][9320/9765] Loss_D: 0.0873 Loss_G: 0.0408 Convergence: 0.0937 k= 0.018391 lr = 0.0000026\n",
      "[21/25][9330/9765] Loss_D: 0.0978 Loss_G: 0.0386 Convergence: 0.0993 k= 0.018365 lr = 0.0000026\n",
      "[21/25][9340/9765] Loss_D: 0.1049 Loss_G: 0.0394 Convergence: 0.1084 k= 0.018340 lr = 0.0000026\n",
      "[21/25][9350/9765] Loss_D: 0.0887 Loss_G: 0.0371 Convergence: 0.0907 k= 0.018339 lr = 0.0000026\n",
      "[21/25][9360/9765] Loss_D: 0.0949 Loss_G: 0.0365 Convergence: 0.0974 k= 0.018347 lr = 0.0000026\n",
      "[21/25][9370/9765] Loss_D: 0.0925 Loss_G: 0.0367 Convergence: 0.0938 k= 0.018362 lr = 0.0000026\n",
      "[21/25][9380/9765] Loss_D: 0.0946 Loss_G: 0.0366 Convergence: 0.0967 k= 0.018394 lr = 0.0000026\n",
      "[21/25][9390/9765] Loss_D: 0.0956 Loss_G: 0.0349 Convergence: 0.0998 k= 0.018426 lr = 0.0000026\n",
      "[21/25][9400/9765] Loss_D: 0.0983 Loss_G: 0.0349 Convergence: 0.1037 k= 0.018468 lr = 0.0000026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/25][9410/9765] Loss_D: 0.0946 Loss_G: 0.0355 Convergence: 0.0979 k= 0.018503 lr = 0.0000026\n",
      "[21/25][9420/9765] Loss_D: 0.1081 Loss_G: 0.0354 Convergence: 0.1168 k= 0.018540 lr = 0.0000026\n",
      "[21/25][9430/9765] Loss_D: 0.1006 Loss_G: 0.0358 Convergence: 0.1059 k= 0.018577 lr = 0.0000026\n",
      "[21/25][9440/9765] Loss_D: 0.0922 Loss_G: 0.0340 Convergence: 0.0959 k= 0.018615 lr = 0.0000026\n",
      "[21/25][9450/9765] Loss_D: 0.0882 Loss_G: 0.0349 Convergence: 0.0895 k= 0.018642 lr = 0.0000026\n",
      "[21/25][9460/9765] Loss_D: 0.0864 Loss_G: 0.0354 Convergence: 0.0877 k= 0.018661 lr = 0.0000026\n",
      "[21/25][9470/9765] Loss_D: 0.0937 Loss_G: 0.0369 Convergence: 0.0952 k= 0.018676 lr = 0.0000026\n",
      "[21/25][9480/9765] Loss_D: 0.0853 Loss_G: 0.0379 Convergence: 0.0895 k= 0.018671 lr = 0.0000026\n",
      "[21/25][9490/9765] Loss_D: 0.0999 Loss_G: 0.0378 Convergence: 0.1030 k= 0.018692 lr = 0.0000026\n",
      "[21/25][9500/9765] Loss_D: 0.1040 Loss_G: 0.0398 Convergence: 0.1068 k= 0.018703 lr = 0.0000026\n",
      "[21/25][9510/9765] Loss_D: 0.1013 Loss_G: 0.0379 Convergence: 0.1049 k= 0.018691 lr = 0.0000026\n",
      "[21/25][9520/9765] Loss_D: 0.0950 Loss_G: 0.0386 Convergence: 0.0960 k= 0.018684 lr = 0.0000026\n",
      "[21/25][9530/9765] Loss_D: 0.0986 Loss_G: 0.0408 Convergence: 0.1005 k= 0.018677 lr = 0.0000026\n",
      "[21/25][9540/9765] Loss_D: 0.0946 Loss_G: 0.0403 Convergence: 0.0976 k= 0.018650 lr = 0.0000026\n",
      "[21/25][9550/9765] Loss_D: 0.0952 Loss_G: 0.0407 Convergence: 0.0983 k= 0.018631 lr = 0.0000026\n",
      "[21/25][9560/9765] Loss_D: 0.0911 Loss_G: 0.0398 Convergence: 0.0950 k= 0.018622 lr = 0.0000026\n",
      "[21/25][9570/9765] Loss_D: 0.0907 Loss_G: 0.0406 Convergence: 0.0955 k= 0.018620 lr = 0.0000026\n",
      "[21/25][9580/9765] Loss_D: 0.0985 Loss_G: 0.0388 Convergence: 0.1001 k= 0.018616 lr = 0.0000026\n",
      "[21/25][9590/9765] Loss_D: 0.0999 Loss_G: 0.0390 Convergence: 0.1019 k= 0.018609 lr = 0.0000026\n",
      "[21/25][9600/9765] Loss_D: 0.0995 Loss_G: 0.0395 Convergence: 0.1009 k= 0.018627 lr = 0.0000026\n",
      "[21/25][9610/9765] Loss_D: 0.1041 Loss_G: 0.0395 Convergence: 0.1072 k= 0.018622 lr = 0.0000026\n",
      "[21/25][9620/9765] Loss_D: 0.0979 Loss_G: 0.0394 Convergence: 0.0988 k= 0.018620 lr = 0.0000026\n",
      "[21/25][9630/9765] Loss_D: 0.0950 Loss_G: 0.0388 Convergence: 0.0962 k= 0.018603 lr = 0.0000026\n",
      "[21/25][9640/9765] Loss_D: 0.0998 Loss_G: 0.0383 Convergence: 0.1024 k= 0.018607 lr = 0.0000026\n",
      "[21/25][9650/9765] Loss_D: 0.0972 Loss_G: 0.0401 Convergence: 0.0988 k= 0.018604 lr = 0.0000026\n",
      "[21/25][9660/9765] Loss_D: 0.0909 Loss_G: 0.0387 Convergence: 0.0936 k= 0.018586 lr = 0.0000026\n",
      "[21/25][9670/9765] Loss_D: 0.0963 Loss_G: 0.0396 Convergence: 0.0978 k= 0.018570 lr = 0.0000026\n",
      "[21/25][9680/9765] Loss_D: 0.0872 Loss_G: 0.0377 Convergence: 0.0904 k= 0.018554 lr = 0.0000026\n",
      "[21/25][9690/9765] Loss_D: 0.0928 Loss_G: 0.0373 Convergence: 0.0936 k= 0.018561 lr = 0.0000026\n",
      "[21/25][9700/9765] Loss_D: 0.1007 Loss_G: 0.0378 Convergence: 0.1041 k= 0.018574 lr = 0.0000026\n",
      "[21/25][9710/9765] Loss_D: 0.0930 Loss_G: 0.0376 Convergence: 0.0938 k= 0.018575 lr = 0.0000026\n",
      "[21/25][9720/9765] Loss_D: 0.1053 Loss_G: 0.0387 Convergence: 0.1096 k= 0.018582 lr = 0.0000026\n",
      "[21/25][9730/9765] Loss_D: 0.0982 Loss_G: 0.0399 Convergence: 0.0992 k= 0.018576 lr = 0.0000026\n",
      "[21/25][9740/9765] Loss_D: 0.0886 Loss_G: 0.0396 Convergence: 0.0932 k= 0.018568 lr = 0.0000026\n",
      "[21/25][9750/9765] Loss_D: 0.0927 Loss_G: 0.0398 Convergence: 0.0958 k= 0.018552 lr = 0.0000026\n",
      "[21/25][9760/9765] Loss_D: 0.0936 Loss_G: 0.0398 Convergence: 0.0965 k= 0.018549 lr = 0.0000026\n",
      "[22/25][0/9765] Loss_D: 0.0988 Loss_G: 0.0382 Convergence: 0.1012 k= 0.018551 lr = 0.0000026\n",
      "[22/25][10/9765] Loss_D: 0.0912 Loss_G: 0.0394 Convergence: 0.0945 k= 0.018543 lr = 0.0000026\n",
      "[22/25][20/9765] Loss_D: 0.0930 Loss_G: 0.0384 Convergence: 0.0946 k= 0.018546 lr = 0.0000026\n",
      "[22/25][30/9765] Loss_D: 0.0979 Loss_G: 0.0378 Convergence: 0.1002 k= 0.018554 lr = 0.0000026\n",
      "[22/25][40/9765] Loss_D: 0.0960 Loss_G: 0.0396 Convergence: 0.0976 k= 0.018548 lr = 0.0000026\n",
      "[22/25][50/9765] Loss_D: 0.0873 Loss_G: 0.0394 Convergence: 0.0922 k= 0.018534 lr = 0.0000026\n",
      "[22/25][60/9765] Loss_D: 0.0991 Loss_G: 0.0391 Convergence: 0.1006 k= 0.018521 lr = 0.0000026\n",
      "[22/25][70/9765] Loss_D: 0.0980 Loss_G: 0.0366 Convergence: 0.1016 k= 0.018514 lr = 0.0000026\n",
      "[22/25][80/9765] Loss_D: 0.0881 Loss_G: 0.0396 Convergence: 0.0929 k= 0.018514 lr = 0.0000026\n",
      "[22/25][90/9765] Loss_D: 0.1048 Loss_G: 0.0379 Convergence: 0.1098 k= 0.018517 lr = 0.0000026\n",
      "[22/25][100/9765] Loss_D: 0.0913 Loss_G: 0.0386 Convergence: 0.0938 k= 0.018531 lr = 0.0000026\n",
      "[22/25][110/9765] Loss_D: 0.1015 Loss_G: 0.0385 Convergence: 0.1045 k= 0.018528 lr = 0.0000026\n",
      "[22/25][120/9765] Loss_D: 0.0915 Loss_G: 0.0391 Convergence: 0.0945 k= 0.018528 lr = 0.0000026\n",
      "[22/25][130/9765] Loss_D: 0.1050 Loss_G: 0.0390 Convergence: 0.1090 k= 0.018523 lr = 0.0000026\n",
      "[22/25][140/9765] Loss_D: 0.0929 Loss_G: 0.0386 Convergence: 0.0947 k= 0.018525 lr = 0.0000026\n",
      "[22/25][150/9765] Loss_D: 0.1154 Loss_G: 0.0372 Convergence: 0.1253 k= 0.018553 lr = 0.0000026\n",
      "[22/25][160/9765] Loss_D: 0.0913 Loss_G: 0.0387 Convergence: 0.0939 k= 0.018555 lr = 0.0000026\n",
      "[22/25][170/9765] Loss_D: 0.0860 Loss_G: 0.0380 Convergence: 0.0900 k= 0.018560 lr = 0.0000026\n",
      "[22/25][180/9765] Loss_D: 0.1048 Loss_G: 0.0385 Convergence: 0.1092 k= 0.018580 lr = 0.0000026\n",
      "[22/25][190/9765] Loss_D: 0.0949 Loss_G: 0.0391 Convergence: 0.0965 k= 0.018593 lr = 0.0000026\n",
      "[22/25][200/9765] Loss_D: 0.1009 Loss_G: 0.0388 Convergence: 0.1035 k= 0.018598 lr = 0.0000026\n",
      "[22/25][210/9765] Loss_D: 0.1042 Loss_G: 0.0390 Convergence: 0.1079 k= 0.018600 lr = 0.0000026\n",
      "[22/25][220/9765] Loss_D: 0.0935 Loss_G: 0.0398 Convergence: 0.0963 k= 0.018588 lr = 0.0000026\n",
      "[22/25][230/9765] Loss_D: 0.0986 Loss_G: 0.0419 Convergence: 0.1015 k= 0.018574 lr = 0.0000026\n",
      "[22/25][240/9765] Loss_D: 0.0932 Loss_G: 0.0391 Convergence: 0.0954 k= 0.018558 lr = 0.0000026\n",
      "[22/25][250/9765] Loss_D: 0.0978 Loss_G: 0.0394 Convergence: 0.0986 k= 0.018550 lr = 0.0000026\n",
      "[22/25][260/9765] Loss_D: 0.0904 Loss_G: 0.0375 Convergence: 0.0922 k= 0.018537 lr = 0.0000026\n",
      "[22/25][270/9765] Loss_D: 0.0953 Loss_G: 0.0387 Convergence: 0.0963 k= 0.018531 lr = 0.0000026\n",
      "[22/25][280/9765] Loss_D: 0.1013 Loss_G: 0.0390 Convergence: 0.1038 k= 0.018530 lr = 0.0000026\n",
      "[22/25][290/9765] Loss_D: 0.0979 Loss_G: 0.0392 Convergence: 0.0990 k= 0.018542 lr = 0.0000026\n",
      "[22/25][300/9765] Loss_D: 0.0962 Loss_G: 0.0393 Convergence: 0.0974 k= 0.018546 lr = 0.0000026\n",
      "[22/25][310/9765] Loss_D: 0.1056 Loss_G: 0.0388 Convergence: 0.1100 k= 0.018539 lr = 0.0000026\n",
      "[22/25][320/9765] Loss_D: 0.0964 Loss_G: 0.0397 Convergence: 0.0979 k= 0.018537 lr = 0.0000026\n",
      "[22/25][330/9765] Loss_D: 0.0896 Loss_G: 0.0386 Convergence: 0.0928 k= 0.018536 lr = 0.0000026\n",
      "[22/25][340/9765] Loss_D: 0.0999 Loss_G: 0.0384 Convergence: 0.1025 k= 0.018540 lr = 0.0000026\n",
      "[22/25][350/9765] Loss_D: 0.1032 Loss_G: 0.0382 Convergence: 0.1073 k= 0.018548 lr = 0.0000026\n",
      "[22/25][360/9765] Loss_D: 0.0915 Loss_G: 0.0379 Convergence: 0.0932 k= 0.018556 lr = 0.0000026\n",
      "[22/25][370/9765] Loss_D: 0.0898 Loss_G: 0.0379 Convergence: 0.0923 k= 0.018555 lr = 0.0000026\n",
      "[22/25][380/9765] Loss_D: 0.1074 Loss_G: 0.0391 Convergence: 0.1123 k= 0.018554 lr = 0.0000026\n",
      "[22/25][390/9765] Loss_D: 0.1065 Loss_G: 0.0379 Convergence: 0.1121 k= 0.018566 lr = 0.0000026\n",
      "[22/25][400/9765] Loss_D: 0.0957 Loss_G: 0.0389 Convergence: 0.0968 k= 0.018563 lr = 0.0000026\n",
      "[22/25][410/9765] Loss_D: 0.0956 Loss_G: 0.0396 Convergence: 0.0974 k= 0.018553 lr = 0.0000026\n",
      "[22/25][420/9765] Loss_D: 0.0989 Loss_G: 0.0379 Convergence: 0.1015 k= 0.018554 lr = 0.0000026\n",
      "[22/25][430/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.018559 lr = 0.0000026\n",
      "[22/25][440/9765] Loss_D: 0.0897 Loss_G: 0.0382 Convergence: 0.0925 k= 0.018554 lr = 0.0000026\n",
      "[22/25][450/9765] Loss_D: 0.0922 Loss_G: 0.0384 Convergence: 0.0942 k= 0.018550 lr = 0.0000026\n",
      "[22/25][460/9765] Loss_D: 0.1021 Loss_G: 0.0393 Convergence: 0.1047 k= 0.018548 lr = 0.0000026\n",
      "[22/25][470/9765] Loss_D: 0.0926 Loss_G: 0.0393 Convergence: 0.0953 k= 0.018544 lr = 0.0000026\n",
      "[22/25][480/9765] Loss_D: 0.0915 Loss_G: 0.0387 Convergence: 0.0940 k= 0.018543 lr = 0.0000026\n",
      "[22/25][490/9765] Loss_D: 0.0965 Loss_G: 0.0391 Convergence: 0.0974 k= 0.018545 lr = 0.0000026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][500/9765] Loss_D: 0.0977 Loss_G: 0.0389 Convergence: 0.0989 k= 0.018549 lr = 0.0000026\n",
      "[22/25][510/9765] Loss_D: 0.0946 Loss_G: 0.0369 Convergence: 0.0964 k= 0.018541 lr = 0.0000026\n",
      "[22/25][520/9765] Loss_D: 0.0999 Loss_G: 0.0363 Convergence: 0.1044 k= 0.018544 lr = 0.0000026\n",
      "[22/25][530/9765] Loss_D: 0.0981 Loss_G: 0.0388 Convergence: 0.0996 k= 0.018557 lr = 0.0000026\n",
      "[22/25][540/9765] Loss_D: 0.0978 Loss_G: 0.0375 Convergence: 0.1004 k= 0.018572 lr = 0.0000026\n",
      "[22/25][550/9765] Loss_D: 0.0932 Loss_G: 0.0383 Convergence: 0.0947 k= 0.018592 lr = 0.0000026\n",
      "[22/25][560/9765] Loss_D: 0.1036 Loss_G: 0.0405 Convergence: 0.1056 k= 0.018614 lr = 0.0000026\n",
      "[22/25][570/9765] Loss_D: 0.0902 Loss_G: 0.0376 Convergence: 0.0922 k= 0.018608 lr = 0.0000026\n",
      "[22/25][580/9765] Loss_D: 0.0981 Loss_G: 0.0383 Convergence: 0.1000 k= 0.018619 lr = 0.0000026\n",
      "[22/25][590/9765] Loss_D: 0.1070 Loss_G: 0.0398 Convergence: 0.1111 k= 0.018620 lr = 0.0000026\n",
      "[22/25][600/9765] Loss_D: 0.1000 Loss_G: 0.0391 Convergence: 0.1020 k= 0.018611 lr = 0.0000026\n",
      "[22/25][610/9765] Loss_D: 0.0949 Loss_G: 0.0389 Convergence: 0.0962 k= 0.018620 lr = 0.0000026\n",
      "[22/25][620/9765] Loss_D: 0.0932 Loss_G: 0.0385 Convergence: 0.0948 k= 0.018618 lr = 0.0000026\n",
      "[22/25][630/9765] Loss_D: 0.0875 Loss_G: 0.0382 Convergence: 0.0912 k= 0.018618 lr = 0.0000026\n",
      "[22/25][640/9765] Loss_D: 0.0976 Loss_G: 0.0376 Convergence: 0.1000 k= 0.018612 lr = 0.0000026\n",
      "[22/25][650/9765] Loss_D: 0.0938 Loss_G: 0.0397 Convergence: 0.0964 k= 0.018604 lr = 0.0000026\n",
      "[22/25][660/9765] Loss_D: 0.0951 Loss_G: 0.0371 Convergence: 0.0970 k= 0.018601 lr = 0.0000026\n",
      "[22/25][670/9765] Loss_D: 0.1003 Loss_G: 0.0385 Convergence: 0.1029 k= 0.018614 lr = 0.0000026\n",
      "[22/25][680/9765] Loss_D: 0.0916 Loss_G: 0.0391 Convergence: 0.0945 k= 0.018621 lr = 0.0000026\n",
      "[22/25][690/9765] Loss_D: 0.0965 Loss_G: 0.0392 Convergence: 0.0975 k= 0.018616 lr = 0.0000026\n",
      "[22/25][700/9765] Loss_D: 0.0935 Loss_G: 0.0375 Convergence: 0.0944 k= 0.018617 lr = 0.0000026\n",
      "[22/25][710/9765] Loss_D: 0.0861 Loss_G: 0.0383 Convergence: 0.0904 k= 0.018619 lr = 0.0000026\n",
      "[22/25][720/9765] Loss_D: 0.0926 Loss_G: 0.0377 Convergence: 0.0937 k= 0.018633 lr = 0.0000026\n",
      "[22/25][730/9765] Loss_D: 0.0954 Loss_G: 0.0380 Convergence: 0.0966 k= 0.018643 lr = 0.0000026\n",
      "[22/25][740/9765] Loss_D: 0.0987 Loss_G: 0.0384 Convergence: 0.1008 k= 0.018652 lr = 0.0000026\n",
      "[22/25][750/9765] Loss_D: 0.0984 Loss_G: 0.0385 Convergence: 0.1003 k= 0.018656 lr = 0.0000026\n",
      "[22/25][760/9765] Loss_D: 0.0962 Loss_G: 0.0375 Convergence: 0.0982 k= 0.018661 lr = 0.0000026\n",
      "[22/25][770/9765] Loss_D: 0.0981 Loss_G: 0.0382 Convergence: 0.1002 k= 0.018673 lr = 0.0000026\n",
      "[22/25][780/9765] Loss_D: 0.0922 Loss_G: 0.0363 Convergence: 0.0937 k= 0.018681 lr = 0.0000026\n",
      "[22/25][790/9765] Loss_D: 0.0953 Loss_G: 0.0384 Convergence: 0.0961 k= 0.018693 lr = 0.0000026\n",
      "[22/25][800/9765] Loss_D: 0.0974 Loss_G: 0.0367 Convergence: 0.1006 k= 0.018713 lr = 0.0000026\n",
      "[22/25][810/9765] Loss_D: 0.0976 Loss_G: 0.0376 Convergence: 0.1001 k= 0.018722 lr = 0.0000026\n",
      "[22/25][820/9765] Loss_D: 0.0942 Loss_G: 0.0393 Convergence: 0.0963 k= 0.018727 lr = 0.0000026\n",
      "[22/25][830/9765] Loss_D: 0.0896 Loss_G: 0.0393 Convergence: 0.0935 k= 0.018734 lr = 0.0000026\n",
      "[22/25][840/9765] Loss_D: 0.0920 Loss_G: 0.0402 Convergence: 0.0959 k= 0.018734 lr = 0.0000026\n",
      "[22/25][850/9765] Loss_D: 0.0924 Loss_G: 0.0378 Convergence: 0.0937 k= 0.018749 lr = 0.0000026\n",
      "[22/25][860/9765] Loss_D: 0.0902 Loss_G: 0.0387 Convergence: 0.0933 k= 0.018745 lr = 0.0000026\n",
      "[22/25][870/9765] Loss_D: 0.0985 Loss_G: 0.0388 Convergence: 0.1001 k= 0.018750 lr = 0.0000026\n",
      "[22/25][880/9765] Loss_D: 0.0950 Loss_G: 0.0380 Convergence: 0.0959 k= 0.018754 lr = 0.0000026\n",
      "[22/25][890/9765] Loss_D: 0.1009 Loss_G: 0.0390 Convergence: 0.1033 k= 0.018753 lr = 0.0000026\n",
      "[22/25][900/9765] Loss_D: 0.1010 Loss_G: 0.0392 Convergence: 0.1032 k= 0.018754 lr = 0.0000026\n",
      "[22/25][910/9765] Loss_D: 0.0874 Loss_G: 0.0383 Convergence: 0.0912 k= 0.018751 lr = 0.0000026\n",
      "[22/25][920/9765] Loss_D: 0.0913 Loss_G: 0.0387 Convergence: 0.0939 k= 0.018751 lr = 0.0000026\n",
      "[22/25][930/9765] Loss_D: 0.0947 Loss_G: 0.0378 Convergence: 0.0958 k= 0.018753 lr = 0.0000026\n",
      "[22/25][940/9765] Loss_D: 0.0962 Loss_G: 0.0380 Convergence: 0.0977 k= 0.018753 lr = 0.0000026\n",
      "[22/25][950/9765] Loss_D: 0.1011 Loss_G: 0.0370 Convergence: 0.1054 k= 0.018756 lr = 0.0000026\n",
      "[22/25][960/9765] Loss_D: 0.0869 Loss_G: 0.0386 Convergence: 0.0912 k= 0.018749 lr = 0.0000026\n",
      "[22/25][970/9765] Loss_D: 0.1023 Loss_G: 0.0375 Convergence: 0.1068 k= 0.018738 lr = 0.0000026\n",
      "[22/25][980/9765] Loss_D: 0.1007 Loss_G: 0.0373 Convergence: 0.1047 k= 0.018752 lr = 0.0000026\n",
      "[22/25][990/9765] Loss_D: 0.0985 Loss_G: 0.0383 Convergence: 0.1007 k= 0.018760 lr = 0.0000026\n",
      "[22/25][1000/9765] Loss_D: 0.1037 Loss_G: 0.0364 Convergence: 0.1097 k= 0.018780 lr = 0.0000026\n",
      "[22/25][1010/9765] Loss_D: 0.0996 Loss_G: 0.0378 Convergence: 0.1027 k= 0.018800 lr = 0.0000026\n",
      "[22/25][1020/9765] Loss_D: 0.1012 Loss_G: 0.0369 Convergence: 0.1057 k= 0.018812 lr = 0.0000026\n",
      "[22/25][1030/9765] Loss_D: 0.0901 Loss_G: 0.0385 Convergence: 0.0930 k= 0.018821 lr = 0.0000026\n",
      "[22/25][1040/9765] Loss_D: 0.0993 Loss_G: 0.0379 Convergence: 0.1021 k= 0.018823 lr = 0.0000026\n",
      "[22/25][1050/9765] Loss_D: 0.0949 Loss_G: 0.0375 Convergence: 0.0963 k= 0.018827 lr = 0.0000026\n",
      "[22/25][1060/9765] Loss_D: 0.0937 Loss_G: 0.0390 Convergence: 0.0957 k= 0.018825 lr = 0.0000026\n",
      "[22/25][1070/9765] Loss_D: 0.0913 Loss_G: 0.0392 Convergence: 0.0944 k= 0.018826 lr = 0.0000026\n",
      "[22/25][1080/9765] Loss_D: 0.0909 Loss_G: 0.0373 Convergence: 0.0922 k= 0.018823 lr = 0.0000026\n",
      "[22/25][1090/9765] Loss_D: 0.0922 Loss_G: 0.0399 Convergence: 0.0956 k= 0.018822 lr = 0.0000026\n",
      "[22/25][1100/9765] Loss_D: 0.0949 Loss_G: 0.0385 Convergence: 0.0958 k= 0.018802 lr = 0.0000026\n",
      "[22/25][1110/9765] Loss_D: 0.0954 Loss_G: 0.0380 Convergence: 0.0966 k= 0.018802 lr = 0.0000026\n",
      "[22/25][1120/9765] Loss_D: 0.0996 Loss_G: 0.0404 Convergence: 0.1006 k= 0.018812 lr = 0.0000026\n",
      "[22/25][1130/9765] Loss_D: 0.0859 Loss_G: 0.0388 Convergence: 0.0908 k= 0.018807 lr = 0.0000026\n",
      "[22/25][1140/9765] Loss_D: 0.0936 Loss_G: 0.0383 Convergence: 0.0948 k= 0.018810 lr = 0.0000026\n",
      "[22/25][1150/9765] Loss_D: 0.0976 Loss_G: 0.0387 Convergence: 0.0990 k= 0.018814 lr = 0.0000026\n",
      "[22/25][1160/9765] Loss_D: 0.0995 Loss_G: 0.0402 Convergence: 0.1003 k= 0.018814 lr = 0.0000026\n",
      "[22/25][1170/9765] Loss_D: 0.0990 Loss_G: 0.0393 Convergence: 0.1003 k= 0.018828 lr = 0.0000025\n",
      "[22/25][1180/9765] Loss_D: 0.0967 Loss_G: 0.0399 Convergence: 0.0984 k= 0.018822 lr = 0.0000025\n",
      "[22/25][1190/9765] Loss_D: 0.0949 Loss_G: 0.0396 Convergence: 0.0969 k= 0.018815 lr = 0.0000025\n",
      "[22/25][1200/9765] Loss_D: 0.0993 Loss_G: 0.0379 Convergence: 0.1021 k= 0.018815 lr = 0.0000025\n",
      "[22/25][1210/9765] Loss_D: 0.0952 Loss_G: 0.0397 Convergence: 0.0973 k= 0.018814 lr = 0.0000025\n",
      "[22/25][1220/9765] Loss_D: 0.0882 Loss_G: 0.0402 Convergence: 0.0936 k= 0.018792 lr = 0.0000025\n",
      "[22/25][1230/9765] Loss_D: 0.0909 Loss_G: 0.0388 Convergence: 0.0938 k= 0.018805 lr = 0.0000025\n",
      "[22/25][1240/9765] Loss_D: 0.0998 Loss_G: 0.0388 Convergence: 0.1019 k= 0.018808 lr = 0.0000025\n",
      "[22/25][1250/9765] Loss_D: 0.0926 Loss_G: 0.0379 Convergence: 0.0939 k= 0.018807 lr = 0.0000025\n",
      "[22/25][1260/9765] Loss_D: 0.1002 Loss_G: 0.0391 Convergence: 0.1022 k= 0.018827 lr = 0.0000025\n",
      "[22/25][1270/9765] Loss_D: 0.0912 Loss_G: 0.0391 Convergence: 0.0943 k= 0.018821 lr = 0.0000025\n",
      "[22/25][1280/9765] Loss_D: 0.0958 Loss_G: 0.0384 Convergence: 0.0967 k= 0.018818 lr = 0.0000025\n",
      "[22/25][1290/9765] Loss_D: 0.1003 Loss_G: 0.0371 Convergence: 0.1044 k= 0.018823 lr = 0.0000025\n",
      "[22/25][1300/9765] Loss_D: 0.0903 Loss_G: 0.0375 Convergence: 0.0921 k= 0.018836 lr = 0.0000025\n",
      "[22/25][1310/9765] Loss_D: 0.0981 Loss_G: 0.0368 Convergence: 0.1015 k= 0.018856 lr = 0.0000025\n",
      "[22/25][1320/9765] Loss_D: 0.1007 Loss_G: 0.0385 Convergence: 0.1035 k= 0.018867 lr = 0.0000025\n",
      "[22/25][1330/9765] Loss_D: 0.0989 Loss_G: 0.0376 Convergence: 0.1018 k= 0.018872 lr = 0.0000025\n",
      "[22/25][1340/9765] Loss_D: 0.0951 Loss_G: 0.0389 Convergence: 0.0964 k= 0.018872 lr = 0.0000025\n",
      "[22/25][1350/9765] Loss_D: 0.0950 Loss_G: 0.0383 Convergence: 0.0957 k= 0.018872 lr = 0.0000025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][1360/9765] Loss_D: 0.0931 Loss_G: 0.0378 Convergence: 0.0941 k= 0.018871 lr = 0.0000025\n",
      "[22/25][1370/9765] Loss_D: 0.1017 Loss_G: 0.0380 Convergence: 0.1054 k= 0.018889 lr = 0.0000025\n",
      "[22/25][1380/9765] Loss_D: 0.0989 Loss_G: 0.0383 Convergence: 0.1011 k= 0.018892 lr = 0.0000025\n",
      "[22/25][1390/9765] Loss_D: 0.0923 Loss_G: 0.0385 Convergence: 0.0943 k= 0.018888 lr = 0.0000025\n",
      "[22/25][1400/9765] Loss_D: 0.0998 Loss_G: 0.0370 Convergence: 0.1036 k= 0.018897 lr = 0.0000025\n",
      "[22/25][1410/9765] Loss_D: 0.1032 Loss_G: 0.0389 Convergence: 0.1066 k= 0.018893 lr = 0.0000025\n",
      "[22/25][1420/9765] Loss_D: 0.0939 Loss_G: 0.0373 Convergence: 0.0952 k= 0.018905 lr = 0.0000025\n",
      "[22/25][1430/9765] Loss_D: 0.0869 Loss_G: 0.0365 Convergence: 0.0890 k= 0.018916 lr = 0.0000025\n",
      "[22/25][1440/9765] Loss_D: 0.1014 Loss_G: 0.0382 Convergence: 0.1047 k= 0.018929 lr = 0.0000025\n",
      "[22/25][1450/9765] Loss_D: 0.0996 Loss_G: 0.0382 Convergence: 0.1023 k= 0.018942 lr = 0.0000025\n",
      "[22/25][1460/9765] Loss_D: 0.0882 Loss_G: 0.0394 Convergence: 0.0927 k= 0.018939 lr = 0.0000025\n",
      "[22/25][1470/9765] Loss_D: 0.0991 Loss_G: 0.0399 Convergence: 0.0999 k= 0.018948 lr = 0.0000025\n",
      "[22/25][1480/9765] Loss_D: 0.0917 Loss_G: 0.0382 Convergence: 0.0937 k= 0.018939 lr = 0.0000025\n",
      "[22/25][1490/9765] Loss_D: 0.0950 Loss_G: 0.0394 Convergence: 0.0969 k= 0.018942 lr = 0.0000025\n",
      "[22/25][1500/9765] Loss_D: 0.0969 Loss_G: 0.0389 Convergence: 0.0978 k= 0.018935 lr = 0.0000025\n",
      "[22/25][1510/9765] Loss_D: 0.0922 Loss_G: 0.0397 Convergence: 0.0955 k= 0.018926 lr = 0.0000025\n",
      "[22/25][1520/9765] Loss_D: 0.0909 Loss_G: 0.0394 Convergence: 0.0944 k= 0.018901 lr = 0.0000025\n",
      "[22/25][1530/9765] Loss_D: 0.0989 Loss_G: 0.0385 Convergence: 0.1010 k= 0.018905 lr = 0.0000025\n",
      "[22/25][1540/9765] Loss_D: 0.0928 Loss_G: 0.0393 Convergence: 0.0955 k= 0.018899 lr = 0.0000025\n",
      "[22/25][1550/9765] Loss_D: 0.1003 Loss_G: 0.0388 Convergence: 0.1026 k= 0.018900 lr = 0.0000025\n",
      "[22/25][1560/9765] Loss_D: 0.1047 Loss_G: 0.0408 Convergence: 0.1068 k= 0.018904 lr = 0.0000025\n",
      "[22/25][1570/9765] Loss_D: 0.0884 Loss_G: 0.0386 Convergence: 0.0921 k= 0.018894 lr = 0.0000025\n",
      "[22/25][1580/9765] Loss_D: 0.0968 Loss_G: 0.0377 Convergence: 0.0989 k= 0.018899 lr = 0.0000025\n",
      "[22/25][1590/9765] Loss_D: 0.0955 Loss_G: 0.0388 Convergence: 0.0965 k= 0.018893 lr = 0.0000025\n",
      "[22/25][1600/9765] Loss_D: 0.0917 Loss_G: 0.0381 Convergence: 0.0936 k= 0.018896 lr = 0.0000025\n",
      "[22/25][1610/9765] Loss_D: 0.1070 Loss_G: 0.0377 Convergence: 0.1130 k= 0.018912 lr = 0.0000025\n",
      "[22/25][1620/9765] Loss_D: 0.0971 Loss_G: 0.0367 Convergence: 0.1002 k= 0.018927 lr = 0.0000025\n",
      "[22/25][1630/9765] Loss_D: 0.0927 Loss_G: 0.0360 Convergence: 0.0948 k= 0.018938 lr = 0.0000025\n",
      "[22/25][1640/9765] Loss_D: 0.1012 Loss_G: 0.0365 Convergence: 0.1062 k= 0.018964 lr = 0.0000025\n",
      "[22/25][1650/9765] Loss_D: 0.1008 Loss_G: 0.0383 Convergence: 0.1038 k= 0.018970 lr = 0.0000025\n",
      "[22/25][1660/9765] Loss_D: 0.1003 Loss_G: 0.0380 Convergence: 0.1035 k= 0.018984 lr = 0.0000025\n",
      "[22/25][1670/9765] Loss_D: 0.0948 Loss_G: 0.0369 Convergence: 0.0968 k= 0.018989 lr = 0.0000025\n",
      "[22/25][1680/9765] Loss_D: 0.1106 Loss_G: 0.0390 Convergence: 0.1169 k= 0.019001 lr = 0.0000025\n",
      "[22/25][1690/9765] Loss_D: 0.0997 Loss_G: 0.0369 Convergence: 0.1036 k= 0.019001 lr = 0.0000025\n",
      "[22/25][1700/9765] Loss_D: 0.1015 Loss_G: 0.0369 Convergence: 0.1062 k= 0.019013 lr = 0.0000025\n",
      "[22/25][1710/9765] Loss_D: 0.0897 Loss_G: 0.0380 Convergence: 0.0922 k= 0.019029 lr = 0.0000025\n",
      "[22/25][1720/9765] Loss_D: 0.1006 Loss_G: 0.0383 Convergence: 0.1036 k= 0.019040 lr = 0.0000025\n",
      "[22/25][1730/9765] Loss_D: 0.0968 Loss_G: 0.0391 Convergence: 0.0976 k= 0.019038 lr = 0.0000025\n",
      "[22/25][1740/9765] Loss_D: 0.1014 Loss_G: 0.0401 Convergence: 0.1029 k= 0.019035 lr = 0.0000025\n",
      "[22/25][1750/9765] Loss_D: 0.0993 Loss_G: 0.0403 Convergence: 0.1003 k= 0.019023 lr = 0.0000025\n",
      "[22/25][1760/9765] Loss_D: 0.0989 Loss_G: 0.0420 Convergence: 0.1018 k= 0.018998 lr = 0.0000025\n",
      "[22/25][1770/9765] Loss_D: 0.1019 Loss_G: 0.0422 Convergence: 0.1038 k= 0.018971 lr = 0.0000025\n",
      "[22/25][1780/9765] Loss_D: 0.0970 Loss_G: 0.0406 Convergence: 0.0993 k= 0.018951 lr = 0.0000025\n",
      "[22/25][1790/9765] Loss_D: 0.0982 Loss_G: 0.0398 Convergence: 0.0992 k= 0.018938 lr = 0.0000025\n",
      "[22/25][1800/9765] Loss_D: 0.0964 Loss_G: 0.0382 Convergence: 0.0977 k= 0.018933 lr = 0.0000025\n",
      "[22/25][1810/9765] Loss_D: 0.0855 Loss_G: 0.0391 Convergence: 0.0908 k= 0.018929 lr = 0.0000025\n",
      "[22/25][1820/9765] Loss_D: 0.0903 Loss_G: 0.0380 Convergence: 0.0926 k= 0.018926 lr = 0.0000025\n",
      "[22/25][1830/9765] Loss_D: 0.0959 Loss_G: 0.0378 Convergence: 0.0975 k= 0.018913 lr = 0.0000025\n",
      "[22/25][1840/9765] Loss_D: 0.1046 Loss_G: 0.0387 Convergence: 0.1088 k= 0.018925 lr = 0.0000025\n",
      "[22/25][1850/9765] Loss_D: 0.0890 Loss_G: 0.0374 Convergence: 0.0913 k= 0.018937 lr = 0.0000025\n",
      "[22/25][1860/9765] Loss_D: 0.1063 Loss_G: 0.0378 Convergence: 0.1120 k= 0.018954 lr = 0.0000025\n",
      "[22/25][1870/9765] Loss_D: 0.0866 Loss_G: 0.0383 Convergence: 0.0907 k= 0.018966 lr = 0.0000025\n",
      "[22/25][1880/9765] Loss_D: 0.1023 Loss_G: 0.0392 Convergence: 0.1051 k= 0.018983 lr = 0.0000025\n",
      "[22/25][1890/9765] Loss_D: 0.0939 Loss_G: 0.0396 Convergence: 0.0964 k= 0.018985 lr = 0.0000025\n",
      "[22/25][1900/9765] Loss_D: 0.0925 Loss_G: 0.0373 Convergence: 0.0932 k= 0.018986 lr = 0.0000025\n",
      "[22/25][1910/9765] Loss_D: 0.1058 Loss_G: 0.0373 Convergence: 0.1118 k= 0.018998 lr = 0.0000025\n",
      "[22/25][1920/9765] Loss_D: 0.0839 Loss_G: 0.0378 Convergence: 0.0886 k= 0.019006 lr = 0.0000025\n",
      "[22/25][1930/9765] Loss_D: 0.0952 Loss_G: 0.0375 Convergence: 0.0969 k= 0.019014 lr = 0.0000025\n",
      "[22/25][1940/9765] Loss_D: 0.0984 Loss_G: 0.0384 Convergence: 0.1004 k= 0.019023 lr = 0.0000025\n",
      "[22/25][1950/9765] Loss_D: 0.1023 Loss_G: 0.0378 Convergence: 0.1065 k= 0.019029 lr = 0.0000025\n",
      "[22/25][1960/9765] Loss_D: 0.1062 Loss_G: 0.0394 Convergence: 0.1103 k= 0.019021 lr = 0.0000025\n",
      "[22/25][1970/9765] Loss_D: 0.0879 Loss_G: 0.0395 Convergence: 0.0927 k= 0.019015 lr = 0.0000025\n",
      "[22/25][1980/9765] Loss_D: 0.1063 Loss_G: 0.0400 Convergence: 0.1099 k= 0.019013 lr = 0.0000025\n",
      "[22/25][1990/9765] Loss_D: 0.0859 Loss_G: 0.0391 Convergence: 0.0911 k= 0.018985 lr = 0.0000025\n",
      "[22/25][2000/9765] Loss_D: 0.0903 Loss_G: 0.0391 Convergence: 0.0937 k= 0.018972 lr = 0.0000025\n",
      "[22/25][2010/9765] Loss_D: 0.0906 Loss_G: 0.0378 Convergence: 0.0925 k= 0.018974 lr = 0.0000025\n",
      "[22/25][2020/9765] Loss_D: 0.1028 Loss_G: 0.0397 Convergence: 0.1052 k= 0.018968 lr = 0.0000025\n",
      "[22/25][2030/9765] Loss_D: 0.0991 Loss_G: 0.0384 Convergence: 0.1014 k= 0.018970 lr = 0.0000025\n",
      "[22/25][2040/9765] Loss_D: 0.0896 Loss_G: 0.0378 Convergence: 0.0920 k= 0.018966 lr = 0.0000025\n",
      "[22/25][2050/9765] Loss_D: 0.0968 Loss_G: 0.0384 Convergence: 0.0982 k= 0.018968 lr = 0.0000025\n",
      "[22/25][2060/9765] Loss_D: 0.0972 Loss_G: 0.0406 Convergence: 0.0993 k= 0.018959 lr = 0.0000025\n",
      "[22/25][2070/9765] Loss_D: 0.0944 Loss_G: 0.0388 Convergence: 0.0959 k= 0.018939 lr = 0.0000025\n",
      "[22/25][2080/9765] Loss_D: 0.0934 Loss_G: 0.0379 Convergence: 0.0944 k= 0.018938 lr = 0.0000025\n",
      "[22/25][2090/9765] Loss_D: 0.1040 Loss_G: 0.0387 Convergence: 0.1079 k= 0.018937 lr = 0.0000025\n",
      "[22/25][2100/9765] Loss_D: 0.0962 Loss_G: 0.0378 Convergence: 0.0979 k= 0.018949 lr = 0.0000025\n",
      "[22/25][2110/9765] Loss_D: 0.1007 Loss_G: 0.0379 Convergence: 0.1040 k= 0.018941 lr = 0.0000025\n",
      "[22/25][2120/9765] Loss_D: 0.1094 Loss_G: 0.0388 Convergence: 0.1153 k= 0.018937 lr = 0.0000025\n",
      "[22/25][2130/9765] Loss_D: 0.0926 Loss_G: 0.0398 Convergence: 0.0958 k= 0.018932 lr = 0.0000025\n",
      "[22/25][2140/9765] Loss_D: 0.0882 Loss_G: 0.0389 Convergence: 0.0922 k= 0.018929 lr = 0.0000025\n",
      "[22/25][2150/9765] Loss_D: 0.0977 Loss_G: 0.0390 Convergence: 0.0988 k= 0.018918 lr = 0.0000025\n",
      "[22/25][2160/9765] Loss_D: 0.0909 Loss_G: 0.0385 Convergence: 0.0935 k= 0.018911 lr = 0.0000025\n",
      "[22/25][2170/9765] Loss_D: 0.1120 Loss_G: 0.0377 Convergence: 0.1201 k= 0.018934 lr = 0.0000025\n",
      "[22/25][2180/9765] Loss_D: 0.0941 Loss_G: 0.0373 Convergence: 0.0954 k= 0.018932 lr = 0.0000025\n",
      "[22/25][2190/9765] Loss_D: 0.0945 Loss_G: 0.0367 Convergence: 0.0966 k= 0.018932 lr = 0.0000025\n",
      "[22/25][2200/9765] Loss_D: 0.0956 Loss_G: 0.0379 Convergence: 0.0970 k= 0.018933 lr = 0.0000025\n",
      "[22/25][2210/9765] Loss_D: 0.0950 Loss_G: 0.0395 Convergence: 0.0969 k= 0.018941 lr = 0.0000025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][2220/9765] Loss_D: 0.0877 Loss_G: 0.0394 Convergence: 0.0925 k= 0.018935 lr = 0.0000025\n",
      "[22/25][2230/9765] Loss_D: 0.1035 Loss_G: 0.0391 Convergence: 0.1068 k= 0.018951 lr = 0.0000025\n",
      "[22/25][2240/9765] Loss_D: 0.0895 Loss_G: 0.0384 Convergence: 0.0925 k= 0.018952 lr = 0.0000025\n",
      "[22/25][2250/9765] Loss_D: 0.0922 Loss_G: 0.0380 Convergence: 0.0938 k= 0.018940 lr = 0.0000025\n",
      "[22/25][2260/9765] Loss_D: 0.0940 Loss_G: 0.0380 Convergence: 0.0948 k= 0.018944 lr = 0.0000025\n",
      "[22/25][2270/9765] Loss_D: 0.1032 Loss_G: 0.0385 Convergence: 0.1070 k= 0.018948 lr = 0.0000025\n",
      "[22/25][2280/9765] Loss_D: 0.0930 Loss_G: 0.0375 Convergence: 0.0937 k= 0.018949 lr = 0.0000025\n",
      "[22/25][2290/9765] Loss_D: 0.0938 Loss_G: 0.0378 Convergence: 0.0946 k= 0.018954 lr = 0.0000025\n",
      "[22/25][2300/9765] Loss_D: 0.1022 Loss_G: 0.0402 Convergence: 0.1040 k= 0.018959 lr = 0.0000025\n",
      "[22/25][2310/9765] Loss_D: 0.0974 Loss_G: 0.0389 Convergence: 0.0985 k= 0.018948 lr = 0.0000025\n",
      "[22/25][2320/9765] Loss_D: 0.0943 Loss_G: 0.0405 Convergence: 0.0975 k= 0.018927 lr = 0.0000025\n",
      "[22/25][2330/9765] Loss_D: 0.0985 Loss_G: 0.0387 Convergence: 0.1002 k= 0.018924 lr = 0.0000025\n",
      "[22/25][2340/9765] Loss_D: 0.0952 Loss_G: 0.0388 Convergence: 0.0964 k= 0.018932 lr = 0.0000025\n",
      "[22/25][2350/9765] Loss_D: 0.0972 Loss_G: 0.0383 Convergence: 0.0988 k= 0.018933 lr = 0.0000025\n",
      "[22/25][2360/9765] Loss_D: 0.0891 Loss_G: 0.0382 Convergence: 0.0921 k= 0.018935 lr = 0.0000025\n",
      "[22/25][2370/9765] Loss_D: 0.1015 Loss_G: 0.0382 Convergence: 0.1050 k= 0.018941 lr = 0.0000025\n",
      "[22/25][2380/9765] Loss_D: 0.0967 Loss_G: 0.0380 Convergence: 0.0984 k= 0.018940 lr = 0.0000025\n",
      "[22/25][2390/9765] Loss_D: 0.0972 Loss_G: 0.0397 Convergence: 0.0985 k= 0.018945 lr = 0.0000025\n",
      "[22/25][2400/9765] Loss_D: 0.0908 Loss_G: 0.0383 Convergence: 0.0932 k= 0.018930 lr = 0.0000025\n",
      "[22/25][2410/9765] Loss_D: 0.0894 Loss_G: 0.0390 Convergence: 0.0931 k= 0.018926 lr = 0.0000025\n",
      "[22/25][2420/9765] Loss_D: 0.0965 Loss_G: 0.0378 Convergence: 0.0983 k= 0.018928 lr = 0.0000025\n",
      "[22/25][2430/9765] Loss_D: 0.0988 Loss_G: 0.0392 Convergence: 0.1002 k= 0.018915 lr = 0.0000025\n",
      "[22/25][2440/9765] Loss_D: 0.1023 Loss_G: 0.0399 Convergence: 0.1044 k= 0.018900 lr = 0.0000025\n",
      "[22/25][2450/9765] Loss_D: 0.1066 Loss_G: 0.0408 Convergence: 0.1096 k= 0.018900 lr = 0.0000025\n",
      "[22/25][2460/9765] Loss_D: 0.0984 Loss_G: 0.0399 Convergence: 0.0994 k= 0.018895 lr = 0.0000025\n",
      "[22/25][2470/9765] Loss_D: 0.1018 Loss_G: 0.0400 Convergence: 0.1036 k= 0.018896 lr = 0.0000025\n",
      "[22/25][2480/9765] Loss_D: 0.0912 Loss_G: 0.0399 Convergence: 0.0951 k= 0.018889 lr = 0.0000025\n",
      "[22/25][2490/9765] Loss_D: 0.1035 Loss_G: 0.0394 Convergence: 0.1065 k= 0.018878 lr = 0.0000025\n",
      "[22/25][2500/9765] Loss_D: 0.0959 Loss_G: 0.0389 Convergence: 0.0969 k= 0.018877 lr = 0.0000025\n",
      "[22/25][2510/9765] Loss_D: 0.0959 Loss_G: 0.0390 Convergence: 0.0970 k= 0.018879 lr = 0.0000025\n",
      "[22/25][2520/9765] Loss_D: 0.0847 Loss_G: 0.0393 Convergence: 0.0906 k= 0.018860 lr = 0.0000025\n",
      "[22/25][2530/9765] Loss_D: 0.0878 Loss_G: 0.0392 Convergence: 0.0923 k= 0.018838 lr = 0.0000025\n",
      "[22/25][2540/9765] Loss_D: 0.1087 Loss_G: 0.0388 Convergence: 0.1143 k= 0.018833 lr = 0.0000025\n",
      "[22/25][2550/9765] Loss_D: 0.0958 Loss_G: 0.0393 Convergence: 0.0972 k= 0.018830 lr = 0.0000025\n",
      "[22/25][2560/9765] Loss_D: 0.0930 Loss_G: 0.0382 Convergence: 0.0945 k= 0.018827 lr = 0.0000025\n",
      "[22/25][2570/9765] Loss_D: 0.1025 Loss_G: 0.0391 Convergence: 0.1054 k= 0.018835 lr = 0.0000025\n",
      "[22/25][2580/9765] Loss_D: 0.0996 Loss_G: 0.0403 Convergence: 0.1005 k= 0.018822 lr = 0.0000025\n",
      "[22/25][2590/9765] Loss_D: 0.1069 Loss_G: 0.0399 Convergence: 0.1108 k= 0.018806 lr = 0.0000025\n",
      "[22/25][2600/9765] Loss_D: 0.1009 Loss_G: 0.0389 Convergence: 0.1034 k= 0.018802 lr = 0.0000025\n",
      "[22/25][2610/9765] Loss_D: 0.0988 Loss_G: 0.0378 Convergence: 0.1015 k= 0.018819 lr = 0.0000025\n",
      "[22/25][2620/9765] Loss_D: 0.0895 Loss_G: 0.0378 Convergence: 0.0919 k= 0.018831 lr = 0.0000025\n",
      "[22/25][2630/9765] Loss_D: 0.1006 Loss_G: 0.0373 Convergence: 0.1045 k= 0.018851 lr = 0.0000025\n",
      "[22/25][2640/9765] Loss_D: 0.0835 Loss_G: 0.0378 Convergence: 0.0884 k= 0.018856 lr = 0.0000025\n",
      "[22/25][2650/9765] Loss_D: 0.0940 Loss_G: 0.0378 Convergence: 0.0948 k= 0.018865 lr = 0.0000025\n",
      "[22/25][2660/9765] Loss_D: 0.1052 Loss_G: 0.0390 Convergence: 0.1093 k= 0.018858 lr = 0.0000025\n",
      "[22/25][2670/9765] Loss_D: 0.0913 Loss_G: 0.0388 Convergence: 0.0940 k= 0.018861 lr = 0.0000025\n",
      "[22/25][2680/9765] Loss_D: 0.0941 Loss_G: 0.0376 Convergence: 0.0951 k= 0.018865 lr = 0.0000025\n",
      "[22/25][2690/9765] Loss_D: 0.0900 Loss_G: 0.0389 Convergence: 0.0933 k= 0.018863 lr = 0.0000025\n",
      "[22/25][2700/9765] Loss_D: 0.0953 Loss_G: 0.0404 Convergence: 0.0981 k= 0.018852 lr = 0.0000025\n",
      "[22/25][2710/9765] Loss_D: 0.0990 Loss_G: 0.0385 Convergence: 0.1011 k= 0.018847 lr = 0.0000025\n",
      "[22/25][2720/9765] Loss_D: 0.1004 Loss_G: 0.0401 Convergence: 0.1015 k= 0.018857 lr = 0.0000025\n",
      "[22/25][2730/9765] Loss_D: 0.0889 Loss_G: 0.0395 Convergence: 0.0932 k= 0.018842 lr = 0.0000025\n",
      "[22/25][2740/9765] Loss_D: 0.1012 Loss_G: 0.0407 Convergence: 0.1021 k= 0.018832 lr = 0.0000025\n",
      "[22/25][2750/9765] Loss_D: 0.0960 Loss_G: 0.0399 Convergence: 0.0979 k= 0.018816 lr = 0.0000025\n",
      "[22/25][2760/9765] Loss_D: 0.0932 Loss_G: 0.0386 Convergence: 0.0950 k= 0.018812 lr = 0.0000025\n",
      "[22/25][2770/9765] Loss_D: 0.0975 Loss_G: 0.0390 Convergence: 0.0985 k= 0.018820 lr = 0.0000025\n",
      "[22/25][2780/9765] Loss_D: 0.0988 Loss_G: 0.0393 Convergence: 0.1000 k= 0.018823 lr = 0.0000025\n",
      "[22/25][2790/9765] Loss_D: 0.0959 Loss_G: 0.0374 Convergence: 0.0978 k= 0.018829 lr = 0.0000025\n",
      "[22/25][2800/9765] Loss_D: 0.0928 Loss_G: 0.0374 Convergence: 0.0936 k= 0.018833 lr = 0.0000025\n",
      "[22/25][2810/9765] Loss_D: 0.1016 Loss_G: 0.0374 Convergence: 0.1057 k= 0.018845 lr = 0.0000025\n",
      "[22/25][2820/9765] Loss_D: 0.0973 Loss_G: 0.0372 Convergence: 0.1000 k= 0.018851 lr = 0.0000025\n",
      "[22/25][2830/9765] Loss_D: 0.0966 Loss_G: 0.0376 Convergence: 0.0986 k= 0.018857 lr = 0.0000025\n",
      "[22/25][2840/9765] Loss_D: 0.0954 Loss_G: 0.0371 Convergence: 0.0974 k= 0.018866 lr = 0.0000025\n",
      "[22/25][2850/9765] Loss_D: 0.1017 Loss_G: 0.0377 Convergence: 0.1057 k= 0.018883 lr = 0.0000025\n",
      "[22/25][2860/9765] Loss_D: 0.0971 Loss_G: 0.0383 Convergence: 0.0986 k= 0.018883 lr = 0.0000025\n",
      "[22/25][2870/9765] Loss_D: 0.1002 Loss_G: 0.0379 Convergence: 0.1034 k= 0.018881 lr = 0.0000025\n",
      "[22/25][2880/9765] Loss_D: 0.0977 Loss_G: 0.0390 Convergence: 0.0988 k= 0.018884 lr = 0.0000025\n",
      "[22/25][2890/9765] Loss_D: 0.0977 Loss_G: 0.0389 Convergence: 0.0989 k= 0.018880 lr = 0.0000025\n",
      "[22/25][2900/9765] Loss_D: 0.0918 Loss_G: 0.0391 Convergence: 0.0946 k= 0.018873 lr = 0.0000025\n",
      "[22/25][2910/9765] Loss_D: 0.0970 Loss_G: 0.0386 Convergence: 0.0983 k= 0.018859 lr = 0.0000025\n",
      "[22/25][2920/9765] Loss_D: 0.0953 Loss_G: 0.0394 Convergence: 0.0971 k= 0.018858 lr = 0.0000025\n",
      "[22/25][2930/9765] Loss_D: 0.0966 Loss_G: 0.0410 Convergence: 0.0994 k= 0.018838 lr = 0.0000025\n",
      "[22/25][2940/9765] Loss_D: 0.1008 Loss_G: 0.0393 Convergence: 0.1029 k= 0.018818 lr = 0.0000025\n",
      "[22/25][2950/9765] Loss_D: 0.1022 Loss_G: 0.0397 Convergence: 0.1044 k= 0.018809 lr = 0.0000025\n",
      "[22/25][2960/9765] Loss_D: 0.1013 Loss_G: 0.0392 Convergence: 0.1037 k= 0.018791 lr = 0.0000025\n",
      "[22/25][2970/9765] Loss_D: 0.0909 Loss_G: 0.0405 Convergence: 0.0954 k= 0.018765 lr = 0.0000025\n",
      "[22/25][2980/9765] Loss_D: 0.0923 Loss_G: 0.0401 Convergence: 0.0959 k= 0.018758 lr = 0.0000025\n",
      "[22/25][2990/9765] Loss_D: 0.0907 Loss_G: 0.0397 Convergence: 0.0946 k= 0.018750 lr = 0.0000025\n",
      "[22/25][3000/9765] Loss_D: 0.0902 Loss_G: 0.0391 Convergence: 0.0936 k= 0.018758 lr = 0.0000025\n",
      "[22/25][3010/9765] Loss_D: 0.0959 Loss_G: 0.0396 Convergence: 0.0976 k= 0.018753 lr = 0.0000025\n",
      "[22/25][3020/9765] Loss_D: 0.0923 Loss_G: 0.0396 Convergence: 0.0954 k= 0.018749 lr = 0.0000025\n",
      "[22/25][3030/9765] Loss_D: 0.0914 Loss_G: 0.0382 Convergence: 0.0935 k= 0.018754 lr = 0.0000025\n",
      "[22/25][3040/9765] Loss_D: 0.0954 Loss_G: 0.0377 Convergence: 0.0968 k= 0.018756 lr = 0.0000025\n",
      "[22/25][3050/9765] Loss_D: 0.1008 Loss_G: 0.0385 Convergence: 0.1036 k= 0.018771 lr = 0.0000025\n",
      "[22/25][3060/9765] Loss_D: 0.0901 Loss_G: 0.0371 Convergence: 0.0916 k= 0.018775 lr = 0.0000025\n",
      "[22/25][3070/9765] Loss_D: 0.0929 Loss_G: 0.0380 Convergence: 0.0942 k= 0.018783 lr = 0.0000025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][3080/9765] Loss_D: 0.0984 Loss_G: 0.0395 Convergence: 0.0993 k= 0.018784 lr = 0.0000025\n",
      "[22/25][3090/9765] Loss_D: 0.1059 Loss_G: 0.0383 Convergence: 0.1110 k= 0.018793 lr = 0.0000025\n",
      "[22/25][3100/9765] Loss_D: 0.0931 Loss_G: 0.0374 Convergence: 0.0940 k= 0.018797 lr = 0.0000025\n",
      "[22/25][3110/9765] Loss_D: 0.0918 Loss_G: 0.0361 Convergence: 0.0934 k= 0.018808 lr = 0.0000025\n",
      "[22/25][3120/9765] Loss_D: 0.0977 Loss_G: 0.0365 Convergence: 0.1013 k= 0.018829 lr = 0.0000025\n",
      "[22/25][3130/9765] Loss_D: 0.0914 Loss_G: 0.0378 Convergence: 0.0931 k= 0.018847 lr = 0.0000025\n",
      "[22/25][3140/9765] Loss_D: 0.1005 Loss_G: 0.0384 Convergence: 0.1033 k= 0.018854 lr = 0.0000025\n",
      "[22/25][3150/9765] Loss_D: 0.0885 Loss_G: 0.0381 Convergence: 0.0917 k= 0.018846 lr = 0.0000025\n",
      "[22/25][3160/9765] Loss_D: 0.0896 Loss_G: 0.0395 Convergence: 0.0938 k= 0.018849 lr = 0.0000025\n",
      "[22/25][3170/9765] Loss_D: 0.0966 Loss_G: 0.0408 Convergence: 0.0992 k= 0.018844 lr = 0.0000025\n",
      "[22/25][3180/9765] Loss_D: 0.1137 Loss_G: 0.0396 Convergence: 0.1207 k= 0.018842 lr = 0.0000025\n",
      "[22/25][3190/9765] Loss_D: 0.0921 Loss_G: 0.0407 Convergence: 0.0965 k= 0.018831 lr = 0.0000025\n",
      "[22/25][3200/9765] Loss_D: 0.0945 Loss_G: 0.0390 Convergence: 0.0961 k= 0.018827 lr = 0.0000025\n",
      "[22/25][3210/9765] Loss_D: 0.0991 Loss_G: 0.0380 Convergence: 0.1017 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3220/9765] Loss_D: 0.0955 Loss_G: 0.0375 Convergence: 0.0972 k= 0.018807 lr = 0.0000025\n",
      "[22/25][3230/9765] Loss_D: 0.1003 Loss_G: 0.0383 Convergence: 0.1031 k= 0.018818 lr = 0.0000025\n",
      "[22/25][3240/9765] Loss_D: 0.0936 Loss_G: 0.0379 Convergence: 0.0945 k= 0.018821 lr = 0.0000025\n",
      "[22/25][3250/9765] Loss_D: 0.0971 Loss_G: 0.0397 Convergence: 0.0985 k= 0.018819 lr = 0.0000025\n",
      "[22/25][3260/9765] Loss_D: 0.0941 Loss_G: 0.0391 Convergence: 0.0961 k= 0.018815 lr = 0.0000025\n",
      "[22/25][3270/9765] Loss_D: 0.0972 Loss_G: 0.0393 Convergence: 0.0981 k= 0.018810 lr = 0.0000025\n",
      "[22/25][3280/9765] Loss_D: 0.0878 Loss_G: 0.0377 Convergence: 0.0909 k= 0.018813 lr = 0.0000025\n",
      "[22/25][3290/9765] Loss_D: 0.0916 Loss_G: 0.0396 Convergence: 0.0950 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3300/9765] Loss_D: 0.0938 Loss_G: 0.0387 Convergence: 0.0954 k= 0.018822 lr = 0.0000025\n",
      "[22/25][3310/9765] Loss_D: 0.0894 Loss_G: 0.0372 Convergence: 0.0912 k= 0.018818 lr = 0.0000025\n",
      "[22/25][3320/9765] Loss_D: 0.0923 Loss_G: 0.0375 Convergence: 0.0933 k= 0.018829 lr = 0.0000025\n",
      "[22/25][3330/9765] Loss_D: 0.1042 Loss_G: 0.0370 Convergence: 0.1098 k= 0.018840 lr = 0.0000025\n",
      "[22/25][3340/9765] Loss_D: 0.0919 Loss_G: 0.0378 Convergence: 0.0934 k= 0.018846 lr = 0.0000025\n",
      "[22/25][3350/9765] Loss_D: 0.1076 Loss_G: 0.0374 Convergence: 0.1141 k= 0.018850 lr = 0.0000025\n",
      "[22/25][3360/9765] Loss_D: 0.0898 Loss_G: 0.0387 Convergence: 0.0930 k= 0.018850 lr = 0.0000025\n",
      "[22/25][3370/9765] Loss_D: 0.0888 Loss_G: 0.0379 Convergence: 0.0916 k= 0.018850 lr = 0.0000025\n",
      "[22/25][3380/9765] Loss_D: 0.0993 Loss_G: 0.0379 Convergence: 0.1021 k= 0.018854 lr = 0.0000025\n",
      "[22/25][3390/9765] Loss_D: 0.0961 Loss_G: 0.0383 Convergence: 0.0973 k= 0.018854 lr = 0.0000025\n",
      "[22/25][3400/9765] Loss_D: 0.1025 Loss_G: 0.0388 Convergence: 0.1057 k= 0.018854 lr = 0.0000025\n",
      "[22/25][3410/9765] Loss_D: 0.1038 Loss_G: 0.0388 Convergence: 0.1075 k= 0.018862 lr = 0.0000025\n",
      "[22/25][3420/9765] Loss_D: 0.0929 Loss_G: 0.0412 Convergence: 0.0974 k= 0.018840 lr = 0.0000025\n",
      "[22/25][3430/9765] Loss_D: 0.0879 Loss_G: 0.0406 Convergence: 0.0938 k= 0.018810 lr = 0.0000025\n",
      "[22/25][3440/9765] Loss_D: 0.0987 Loss_G: 0.0403 Convergence: 0.0999 k= 0.018798 lr = 0.0000025\n",
      "[22/25][3450/9765] Loss_D: 0.0994 Loss_G: 0.0399 Convergence: 0.1002 k= 0.018780 lr = 0.0000025\n",
      "[22/25][3460/9765] Loss_D: 0.1037 Loss_G: 0.0381 Convergence: 0.1081 k= 0.018781 lr = 0.0000025\n",
      "[22/25][3470/9765] Loss_D: 0.1036 Loss_G: 0.0370 Convergence: 0.1090 k= 0.018781 lr = 0.0000025\n",
      "[22/25][3480/9765] Loss_D: 0.0977 Loss_G: 0.0386 Convergence: 0.0991 k= 0.018811 lr = 0.0000025\n",
      "[22/25][3490/9765] Loss_D: 0.0972 Loss_G: 0.0383 Convergence: 0.0988 k= 0.018811 lr = 0.0000025\n",
      "[22/25][3500/9765] Loss_D: 0.0950 Loss_G: 0.0379 Convergence: 0.0960 k= 0.018808 lr = 0.0000025\n",
      "[22/25][3510/9765] Loss_D: 0.0948 Loss_G: 0.0382 Convergence: 0.0955 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3520/9765] Loss_D: 0.0865 Loss_G: 0.0389 Convergence: 0.0913 k= 0.018810 lr = 0.0000025\n",
      "[22/25][3530/9765] Loss_D: 0.0936 Loss_G: 0.0400 Convergence: 0.0966 k= 0.018801 lr = 0.0000025\n",
      "[22/25][3540/9765] Loss_D: 0.1074 Loss_G: 0.0394 Convergence: 0.1120 k= 0.018799 lr = 0.0000025\n",
      "[22/25][3550/9765] Loss_D: 0.0951 Loss_G: 0.0380 Convergence: 0.0961 k= 0.018800 lr = 0.0000025\n",
      "[22/25][3560/9765] Loss_D: 0.0978 Loss_G: 0.0393 Convergence: 0.0986 k= 0.018795 lr = 0.0000025\n",
      "[22/25][3570/9765] Loss_D: 0.1004 Loss_G: 0.0400 Convergence: 0.1016 k= 0.018783 lr = 0.0000025\n",
      "[22/25][3580/9765] Loss_D: 0.0977 Loss_G: 0.0391 Convergence: 0.0988 k= 0.018777 lr = 0.0000025\n",
      "[22/25][3590/9765] Loss_D: 0.0898 Loss_G: 0.0391 Convergence: 0.0934 k= 0.018764 lr = 0.0000025\n",
      "[22/25][3600/9765] Loss_D: 0.0984 Loss_G: 0.0400 Convergence: 0.0995 k= 0.018760 lr = 0.0000025\n",
      "[22/25][3610/9765] Loss_D: 0.0964 Loss_G: 0.0404 Convergence: 0.0987 k= 0.018744 lr = 0.0000025\n",
      "[22/25][3620/9765] Loss_D: 0.0928 Loss_G: 0.0384 Convergence: 0.0945 k= 0.018733 lr = 0.0000025\n",
      "[22/25][3630/9765] Loss_D: 0.0944 Loss_G: 0.0401 Convergence: 0.0972 k= 0.018726 lr = 0.0000025\n",
      "[22/25][3640/9765] Loss_D: 0.0990 Loss_G: 0.0390 Convergence: 0.1007 k= 0.018719 lr = 0.0000025\n",
      "[22/25][3650/9765] Loss_D: 0.1030 Loss_G: 0.0399 Convergence: 0.1054 k= 0.018715 lr = 0.0000025\n",
      "[22/25][3660/9765] Loss_D: 0.0939 Loss_G: 0.0385 Convergence: 0.0953 k= 0.018713 lr = 0.0000025\n",
      "[22/25][3670/9765] Loss_D: 0.0991 Loss_G: 0.0384 Convergence: 0.1013 k= 0.018719 lr = 0.0000025\n",
      "[22/25][3680/9765] Loss_D: 0.0855 Loss_G: 0.0388 Convergence: 0.0905 k= 0.018716 lr = 0.0000025\n",
      "[22/25][3690/9765] Loss_D: 0.0903 Loss_G: 0.0371 Convergence: 0.0917 k= 0.018719 lr = 0.0000025\n",
      "[22/25][3700/9765] Loss_D: 0.0894 Loss_G: 0.0371 Convergence: 0.0911 k= 0.018722 lr = 0.0000025\n",
      "[22/25][3710/9765] Loss_D: 0.0932 Loss_G: 0.0371 Convergence: 0.0944 k= 0.018729 lr = 0.0000025\n",
      "[22/25][3720/9765] Loss_D: 0.0993 Loss_G: 0.0376 Convergence: 0.1024 k= 0.018745 lr = 0.0000025\n",
      "[22/25][3730/9765] Loss_D: 0.0913 Loss_G: 0.0381 Convergence: 0.0933 k= 0.018761 lr = 0.0000025\n",
      "[22/25][3740/9765] Loss_D: 0.0980 Loss_G: 0.0386 Convergence: 0.0997 k= 0.018775 lr = 0.0000025\n",
      "[22/25][3750/9765] Loss_D: 0.0979 Loss_G: 0.0374 Convergence: 0.1006 k= 0.018787 lr = 0.0000025\n",
      "[22/25][3760/9765] Loss_D: 0.1016 Loss_G: 0.0369 Convergence: 0.1064 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3770/9765] Loss_D: 0.0914 Loss_G: 0.0374 Convergence: 0.0927 k= 0.018824 lr = 0.0000025\n",
      "[22/25][3780/9765] Loss_D: 0.0965 Loss_G: 0.0388 Convergence: 0.0973 k= 0.018831 lr = 0.0000025\n",
      "[22/25][3790/9765] Loss_D: 0.0875 Loss_G: 0.0372 Convergence: 0.0901 k= 0.018837 lr = 0.0000025\n",
      "[22/25][3800/9765] Loss_D: 0.0946 Loss_G: 0.0392 Convergence: 0.0964 k= 0.018848 lr = 0.0000025\n",
      "[22/25][3810/9765] Loss_D: 0.0962 Loss_G: 0.0387 Convergence: 0.0970 k= 0.018852 lr = 0.0000025\n",
      "[22/25][3820/9765] Loss_D: 0.0935 Loss_G: 0.0386 Convergence: 0.0952 k= 0.018853 lr = 0.0000025\n",
      "[22/25][3830/9765] Loss_D: 0.0875 Loss_G: 0.0389 Convergence: 0.0918 k= 0.018862 lr = 0.0000025\n",
      "[22/25][3840/9765] Loss_D: 0.1085 Loss_G: 0.0387 Convergence: 0.1143 k= 0.018868 lr = 0.0000025\n",
      "[22/25][3850/9765] Loss_D: 0.0994 Loss_G: 0.0394 Convergence: 0.1008 k= 0.018862 lr = 0.0000025\n",
      "[22/25][3860/9765] Loss_D: 0.1050 Loss_G: 0.0390 Convergence: 0.1091 k= 0.018865 lr = 0.0000025\n",
      "[22/25][3870/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1042 k= 0.018858 lr = 0.0000025\n",
      "[22/25][3880/9765] Loss_D: 0.0917 Loss_G: 0.0396 Convergence: 0.0951 k= 0.018842 lr = 0.0000025\n",
      "[22/25][3890/9765] Loss_D: 0.1012 Loss_G: 0.0395 Convergence: 0.1033 k= 0.018831 lr = 0.0000025\n",
      "[22/25][3900/9765] Loss_D: 0.0981 Loss_G: 0.0401 Convergence: 0.0995 k= 0.018819 lr = 0.0000025\n",
      "[22/25][3910/9765] Loss_D: 0.0974 Loss_G: 0.0397 Convergence: 0.0986 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3920/9765] Loss_D: 0.1025 Loss_G: 0.0399 Convergence: 0.1046 k= 0.018809 lr = 0.0000025\n",
      "[22/25][3930/9765] Loss_D: 0.1006 Loss_G: 0.0386 Convergence: 0.1033 k= 0.018807 lr = 0.0000025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][3940/9765] Loss_D: 0.0961 Loss_G: 0.0387 Convergence: 0.0968 k= 0.018813 lr = 0.0000025\n",
      "[22/25][3950/9765] Loss_D: 0.0882 Loss_G: 0.0385 Convergence: 0.0919 k= 0.018810 lr = 0.0000025\n",
      "[22/25][3960/9765] Loss_D: 0.0929 Loss_G: 0.0390 Convergence: 0.0951 k= 0.018820 lr = 0.0000025\n",
      "[22/25][3970/9765] Loss_D: 0.0930 Loss_G: 0.0402 Convergence: 0.0964 k= 0.018816 lr = 0.0000025\n",
      "[22/25][3980/9765] Loss_D: 0.0994 Loss_G: 0.0386 Convergence: 0.1016 k= 0.018818 lr = 0.0000025\n",
      "[22/25][3990/9765] Loss_D: 0.1089 Loss_G: 0.0402 Convergence: 0.1133 k= 0.018826 lr = 0.0000025\n",
      "[22/25][4000/9765] Loss_D: 0.0861 Loss_G: 0.0378 Convergence: 0.0899 k= 0.018831 lr = 0.0000025\n",
      "[22/25][4010/9765] Loss_D: 0.0982 Loss_G: 0.0390 Convergence: 0.0994 k= 0.018836 lr = 0.0000025\n",
      "[22/25][4020/9765] Loss_D: 0.0903 Loss_G: 0.0382 Convergence: 0.0928 k= 0.018839 lr = 0.0000025\n",
      "[22/25][4030/9765] Loss_D: 0.1038 Loss_G: 0.0386 Convergence: 0.1077 k= 0.018847 lr = 0.0000025\n",
      "[22/25][4040/9765] Loss_D: 0.0956 Loss_G: 0.0388 Convergence: 0.0966 k= 0.018849 lr = 0.0000025\n",
      "[22/25][4050/9765] Loss_D: 0.0888 Loss_G: 0.0388 Convergence: 0.0925 k= 0.018850 lr = 0.0000025\n",
      "[22/25][4060/9765] Loss_D: 0.1027 Loss_G: 0.0405 Convergence: 0.1043 k= 0.018849 lr = 0.0000025\n",
      "[22/25][4070/9765] Loss_D: 0.0989 Loss_G: 0.0392 Convergence: 0.1002 k= 0.018847 lr = 0.0000025\n",
      "[22/25][4080/9765] Loss_D: 0.1055 Loss_G: 0.0381 Convergence: 0.1105 k= 0.018860 lr = 0.0000025\n",
      "[22/25][4090/9765] Loss_D: 0.0874 Loss_G: 0.0367 Convergence: 0.0895 k= 0.018877 lr = 0.0000025\n",
      "[22/25][4100/9765] Loss_D: 0.0985 Loss_G: 0.0374 Convergence: 0.1015 k= 0.018890 lr = 0.0000025\n",
      "[22/25][4110/9765] Loss_D: 0.0917 Loss_G: 0.0386 Convergence: 0.0941 k= 0.018892 lr = 0.0000025\n",
      "[22/25][4120/9765] Loss_D: 0.1036 Loss_G: 0.0393 Convergence: 0.1068 k= 0.018890 lr = 0.0000025\n",
      "[22/25][4130/9765] Loss_D: 0.0947 Loss_G: 0.0404 Convergence: 0.0976 k= 0.018883 lr = 0.0000025\n",
      "[22/25][4140/9765] Loss_D: 0.1007 Loss_G: 0.0407 Convergence: 0.1015 k= 0.018881 lr = 0.0000025\n",
      "[22/25][4150/9765] Loss_D: 0.0997 Loss_G: 0.0407 Convergence: 0.1010 k= 0.018856 lr = 0.0000025\n",
      "[22/25][4160/9765] Loss_D: 0.0986 Loss_G: 0.0403 Convergence: 0.0999 k= 0.018845 lr = 0.0000025\n",
      "[22/25][4170/9765] Loss_D: 0.0960 Loss_G: 0.0419 Convergence: 0.1000 k= 0.018822 lr = 0.0000024\n",
      "[22/25][4180/9765] Loss_D: 0.0978 Loss_G: 0.0400 Convergence: 0.0991 k= 0.018804 lr = 0.0000024\n",
      "[22/25][4190/9765] Loss_D: 0.0921 Loss_G: 0.0398 Convergence: 0.0955 k= 0.018792 lr = 0.0000024\n",
      "[22/25][4200/9765] Loss_D: 0.0944 Loss_G: 0.0397 Convergence: 0.0968 k= 0.018784 lr = 0.0000024\n",
      "[22/25][4210/9765] Loss_D: 0.1006 Loss_G: 0.0406 Convergence: 0.1014 k= 0.018761 lr = 0.0000024\n",
      "[22/25][4220/9765] Loss_D: 0.0975 Loss_G: 0.0409 Convergence: 0.0999 k= 0.018759 lr = 0.0000024\n",
      "[22/25][4230/9765] Loss_D: 0.1021 Loss_G: 0.0401 Convergence: 0.1039 k= 0.018758 lr = 0.0000024\n",
      "[22/25][4240/9765] Loss_D: 0.0948 Loss_G: 0.0404 Convergence: 0.0977 k= 0.018739 lr = 0.0000024\n",
      "[22/25][4250/9765] Loss_D: 0.0976 Loss_G: 0.0382 Convergence: 0.0994 k= 0.018733 lr = 0.0000024\n",
      "[22/25][4260/9765] Loss_D: 0.0878 Loss_G: 0.0374 Convergence: 0.0905 k= 0.018725 lr = 0.0000024\n",
      "[22/25][4270/9765] Loss_D: 0.0975 Loss_G: 0.0388 Convergence: 0.0987 k= 0.018722 lr = 0.0000024\n",
      "[22/25][4280/9765] Loss_D: 0.0966 Loss_G: 0.0373 Convergence: 0.0990 k= 0.018727 lr = 0.0000024\n",
      "[22/25][4290/9765] Loss_D: 0.0985 Loss_G: 0.0366 Convergence: 0.1023 k= 0.018740 lr = 0.0000024\n",
      "[22/25][4300/9765] Loss_D: 0.0976 Loss_G: 0.0382 Convergence: 0.0995 k= 0.018760 lr = 0.0000024\n",
      "[22/25][4310/9765] Loss_D: 0.0872 Loss_G: 0.0381 Convergence: 0.0908 k= 0.018761 lr = 0.0000024\n",
      "[22/25][4320/9765] Loss_D: 0.0936 Loss_G: 0.0375 Convergence: 0.0945 k= 0.018763 lr = 0.0000024\n",
      "[22/25][4330/9765] Loss_D: 0.0921 Loss_G: 0.0377 Convergence: 0.0934 k= 0.018769 lr = 0.0000024\n",
      "[22/25][4340/9765] Loss_D: 0.0909 Loss_G: 0.0395 Convergence: 0.0945 k= 0.018780 lr = 0.0000024\n",
      "[22/25][4350/9765] Loss_D: 0.1035 Loss_G: 0.0395 Convergence: 0.1064 k= 0.018766 lr = 0.0000024\n",
      "[22/25][4360/9765] Loss_D: 0.0921 Loss_G: 0.0397 Convergence: 0.0953 k= 0.018751 lr = 0.0000024\n",
      "[22/25][4370/9765] Loss_D: 0.0953 Loss_G: 0.0392 Convergence: 0.0969 k= 0.018754 lr = 0.0000024\n",
      "[22/25][4380/9765] Loss_D: 0.0979 Loss_G: 0.0401 Convergence: 0.0992 k= 0.018747 lr = 0.0000024\n",
      "[22/25][4390/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0985 k= 0.018743 lr = 0.0000024\n",
      "[22/25][4400/9765] Loss_D: 0.1015 Loss_G: 0.0392 Convergence: 0.1040 k= 0.018741 lr = 0.0000024\n",
      "[22/25][4410/9765] Loss_D: 0.0962 Loss_G: 0.0396 Convergence: 0.0978 k= 0.018740 lr = 0.0000024\n",
      "[22/25][4420/9765] Loss_D: 0.0926 Loss_G: 0.0395 Convergence: 0.0955 k= 0.018732 lr = 0.0000024\n",
      "[22/25][4430/9765] Loss_D: 0.1073 Loss_G: 0.0397 Convergence: 0.1116 k= 0.018720 lr = 0.0000024\n",
      "[22/25][4440/9765] Loss_D: 0.0913 Loss_G: 0.0394 Convergence: 0.0946 k= 0.018703 lr = 0.0000024\n",
      "[22/25][4450/9765] Loss_D: 0.1010 Loss_G: 0.0401 Convergence: 0.1024 k= 0.018701 lr = 0.0000024\n",
      "[22/25][4460/9765] Loss_D: 0.0970 Loss_G: 0.0388 Convergence: 0.0980 k= 0.018696 lr = 0.0000024\n",
      "[22/25][4470/9765] Loss_D: 0.0951 Loss_G: 0.0384 Convergence: 0.0959 k= 0.018685 lr = 0.0000024\n",
      "[22/25][4480/9765] Loss_D: 0.0912 Loss_G: 0.0379 Convergence: 0.0930 k= 0.018682 lr = 0.0000024\n",
      "[22/25][4490/9765] Loss_D: 0.0923 Loss_G: 0.0383 Convergence: 0.0941 k= 0.018681 lr = 0.0000024\n",
      "[22/25][4500/9765] Loss_D: 0.0979 Loss_G: 0.0381 Convergence: 0.0999 k= 0.018688 lr = 0.0000024\n",
      "[22/25][4510/9765] Loss_D: 0.0965 Loss_G: 0.0385 Convergence: 0.0976 k= 0.018689 lr = 0.0000024\n",
      "[22/25][4520/9765] Loss_D: 0.0994 Loss_G: 0.0389 Convergence: 0.1013 k= 0.018687 lr = 0.0000024\n",
      "[22/25][4530/9765] Loss_D: 0.0915 Loss_G: 0.0382 Convergence: 0.0935 k= 0.018694 lr = 0.0000024\n",
      "[22/25][4540/9765] Loss_D: 0.0848 Loss_G: 0.0379 Convergence: 0.0892 k= 0.018696 lr = 0.0000024\n",
      "[22/25][4550/9765] Loss_D: 0.0957 Loss_G: 0.0384 Convergence: 0.0966 k= 0.018698 lr = 0.0000024\n",
      "[22/25][4560/9765] Loss_D: 0.0896 Loss_G: 0.0384 Convergence: 0.0926 k= 0.018703 lr = 0.0000024\n",
      "[22/25][4570/9765] Loss_D: 0.0915 Loss_G: 0.0373 Convergence: 0.0926 k= 0.018706 lr = 0.0000024\n",
      "[22/25][4580/9765] Loss_D: 0.1114 Loss_G: 0.0364 Convergence: 0.1205 k= 0.018726 lr = 0.0000024\n",
      "[22/25][4590/9765] Loss_D: 0.1021 Loss_G: 0.0378 Convergence: 0.1060 k= 0.018748 lr = 0.0000024\n",
      "[22/25][4600/9765] Loss_D: 0.0885 Loss_G: 0.0359 Convergence: 0.0894 k= 0.018757 lr = 0.0000024\n",
      "[22/25][4610/9765] Loss_D: 0.0958 Loss_G: 0.0381 Convergence: 0.0969 k= 0.018775 lr = 0.0000024\n",
      "[22/25][4620/9765] Loss_D: 0.0995 Loss_G: 0.0389 Convergence: 0.1013 k= 0.018780 lr = 0.0000024\n",
      "[22/25][4630/9765] Loss_D: 0.0913 Loss_G: 0.0377 Convergence: 0.0929 k= 0.018784 lr = 0.0000024\n",
      "[22/25][4640/9765] Loss_D: 0.0990 Loss_G: 0.0387 Convergence: 0.1010 k= 0.018793 lr = 0.0000024\n",
      "[22/25][4650/9765] Loss_D: 0.0987 Loss_G: 0.0392 Convergence: 0.1000 k= 0.018789 lr = 0.0000024\n",
      "[22/25][4660/9765] Loss_D: 0.0858 Loss_G: 0.0387 Convergence: 0.0907 k= 0.018777 lr = 0.0000024\n",
      "[22/25][4670/9765] Loss_D: 0.0962 Loss_G: 0.0388 Convergence: 0.0970 k= 0.018783 lr = 0.0000024\n",
      "[22/25][4680/9765] Loss_D: 0.1007 Loss_G: 0.0388 Convergence: 0.1033 k= 0.018786 lr = 0.0000024\n",
      "[22/25][4690/9765] Loss_D: 0.1020 Loss_G: 0.0398 Convergence: 0.1040 k= 0.018783 lr = 0.0000024\n",
      "[22/25][4700/9765] Loss_D: 0.0858 Loss_G: 0.0401 Convergence: 0.0920 k= 0.018772 lr = 0.0000024\n",
      "[22/25][4710/9765] Loss_D: 0.0976 Loss_G: 0.0385 Convergence: 0.0991 k= 0.018771 lr = 0.0000024\n",
      "[22/25][4720/9765] Loss_D: 0.1032 Loss_G: 0.0404 Convergence: 0.1051 k= 0.018773 lr = 0.0000024\n",
      "[22/25][4730/9765] Loss_D: 0.0914 Loss_G: 0.0415 Convergence: 0.0968 k= 0.018759 lr = 0.0000024\n",
      "[22/25][4740/9765] Loss_D: 0.1018 Loss_G: 0.0394 Convergence: 0.1042 k= 0.018753 lr = 0.0000024\n",
      "[22/25][4750/9765] Loss_D: 0.0936 Loss_G: 0.0378 Convergence: 0.0944 k= 0.018748 lr = 0.0000024\n",
      "[22/25][4760/9765] Loss_D: 0.0943 Loss_G: 0.0384 Convergence: 0.0954 k= 0.018747 lr = 0.0000024\n",
      "[22/25][4770/9765] Loss_D: 0.1071 Loss_G: 0.0369 Convergence: 0.1140 k= 0.018753 lr = 0.0000024\n",
      "[22/25][4780/9765] Loss_D: 0.0952 Loss_G: 0.0380 Convergence: 0.0963 k= 0.018768 lr = 0.0000024\n",
      "[22/25][4790/9765] Loss_D: 0.0979 Loss_G: 0.0393 Convergence: 0.0987 k= 0.018782 lr = 0.0000024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][4800/9765] Loss_D: 0.1067 Loss_G: 0.0399 Convergence: 0.1105 k= 0.018796 lr = 0.0000024\n",
      "[22/25][4810/9765] Loss_D: 0.0976 Loss_G: 0.0388 Convergence: 0.0988 k= 0.018801 lr = 0.0000024\n",
      "[22/25][4820/9765] Loss_D: 0.0940 Loss_G: 0.0390 Convergence: 0.0958 k= 0.018788 lr = 0.0000024\n",
      "[22/25][4830/9765] Loss_D: 0.0949 Loss_G: 0.0389 Convergence: 0.0963 k= 0.018793 lr = 0.0000024\n",
      "[22/25][4840/9765] Loss_D: 0.0999 Loss_G: 0.0386 Convergence: 0.1023 k= 0.018803 lr = 0.0000024\n",
      "[22/25][4850/9765] Loss_D: 0.0906 Loss_G: 0.0369 Convergence: 0.0917 k= 0.018800 lr = 0.0000024\n",
      "[22/25][4860/9765] Loss_D: 0.0974 Loss_G: 0.0387 Convergence: 0.0987 k= 0.018807 lr = 0.0000024\n",
      "[22/25][4870/9765] Loss_D: 0.1022 Loss_G: 0.0376 Convergence: 0.1065 k= 0.018811 lr = 0.0000024\n",
      "[22/25][4880/9765] Loss_D: 0.0962 Loss_G: 0.0381 Convergence: 0.0977 k= 0.018820 lr = 0.0000024\n",
      "[22/25][4890/9765] Loss_D: 0.1055 Loss_G: 0.0388 Convergence: 0.1100 k= 0.018825 lr = 0.0000024\n",
      "[22/25][4900/9765] Loss_D: 0.0933 Loss_G: 0.0365 Convergence: 0.0951 k= 0.018829 lr = 0.0000024\n",
      "[22/25][4910/9765] Loss_D: 0.0960 Loss_G: 0.0386 Convergence: 0.0968 k= 0.018837 lr = 0.0000024\n",
      "[22/25][4920/9765] Loss_D: 0.1019 Loss_G: 0.0369 Convergence: 0.1068 k= 0.018852 lr = 0.0000024\n",
      "[22/25][4930/9765] Loss_D: 0.0994 Loss_G: 0.0381 Convergence: 0.1021 k= 0.018867 lr = 0.0000024\n",
      "[22/25][4940/9765] Loss_D: 0.0938 Loss_G: 0.0382 Convergence: 0.0949 k= 0.018881 lr = 0.0000024\n",
      "[22/25][4950/9765] Loss_D: 0.0945 Loss_G: 0.0386 Convergence: 0.0957 k= 0.018879 lr = 0.0000024\n",
      "[22/25][4960/9765] Loss_D: 0.0878 Loss_G: 0.0396 Convergence: 0.0927 k= 0.018874 lr = 0.0000024\n",
      "[22/25][4970/9765] Loss_D: 0.0909 Loss_G: 0.0387 Convergence: 0.0937 k= 0.018864 lr = 0.0000024\n",
      "[22/25][4980/9765] Loss_D: 0.0880 Loss_G: 0.0381 Convergence: 0.0914 k= 0.018861 lr = 0.0000024\n",
      "[22/25][4990/9765] Loss_D: 0.0969 Loss_G: 0.0398 Convergence: 0.0984 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5000/9765] Loss_D: 0.1062 Loss_G: 0.0395 Convergence: 0.1102 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5010/9765] Loss_D: 0.0975 Loss_G: 0.0406 Convergence: 0.0995 k= 0.018855 lr = 0.0000024\n",
      "[22/25][5020/9765] Loss_D: 0.0933 Loss_G: 0.0385 Convergence: 0.0949 k= 0.018840 lr = 0.0000024\n",
      "[22/25][5030/9765] Loss_D: 0.0974 Loss_G: 0.0380 Convergence: 0.0995 k= 0.018835 lr = 0.0000024\n",
      "[22/25][5040/9765] Loss_D: 0.0884 Loss_G: 0.0381 Convergence: 0.0916 k= 0.018826 lr = 0.0000024\n",
      "[22/25][5050/9765] Loss_D: 0.0999 Loss_G: 0.0383 Convergence: 0.1026 k= 0.018827 lr = 0.0000024\n",
      "[22/25][5060/9765] Loss_D: 0.0954 Loss_G: 0.0384 Convergence: 0.0962 k= 0.018819 lr = 0.0000024\n",
      "[22/25][5070/9765] Loss_D: 0.0974 Loss_G: 0.0375 Convergence: 0.0998 k= 0.018823 lr = 0.0000024\n",
      "[22/25][5080/9765] Loss_D: 0.0900 Loss_G: 0.0380 Convergence: 0.0925 k= 0.018823 lr = 0.0000024\n",
      "[22/25][5090/9765] Loss_D: 0.0952 Loss_G: 0.0385 Convergence: 0.0961 k= 0.018820 lr = 0.0000024\n",
      "[22/25][5100/9765] Loss_D: 0.0931 Loss_G: 0.0383 Convergence: 0.0946 k= 0.018818 lr = 0.0000024\n",
      "[22/25][5110/9765] Loss_D: 0.0927 Loss_G: 0.0383 Convergence: 0.0944 k= 0.018819 lr = 0.0000024\n",
      "[22/25][5120/9765] Loss_D: 0.1025 Loss_G: 0.0375 Convergence: 0.1070 k= 0.018825 lr = 0.0000024\n",
      "[22/25][5130/9765] Loss_D: 0.0919 Loss_G: 0.0382 Convergence: 0.0937 k= 0.018826 lr = 0.0000024\n",
      "[22/25][5140/9765] Loss_D: 0.1018 Loss_G: 0.0381 Convergence: 0.1054 k= 0.018821 lr = 0.0000024\n",
      "[22/25][5150/9765] Loss_D: 0.0955 Loss_G: 0.0378 Convergence: 0.0969 k= 0.018834 lr = 0.0000024\n",
      "[22/25][5160/9765] Loss_D: 0.0987 Loss_G: 0.0373 Convergence: 0.1019 k= 0.018853 lr = 0.0000024\n",
      "[22/25][5170/9765] Loss_D: 0.0982 Loss_G: 0.0383 Convergence: 0.1001 k= 0.018857 lr = 0.0000024\n",
      "[22/25][5180/9765] Loss_D: 0.0905 Loss_G: 0.0376 Convergence: 0.0924 k= 0.018860 lr = 0.0000024\n",
      "[22/25][5190/9765] Loss_D: 0.0981 Loss_G: 0.0391 Convergence: 0.0993 k= 0.018872 lr = 0.0000024\n",
      "[22/25][5200/9765] Loss_D: 0.1011 Loss_G: 0.0389 Convergence: 0.1037 k= 0.018870 lr = 0.0000024\n",
      "[22/25][5210/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0966 k= 0.018871 lr = 0.0000024\n",
      "[22/25][5220/9765] Loss_D: 0.0946 Loss_G: 0.0379 Convergence: 0.0955 k= 0.018873 lr = 0.0000024\n",
      "[22/25][5230/9765] Loss_D: 0.0986 Loss_G: 0.0400 Convergence: 0.0996 k= 0.018879 lr = 0.0000024\n",
      "[22/25][5240/9765] Loss_D: 0.0947 Loss_G: 0.0382 Convergence: 0.0954 k= 0.018880 lr = 0.0000024\n",
      "[22/25][5250/9765] Loss_D: 0.0906 Loss_G: 0.0399 Convergence: 0.0948 k= 0.018881 lr = 0.0000024\n",
      "[22/25][5260/9765] Loss_D: 0.0890 Loss_G: 0.0385 Convergence: 0.0924 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5270/9765] Loss_D: 0.0976 Loss_G: 0.0382 Convergence: 0.0995 k= 0.018857 lr = 0.0000024\n",
      "[22/25][5280/9765] Loss_D: 0.0921 Loss_G: 0.0403 Convergence: 0.0960 k= 0.018848 lr = 0.0000024\n",
      "[22/25][5290/9765] Loss_D: 0.1015 Loss_G: 0.0399 Convergence: 0.1033 k= 0.018845 lr = 0.0000024\n",
      "[22/25][5300/9765] Loss_D: 0.0959 Loss_G: 0.0397 Convergence: 0.0976 k= 0.018844 lr = 0.0000024\n",
      "[22/25][5310/9765] Loss_D: 0.0971 Loss_G: 0.0399 Convergence: 0.0986 k= 0.018850 lr = 0.0000024\n",
      "[22/25][5320/9765] Loss_D: 0.1014 Loss_G: 0.0394 Convergence: 0.1036 k= 0.018852 lr = 0.0000024\n",
      "[22/25][5330/9765] Loss_D: 0.0999 Loss_G: 0.0392 Convergence: 0.1018 k= 0.018862 lr = 0.0000024\n",
      "[22/25][5340/9765] Loss_D: 0.0870 Loss_G: 0.0382 Convergence: 0.0908 k= 0.018861 lr = 0.0000024\n",
      "[22/25][5350/9765] Loss_D: 0.0951 Loss_G: 0.0384 Convergence: 0.0959 k= 0.018869 lr = 0.0000024\n",
      "[22/25][5360/9765] Loss_D: 0.0914 Loss_G: 0.0382 Convergence: 0.0935 k= 0.018862 lr = 0.0000024\n",
      "[22/25][5370/9765] Loss_D: 0.0954 Loss_G: 0.0387 Convergence: 0.0964 k= 0.018859 lr = 0.0000024\n",
      "[22/25][5380/9765] Loss_D: 0.0842 Loss_G: 0.0390 Convergence: 0.0900 k= 0.018842 lr = 0.0000024\n",
      "[22/25][5390/9765] Loss_D: 0.0942 Loss_G: 0.0377 Convergence: 0.0951 k= 0.018852 lr = 0.0000024\n",
      "[22/25][5400/9765] Loss_D: 0.1026 Loss_G: 0.0389 Convergence: 0.1058 k= 0.018864 lr = 0.0000024\n",
      "[22/25][5410/9765] Loss_D: 0.1003 Loss_G: 0.0392 Convergence: 0.1022 k= 0.018870 lr = 0.0000024\n",
      "[22/25][5420/9765] Loss_D: 0.1048 Loss_G: 0.0394 Convergence: 0.1083 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5430/9765] Loss_D: 0.0938 Loss_G: 0.0401 Convergence: 0.0968 k= 0.018862 lr = 0.0000024\n",
      "[22/25][5440/9765] Loss_D: 0.0953 Loss_G: 0.0374 Convergence: 0.0970 k= 0.018861 lr = 0.0000024\n",
      "[22/25][5450/9765] Loss_D: 0.0904 Loss_G: 0.0389 Convergence: 0.0936 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5460/9765] Loss_D: 0.0883 Loss_G: 0.0390 Convergence: 0.0924 k= 0.018862 lr = 0.0000024\n",
      "[22/25][5470/9765] Loss_D: 0.0941 Loss_G: 0.0382 Convergence: 0.0950 k= 0.018855 lr = 0.0000024\n",
      "[22/25][5480/9765] Loss_D: 0.0910 Loss_G: 0.0384 Convergence: 0.0934 k= 0.018847 lr = 0.0000024\n",
      "[22/25][5490/9765] Loss_D: 0.0962 Loss_G: 0.0392 Convergence: 0.0974 k= 0.018832 lr = 0.0000024\n",
      "[22/25][5500/9765] Loss_D: 0.0909 Loss_G: 0.0393 Convergence: 0.0943 k= 0.018827 lr = 0.0000024\n",
      "[22/25][5510/9765] Loss_D: 0.0915 Loss_G: 0.0380 Convergence: 0.0933 k= 0.018832 lr = 0.0000024\n",
      "[22/25][5520/9765] Loss_D: 0.0890 Loss_G: 0.0387 Convergence: 0.0925 k= 0.018836 lr = 0.0000024\n",
      "[22/25][5530/9765] Loss_D: 0.0956 Loss_G: 0.0378 Convergence: 0.0971 k= 0.018828 lr = 0.0000024\n",
      "[22/25][5540/9765] Loss_D: 0.0901 Loss_G: 0.0380 Convergence: 0.0926 k= 0.018824 lr = 0.0000024\n",
      "[22/25][5550/9765] Loss_D: 0.0921 Loss_G: 0.0383 Convergence: 0.0940 k= 0.018803 lr = 0.0000024\n",
      "[22/25][5560/9765] Loss_D: 0.0900 Loss_G: 0.0373 Convergence: 0.0917 k= 0.018800 lr = 0.0000024\n",
      "[22/25][5570/9765] Loss_D: 0.0991 Loss_G: 0.0388 Convergence: 0.1009 k= 0.018805 lr = 0.0000024\n",
      "[22/25][5580/9765] Loss_D: 0.0937 Loss_G: 0.0389 Convergence: 0.0955 k= 0.018810 lr = 0.0000024\n",
      "[22/25][5590/9765] Loss_D: 0.0993 Loss_G: 0.0379 Convergence: 0.1022 k= 0.018814 lr = 0.0000024\n",
      "[22/25][5600/9765] Loss_D: 0.0966 Loss_G: 0.0386 Convergence: 0.0977 k= 0.018820 lr = 0.0000024\n",
      "[22/25][5610/9765] Loss_D: 0.0970 Loss_G: 0.0390 Convergence: 0.0978 k= 0.018819 lr = 0.0000024\n",
      "[22/25][5620/9765] Loss_D: 0.0935 Loss_G: 0.0377 Convergence: 0.0942 k= 0.018819 lr = 0.0000024\n",
      "[22/25][5630/9765] Loss_D: 0.0959 Loss_G: 0.0363 Convergence: 0.0989 k= 0.018832 lr = 0.0000024\n",
      "[22/25][5640/9765] Loss_D: 0.0925 Loss_G: 0.0390 Convergence: 0.0949 k= 0.018850 lr = 0.0000024\n",
      "[22/25][5650/9765] Loss_D: 0.0885 Loss_G: 0.0387 Convergence: 0.0922 k= 0.018851 lr = 0.0000024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][5660/9765] Loss_D: 0.0841 Loss_G: 0.0380 Convergence: 0.0889 k= 0.018856 lr = 0.0000024\n",
      "[22/25][5670/9765] Loss_D: 0.0950 Loss_G: 0.0379 Convergence: 0.0962 k= 0.018857 lr = 0.0000024\n",
      "[22/25][5680/9765] Loss_D: 0.0978 Loss_G: 0.0398 Convergence: 0.0989 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5690/9765] Loss_D: 0.0908 Loss_G: 0.0391 Convergence: 0.0940 k= 0.018855 lr = 0.0000024\n",
      "[22/25][5700/9765] Loss_D: 0.1031 Loss_G: 0.0402 Convergence: 0.1053 k= 0.018856 lr = 0.0000024\n",
      "[22/25][5710/9765] Loss_D: 0.0866 Loss_G: 0.0375 Convergence: 0.0899 k= 0.018861 lr = 0.0000024\n",
      "[22/25][5720/9765] Loss_D: 0.0960 Loss_G: 0.0392 Convergence: 0.0972 k= 0.018863 lr = 0.0000024\n",
      "[22/25][5730/9765] Loss_D: 0.0910 Loss_G: 0.0403 Convergence: 0.0954 k= 0.018859 lr = 0.0000024\n",
      "[22/25][5740/9765] Loss_D: 0.0926 Loss_G: 0.0393 Convergence: 0.0953 k= 0.018847 lr = 0.0000024\n",
      "[22/25][5750/9765] Loss_D: 0.0875 Loss_G: 0.0395 Convergence: 0.0925 k= 0.018849 lr = 0.0000024\n",
      "[22/25][5760/9765] Loss_D: 0.0941 Loss_G: 0.0396 Convergence: 0.0966 k= 0.018828 lr = 0.0000024\n",
      "[22/25][5770/9765] Loss_D: 0.0970 Loss_G: 0.0398 Convergence: 0.0985 k= 0.018808 lr = 0.0000024\n",
      "[22/25][5780/9765] Loss_D: 0.1007 Loss_G: 0.0404 Convergence: 0.1016 k= 0.018792 lr = 0.0000024\n",
      "[22/25][5790/9765] Loss_D: 0.1006 Loss_G: 0.0416 Convergence: 0.1024 k= 0.018762 lr = 0.0000024\n",
      "[22/25][5800/9765] Loss_D: 0.0985 Loss_G: 0.0392 Convergence: 0.0997 k= 0.018745 lr = 0.0000024\n",
      "[22/25][5810/9765] Loss_D: 0.1008 Loss_G: 0.0382 Convergence: 0.1039 k= 0.018749 lr = 0.0000024\n",
      "[22/25][5820/9765] Loss_D: 0.0960 Loss_G: 0.0386 Convergence: 0.0968 k= 0.018745 lr = 0.0000024\n",
      "[22/25][5830/9765] Loss_D: 0.0900 Loss_G: 0.0384 Convergence: 0.0928 k= 0.018745 lr = 0.0000024\n",
      "[22/25][5840/9765] Loss_D: 0.0949 Loss_G: 0.0366 Convergence: 0.0972 k= 0.018757 lr = 0.0000024\n",
      "[22/25][5850/9765] Loss_D: 0.0931 Loss_G: 0.0355 Convergence: 0.0958 k= 0.018779 lr = 0.0000024\n",
      "[22/25][5860/9765] Loss_D: 0.0950 Loss_G: 0.0362 Convergence: 0.0977 k= 0.018802 lr = 0.0000024\n",
      "[22/25][5870/9765] Loss_D: 0.1023 Loss_G: 0.0361 Convergence: 0.1080 k= 0.018820 lr = 0.0000024\n",
      "[22/25][5880/9765] Loss_D: 0.0918 Loss_G: 0.0381 Convergence: 0.0935 k= 0.018836 lr = 0.0000024\n",
      "[22/25][5890/9765] Loss_D: 0.0919 Loss_G: 0.0366 Convergence: 0.0930 k= 0.018858 lr = 0.0000024\n",
      "[22/25][5900/9765] Loss_D: 0.0957 Loss_G: 0.0382 Convergence: 0.0968 k= 0.018882 lr = 0.0000024\n",
      "[22/25][5910/9765] Loss_D: 0.0898 Loss_G: 0.0368 Convergence: 0.0911 k= 0.018890 lr = 0.0000024\n",
      "[22/25][5920/9765] Loss_D: 0.0899 Loss_G: 0.0377 Convergence: 0.0921 k= 0.018904 lr = 0.0000024\n",
      "[22/25][5930/9765] Loss_D: 0.1049 Loss_G: 0.0392 Convergence: 0.1087 k= 0.018912 lr = 0.0000024\n",
      "[22/25][5940/9765] Loss_D: 0.1046 Loss_G: 0.0396 Convergence: 0.1078 k= 0.018914 lr = 0.0000024\n",
      "[22/25][5950/9765] Loss_D: 0.0950 Loss_G: 0.0392 Convergence: 0.0966 k= 0.018908 lr = 0.0000024\n",
      "[22/25][5960/9765] Loss_D: 0.1006 Loss_G: 0.0406 Convergence: 0.1014 k= 0.018905 lr = 0.0000024\n",
      "[22/25][5970/9765] Loss_D: 0.1048 Loss_G: 0.0394 Convergence: 0.1084 k= 0.018891 lr = 0.0000024\n",
      "[22/25][5980/9765] Loss_D: 0.0900 Loss_G: 0.0401 Convergence: 0.0946 k= 0.018870 lr = 0.0000024\n",
      "[22/25][5990/9765] Loss_D: 0.0857 Loss_G: 0.0383 Convergence: 0.0902 k= 0.018859 lr = 0.0000024\n",
      "[22/25][6000/9765] Loss_D: 0.0914 Loss_G: 0.0393 Convergence: 0.0945 k= 0.018865 lr = 0.0000024\n",
      "[22/25][6010/9765] Loss_D: 0.0870 Loss_G: 0.0388 Convergence: 0.0914 k= 0.018852 lr = 0.0000024\n",
      "[22/25][6020/9765] Loss_D: 0.1052 Loss_G: 0.0391 Convergence: 0.1093 k= 0.018854 lr = 0.0000024\n",
      "[22/25][6030/9765] Loss_D: 0.0968 Loss_G: 0.0399 Convergence: 0.0984 k= 0.018843 lr = 0.0000024\n",
      "[22/25][6040/9765] Loss_D: 0.0860 Loss_G: 0.0394 Convergence: 0.0914 k= 0.018827 lr = 0.0000024\n",
      "[22/25][6050/9765] Loss_D: 0.0949 Loss_G: 0.0381 Convergence: 0.0957 k= 0.018822 lr = 0.0000024\n",
      "[22/25][6060/9765] Loss_D: 0.0866 Loss_G: 0.0404 Convergence: 0.0928 k= 0.018809 lr = 0.0000024\n",
      "[22/25][6070/9765] Loss_D: 0.0935 Loss_G: 0.0388 Convergence: 0.0954 k= 0.018809 lr = 0.0000024\n",
      "[22/25][6080/9765] Loss_D: 0.0929 Loss_G: 0.0396 Convergence: 0.0958 k= 0.018816 lr = 0.0000024\n",
      "[22/25][6090/9765] Loss_D: 0.0926 Loss_G: 0.0383 Convergence: 0.0942 k= 0.018818 lr = 0.0000024\n",
      "[22/25][6100/9765] Loss_D: 0.0975 Loss_G: 0.0384 Convergence: 0.0992 k= 0.018820 lr = 0.0000024\n",
      "[22/25][6110/9765] Loss_D: 0.0901 Loss_G: 0.0379 Convergence: 0.0924 k= 0.018822 lr = 0.0000024\n",
      "[22/25][6120/9765] Loss_D: 0.0930 Loss_G: 0.0375 Convergence: 0.0937 k= 0.018832 lr = 0.0000024\n",
      "[22/25][6130/9765] Loss_D: 0.1034 Loss_G: 0.0384 Convergence: 0.1073 k= 0.018847 lr = 0.0000024\n",
      "[22/25][6140/9765] Loss_D: 0.1027 Loss_G: 0.0381 Convergence: 0.1067 k= 0.018852 lr = 0.0000024\n",
      "[22/25][6150/9765] Loss_D: 0.0914 Loss_G: 0.0378 Convergence: 0.0931 k= 0.018858 lr = 0.0000024\n",
      "[22/25][6160/9765] Loss_D: 0.0873 Loss_G: 0.0385 Convergence: 0.0913 k= 0.018863 lr = 0.0000024\n",
      "[22/25][6170/9765] Loss_D: 0.0870 Loss_G: 0.0364 Convergence: 0.0890 k= 0.018868 lr = 0.0000024\n",
      "[22/25][6180/9765] Loss_D: 0.0955 Loss_G: 0.0376 Convergence: 0.0972 k= 0.018887 lr = 0.0000024\n",
      "[22/25][6190/9765] Loss_D: 0.0963 Loss_G: 0.0371 Convergence: 0.0987 k= 0.018898 lr = 0.0000024\n",
      "[22/25][6200/9765] Loss_D: 0.1001 Loss_G: 0.0386 Convergence: 0.1025 k= 0.018908 lr = 0.0000024\n",
      "[22/25][6210/9765] Loss_D: 0.1079 Loss_G: 0.0390 Convergence: 0.1130 k= 0.018912 lr = 0.0000024\n",
      "[22/25][6220/9765] Loss_D: 0.0937 Loss_G: 0.0399 Convergence: 0.0966 k= 0.018912 lr = 0.0000024\n",
      "[22/25][6230/9765] Loss_D: 0.0992 Loss_G: 0.0391 Convergence: 0.1007 k= 0.018894 lr = 0.0000024\n",
      "[22/25][6240/9765] Loss_D: 0.0955 Loss_G: 0.0390 Convergence: 0.0968 k= 0.018884 lr = 0.0000024\n",
      "[22/25][6250/9765] Loss_D: 0.1057 Loss_G: 0.0405 Convergence: 0.1085 k= 0.018872 lr = 0.0000024\n",
      "[22/25][6260/9765] Loss_D: 0.0924 Loss_G: 0.0391 Convergence: 0.0949 k= 0.018844 lr = 0.0000024\n",
      "[22/25][6270/9765] Loss_D: 0.0907 Loss_G: 0.0382 Convergence: 0.0931 k= 0.018842 lr = 0.0000024\n",
      "[22/25][6280/9765] Loss_D: 0.1008 Loss_G: 0.0397 Convergence: 0.1024 k= 0.018849 lr = 0.0000024\n",
      "[22/25][6290/9765] Loss_D: 0.1010 Loss_G: 0.0407 Convergence: 0.1018 k= 0.018839 lr = 0.0000024\n",
      "[22/25][6300/9765] Loss_D: 0.0922 Loss_G: 0.0389 Convergence: 0.0946 k= 0.018832 lr = 0.0000024\n",
      "[22/25][6310/9765] Loss_D: 0.0964 Loss_G: 0.0393 Convergence: 0.0975 k= 0.018830 lr = 0.0000024\n",
      "[22/25][6320/9765] Loss_D: 0.0951 Loss_G: 0.0385 Convergence: 0.0960 k= 0.018813 lr = 0.0000024\n",
      "[22/25][6330/9765] Loss_D: 0.0992 Loss_G: 0.0397 Convergence: 0.1002 k= 0.018826 lr = 0.0000024\n",
      "[22/25][6340/9765] Loss_D: 0.1021 Loss_G: 0.0392 Convergence: 0.1048 k= 0.018831 lr = 0.0000024\n",
      "[22/25][6350/9765] Loss_D: 0.0960 Loss_G: 0.0388 Convergence: 0.0969 k= 0.018830 lr = 0.0000024\n",
      "[22/25][6360/9765] Loss_D: 0.0923 Loss_G: 0.0398 Convergence: 0.0957 k= 0.018824 lr = 0.0000024\n",
      "[22/25][6370/9765] Loss_D: 0.1058 Loss_G: 0.0391 Convergence: 0.1101 k= 0.018833 lr = 0.0000024\n",
      "[22/25][6380/9765] Loss_D: 0.0872 Loss_G: 0.0399 Convergence: 0.0927 k= 0.018815 lr = 0.0000024\n",
      "[22/25][6390/9765] Loss_D: 0.1048 Loss_G: 0.0390 Convergence: 0.1087 k= 0.018797 lr = 0.0000024\n",
      "[22/25][6400/9765] Loss_D: 0.0977 Loss_G: 0.0385 Convergence: 0.0993 k= 0.018787 lr = 0.0000024\n",
      "[22/25][6410/9765] Loss_D: 0.1037 Loss_G: 0.0391 Convergence: 0.1072 k= 0.018791 lr = 0.0000024\n",
      "[22/25][6420/9765] Loss_D: 0.0965 Loss_G: 0.0385 Convergence: 0.0976 k= 0.018776 lr = 0.0000024\n",
      "[22/25][6430/9765] Loss_D: 0.0967 Loss_G: 0.0390 Convergence: 0.0975 k= 0.018784 lr = 0.0000024\n",
      "[22/25][6440/9765] Loss_D: 0.1042 Loss_G: 0.0383 Convergence: 0.1086 k= 0.018784 lr = 0.0000024\n",
      "[22/25][6450/9765] Loss_D: 0.0985 Loss_G: 0.0384 Convergence: 0.1005 k= 0.018789 lr = 0.0000024\n",
      "[22/25][6460/9765] Loss_D: 0.0965 Loss_G: 0.0386 Convergence: 0.0975 k= 0.018788 lr = 0.0000024\n",
      "[22/25][6470/9765] Loss_D: 0.0975 Loss_G: 0.0385 Convergence: 0.0989 k= 0.018791 lr = 0.0000024\n",
      "[22/25][6480/9765] Loss_D: 0.0950 Loss_G: 0.0377 Convergence: 0.0963 k= 0.018795 lr = 0.0000024\n",
      "[22/25][6490/9765] Loss_D: 0.0889 Loss_G: 0.0372 Convergence: 0.0910 k= 0.018806 lr = 0.0000024\n",
      "[22/25][6500/9765] Loss_D: 0.0980 Loss_G: 0.0381 Convergence: 0.1001 k= 0.018810 lr = 0.0000024\n",
      "[22/25][6510/9765] Loss_D: 0.0963 Loss_G: 0.0382 Convergence: 0.0977 k= 0.018828 lr = 0.0000024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/25][6520/9765] Loss_D: 0.0948 Loss_G: 0.0384 Convergence: 0.0957 k= 0.018833 lr = 0.0000024\n",
      "[22/25][6530/9765] Loss_D: 0.1013 Loss_G: 0.0388 Convergence: 0.1040 k= 0.018845 lr = 0.0000024\n",
      "[22/25][6540/9765] Loss_D: 0.0975 Loss_G: 0.0408 Convergence: 0.0997 k= 0.018840 lr = 0.0000024\n",
      "[22/25][6550/9765] Loss_D: 0.1040 Loss_G: 0.0392 Convergence: 0.1074 k= 0.018831 lr = 0.0000024\n",
      "[22/25][6560/9765] Loss_D: 0.0945 Loss_G: 0.0385 Convergence: 0.0956 k= 0.018827 lr = 0.0000024\n",
      "[22/25][6570/9765] Loss_D: 0.1063 Loss_G: 0.0393 Convergence: 0.1105 k= 0.018830 lr = 0.0000024\n",
      "[22/25][6580/9765] Loss_D: 0.0964 Loss_G: 0.0377 Convergence: 0.0983 k= 0.018820 lr = 0.0000024\n",
      "[22/25][6590/9765] Loss_D: 0.0975 Loss_G: 0.0383 Convergence: 0.0992 k= 0.018817 lr = 0.0000024\n",
      "[22/25][6600/9765] Loss_D: 0.0940 Loss_G: 0.0387 Convergence: 0.0956 k= 0.018819 lr = 0.0000024\n",
      "[22/25][6610/9765] Loss_D: 0.0945 Loss_G: 0.0387 Convergence: 0.0958 k= 0.018819 lr = 0.0000024\n",
      "[22/25][6620/9765] Loss_D: 0.0926 Loss_G: 0.0389 Convergence: 0.0949 k= 0.018809 lr = 0.0000024\n",
      "[22/25][6630/9765] Loss_D: 0.0902 Loss_G: 0.0387 Convergence: 0.0933 k= 0.018803 lr = 0.0000024\n",
      "[22/25][6640/9765] Loss_D: 0.1123 Loss_G: 0.0393 Convergence: 0.1190 k= 0.018813 lr = 0.0000024\n",
      "[22/25][6650/9765] Loss_D: 0.0895 Loss_G: 0.0384 Convergence: 0.0925 k= 0.018809 lr = 0.0000024\n",
      "[22/25][6660/9765] Loss_D: 0.0927 Loss_G: 0.0378 Convergence: 0.0939 k= 0.018796 lr = 0.0000024\n",
      "[22/25][6670/9765] Loss_D: 0.0884 Loss_G: 0.0385 Convergence: 0.0920 k= 0.018800 lr = 0.0000024\n",
      "[22/25][6680/9765] Loss_D: 0.0980 Loss_G: 0.0397 Convergence: 0.0989 k= 0.018798 lr = 0.0000024\n",
      "[22/25][6690/9765] Loss_D: 0.0946 Loss_G: 0.0380 Convergence: 0.0954 k= 0.018788 lr = 0.0000024\n",
      "[22/25][6700/9765] Loss_D: 0.0883 Loss_G: 0.0377 Convergence: 0.0911 k= 0.018779 lr = 0.0000024\n",
      "[22/25][6710/9765] Loss_D: 0.0927 Loss_G: 0.0381 Convergence: 0.0942 k= 0.018789 lr = 0.0000024\n",
      "[22/25][6720/9765] Loss_D: 0.0917 Loss_G: 0.0378 Convergence: 0.0932 k= 0.018788 lr = 0.0000024\n",
      "[22/25][6730/9765] Loss_D: 0.1009 Loss_G: 0.0383 Convergence: 0.1040 k= 0.018793 lr = 0.0000024\n",
      "[22/25][6740/9765] Loss_D: 0.1045 Loss_G: 0.0389 Convergence: 0.1084 k= 0.018801 lr = 0.0000024\n",
      "[22/25][6750/9765] Loss_D: 0.1035 Loss_G: 0.0396 Convergence: 0.1063 k= 0.018811 lr = 0.0000024\n",
      "[22/25][6760/9765] Loss_D: 0.0967 Loss_G: 0.0384 Convergence: 0.0979 k= 0.018821 lr = 0.0000024\n",
      "[22/25][6770/9765] Loss_D: 0.0856 Loss_G: 0.0377 Convergence: 0.0895 k= 0.018817 lr = 0.0000024\n",
      "[22/25][6780/9765] Loss_D: 0.0986 Loss_G: 0.0390 Convergence: 0.1000 k= 0.018830 lr = 0.0000024\n",
      "[22/25][6790/9765] Loss_D: 0.0942 Loss_G: 0.0386 Convergence: 0.0956 k= 0.018820 lr = 0.0000024\n",
      "[22/25][6800/9765] Loss_D: 0.0980 Loss_G: 0.0385 Convergence: 0.0997 k= 0.018821 lr = 0.0000024\n",
      "[22/25][6810/9765] Loss_D: 0.0972 Loss_G: 0.0386 Convergence: 0.0986 k= 0.018817 lr = 0.0000024\n",
      "[22/25][6820/9765] Loss_D: 0.0912 Loss_G: 0.0397 Convergence: 0.0949 k= 0.018810 lr = 0.0000024\n",
      "[22/25][6830/9765] Loss_D: 0.0861 Loss_G: 0.0385 Convergence: 0.0906 k= 0.018814 lr = 0.0000024\n",
      "[22/25][6840/9765] Loss_D: 0.0977 Loss_G: 0.0382 Convergence: 0.0996 k= 0.018824 lr = 0.0000024\n",
      "[22/25][6850/9765] Loss_D: 0.1030 Loss_G: 0.0378 Convergence: 0.1075 k= 0.018829 lr = 0.0000024\n",
      "[22/25][6860/9765] Loss_D: 0.0967 Loss_G: 0.0404 Convergence: 0.0989 k= 0.018831 lr = 0.0000024\n",
      "[22/25][6870/9765] Loss_D: 0.0978 Loss_G: 0.0403 Convergence: 0.0994 k= 0.018822 lr = 0.0000024\n",
      "[22/25][6880/9765] Loss_D: 0.0948 Loss_G: 0.0385 Convergence: 0.0958 k= 0.018810 lr = 0.0000024\n",
      "[22/25][6890/9765] Loss_D: 0.0976 Loss_G: 0.0386 Convergence: 0.0991 k= 0.018823 lr = 0.0000024\n",
      "[22/25][6900/9765] Loss_D: 0.0904 Loss_G: 0.0398 Convergence: 0.0945 k= 0.018814 lr = 0.0000024\n",
      "[22/25][6910/9765] Loss_D: 0.1042 Loss_G: 0.0416 Convergence: 0.1054 k= 0.018799 lr = 0.0000024\n",
      "[22/25][6920/9765] Loss_D: 0.1121 Loss_G: 0.0402 Convergence: 0.1178 k= 0.018792 lr = 0.0000024\n",
      "[22/25][6930/9765] Loss_D: 0.1044 Loss_G: 0.0397 Convergence: 0.1075 k= 0.018782 lr = 0.0000024\n",
      "[22/25][6940/9765] Loss_D: 0.0976 Loss_G: 0.0389 Convergence: 0.0989 k= 0.018766 lr = 0.0000024\n",
      "[22/25][6950/9765] Loss_D: 0.1034 Loss_G: 0.0404 Convergence: 0.1053 k= 0.018767 lr = 0.0000024\n",
      "[22/25][6960/9765] Loss_D: 0.1020 Loss_G: 0.0392 Convergence: 0.1047 k= 0.018752 lr = 0.0000024\n",
      "[22/25][6970/9765] Loss_D: 0.1013 Loss_G: 0.0386 Convergence: 0.1042 k= 0.018750 lr = 0.0000024\n",
      "[22/25][6980/9765] Loss_D: 0.1025 Loss_G: 0.0384 Convergence: 0.1062 k= 0.018740 lr = 0.0000024\n",
      "[22/25][6990/9765] Loss_D: 0.0998 Loss_G: 0.0385 Convergence: 0.1022 k= 0.018728 lr = 0.0000024\n",
      "[22/25][7000/9765] Loss_D: 0.0876 Loss_G: 0.0393 Convergence: 0.0922 k= 0.018713 lr = 0.0000024\n",
      "[22/25][7010/9765] Loss_D: 0.0951 Loss_G: 0.0393 Convergence: 0.0968 k= 0.018721 lr = 0.0000024\n",
      "[22/25][7020/9765] Loss_D: 0.0939 Loss_G: 0.0369 Convergence: 0.0956 k= 0.018728 lr = 0.0000024\n",
      "[22/25][7030/9765] Loss_D: 0.0924 Loss_G: 0.0369 Convergence: 0.0933 k= 0.018732 lr = 0.0000024\n",
      "[22/25][7040/9765] Loss_D: 0.0999 Loss_G: 0.0365 Convergence: 0.1043 k= 0.018753 lr = 0.0000024\n",
      "[22/25][7050/9765] Loss_D: 0.0922 Loss_G: 0.0378 Convergence: 0.0935 k= 0.018767 lr = 0.0000024\n",
      "[22/25][7060/9765] Loss_D: 0.0928 Loss_G: 0.0395 Convergence: 0.0956 k= 0.018776 lr = 0.0000024\n",
      "[22/25][7070/9765] Loss_D: 0.0950 Loss_G: 0.0397 Convergence: 0.0972 k= 0.018777 lr = 0.0000024\n",
      "[22/25][7080/9765] Loss_D: 0.0992 Loss_G: 0.0382 Convergence: 0.1016 k= 0.018774 lr = 0.0000024\n",
      "[22/25][7090/9765] Loss_D: 0.0970 Loss_G: 0.0383 Convergence: 0.0986 k= 0.018784 lr = 0.0000024\n",
      "[22/25][7100/9765] Loss_D: 0.0914 Loss_G: 0.0388 Convergence: 0.0940 k= 0.018785 lr = 0.0000024\n",
      "[22/25][7110/9765] Loss_D: 0.0993 Loss_G: 0.0396 Convergence: 0.1004 k= 0.018775 lr = 0.0000024\n",
      "[22/25][7120/9765] Loss_D: 0.1023 Loss_G: 0.0406 Convergence: 0.1036 k= 0.018767 lr = 0.0000024\n"
     ]
    }
   ],
   "source": [
    "data_loss_D = []\n",
    "data_loss_G = []\n",
    "data_loss_D_real = []\n",
    "data_loss_k = []\n",
    "data_loss_global = []\n",
    "for epoch in range(opt.niter):\n",
    "    index = get_permutation()\n",
    "    for i in range(int(mini_batch)):\n",
    "\n",
    "        ############################\n",
    "        # (1) Update D network\n",
    "        ###########################\n",
    "        netD.zero_grad()\n",
    "\n",
    "        # prepare real\n",
    "        input.data.copy_(get_samples(index, i))\n",
    "#         real_cpu, _ = data\n",
    "#         batch_size = real_cpu.size(0)\n",
    "#         input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "\n",
    "        # train with real\n",
    "        output = netD(input)\n",
    "        errD_real = torch.mean(torch.abs(output - input))  # score on real\n",
    "        errD_real.backward()  # backward on score on real\n",
    "        L_x = errD_real.data[0]  # score fore supervision\n",
    "        \n",
    "        # generate fake\n",
    "        #noise.data.resize_(batch_size, nz, 1, 1)\n",
    "        noise.data.uniform_(-1, 1)\n",
    "        fake = netG(noise)\n",
    "        \n",
    "        # train with fake\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = torch.mean(torch.abs(output - fake))  # score on fake\n",
    "        errD_fake_use = - k * errD_fake\n",
    "        errD_fake_use.backward()  # backward on score on fake\n",
    "        optimizerD.step()\n",
    "        \n",
    "        #D_G_z1 = errD_fake.data.mean()  # score fore supervision <- generated when calc D loss\n",
    "        errD = errD_real + errD_fake_use  # score fore supervision\n",
    "\n",
    "        \n",
    "\n",
    "        ############################\n",
    "        # (2) Update G network\n",
    "        ############################\n",
    "\n",
    "        netG.zero_grad()\n",
    "\n",
    "        # generate fake\n",
    "#         noise.data.resize_(batch_size, nz, 1, 1)\n",
    "#         noise.data.uniform_(-1, 1)\n",
    "        fake_new = netG(noise)\n",
    "        \n",
    "        # NOT reuse generated fake samples\n",
    "        output = netD(fake_new)\n",
    "        errG = torch.mean(torch.abs(output - fake_new))  # L1\n",
    "        errG.backward()\n",
    "        \n",
    "        L_G = errG.data[0] # score fore supervision <- generated when calc G loss\n",
    "\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # K STEP\n",
    "        #left -> real\n",
    "#         output = netD(input)\n",
    "#         errD_real_k = criterion_L1(output, input)  # score on real\n",
    "#         #right -> fake\n",
    "#         fake = netG(noise)\n",
    "#         output = netD(fake.detach())\n",
    "#         errD_fake_k = criterion_L1(output, fake.detach())  # score on fake\n",
    "        \n",
    "        #Convergence Measure\n",
    "        cm = L_x + abs(opt.gamma * L_x - L_G)\n",
    "        \n",
    "        k += 0.001 * (opt.gamma * L_x - L_G)\n",
    "        k = max(min(k, 1), 0)\n",
    "        ############################\n",
    "        # (3) Report & 100 Batch checkpoint\n",
    "        ############################\n",
    "        data_loss_G.append(L_G)\n",
    "        data_loss_D.append(errD.data[0])\n",
    "        data_loss_D_real.append(L_x)\n",
    "        data_loss_k.append(k)\n",
    "        data_loss_global.append(cm)\n",
    "        \n",
    "        if (i + epoch * int(mini_batch)) % opt.lr_decay_every == (opt.lr_decay_every - 1):\n",
    "            optimizerD = optim.Adam(netD.parameters(), lr=opt.lr*opt.lr_decay, betas=(0.5, 0.999))\n",
    "            optimizerG = optim.Adam(netG.parameters(), lr=opt.lr*opt.lr_decay, betas=(0.5, 0.999))\n",
    "            opt.lr = opt.lr * opt.lr_decay\n",
    "        if i % 10 == 0:\n",
    "            print('[%d/%d][%d/%d] Loss_D: %.4f Loss_G: %.4f Convergence: %.4f k= %.6f lr = %.7f' % (epoch, opt.niter, i, int(mini_batch), errD.data[0], L_G, cm, k, opt.lr))\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            fake_fixed = netG(fixed_noise)\n",
    "            vutils.save_image(fake_fixed.data, opt.base_dir+'%05d_fake_samples_epoch_%03d.png' % (i, epoch), normalize = True, scale_each=True)\n",
    "\n",
    "    # do checkpointing\n",
    "    torch.save(netG.state_dict(), opt.base_dir+'netG_epoch_%d.pth' % (epoch))\n",
    "    torch.save(netD.state_dict(), opt.base_dir+'netD_epoch_%d.pth' % (epoch))\n",
    "    np.save(opt.base_dir+'k.npy', np.array(k))\n",
    "    np.save(opt.base_dir+'lr.npy', np.array(opt.lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
